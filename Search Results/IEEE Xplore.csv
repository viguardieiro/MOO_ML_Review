"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies","Y. Jin; B. Sendhoff","Honda Res. Inst. Eur., Offenbach; Honda Res. Inst. Eur., Offenbach","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","18 Apr 2008","2008","38","3","397","415","Machine learning is inherently a multiobjective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can be mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multiobjective optimization methodology have gained increasing impetus, particularly due to the great success of multiobjective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multiobjective learning approaches are more powerful compared to learning algorithms with a scalar cost function in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. One common benefit of the different multiobjective learning approaches is that a deeper insight into the learning problem can be gained by analyzing the Pareto front composed of multiple Pareto-optimal solutions. This paper provides an overview of the existing research on multiobjective machine learning, focusing on supervised learning. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multiobjective ensemble generation are compared and discussed in detail. Finally, potentially interesting topics in multiobjective machine learning are suggested.","1558-2442","","10.1109/TSMCC.2008.919172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4492360","Ensemble;evolutionary multiobjective optimization;generalization;machine learning;multiobjective learning;multiobjective optimization;neural networks;Pareto optimization","Machine learning;Cost function;Machine learning algorithms;Evolutionary computation;Stochastic processes;Search methods;Clustering algorithms;Power generation;Pareto analysis;Supervised learning","evolutionary computation;learning (artificial intelligence);Pareto optimisation","Machine Learning:;Pareto-based multiobjective learning;scalar cost function;multiobjective optimization;evolutionary algorithms","","217","1","94","","18 Apr 2008","","","IEEE","IEEE Journals"
"Multiobjective Evolutionary Data Mining for Performance Improvement of Evolutionary Multiobjective Optimization","Y. Nojima; Y. Tanigaki; N. Masuyama; H. Ishibuchi","Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan; Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan; Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan; Dept. of Comput. Sci. & Eng., Southern Univ. of Sci. & Technol., Shenzhen, China","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","745","750","In recent years, evolutionary multiobjective optimization (EMO) algorithms have frequently been used for engineering problems with some conflicting objective functions to be simultaneously optimized. EMO algorithms can provide a number of Pareto optimal solutions to users. Two scenarios are considered in the practical use of EMO algorithms. One is that a decision maker selects a single solution from the obtained ones after the EMO process. The other is that a decision maker utilizes the solutions to analyze the relationship between design variables and objective functions of the corresponding problem. In this paper, we apply fuzzy genetics-based machine learning to the second scenario in order to generate if-then rule-based classifiers which represent the relationship between design variables and objective functions. We also utilize this method during the EMO process to pre-screen candidate offspring solutions. The classifier detects non-promising offspring solutions. Then, they are discarded before their fitness evaluation, so that the computation resource is used only for promising solutions. We apply this method to one engineering problem and examine its effect on the search performance of an EMO algorithm.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616131","Evolutionary multiobjective optimization;data mining;multiobjective fuzzy genetics-based machine learning;pattern classification","Conferences;Cybernetics;Machine learning;Search problems","data mining;fuzzy set theory;genetic algorithms;learning (artificial intelligence);Pareto optimisation","Pareto optimal solutions;EMO algorithm;decision maker;design variables;fuzzy genetics-based machine;pre-screen candidate offspring solutions;multiobjective evolutionary data mining;performance improvement;evolutionary multiobjective optimization algorithms;conflicting objective functions","","","","25","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Single-Objective/Multiobjective Cat Swarm Optimization Clustering Analysis for Data Partition","D. Yan; H. Cao; Y. Yu; Y. Wang; X. Yu","Shaanxi Key Laboratory of Smart Grid, the State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi’an Jiaotong University, Xi’an, China; Shaanxi Key Laboratory of Smart Grid, the State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi’an Jiaotong University, Xi’an, China; Shaanxi Key Laboratory of Smart Grid, the State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi’an Jiaotong University, Xi’an, China; College of Metropolian Transportation, Beijing University of Technology, Beijing, China; NR Electric Company Ltd., Nanjing, China","IEEE Transactions on Automation Science and Engineering","1 Jul 2020","2020","17","3","1633","1646","This article proposes single-objective/multiobjective cat swarm optimization clustering algorithms for data partition. The proposed methods use the cat swarm to search the optimal. The position of the cat tightly associates with the clustering centers and is updated by two submodes: the seeking mode and the tracing mode. The seeking mode uses the simulated annealing strategy to update the cat position at a probability. Inspired by the quantum theories, the tracing mode adopts the quantum model to update the cat position in the whole solution space. First, the single-objective method is proposed and adopts the cohesion of clustering as the objective function, in which the kernel method is applied. For considering more objective functions to reveal diverse aspects of data, the multiobjective method is proposed and adopts both the cohesion and the connectivity as the objective functions. The Pareto optimization method is applied to balance the objectives. In the experiments, three kinds of data sets are used to examine the effectiveness of the proposed methods, which are three synthetic data sets, four data sets from the UCI Machine Learning Repository, and a field data set. Experimental results verified that the proposed methods perform better than the traditional clustering algorithms, and the proposed multiobjective method has the highest accuracy. Note to Practitioners-This article presents single-objective/multiobjective cat swarm optimization clustering analysis methods for data partition. Through automatically extracting meaningful or useful classes, clustering analysis could help the practitioners or the intelligent devices find the specific meanings of data, natural data structure, the data relationships, or other characteristics. The proposed methods use the cat swarm to search the optimal clustering result. One or more criterion functions could be selected as the optimization objectives. The time complexity of the multiobjective type is higher than that of the single-objective type. Therefore, in the industrial field, engineers should choose the number of the optimization objectives based on the actual requirements. The proposed methods could be widely used into industrial applications to deal with complex data sets. Future research could consider some more progressive optimization schemes to improve the effectiveness.","1558-3783","","10.1109/TASE.2020.2969485","National Natural Science Foundation of China(grant numbers:61375055); Program for New Century Excellent Talents in University(grant numbers:NCET-12-0447); Cooperation and Exchange Program of International Science and Technology of Shaanxi Province(grant numbers:2019KW-010); State Key Laboratory of Electrical Insulation and Power Equipment(grant numbers:EIPE16313); Fundamental Research Funds for the Central University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9032317","Clustering analysis;data partition;quantum model;single-objective/multiobjective optimization","Cats;Clustering algorithms;Particle swarm optimization;Optimization;Linear programming;Genetic algorithms;Convergence","data structures;learning (artificial intelligence);optimisation;Pareto optimisation;particle swarm optimisation;pattern clustering;simulated annealing","seeking mode;cat tightly associates;complex data sets;single-objective type;optimization objectives;optimal clustering result;data partition;traditional clustering algorithms;field data set;Pareto optimization method;multiobjective method;objective function;single-objective method;cat position;tracing mode","","9","","44","IEEE","11 Mar 2020","","","IEEE","IEEE Journals"
"Deep-Learning-Aided Packet Routing in Aeronautical <italic>Ad Hoc</italic> Networks Relying on Real Flight Data: From Single-Objective to Near-Pareto Multiobjective Optimization","D. Liu; J. Zhang; J. Cui; S. -X. Ng; R. G. Maunder; L. Hanzo","School of Cyber Science and Technology, Beihang University, Beijing, China; Department of Computing and Informatics, Bournemouth University, Bournemouth, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.","IEEE Internet of Things Journal","8 Mar 2022","2022","9","6","4598","4614","Data packet routing in aeronautical <italic>ad hoc</italic> networks (AANETs) is challenging due to their high-dynamic topology. In this article, we invoke deep learning (DL) to assist routing in AANETs. We set out from the single objective of minimizing the end-to-end (E2E) delay. Specifically, a deep neural network (DNN) is conceived for mapping the local geographic information observed by the forwarding node into the information required for determining the optimal next hop. The DNN is trained by exploiting the regular mobility pattern of commercial passenger airplanes from historical flight data. After training, the DNN is stored by each airplane for assisting their routing decisions during flight relying solely on local geographic information. Furthermore, we extend the DL-aided routing algorithm to a multiobjective scenario, where we aim for simultaneously minimizing the delay, maximizing the path capacity, and maximizing the path lifetime. Our simulation results based on real flight data show that the proposed DL-aided routing outperforms existing position-based routing protocols in terms of its E2E delay, path capacity, as well as path lifetime, and it is capable of approaching the Pareto front that is obtained using global link information.","2327-4662","","10.1109/JIOT.2021.3105357","Engineering and Physical Sciences Research Council Projects (COALESCE)(grant numbers:EP/P034284/1,EP/P003990/1); European Research Council’s Advanced Fellow Grant QuantCom(grant numbers:789028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514583","Aeronautical ad hoc network (AANET);deep learning (DL);multiobjective optimization (MOO);routing","Routing;Delays;Network topology;Ad hoc networks;Topology;Routing protocols;Measurement","","","","","","25","IEEE","16 Aug 2021","","","IEEE","IEEE Journals"
"Rotation effects of objective functions in parallel distributed multiobjective fuzzy genetics-based machine learning","Y. Takahashi; Y. Nojima; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Osaka Prefecture University, Sakai, Osaka, Japan; Department of Computer Science and Intelligent Systems, Osaka Prefecture University, Sakai, Osaka, Japan; Department of Computer Science and Intelligent Systems, Osaka Prefecture University, Sakai, Osaka, Japan","2015 10th Asian Control Conference (ASCC)","10 Sep 2015","2015","","","1","6","Fuzzy genetics-based machine learning (FGBML) is one of data mining techniques using evolutionary computation. It can obtain fuzzy rule-based classifiers that are accurate and linguistically interpretable for human users. However, there are two major problems. One is that it is impossible to design the best classifier with respect to both accuracy and interpretability due to their tradeoff. To solve this problem, we proposed multiobjective FGBML (MoFGBML) where an evolutionary multiobjective optimization algorithm is used to obtain a number of classifiers with different tradeoffs between accuracy and complexity. The other is the heavy computational load of FGBML for large data sets. In the previous study, we applied parallel distributed implementation to our MoFGBML to overcome this problem. We examined the effects of the parallel distributed implementation on the search ability. Although the computational time became much shorter, the number of the obtained non-dominated classifiers became small. As a result, accurate classifiers were not obtained for some data sets. In this paper, we propose a simple idea to bias the search direction of our MoFGBML. We rotate one or two objective functions. This rotation changes the dominance relation in multiobjective optimization. Through computational experiments, we examine the effects of the rotated objective functions on the search ability of our MoFGBML for large data sets.","","978-1-4799-7862-5","10.1109/ASCC.2015.7244890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244890","Fuzzy genetics-based machine learning;parallel distributed implementation;multiobjective optimization","Linear programming;Error analysis;Training data;Data models;Accuracy;Sociology;Statistics","data mining;fuzzy set theory;genetic algorithms;learning (artificial intelligence);search problems","objective functions;rotation effects;distributed multiobjective fuzzy genetics-based machine learning;data mining techniques;evolutionary computation;fuzzy rule-based classifiers;multiobjective FGBML;MoFGBML;computational load;search ability;computational time;nondominated classifiers","","1","","20","","10 Sep 2015","","","IEEE","IEEE Conferences"
"Multicriteria PM Motor Design Based on ANFIS Evaluation of EV Driving Cycle Efficiency","C. T. Krasopoulos; M. E. Beniakar; A. G. Kladas","Department of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; ABB Corporate Research Center, Västerås, Sweden; Department of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece","IEEE Transactions on Transportation Electrification","6 Jun 2018","2018","4","2","525","535","This paper proposes a multicriteria design optimization methodology for permanent magnet (PM) motors used in electric vehicle (EV) applications. In the process, an adaptive-network-based fuzzy inference system (ANFIS) is utilized, coupled with a multiobjective optimization algorithm, as a surrogate model of the electric motor. This allows for the consideration of the full drive cycle and respective efficiency map for every motor design. The prediction error of the ANFIS is minimized by employing appropriate membership functions, initial training data, and an adaptive learning scheme via iterative training. The efficiency map is then implemented in a vehicle dynamic model to compute the total consumed energy over the driving cycle. The optimization profile accounts for total energy efficiency, torque density, and additionally considers complementary design criteria via an a posteriori selection procedure on the resulting Pareto set. The methodology developed is applied to optimize a surface PM motor with concentrated fractional slot winding, mounted on a light EV that competes in fuel economy races. The selected motor design has been validated through measurements on a prototype.","2332-7782","","10.1109/TTE.2018.2810707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304609","Adaptive-network-based fuzzy inference system (ANFIS);drive cycle;efficiency map;electric vehicle (EV);energy efficiency;machine learning;multicriteria design;multiobjective optimization;permanent magnet (PM) motor design;torque density","Optimization;Torque;Permanent magnet motors;Traction motors;Computational modeling;Geometry;Adaptation models","electric machine analysis computing;electric vehicles;fuel economy;fuzzy reasoning;learning (artificial intelligence);Pareto optimisation;permanent magnet motors;torque;vehicle dynamics","permanent magnet motors;electric vehicle applications;multiobjective optimization algorithm;electric motor;drive cycle;initial training data;adaptive learning scheme;iterative training;vehicle dynamic model;optimization profile accounts;total energy efficiency;complementary design criteria;surface PM motor;light EV;ANFIS evaluation;EV driving cycle efficiency;multicriteria design optimization methodology;adaptive-network-based fuzzy inference system;membership functions;torque density","","31","","30","IEEE","28 Feb 2018","","","IEEE","IEEE Journals"
"Machine Learning for Multiobjective Evolutionary Optimization in Python for EM Problems","A. Boryssenko; N. Herscovici","A&E Partnership, Belchertown, MA, USA; Framingham, MA, USA","2018 IEEE International Symposium on Antennas and Propagation & USNC/URSI National Radio Science Meeting","13 Jan 2019","2018","","","541","542","A highly efficient algorithm for the optimization of EM problems is proposed. The algorithm is mostly based on Python open-source libraries and was successfully used in the development of antennas and arrays using HFSS.","1947-1491","978-1-5386-7102-3","10.1109/APUSNCURSINRSM.2018.8609394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8609394","machine learning;surrogate objective function;multiobjective evolutionary algorithm (MOEA);Gaussian process;HFSS","Optimization;Linear programming;Python;Machine learning;Machine learning algorithms;Antenna arrays;Computational modeling","evolutionary computation;learning (artificial intelligence);optimisation;Python","multiobjective evolutionary optimization;EM problems;Python open-source libraries;Machine Learning;HFSS;antennas","","2","","7","","13 Jan 2019","","","IEEE","IEEE Conferences"
"Multiple Reference Points-Based Decomposition for Multiobjective Feature Selection in Classification: Static and Dynamic Mechanisms","B. H. Nguyen; B. Xue; P. Andreae; H. Ishibuchi; M. Zhang","School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China","IEEE Transactions on Evolutionary Computation","29 Jan 2020","2020","24","1","170","184","Feature selection is an important task in machine learning that has two main objectives: 1) reducing dimensionality and 2) improving learning performance. Feature selection can be considered a multiobjective problem. However, it has its problematic characteristics, such as a highly discontinuous Pareto front, imbalance preferences, and partially conflicting objectives. These characteristics are not easy for existing evolutionary multiobjective optimization (EMO) algorithms. We propose a new decomposition approach with two mechanisms (static and dynamic) based on multiple reference points under the multiobjective evolutionary algorithm based on decomposition (MOEA/D) framework to address the above-mentioned difficulties of feature selection. The static mechanism alleviates the dependence of the decomposition on the Pareto front shape and the effect of the discontinuity. The dynamic one is able to detect regions in which the objectives are mostly conflicting, and allocates more computational resources to the detected regions. In comparison with other EMO algorithms on 12 different classification datasets, the proposed decomposition approach finds more diverse feature subsets with better performance in terms of hypervolume and inverted generational distance. The dynamic mechanism successfully identifies conflicting regions and further improves the approximation quality for the Pareto fronts.","1941-0026","","10.1109/TEVC.2019.2913831","Marsden Fund(grant numbers:VUW1509,VUW1615); Huawei Industry(grant numbers:E2880/3663); Victoria University of Wellington(grant numbers:216378/3764); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703157","Classification;feature selection;multiobjective evolutionary algorithm based on decomposition (MOEA/D);multiobjective optimization;partially conflicting","Feature extraction;Heuristic algorithms;Optimization;Task analysis;Approximation algorithms;Sociology;Statistics","evolutionary computation;feature selection;learning (artificial intelligence);Pareto optimisation;pattern classification","multiple reference points-based decomposition;multiobjective feature selection;static mechanisms;dynamic mechanisms;machine learning;highly discontinuous Pareto front;evolutionary multiobjective optimization algorithms;multiobjective evolutionary algorithm;EMO algorithms;diverse feature subsets","","23","","47","IEEE","30 Apr 2019","","","IEEE","IEEE Journals"
"Expensive Multiobjective Evolutionary Optimization Assisted by Dominance Prediction","Y. Yuan; W. Banzhaf","Department of Computer Science and Engineering and the BEACON Center for the Study of Evolution in Action, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering and the BEACON Center for the Study of Evolution in Action, Michigan State University, East Lansing, MI, USA","IEEE Transactions on Evolutionary Computation","28 Jan 2022","2022","26","1","159","173","We propose a new surrogate-assisted evolutionary algorithm for expensive multiobjective optimization. Two classification-based surrogate models are used, which can predict the Pareto dominance relation and <inline-formula> <tex-math notation=""LaTeX"">$\theta $ </tex-math></inline-formula>-dominance relation between two solutions, respectively. To make such surrogates as accurate as possible, we formulate dominance prediction as an imbalanced classification problem and address this problem using deep learning techniques. Furthermore, to integrate the surrogates based on dominance prediction with multiobjective evolutionary optimization, we develop a two-stage preselection strategy. This strategy aims to select a promising solution to be evaluated among those produced by genetic operations, taking proper account of the balance between convergence and diversity. We conduct an empirical study on a number of well-known multiobjective and many-objective benchmark problems, over a relatively small number of function evaluations. Our experimental results demonstrate the superiority of the proposed algorithm compared with several representative surrogate-assisted algorithms.","1941-0026","","10.1109/TEVC.2021.3098257","John R. Koza Chair Endowment Fund to Michigan State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490636","Deep neural networks;expensive multiobjective optimization;many-objective optimization;metamodeling;surrogate-assisted evolutionary computation","Optimization;Predictive models;Computational modeling;Convergence;Support vector machines;Linear programming;Prediction algorithms","","","","","","65","IEEE","19 Jul 2021","","","IEEE","IEEE Journals"
"Multiobjective Neural Network Ensembles Based on Regularized Negative Correlation Learning","H. Chen; X. Yao","University of Birmingham, Birmingham; University of Birmingham, Birmingham","IEEE Transactions on Knowledge and Data Engineering","28 Oct 2010","2010","22","12","1738","1751","Negative Correlation Learning (NCL) [CHECK END OF SENTENCE], [CHECK END OF SENTENCE] is a neural network ensemble learning algorithm which introduces a correlation penalty term to the cost function of each individual network so that each neural network minimizes its mean-square-error (MSE) together with the correlation. This paper describes NCL in detail and observes that the NCL corresponds to training the entire ensemble as a single learning machine that only minimizes the MSE without regularization. This insight explains that NCL is prone to overfitting the noise in the training set. The paper analyzes this problem and proposes the multiobjective regularized negative correlation learning (MRNCL) algorithm which incorporates an additional regularization term for the ensemble and uses the evolutionary multiobjective algorithm to design ensembles. In MRNCL, we define the crossover and mutation operators and adopt nondominated sorting algorithm with fitness sharing and rank-based fitness assignment. The experiments on synthetic data as well as real-world data sets demonstrate that MRNCL achieves better performance than NCL, especially when the noise level is nontrivial in the data set. In the experimental discussion, we give three reasons why our algorithm outperforms others.","1558-2191","","10.1109/TKDE.2010.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416712","Multiobjective algorithm;multiobjective learning;neural network ensembles;neural networks;negative correlation learning;regularization.","Neural networks;Machine learning;Cost function;Machine learning algorithms;Algorithm design and analysis;Genetic mutations;Sorting;Noise level;Computational intelligence;Application software","evolutionary computation;learning (artificial intelligence);mathematical operators;mean square error methods;neural nets;sorting","multiobjective neural network ensembles;neural network ensemble learning algorithm;correlation penalty term;cost function;mean-square-error;multiobjective regularized negative correlation learning algorithm;evolutionary multiobjective algorithm;crossover operator;mutation operator;nondominated sorting algorithm;fitness sharing;rank-based fitness assignment","","83","1","42","","18 Feb 2010","","","IEEE","IEEE Journals"
"Feature Selection Using Multiobjective Optimization for Named Entity Recognition","A. Ekbal; S. Saha; C. S. Garbe","Dept. of Comput. Linguistics, Heidelberg Univ., Heidelberg, Germany; Interdiscipl. Center for Sci. Comput. (IWR), Heidelberg Univ., Heidelberg, Germany; NA","2010 20th International Conference on Pattern Recognition","7 Oct 2010","2010","","","1937","1940","Appropriate feature selection is a very crucial issue in any machine learning framework, specially in Maximum Entropy (ME). In this paper, the selection of appropriate features for constructing a ME based Named Entity Recognition (NER) system is posed as a multiobjective optimization (MOO) problem. Two classification quality measures, namely recall and precision are simultaneously optimized using the search capability of a popular evolutionary MOO technique, NSGA-II. The proposed technique is evaluated to determine suitable feature combinations for NER in two languages, namely Bengali and English that have significantly different characteristics. Evaluation results yield the recall, precision and F-measure values of 70.76%, 81.88% and 75.91%, respectively for Bengali, and 78.38%, 81.27% and 79.80%, respectively for English. Comparison with an existing ME based NER system shows that our proposed feature selection technique is more efficient than the heuristic based feature selection.","1051-4651","978-1-4244-7541-4","10.1109/ICPR.2010.477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5597245","Multiobjective Optimization;Feature Selection;Maximum Entropy;Named Entity Recognition","Biological cells;Optimization;Training data;Entropy;Training;Machine learning;Context","feature extraction;image recognition;learning (artificial intelligence);optimisation","multiobjective optimization;named entity recognition;maximum entropy;classification quality measures;evolutionary MOO technique;NSGA-II;feature selection technique;heuristic based feature selection","","17","","6","","7 Oct 2010","","","IEEE","IEEE Conferences"
"Neural-Architecture-Search-Based Multiobjective Cognitive Automation System","E. K. Wang; S. P. Xu; C. -M. Chen; N. Kumar","Department of Computer Science, Harbin Institute of Technology (Shenzhen), Harbin, China; Department of Computer Science, Harbin Institute of Technology (Shenzhen), Harbin, China; Shandong University of Science and Technology, Shandong, China; Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan","IEEE Systems Journal","7 Jun 2021","2021","15","2","2918","2925","Currently, deep-learning-based cognitive automation for decision-making in industrial informatics is a new hot topic in the field of cognitive computing, among which multiobjective architecture optimization is of great difficulty in the research area. When the existing algorithms face multiobjective cognitive model problems, it often takes a lot of time to continuously set different search preference parameters to generate a new search process. This article mainly aims to solve the problem in a multiobjective neural architecture search process, and the key issue is how to adapt user preferences during architectural search. We propose a new algorithm: linear-prefer coevolutionary algorithm. Compared to the original user-constrained method and the Pareto-dominant NSGA-II algorithm, we have faster adaptation time and better quality of adaptation. At the same time, it can respond to user's needs at a relatively faster pace during the reasoning phase. Based on a large number of comparative test results, our algorithm is superior to the traditional cognitive automation algorithms for the multiobjective problem in search quality.","1937-9234","","10.1109/JSYST.2020.3002428","National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2018YFB1003800,2018YFB1003805); Natural Science Foundation of Guangdong Province(grant numbers:2016A030313660,2017A030313365); Shenzhen Municipal Science and Technology Innovation Project(grant numbers:JCYJ20160608161351559,KQJSCX70726103044992,JCYJ20170811155158682,JCYJ20160428092427867); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9127493","Cognitive automation;evolutional algorithm;multiobjective;neural architecture search (NAS);Pareto dominant","Search problems;Optimization;Automation;Computer architecture;Neural networks;Evolutionary computation;Cognitive systems","cognitive systems;evolutionary computation;neural nets;search problems","user-constrained method;cognitive automation algorithms;search preference parameters;multiobjective cognitive model problems;multiobjective architecture optimization;cognitive computing;deep-learning-based cognitive automation;neural-architecture-search-based multiobjective cognitive automation system;Pareto-dominant NSGA-II algorithm;linear-prefer coevolutionary algorithm;multiobjective neural architecture search process","","1","","31","IEEE","29 Jun 2020","","","IEEE","IEEE Journals"
"Collective Personalized Change Classification With Multiobjective Search","X. Xia; D. Lo; X. Wang; X. Yang","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China","IEEE Transactions on Reliability","29 Nov 2016","2016","65","4","1810","1829","Many change classification techniques have been proposed to identify defect-prone changes. These techniques consider all developers' historical change data to build a global prediction model. In practice, since developers have their own coding preferences and behavioral patterns, which causes different defect patterns, a separate change classification model for each developer can help to improve performance. Jiang, Tan, and Kim refer to this problem as personalized change classification, and they propose PCC+ to solve this problem. A software project has a number of developers; for a developer, building a prediction model not only based on his/her change data, but also on other relevant developers' change data can further improve the performance of change classification. In this paper, we propose a more accurate technique named collective personalized change classification (CPCC), which leverages a multiobjective genetic algorithm. For a project, CPCC first builds a personalized prediction model for each developer based on his/her historical data. Next, for each developer, CPCC combines these models by assigning different weights to these models with the purpose of maximizing two objective functions (i.e., F1-scores and cost effectiveness). To further improve the prediction accuracy, we propose CPCC+ by combining CPCC with PCC proposed by Jiang, Tan, and Kim To evaluate the benefits of CPCC+ and CPCC, we perform experiments on six large software projects from different communities: Eclipse JDT, Jackrabbit, Linux kernel, Lucene, PostgreSQL, and Xorg. The experiment results show that CPCC+ can discover up to 245 more bugs than PCC+ (468 versus 223 for PostgreSQL) if developers inspect the top 20% lines of code that are predicted buggy. In addition, CPCC+ can achieve F1-scores of 0.60-0.75, which are statistically significantly higher than those of PCC+ on all of the six projects.","1558-1721","","10.1109/TR.2016.2588139","National Basic Research Program of China(grant numbers:2015CB352201); National Natural Science Foundation of China(grant numbers:61572426); National Key Technology R&D Program of the Ministry of Science and Technology of China(grant numbers:2015BAH17F01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7518675","Cost effectiveness;developer;machine learning;multiobjective genetic algorithm;personalized change classification (PCC)","Data models;Predictive models;Software;Computer bugs;Genetic algorithms;Feature extraction;Buildings","genetic algorithms;program debugging","collective personalized change classification technique;multiobjective search;PCC+;software project;CPCC;multiobjective genetic algorithm;personalized prediction model;Eclipse JDT;Jackrabbit;Linux kernel;Lucene;PostgreSQL;Xorg","","27","","65","IEEE","21 Jul 2016","","","IEEE","IEEE Journals"
"Evolutionary Multiobjective Optimization Driven by Generative Adversarial Networks (GANs)","C. He; S. Huang; R. Cheng; K. C. Tan; Y. Jin","Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-Inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-Inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-Inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, University of Surrey, Guildford, U.K.","IEEE Transactions on Cybernetics","18 May 2021","2021","51","6","3129","3142","Recently, increasing works have been proposed to drive evolutionary algorithms using machine-learning models. Usually, the performance of such model-based evolutionary algorithms is highly dependent on the training qualities of the adopted models. Since it usually requires a certain amount of data (i.e., the candidate solutions generated by the algorithms) for model training, the performance deteriorates rapidly with the increase of the problem scales due to the curse of dimensionality. To address this issue, we propose a multiobjective evolutionary algorithm driven by the generative adversarial networks (GANs). At each generation of the proposed algorithm, the parent solutions are first classified into real and fake samples to train the GANs; then the offspring solutions are sampled by the trained GANs. Thanks to the powerful generative ability of the GANs, our proposed algorithm is capable of generating promising offspring solutions in high-dimensional decision space with limited training data. The proposed algorithm is tested on ten benchmark problems with up to 200 decision variables. The experimental results on these test problems demonstrate the effectiveness of the proposed algorithm.","2168-2275","","10.1109/TCYB.2020.2985081","National Natural Science Foundation of China(grant numbers:61903178,61906081); Program for Guangdong Introducing Innovative and Entrepreneurial Teams(grant numbers:2017ZT07X386); Shenzhen Peacock Plan(grant numbers:KQTD2016112514355531); Program for University Key Laboratory of Guangdong Province(grant numbers:2017KSYS008); Research Grants Council of the Hong Kong(grant numbers:CityU11202418,CityU11209219); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082904","Deep learning;machine learning;evolutionary algorithm;generative adversarial networks (GANs);machine learning;multiobjective optimization","Optimization;Computational modeling;Generative adversarial networks;Machine learning;Evolutionary computation;Training data;Adaptation models","genetic algorithms;learning (artificial intelligence);neural nets;Pareto optimisation","evolutionary multiobjective optimization;generative adversarial networks;machine-learning models;model-based evolutionary algorithms;model training;parent solutions;trained GAN;offspring solutions;high-dimensional decision space;training data","","20","","72","IEEE","30 Apr 2020","","","IEEE","IEEE Journals"
"Search ability of evolutionary multiobjective optimization algorithms for multiobjective fuzzy genetics-based machine learning","H. Ishibuchi; Y. Nakashima; Y. Nojima","Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, Osaka 599-8531, Japan","2009 IEEE International Conference on Fuzzy Systems","2 Oct 2009","2009","","","1724","1729","Recently evolutionary multiobjective optimization (EMO) algorithms have been actively used for the design of accurate and interpretable fuzzy rule-based systems. This research area is often referred to as multiobjective genetic fuzzy systems where EMO algorithms are used to search for a number of non-dominated fuzzy rule-based systems with respect to their accuracy and interpretability. The main advantage of the use of EMO algorithms for fuzzy system design over single-objective optimizers is that multiple alternative fuzzy rule-based systems with different accuracy-interpretability tradeoffs are obtained by their single run. The decision maker can choose a single fuzzy rule-based system according to their preference. There still exist several important issues to be discussed in this research area such as the definition of interpretability, the formulation of interpretability measures, the visualization of tradeoff relations, and the interpretability of the explanation of fuzzy reasoning results. In this paper, we discuss the ability of EMO algorithms as multiobjective optimizers to search for Pareto optimal or near Pareto optimal fuzzy rule-based systems. More specifically, we examine whether EMO algorithms can find non-dominated fuzzy rule-based systems that approximate the entire Pareto fronts of multiobjective fuzzy system design problems.","1098-7584","978-1-4244-3596-8","10.1109/FUZZY.2009.5277370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5277370","","Machine learning algorithms;Machine learning;Fuzzy systems;Knowledge based systems;Algorithm design and analysis;Design optimization;Genetics;Area measurement;Visualization;Fuzzy reasoning","fuzzy reasoning;genetic algorithms;learning (artificial intelligence);Pareto optimisation;search problems","search ability;evolutionary multiobjective optimization algorithm;multiobjective fuzzy genetics;machine learning;fuzzy rule-based system;fuzzy system design;single-objective optimizer;fuzzy reasoning;Pareto optimal","","6","","27","","2 Oct 2009","","","IEEE","IEEE Conferences"
"Multiobjective evolution for deep learning and its robotic applications","D. Hossain; G. Capi","Graduate School of Science and Engineering for Education, University of Toyama, Toyama, Japan; Department of Mechanical Engineering, Hosei University, Tokyo, Japan","2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Mar 2018","2017","","","1","6","In numerous industrial applications where robot object recognition and grasping are the primary concern as the most effective and reliable object sorting policy. Deep Learning approaches have produced promising results in object recognition and robot gasping, its performance does not have any influence from handcrafted features. In this paper, we propose a multiobjective deep belief neural network (DBNN) method. It employs a multiobjective evolutionary algorithm integrated with DBNN [10] training technique subject to accuracy and network time as two conflicting objectives. We evaluate the proposed method on the real-time object recognition and robot grasping tasks. Experimental results demonstrate that the proposed method outperforms on the assign tasks.","","978-1-5386-3731-9","10.1109/IISA.2017.8316404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316404","deep learning;multiobjective;object recognition;robot grasping;deep belief neural network (DBNN);NSGA-II","Machine learning;Robots;Training;Genetic algorithms;Feature extraction;Object recognition;Grasping","belief networks;control engineering computing;evolutionary computation;learning (artificial intelligence);neural nets;object recognition;robot vision","multiobjective evolution;robotic applications;robot object recognition;handcrafted features;multiobjective evolutionary algorithm;real-time object recognition;robot grasping tasks;industrial applications;Deep Learning;object sorting policy;multiobjective deep belief neural network;DBNN","","4","","28","","15 Mar 2018","","","IEEE","IEEE Conferences"
"A Selective Ensemble Classifier Using Multiobjective Optimization Based Extreme Learning Machine Algorithm","L. Bai; H. Li; W. Gao","School of Mathematics and Statistics, Xidian University,Xi'an,China; School of Mathematics and Statistics, Xidian University,Xi'an,China; School of Mathematics and Statistics, Xidian University,Xi'an,China","2021 17th International Conference on Computational Intelligence and Security (CIS)","11 Feb 2022","2021","","","40","44","In a single hidden layer feedforward neural network (SLFN), acquiring optimal values for the number of hidden neurons and connection parameters simultaneously is regarded as one of challenges, which has attracted extensive attention. This is because changing the number of hidden neurons and connection parameters greatly affect overall performance of the SLFN and increase the training complexity. In this article, the training error, validation error, and network complexity are treated as three conflicting objectives of multiobjective model for getting a compact network with good generalization ability. For solving the multiobjective model, a hybrid coding scheme is designed for network structure and connection parameters of a SLFN, and then a multiobjective optimization based extreme learning machine (MOELM) is proposed for structure learning and parameter optimization simultaneously. To improve recognition accuracy, a selective ensemble classifier with three base classifiers according to the selection strategy is utilized to make final decision. Experimental results and comparison with other classifiers on several benchmark classification problems indicate the effectiveness and superiority of the proposed MOELM.","","978-1-6654-9489-2","10.1109/CIS54983.2021.00017","National Natural Science Foundation of China(grant numbers:61966030,61772391); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701767","feedforward neural network;extreme learning machine;multiobjective optimization;ensemble learning;classification","Training;Extreme learning machines;Neurons;Pareto optimization;Encoding;Complexity theory;Classification algorithms","","","","","","14","","11 Feb 2022","","","IEEE","IEEE Conferences"
"SDN-Enabled Adaptive and Reliable Communication in IoT-Fog Environment Using Machine Learning and Multiobjective Optimization","A. Akbar; M. Ibrar; M. A. Jan; A. K. Bashir; L. Wang","Department of Computer Science, Abdul Wali Khan University Mardan, Mardan, Pakistan; School of Software, Dalian University of Technology, Dalian, China; Department of Computer Science, Abdul Wali Khan University Mardan, Mardan, Pakistan; School of Computing and Mathematics, Manchester Metropolitan University, Manchester, U.K.; School of Software, Dalian University of Technology, Dalian, China","IEEE Internet of Things Journal","18 Feb 2021","2021","8","5","3057","3065","The Internet-of-Things (IoT) devices, backed by resourceful fog computing, are capable of meeting the requirements of computationally-intensive tasks. However, many existing IoT applications are unable to perform well, due to different Quality-of-Service (QoS) requirements, while communicating with the fog server. Besides, constantly changing traffic demands of applications is another challenge. For example, the demand for real-time applications includes communicating over a path that is less prone to delay, and applications that offload computationally intensive tasks to the fog server need a reliable path that has a lower probability of link failure. This results in a tradeoff between conflicting objectives that are constantly evolving, i.e., minimizing end-to-end delay and maximizing the reliability of paths between IoT devices and the fog server. We propose a novel approach that takes advantage of machine learning (ML) and multiobjective optimization (MOO)-based techniques. The reliability of links is evaluated using an ML-based algorithm in an software-defined network (SDN)-enabled multihop scenario for the IoT-fog environment. By considering the two conflicting objectives, the MOO algorithm is used to find the Pareto-optimal paths. Our experimental evaluation considers two applications with different QoS requirements-a real-time application (App-1) using UDP sockets and a task offloading application (App-2) using TCP sockets. Our results show that: 1) the tradeoff between the two objectives can be optimized and 2) the SDN controller was able to make adaptive decision on-the-fly to choose the best path from the Pareto-optimal set. The App-1 communicating over the selected path finished its execution in 13% less time than communicating over the shortest path. The App-2 had 41% less packet loss using the selected path compared to using the shortest path.","2327-4662","","10.1109/JIOT.2020.3038768","“National Key Research and Development Plan”(grant numbers:2017YFC0821003-2); “Dalian Science and Technology Innovation Fund”(grant numbers:2019J11CY004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261365","Fog computing;Internet of Things (IoT);machine learning (ML);multiobjective optimization (MOO);software-defined networks (SDNs)","Reliability;Internet of Things;Delays;Quality of service;Servers;Quality of experience;Edge computing","cloud computing;Internet;Internet of Things;mobile computing;optimisation;Pareto optimisation;quality of service;telecommunication network reliability;telecommunication traffic;transport protocols","IoT-fog environment;Internet-of-Things devices;resourceful fog computing;computationally-intensive tasks;existing IoT applications;Quality-of-Service requirements;fog server;traffic demands;real-time application;offload computationally intensive tasks;reliable path;end-to-end delay;IoT devices;ML-based algorithm;software-defined network-enabled multihop scenario;Pareto-optimal paths;different QoS requirements-a;task offloading application;Pareto-optimal set;App-1 communicating;selected path;shortest path;App-2","","11","","31","IEEE","17 Nov 2020","","","IEEE","IEEE Journals"
"Multiobjective Design of 2-D-Material-Based Field-Effect Transistors With Machine Learning Methods","T. Wu; J. Guo","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","IEEE Transactions on Electron Devices","21 Oct 2021","2021","68","11","5476","5482","Design optimization of emerging nanoscale transistor technologies often requires careful design tradeoff between many objectives, including speed, power, variability, and so on. By leveraging machine learning (ML) methods, we develop a multiobjective optimization (MOO) framework for 2-D-material-based field-effect transistors (FETs) near the scaling limit. The MOO design framework performs gradient-free efficient global optimization and offers the option of using active learning. Optimum designs with a tradeoff between transistor speed, power, and variability are identified automatically for transition metal dichalcogenide (TMDC) and black phosphorene FETs by applying the MOO design framework that couples ML methods to quantum transport device simulations. The design optimization results show that the International Roadmap of Devices and Systems (IRDS) target of 2025 and 2028 technology nodes can be met by 2-D FETs.","1557-9646","","10.1109/TED.2021.3085701","NSF(grant numbers:1904580,1809770); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9457054","2-D field-effect transistors (FETs);active learning;global optimization;machine learning (ML);multiobjective optimization (MOO);nanoscale transistors;transistor simulation","Field effect transistors;Optimization;Logic gates;Nanoscale devices;Effective mass;Performance evaluation;Capacitance","electronic engineering computing;field effect transistors;learning (artificial intelligence);nanoelectronics;optimisation;semiconductor device models;transition metals","transistor speed;couples ML methods;multiobjective design;2-D-material-based field-effect transistors;nanoscale transistor technologies;careful design tradeoff;leveraging machine learning methods;multiobjective optimization framework;active learning;optimum designs;MOO design framework;gradient-free efficient global optimization;transition metal dichalcogenide;TMDC;black phosphorene FET;quantum transport device simulations","","","","24","IEEE","16 Jun 2021","","","IEEE","IEEE Journals"
"Multiobjective fuzzy genetics-based machine learning with a reject option","Y. Nojima; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, 599-8531, Japan","2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","10 Nov 2016","2016","","","1405","1412","Classifier design for a classification problem with M classes can be viewed as finding an optimal partition of its pattern space into M disjoint subspaces. However, this is not always a good strategy especially when training patterns from different classes are heavily overlapping in the pattern space. A simple but practically useful idea is the use of a reject option. In this case, the pattern space is partitioned into (M+1) disjoint subspace where the classification of new patterns is rejected in the (M+1)th subspace. In this paper, we discuss the design of fuzzy rule-based classifiers with a reject option. The rejection subspace is specified by a threshold value for the difference of a kind of matching degrees between the best matching class and the second best matching class. The important research question is how to specify the threshold value. We examine the following two approaches: One is manual specification after designing a fuzzy rule-based classifier, and the other is simultaneous multiobjective optimization of a threshold value and a fuzzy rule-based classifier. In the latter approach, we use three objectives: maximization of the correct classification, and minimization of the rejection and the complexity of the classifier.","","978-1-5090-0626-7","10.1109/FUZZ-IEEE.2016.7737854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7737854","Fuzzy genetics-based machine learning;reject option;evolutionary multiobjective optimization","Complexity theory;Optimization;Minimization;Training data;Training;Error analysis;Fuzzy systems","fuzzy set theory;knowledge based systems;learning (artificial intelligence);optimisation;pattern classification","multiobjective fuzzy genetics;machine learning;reject option;classifier design;pattern space;training patterns;fuzzy rule-based classifiers;multiobjective optimization","","1","","19","","10 Nov 2016","","","IEEE","IEEE Conferences"
"Determination of Weights for Multiobjective Decision Making or Machine Learning","P. Wang; H. Zhu; M. Wilamowska-Korsak; Z. Bi; L. Li","School of Automation and the Institute of Systems Science and Engineering, Wuhan University of Technology, Wuhan, China; City University of Hong Kong, Kowloon, Hong Kong; Warmia and Mazury University, Olsztyn, Poland; Indiana University–Purdue University Fort Wayne, Fort Wayne, IN, USA; Old Dominion University, Norfolk, VA, USA","IEEE Systems Journal","14 Feb 2014","2014","8","1","63","72","Decision-making processes in complex systems generally require the mechanisms to make the tradeoff among contradicting design criteria. When multiple objectives are involved in decision making or machine learning, a crucial step is to determine the weights of individual objectives to the system-level performance. Determining the weights of multiobjectives is an evaluation process, and it has been often treated as an optimization problem. However, our preliminary investigation has shown that existing methodologies in dealing with the weights of multiobjectives have some obvious limitations in the sense that the determination of weights is tackled as a single optimization problem, a result based on such an optimization is incomprehensive, and it can even be unreliable when the information about multiple objectives is incomplete such as an incompleteness caused by poor data. The constraints of weights are also discussed. Variable weights are natural in decision-making processes. Therefore, we are motivated to develop a systematic methodology in determining variable weights of multiobjectives. The roles of weights in an original multiobjective decision-making or machine-learning problem are analyzed, and the weights are determined with the aid of a modular neural network. The inconsistency issue of weights is particularly discussed.","1937-9234","","10.1109/JSYST.2013.2265663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547983","Consistency;multidisciplinary design optimization (MDO);multifunctional machine learning (MFML);multiobjective decision making (MODM);neural network;tradeoff;variable weights","Decision making;Optimization;Machine learning;Task analysis;Complex systems;Neural networks;Aerodynamics","decision making;learning (artificial intelligence);neural nets;optimisation","weight determination;multiobjective decision making;machine learning;optimization problem;modular neural network","","12","","66","IEEE","27 Jun 2013","","","IEEE","IEEE Journals"
"An Entropy Driven Multiobjective Particle Swarm Optimization Algorithm for Feature Selection","J. Luo; D. Zhou; L. Jiang; H. Ma","Beijing University of Posts and Telecommunications,Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia,Beijing,China; Northern Institute of Electronic Equipment of China,Beijing,China; Beijing University of Posts and Telecommunications,Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia,Beijing,China; Beijing University of Posts and Telecommunications,Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia,Beijing,China","2021 IEEE Congress on Evolutionary Computation (CEC)","9 Aug 2021","2021","","","768","775","Feature selection is an important research field in machine learning since high-dimensionality is a common characteristic of real-world data. It has two main objectives, which are to maximize the classification accuracy while minimizing the number of selected features. As the two objectives are usually in conflict with each other, it makes feature selection a multi-objective problem. However, the large search space and discrete Pareto front makes it not easy for existing evolutionary multi-objective algorithms. In order to deal with the above mentioned difficulties in feature selection, an entropy driven multiobjective particle swarm optimization algorithm is proposed to remove redundant feature and decrease computational complexity. First, its basic idea is to model feature selection as a multiobjective optimization problem by optimizing the number of features and the classification accuracy in supervised condition simultaneously. Second, a particle initialization strategy based on information entropy is designed to improve the quality of initial solutions, and an adaptive velocity update rule is used to swap between local search and global search. Besides, a specified discrete nondominated sorting is designed. These strategies enable the proposed algorithm to gain better performance on both the quality and size of feature subset. The experimental results show that the proposed algorithm can maintain or improve the quality of Pareto fronts evolved by the state-of-the-art algorithms for feature selection.","","978-1-7281-8393-0","10.1109/CEC45853.2021.9504837","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504837","feature selection;multiobjective optimization;particle swarm optimization","Feature extraction;Entropy;Robustness;Classification algorithms;Particle swarm optimization;Task analysis;Information entropy","computational complexity;entropy;evolutionary computation;Pareto optimisation;particle swarm optimisation;pattern classification;search problems;sorting;supervised learning","feature selection;entropy driven multiobjective particle swarm optimization algorithm;evolutionary multiobjective algorithms;machine learning;classification accuracy;search space;discrete Pareto front;computational complexity;supervised condition;particle initialization strategy;information entropy;adaptive velocity update rule;discrete nondominated sorting","","1","","19","","9 Aug 2021","","","IEEE","IEEE Conferences"
"Model-based multiobjective fuzzy control using a new multiobjective dynamic programming approach","Dong-Oh Kang; Zeungnam Bien","Dept. of Electr. Eng., KAIST, Taejon, South Korea; NA","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","7 Aug 2002","2001","3","","1390","1395 vol.3","The authors propose a model-based multiobjective fuzzy control method which is optimized online via a novel multiobjective dynamic programming. The new multiobjective dynamic programming is guaranteed to derive a Pareto optimal solution. To estimate the effect of each candidate for control input in the dynamic programming procedure, we use state-value predictors of multiple objectives based on the plant model. Temporal difference learning and supervised learning are used for update of the predictors and the plant model. As the learning proceeds, the proposed method derives the compromised solution among multiple objectives. To show the effectiveness of the proposed method, some simulation results are given.","","0-7803-7078-3","10.1109/NAFIPS.2001.943752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943752","","Fuzzy control;Dynamic programming;Automatic control;Predictive models;Control systems;Fuzzy sets;Pareto optimization;Optimization methods;Linear programming;State estimation","fuzzy control;dynamic programming;operations research;Pareto distribution;learning (artificial intelligence);intelligent control;optimal control","model-based multiobjective fuzzy control;multiobjective dynamic programming;online optimization;Pareto optimal solution;control input;dynamic programming procedure;state-value predictors;plant model;temporal difference learning;supervised learning","","1","","13","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Effects of the Use of Multiple Fuzzy Partitions on the Search Ability of Multiobjective Fuzzy Genetics-Based Machine Learning","Y. Nojima; Y. Nakashima; H. Ishibuchi","Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan; Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan; Dept. of Comput. Sci. & Intell. Syst., Osaka Prefecture Univ., Sakai, Japan","2009 International Conference of Soft Computing and Pattern Recognition","31 Dec 2009","2009","","","341","346","An important issue in the design of fuzzy rule-based systems is to find a good accuracy-complexity tradeoff. While simple fuzzy systems with high interpretability are usually not accurate, complicated fuzzy systems with high accuracy are usually not interpretable. Recently evolutionary multiobjective optimization (EMO) algorithms have been used to search for simple and accurate fuzzy systems. The main advantage of EMO-based approaches over single-objective techniques is that a number of alternative fuzzy systems with different accuracy-complexity tradeoffs can be obtained by their single run. We have already proposed a multiobjective fuzzy genetics-based machine learning (GBML) algorithm for pattern classification problems. In our GBML algorithm, multiple fuzzy partitions with different granularities are simultaneously used. This is because we usually do not know an appropriate fuzzy partition for each input variable. However, the use of multiple fuzzy partitions significantly increases the size of the search space. In this paper, we examine the effect of the use of multiple fuzzy partitions on the search ability of our multiobjective fuzzy GBML algorithms through computational experiments.","","978-1-4244-5330-6","10.1109/SoCPaR.2009.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370991","Fuzzy genetics-based machine learning;Evolutionary multiobjective optimization;Fuzzy rules;Fuzzy partitions;Pattern classification problems","Machine learning;Fuzzy systems;Machine learning algorithms;Partitioning algorithms;Input variables;Knowledge based systems;Genetic algorithms;Classification algorithms;Pattern classification;Algorithm design and analysis","evolutionary computation;fuzzy systems;genetics;learning (artificial intelligence);logic programming;pattern classification","multiple fuzzy partitions;multiobjective fuzzy genetics-based machine learning search ability;fuzzy rule-based systems design;evolutionary multiobjective optimization algorithms;single-objective techniques;pattern classification problems","","","","17","","31 Dec 2009","","","IEEE","IEEE Conferences"
"Multiobjective model-based optimization of diesel injection rate profile by machine learning methods","E. Immonen; M. Lauren; L. Roininen; S. Särkkä","Turku University of Applied Sciences,Smart Machines Research Group,Turku,Finland; Turku University of Applied Sciences,Smart Machines Research Group,Turku,Finland; LUT University,School of Engineering Science,Lappeenranta,Finland; Aalto University,Department of Electrical Engineering and Automation,Espoo,Finland","2020 IEEE International Systems Conference (SysCon)","9 Feb 2021","2020","","","1","6","The contribution of this article is to present a model-based machine learning methodology for automatic and simultaneous optimization of the power output and exhaust emissions of diesel internal combustion (IC) engines. We carry out parametric optimization of the rate profile at which fuel is injected into the cylinder for producing minimal nitrogen oxide (NOx) emissions and maximal cylinder power (nIMEP) output, on a computational simulation model of an Agco Power 44 AWI engine calibrated by measurements. Our results display the tradeoffs in reaching these two contradictory optimization objectives on the Pareto frontiers. We show that the so-called boot injection profile, which is commonly used in practice, also emerges through mathematical optimization as a reasonable compromise of the objectives.","2472-9647","978-1-7281-5365-0","10.1109/SysCon47679.2020.9349028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9349028","Machine learning;multiobjective optimization;diesel engine;fuel injection;NOx emissions;modeling and simulation","Power measurement;Computational modeling;Machine learning;Mathematical model;Integrated circuit modeling;Optimization;Engines","air pollution control;combustion;diesel engines;engine cylinders;fuel systems;optimisation","multiobjective model-based optimization;diesel injection rate profile;machine learning methods;model-based machine;automatic optimization;simultaneous optimization;power output;exhaust emissions;diesel internal combustion engines;parametric optimization;minimal nitrogen oxide emissions;maximal cylinder power;computational simulation model;Agco Power 44 AWI engine;optimization objectives;boot injection profile;mathematical optimization","","","","24","","9 Feb 2021","","","IEEE","IEEE Conferences"
"Attitudinal Choquet Integral-Based Stochastic Multicriteria Acceptability Analysis","X. Mi; H. Liao; X. -J. Zeng","Sichuan University,Business School,Chengdu,China,610064; Sichuan University,Business School,Chengdu,China,610064; The Univerisity of Manchester,Department of Computer Science,Manchester,UK,M13 9PL","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","7","Preference learning is a subfield of machine learning. In the preference learning-fused decision analysis, the utility values of alternatives are inducted from human decision behavior. The commonly used utility model is the weighted summation. The model assumes the independency between criteria and the same attitude towards each performance value of alternatives, which is often unrealistic in practice. To solve this problem, this study presents an ACI-SMAA (Attitudinal Choquet Integral-based Stochastic Multicriteria Acceptability Analysis) model to consider the criteria interaction and attitudinal parameter of human decision behavior in decision analysis. The ACI-SMAA model is helpful to learn human preferences and analyze latent correlations. An application example about household energy selection is used to show the applicability and validity of the proposed model.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207443","Preference learning;Attitudinal Choquet integral;Human decision behavior;Criteria interaction;Stochastic multicriteria acceptability analysis (SMAA)","Stochastic processes;Analytical models;Decision analysis;Mobile handsets;Scholarships;Additives","decision theory;learning (artificial intelligence);operations research;stochastic processes","attitudinal parameter;human decision behavior;ACI-SMAA model;human preferences;machine learning;preference learning-fused decision analysis;utility model;attitudinal choquet integral-based stochastic multicriteria acceptability analysis;household energy selection","","","","24","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Seasonal-trend and multiobjective ensemble learning model for water consumption forecasting","M. H. Dal Molin Ribeiro; R. G. Da Silva; J. H. K. Larcher; J. D. De Lima; V. C. Mariani; L. Dos Santos Coelho","Pontifical Catholic University of Paraná (PUCPR),Industrial & Systems Engineering Graduate Program (PPGEPS),Curitiba,Paraná,Brazil,80215-901; Pontifical Catholic University of Paraná (PUCPR),Industrial & Systems Engineering Graduate Program (PPGEPS),Curitiba,Paraná,Brazil,80215-901; Pontifical Catholic University of Paraná (PUCPR),Mechanical Engineering Graduate Program (PPGEM),Curitiba,Paraná,Brazil,80215-901; Federal University of Technology - Paraná (UTFPR),Department of Mathematics,Pato Branco,Paraná,Brazil,85503-390; Pontifical Catholic University of Paraná (PUCPR),Mechanical Engineering Graduate Program (PPGEM),Curitiba,Paraná,Brazil,80215-901; Pontifical Catholic University of Paraná (PUCPR),Industrial & Systems Engineering Graduate Program (PPGEPS),Curitiba,Paraná,Brazil,80215-901","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Water consumption forecasting is essential for the development of efficient cities planning. Due to the non-linearities and relations of the water consumption with different factors the developing of an accurate forecasting system is challenging. This paper proposes a seasonal, trend and multiobjective ensemble learning model to forecast multi-step-ahead (one, two, and three-month-ahead) water consumption for two cities of Paraná state in Brazil. The proposed data analysis uses seasonal and trend decomposition using Loess (STL) to split the original data into the seasonal, trend, and residual components. In the next stage, the machine learning models named Support Vector Regression and Ridge Regression as well as the stochastic approach Gaussian Processes model are employed to train and predict the STL components. The previous components are weighted integrated to compose a heterogeneous ensemble learning of components obtaining the final forecasts. The elitist Non-Dominated Sorting Genetic Algorithm – version II (NSGA-II) is adopted to obtain the weights assigned to the components. The best model has better generalization out-of-sample considering the root mean squared error, mean absolute error, and mean absolute percentage error criteria in respect to minimization problem. Through developed comparisons, results showed that combining STL and multi-objective optimization with a heterogeneous ensemble learning can achieve high forecasting accuracy in comparison with some models. The framework proposed in this paper is effective to obtain reliable water consumption forecasting and can support and help future decision.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534104","National Council of Scientific and Technologic Development of Brazil – CNPq(grant numbers:307958/2019-1-PQ,307966/2019-4-PQ,404659/2016-0-Univ,405101/2016-3-Univ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534104","Decomposition;water consumption;ensemble learning;forecasting;multiobjective optimization","Support vector machines;Urban areas;Time series analysis;Machine learning;Predictive models;Market research;Data models","","","","","","36","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Multiobjective Fuzzy Genetics-Based Machine Learning for Multi-Label Classification","Y. Omozaki; N. Masuyama; Y. Nojima; H. Ishibuchi","Osaka Prefecture University,Department of Computer Science and Intelligent Systems,Osaka,Japan; Osaka Prefecture University,Department of Computer Science and Intelligent Systems,Osaka,Japan; Osaka Prefecture University,Department of Computer Science and Intelligent Systems,Osaka,Japan; Southern University of Science and Technology,Department of Computer Science and Engineering,Shenzhen,China","2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","26 Aug 2020","2020","","","1","8","In multi-label classification problems, multiple class labels are assigned to each instance. Two approaches have been studied in the literature. One is a data transformation approach, which transforms a multi-label dataset into a number of singlelabel datasets. However, this approach often loses the correlation information among classes in the multi-class assignment. The other is a method adaptation approach where a conventional classification method is extended to multi-label classification. Recently, some explainable classification models for multi-label classification have been proposed. Their high interpretability has also been discussed with respect to the transparency of the classification process. Although the explainability is a well-known advantage of fuzzy systems, their applications to multi-label classification have not been well studied. Since multi-label classification problems often have vague class boundaries, fuzzy systems seem to be a promising approach to multi-label classification. In this paper, we propose a new multiobjective evolutionary fuzzy system, which can be categorized as a method adaptation approach. The proposed algorithm produces nondominated classifiers with different tradeoffs between accuracy and complexity. We examine the behavior of the proposed algorithm using synthetic multi-label datasets. We also compare the proposed algorithm with five representative algorithms. Our experimental results on real-world datasets show that the obtained fuzzy classifiers with a small number of fuzzy rules have high transparency and comparable generalization ability to the other examined multi-label classification algorithms.","1558-4739","978-1-7281-6932-3","10.1109/FUZZ48607.2020.9177804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177804","multi-label classification;multiobjective fuzzy genetics-based machine learning;fuzzy rule-based classification system;method adaptation approach","Classification algorithms;Fuzzy systems;Machine learning algorithms;Measurement;Machine learning;Correlation;Fuzzy sets","fuzzy set theory;genetic algorithms;learning (artificial intelligence);pattern classification","multilabel classification;multilabel dataset;multiobjective fuzzy genetics;machine learning;data transformation;multiobjective evolutionary fuzzy system;fuzzy classifiers","","1","","21","","26 Aug 2020","","","IEEE","IEEE Conferences"
"Effects of heuristic rule generation from multiple patterns in multiobjective fuzzy genetics-based machine learning","Y. Nojima; K. Watanabe; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan","2015 IEEE Congress on Evolutionary Computation (CEC)","14 Sep 2015","2015","","","2996","3003","Fuzzy genetics-based machine learning (FGBML) has frequently been used for fuzzy classifier design. It is one of the promising evolutionary machine learning (EML) techniques from the viewpoint of data mining. This is because FGBML can generate accurate classifiers with linguistically interpretable fuzzy if-then rules. Of course, a classifier with tens of thousands of if-then rules is not linguistically understandable. Thus, the complexity minimization of fuzzy classifiers should be considered together with the accuracy maximization. In previous studies, we proposed hybrid FGBML and its multiobjective formulation (MoFGBML) to handle both the accuracy maximization and the complexity minimization simultaneously. MoFGBML can obtain a number of non-dominated classifiers with different tradeoffs between accuracy and complexity. In this paper, we focus on heuristic rule generation in MoFGBML to improve the search performance. In the original heuristic rule generation, each if-then rule is generated from a randomly-selected training pattern in a heuristic manner. This operation is performed at population initialization and during evolution. To generate more generalized rules according to the training data, we propose new heuristic rule generation where each rule is generated from multiple training patterns. Through computational experiments using some benchmark data sets, we discuss the effects of the proposed operation on the search performance of our MoFGBML.","1941-0026","978-1-4799-7492-4","10.1109/CEC.2015.7257262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7257262","Fuzzy genetics-based machine learning;heuristic rule generation;evolutionary multiobjective optimization","Training;Accuracy;Complexity theory;Training data;Fuzzy sets;Genetics;Probabilistic logic","computational complexity;data mining;fuzzy reasoning;genetic algorithms;learning (artificial intelligence);minimisation;pattern classification","heuristic rule generation effects;multiobjective fuzzy genetics-based machine learning;fuzzy classifier design;evolutionary machine learning techniques;EML techniques;data mining;linguistically interpretable fuzzy if-then rules;complexity minimization;MoFGBML;nondominated classifiers;search performance;randomly-selected training pattern;multiple training patterns","","5","","25","","14 Sep 2015","","","IEEE","IEEE Conferences"
"Multiobjective Particle Swarm Optimization for Feature Selection With Fuzzy Cost","Y. Hu; Y. Zhang; D. Gong","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Transactions on Cybernetics","15 Jan 2021","2021","51","2","874","888","Feature selection (FS) is an important data processing technique in the field of machine learning. There have been various FS methods, but all assume that the cost associated with a feature is precise, which restricts their real applications. Focusing on the FS problem with fuzzy cost, a fuzzy multiobjective FS method with particle swarm optimization, called PSOMOFS, is studied in this article. The proposed method develops a fuzzy dominance relationship to compare the goodness of candidate particles and defines a fuzzy crowding distance measure to prune the elitist archive and determine the global leader of particles. Also, a tolerance coefficient is introduced into the proposed method to ensure that the Pareto-optimal solutions obtained satisfy decision makers' preferences. The developed method is used to tackle a series of the UCI datasets and is compared with three fuzzy multiobjective evolutionary methods and three typical multiobjective FS methods. Experimental results show that the proposed method can achieve feature sets with superior performances in approximation, diversity, and feature cost.","2168-2275","","10.1109/TCYB.2020.3015756","National Natural Science Foundation of China(grant numbers:61876185,61876184); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195533","Feature selection (FS);fuzzy cost;multiobjective optimization;particle swarm optimization (PSO)","Optimization;Particle swarm optimization;Feature extraction;Measurement;Machine learning algorithms;Cybernetics;Machine learning","decision making;feature selection;fuzzy set theory;genetic algorithms;learning (artificial intelligence);Pareto optimisation;particle swarm optimisation","multiobjective particle swarm optimization;feature selection;fuzzy cost;data processing technique;machine learning;fuzzy multiobjective FS method;fuzzy dominance relationship;fuzzy crowding distance measure;Pareto-optimal solutions;fuzzy multiobjective evolutionary methods;feature sets;feature cost;PSOMOFS;UCI datasets;decision maker preferences","","37","","53","IEEE","14 Sep 2020","","","IEEE","IEEE Journals"
"Evolutionary Algorithm-Based and Network Architecture Search-Enabled Multiobjective Traffic Classification","X. Wang; X. Wang; L. Jin; R. Lv; B. Dai; M. He; T. Lv","School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Statistics, Colorado State University, Fort Collins, CO, USA; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","8 Apr 2021","2021","9","","52310","52325","Network traffic classification technology plays an important role in network security management. However, the inherent limitations of traditional methods have become increasingly obvious, and they cannot address existing traffic classification tasks. Very recently, neural architecture search (NAS) has aroused widespread interest as a tool to automate the manual architecture construction process. To this end, this paper proposes NAS based on multiobjective evolutionary algorithms (MOEAs) to classify malicious network traffic. The main purpose is to simplify the search space by reducing the spatial ratio and number of channels of the model. In addition, the search strategy is changed in the effective search space, and the utilized strategies include EAs with the nondominated sorting genetic algorithm with the elite retention strategy (NSGA-II), strength Pareto evolutionary algorithm (SPEA-II) and multiobjective particle swarm optimization (MOPSO) to solve the formulated multiobjective NAS. Through comprehensive comparison of the population convergence times, model accuracies, Pareto optimality sets, model complexities and running speeds of the strategies, it is concluded that the model based on NSGA-II search has the best performance. The experimental results of the current machine learning algorithms and artificial learning methods based on the network are compared, showing that our method achieved better classification performance on two public datasets with a lower computational complexity, as mainly measured by FLOPs. Our approach is able to achieve 99.806% and 99.369% F1-score with 11.501 MB and 4.718 MB FLOPs on both IDS2012 and ISCX VPN dataset respectively.","2169-3536","","10.1109/ACCESS.2021.3068267","National Natural Science Foundation of China(grant numbers:61871046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383257","Deep learning;multiobjective;neural architecture search;traffic classification","Computer architecture;Search problems;Task analysis;Feature extraction;Network architecture;Microprocessors;Data models","computational complexity;computer network management;computer network security;evolutionary computation;genetic algorithms;learning (artificial intelligence);Pareto optimisation;particle swarm optimisation;pattern classification;search problems;sorting;telecommunication traffic;virtual private networks","evolutionary algorithm;network architecture search-enabled;network traffic classification technology;network security management;traffic classification tasks;neural architecture search;manual architecture construction process;multiobjective evolutionary algorithms;malicious network traffic;spatial ratio;search strategy;effective search space;utilized strategies;nondominated sorting genetic algorithm;elite retention strategy;SPEA-II;multiobjective particle swarm optimization;formulated multiobjective NAS;model accuracies;Pareto optimality sets;model complexities;running speeds;NSGA-II search;machine learning algorithms;artificial learning methods;classification performance","","3","","72","CCBYNCND","23 Mar 2021","","","IEEE","IEEE Journals"
"Multiobjective Semisupervised Classifier Ensemble","Z. Yu; Y. Zhang; C. L. P. Chen; J. You; H. Wong; D. Dai; S. Wu; J. Zhang","Guangdong Provincial Key Laboratory of Computational Intelligence and Cyberspace Information; Guangdong Provincial Key Laboratory of Computational Intelligence and Cyberspace Information; Department of Computer and Information Science, University of Macau, Macau, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Guangdong Provincial Key Laboratory of Computational Intelligence and Cyberspace Information; Guangdong Provincial Key Laboratory of Computational Intelligence and Cyberspace Information; Guangdong Provincial Key Laboratory of Computational Intelligence and Cyberspace Information","IEEE Transactions on Cybernetics","28 Mar 2019","2019","49","6","2280","2293","Classification of high-dimensional data with very limited labels is a challenging task in the field of data mining and machine learning. In this paper, we propose the multiobjective semisupervised classifier ensemble (MOSSCE) approach to address this challenge. Specifically, a multiobjective subspace selection process (MOSSP) in MOSSCE is first designed to generate the optimal combination of feature subspaces. Three objective functions are then proposed for MOSSP, which include the relevance of features, the redundancy between features, and the data reconstruction error. Then, MOSSCE generates an auxiliary training set based on the sample confidence to improve the performance of the classifier ensemble. Finally, the training set, combined with the auxiliary training set, is used to select the optimal combination of basic classifiers in the ensemble, train the classifier ensemble, and generate the final result. In addition, diversity analysis of the ensemble learning process is applied, and a set of nonparametric statistical tests is adopted for the comparison of semisupervised classification approaches on multiple datasets. The experiments on 12 gene expression datasets and two large image datasets show that MOSSCE has a better performance than other state-of-the-art semisupervised classifiers on high-dimensional data.","2168-2275","","10.1109/TCYB.2018.2824299","National Natural Science Foundation of China(grant numbers:61722205,61751205,61572199,61572540,61472145,U1611461); Guangdong Natural Science Funds(grant numbers:S2013050014677,2017A030312008); Science and Technology Planning Project of Guangdong Province, China(grant numbers:2015A050502011,2016B090918042,2016A050503015,2016B010127003); Guangzhou Municipal Science and Technology Project(grant numbers:201704030051); Macau Science and Technology Development(grant numbers:019/2015/A,024/2015/AMJ); Multiyear Research Grants through the University of Macau Multiyear Research; Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:CityU 11300715); Hong Kong General Research Grant(grant numbers:152202/14E); PolyU Central Research Grant(grant numbers:G-YBJW); City University of Hong Kong(grant numbers:7004884); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344441","Ensemble learning;feature selection;multiobjective optimization;semisupervised learning","Semisupervised learning;Training;Clustering algorithms;Linear programming;Robustness;Partitioning algorithms;Cybernetics","data mining;feature extraction;learning (artificial intelligence);nonparametric statistics;pattern classification;statistical testing","MOSSCE;feature subspaces;MOSSP;data reconstruction error;auxiliary training set;ensemble learning process;multiobjective semisupervised classifier ensemble;data mining;machine learning;multiobjective subspace selection process;semisupervised classification;high-dimensional data classification;feature relevance;feature redundancy;sample confidence;diversity analysis;nonparametric statistical tests;gene expression datasets;large image datasets","","13","","91","IEEE","20 Apr 2018","","","IEEE","IEEE Journals"
"Convex Hull-Based Multiobjective Genetic Programming for Maximizing Receiver Operating Characteristic Performance","P. Wang; M. Emmerich; R. Li; K. Tang; T. Bäck; X. Yao","Nature Inspired Computation and Applications Laboratory, University of Science and Technology of China (USTC)–Birmingham Joint Research Institute in Intelligent Computation and its Applications, School of Computer Science and Technology, Hefei, Anhui, China; Leiden Institute for Advanced Computer Science, Leiden University, Leiden, The Netherlands; Leiden Institute for Advanced Computer Science, Leiden University, Leiden, The Netherlands; Nature Inspired Computation and Applications Laboratory, University of Science and Technology of China (USTC)–Birmingham Joint Research Institute in Intelligent Computation and its Applications, School of Computer Science and Technology, Hefei, Anhui, China; Leiden Institute for Advanced Computer Science, Leiden University, Leiden, The Netherlands; Nature Inspired Computation and Applications Laboratory, University of Science and Technology of China (USTC)–Birmingham Joint Research Institute in Intelligent Computation and its Applications, School of Computer Science and Technology, Hefei, Anhui, China","IEEE Transactions on Evolutionary Computation","27 Mar 2015","2015","19","2","188","200","The receiver operating characteristic (ROC) is commonly used to analyze the performance of classifiers in data mining. An important topic in ROC analysis is the ROC convex hull (ROCCH), which is the least convex majorant (LCM) of the empirical ROC curve and covers potential optima for a given set of classifiers. ROCCH maximization problems have been taken as multiobjective optimization problem (MOPs) in some previous work. However, the special characteristics of ROCCH maximization problem makes it different from traditional MOPs. In this paper, the difference will be discussed in detail and a new convex hull-based multiobjective genetic programming (CH-MOGP) is proposed to solve ROCCH maximization problems. Specifically, convex hull-based without redundancy sorting (CWR-sorting) is introduced, which is an indicator-based selection scheme that aims to maximize the area under the convex hull. A novel selection procedure is also proposed based on the proposed sorting scheme. It is hypothesized that by using a tailored indicator-based selection, CH-MOGP becomes more efficient for ROC convex hull approximation than algorithms that compute all Pareto optimal points. Empirical studies are conducted to compare CH-MOGP to both existing machine learning approaches and multiobjective genetic programming (MOGP) methods with classical selection schemes. Experimental results show that CH-MOGP outperforms the other approaches significantly.","1941-0026","","10.1109/TEVC.2014.2305671","973 Program of China(grant numbers:2011CB707006); National Natural Science Foundation of China(grant numbers:61175065,61329302); Program for New Century Excellent Talents in University(grant numbers:NCET-12-0512); Science and Technological Fund of Anhui Province for Outstanding Youth(grant numbers:1108085J16); EPSRC(grant numbers:EP/J017515/1); European Union Seventh Framework Programme(grant numbers:247619); Royal Society Wolfson Research Merit Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6762993","Classification;evolutionary multiobjective algorithm;genetic programming;memetic algorithm;receiver operating characteristic (ROC) convex hull","Optimization;Sorting;Sociology;Statistics;Vectors;Genetic programming;Approximation methods","convex programming;data mining;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification","convex hull-based multiobjective genetic programming;receiver operating characteristic performance;classifier performance;ROC convex hull;ROCCH analysis;least convex majorant;LCM;empirical ROC curve;multiobjective optimization problem;MOP;CH-MOGP;convex hull-based without redundancy sorting;CWR-sorting;indicator-based selection scheme;selection procedure;Pareto optimal points;machine learning approach;data mining","","26","","39","IEEE","11 Mar 2014","","","IEEE","IEEE Journals"
"Multiobjectivization from two objectives to four objectives in evolutionary multi-objective optimization algorithms","H. Ishibuchi; Y. Hitotsuyanagi; Y. Nakashima; Y. Nojima","Dept. of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan; Dept. of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan; Dept. of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan; Dept. of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan","2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC)","17 Feb 2011","2010","","","502","507","Multiobjectivization is an interesting idea to solve a difficult single-objective optimization problem through its reformulation as a multiobjective problem. The reformulation is performed by introducing an additional objective function or decomposing the original objective function into multiple ones. Evolutionary multiobjective optimization (EMO) algorithms are often used to solve the reformulated problem. Such an optimization approach, which is called multiobjectivization, has been used to solve difficult single-objective problems in many studies. In this paper, we discuss the use of multiobjectivization to solve two-objective problems. That is, we discuss the idea of solving a two-objective optimization problem by reformulating it as a four-objective one. In general, the increase in the number of objectives usually makes the problem more difficult for EMO algorithms. Thus the handling of two-objective problems as four-objective ones may simply lead to the deterioration in the quality of obtained non-dominated solutions. However, in this paper, we demonstrate through computational experiments that better results are obtained for some two-objective test problems by increasing the number of objectives from two to four.","","978-1-4244-7376-2","10.1109/NABIC.2010.5716359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716359","multiobjectivization;single-objective optimization;evolutionary multiobjective optimization;knapsack problems;fuzzy genetics-based machine learning","","evolutionary computation;optimisation;problem solving","multiobjectivization;evolutionary algorithms;multiobjective optimization;problem solving;reformulation","","5","","21","","17 Feb 2011","","","IEEE","IEEE Conferences"
"Transfer Learning-Based Dynamic Multiobjective Optimization Algorithms","M. Jiang; Z. Huang; L. Qiu; W. Huang; G. G. Yen","Department of Cognitive Science and Technology, Fujian Key Laboratory of Machine Intelligence and Robotics, Xiamen University, Xiamen, China; Institute of Innovation Research, Sangfor Technologies, Shenzhen, China; Department of Cognitive Science and Technology, Fujian Key Laboratory of Machine Intelligence and Robotics, Xiamen University, Xiamen, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA","IEEE Transactions on Evolutionary Computation","30 Jul 2018","2018","22","4","501","514","One of the major distinguishing features of the dynamic multiobjective optimization problems (DMOPs) is that optimization objectives will change over time, thus tracking the varying Pareto-optimal front becomes a challenge. One of the promising solutions is reusing “experiences” to construct a prediction model via statistical machine learning approaches. However, most existing methods neglect the nonindependent and identically distributed nature of data to construct the prediction model. In this paper, we propose an algorithmic framework, called transfer learning-based dynamic multiobjective evolutionary algorithm (EA), which integrates transfer learning and population-based EAs to solve the DMOPs. This approach exploits the transfer learning technique as a tool to generate an effective initial population pool via reusing past experience to speed up the evolutionary process, and at the same time any population-based multiobjective algorithms can benefit from this integration without any extensive modifications. To verify this idea, we incorporate the proposed approach into the development of three well-known EAs, nondominated sorting genetic algorithm II, multiobjective particle swarm optimization, and the regularity model-based multiobjective estimation of distribution algorithm. We employ 12 benchmark functions to test these algorithms as well as compare them with some chosen state-of-the-art designs. The experimental results confirm the effectiveness of the proposed design for DMOPs.","1941-0026","","10.1109/TEVC.2017.2771451","National Natural Science Foundation of China(grant numbers:61003014,61673328); Foundation of Xiamen University’s President(grant numbers:20720150150); China Scholarship Council(grant numbers:20150631505); Oklahoma State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100935","Dimensionality reduction;domain adaption;dynamic multiobjective optimization;evolutionary algorithm (EA);transfer learning","Heuristic algorithms;Sociology;Statistics;Optimization;Predictive models;Prediction algorithms;Algorithm design and analysis","estimation theory;genetic algorithms;learning (artificial intelligence);mathematics computing;Pareto optimisation;particle swarm optimisation","distribution algorithm;DMOPs;transfer learning-based dynamic multiobjective optimization algorithms;dynamic multiobjective optimization problems;optimization objectives;prediction model;statistical machine learning approaches;algorithmic framework;transfer learning technique;effective initial population pool;population-based multiobjective algorithms;nondominated sorting genetic algorithm II;multiobjective particle swarm optimization;regularity model-based multiobjective estimation;Pareto-optimal front;transfer learning-based dynamic multiobjective evolutionary algorithm","","100","","56","IEEE","9 Nov 2017","","","IEEE","IEEE Journals"
"Multiobjective Deep Belief Networks Ensemble for Remaining Useful Life Estimation in Prognostics","C. Zhang; P. Lim; A. K. Qin; K. C. Tan","Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Advance Technology Center of Rolls Royce Singapore, Singapore; School of Science, RMIT University, Melbourne, VIC, Australia; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Neural Networks and Learning Systems","15 Sep 2017","2017","28","10","2306","2318","In numerous industrial applications where safety, efficiency, and reliability are among primary concerns, condition-based maintenance (CBM) is often the most effective and reliable maintenance policy. Prognostics, as one of the key enablers of CBM, involves the core task of estimating the remaining useful life (RUL) of the system. Neural networks-based approaches have produced promising results on RUL estimation, although their performances are influenced by handcrafted features and manually specified parameters. In this paper, we propose a multiobjective deep belief networks ensemble (MODBNE) method. MODBNE employs a multiobjective evolutionary algorithm integrated with the traditional DBN training technique to evolve multiple DBNs simultaneously subject to accuracy and diversity as two conflicting objectives. The eventually evolved DBNs are combined to establish an ensemble model used for RUL estimation, where combination weights are optimized via a single-objective differential evolution algorithm using a task-oriented objective function. We evaluate the proposed method on several prognostic benchmarking data sets and also compare it with some existing approaches. Experimental results demonstrate the superiority of our proposed method.","2162-2388","","10.1109/TNNLS.2016.2582798","Ministry of Education, Singapore(grant numbers:R-263-000-A12-112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7508982","Deep belief network (DBN);ensemble learning;evolutionary algorithm (EA);multiobjective;prognostics","Estimation;Degradation;Maintenance engineering;Training;Artificial neural networks;Reliability;Benchmark testing","belief networks;condition monitoring;evolutionary computation;maintenance engineering;mechanical engineering computing;neural nets","multiobjective deep belief networks ensemble method;remaining useful life estimation;prognostics;condition-based maintenance;CBM;RUL estimation;neural networks-based approaches;maintenance policy;MODBNE method;evolutionary algorithm;DBN training technique;combination weights;single-objective differential evolution algorithm;task-oriented objective function;prognostic benchmarking data sets","","290","","83","IEEE","11 Jul 2016","","","IEEE","IEEE Journals"
"Learning From a Stream of Nonstationary and Dependent Data in Multiobjective Evolutionary Optimization","J. Sun; H. Zhang; A. Zhou; Q. Zhang; K. Zhang; Z. Tu; K. Ye","School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science, Beijing Electro-Mechanical Engineering Institute, Beijing, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, Beijing Electro-Mechanical Engineering Institute, Beijing, China; Department of Computer Science, Beijing Electro-Mechanical Engineering Institute, Beijing, China; MOE Key Laboratory for Intelligent Networks and Networks Security, School of Electronics and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Evolutionary Computation","30 Jul 2019","2019","23","4","541","555","Combining machine learning techniques has shown great potentials in evolutionary optimization since the domain knowledge of an optimization problem, if well learned, can be a great help for creating high-quality solutions. However, existing learning-based multiobjective evolutionary algorithms (MOEAs) spend too much computational overhead on learning. To address this problem, we propose a learning-based MOEA where an online learning algorithm is embedded within the evolutionary search procedure. The online learning algorithm takes the stream of sequentially generated solutions along the evolution as its training data. It is noted that the stream of solutions are temporal, dependent, nonstationary, and nonstatic. These data characteristics make existing online learning algorithm not suitable for the evolution data. We hence modify an existing online agglomerative clustering algorithm to accommodate these characteristics. The modified online clustering algorithm is applied to adaptively discover the structure of the Pareto optimal set; and the learned structure is used to guide new solution creation. Experimental results have shown significant improvement over four state-of-the-art MOEAs on a variety of benchmark problems.","1941-0026","","10.1109/TEVC.2018.2865495","National Basic Research Program of China (973 Program)(grant numbers:2018YFC0809800); National Natural Science Foundation of China(grant numbers:61703382); NSFC(grant numbers:61673180); ANR/RGC Joint Research Scheme(grant numbers:A-CityU101/16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437195","Evolutionary algorithms (EAs);machine learning (ML);multiobjective optimization;online agglomerative clustering","Sociology;Statistics;Training;Clustering algorithms;Optimization;Evolutionary computation;Convergence","evolutionary computation;learning (artificial intelligence);Pareto optimisation;pattern clustering;search problems","multiobjective evolutionary optimization;machine learning techniques;learning-based MOEA;online learning algorithm;evolutionary search procedure;nonstationary data;online agglomerative clustering algorithm;dependent data;learning-based multiobjective evolutionary algorithms;Pareto optimal set","","12","","57","IEEE","15 Aug 2018","","","IEEE","IEEE Journals"
"Semi-supervised clustering using multiobjective optimization","S. Saha; A. Ekbal; A. K. Alok","Computer Science Engineering, Indian Institute of Technology Patna, India; Computer Science Engineering, Indian Institute of Technology Patna, India; Computer Science Engineering, Indian Institute of Technology Patna, India","2012 12th International Conference on Hybrid Intelligent Systems (HIS)","28 Jan 2013","2012","","","360","365","Semi-supervised clustering uses the information of unsupervised and supervised learning to overcome the problems associated with them. Extracted information are given in the form of class labels and data distribution during clustering process. In this paper the problem of semi-supervised clustering is formulated under the framework of multiobjective optimization (MOO). Thereafter, a multiobjective based clustering technique is extended to solve the semi-supervised clustering problem. The newly developed semi-supervised multiobjective clustering algorithm (Semi-GenClustMOO), is used for appropriate partitioning of data into appropriate number of clusters. Four objective functions are optimized, out of which first three use some unsupervised information and the last one uses supervised information. These four objective functions represent, respectively, the, total compactness of the partitioning, total symmetry present in the clusters, cluster connectedness and Adjust Rand Index. These four objective functions are optimized simultaneously using AMOSA, a newly developed simulated annealing based multiobjective optimization method. Results show that it can easily detect the appropriate number of clusters as well as the appropriate partitioning from data sets having either well-separated clusters of any shape or symmetrical clusters with or without overlaps. Seven artificial and four real-life data sets have been used for evaluation to show the effectiveness of the Semi-GenClustMOO technique. In each case class information of 10% randomly chosen data point is known to us <sup>1</sup>.","","978-1-4673-5116-4","10.1109/HIS.2012.6421361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6421361","Semi-supervised clustering;Multiobjective optimization;Cluster validity index;Adjusted Rand Index (ARI);Sym-index;Con-index;I-Index;AMOSA","Distributed databases;Linear programming;Indexes;Clustering algorithms;Optimization;Partitioning algorithms;Euclidean distance","data handling;learning (artificial intelligence);optimisation;pattern clustering","multiobjective optimization;supervised learning;extracted information;data distribution;clustering process;MOO;semisupervised multiobjective clustering algorithm;Semi-GenClustMOO;unsupervised information;supervised information;Adjust Rand Index;cluster connectedness","","11","","17","","28 Jan 2013","","","IEEE","IEEE Conferences"
"Survey of Multiobjective Evolutionary Algorithms for Data Mining: Part II","A. Mukhopadhyay; U. Maulik; S. Bandyopadhyay; C. A. C. Coello","Department of Computer Science and Engineering, University of Kalyani, Kalyani, India; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India; Machine Intelligence Unit, Indian Statistical Institute, Kolkata, India; Departamento de Computación (Evolutionary Computation Group), CINVESTAV-IPN, Mexico City, Mexico","IEEE Transactions on Evolutionary Computation","27 Jan 2014","2014","18","1","20","35","This paper is the second part of a two-part paper, which is a survey of multiobjective evolutionary algorithms for data mining problems. In Part I , multiobjective evolutionary algorithms used for feature selection and classification have been reviewed. In this part, different multiobjective evolutionary algorithms used for clustering, association rule mining, and other data mining tasks are surveyed. Moreover, a general discussion is provided along with scopes for future research in the domain of multiobjective evolutionary algorithms for data mining.","1941-0026","","10.1109/TEVC.2013.2290082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6658840","Association rule mining;biclustering;clustering;ensemble learning;multiobjective evolutionary algorithms","Clustering algorithms;Biological cells;Indexes;Encoding;Association rules;Linear programming","data mining;evolutionary computation;feature selection;pattern classification;pattern clustering","multiobjective evolutionary algorithm;data mining problem;feature selection;classification;clustering;association rule mining","","114","","117","IEEE","8 Nov 2013","","","IEEE","IEEE Journals"
"Decomposition-Based Evolutionary Multiobjective Optimization to Self-Paced Learning","M. Gong; H. Li; D. Meng; Q. Miao; J. Liu","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, China; School of Mathematics and Statistics and Ministry of Education Key Laboratory of Intelligent Networks and Network Security, Xi’an Jiaotong University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, China","IEEE Transactions on Evolutionary Computation","29 Mar 2019","2019","23","2","288","302","Self-paced learning (SPL) is a recently proposed paradigm to imitate the learning process of humans/animals. SPL involves easier samples into training at first and then gradually takes more complex ones into consideration. Current SPL regimes incorporate a self-paced (SP) regularizer into the learning objective with a gradually increasing pace parameter. Therefore, it is difficult to obtain the solution path of the SPL regime and determine where to optimally stop this increasing process. In this paper, a multiobjective SPL method is proposed to optimize the loss function and the SP regularizer simultaneously. A decomposition-based multiobjective particle swarm optimization algorithm is used to simultaneously optimize the two objectives for obtaining the solutions. In the proposed method, a polynomial soft weighting regularizer is proposed to penalize the loss. Theoretical studies are conducted to show that the previous regularizers are roughly particular cases of the proposed polynomial soft weighting regularizer family. Then an implicit decomposition method is proposed to search the solutions with respect to the sample number involved into training. A set of solutions can be obtained by the proposed method and naturally constitute the solution path of the SPL regime. Then a satisfactory solution can be naturally obtained from these solutions by utilizing some effective tools in evolutionary multiobjective optimization. Experiments on matrix factorization and classification problems demonstrate the effectiveness of the proposed technique.","1941-0026","","10.1109/TEVC.2018.2850769","National Natural Science Foundation of China(grant numbers:61772393); National Program for Support of Top-Notch Young Professionals of China; National Key Research and Development Program of China(grant numbers:2017YFB0802200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8396286","Decomposition;machine learning;multiobjective optimization;self-paced learning (SPL)","Pareto optimization;Evolutionary computation;Machine learning;Particle swarm optimization","evolutionary computation;learning (artificial intelligence);particle swarm optimisation","SPL regime;multiobjective SPL method;loss function;SP regularizer;decomposition-based multiobjective particle swarm optimization algorithm;polynomial soft weighting regularizer family;implicit decomposition method;sample number;solution path;satisfactory solution;decomposition-based evolutionary multiobjective optimization;self-paced learning;learning process;humans/animals;regularizers;pace parameter;SPL regimes","","13","","56","IEEE","26 Jun 2018","","","IEEE","IEEE Journals"
"An Efficient Multiobjective Design Optimization Method for a PMSLM Based on an Extreme Learning Machine","J. Song; F. Dong; J. Zhao; H. Wang; Z. He; L. Wang","School of Electronics and Information Engineering, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China","IEEE Transactions on Industrial Electronics","30 Sep 2018","2019","66","2","1001","1011","This paper focuses on the multiobjective design optimization of the permanent magnet synchronous linear motors (PMSLMs), which are applied to a high-precision laser engraving machine. A novel efficient multiobjective design optimization method for a PMSLM is proposed to achieve optimal performances as indicated by high average thrust, low thrust ripple, and low total harmonic distortion at different running speeds. First, based on the finite-element analysis (FEA) data, a regression machine learning algorithm, called an extreme learning machine (ELM), is introduced to solve the calculation modeling problem by mapping out the nonlinear and complex relationship between input structural factors and output motor performances. Comparative simulation experiments conducted using the traditional analytical modeling method and another machine learning modeling method, i.e., support vector machine, confirm the superiority of the ELM. Then, a new bionic intelligent optimization algorithm, called the gray wolf optimizer algorithm, is used to search the best optimization performances and structural parameters by performing iteration optimization calculation for multiobjective functions. Finally, FEA and prototype motor experiments prove the effectiveness and validity of the proposed method.","1557-9948","","10.1109/TIE.2018.2835413","National Natural Science Foundation of China(grant numbers:51637001,51577001,51607002,51277002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357457","Extreme learning machine (ELM);finite-element analysis (FEA);gray wolf optimizer algorithm (GWOA);multiobjective design optimization;permanent magnet synchronous linear motors (PMSLMs);support vector machine (SVM)","Coils;Analytical models;Permanent magnet motors;Design optimization;Machine learning algorithms;Magnetic analysis","finite element analysis;harmonic distortion;iterative methods;learning (artificial intelligence);linear synchronous motors;optimisation;permanent magnet motors;regression analysis;support vector machines","PMSLM;extreme learning machine;permanent magnet synchronous linear motors;high-precision laser engraving machine;low total harmonic distortion;finite-element analysis data;regression machine;ELM;calculation modeling problem;output motor performances;traditional analytical modeling method;support vector machine;bionic intelligent optimization algorithm;gray wolf optimizer algorithm;optimization performances;iteration optimization calculation;multiobjective functions;prototype motor experiments;multiobjective design optimization method","","50","","27","IEEE","10 May 2018","","","IEEE","IEEE Journals"
"On a Multiobjective Training Algorithm for RBF Networks Using Particle Swarm Optimization","G. R. L. Silva; D. A. G. Vieira; A. C. Lisboa; V. Palade","Dept. of Electr. Eng., Univ. Fed. de Minas Gerais, Belo Horizonte, Brazil; Dept. of Electr. Eng., Univ. Fed. de Minas Gerais, Belo Horizonte, Brazil; Dept. of Electr. Eng., Univ. Fed. de Minas Gerais, Belo Horizonte, Brazil; Comput. Lab., Oxford Univ., Oxford, UK","2010 22nd IEEE International Conference on Tools with Artificial Intelligence","17 Dec 2010","2010","2","","282","285","This paper presents a novel algorithm for multiobjective training of Radial Basis Function (RBF) networks based on least-squares and Particle Swarm Optimization methods. The formulation is based on the fundamental concept that supervised learning is a bi-objective optimization problem, in which two conflicting objectives should be minimized. The objectives are related to the empirical training error and the machine complexity. The training is done in three steps: i) a conventional minimization of the training error, ii) multiobjective least-squares optimization for the linear parameters and, iii) particle swarm optimization for the nonlinear parameters. Some results are presented and they show the effectiveness of the proposed approach.","2375-0197","978-1-4244-8817-9","10.1109/ICTAI.2010.112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5671402","radial basis network;multiobjective least squares;particle swarm optimization","Training;Radial basis function networks;Complexity theory;Particle swarm optimization;Artificial neural networks;Optimization;Machine learning","learning (artificial intelligence);least squares approximations;particle swarm optimisation;radial basis function networks","multiobjective training;RBF networks;particle swarm optimization;radial basis function networks;least-squares approximation;supervised learning;biobjective optimization problem;machine complexity;multiobjective least-squares optimization;linear parameters","","","","32","","17 Dec 2010","","","IEEE","IEEE Conferences"
"Multicriteria-Based Active Discriminative Dictionary Learning for Scene Recognition","C. Zheng; Y. Yi; M. Qi; F. Liu; C. Bi; J. Wang; J. Kong","College of Information Sciences and Technology, Northeast Normal University, Changchun, China; School of Software, Jiangxi Normal University, Nanchang, China; College of Information Sciences and Technology, Northeast Normal University, Changchun, China; College of Information Sciences and Technology, Northeast Normal University, Changchun, China; School of Psychology, Northeast Normal University, Changchun, China; College of Information Sciences and Technology, Northeast Normal University, Changchun, China; College of Information Sciences and Technology, Northeast Normal University, Changchun, China","IEEE Access","21 Feb 2018","2018","6","","4416","4426","Scene recognition is a significant and challenging problem in the field of computer vision. One of the principal bottlenecks in applying machine learning techniques to scene recognition tasks is the requirement of a large number of labeled training data. However, labeling massive training data manually (especially labeling images and videos) is very expensive in terms of human time and effort. In this paper, we present a novel multicriteria-based active discriminative dictionary learning (M-ADDL) algorithm to reduce the human annotation effort and create a robust scene recognition model. The M-ADDL algorithm possesses three advantages. First, M-ADDL introduces an active learning strategy into the discriminative dictionary learning model so that the performance of discriminative dictionary learning can be improved when the number of labeled samples is small. Second, different from most existing active learning methods that measure either the informativeness or representativeness of unlabeled samples to select useful samples for expanding the training dataset, M-ADDL employs both informativeness and representativeness to query useful unlabeled samples and utilizes the manifold-preserving ability of unlabeled samples as an additional sample selection criterion. Finally, a more effective representativeness criterion is presented based on the reconstruction coefficients of the samples. The experimental results of four standard scene recognition databases demonstrate the feasibility and validity of the proposed M-ADDL algorithm.","2169-3536","","10.1109/ACCESS.2017.2786672","National Natural Science Foundation of China(grant numbers:61702092,61672150,61471111,61403078,61602221); China Postdoctoral Science Foundation(grant numbers:2017M621193); Fund of the Jilin Provincial Science and Technology Department(grant numbers:20180520215JH,20180201089GX,20170204018GX,20160204047GX); Natural Science Foundation of Jiangxi Province(grant numbers:20171BAB212009); Fundamental Research Funds for the Central Universities(grant numbers:2412017QD029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240937","Active learning;dictionary learning;multicriteria of sample selection;scene recognition","Machine learning;Classification algorithms;Training;Dictionaries;Algorithm design and analysis;Labeling","computer vision;image recognition;learning (artificial intelligence)","standard scene recognition databases;M-ADDL algorithm;active discriminative dictionary learning;scene recognition tasks;labeled training data;massive training data;human time;human annotation effort;robust scene recognition model;active learning strategy;sample selection criterion;reconstruction coefficients","","9","","57","OAPA","27 Dec 2017","","","IEEE","IEEE Journals"
"A reinforcement neuro-fuzzy combiner for multiobjective control","Chin-Teng Lin; I-Fang Chung","Dept. of Electr. & Control Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan; NA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","6 Aug 2002","1999","29","6","726","744","This paper proposes a neuro-fuzzy combiner (NFC) with reinforcement learning capability for solving multiobjective control problems. The proposed NFC can combine n existing low-level controllers in a hierarchical way to form a multiobjective fuzzy controller. It is assumed that each low-level (fuzzy or nonfuzzy) controller has been well designed to serve a particular objective. The role of the NFC is to fuse the n actions decided by the n low-level controllers and determine a proper action acting on the environment (plant) at each time step. Hence, the NFC can combine low-level controllers and achieve multiple objectives (goals) at once. The NFC acts like a switch that chooses a proper action from the actions of low-level controllers according to the feedback information from the environment. In fact, the NFC is a soft switch; it allows more than one low-level actions to be active with different degrees through fuzzy combination at each time step. An NFC can be designed by the trial-and-error approach if enough a priori knowledge is available, or it can be obtained by supervised learning if precise input/output training data are available. In the more practical cases when there is no instructive teaching information available, the NFC can learn by itself using the proposed reinforcement learning scheme. Adopted with reinforcement learning capability, the NFC can learn to achieve desired multiobjectives simultaneously through the rough reinforcement feedback from the environment, which contains only critic information such as ""success (good)"" or ""failure (bad)"" for each desired objective. Computer simulations have been conducted to illustrate the performance and applicability of the proposed architecture and learning scheme.","1941-0492","","10.1109/3477.809028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=809028","","Fuzzy control;Switches;Training data;Fuzzy logic;Fuses;Supervised learning;Education;Computer simulation;Computer architecture;Engines","learning (artificial intelligence);fuzzy control;neurocontrollers;neural nets","reinforcement neuro-fuzzy combiner;multiobjective control;reinforcement learning;multiobjective fuzzy controller.;supervised learning;rough reinforcement feedback;computer simulations;learning scheme","","10","","35","","6 Aug 2002","","","IEEE","IEEE Journals"
"Multiobjective Operation Optimization of Continuous Annealing Based on Data Analytics","B. Zhang; Z. Wang; X. Wang","Key Laboratory of Data Analytics and Optimization for Smart Industry, Ministry of Education, Northeastern University, Shenyang, China; Liaoning Engineering Laboratory of Operations Analytics and Optimization for Smart Industry, Shenyang, China; Liaoning Key Laboratory of Manufacturing System and Logistics, Institute of Industrial and Systems Engineering, Northeastern University, Shenyang, China","IEEE Access","23 Apr 2019","2019","7","","50109","50118","Continuous annealing production process generally consists of multiple complex processes that are coupled to each other, and each process contains many control variables. It is difficult to establish a precise mechanism model of the production process. The operators mainly set these control variables based on past production experience, which often result in great fluctuations of product quality (even unqualified products) and high energy consumption. This in turn significantly affected production cost and economic benefits of the cold rolling mill. To efficiently handle this problem, an ensemble learning modeling method based on production data is first proposed for this production process, and then, a multiobjective operation optimization model is established to optimize the operation of continuous annealing production process. Finally, an improved multiobjective differential evolution algorithm based on search process memory is developed to solve this model and achieve the optimal setting of control variables. The computational results on both benchmark problems and practical problems illustrate that the proposed algorithm is superior to some powerful multiobjective evolutionary algorithms in the literature and it can effectively achieve good setting of control variables for the continuous annealing production process.","2169-3536","","10.1109/ACCESS.2019.2911087","National Natural Science Foundation of China(grant numbers:61573086); Major Program of the National Natural Science Foundation of China(grant numbers:71790614); Fund for Innovative Research Groups of the National Natural Science Foundation of China(grant numbers:71621061); Major International Joint Research Project of the National Natural Science Foundation of China(grant numbers:71520107004); 111 Project(grant numbers:B16009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691442","Multiobjective operation optimization;differential evolutions;data analytics","Optimization;Strips;Annealing;Furnaces;Bagging;Data analysis","annealing;evolutionary computation;Pareto optimisation;production engineering computing","improved multiobjective differential evolution algorithm;data analytics;search process memory;multiobjective operation optimization model;product quality;production experience;control variables;multiple complex processes;continuous annealing production process","","5","","27","OAPA","14 Apr 2019","","","IEEE","IEEE Journals"
"Deep Learning for Generalized Multiobjective Optimization of Metamaterials","R. P. Jenkins; P. J. O’Connor; S. D. Campbell; P. L. Werner; D. H. Werner","The Pennsylvania State University,Department of Electrical Engineering, University Park,PA,USA,16802; The Pennsylvania State University,Department of Electrical Engineering, University Park,PA,USA,16802; The Pennsylvania State University,Department of Electrical Engineering, University Park,PA,USA,16802; The Pennsylvania State University,Department of Electrical Engineering, University Park,PA,USA,16802; The Pennsylvania State University,Department of Electrical Engineering, University Park,PA,USA,16802","2020 Fourteenth International Congress on Artificial Materials for Novel Wave Phenomena (Metamaterials)","14 Dec 2020","2020","","","261","263","The inverse-design of metamaterials often requires full-wave evaluation of an enormous number of different candidate designs, which can be extremely time consuming and, in many cases of practical interest, even intractable. By introducing deep learning at an early stage in the design process, a generalized network can be paired with multiobjective optimization to rapidly solve a variety of complex electromagnetic metamaterial design problems.","","978-1-7281-6104-4","10.1109/Metamaterials49557.2020.9285137","Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285137","","Deep learning;Training;Computational modeling;Acceleration;Optimization;Electromagnetic metamaterials","deep learning (artificial intelligence);design;metamaterials;optimisation;production engineering computing","generalized multiobjective optimization;full-wave evaluation;deep learning;generalized network;complex electromagnetic metamaterial design problems;metamaterial inverse-design","","","","9","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Evolutionary Multiobjective Feature Selection for Sentiment Analysis","A. Deniz; M. Angin; P. Angin","Department of Computer Engineering, Middle East Technical University, Ankara, Turkey; Department of International Relations, Koç University, İstanbul, Turkey; Department of Computer Engineering, Middle East Technical University, Ankara, Turkey","IEEE Access","26 Oct 2021","2021","9","","142982","142996","Sentiment analysis is one of the prominent research areas in data mining and knowledge discovery, which has proven to be an effective technique for monitoring public opinion. The big data era with a high volume of data generated by a variety of sources has provided enhanced opportunities for utilizing sentiment analysis in various domains. In order to take best advantage of the high volume of data for accurate sentiment analysis, it is essential to clean the data before the analysis, as irrelevant or redundant data will hinder extracting valuable information. In this paper, we propose a hybrid feature selection algorithm to improve the performance of sentiment analysis tasks. Our proposed sentiment analysis approach builds a binary classification model based on two feature selection techniques: an entropy-based metric and an evolutionary algorithm. We have performed comprehensive experiments in two different domains using a benchmark dataset, Stanford Sentiment Treebank, and a real-world dataset we have created based on World Health Organization (WHO) public speeches regarding COVID-19. The proposed feature selection model is shown to achieve significant performance improvements in both datasets, increasing classification accuracy for all utilized machine learning and text representation technique combinations. Moreover, it achieves over 70% reduction in feature size, which provides efficiency in computation time and space.","2169-3536","","10.1109/ACCESS.2021.3118961","2232 International Fellowship for Outstanding Researchers Program of TÜBİTAK(grant numbers:118C309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564078","Binary classification;evolutionary computation;feature selection;multiobjective optimization;sentiment analysis","Feature extraction;Sentiment analysis;Task analysis;Machine learning;Analytical models;Measurement;Data mining","data mining;entropy;evolutionary computation;feature extraction;feature selection;learning (artificial intelligence);natural language processing;pattern classification;text analysis","Stanford Sentiment Treebank;feature selection model;evolutionary multiobjective feature selection;prominent research areas;data mining;knowledge discovery;public opinion;big data era;utilizing sentiment analysis;accurate sentiment analysis;irrelevant data;redundant data;hybrid feature selection algorithm;sentiment analysis tasks;sentiment analysis approach;feature selection techniques;evolutionary algorithm","","","","71","CCBY","8 Oct 2021","","","IEEE","IEEE Journals"
"Classification rule mining approach based on multiobjective optimization","T. Sağ; H. Kahramanli","Computer Engineering Selcuk University, Technology Faculty Konya, Turkiye; Computer Engineering Selcuk University, Technology Faculty Konya, Turkiye","2017 International Artificial Intelligence and Data Processing Symposium (IDAP)","2 Nov 2017","2017","","","1","6","In this paper, a novel approach for classification rule mining is presented. The remarkable relationship between the rule extraction procedure and the concept of multiobjective optimization is emphasized. The range values of features composing the rules are handled as decision variables in the modelled multiobjective optimization problem. The proposed method is applied to three well-known datasets in literature. These are Iris, Haberman's Survival Data and Pima Indians Diabetes Datasets obtained from machine learning repository of University of California at Irvine (UCI). The classification rules are extracted with 100% accuracy for all datasets. These experimental results are the best outcomes found in literature so far.","","978-1-5386-1880-6","10.1109/IDAP.2017.8090264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8090264","Rule extraction;multiobjective optimization;genetic algorithms","Optimization;Iris;Classification algorithms;Breast cancer;Data mining;Genetic algorithms;Dermatology","data mining;feature extraction;learning (artificial intelligence);optimisation;pattern classification","rule extraction procedure;decision variables;classification rule mining;multiobjective optimization problem;Pima Indians diabetes datasets;Haberman survival data;machine learning repository;classification rules extraction","","","","24","","2 Nov 2017","","","IEEE","IEEE Conferences"
"A Multiobjective Approach to Classification in Drug Discovery","P. Echtenbruck; M. Emmerich; B. Naujoks","IDE+A, Cologne University of Applied Sciences, Gummersbach, 51643, Germany; LIACS, Leiden University, Leiden, 2333CA, The Netherlands; IDE+A, Cologne University of Applied Sciences, Gummersbach, 51643, Germany","2019 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","8 Aug 2019","2019","","","1","8","Classification based on machine learning algorithms is a widely used technique in contemporary in silico methods for drug discovery. However, typically the performance of the classification tool is evaluated based on a scalar performance score and essential information, such as the balance between false positive rates (FPRs)and false negative rates (FNRs)is not directly assessed. Moreover, there might be a large number of molecular features that are not relevant for the classification task and merely slow down the computations or add noise to the learning process. In this paper we adopt an approach that previously was used for the classification of text messages (spam/no-spam)to the classification of drug compounds (active/inactive). By considering the minimization of the classification costs (FPR, FNR)and the minimization of the number of features as separate optimization tasks, we demonstrate that it is possible to develop a more informative and versatile tool for drug discovery. We show, how to derive and evaluate 2-D and 3-D Pareto fronts for the classification of small compounds in active and non-active (similar studies could be conducted for toxic/non-toxic classification, and on other chemically relevant properties). We demonstrate the applicability of the method on a small data set for bio-activity prediction of ligands.","","978-1-7281-1462-0","10.1109/CIBCB.2019.8791463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791463","Bioactivity Prediction;Machine Learning;Multiobjective Optimization;Hyperparameter Tuning;In-Silico Drug Discovery","","biology computing;drugs;learning (artificial intelligence);pattern classification","multiobjective approach;drug discovery;machine learning algorithms;silico methods;classification tool;scalar performance score;false positive rates;false negative rates;molecular features;classification task;learning process;drug compounds;minimization;classification costs;informative tool;optimization tasks;3-D Pareto fronts;ligands","","3","","11","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Application of Multiobjective Genetic Programming to the Design of Robot Failure Recognition Systems","Y. Zhang; P. I. Rockett","Dept. of Electron. & Electr. Eng., Univ. of Sheffield, Sheffield; Dept. of Electron. & Electr. Eng., Univ. of Sheffield, Sheffield","IEEE Transactions on Automation Science and Engineering","31 Mar 2009","2009","6","2","372","376","We present an evolutionary approach using multiobjective genetic programming (MOGP) to derive optimal feature extraction preprocessing stages for robot failure detection. This data-driven machine learning method is compared both with conventional (nonevolutionary) classifiers and a set of domain-dependent feature extraction methods. We conclude MOGP is an effective and practical design method for failure recognition systems with enhanced recognition accuracy over conventional classifiers, independent of domain knowledge.","1558-3783","","10.1109/TASE.2008.2004414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4667633","Autonomous robots;failure recognition;feature extraction;multiobjective genetic programming (MOGP)","Genetic programming;Feature extraction;Robot sensing systems;Learning systems;Machine learning;Educational institutions;Design methodology;Control systems;Fault detection;Fault diagnosis","control engineering computing;feature extraction;genetic algorithms;learning (artificial intelligence);telerobotics","multiobjective genetic programming;robot failure recognition systems;data-driven machine learning method;domain-dependent feature extraction;classifiers;domain knowledge","","4","","22","IEEE","7 Nov 2008","","","IEEE","IEEE Journals"
"Multiobjective evolutionary optimization of quadratic Takagi-Sugeno fuzzy rules for remote bathymetry estimation","M. Cococcioni; B. Lazzerini","Department of Information Engineering, University of Pisa, Pisa, 56122 - Italy; Department of Information Engineering, University of Pisa, Pisa, 56122 - Italy","OCEANS 2015 - Genova","21 Sep 2015","2015","","","1","6","In this work we tackle the problem of bathymetry estimation using: i) a multispectral optical image of the region of interest, and ii) a set of in situ measurements. The idea is to learn the relation that between the reflectances and the depth using a supervised learning approach. In particular, quadratic Takagi-Sugeno fuzzy rules are used to model this relation. The rule base is optimized by means of a multiobjective evolutionary algorithm. To the best of our knowledge this work represents the first use of a quadratic Takagi-Sugeno fuzzy system optimized by a multiobjective evolutionary algorithm with bounded complexity, i.e., able to control the complexity of the consequent part of second-order fuzzy rules. This model has an outstanding modeling power, without inheriting the drawback of complexity due to the use of quadratic functions (which have complexity that scales quadratically with the number of inputs). This opens the way to the use of the proposed approach even for medium/high dimensional problems, like in the case of hyper-spectral images.","","978-1-4799-8736-8","10.1109/OCEANS-Genova.2015.7271447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271447","Bathymetry estimation;quadratic Takagi-Sugeno fuzzy rules;remotely sensed optical images;multiobjective evolutionary algorithms","Complexity theory;Fuzzy systems;Estimation;Accuracy;Optical sensors;Optimization;Optical imaging","bathymetry;evolutionary computation;fuzzy systems;geophysical image processing;learning (artificial intelligence);oceanographic techniques","multiobjective evolutionary optimization;remote bathymetry estimation;multispectral optical image;supervised learning approach;quadratic Takagi-Sugeno fuzzy system;bounded complexity;second-order fuzzy rules","","1","","35","","21 Sep 2015","","","IEEE","IEEE Conferences"
"FedMCCS: Multicriteria Client Selection Model for Optimal IoT Federated Learning","S. Abdulrahman; H. Tout; A. Mourad; C. Talhi","Department of Software Engineering and IT, École de Technologie Supérieure, Montreal, QC, Canada; Department of Software Engineering and IT, École de Technologie Supérieure, Montreal, QC, Canada; Department of Computer Science and Mathematics, Lebanese American University, Beirut, Lebanon; Department of Software Engineering and IT, École de Technologie Supérieure, Montreal, QC, Canada","IEEE Internet of Things Journal","5 Mar 2021","2021","8","6","4723","4735","As an alternative centralized systems, which may prevent data to be stored in a central repository due to its privacy and/or abundance, federated learning (FL) is nowadays a game changer addressing both privacy and cooperative learning. It succeeds in keeping training data on the devices, while sharing locally computed then globally aggregated models throughout several communication rounds. The selection of clients participating in FL process is currently at complete/quasi randomness. However, the heterogeneity of the client devices within Internet-of-Things environment and their limited communication and computation resources might fail to complete the training task, which may lead to many discarded learning rounds affecting the model accuracy. In this article, we propose FedMCCS, a multicriteria-based approach for client selection in FL. All of the CPU, memory, energy, and time are considered for the clients resources to predict whether they are able to perform the FL task. Particularly, in each round, the number of clients in FedMCCS is maximized to the utmost, while considering each client resources and its capability to successfully train and send the needed updates. The conducted experiments show that FedMCCS outperforms the other approaches by: 1) reducing the number of communication rounds to reach the intended accuracy; 2) maximizing the number of clients; 3) handling the least number of discarded rounds; and 4) optimizing the network traffic.","2327-4662","","10.1109/JIOT.2020.3028742","MITACS; Ericsson Canada; ÉTS Montreal; Lebanese American University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212434","Bilevel optimization;cooperative learning;federated learning (FL);Internet of Things (IoT);linear regression;machine learning;multicriteria selection;privacy;resource management;resource utilization prediction","Training;Internet of Things;Servers;Collaborative work;Task analysis;Wireless communication;Computational modeling","data privacy;decision making;Internet of Things;learning (artificial intelligence);optimisation","FedMCCS;multicriteria client selection model;optimal IoT federated learning;alternative centralized systems;central repository;privacy;cooperative learning;training data;globally aggregated models;communication rounds;FL process;client devices;Internet-of-Things environment;computation resources;training task;discarded learning rounds;model accuracy;multicriteria-based approach;clients resources;FL task;client resources;discarded rounds","","7","","47","IEEE","5 Oct 2020","","","IEEE","IEEE Journals"
"A Robo-Advisor Design using Multiobjective RankNets with Gated Neural Network Structure","P. Wang; C. Liu; Y. Yang; S. Huang","National Chiao Tung University,Institute of Information Management,Hsinchu,Taiwan, R.O.C; National Chiao Tung University,Institute of Information Management,Hsinchu,Taiwan, R.O.C; National Chiao Tung University,Institute of Information Management,Hsinchu,Taiwan, R.O.C; National Chiao Tung University,Department of Information Management and Finance,Hsinchu,Taiwan, R.O.C","2019 IEEE International Conference on Agents (ICA)","12 Dec 2019","2019","","","77","78","With rapid developments in deep learning and financial technology, a customized robo-advisory service based on novel artificial intelligence techniques has been widely adopted to realize financial inclusion. This study proposes a novel robo-advisor system that integrates trend prediction, portfolio management, and a recommendation mechanism. A gated neural network structure combining three multiobjective RankNet kernels could rank target financial products and recommend the top-n securities to investors. The gated neural network learns to choose or weigh each RankNet for incorporating the most important partial network inputs, such as earnings per share, market index, and hidden information from the time series. Experimental results indicate that the recommendation results of our proposed robo-advisor based on a gated neural network and multiobjective RankNets can outperform existing models.","","978-1-7281-4026-1","10.1109/AGENTS.2019.8929188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929188","learning preferences;rankings;deep learning","Logic gates;Neural networks;Machine learning;Indexes;Market research;Learning (artificial intelligence)","financial data processing;learning (artificial intelligence);neural nets;time series","trend prediction;portfolio management;robo-advisor system;important partial network inputs;target financial products;multiobjective RankNet kernels;recommendation mechanism;financial inclusion;artificial intelligence techniques;customized robo-advisory service;financial technology;deep learning;gated neural network structure;robo-advisor design","","2","","4","","12 Dec 2019","","","IEEE","IEEE Conferences"
"Multiobjective Intelligent Energy Management for a Microgrid","A. Chaouachi; R. M. Kamel; R. Andoulsi; K. Nagasaka","Department of Electronic and Information Engineering, Tokyo University of Agriculture and Technology, Koganei, Japan; Department of Electrical Engineering, Faculty of Engineering, Assuit University, Assiut, Egypt; Department of Electrical Engineering, Community College, University of Hail, Hail, Saudi Arabia; Department of Electronic and Information Engineering, Tokyo University of Agriculture and Technology, Koganei, Japan","IEEE Transactions on Industrial Electronics","22 Nov 2012","2013","60","4","1688","1699","In this paper, a generalized formulation for intelligent energy management of a microgrid is proposed using artificial intelligence techniques jointly with linear-programming-based multiobjective optimization. The proposed multiobjective intelligent energy management aims to minimize the operation cost and the environmental impact of a microgrid, taking into account its preoperational variables as future availability of renewable energies and load demand (LD). An artificial neural network ensemble is developed to predict 24-h-ahead photovoltaic generation and 1-h-ahead wind power generation and LD. The proposed machine learning is characterized by enhanced learning model and generalization capability. The efficiency of the microgrid operation strongly depends on the battery scheduling process, which cannot be achieved through conventional optimization formulation. In this paper, a fuzzy logic expert system is used for battery scheduling. The proposed approach can handle uncertainties regarding to the fuzzy environment of the overall microgrid operation and the uncertainty related to the forecasted parameters. The results show considerable minimization on operation cost and emission level compared to literature microgrid energy management approaches based on opportunity charging and Heuristic Flowchart (HF) battery management.","1557-9948","","10.1109/TIE.2012.2188873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6157610","Fuzzy logic (FL);microgrid;multiobjective intelligent energy management (MIEM);neural network ensemble (NNE);short-term forecasting","Forecasting;Artificial neural networks;Energy management;Batteries;Optimization;Training;Vectors","battery management systems;distributed power generation;energy management systems;expert systems;fuzzy logic;fuzzy set theory;learning (artificial intelligence);linear programming;neural nets;photovoltaic power systems;power engineering computing;power generation scheduling;wind power plants","multiobjective intelligent energy management;artificial intelligence techniques;linear-programming-based multiobjective optimization;renewable energies;load demand;artificial neural network ensemble;photovoltaic generation;wind power generation;enhanced learning model;machine learning;battery scheduling process;optimization formulation;emission level;operation cost;microgrid energy management approach;heuristic flowchart battery management;HF battery management;time 24 h;time 1 h","","439","1","35","IEEE","24 Feb 2012","","","IEEE","IEEE Journals"
"Predicting Fault Proneness of Classes Trough a Multiobjective Particle Swarm Optimization Algorithm","A. B. de Carvalho; A. Pozo; S. Vergilio; A. Lenz","Fed. Univ. of Parana, Curitiba; Fed. Univ. of Parana, Curitiba; Fed. Univ. of Parana, Curitiba; Fed. Univ. of Parana, Curitiba","2008 20th IEEE International Conference on Tools with Artificial Intelligence","11 Nov 2008","2008","2","","387","394","Software testing is a fundamental software engineering activity for quality assurance that is also traditionally very expensive. To reduce efforts of testing strategies, some design metrics have been used to predict the fault-proneness of a software class or module. Recent works have explored the use of machine learning (ML) techniques for fault prediction. However most used ML techniques can not deal with unbalanced data and their results usually have a difficult interpretation. Because of this, this paper introduces a multi-objective particle swarm optimization (MOPSO) algorithm for fault prediction. It allows the creation of classifiers composed by rules with specific properties by exploring Pareto dominance concepts. These rules are more intuitive and easier to understand because they can be interpreted independently one of each other. Furthermore, an experiment using the approach is presented and the results are compared to the other techniques explored in the area.","2375-0197","978-0-7695-3440-4","10.1109/ICTAI.2008.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4669800","Particle Swarm Optimization;Multiobjective Optimization;Fault prediction;Software mining","Particle swarm optimization;Object oriented modeling;Software testing;Machine learning algorithms;Machine learning;Bayesian methods;Support vector machines;Software engineering;Quality assurance;Costs","learning (artificial intelligence);object-oriented programming;Pareto optimisation;particle swarm optimisation;program diagnostics;program testing;quality assurance;software metrics;software quality","software testing;software engineering;quality assurance;design metrics;fault-proneness prediction;software class;machine learning;multiobjective particle swarm optimization algorithm;Pareto dominance concept","","12","","39","","11 Nov 2008","","","IEEE","IEEE Conferences"
"Design and Development of a Benchmark for Dynamic Multi-objective Optimisation Problem in the Context of Deep Reinforcement Learning","M. M. Hasan; K. Lwin; A. Shabut; M. A. Hossain","Daffodil International University,Department of Computer Science and Engineering,Dhaka,Bangladesh; Teesside University,School of Computing and Digital Technologies,Middlesbrough,UK; Leeds Trinity University,School of Arts and Communication,Leeds,UK; Teesside University,School of Computing and Digital Technologies,Middlesbrough,UK","2019 22nd International Conference on Computer and Information Technology (ICCIT)","19 Mar 2020","2019","","","1","6","Different benchmarks have played an important role in analysing algorithms for dynamic multi-objective optimisation problems. According to the literature, there are several benchmarks to deal with the dynamic multi-objective optimisation problems, especially in the evolutionary approaches. In this study, a comprehensive review has been done regarding the existing benchmarks in the single objective and multi-objective reinforcement learning (MORL) settings. To the best of our knowledge, there is no benchmark in the context of dynamic multiobjective reinforcement learning (DMORL). Therefore, this study has addressed this gap by applying the existing knowledge to propose a benchmark which may help to investigate the performance of different algorithms. It can also support to understand the dynamics while objectives are conflicting with each other and deal with the constraints and problem parameters that change over time. The proposed benchmark is the modified version of the deep-sea treasure hunt problem where several features such as changing parameters and objectives have been integrated to support the dynamics in a multi-objective environment. This paper highlights the methodology part of designing and developing a benchmark.","","978-1-7281-5842-6","10.1109/ICCIT48885.2019.9038529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9038529","machine learning;deep reinforcement learning;multiobjective reinforcement learning;artificial intelligence;Markov decision process;dynamic multi-objective optimisation","","evolutionary computation;learning (artificial intelligence)","dynamic multiobjective optimisation problem;deep reinforcement learning;dynamic multiobjective reinforcement learning;deep-sea treasure hunt problem;MORL","","","","24","","19 Mar 2020","","","IEEE","IEEE Conferences"
"Designing Fuzzy Ensemble Classifiers by Evolutionary Multiobjective Optimization with an Entropy-Based Diversity Criterion","Y. Nojima; H. Ishibuchi","Osaka Prefecture University, Japan; Osaka Prefecture University, Japan","2006 Sixth International Conference on Hybrid Intelligent Systems (HIS'06)","26 Dec 2006","2006","","","59","59","In this paper, we propose a multi-classifier coding scheme and an entropy-based diversity criterion in evolutionary multiobjective optimization algorithms for the design of fuzzy ensemble classifiers. In a multi-classifier coding scheme, an ensemble classifier is coded as an integer string. Each string is evaluated by using its accuracy and diversity. We use two accuracy criteria. One is the overall classification rate of the string as an ensemble classifier. The other is the average classification rate of component classifiers in the ensemble classifier. As a diversity criterion, we use the entropy of outputs from component classifiers in the ensemble classifier. We examine four formulations based on the above criteria through computational experiments on benchmark data sets in the UCI machine learning repository. The experimental results show the effectiveness of the multi-classifier coding scheme and the entropy-based diversity criterion.","","0-7695-2662-4","10.1109/HIS.2006.264942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4041439","","","","","","9","","8","","26 Dec 2006","","","IEEE","IEEE Conferences"
"An Adaptive Multiobjective Approach to Evolving ART Architectures","A. Kaylani; M. Georgiopoulos; M. Mollaghasemi; G. C. Anagnostopoulos; C. Sentelle; M. Zhong","School of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; School of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; Industrial Engineering, University of Central Florida, Orlando, FL, USA; Electrical & Computer Engineering, Florida Institute of Technology, Melbourne, FL, USA; School of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; School of Electrical Engineering and Computer Science, University of Central Florida, Orlando, United States","IEEE Transactions on Neural Networks","1 Apr 2010","2010","21","4","529","550","In this paper, we present the evolution of adaptive resonance theory (ART) neural network architectures (classifiers) using a multiobjective optimization approach. In particular, we propose the use of a multiobjective evolutionary approach to simultaneously evolve the weights and the topology of three well-known ART architectures; fuzzy ARTMAP (FAM), ellipsoidal ARTMAP (EAM), and Gaussian ARTMAP (GAM). We refer to the resulting architectures as MO-GFAM, MO-GEAM, and MO-GGAM, and collectively as MO-GART. The major advantage of MO-GART is that it produces a number of solutions for the classification problem at hand that have different levels of merit [accuracy on unseen data (generalization) and size (number of categories created)]. MO-GART is shown to be more elegant (does not require user intervention to define the network parameters), more effective (of better accuracy and smaller size), and more efficient (faster to produce the solution networks) than other ART neural network architectures that have appeared in the literature. Furthermore, MO-GART is shown to be competitive with other popular classifiers, such as classification and regression tree (CART) and support vector machines (SVMs).","1941-0093","","10.1109/TNN.2009.2037813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5411927","ARTMAP;category proliferation;classification;genetic algorithms (GAs);genetic operators;machine learning","Subspace constraints;Neural networks;Fuzzy logic;Resonance;Network topology;Classification tree analysis;Genetic algorithms;Computer architecture;Regression tree analysis;Support vector machines","ART neural nets;evolutionary computation;fuzzy neural nets;neural net architecture;optimisation","adaptive multiobjective approach;ART architecture;adaptive resonance theory;ART neural network architecture;multiobjective optimization;multiobjective evolutionary approach;fuzzy ARTMAP;ellipsoidal ARTMAP;Gaussian ARTMAP;classification problem","Algorithms;Artificial Intelligence;Computer Simulation;Fuzzy Logic;Humans;Neural Networks (Computer);Normal Distribution;Pattern Recognition, Automated","31","","61","IEEE","17 Feb 2010","","","IEEE","IEEE Journals"
"Design Space Exploration based on multiobjective genetic algorithms and clustering-based high-level estimation","L. G. A. Martins; E. Marques","Faculty of Computing, Federal University of Uberlandia, Uberlandia, MG, Brazil; Institute of Mathematics and Computer Science, University of Sao Paulo, Sao Carlos, SP, Brazil","2013 23rd International Conference on Field programmable Logic and Applications","24 Oct 2013","2013","","","1","2","A desirable characteristic in high-level synthesis (HLS) is fast search and analysis of implementation alternatives with low or none intervention. This process is known as Design Space Exploration (DSE) and it requires an efficient search method. The employment of intelligent techniques like evolutionary algorithms has been investigated as an alternative to DSE. They turn possible to reduce the search time through selection of higher potential regions of the solution space. We propose here the development of a DSE approach based on a multiobjective evolutionary algorithm (MOEA) and machine learning techniques. It must be employed to indicate the code transformations and architectural parameters adopted in design solution. Furthermore, DSE will use a high-level estimator model to evaluate candidate solutions. Such model must be able to provide a good estimation of energy consumption and execution time at early stages of design.","1946-1488","978-1-4799-0004-6","10.1109/FPL.2013.6645608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645608","","Estimation;Benchmark testing;Power demand;Space exploration;Search methods;Computer architecture;Algorithm design and analysis","electronic engineering computing;field programmable gate arrays;genetic algorithms;learning (artificial intelligence);logic design","FPGA;energy consumption;high-level estimator model;architectural parameters;code transformations;machine learning techniques;MOEA;multiobjective evolutionary algorithm;DSE approach;search time reduction;intelligent techniques;search method;HLS;high-level synthesis;clustering-based high-level estimation;multiobjective genetic algorithms;design space exploration","","1","","7","","24 Oct 2013","","","IEEE","IEEE Conferences"
"An Advanced Home Energy Management System Facilitated by Nonintrusive Load Monitoring With Automated Multiobjective Power Scheduling","Y. Lin; M. Tsai","Graduate Institute of Mechanical and Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan; Graduate Institute of Automation Technology, National Taipei University of Technology, Taipei, Taiwan","IEEE Transactions on Smart Grid","20 May 2017","2015","6","4","1839","1851","Nowadays, electricity energy demands requested from down-stream sectors in a smart grid constantly increase. One way to meet those demands is use of home energy management systems (HEMS). By effectively scheduling major household appliances in response to demand response (DR) schemes, residents can save their electricity bills. In this paper, an advanced HEMS facilitated by a nonintrusive load monitoring (NILM) technique with an automated nondominated sorting genetic algorithm-II (NSGA-II)-based multiobjective in-home power scheduling mechanism is proposed. The NILM as an electricity audit is able to nonintrusively estimate power consumed by each of monitored major household appliances at a certain period of time. Data identified by the NILM are very useful for DR implementation. For DR implementation, the NSGA-II-based multiobjective in-home power scheduling mechanism autonomously and meta-heuristically schedules monitored and enrolled major household appliances without user intervention. It is based on an analysis of the NILM with historical data with past trends. The experimental results reported in this paper reveal that the proposed advanced HEMS with the NILM assessed in a real-house environment with uncertainties is workable and feasible.","1949-3061","","10.1109/TSG.2015.2388492","National Science Council, Taiwan(grant numbers:101-2221-E-027-097-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7015635","Data fusion;demand response (DR);energy management system;ensemble learning;nonintrusive load monitoring (NILM);power scheduling;smart grid;smart house;Data fusion;demand response (DR);energy management system;ensemble learning;nonintrusive load monitoring (NILM);power scheduling;smart grid;smart house","Home appliances;Biomedical monitoring;Monitoring;Electricity;Load management;Schedules;Power demand","domestic appliances;genetic algorithms;home automation;learning (artificial intelligence);load management;smart power grids","advanced home energy management system;nonintrusive load monitoring;electricity energy demands;down-stream sectors;smart grid;major household appliances scheduling;demand response schemes;electricity bills;advanced HEMS;automated nondominated sorting genetic algorithm-II;NILM;electricity audit;nonintrusively power estimation;automated NSGA-II-based multiobjective in-home power scheduling mechanism;ensemble learning;smart house","","107","","28","IEEE","20 Jan 2015","","","IEEE","IEEE Journals"
"Multicriteria approaches based on a new discrimination criterions for feature selection","H. Chamlal; T. Ouaderhman; B. E. Mourtji","FSAC Hassan II University,Department of Mathematics LMFA Laboratory,Casablanca,Morocco; FSAC Hassan II University,Department of Mathematics LMFA Laboratory,Casablanca,Morocco; FSAC Hassan II University,Department of Mathematics LMFA Laboratory,Casablanca,Morocco","2021 Fifth International Conference On Intelligent Computing in Data Sciences (ICDS)","1 Dec 2021","2021","","","1","7","In machine learning, the presence of a large number of explanatory features leads to a greater complexity of the algorithms and to a strong degradation in the performance of the prediction models. For this, a selection of an optimal discriminating subset is necessary. Feature selection can be viewed as a multi-objective optimization problem, since, in the simplest case, it involves feature subset size minimization and performance maximization. In our work, we introduced approaches based on the theory of preordering that use association techniques between two heterogeneous features, introduced by S.Chah, H. Chamla1 [14], and between several ones, the first approach consists in selecting at each step a variable by maximizing two criteria, eliminating the effect of the variable in question, and moving on to the next step, the procedure stops when the second criterion is no longer significant. In the second approach, we adapted SFFS (Sequential Floating Forward Selection) and SFBS (Sequential Floating Backward Selection) to our problem. These methods consist of using the SFS (Sequential Forward Selection) algorithm once so as to add 1 features, then using the SBS (Sequential Backward Selection) algorithm for r times in order to remove r features. These steps are then repeated until the stop criterion is obtained. As the optimal values of these parameters cannot be determined theoretically, we proposed to leave them floating during the selection process in order to get as close as possible to the optimal solution. The proposed approaches were tested on several datasets and the experimental results were very satisfactory.","","978-1-6654-4238-1","10.1109/ICDS53782.2021.9626744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626744","Heterogeneous variables;preordonnance;concordance measures;feature selection;discrimination;TOPSIS","Degradation;Machine learning algorithms;Computational modeling;Machine learning;Predictive models;Feature extraction;Prediction algorithms","feature selection;learning (artificial intelligence);optimisation","discrimination criterions;feature selection;machine learning;multiobjective optimization problem;feature subset size minimization;heterogeneous features;SFS algorithm;sequential forward selection;SBS algorithm;sequential backward selection;stop criterion;selection process","","","","16","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"Multiobjective fuzzy genetics-based machine learning based on MOEA/D with its modifications","Y. Nojima; K. Arahari; S. Takemura; H. Ishibuchi","Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Intelligent Systems, Graduate School of Engineering, Osaka Prefecture University, Sakai, Osaka 599-8531, Japan; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China","2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","24 Aug 2017","2017","","","1","6","Various evolutionary multiobjective optimization (EMO) algorithms have been used in the field of evolutionary fuzzy systems (EFS), because EMO algorithms can easily handle multiple objective functions such as the accuracy maximization and complexity minimization for fuzzy system design. Most EMO algorithms used in EFS are Pareto dominance-based algorithms such as NSGA-II, SPEA2, and PAES. There are a few studies where other types of EMO algorithms are used in EFS. In this paper, we apply a multiobjective evolutionary algorithm based on decomposition called MOEA/D to EFS for fuzzy classifier design. MOEA/D is one of the most well-known decomposition-based EMO algorithms. The key idea is to divide a multiobjective optimization problem into a number of single-objective problems using a set of uniformly distributed weight vectors in a scalarizing function. We propose a new scalarizing function called an accuracy-oriented function (AOF) which is specialized for classifier design. We examine the effects of using AOF in MOEA/D on the search ability of our multiobjective fuzzy genetics-based machine learning (GBML). We also examine the synergy effect of MOEA/D with AOF and parallel distributed implementation of fuzzy GBML on the generalization ability.","1558-4739","978-1-5090-6034-4","10.1109/FUZZ-IEEE.2017.8015749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8015749","Fuzzy classifier design;evolutionary fuzzy systems;MOEA/D;accuracy-oriented scalarizingfunction","Training data;Error analysis;Algorithm design and analysis;Classification algorithms;Computational modeling;Data models;Optimization","fuzzy set theory;generalisation (artificial intelligence);genetic algorithms;learning (artificial intelligence);pattern classification;search problems","MOEA/D;evolutionary multiobjective optimization algorithm;evolutionary fuzzy systems;EFS;objective functions;accuracy maximization;complexity minimization;fuzzy system design;multiobjective evolutionary algorithm based-on-decomposition;fuzzy classifier design;decomposition-based EMO algorithm;single-objective problems;uniformly distributed weight vectors;scalarizing function;accuracy-oriented function;AOF;search ability;multiobjective fuzzy genetics-based machine learning;synergy effect;parallel distributed implementation;fuzzy GBML;generalization ability","","3","","25","","24 Aug 2017","","","IEEE","IEEE Conferences"
"Multiobjective Optimization for Model Selection in Kernel Methods in Regression","D. You; C. F. Benitez-Quiroz; A. M. Martinez","Motorola Mobility, Libertyville, IL, USA; Department of Electrical and Computer Engineering, The Ohio State University, Columbus, OH, USA; Department of Electrical and Computer Engineering, The Ohio State University, Columbus, OH, USA","IEEE Transactions on Neural Networks and Learning Systems","20 May 2017","2014","25","10","1879","1893","Regression plays a major role in many scientific and engineering problems. The goal of regression is to learn the unknown underlying function from a set of sample vectors with known outcomes. In recent years, kernel methods in regression have facilitated the estimation of nonlinear functions. However, two major (interconnected) problems remain open. The first problem is given by the bias-versus-variance tradeoff. If the model used to estimate the underlying function is too flexible (i.e., high model complexity), the variance will be very large. If the model is fixed (i.e., low complexity), the bias will be large. The second problem is to define an approach for selecting the appropriate parameters of the kernel function. To address these two problems, this paper derives a new smoothing kernel criterion, which measures the roughness of the estimated function as a measure of model complexity. Then, we use multiobjective optimization to derive a criterion for selecting the parameters of that kernel. The goal of this criterion is to find a tradeoff between the bias and the variance of the learned function. That is, the goal is to increase the model fit while keeping the model complexity in check. We provide extensive experimental evaluations using a variety of problems in machine learning, pattern recognition, and computer vision. The results demonstrate that the proposed approach yields smaller estimation errors as compared with methods in the state of the art.","2162-2388","","10.1109/TNNLS.2013.2297686","U.S. National Institutes of Health(grant numbers:R21 DC 011081,R01 EY 020834); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6712159","Kernel methods;kernel optimization;optimization;Pareto optimality;regression.;Kernel methods;kernel optimization;optimization;Pareto optimality;regression","Kernel;Complexity theory;Vectors;Training;Computational modeling;Noise;Optimization","nonlinear estimation;nonlinear functions;optimisation;regression analysis","multiobjective optimization;model selection;kernel methods;regression;nonlinear function estimation;bias-versus-variance tradeoff;kernel function;smoothing kernel criterion;estimated function;model complexity;experimental evaluation;machine learning;pattern recognition;computer vision;estimation error","Algorithms;Artificial Intelligence;Computer Simulation;Humans;Models, Theoretical;Pattern Recognition, Automated;Pattern Recognition, Visual;Regression Analysis","12","","48","IEEE","14 Jan 2014","","","IEEE","IEEE Journals"
"Evolutionary Multiobjective Ensemble Learning Based on Bayesian Feature Selection","Huanhuan Chen; Xin Yao","CERCIA, School of Computer Science, University of Birmingham, Birmingham B15 2TT, United Kingdom (phone: 44-121-4143736; email: H.Chen@cs.bham.ac.uk); NA","2006 IEEE International Conference on Evolutionary Computation","11 Sep 2006","2006","","","267","274","This paper proposes to incorporate evolutionary multiobjective algorithm and Bayesian Automatic Relevance Determination (ARD) to automatically design and train ensemble. The algorithm determines almost all the parameters of ensemble automatically. Our algorithm adopts different feature subsets, selected by Bayesian ARD, to maintain accuracy and promote diversity among individual NNs in an ensemble. The multiobjective evaluation of the fitness of the networks encourages the networks with lower error rate and fewer features. The proposed algorithm is applied to several real-world classification problems and in all cases the performance of the method is better than the performance of other ensemble construction algorithms.","1941-0026","0-7803-9487-9","10.1109/CEC.2006.1688318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1688318","","Bayesian methods;Neural networks;Machine learning;Bagging;Boosting;Computer science;Algorithm design and analysis;Error analysis;Supervised learning;Uncertainty","belief networks;evolutionary computation;learning (artificial intelligence)","evolutionary multiobjective ensemble learning;Bayesian feature selection;automatic relevance determination;ensemble construction algorithms","","4","","42","","11 Sep 2006","","","IEEE","IEEE Conferences"
"Multiobjective Reinforcement Learning for Cognitive Satellite Communications Using Deep Neural Network Ensembles","P. V. R. Ferreira; R. Paffenroth; A. M. Wyglinski; T. M. Hackett; S. G. Bilén; R. C. Reinhart; D. J. Mortensen","Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Mathematical Sciences, Department of Computer Science and Data Science Program, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; School of Electrical Engineering and Computer Science, The Pennsylvania State University, University Park, PA, USA; School of Electrical Engineering and Computer Science, The Pennsylvania State University, University Park, PA, USA; Space Communications and Navigation, NASA John H. Glenn Research Center, Cleveland, OH, USA; Space Communications and Navigation, NASA John H. Glenn Research Center, Cleveland, OH, USA","IEEE Journal on Selected Areas in Communications","24 Jul 2018","2018","36","5","1030","1041","Future spacecraft communication subsystems will potentially benefit from software-defined radios controlled by artificial intelligence algorithms. In this paper, we propose a novel radio resource allocation algorithm leveraging multiobjective reinforcement learning and artificial neural network ensembles able to manage available resources and conflicting mission-based goals. The uncertainty in the performance of thousands of possible radio parameter combinations and the dynamic behavior of the radio channel over time producing a continuous multidimensional state–action space requires a fixed-size memory continuous state–action mapping instead of the traditional discrete mapping. In addition, actions need to be decoupled from states in order to allow for online learning, performance monitoring, and resource allocation prediction. The proposed approach leverages the authors’ previous research on constraining decisions predicted to have poor performance through ”virtual environment exploration.” The simulation results show the performance for different communication mission profiles, and accuracy benchmarks are provided for the future research reference. The proposed approach constitutes part of the core cognitive engine proof-of-concept delivered to the NASA John H. Glenn Research Center’s SCaN Testbed radios on-board the International Space Station.","1558-0008","","10.1109/JSAC.2018.2832820","Glenn Research Center(grant numbers:NNC14AA01A); National Aeronautics and Space Administration(grant numbers:NNX15AQ41H); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior(grant numbers:BEX 18701/12-4); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353861","Satellite communication;machine learning;artificial intelligence;reinforcement learning;neural networks;cognitive radio;space communication;SCaN Testbed;NASA GRC","Space vehicles;Artificial neural networks;Learning (artificial intelligence);Communication systems;Resource management;NASA","aerospace computing;cognition;cognitive radio;learning (artificial intelligence);neural nets;resource allocation;satellite communication;software radio;space vehicles","future spacecraft communication subsystems;software-defined radios;artificial intelligence algorithms;novel radio resource allocation algorithm leveraging multiobjective reinforcement learning;artificial neural network;conflicting mission-based goals;possible radio parameter combinations;radio channel;continuous multidimensional state-action space;fixed-size memory continuous state-action mapping;traditional discrete mapping;online learning;performance monitoring;resource allocation prediction;poor performance;future research reference;NASA John H. Glenn Research Center's SCaN Testbed radios;cognitive satellite communications;deep neural network ensembles;communication mission profiles","","20","","37","IEEE","3 May 2018","","","IEEE","IEEE Journals"
"Difficulties in choosing a single final classifier from non-dominated solutions in multiobjective fuzzy genetics-based machine learning","H. Ishibuchi; Y. Nojima","Department of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan; Department of Computer Science and Intelligent Systems, Osaka Prefecture University, 1-1 Gakuen-cho, Naka-ku, Sakai, 599-8531, Japan","2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)","26 Sep 2013","2013","","","1203","1208","A large number of non-dominated fuzzy rule-based classifiers are often obtained by applying a multiobjective fuzzy genetics-based machine learning (MoFGBML) algorithm to a pattern classification problem. The obtained set of non-dominated classifiers can be used to analyze their accuracy-interpretability tradeoff relation. One important issue, which has not been discussed in many studies on MoFGBML, is the choice of a single final classifier from a large number of non-dominated classifiers. The selected classifier is used for the classification of new input patterns. In this paper, we focus on this important research issue: classifier selection from a large number of non-dominated fuzzy rule-based classifiers. In general, it is not easy to choose a single final solution from non-dominated solutions in multiobjective optimization. This is because further information on the decision maker's preference is needed to choose the single final solution. In addition to this general difficulty in multiobjective optimization, MoFGBML has its own difficulty in classifier selection, which is the difference between training data accuracy and test data accuracy. While our true objective is to maximize the test data accuracy (i.e., classifier's generalization ability), only the training data accuracy is available for fitness evaluation and classifier selection. In this paper, we discuss why classifier selection is difficult in MoFGBML.","","978-1-4799-0348-1","10.1109/IFSA-NAFIPS.2013.6608572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6608572","","Accuracy;Training data;Error analysis;Complexity theory;Classification algorithms;Search problems;Fuzzy sets","fuzzy set theory;genetic algorithms;knowledge based systems;learning (artificial intelligence);pattern classification","single final classifier;nondominated solutions;multiobjective fuzzy genetics-based machine learning;nondominated fuzzy rule-based classifiers;MoFGBML algorithm;pattern classification problem;nondominated classifier;accuracy-interpretability tradeoff relation;classifier selection;multiobjective optimization;decision maker preference;training data accuracy;test data accuracy;fitness evaluation","","1","","30","","26 Sep 2013","","","IEEE","IEEE Conferences"
"Active Learning of Pareto Fronts","P. Campigotto; A. Passerini; R. Battiti","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Neural Networks and Learning Systems","20 May 2017","2014","25","3","506","519","This paper introduces the active learning of Pareto fronts (ALP) algorithm, a novel approach to recover the Pareto front of a multiobjective optimization problem. ALP casts the identification of the Pareto front into a supervised machine learning task. This approach enables an analytical model of the Pareto front to be built. The computational effort in generating the supervised information is reduced by an active learning strategy. In particular, the model is learned from a set of informative training objective vectors. The training objective vectors are approximated Pareto-optimal vectors obtained by solving different scalarized problem instances. The experimental results show that ALP achieves an accurate Pareto front approximation with a lower computational effort than state-of-the-art estimation of distribution algorithms and widely known genetic techniques.","2162-2388","","10.1109/TNNLS.2013.2275918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606803","Active learning;Gaussian process regression;multiobjective optimization;uncertainty sampling","Training;Vectors;Optimization;Uncertainty;Approximation methods;Linear programming;Analytical models","learning (artificial intelligence);Pareto optimisation","Pareto fronts;ALP algorithm;multiobjective optimization problem;supervised machine learning task;analytical model;computational effort;active learning strategy;informative training objective vectors;Pareto optimal vectors;scalarized problem instances;Pareto front approximation;distribution algorithms;genetic techniques","","23","","29","IEEE","23 Sep 2013","","","IEEE","IEEE Journals"
"Distributed Pareto Optimization for Large-Scale Noisy Subset Selection","C. Qian","National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","IEEE Transactions on Evolutionary Computation","29 Jul 2020","2020","24","4","694","707","Subset selection, aiming to select the best subset from a ground set with respect to some objective function, is a fundamental problem with applications in many areas, such as combinatorial optimization, machine learning, data mining, computer vision, information retrieval, etc. Along with the development of data collection and storage, the size of the ground set grows larger. Furthermore, in many subset selection applications, the objective function evaluation is subject to noise. We thus study the large-scale noisy subset selection problem in this paper. The recently proposed DPOSS algorithm based on multiobjective evolutionary optimization is a powerful distributed solver for large-scale subset selection. Its performance, however, has been only validated in the noise-free environment. In this paper, we first prove its approximation guarantee under two common noise models, i.e., multiplicative noise and additive noise, disclosing that the presence of noise degrades the performance of DPOSS largely. Next, we propose a new distributed multiobjective evolutionary algorithm called DPONSS for large-scale noisy subset selection. We prove that the approximation guarantee of DPONSS under noise is significantly better than that of DPOSS. We also conduct experiments on the application of sparse regression, where the objective evaluation is often estimated using a sample data, bringing noise. The results on various real-world data sets, whose size can reach millions, clearly show the excellent performance of DPONSS.","1941-0026","","10.1109/TEVC.2019.2929555","National Basic Research Program of China (973 Program)(grant numbers:2017YFB1003102); National Natural Science Foundation of China(grant numbers:61603367); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765790","Distributed algorithms;experimental studies;large-scale;multiobjective evolutionary algorithms (MOEAs);noise;Pareto optimization;subset selection;theoretical analyses","Linear programming;Noise measurement;Approximation algorithms;Optimization;Greedy algorithms;Additive noise;Distributed algorithms","evolutionary computation;feature selection;Pareto optimisation;regression analysis;set theory","ground set;combinatorial optimization;computer vision;data collection;subset selection applications;objective function evaluation;DPOSS;multiobjective evolutionary optimization;large-scale subset selection;noise-free environment;common noise models;multiplicative noise;additive noise;distributed multiobjective evolutionary algorithm;real-world data sets;distributed Pareto optimization","","8","","43","IEEE","18 Jul 2019","","","IEEE","IEEE Journals"
"Unsupervised texture image segmentation using multiobjective evolutionary clustering ensemble algorithm","Xiaoxue Qian; Xiangrong Zhang; Licheng Jiao; Wenping Ma","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Institute of Intelligence Information Processing, xidian University, 710071, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Institute of Intelligence Information Processing, xidian University, 710071, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Institute of Intelligence Information Processing, xidian University, 710071, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Institute of Intelligence Information Processing, xidian University, 710071, China","2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)","23 Sep 2008","2008","","","3561","3567","Multiobjective evolutionary clustering approach has been successfully utilized in data clustering. In this paper, we propose a novel unsupervised machine learning algorithm namely multiobjective evolutionary clustering ensemble algorithm (MECEA) to perform the texture image segmentation. MECEA comprises two main phases. In the first phase, MECEA uses a multiobjective evolutionary clustering algorithm to optimize two complementary clustering objectives: one based on compactness in the same cluster, and the other based on connectedness of different clusters. The output of the first phase is a set of Pareto solutions, which correspond to different tradeoffs between two clustering objectives, and different numbers of clusters. In the second phase, we make use of the meta-clustering algorithm (MCLA) to combine all the Pareto solutions to get the final segmentation. The segmentation results are evaluated by comparing with three known algorithms: K-means, fuzzy K-means (FCM), and evolutionary clustering algorithm (ECA). It is shown that MECEA is an adaptive clustering algorithm, which outperforms the three algorithms in the experiments we carried out.","1941-0026","978-1-4244-1822-0","10.1109/CEC.2008.4631279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4631279","","Evolutionary computation","evolutionary computation;image segmentation;image texture;Pareto optimisation;pattern clustering","unsupervised texture image segmentation;multiobjective evolutionary clustering ensemble algorithm;fuzzy K-means;meta-clustering algorithm;Pareto solutions;adaptive clustering algorithm","","4","","22","","23 Sep 2008","","","IEEE","IEEE Conferences"
"Automated ischemic beat classification using genetic algorithms and multicriteria decision analysis","Y. Goletsis; C. Papaloukas; D. I. Fotiadis; A. Likas; L. K. Michalis","Univ. of Ioannina, Greece; Univ. of Ioannina, Greece; Univ. of Ioannina, Greece; Univ. of Ioannina, Greece; Univ. of Ioannina, Greece","IEEE Transactions on Biomedical Engineering","27 Sep 2004","2004","51","10","1717","1725","Cardiac beat classification is a key process in the detection of myocardial ischemic episodes in the electrocardiographic signal. In the present study, we propose a multicriteria sorting method for classifying the cardiac beats as ischemic or not. Through a supervised learning procedure, each beat is compared to preclassified category prototypes under five criteria. These criteria refer to ST segment changes, T wave alterations, and the patient's age. The difficulty in applying the above criteria is the determination of the required method parameters, namely the thresholds and weight values. To overcome this problem, we employed a genetic algorithm, which, after proper training, automatically calculates the optimum values for the above parameters. A task-specific cardiac beat database was developed for training and testing the proposed method using data from the European Society of Cardiology ST-T database. Various experimental tests were carried out in order to adjust each module of the classification system. The obtained performance was 91% in terms of both sensitivity and specificity and compares favorably to other beat classification approaches proposed in the literature.","1558-2531","","10.1109/TBME.2004.828033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1337140","","Genetic algorithms;Algorithm design and analysis;Databases;Myocardium;Signal processing;Sorting;Supervised learning;Prototypes;Testing;Cardiology","electrocardiography;signal classification;medical signal detection;medical signal processing;genetic algorithms;learning (artificial intelligence)","Automated Ischemic Beat Classification;genetic algorithms;multicriteria decision analysis;cardiac beat classification;myocardial ischemic episode detection;electrocardiographic signal;multicriteria sorting method;supervised learning procedure;ST segment changes;T wave alterations;patient age;task-specific cardiac beat database;European Society of Cardiology ST-T database","Age Factors;Aging;Algorithms;Arrhythmias, Cardiac;Arrhythmias, Cardiac;Artificial Intelligence;Cluster Analysis;Decision Support Systems, Clinical;Diagnosis, Computer-Assisted;Electrocardiography;Heart Rate;Humans;Myocardial Ischemia;Myocardial Ischemia;Pattern Recognition, Automated;Reproducibility of Results;Risk Assessment;Sensitivity and Specificity","74","1","40","","27 Sep 2004","","","IEEE","IEEE Journals"
"Algorithms for Speeding-Up the Deep Neural Networks For Detecting Plant Disease","L. Kouhalvandi; E. O. Gunes; S. Ozoguz","Department of Electronics and Communication Engineering, Istanbul Technical University, Istanbul, Turkey; Department of Electronics and Communication Engineering, Istanbul Technical University, Istanbul, Turkey; Department of Electronics and Communication Engineering, Istanbul Technical University, Istanbul, Turkey","2019 8th International Conference on Agro-Geoinformatics (Agro-Geoinformatics)","2 Sep 2019","2019","","","1","4","In designing an artificial network, different parameters such as activation functions, hyper-parameters, etc. are considered. Dealing with large number of parameters and also the functions that are expensive for evalualtion are very hard tasks. In this case, it is logical to find methods that results in smaller number of evaluations and improvements in performance. There are various techniques for multiobjective Bayesian optimization in deep learning structure. S-metric selection efficient global optimization (SMS-EGO) and DIRECT are one of the many techniques for multiobjective Bayesian optimization. In this paper, SMS-EGO and DIRECT techniques are applied to deep learning model and the average number of evaluations of each objective including time and error are investigated. For training and validating the deep network, a number of images present various diseases in leaves are provided from Plant Village data set. The simulation results show that by using SMSEGO technique, performance is improved and average time per iteration is faster.","","978-1-7281-2116-1","10.1109/Agro-Geoinformatics.2019.8820541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820541","Agriculture;Bayesian optimization;deep learning (DL);multiobjective optimization;planet disease","Optimization;Diseases;Deep learning;Bayes methods;Training;Agriculture;Linear programming","Bayes methods;learning (artificial intelligence);neural nets;optimisation;plant diseases","artificial network;activation functions;hyper-parameters;evalualtion;hard tasks;multiobjective Bayesian optimization;deep learning structure;SMS-EGO;DIRECT techniques;deep learning model;objective including time;deep network;SMSEGO technique;deep neural networks;detecting plant disease;plant village data","","1","","25","","2 Sep 2019","","","IEEE","IEEE Conferences"
"Multiobjective Optimization in Bioinformatics and Computational Biology","J. Handl; D. B. Kell; J. Knowles",Manchester Univ.; Manchester Univ.; Manchester Univ.,"IEEE/ACM Transactions on Computational Biology and Bioinformatics","7 May 2007","2007","4","2","279","292","This paper reviews the application of multiobjective optimization in the fields of bioinformatics and computational biology. A survey of existing work, organized by application area, forms the main body of the review, following an introduction to the key concepts in multiobjective optimization. An original contribution of the review is the identification of five distinct ""contexts,"" giving rise to multiple objectives: These are used to explain the reasons behind the use of multiobjective optimization in each application area and also to point the way to potential future uses of the technique","1557-9964","","10.1109/TCBB.2007.070203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4196538","Global optimization;clustering;classification and association rules;interactive data exploration and discovery;experimental design;machine learning;bioinformatics (genome or protein) databases.","Bioinformatics;Computational biology;Design optimization;Association rules;Design for experiments;Machine learning;Genomics;Proteins;Databases;Inverse problems","biology computing;optimisation;reviews","multiobjective optimization;bioinformatics;computational biology;reviews","Algorithms;Artificial Intelligence;Computational Biology;Computational Biology;Gene Expression Profiling;Gene Expression Profiling;Models, Biological;Pattern Recognition, Automated;Pattern Recognition, Automated;Sequence Analysis;Sequence Analysis","212","3","141","","7 May 2007","","","IEEE","IEEE Journals"
"Ranking Machine Learning Classifiers Using Multicriteria Approach","F. de Moura Rezende dos Santos; F. Guedes de Oliveira Almeida; A. C. Pereira Rocha Martins; A. C. Bittencourt Reis; M. Holanda","Comput. Sci., Univ. de Brasilia, Brasilia, Brazil; Comput. Sci., Univ. de Brasilia, Brasilia, Brazil; Comput. Sci., Univ. de Brasilia, Brasilia, Brazil; Ind. Eng., Univ. de Brasilia, Brasilia, Brazil; Comput. Sci., Univ. de Brasilia, Brasilia, Brazil","2018 11th International Conference on the Quality of Information and Communications Technology (QUATIC)","27 Dec 2018","2018","","","168","174","Classification algorithms are widely used as data mining tools for knowledge extraction. The literature presents several classifiers, but none of them applies to all problems. encountered in the various context in which they are used. Faced with this situation, the present article proposes a multicriteria approach to help practitioners to select the classifiers that will generate the best quality results by observing their performance measures. An empirical study was performed using a baseline of fetal examination from an UCI database using five classification algorithms (C4.5, Naive Bayes, SMO, KNN and Bayesnet), and each classifier was measured using five performance indicators (accuracy, true positive rate, precision, ROC curve and f-measure). Once implemented, a classifier ranking was conducted based on MCDA PROMETHEE II method, and the results show that SMO, C4.5 and Naive Bayes achieved the highest overall ranking.","","978-1-5386-5841-3","10.1109/QUATIC.2018.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590187","MCDA;Promethee;Machine Learning;Algorithms Selection;Classification Algorithms","Data mining;Measurement;Machine learning;Machine learning algorithms;Task analysis;Support vector machines;Computational modeling","data mining;learning (artificial intelligence);pattern classification","multicriteria approach;classification algorithms;data mining tools;knowledge extraction;performance measures;performance indicators;machine learning classifiers ranking","","","","36","","27 Dec 2018","","","IEEE","IEEE Conferences"
"Sensitivity Versus Accuracy in Multiclass Problems Using Memetic Pareto Evolutionary Neural Networks","J. C. Fernandez Caballero; F. J. Martinez; C. Hervas; P. A. Gutierrez","Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain; Department of Management and Quantitative Methods, ETEA, Córdoba, Spain; Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain; Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain","IEEE Transactions on Neural Networks","29 Apr 2010","2010","21","5","750","770","This paper proposes a multiclassification algorithm using multilayer perceptron neural network models. It tries to boost two conflicting main objectives of multiclassifiers: a high correct classification rate level and a high classification rate for each class. This last objective is not usually optimized in classification, but is considered here given the need to obtain high precision in each class in real problems. To solve this machine learning problem, we use a Pareto-based multiobjective optimization methodology based on a memetic evolutionary algorithm. We consider a memetic Pareto evolutionary approach based on the NSGA2 evolutionary algorithm (MPENSGA2). Once the Pareto front is built, two strategies or automatic individual selection are used: the best model in accuracy and the best model in sensitivity (extremes in the Pareto front). These methodologies are applied to solve 17 classification benchmark problems obtained from the University of California at Irvine (UCI) repository and one complex real classification problem. The models obtained show high accuracy and a high classification rate for each class.","1941-0093","","10.1109/TNN.2010.2041468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5428802","Accuracy;local search;multiclassification;multiobjective evolutionary algorithms;neural networks;sensitivity","Neural networks;Evolutionary computation;Backpropagation algorithms;Multi-layer neural network;Artificial neural networks;Multilayer perceptrons;Computer science;Testing;Iterative algorithms;Network topology","genetic algorithms;multilayer perceptrons;Pareto optimisation;pattern classification","multiclassification algorithm;multilayer perceptron;neural networks;memetic evolutionary algorithm;Pareto-based multiobjective optimization;nondominated sorting genetic algorithm 2;machine learning problem","Algorithms;Artificial Intelligence;Biological Evolution;Computer Communication Networks;Computer Simulation;Humans;Models, Genetic;Mutation;Neural Networks (Computer);ROC Curve;Reproducibility of Results","113","","75","IEEE","11 Mar 2010","","","IEEE","IEEE Journals"
"Comparision of Classification Algorithims for Survival of Breast Cancer Patients","G. Y. Özkan; S. Y. Gündüz","Havelsan A.Ş.,Ankara,Türkiye; Eskisehir Teknik Üniversitesi,Bilgisayar Mühendisliği Bölümü,Eskişehir,Türkiye","2020 Innovations in Intelligent Systems and Applications Conference (ASYU)","23 Nov 2020","2020","","","1","4","Breast cancer has become one of the most common diseases, especially among women, increasing the importance of predicting survival. In this study, the successes of machine learning algorithms on survival prediction were compared using the Surveillance, Epidemiology, and End Results (SEER) breast cancer data set. Used machine learning algorithms are: Naive Bayes, J48, Multiobjective Evolutionary Fuzzy Classifier (MEFC), Support Vector Machines (SVM). The most successful algorithm is J48 algorithm. The most successful algorithm is J48 algorithm according to the tests.","","978-1-7281-9136-2","10.1109/ASYU50717.2020.9259846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259846","Breast cancer;SEER Dataset;Naive Bayes;J48;Multiobjective Evolutionary Fuzzy Classifier;Support Vector Machine","Breast cancer;Classification algorithms;Machine learning algorithms;Surveillance;Support vector machine classification;Predictive models;Machine learning","cancer;data analysis;diseases;gynaecology;learning (artificial intelligence);medical computing;pattern classification","survival prediction;machine learning algorithms;classification algorithims;breast cancer patients;breast cancer data set","","","","0","","23 Nov 2020","","","IEEE","IEEE Conferences"
"Brain–Computer Evolutionary Multiobjective Optimization: A Genetic Algorithm Adapting to the Decision Maker","R. Battiti; A. Passerini","Dipartimento di Ingegneria e Scienza dell'Informazione, Università di Trento, Trento, Italy; Dipartimento di Ingegneria e Scienza dell'Informazione, Università di Trento, Trento, Italy","IEEE Transactions on Evolutionary Computation","30 Sep 2010","2010","14","5","671","687","The centrality of the decision maker (DM) is widely recognized in the multiple criteria decision-making community. This translates into emphasis on seamless human-computer interaction, and adaptation of the solution technique to the knowledge which is progressively acquired from the DM. This paper adopts the methodology of reactive search optimization (RSO) for evolutionary interactive multiobjective optimization. RSO follows to the paradigm of “learning while optimizing,” through the use of online machine learning techniques as an integral part of a self-tuning optimization scheme. User judgments of couples of solutions are used to build robust incremental models of the user utility function, with the objective to reduce the cognitive burden required from the DM to identify a satisficing solution. The technique of support vector ranking is used together with a k-fold cross-validation procedure to select the best kernel for the problem at hand, during the utility function training procedure. Experimental results are presented for a series of benchmark problems.","1941-0026","","10.1109/TEVC.2010.2058118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560789","Interactive decision making;machine learning;reactive search optimization;support vector ranking","Delta modulation;Optimization;Kernel;Humans;Support vector machines;Machine learning;Training","brain-computer interfaces;decision making;evolutionary computation;human computer interaction;learning (artificial intelligence);optimisation","decision making;brain-computer interaction;human-computer interaction;DM;reactive search optimization;evolutionary algorithm;multiobjective optimization;RSO;online machine learning;self-tuning optimization;robust incremental models;user utility function;k-fold cross validation procedure","","64","","56","IEEE","2 Sep 2010","","","IEEE","IEEE Journals"
"A neuro-fuzzy combiner for multiobjective control","I-Fang Chung; Chin-Teng Lin","Dept. of Electr. & Control Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan; NA","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","7 Aug 2002","2001","3","","1384","1389 vol.3","The paper proposes a neuro-fuzzy combiner (NFC) with supervised learning capability for solving multiobjective control problems. The proposed NFC can combine n existing low-level controllers in a hierarchical way to form a multiobjective fuzzy controller. It is assumed that each low-level (fuzzy or nonfuzzy) controller has been well designed to serve a particular objective. The role of the NFC is to fuse the n actions decided by the n low-level controllers and determine a proper action acting on the environment (plant) at each time step. Hence, the NFC can combine low-level controllers and achieve multiple objectives (goals) at once. A NFC can be designed by the proposed architecture and supervised learning scheme. Computer simulations have been conducted to illustrate the performance and applicability of the proposed architecture and learning scheme.","","0-7803-7078-3","10.1109/NAFIPS.2001.943751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943751","","Fuzzy control;Supervised learning;Control engineering;Fuses;Computer architecture;Fuzzy logic;Computer simulation;Application software;Engines;Aircraft propulsion","fuzzy neural nets;fuzzy control;neurocontrollers;learning (artificial intelligence);fuzzy logic;operations research;intelligent control","neuro-fuzzy combiner;NFC;supervised learning capability;multiobjective control problems;low-level controllers;multiobjective fuzzy controller;supervised learning scheme","","","","8","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Semi-supervised training of Least Squares Support Vector Machine using a multiobjective evolutionary algorithm","C. Silva; J. S. Santos; E. F. Wanner; E. G. Carrano; R. H. C. Takahashi","Department of Electrical Engineering, Universidade Federal de Minas Gerais, Brazil; Department of Electrical Engineering, Universidade Federal de Minas Gerais, Brazil; Department of Mathematics, Universidade Federal de Ouro Preto, Brazil; Centro Federal de Educação Tecnológica de Minas Gerais, CEFET-MG, Brazil; Department of Mathematics, Universidade Federal de Ouro Preto, Brazil","2009 IEEE Congress on Evolutionary Computation","29 May 2009","2009","","","2996","3002","Support Vector Machines (SVMs) are considered state-of-the-art learning machines techniques for classification problems. This paper studies the training of SVMs in the special case of problems in which the raw data to be used for training purposes is composed of both labeled and unlabeled data - the semi-supervised learning problem. This paper proposes the definition of an intermediate problem of attributing labels to the unlabeled data as a multiobjective optimization problem, with the conflicting objectives of minimizing the classification error over the training data set and maximizing the regularity of the resulting classifier. This intermediate problem is solved using an evolutionary multiobjective algorithm, the SPEA2. Simulation results are presented in order to illustrate the suitability of the proposed technique.","1941-0026","978-1-4244-2958-5","10.1109/CEC.2009.4983321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4983321","","Least squares methods;Support vector machines;Evolutionary computation;Support vector machine classification;Semisupervised learning;Text categorization;Testing;Statistical learning;Machine learning;Boosting","data analysis;error statistics;evolutionary computation;learning (artificial intelligence);minimisation;pattern classification;support vector machines","semi-supervised training;least square support vector machine;multiobjective evolutionary algorithm;unlabeled data set;classification error","","1","","14","","29 May 2009","","","IEEE","IEEE Conferences"
"Machine Learning Enabled Design Automation and Multi-Objective Optimization for Electric Transportation Power Systems","D. Jackson; S. Belakaria; Y. Cao; J. R. Doppa; X. Lu","School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA; Department of Electrical and Computer Engineering, Temple University, Philadelphia, PA, USA","IEEE Transactions on Transportation Electrification","21 Mar 2022","2022","8","1","1467","1481","This article presents an automated design and optimization framework for electric transportation power systems (ETPS) enabled by machine learning (ML). The use of physical models, simulations, and optimization methods can greatly aid the engineering design process. However, when considering the optimal co-design of multiple interdependent subsystems that span multiple physical domains, such model-based simulations can be computationally expensive, and traditional metaheuristic optimization methods can be unreliable. Bayesian optimization (BO), an ML framework, paves one feasible pathway to realize an efficient design process practically. However, current state-of-the-art BO algorithms are non-compatible or perform poorly when applied to system-level ETPS design with multiple objectives and constraints. This article proposes a novel BO algorithm referred to as max-value entropy search for multiobjective optimization with constraints (MESMOC) to solve multiobjective optimization (MOO) problems with black-box constraints that can only be evaluated through design simulations. After a full presentation of the algorithm, MESMOC is applied to a realistic ETPS design case using a heavy-duty electric vertical-takeoff-landing (eVTOL) urban aerial vehicle (UAV) power system. Two MOO experimental trials show a drastic reduction in the number of design simulations to discover a high-quality Pareto front. In Trial 1, MESMOC uncovered the entire Pareto front while only requiring to explore ~4% of the design space. With expanded design parameters and larger design space in Trial 2, a near complete but high-quality Pareto front was uncovered. Both trials compared MESMOC to the popular genetic algorithm NSGA-II and another BO algorithm predictive entropy search for multi-objective Bayesian optimization with constraints (PESMOC), showing superior performance.","2332-7782","","10.1109/TTE.2021.3113958","Oregon State University Foundation; U.S. National Science Foundation (NSF) CAREER Award(grant numbers:IIS-1845922,OAC-1910213); U.S. Department of Energy Advanced Research Projects Agency-Energy (ARPA-E) Award(grant numbers:DE-AR0001471); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9541164","Aviation;Bayesian optimization (BO);design automation;electric transportation;machine learning (ML);model-based design;multiobjective optimization (MOO);power system design;urban aerial vehicle (UAV)","Optimization;Computational modeling;Transportation;Mathematical model;Heuristic algorithms;Search problems;Machine learning","","","","","","46","IEEE","20 Sep 2021","","","IEEE","IEEE Journals"
"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data","E. R. Q. Fernandes; A. C. P. L. F. de Carvalho; X. Yao","Instituto de Ciências Matemáticas e de Computação (ICMC), University of São Paulo (USP), São Paulo, Brazil; Instituto de Ciências Matemáticas e de Computação (ICMC), University of São Paulo (USP), São Paulo, Brazil; Department of Compute Science and Engineering, Southern University of Science and Technology, Shenzhen, China","IEEE Transactions on Knowledge and Data Engineering","30 Apr 2020","2020","32","6","1104","1115","Imbalanced datasets may negatively impact the predictive performance of most classical classification algorithms. This problem, commonly found in real-world, is known in machine learning domain as imbalanced learning. Most techniques proposed to deal with imbalanced learning have been proposed and applied only to binary classification. When applied to multiclass tasks, their efficiency usually decreases and negative side effects may appear. This paper addresses these limitations by presenting a novel adaptive approach, E-MOSAIC (Ensemble of Classifiers based on MultiObjective Genetic Sampling for Imbalanced Classification). E-MOSAIC evolves a selection of samples extracted from training dataset, which are treated as individuals of a MOEA. The multiobjective process looks for the best combinations of instances capable of producing classifiers with high predictive accuracy in all classes. E-MOSAIC also incorporates two mechanisms to promote the diversity of these classifiers, which are combined into an ensemble specifically designed for imbalanced learning. Experiments using twenty imbalanced multi-class datasets were carried out. In these experiments, the predictive performance of E-MOSAIC is compared with state-of-the-art methods, including methods based on presampling, active-learning, cost-sensitive, and boosting. According to the experimental results, the proposed method obtained the best predictive performance for the multiclass accuracy measures mAUC and G-mean.","1558-2191","","10.1109/TKDE.2019.2898861","Fundação de Amparo à Pesquisa do Estado de São Paulo; Conselho Nacional de Desenvolvimento Científico e Tecnológico; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Intel; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8640265","Imbalanced datasets;ensemble of classifiers;evolutionary algorithm","Prediction algorithms;Task analysis;Training;Genetics;Boosting;Machine learning algorithms","data analysis;learning (artificial intelligence);pattern classification;sampling methods","imbalanced datasets;machine learning;imbalanced learning;binary classification;E-MOSAIC;ensemble of classifiers based on multiobjective genetic sampling for imbalanced classification","","18","","55","IEEE","12 Feb 2019","","","IEEE","IEEE Journals"
"Pareto-Optimal Adaptive Loss Residual Shrinkage Network for Imbalanced Fault Diagnostics of Machines","Y. Yu; L. Guo; H. Gao; Y. Liu; T. Feng","Southwest Jiaotong University, Chengdu, China; Southwest Jiaotong University, Chengdu, China; Southwest Jiaotong University, Chengdu, China; Southwest Jiaotong University, Chengdu, China; Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Industrial Informatics","5 Jan 2022","2022","18","4","2233","2243","In the industrial applications of mechanical fault diagnosis, machines work in normal condition at most time. In other words, most of the collected datasets are highly imbalanced. Although deep learning has been widely applied in intelligent diagnosis, it is unsuitable for such imbalanced situation. In addition, few studies attempted to determine the parameters in the diagnosis models. For solving such problems, Pareto-optimal adaptive loss residual shrinkage network (PALRSN) is proposed. First, a fixed length-based encoding method is implemented to represent the candidate architectures of PALRSN. Then, multiply accumulate operations and Gmean value representing the model complexity and identification performance, respectively, on imbalanced datasets are selected as the optimization targets to search for the optimal PALRSN architecture. In the training process, an adaptive loss function assigns different misclassification costs on all categories according to their number discrepancy to highlight the minority samples. The proposed method is validated by bearing data and milling cutter data with different imbalanced ratio. The experimental results demonstrate that such approach outperforms the state-of-the-art methods in imbalanced classification.","1941-0050","","10.1109/TII.2021.3094186","National Natural Science Foundation of China(grant numbers:51905452); Planning Project of Science Technology Department of Sichuan Province under Grant(grant numbers:2019YFG0353); Local Development Fundatoin guided by the Central Government(grant numbers:2020ZYD012); China Postdoctoral Science Foundation(grant numbers:2019M663549); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9483679","Adaptive loss function;imbalanced data;multiobjective genetic algorithm (GA);Pareto front;residual shrinkage network","Optimization;Training;Feature extraction;Adaptive systems;Neural networks;Fault diagnosis;Convolution","","","","","","30","IEEE","13 Jul 2021","","","IEEE","IEEE Journals"
"Multistage Collaborative Machine Learning and its Application to Antenna Modeling and Optimization","Q. Wu; H. Wang; W. Hong","State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, China; State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, China; State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, China","IEEE Transactions on Antennas and Propagation","5 May 2020","2020","68","5","3397","3409","A multistage collaborative machine learning (MS-CoML) method that can be applied to efficient multiobjective antenna modeling and optimization is proposed. Machine learning methods, including single-output Gaussian process regression (SOGPR) and symmetric and asymmetric multioutput GPR (MOGPR) methods, are introduced to collaboratively build highly accurate multitask surrogate models for antennas. Variable-fidelity electromagnetic (EM) models are simulated, with their responses utilized to build separate MOGPR surrogate models. By combining the three machine-learning methods in a multistage framework, mappings between the same and different responses of the EM models with variable fidelity are learned, therein helping to substantially reduce the computational effort under a negligible loss of predictive power. Three antenna designs aiming at single-band, broadband, and multiband applications are selected as examples. And, for illustrating the applicability and superiority of the proposed MS-CoML method, a reference point-based multiobjective antenna optimization algorithm is used to optimize these three antennas. Simulation results show that using the MS-CoML method can significantly reduce the total optimization time without compromising modeling accuracy and optimized performance.","1558-2221","","10.1109/TAP.2019.2963570","National Basic Research Program of China (973 Program)(grant numbers:2018YFB1801101); National Natural Science Foundation of China(grant numbers:61671145,61960206006); Key Research and Development Program of Jiangsu Province of China(grant numbers:BE2018121); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952905","Antenna modeling;machine learning;multiobjective optimization;multioutput Gaussian process regression;optimization methods","Antennas;Optimization;Computational modeling;Ground penetrating radar;Training;Data models;Analytical models","electrical engineering computing;Gaussian processes;learning (artificial intelligence);optimisation;regression analysis","EM models;multistage framework;machine-learning methods;separate MOGPR surrogate models;variable-fidelity electromagnetic models;highly accurate multitask surrogate models;machine learning methods;efficient multiobjective antenna modeling;multistage collaborative machine learning;modeling accuracy;reference point-based multiobjective antenna optimization algorithm;MS-CoML method;antenna designs","","17","","60","IEEE","8 Jan 2020","","","IEEE","IEEE Journals"
"Multicriteria Classifier Ensemble Learning for Imbalanced Data","W. Węgier; M. Koziarski; M. Woźniak","Department of Systems and Computer Networks, Wrocław University of Science and Technology, Wrocław, Poland; Department of Electronics, AGH University of Science and Technology, Kraków, Poland; Department of Systems and Computer Networks, Wrocław University of Science and Technology, Wrocław, Poland","IEEE Access","16 Feb 2022","2022","10","","16807","16818","One of the vital problems with the imbalanced data classifier training is the definition of an optimization criterion. Typically, since the exact cost of misclassification of the individual classes is unknown, combined metrics and loss functions that roughly balance the cost for each class are used. However, this approach can lead to a loss of information, since different trade-offs between class misclassification rates can produce similar combined metric values. To address this issue, this paper discusses a multi-criteria ensemble training method for the imbalanced data. The proposed method jointly optimizes <italic>precision</italic> and <italic>recall</italic>, and provides the end-user with a set of Pareto optimal solutions, from which the final one can be chosen according to the user’s preference. The proposed approach was evaluated on a number of benchmark datasets and compared with the single-criterion approach (where the selected criterion was one of the chosen metrics). The results of the experiments confirmed the usefulness of the obtained method, which on the one hand guarantees good quality, i.e., not worse than the one obtained with the use of single-criterion optimization, and on the other hand, offers the user the opportunity to choose the solution that best meets their expectations regarding the trade-off between errors on the minority and the majority class.","2169-3536","","10.1109/ACCESS.2022.3149914","Polish National Science Centre under the grant(grant numbers:2019/35/B/ST6/04442); Infrastruktura PL-Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706443","Classifier ensemble;imbalanced data;multi-objective optimization;pattern classification","Measurement;Optimization;Costs;Task analysis;Bagging;Training;Licenses","","","","","","53","CCBY","7 Feb 2022","","","IEEE","IEEE Journals"
"Multiobjective Optimization of Fully Autonomous Evolving Fuzzy Granular Models","D. Leite; F. Gomide; I. Škrjanc","Dept. of Engineering, Federal University of Lavras, Lavras, Brazil; School of Electrical and Computer Engineering, University of Campinas, Campinas, Brazil; Faculty of Electrical Engineering, University of Ljubljana, Ljubljana, Slovenia","2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","11 Oct 2019","2019","","","1","7","We introduce an incremental learning method for the optimal construction of rule-based granular models from numerical data streams. We take into account a multiobjective function, the specificity of information, model compactness, and variability and coverage of the data. We use α-level sets over Gaussian membership functions to set model granularity and operate with hyper-rectangular forms of granules in nonstationary environment. Rule-based models are formed in a systematic fashion and can be used for time series prediction and nonlinear function approximation. Precise estimates and enclosures are given by linear piecewise and inclusion functions related to optimal granular mappings. An application example on early detection and monitoring of the severity of the Parkinson's disease shows the usefulness of the method.","1558-4739","978-1-5386-1728-1","10.1109/FUZZ-IEEE.2019.8858964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8858964","Evolving system;fuzzy system;machine learning;online data stream;granular computing","Numerical models;Data models;Computational modeling;Adaptation models;Level set;Dispersion;Estimation error","diseases;function approximation;fuzzy set theory;granular computing;learning (artificial intelligence);medical computing;patient monitoring;time series","multiobjective optimization;fully autonomous evolving fuzzy granular models;incremental learning method;rule-based granular models;numerical data streams;α-level sets;Gaussian membership functions;rule-based models;time series prediction;nonlinear function approximation;linear piecewise;inclusion functions;optimal granular mappings;Parkinson's disease","","","","39","","11 Oct 2019","","","IEEE","IEEE Conferences"
"Benchmarking evolutionary multiobjective optimization algorithms","O. Mersmann; H. Trautmann; B. Naujoks; C. Weihs","Statistics Department of TU Dortmund University, Germany; Statistics Department of TU Dortmund University, Germany; Department of Computer Science of TU Dortmund University, Germany; Statistics Department of TU Dortmund University, Germany","IEEE Congress on Evolutionary Computation","27 Sep 2010","2010","","","1","8","Choosing and tuning an optimization procedure for a given class of nonlinear optimization problems is not an easy task. One way to proceed is to consider this as a tournament, where each procedure will compete in different `disciplines'. Here, disciplines could either be different functions, which we want to optimize, or specific performance measures of the optimization procedure. We would then be interested in the algorithm that performs best in a majority of cases or whose average performance is maximal. We will focus on evolutionary multiobjective optimization algorithms (EMOA), and will present a novel approach to the design and analysis of evolutionary multiobjective benchmark experiments based on similar work from the context of machine learning. We focus on deriving a consensus among several benchmarks over different test problems and illustrate the methodology by reanalyzing the results of the CEC 2007 EMOA competition.","1941-0026","978-1-4244-6911-6","10.1109/CEC.2010.5586241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586241","","Benchmark testing;Optimization;Algorithm design and analysis;Systematics;Machine learning algorithms;Handheld computers;Context","evolutionary computation;learning (artificial intelligence);optimisation","evolutionary multiobjective optimization algorithm;nonlinear optimization problem;machine learning;CEC 2007 EMOA competition","","5","","19","","27 Sep 2010","","","IEEE","IEEE Conferences"
"Feature Selection with Dynamic Classifier Ensembles","H. E. Kiziloz; A. Deniz","University of Turkish Aeronautical Association,Computer Engineering Department,Ankara,Turkey; Middle East Technical University,Computer Engineering Department,Ankara,Turkey","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","2038","2043","With the advance in technology, the volume of available data grows massively. Therefore, feature selection has become an essential preprocessing step to extract valuable information. Feature selection is the task of reducing the number of features by removing redundant features from data while preserving the classification accuracy. It is a multiobjective problem as there are two objectives. In general, multiobjective selection algorithms with machine learning techniques are utilized to find the most promising feature subsets; however, classification performances of these machine learning techniques are analyzed separately. In this study, we propose a new multiobjective selection model that dynamically searches for the best ensemble of five classifiers to extract the best representative feature subsets. We present the experiment results on 12 well-known datasets. The results show that the proposed method performs significantly better than all the machine learning techniques when they are executed separately. Moreover, the proposed method outperforms two existing ensemble algorithms, namely AdaBoost and Gradient Boosting.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9282969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282969","feature selection;multiobjective optimization;machine learning;classifier ensemble","Machine learning algorithms;Heuristic algorithms;Feature extraction;Prediction algorithms;Boosting;Classification algorithms;Task analysis","feature selection;learning (artificial intelligence);pattern classification","multiobjective selection algorithms;machine learning techniques;feature subsets;multiobjective selection model;representative feature subsets;feature selection;dynamic classifier ensembles;redundant features;general selection algorithms;AdaBoost algorithm;gradient boosting algorithm","","1","","20","","14 Dec 2020","","","IEEE","IEEE Conferences"
"A two-phase evolutionary algorithm for multiobjective mining of classification rules","Y. -H. Chan; T. -C. Chiang; L. -C. Fu","Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, R.O.C.; Department of Computer Science and Information Engineering, National Taiwan Normal University, Taiwan, R.O.C.; Department of Electrical Engineering and Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, R.O.C.","IEEE Congress on Evolutionary Computation","27 Sep 2010","2010","","","1","7","Classification rule mining, addressed a lot in machine learning and statistics communities, is an important task to extract knowledge from data. Most existing approaches do not particularly deal with data instances matched by more than one rule, which results in restricted performance. We present a two-phase multiobjective evolutionary algorithm which first aims at searching decent rules and then takes the rule interaction into account to produce the final rule sets. The algorithm incorporates the concept of Pareto dominance to deal with trade-off relations in both phases. Through computational experiments, the proposed algorithm shows competitive to the state-of-the-art. We also study the effect of a niching mechanism.","1941-0026","978-1-4244-6911-6","10.1109/CEC.2010.5586523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586523","","Classification algorithms;Accuracy;Data mining;Breast cancer;Evolutionary computation;Algorithm design and analysis;Iris","data mining;database management systems;evolutionary computation;Pareto optimisation;pattern classification","two-phase multiobjective evolutionary algorithm;multiobjective mining;classification rule set;knowledge extraction;classification rule mining;Pareto dominance;data instances;rule interaction;niching mechanism","","12","","31","","27 Sep 2010","","","IEEE","IEEE Conferences"
"Model-building algorithms for multiobjective EDAs: Directions for improvement","L. Marti; J. Garcia; A. Berlanga; J. M. Molina","Group of Applied Artificial Intelligence, Department of Informatics, Universidad Carlos III de Madrid, Spain; Group of Applied Artificial Intelligence, Department of Informatics, Universidad Carlos III de Madrid, Spain; Group of Applied Artificial Intelligence, Department of Informatics, Universidad Carlos III de Madrid, Spain; Group of Applied Artificial Intelligence, Department of Informatics, Universidad Carlos III de Madrid, Spain","2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)","23 Sep 2008","2008","","","2843","2850","In order to comprehend the advantages and short-comings of each model-building algorithm they should be tested under similar conditions and isolated from the MOEDA it takes part of. In this work we will assess some of the main machine learning algorithms used or suitable for model-building in a controlled environment and under equal conditions. They are analyzed in terms of solution accuracy and computational complexity. To the best of our knowledge a study like this has not been put forward before and it is essential for the understanding of the nature of the model-building problem of MOEDAs and how they should be improved to achieve a quantum leap in their problem solving capacity.","1941-0026","978-1-4244-1822-0","10.1109/CEC.2008.4631179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4631179","","Clustering algorithms;Optimization;Machine learning algorithms;Partitioning algorithms;Evolutionary computation;Complexity theory;Bayesian methods","computational complexity;evolutionary computation;learning (artificial intelligence);optimisation;problem solving","model-building algorithms;multiobjective EDA;machine learning algorithms;computational complexity;problem solving capacity;multiobjective optimization problems;multiobjective optimization evolutionary algorithms;MOEDAs;estimation of distribution algorithms","","2","","32","","23 Sep 2008","","","IEEE","IEEE Conferences"
"The Power Quality Forecasting Model for Off-Grid System Supported by Multiobjective Optimization","T. Vantuch; S. Mišák; T. Ježowicz; T. Buriánek; V. Snášel","Centre ENET, VŠB—TU Ostrava, Ostrava, Czech Republic; Department of Computer Science, VŠB—Technical University of Ostrava, Czech Republic; Centre ENET, VŠB—TU Ostrava, Ostrava, Czech Republic; Centre ENET, VŠB—TU Ostrava, Ostrava, Czech Republic; Department of Computer Science, VŠB—Technical University of Ostrava, Czech Republic","IEEE Transactions on Industrial Electronics","25 Oct 2017","2017","64","12","9507","9516","Measurement and control of electric power quality (PQ) parameters in off-grid systems has played an important role in recent years. The purpose is to detect or forecast the presence of PQ parameter disturbances to be able to suppress or to avoid their negative effects on the power grid and appliances. This paper focuses on several PQ parameters in off-grid systems and it defines three evaluation criteria that are supposed to estimate the performance of a new forecasting model combining all the involved PQ parameters. These criteria are based on common statistical evaluations of computational models from the machine learning field of study. The studied PQ parameters are voltage, power frequency, total harmonic distortion, and flicker severity. The approach presented in this paper also applies a machine learning based model of random decision forest for PQ forecasting. The database applied in this task contains real off-grid data from long-term one-minute measurements. The hyperparameters of the model are optimized by multiobjective optimization toward the defined evaluation criteria.","1557-9948","","10.1109/TIE.2017.2711540","TUCENET Sustainable Development of Centre ENET(grant numbers:LO1404); Students Grant Competition(grant numbers:SP2017/157,SP2017/159,CZ.1.05/2.1.00/19.0389); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7938383","Forecasting;off-grid system;power quality","Forecasting;Predictive models;Optimization;Computational modeling;Measurement;Power systems;Inverters","harmonic distortion;learning (artificial intelligence);machine control;optimisation;power grids;power supply quality","power frequency;PQ forecasting;off-grid data;multiobjective optimization;power quality forecasting model;off-grid system;PQ parameter disturbances;power grid;machine learning field;electric power quality parameter control;electric power quality parameter measurement","","23","","35","IEEE","2 Jun 2017","","","IEEE","IEEE Journals"
"A Data-Driven Method for IGBT Open-Circuit Fault Diagnosis Based on Hybrid Ensemble Learning and Sliding-Window Classification","Y. Xia; Y. Xu; B. Gou","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Rolls-Royce @ NTU Corporate Lab, Nanyang Technological University, Singapore","IEEE Transactions on Industrial Informatics","29 Apr 2020","2020","16","8","5223","5233","In this article, a novel data-driven method is proposed for open-circuit fault diagnosis of insulated gate bipolar transistor used in three-phase pulsewidth modulation converter. Based on the sampled three-phase current signals, fast Fourier transform and ReliefF algorithm are used to select most correlated features. Then, based on two randomized learning technologies named extreme learning machine and random vector functional link network, a hybrid ensemble learning scheme is proposed for extracting mapping relationship between fault modes and the selected features. Furthermore, in order to achieve an accurate and fast diagnostic performance, a sliding-window classification framework is designed. Finally, parameters in the diagnostic model are optimized by a multiobjective optimization programming model to achieve optimal balance between diagnosis accuracy and speed. At offline testing stage, the overall average diagnostic accuracy can be as high as 99% with the diagnostic time of around one-cycle sampling time. Furthermore, real-time experiments verify its effectiveness and reliability under different operation conditions.","1941-0050","","10.1109/TII.2019.2949344","Ministry of Education (MOE), Republic of Singapore(grant numbers:AcRF TIER 1 2019-T1-001-069 (RG75/19)); National Research Foundation (NRF) of Singapore(grant numbers:NRF2018-SR2001-018); Nanyang Assistant Professorship from Nanyang Technological University, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882319","Hybrid ensemble learning;insulated gate bipolar transistor (IGBT) open-circuit fault;multiobjective optimization programming (MOP);sliding-window classifier","Feature extraction;Circuit faults;Insulated gate bipolar transistors;Fault diagnosis;Integrated circuit modeling;Adaptation models;Optimization","fast Fourier transforms;fault diagnosis;feature selection;insulated gate bipolar transistors;learning (artificial intelligence);optimisation;pattern classification;PWM power convertors","correlated features selection;mapping relationship extraction;sampled three-phase current signals;one-cycle sampling time;optimal balance;multiobjective optimization programming model;sliding-window classification framework;fast diagnostic performance;fault modes;hybrid ensemble learning scheme;random vector functional link network;extreme learning machine;randomized learning technologies;relief algorithm;three-phase pulsewidth modulation converter;insulated gate bipolar transistor;data-driven method;IGBT open-circuit fault diagnosis","","18","","29","IEEE","24 Oct 2019","","","IEEE","IEEE Journals"
"On Balancing Neighborhood and Global Replacement Strategies in MOEA/D","X. Chen; C. Shi; A. Zhou; B. Wu; P. Sheng","Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Shanghai Key Laboratory of Multidimensional Information Processing Department of Computer Science and Technology, East China Normal University, Shanghai, China; Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; School of Mechanical Engineering, Hebei University of Technology, Tianjin, China","IEEE Access","14 Apr 2019","2019","7","","45274","45290","In recent years, the multiobjective evolutionary algorithm based on decomposition (MOEA/D) has shown superior performance in solving multiobjective optimization problems (MOPs). In MOEA/D, the adaptive replacement strategy (ARS) plays a key role in balancing convergence and diversity. However, existing ARSs do not effectively balance convergence and diversity. To overcome this disadvantage, we propose a mechanism for adapting neighborhood and global replacement. This mechanism determines whether a neighborhood or global replacement strategy should be employed in the search process. Furthermore, we design an offspring generation strategy to generate high-quality solutions. We call this new algorithm framework MOEA/D-ARS. The experimental results suggest that the proposed algorithm performs better than certain state-of-the-art MOEAs.","2169-3536","","10.1109/ACCESS.2019.2909290","National Natural Science Foundation of China(grant numbers:61772082,61375058,61673180); National Key Research and Development Program of China(grant numbers:2017YFB0102500); Natural Science Foundation of Beijing Municipality(grant numbers:4182043); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681506","Evolutionary algorithm;multiobjective optimization;convergence;adaptive replacement strategy;supervised learning;upper bound","Convergence;Optimization;Sociology;Statistics;Evolutionary computation;Search problems;Telecommunications","evolutionary computation;optimisation;search problems","multiobjective evolutionary algorithm;multiobjective optimization problems;adaptive replacement strategy;convergence;offspring generation strategy;algorithm framework MOEA/D-ARS;global replacement strategies;neighborhood replacement strategies;search process","","","","60","OAPA","4 Apr 2019","","","IEEE","IEEE Journals"
"Two Machine Learning Approaches for Short-Term Wind Speed Time-Series Prediction","R. Ak; O. Fink; E. Zio","Chair on Systems Science and the Energetic Challenge, European Foundation for New Energy-Electricité de France, École Centrale Paris, Châtenay-Malabry, France; Institute of Data Analysis and Process Design, Zurich University of Applied Sciences, Winterthur, Switzerland; Chair on Systems Science and the Energetic Challenge, European Foundation for New Energy-Electricité de France, École Centrale Paris, Châtenay-Malabry, France","IEEE Transactions on Neural Networks and Learning Systems","15 Jul 2016","2016","27","8","1734","1747","The increasing liberalization of European electricity markets, the growing proportion of intermittent renewable energy being fed into the energy grids, and also new challenges in the patterns of energy consumption (such as electric mobility) require flexible and intelligent power grids capable of providing efficient, reliable, economical, and sustainable energy production and distribution. From the supplier side, particularly, the integration of renewable energy sources (e.g., wind and solar) into the grid imposes an engineering and economic challenge because of the limited ability to control and dispatch these energy sources due to their intermittent characteristics. Time-series prediction of wind speed for wind power production is a particularly important and challenging task, wherein prediction intervals (PIs) are preferable results of the prediction, rather than point estimates, because they provide information on the confidence in the prediction. In this paper, two different machine learning approaches to assess PIs of time-series predictions are considered and compared: 1) multilayer perceptron neural networks trained with a multiobjective genetic algorithm and 2) extreme learning machines combined with the nearest neighbors approach. The proposed approaches are applied for short-term wind speed prediction from a real data set of hourly wind speed measurements for the region of Regina in Saskatchewan, Canada. Both approaches demonstrate good prediction precision and provide complementary advantages with respect to different evaluation criteria.","2162-2388","","10.1109/TNNLS.2015.2418739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091914","Extreme learning machines (ELMs);multilayer perceptron (MLP);multiobjective genetic algorithms (MOGAs);prediction intervals (PIs);short-term wind speed prediction;wind power production","Wind speed;Prediction algorithms;Sociology;Statistics;Artificial neural networks;Training;Neurons","genetic algorithms;learning (artificial intelligence);multilayer perceptrons;power engineering computing;power markets;smart power grids;time series;wind power plants","short-term wind speed time-series prediction;European electricity markets;energy grids;energy consumption;flexible intelligent power grids;sustainable energy production;sustainable energy distribution;wind power production;prediction intervals;machine learning approaches;multilayer perceptron neural network training;multiobjective genetic algorithm;extreme learning machines;nearest neighbors approach;wind speed measurement;Regina;Saskatchewan;Canada","","85","","51","IEEE","22 Apr 2015","","","IEEE","IEEE Journals"
"A Neurobiologically-inspired Deep Learning Framework for Autonomous Context Learning","D. W. Ludwig; L. W. Remedios; J. L. Phillips","Middle Tennessee State University,Department of Computer Science,Murfreesboro,TN,USA; Middle Tennessee State University,Department of Computer Science,Murfreesboro,TN,USA; Middle Tennessee State University,Department of Computer Science,Murfreesboro,TN,USA","2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)","21 Dec 2021","2021","","","97","104","Neurobiologically-inspired working memory models demonstrate human/animal capabilities to rapidly adapt and alter responses to the environment via context-switching and error monitoring. However, the application of these models outside of reinforcement learning problems has been relatively unexplored. We present a new framework compatible with Tensorflow/Keras enabling the integration of working memory-inspired mechanisms into typical neural network architectures. These mechanisms allow models to autonomously learn multiple tasks, statically or dynamically allocated. We also examine the generalization of the framework across a variety of multi-context supervised learning and reinforcement learning tasks. The resulting experiments successfully integrate these mechanisms with multi-layer and convolutional neural network architectures and the diversity of problems solved demonstrates the framework's generalizability across a variety of architectures and tasks.","2375-0197","978-1-6654-0898-1","10.1109/ICTAI52525.2021.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643379","cognitive architectures;machine learning;taskswitching;multiobjective;working memory","Deep learning;Adaptation models;Neural networks;Supervised learning;Stochastic processes;Reinforcement learning;Switches","","","","","","20","","21 Dec 2021","","","IEEE","IEEE Conferences"
"Multicriteria approaches for predictive model generation: A comparative experimental study","B. Al-Jubouri; B. Gabrys","Smart Technology Research Centre, Faculty of Science and Technology, Bournemouth University, UK; Smart Technology Research Centre, Faculty of Science and Technology, Bournemouth University, UK","2014 IEEE Symposium on Computational Intelligence in Multi-Criteria Decision-Making (MCDM)","15 Jan 2015","2014","","","64","71","This study investigates the evaluation of machine learning models based on multiple criteria. The criteria included are: predictive model accuracy, model complexity, and algorithmic complexity (related to the learning/adaptation algorithm and prediction delivery) captured by monitoring the execution time. Furthermore, it compares the models generated from optimising the criteria using two approaches. The first approach is a scalarized multi objective optimisation, where the models are generated from optimising a single cost function that combines the criteria. On the other hand the second approach uses a Pareto-based multi objective optimisation to trade-off the three criteria and to generate a set of non-dominated models. This study shows that defining universal measures for the three criteria is not always feasible. Furthermore, it was shown that, the models generated from Pareto-based multi objective optimisation approach can be more accurate and more diverse than the models generated from scalarized multi objective optimisation approach.","","978-1-4799-4467-5","10.1109/MCDM.2014.7007189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7007189","","Complexity theory;Predictive models;Accuracy;Prediction algorithms;Optimization;Artificial neural networks;Mathematical model","computational complexity;learning (artificial intelligence);Pareto optimisation;prediction theory","multicriteria approaches;predictive model generation;machine learning models;multiple criteria;predictive model accuracy;model complexity;algorithmic complexity;learning algorithm;adaptation algorithm;prediction delivery;scalarized multiobjective optimisation;Pareto-based multiobjective optimisation;nondominated models","","3","","31","","15 Jan 2015","","","IEEE","IEEE Conferences"
"A Survey of Evolutionary Algorithms for Multi-Objective Optimization Problems With Irregular Pareto Fronts","Y. Hua; Q. Liu; K. Hao; Y. Jin","College of Information Sciences and Technology, Donghua University,Shanghai,China,201620; University of Surrey,Department of Computer Science,Guildford,Surrey,U.K.,GU2 7XH; College of Information Sciences and Technology, Donghua University,Shanghai,China,201620; University of Surrey,Department of Computer Science,Guildford,Surrey,U.K.,GU2 7XH","IEEE/CAA Journal of Automatica Sinica","12 Jan 2021","2021","8","2","303","318","Evolutionary algorithms have been shown to be very successful in solving multi-objective optimization problems (MOPs). However, their performance often deteriorates when solving MOPs with irregular Pareto fronts. To remedy this issue, a large body of research has been performed in recent years and many new algorithms have been proposed. This paper provides a comprehensive survey of the research on MOPs with irregular Pareto fronts. We start with a brief introduction to the basic concepts, followed by a summary of the benchmark test problems with irregular problems, an analysis of the causes of the irregularity, and real-world optimization problems with irregular Pareto fronts. Then, a taxonomy of the existing methodologies for handling irregular problems is given and representative algorithms are reviewed with a discussion of their strengths and weaknesses. Finally, open challenges are pointed out and a few promising future directions are suggested.","2329-9274","","10.1109/JAS.2021.1003817","National Natural Science Foundation of China(grant numbers:61806051,61903078); Natural Science Foundation of Shanghai(grant numbers:20ZR1400400); Fundamental Research Funds for the Central Universities(grant numbers:2232020D-48); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321268","Evolutionary algorithm;machine learning;multiobjective optimization problems (MOPs);irregular Pareto fronts","Taxonomy;Evolutionary computation;Benchmark testing;Optimization","evolutionary computation;Pareto optimisation","evolutionary algorithms;multiobjective optimization problems;irregular Pareto fronts;MOPs;benchmark test problems;irregular problems;irregularity;real-world optimization problems","","9","","111","","12 Jan 2021","","","IEEE","IEEE Journals"
"A first study on bagging fuzzy rule-based classification systems with multicriteria genetic selection of the component classifiers","O. Cordon; A. Quirin; L. Sanchez","European Centre for Soft Computing, Edificio Científico-Tecnológico, planta 3. Gonzalo Gutiérrez Quirós, s/n, 33600 - Mieres (Asturias), SPAIN; European Centre for Soft Computing, Edificio Científico-Tecnológico, planta 3. Gonzalo Gutiérrez Quirós, s/n, 33600 - Mieres (Asturias), SPAIN; Computer Science Department. University of Oviedo, Campus de Viesques, 33203 - Gijón (Asturias), SPAIN","2008 3rd International Workshop on Genetic and Evolving Systems","11 Apr 2008","2008","","","11","16","Fuzzy rule-based classification systems (FRBCSs) are able to design interpretable classifiers but suffer from the curse of dimensionality when dealing with complex problems with a large number of features. In this contribution we explore the use of popular approaches for designing ensembles of classifiers in the machine learning field, bagging and random subspace, to design FRBCS multiclassifiers from a basic, heuristic fuzzy classification rule generation method, aiming to both improve their accuracy and to make them able to deal with high dimensional classification problems. Besides, a multicriteria genetic algorithm is proposed to select the component classifiers in the ensemble guided by the cumulative likelihood in order to look for an appropriate accuracy-complexity trade-off.","","978-1-4244-1612-7","10.1109/GEFS.2008.4484560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4484560","","Bagging;Fuzzy systems;Machine learning;Genetic algorithms;Boosting;Proposals;Humans;Design methodology;Evolutionary computation;Scalability","fuzzy set theory;genetic algorithms;knowledge based systems;learning (artificial intelligence);pattern classification","bagging fuzzy rule-based classification system;multicriteria genetic algorithm;component classifier;machine learning;heuristic fuzzy classification rule generation method","","8","","29","","11 Apr 2008","","","IEEE","IEEE Conferences"
"Cooperative coevolution of artificial neural network ensembles for pattern classification","N. Garcia-Pedrajas; C. Hervas-Martinez; D. Ortiz-Boyer","Dept. of Comput. & Numerical Anal., Univ. of Cordoba, Spain; Dept. of Comput. & Numerical Anal., Univ. of Cordoba, Spain; Dept. of Comput. & Numerical Anal., Univ. of Cordoba, Spain","IEEE Transactions on Evolutionary Computation","6 Jun 2005","2005","9","3","271","302","This paper presents a cooperative coevolutive approach for designing neural network ensembles. Cooperative coevolution is a recent paradigm in evolutionary computation that allows the effective modeling of cooperative environments. Although theoretically, a single neural network with a sufficient number of neurons in the hidden layer would suffice to solve any problem, in practice many real-world problems are too hard to construct the appropriate network that solve them. In such problems, neural network ensembles are a successful alternative. Nevertheless, the design of neural network ensembles is a complex task. In this paper, we propose a general framework for designing neural network ensembles by means of cooperative coevolution. The proposed model has two main objectives: first, the improvement of the combination of the trained individual networks; second, the cooperative evolution of such networks, encouraging collaboration among them, instead of a separate training of each network. In order to favor the cooperation of the networks, each network is evaluated throughout the evolutionary process using a multiobjective method. For each network, different objectives are defined, considering not only its performance in the given problem, but also its cooperation with the rest of the networks. In addition, a population of ensembles is evolved, improving the combination of networks and obtaining subsets of networks to form ensembles that perform better than the combination of all the evolved networks. The proposed model is applied to ten real-world classification problems of a very different nature from the UCI machine learning repository and proben1 benchmark set. In all of them the performance of the model is better than the performance of standard ensembles in terms of generalization error. Moreover, the size of the obtained ensembles is also smaller.","1941-0026","","10.1109/TEVC.2005.844158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1438402","Classification;cooperative coevolution;multiobjective optimization;neural network ensembles","Artificial neural networks;Pattern classification;Neural networks;Evolutionary computation;Neurons;Collaboration;Machine learning;Numerical analysis;Robustness","evolutionary computation;neural nets;pattern classification","cooperative coevolution;artificial neural network;neural network ensemble design;evolutionary computation;evolutionary process;multiobjective method;pattern classification;UCI machine learning repository;proben1 benchmark set","","150","7","100","","6 Jun 2005","","","IEEE","IEEE Journals"
"Plausible Counterfactuals: Auditing Deep Learning Classifiers with Realistic Adversarial Examples","A. Barredo-Arrieta; J. Del Ser","Basque Research and Technology Alliance (BRTA),TECNALIA,Derio,Bizkaia,Spain,48160; Basque Research and Technology Alliance (BRTA),TECNALIA,Derio,Bizkaia,Spain,48160","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","7","The last decade has witnessed the proliferation of Deep Learning models in many applications, achieving unrivaled levels of predictive performance. Unfortunately, the black-box nature of Deep Learning models has posed unanswered questions about what they learn from data. Certain application scenarios have highlighted the importance of assessing the bounds under which Deep Learning models operate, a problem addressed by using assorted approaches aimed at audiences from different domains. However, as the focus of the application is placed more on non-expert users, it results mandatory to provide the means for him/her to trust the model, just like a human gets familiar with a system or process: by understanding the hypothetical circumstances under which it fails. This is indeed the angular stone for this research work: to undertake an adversarial analysis of a Deep Learning model. The proposed framework constructs counterfactual examples by ensuring their plausibility, e.g. there is a reasonable probability that a human could generate them without resorting to a computer program. Therefore, this work must be regarded as valuable auditing exercise of the usable bounds a certain model is constrained within, thereby allowing for a much greater understanding of the capabilities and pitfalls of a model used in a real application. To this end, a Generative Adversarial Network (GAN) and multi-objective heuristics are used to furnish a plausible attack to the audited model, efficiently trading between the confusion of this model, the intensity and plausibility of the generated counterfactual. Its utility is showcased within a human face classification task, unveiling the enormous potential of the proposed framework.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206728","Explainable Artificial Intelligence;Deep Learning;Counterfactuals;Generative Adversarial Networks;Multiobjective Optimization;Meta-heuristics","Gallium nitride;Machine learning;Faces;Generators;Analytical models;Generative adversarial networks;Task analysis","image classification;learning (artificial intelligence);neural nets","plausible counterfactuals;deep learning classifiers;realistic adversarial examples;adversarial analysis;generative adversarial network;multiobjective heuristics;image classification","","2","","32","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Analysis of Multiobjective Algorithms for the Classification of Multi-Label Video Datasets","G. N. Karagoz; A. Yazici; T. Dokeroglu; A. Cosar","Department of Computer Engineering, Middle East Technical University, Ankara, Turkey; Department of Computer Engineering, Middle East Technical University, Ankara, Turkey; Department of Computer Engineering, TED University, Ankara, Turkey; Department of Computer Engineering, Ankara Science University, Ankara, Turkey","IEEE Access","16 Sep 2020","2020","8","","163937","163952","It is of great importance to extract and validate an optimal subset of non-dominated features for effective multi-label classification. However, deciding on the best subset of features is an NP-Hard problem and plays a key role in improving the prediction accuracy and the processing time of video datasets. In this study, we propose autoencoders for dimensionality reduction of video data sets and ensemble the features extracted by the multi-objective evolutionary Non-dominated Sorting Genetic Algorithm and the autoencoder. We explore the performance of well-known multi-label classification algorithms for video datasets in terms of prediction accuracy and the number of features used. More specifically, we evaluate Non-dominated Sorting Genetic Algorithm-II, autoencoders, ensemble learning algorithms, Principal Component Analysis, Information Gain, and Correlation Based Feature Selection. Some of these algorithms use feature selection techniques to improve the accuracy of the classification. Experiments are carried out with local feature descriptors extracted from two multi-label datasets, the MIR-Flickr dataset which consists of images and the Wireless Multimedia Sensor dataset that we have generated from our video recordings. Significant improvements in the accuracy performance of the algorithms are observed while the number of features is being reduced.","2169-3536","","10.1109/ACCESS.2020.3022317","NU Faculty-development competitive research grants program, Nazarbayev University(grant numbers:110119FD4543); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187265","Feature selection;multi-label;multi-objective optimization;autoencoder;ensemble;classification","Feature extraction;Prediction algorithms;Optimization;Dimensionality reduction;Machine learning algorithms;Genetic algorithms;Support vector machines","feature extraction;feature selection;genetic algorithms;image classification;neural nets;principal component analysis;video signal processing","autoencoder;well-known multilabel classification algorithms;prediction accuracy;learning algorithms;Principal Component Analysis;feature selection techniques;local feature descriptors;multilabel datasets;MIR-Flickr dataset;Wireless Multimedia Sensor dataset;video recordings;multiobjective algorithms;multilabel video datasets;optimal subset;nondominated features;effective multilabel classification;NP-Hard problem;video data sets;multiobjective evolutionary Nondominated Sorting Genetic Algorithm;Non-dominated Sorting Genetic Algorithm-II;ensemble learning algorithms","","1","","60","CCBY","7 Sep 2020","","","IEEE","IEEE Journals"
"A Novel Deep Learning Approach: Stacked Evolutionary Auto-encoder","Y. Cai; Z. Cai; M. Zeng; X. Liu; J. Wu; G. Wang","School of Computer Science, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; School of Automation, China University of Geosciences, Wuhan, China; Department of Computing, Macquarie University, Sydney, NSW, 2109, Australia; School of Automation, China University of Geosciences, Wuhan, China","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","Deep neural networks have been successfully applied to many data mining problems in recent works. The training of deep neural networks relies heavily upon gradient descent methods, however, which may lead to the failure of training due to the vanishing gradient (or exploding gradient) and local optima problems. In this paper, we present SEvoAE method based on using Evolutionary Multiobjective optimization (EMO) algorithm to train single layer auto-encoder, and sequentially learning deeper representation in a stacking way. SEvoAE is able to achieve accurate feature representation with good sparseness by globally simultaneously optimizing two conflicting objective functions and allows users to flexibly design objective functions and evolutionary optimizers. We compare results of the proposed method with existing architectures for seven classification problems, showing that the proposed method is able to outperform existing methods with a reduced risk of overfitting the training data.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489138","Deep learning;Auto-encoder;Evolutionary Multiobjective Optimization","Training;Optimization;Decoding;Neural networks;Linear programming;Feature extraction;Stacking","data mining;evolutionary computation;gradient methods;learning (artificial intelligence);neural nets","stacked Evolutionary auto-encoder;deep neural networks;data mining problems;gradient descent methods;vanishing gradient;local optima problems;SEvoAE method;single layer auto-encoder;conflicting objective functions;evolutionary optimizers;training data;evolutionary multiobjective optimization algorithm;feature representation;classification problems;deep learning approach","","4","","32","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Differential evolution based multiobjective optimization for biomedical entity extraction","U. K. Sikdar; A. Ekbal; S. Saha","Department of CSE, Indian Institute of Technology, Patna, India; Department of CSE, Indian Institute of Technology, Patna, India; Department of CSE, Indian Institute of Technology, Patna, India","2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","1 Dec 2014","2014","","","1039","1044","In this paper, we propose multi-objective differential evolution (DE) based feature selection and ensemble learning techniques for biomedical entity extraction. The algorithm operates in two layers, first step of which concerns with the problem of automatic feature selection for a machine learning algorithm, namely Conditional Random Field (CRF). The solutions of the final best population provides different feature combinations. The classifiers generated with these feature representations are combined together using a multi-objective differential based ensemble technique. We evaluate the proposed algorithm for named entity (NE) extraction in biomedical text. Experiments on the benchmark setup yield recall, precision and F-measure values of 73.50%, 77.02% and 75.22%, respectively.","","978-1-4799-3080-7","10.1109/ICACCI.2014.6968390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6968390","","Biological cells;Vectors;Sociology;Statistics;Feature extraction;Optimization;Linear programming","evolutionary computation;feature extraction;feature selection;learning (artificial intelligence);medical computing;pattern classification;random processes;text analysis","differential evolution based multiobjective optimization;multiobjective differential evolution;DE based feature selection;ensemble learning techniques;biomedical entity extraction;automatic feature selection;machine learning algorithm;conditional random field;CRF;feature combinations;classifiers;feature representations;multiobjective differential based ensemble technique;named entity;NE extraction;biomedical text","","1","","16","","1 Dec 2014","","","IEEE","IEEE Conferences"
"Multiobjective Evolutionary Design of Deep Convolutional Neural Networks for Image Classification","Z. Lu; I. Whalen; Y. Dhebar; K. Deb; E. D. Goodman; W. Banzhaf; V. N. Boddeti","Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA","IEEE Transactions on Evolutionary Computation","30 Mar 2021","2021","25","2","277","291","Convolutional neural networks (CNNs) are the backbones of deep learning paradigms for numerous vision tasks. Early advancements in CNN architectures are primarily driven by human expertise and by elaborate design processes. Recently, neural architecture search was proposed with the aim of automating the network design process and generating task-dependent architectures. While existing approaches have achieved competitive performance in image classification, they are not well suited to problems where the computational budget is limited for two reasons: 1) the obtained architectures are either solely optimized for classification performance, or only for one deployment scenario and 2) the search process requires vast computational resources in most approaches. To overcome these limitations, we propose an evolutionary algorithm for searching neural architectures under multiple objectives, such as classification performance and floating point operations (FLOPs). The proposed method addresses the first shortcoming by populating a set of architectures to approximate the entire Pareto frontier through genetic operations that recombine and modify architectural components progressively. Our approach improves computational efficiency by carefully down-scaling the architectures during the search as well as reinforcing the patterns commonly shared among past successful architectures through Bayesian model learning. The integration of these two main contributions allows an efficient design of architectures that are competitive and in most cases outperform both manually and automatically designed architectures on benchmark image classification datasets: CIFAR, ImageNet, and human chest X-ray. The flexibility provided from simultaneously obtaining multiple architecture choices for different compute requirements further differentiates our approach from other methods in the literature.","1941-0026","","10.1109/TEVC.2020.3024708","National Science Foundation(grant numbers:DBI-0939454); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201169","Convolutional neural networks (CNNs);evolutionary deep learning;genetic algorithms (GAs);neural architecture search (NAS)","Computer architecture;Optimization;Search problems;Task analysis;Neural networks;Computational modeling;Graphics processing units","Bayes methods;convolutional neural nets;deep learning (artificial intelligence);evolutionary computation;image classification;neural net architecture","human chest X-ray;ImageNet;CIFAR;Bayesian model learning;FLOP;computational resources;neural architecture;CNN;image classification;floating point operations;evolutionary algorithm;deep convolutional neural networks;multiobjective evolutionary design","","17","","61","IEEE","21 Sep 2020","","","IEEE","IEEE Journals"
"An Information Fusion-Based Multiobjective Security System With a Multiple-Input/ Single-Output Sensor","T. Ishigaki; T. Higuchi; K. Watanabe","Dept. of Stat. Sci., Graduate Univ. for Adv. Studies, Tokyo; NA; NA","IEEE Sensors Journal","16 Apr 2007","2007","7","5","734","742","In the framework of sensor fusion, multiple sensors corresponding to the number of physical variables that must be measured are used. In this paper, we propose a novel sensing approach that simultaneously deals with heterogeneous physical variables with a sensor. It is fundamentally different from sensor fusion. The proposed approach takes into consideration the fact that any sensor that detects a certain physical variable is influenced to a degree by other physical variables, which are designated as noise. The objective in conventional sensor design has been the minimization of noise. In contrast, the proposed approach takes advantage of sensors that are easily influenced by many physical variables and makes full use of the multisensing characteristics of these sensors. The system designed using this concept has advantages in terms of cost performance and system simplification compared to existing approaches. This concept can be realized by developing a novel multiple-input/single-output sensor that can detect various variables, including pressure, acceleration, temperature and incandescent light emission, by a single device. We apply the sensor to monitor the symptoms of fire, earthquakes, and break-ins for the purpose of home security. The proposed security system is realized through statistical signal processing and machine learning techniques","1558-1748","","10.1109/JSEN.2007.894887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4154675","Autoregressive model;home security;information fusion;Kalman filter;multiple-input/single-output sensor;support vector machine","Information security;Sensor systems;Sensor phenomena and characterization;Sensor fusion;Temperature sensors;Costs;Acceleration;Monitoring;Fires;Earthquakes","learning (artificial intelligence);security;sensor fusion;statistical analysis","information fusion;multiobjective security system;multiple-input/single-output sensor;sensor fusion;statistical signal processing;machine learning techniques","","10","","15","","16 Apr 2007","","","IEEE","IEEE Journals"
"Transfer Clustering Ensemble Selection","Y. Shi; Z. Yu; C. L. P. Chen; J. You; H. -S. Wong; Y. Wang; J. Zhang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Computer and Information Science, University of Macau, Macau, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Electronic and Digital Technology, Ecole Polytechnique de l’Universite de Nantes, Nantes, France; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Cybernetics","7 May 2020","2020","50","6","2872","2885","Clustering ensemble (CE) takes multiple clustering solutions into consideration in order to effectively improve the accuracy and robustness of the final result. To reduce redundancy as well as noise, a CE selection (CES) step is added to further enhance performance. Quality and diversity are two important metrics of CES. However, most of the CES strategies adopt heuristic selection methods or a threshold parameter setting to achieve tradeoff between quality and diversity. In this paper, we propose a transfer CES (TCES) algorithm which makes use of the relationship between quality and diversity in a source dataset, and transfers it into a target dataset based on three objective functions. Furthermore, a multiobjective self-evolutionary process is designed to optimize these three objective functions. Finally, we construct a transfer CE framework (TCE-TCES) based on TCES to obtain better clustering results. The experimental results on 12 transfer clustering tasks obtained from the 20newsgroups dataset show that TCE-TCES can find a better tradeoff between quality and diversity, as well as obtaining more desirable clustering results.","2168-2275","","10.1109/TCYB.2018.2885585","Guangdong Province Higher Vocational Colleges and Schools Pearl River Scholar Funded Scheme 2018; NSFC(grant numbers:61722205,61751205,61751202,61572199,61502174,61872148); Natural Science Foundation of Guangdong Province(grant numbers:2017A030313355); Guangzhou Science and Technology Planning Project(grant numbers:201704030051); Research Grants Council of the Hong Kong(grant numbers:CityU 11300715); Hong Kong General Research(grant numbers:152202/14E); Hong Kong Polytechnic University(grant numbers:G-YM05,G-YN39); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588377","Clustering ensemble selection (CES);machine learning;multiobjective;transfer learning","Clustering algorithms;Partitioning algorithms;Task analysis;Micromechanical devices;Redundancy;Indexes;Cybernetics","learning (artificial intelligence);pattern clustering","transfer CES algorithm;heuristic selection methods;CES strategies;CE selection step;transfer clustering ensemble selection;TCE-TCES;transfer CE framework","","7","","73","IEEE","25 Dec 2018","","","IEEE","IEEE Journals"
"Understanding the Interplay of Model Complexity and Fidelity in Multiagent Systems via an Evolutionary Framework","E. Lakshika; M. Barlow; A. Easton","School of Engineering and IT, University of New South Wales, Canberra, Australia; School of Engineering and IT, University of New South Wales, Canberra, Australia; Simcentric Technologies, Oxford, U.K.","IEEE Transactions on Computational Intelligence and AI in Games","13 Sep 2017","2017","9","3","277","289","Modern video games come with highly realistic graphics enabling the players to interact with visually rich virtual worlds. Realistic (life-like) animation of nonplayer characters (NPCs) in such virtual worlds is particularly important to enhance the gaming experience. Multiagent systems are one effective approach to synthesize life-like behaviors and interactions by codifying simple rules into NPCs (each NPC as an autonomous agent). However, such behaviors generally come at the cost of increasing computational expense and complexity in terms of aspects such as number of rules and parameters. Therefore, the desire for high fidelity (highly realistic) behaviors is often in conflict with the drive for low complexity. Multiobjective evolutionary algorithms provide a sophisticated mechanism to optimize two or more conflicting objectives simultaneously. However, evolutionary computing techniques need an appropriate objective function to drive the exploration in the correct direction. Pairing of evolutionary techniques and multiagent systems is challenging in the classes of problems in which the fitness is evaluated based on human aesthetic judgment rather than on objective forms of measurements. In this study, we present a multiobjective evolutionary framework to evolve low complexity and high fidelity multiagent systems by utilizing a machine learning system trained by bootstrapping human aesthetic judgment. We have gathered empirical data in three problem areas-simulation of conversational group dynamics, sheepdog herding behaviors, and traffic dynamics, and show the effectiveness of our approach in deriving low complexity and high fidelity multiagent systems. Further, we have identified common properties of the Pareto-optimal frontiers in the three problem areas that can ultimately lead to an understanding of a relationship between simulation model complexity and behavior fidelity. This understanding will be useful in deciding which level of behavioral fidelity is required for the characters in video games based on the distance to the camera, importance to the scene, and available computational resources.","1943-0698","","10.1109/TCIAIG.2016.2560882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463035","Complexity;fidelity;level of detail artificial intelligence (LOD AI);multiagent systems;multiobjective optimization","Complexity theory;Multi-agent systems;Optimization;Evolutionary computation;Computational modeling;Learning systems;Games","computational complexity;computer animation;computer games;evolutionary computation;multi-agent systems;Pareto optimisation;statistical analysis;virtual reality","multiobjective evolutionary algorithms;evolutionary computing techniques;multiobjective evolutionary framework;simulation model complexity;behavioral fidelity;virtual worlds;objective function;multiagent systems;video games;nonplayer characters;NPC animation;realistic graphics;human aesthetic judgment bootstrapping;Pareto-optimal frontiers","","10","","36","IEEE","29 Apr 2016","","","IEEE","IEEE Journals"
"Privacy-Preserving Multiobjective Sanitization Model in 6G IoT Environments","J. C. -W. Lin; G. Srivastava; Y. Zhang; Y. Djenouri; M. Aloqaily","School of Information and Control Engineering, Qingdao University of Technology, Qingdao, China; Department of Mathematics and Computer Science, Brandon University, Brandon, MB, Canada; School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen), Shenzhen, China; Department of Mathematics and Cybernetics, SINTEF Digital, Oslo, Norway; Faculty of Engineering, Al Ain University, Al Ain, UAE","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5340","5349","The next revolution of the smart industry relies on the emergence of the Industrial Internet of Things (IoT) and 5G/6G technology. The properties of such sophisticated communication technologies will change our perspective of information and communication by enabling seamless connectivity and bring closer entities, data, and “things.” Terahertz-based 6G networks promise the best speed and reliability, but they will face new man-in-the-middle attacks. In such critical and high-sensitive environments, the security of data and privacy of information still a big challenge. Without privacy-preserving considerations, the configuration state may be attacked or modified, thus causing security problems and damage to data. In this article, motivated by the need to secure 6G IoT networks, an ant colony optimization (ACO) approach is presented by adopting multiple objectives as well as using transaction deletion to secure confidential and sensitive information. Each ant in the population is represented as a set of possible deletion transactions for hiding sensitive information. We utilize the use of a prelarge concept to assist in the reduction of multiple database scans in the evaluation progress. We then also adopt external solutions to maintain discovered Pareto solutions, thus improving effectiveness to find optimized solutions. Experiments are conducted comparing our methodology to state-of-the-art bioinspired particle swarm optimization (PSO) as well as genetic algorithm (GA). Our strong results clearly show that the designed approach achieves fewer side effects while maintaining low computational cost overall (Chen et al., 2020).","2327-4662","","10.1109/JIOT.2020.3032896","Canadian Network for Research and Innovation in Machining Technology Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2020-05363); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234523","5G/6G;ant colony;decomposition;deep learning;IIoT;object detection;particle swarm optimization (PSO);smart factory","Internet of Things;Optimization;Genetic algorithms;6G mobile communication;Data privacy;Security;Databases","6G mobile communication;ant colony optimisation;data mining;data privacy;database management systems;genetic algorithms;Internet of Things;particle swarm optimisation;security of data","privacy-preserving multiobjective sanitization model;smart industry;sophisticated communication technologies;Terahertz-based 6G networks;reliability;man-in-the-middle attacks;high-sensitive environments;configuration state;security problems;ant colony optimization approach;multiple database;external solutions;Pareto solutions;optimized solutions;deletion transactions;bioinspired particle swarm optimization;6G IoT environments;Industrial Internet of Things;5G-6G technology;security of data;ACO;PSO;genetic algorithm;confidential sensitive information","","43","","27","IEEE","21 Oct 2020","","","IEEE","IEEE Journals"
"Multiobjective Optimization for Stiffness and Position Control in a Soft Robot Arm Module","Y. Ansari; M. Manti; E. Falotico; M. Cianchetti; C. Laschi","Scuola Superiore Sant'Anna, BioRobotics Institute, Pontedera, Italy; Scuola Superiore Sant'Anna, BioRobotics Institute, Pontedera, Italy; Scuola Superiore Sant'Anna, BioRobotics Institute, Pontedera, Italy; Scuola Superiore Sant'Anna, BioRobotics Institute, Pontedera, Italy; Scuola Superiore Sant'Anna, BioRobotics Institute, Pontedera, Italy","IEEE Robotics and Automation Letters","18 Aug 2017","2018","3","1","108","115","The central concept of this letter is to develop an assistive manipulator that can automate the bathing task for elderly citizens. We propose to exploit principles of soft robotic technologies to design and control a compliant system to ensure safe human-robot interaction, a primary requirement for the task. The overall system is intended to be modular with a proximal segment that provides structural integrity to overcome gravitational challenges and a distal segment to perform the main bathing activities. The focus of this letter is on the design and control of the latter module. The design comprises of alternating tendons and pneumatics in a radial arrangement, which enables elongation, contraction, and omnidirectional bending. Additionally, a synergetic coactivation of cables and tendons in a given configuration allows for stiffness modulation, which is necessary to facilitate washing and scrubbing. The novelty of the work is twofold: 1) Three base cases of antagonistic actuation are identified that enable stiffness variation. Each category is then experimentally characterized by the application of an external force that imposes a linear displacement at the tip in both axial and lateral directions. 2) The development of a novel algorithm based on cooperative multiagent reinforcement learning that simultaneously optimizes stiffness and position. The results highlight the effectiveness of the design and control to contribute toward the development of the assistive device.","2377-3766","","10.1109/LRA.2017.2734247","People Programme (Marie Curie Actions) of the European Union's Seventh Framework Programme FP7/2007–2013/ under REA Grant agreement Smart-e(grant numbers:608022); European Commission through the I-SUPPORT project(grant numbers:643666); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7997875","Assistive robotics;machine learning;robot control;soft robotics","Tendons;Manipulators;Actuators;Learning (artificial intelligence);Soft robotics;Force","assisted living;cables (mechanical);elastic constants;geriatrics;human-robot interaction;manipulators;medical robotics;position control","multiobjective optimization;stiffness modulation;position control;soft robot arm module;assistive manipulator;bathing task;elderly citizens;soft robotic technologies;compliant system design;compliant system control;human-robot interaction;synergetic coactivation;cables;tendons;antagonistic actuation;external force;linear displacement;cooperative multiagent reinforcement learning","","45","","30","IEEE","31 Jul 2017","","","IEEE","IEEE Journals"
"A Review and Classification of Multi-Criteria Recommender Systems","S. Gupta; V. Kant","The LNM Institute of Information Technology,Jaipur,India,302031; The LNM Institute of Information Technology,Jaipur,India,302031","2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)","19 Jun 2020","2020","","","1156","1162","Recommender systems (RSs) are personalization tools that gives recommendations for items to users by exploiting various methods. Conventional collaborative filtering (CF) based RSs provide suggestions to users based on overall rating of items which is not an efficient procedure as users in system may have different choices on different criteria. So, multicriteria recommender systems (MCRS) came into existence as an extension of traditional CF based RSs. MCRS recommends items to users based on number of criteria. Recommending products to users from the vast catalog is still a challenge for researchers. This paper presents a review of some significant work in the area of multi-criteria recommender system. After a brief introduction, we present review of existing methods categories according to heuristic and model based approach, and some of the popular approaches are classified into different sets such as recommendation fields, research problem, data mining and machine learning techniques. Insights and possible future work in the area of MCRSs are also discussed.","","978-1-7281-4876-2","10.1109/ICICCS48265.2020.9120983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120983","classification;collaborative filtering;multicriteria ratings;recommender system","Scalability;Current measurement;Collaborative filtering;Process control;Machine learning;Control systems;Data models","collaborative filtering;operations research;pattern classification;recommender systems","collaborative filtering;recommender systems;multicriteria recommender system review;multicriteria recommender system classification","","","","34","","19 Jun 2020","","","IEEE","IEEE Conferences"
"Cognitive Analytics of Social Media Services for Edge Resource Pre-Allocation in Industrial Manufacturing","D. Zhu; Z. Xu; X. Xu; Q. Zhao; L. Qi; G. Srivastava","School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Science and Technology Property Division, Shihezi University, Xinjiang, China; School of Information Science and Engineering, Qufu Normal University, Jining, China; Department of Mathematics and Computer Science, Brandon University, Brandon, MB, Canada","IEEE Transactions on Computational Social Systems","1 Apr 2021","2021","8","2","500","511","With the development of industrial intelligence, the resource requests of various social media services in smart cities are expanding rapidly. For hosting services, the edge computing (EC) platform for its low-latency resource provisioning is fully explored. However, the mapping between edge servers (ESs) and services affects the service latency. Meanwhile, the real-time dynamic distribution of resource requirements also impairs the load balance. Therefore, how to optimize the load balance of ESs while meeting the latency-critical requests remains challenging. To deal with the above challenge, in this article, we propose a resource pre-allocation (RPA) method for the social media services with cognitive analytics. Technically, the deep spatiotemporal residual network (ST-ResNet) is employed to complete the cognitive analytics of resource requests. Then based on the analysis results, the optimal resource allocation (ORA) scheme is designed with multiobjective optimization. Finally, the performance of RPA is evaluated by a real-world resource request data set.","2329-924X","","10.1109/TCSS.2021.3052231","Financial and Science Technology Plan Project of Xinjiang Production and Construction Corps(grant numbers:2020DB005,2017DB005); Scientific Research Projects of Shanghai Municipal Science and Technology Commission(grant numbers:18DZ12000403); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340550","Cognitive analytics;deep learning;multiobjective optimization;optimal resource allocation (ORA);social media","Social networking (online);Industrial Internet of Things;Industries;Resource management;Deep learning;Delays;Residual neural networks","distributed processing;manufacturing data processing;optimisation;production engineering computing;resource allocation;social networking (online)","resource requirements;resource provisioning;edge computing platform;hosting services;industrial intelligence;industrial manufacturing;edge resource pre-allocation;real-world resource request data;optimal resource allocation scheme;resource requests;cognitive analytics;social media services;resource pre-allocation method;latency-critical requests;load balance","","1","","30","IEEE","29 Jan 2021","","","IEEE","IEEE Journals"
"DCBRTS: A Classification-Summarization Approach for Evolving Tweet Streams in Multiobjective Optimization Framework","D. Bansal; N. Saini; S. Saha","Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, India; AI and Big Data Department, Endicott College of International Studies, Woosong University, Daejeon, South Korea; Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, India","IEEE Access","9 Nov 2021","2021","9","","148325","148338","The emergence of social media platforms like Twitter has become a prominent communication source in disaster outbreak. NGOs, Government agencies leverage twitter’s open and public features to provide immediate relief. Nevertheless, situational information gets immersed in millions of tweets with varying characteristics. Examining each tweet can be cumbersome and time-consuming. Thus, the efficient extraction of disaster-related situational tweets and getting information from all the extracted tweets is required. In the current paper, we have developed a novel framework that uses a deep learning-based classification model to separate the situational tweets from others and summarize them in real-time. Our system is a three-phase process: (a) Creating tweet clusters using a representative set of tweets from the initial set of extracted tweets using a multi-objective optimization concept; (b) When a new tweet arrives, the clusters are updated. The new tweet is classified as situational vs. non-situational. If situational, it is assigned to the closest cluster or new cluster. This assignment is based on its weighted average of syntactic and semantic distances and relevancy to the cluster; (c) Summary is formulated by extracting tweets from each cluster. The proposed approach’s superior performance on four datasets related to different disaster-related events indicates the developed framework’s efficiency over the state-of-the-art techniques.","2169-3536","","10.1109/ACCESS.2021.3120112","Woosong University Academic Research, in 2021; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9570355","Evolving tweet-stream;summarization;classification;convolution neural network;clustering;multi-objective optimization","Real-time systems;Feature extraction;Blogs;Social networking (online);Semantics;Optimization;Syntactics","disasters;learning (artificial intelligence);optimisation;social networking (online)","classification-summarization approach;evolving tweet streams;multiobjective optimization framework;situational information;disaster-related situational tweets;extracted tweets;deep learning-based classification model;tweet clusters;DCBRTS;social media platforms;Twitter;situational tweets","","","","34","CCBY","14 Oct 2021","","","IEEE","IEEE Journals"
"Pareto-Path Multitask Multiple Kernel Learning","C. Li; M. Georgiopoulos; G. C. Anagnostopoulos","Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, Florida Institute of Technology, Melbourne, FL, USA","IEEE Transactions on Neural Networks and Learning Systems","20 May 2017","2015","26","1","51","61","A traditional and intuitively appealing Multitask Multiple Kernel Learning (MT-MKL) method is to optimize the sum (thus, the average) of objective functions with (partially) shared kernel function, which allows information sharing among the tasks. We point out that the obtained solution corresponds to a single point on the Pareto Front (PF) of a multiobjective optimization problem, which considers the concurrent optimization of all task objectives involved in the Multitask Learning (MTL) problem. Motivated by this last observation and arguing that the former approach is heuristic, we propose a novel support vector machine MT-MKL framework that considers an implicitly defined set of conic combinations of task objectives. We show that solving our framework produces solutions along a path on the aforementioned PF and that it subsumes the optimization of the average of objective functions as a special case. Using the algorithms we derived, we demonstrate through a series of experimental results that the framework is capable of achieving a better classification performance, when compared with other similar MTL approaches.","2162-2388","","10.1109/TNNLS.2014.2309939","National Science Foundation(grant numbers:0806931,0963146); National Science Foundation(grant numbers:0963146,1200566,1161228); National Science Foundation(grant numbers:0647018,1263011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775340","Machine learning;optimization methods;pattern recognition;supervised learning;support vector machines (SVM).;Machine learning;optimization methods;pattern recognition;supervised learning;support vector machines (SVM)","Kernel;Support vector machines;Linear programming;Vectors;Optimization;Minimization;Information management","learning (artificial intelligence);Pareto optimisation;pattern classification;support vector machines","Pareto-path multitask multiple kernel learning;MT-MKL method;partially shared kernel function;information sharing;Pareto front;PF;multiobjective optimization problem;concurrent optimization;MTL problem;support vector machine MT-MKL framework","","14","","36","IEEE","19 Mar 2014","","","IEEE","IEEE Journals"
"Investigating The Influential Factors On Firefighter Injuries Using Statistical Machine Learning","Z. Yang; Y. Liu","School of Information Technology, York University, Toronto, Ontario, M3J 1P3, Canada; Department of Mathematics and Statistics, York University, Toronto, Ontario, M3J 1P3, Canada","2018 International Conference on Machine Learning and Cybernetics (ICMLC)","11 Nov 2018","2018","2","","422","427","Firefighters are the most important resources in protecting the public and responding to emergencies. Canada's first-ever national fire information database (NFID) was implemented in 2017, which enables effective big data analytics to investigate fire and firefighter related issues. This paper proposes principal component analysis and deep neural networks to investigate the influential factors that affect firefighter injuries. The methods have been validated using the data available in NFID. The results are valuable in supporting multicriteria decision making and decision support systems.","2160-1348","978-1-5386-5214-5","10.1109/ICMLC.2018.8527021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8527021","Statistical machine learning;Big data analytics;Ensemble method;Principal component analysis;Deep neural networks;Multicriteria decision making;Decision support systems","Injuries;Fires;Principal component analysis;Eigenvalues and eigenfunctions;Biological neural networks;Machine learning;Meteorology","Big Data;emergency services;fires;injuries;learning (artificial intelligence);neural nets;principal component analysis","principal component analysis;deep neural networks;firefighter injuries;NFID;statistical machine learning;national fire information database;big data analytics;Canada;multicriteria decision making;decision support system","","","","14","","11 Nov 2018","","","IEEE","IEEE Conferences"
"Evolving Diverse Ensembles Using Genetic Programming for Classification With Unbalanced Data","U. Bhowan; M. Johnston; M. Zhang; X. Yao","Victoria University of Wellington, Wellington, New Zealand; Victoria University of Wellington, Wellington, New Zealand; Victoria University of Wellington, Wellington, New Zealand; Center of Excellence for Research in Computational Intelligence and Applications, School of Computer Science, University of Birmingham, Birmingham, U.K.","IEEE Transactions on Evolutionary Computation","24 May 2013","2013","17","3","368","386","In classification, machine learning algorithms can suffer a performance bias when data sets are unbalanced. Data sets are unbalanced when at least one class is represented by only a small number of training examples (called the minority class), while the other class(es) make up the majority. In this scenario, classifiers can have good accuracy on the majority class, but very poor accuracy on the minority class(es). This paper proposes a multiobjective genetic programming (MOGP) approach to evolving accurate and diverse ensembles of genetic program classifiers with good performance on both the minority and majority of classes. The evolved ensembles comprise of nondominated solutions in the population where individual members vote on class membership. This paper evaluates the effectiveness of two popular Pareto-based fitness strategies in the MOGP algorithm (SPEA2 and NSGAII), and investigates techniques to encourage diversity between solutions in the evolved ensembles. Experimental results on six (binary) class imbalance problems show that the evolved ensembles outperform their individual members, as well as single-predictor methods such as canonical GP, naive Bayes, and support vector machines, on highly unbalanced tasks. This highlights the importance of developing an effective fitness evaluation strategy in the underlying MOGP algorithm to evolve good ensemble members.","1941-0026","","10.1109/TEVC.2012.2199119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6198882","Classification;class imbalance learning;genetic programming (GP);multiobjective machine learning (ML)","Accuracy;Training;Bagging;Silicon;Boosting;Optimization;Benchmark testing","Bayes methods;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification;support vector machines","diverse ensembles evolution;unbalanced data classification;machine learning algorithms;minority classes;multiobjective genetic programming approach;MOGP;genetic program classifiers;Pareto-based fitness strategies;class imbalance problems;single-predictor methods;canonical GP;naive Bayes;support vector machines","","140","","52","","11 May 2012","","","IEEE","IEEE Journals"
"A multi-objective competitive co-evolutionary approach for classification problems","V. T. VU; L. T. BUI; T. T. NGUYEN","Le Quy Don Technical University,Ha Noi,VietNam; Le Quy Don Technical University,Ha Noi,VietNam; Liverpool John Moores University,Liverpool,United Kingdom","2019 6th NAFOSTED Conference on Information and Computer Science (NICS)","5 Mar 2020","2019","","","49","54","This paper proposes a multi-objective competitive co-evolutionary algorithm (MOCPCEA) based on the PreyPredator model to solve classification problems. In the MOCPCEA, a data population acts as preys. To be specific, each prey represents a selected subset of the training dataset. Another population is ANN classifiers which play as Predators. The task of the Predators is to try to classify the data sets as correctly as possible, whereas the Preys try to find the data sets that are difficult to be classified. Through this interaction process, MOCPCEA generates a set of classifiers that are able to classify difficult data sets. The final classification result is given by the ensemble voting mechanism among these sets of classifiers. The performance of the proposed algorithm is performed on seven benchmark problems. Through comparison with other algorithms, the proposed algorithm indicates that it could create an ensemble of ANN networks that give high and stable classification results.","","978-1-7281-5163-2","10.1109/NICS48868.2019.9023887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023887","competitive co-evolutionary;Prey-Predator;multiobjective optimization;classification;ensemble learning.","","evolutionary computation;neural nets;pattern classification;predator-prey systems;set theory","stable classification;classification problems;co-evolutionary algorithm;MOCPCEA;PreyPredator model;data population;prey;selected subset;training dataset;ANN classifiers;ANN networks;multi-objective competitive co-evolutionary approach","","","","18","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Optimal Energy Operation Strategy for We-Energy of Energy Internet Based on Hybrid Reinforcement Learning With Human-in-the-Loop","L. Yang; Q. Sun; N. Zhang; Z. Liu","College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","16 Dec 2021","2022","52","1","32","42","This article investigates the energy operation problem based on We-Energy (WE), a novel full-duplex model in Energy Internet (EI). A dual-objective optimal energy operation model of WE is formulated with the consideration of economical benefit and security operation under different time scenarios. Due to the inaccurate model of distributed generation devices and loads, a multipolicy convex hull reinforcement learning (MCRL) algorithm is proposed. It can find the multiobjective strategy set with model-free feature. Moreover, considering the limitations of artificial intelligence technology and the human advantages in information processing for complex task, a two-channel Human-in-the-loop (HITL) method is designed to combine with MCRL to avoid decision-making risks. The one channel of HITL can evaluate the operation strategy by human under normal conditions so that the understanding of human for complex operating conditions can be incorporated into the machine learning algorithms to improve the confidence of intelligent systems. The other channel of HITL can allow human to participate in real-time adjustment under abnormal conditions to avoid system out of control. Simulation studies of modified EI are confirmed that the proposed algorithm can improve system performance effectively.","2168-2232","","10.1109/TSMC.2020.3035406","National Key Research and Development Program of China(grant numbers:2018YFA0702200); National Natural Science Foundation of China(grant numbers:62073065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274496","Human-in-the-loop (HITL);multiobjective optimization model;multipolicy convex hull reinforcement learning (MCRL);optimal energy operation;We-Energy (WE)","Load modeling;Security;Collaboration;Economics;Decision making;Natural gas;Internet","artificial intelligence;convex programming;distributed power generation;learning (artificial intelligence);optimisation;power generation economics","full-duplex model;dual-objective optimal energy operation model;economical benefit;security operation;distributed generation devices;multipolicy convex hull reinforcement learning algorithm;artificial intelligence technology;energy internet;two-channel human-in-the-loop;MCRL algorithm;machine learning algorithm","","","","31","IEEE","1 Dec 2020","","","IEEE","IEEE Journals"
"A Hierarchical Self-Adaptive Data-Analytics Method for Real-Time Power System Short-Term Voltage Stability Assessment","Y. Zhang; Y. Xu; Z. Y. Dong; R. Zhang","School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, NSW, Australia; School of Electrical and Information Engineering, University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Industrial Informatics","4 Jan 2019","2019","15","1","74","84","As one of the most complex and largest dynamic industrial systems, a modern power grid envisages the wide-area measurement protection and control (WAMPAC) system as the grid sensing backbone to enhance security, reliability, and resiliency. However, based on the massive wide-area measurement data, how to realize real-time short-term voltage stability (STVS) assessment is an essential yet challenging problem. This paper proposes a hierarchical and self-adaptive data-analytics method for real-time STVS assessment covering both the voltage instability and the fault-induced delayed voltage recovery phenomenon. Based on a strategically designed ensemble-based randomized learning model, the STVS assessment is achieved sequentially and self-adaptively. Besides, the assessment accuracy and the earliness are simultaneously optimized through the multiobjective programming. The proposed method has been tested on a benchmark power system, and its exceptional assessment accuracy, speed, and comprehensiveness are demonstrated by comparing with existing methods.","1941-0050","","10.1109/TII.2018.2829818","ARC Discovery(grant numbers:DP170103427); Singapore Ministry of Education; National Natural Science Foundation of China(grant numbers:51777173); Research Training Program from Australian government; Nanyang Technological University(grant numbers:TII-17-0906); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345652","Data-analytics;ensemble learning;extreme learning machine;multiobjective programming;short-term voltage stability (STVS);smart grid","Power system stability;Real-time systems;Indexes;Stability criteria;Voltage control;Power system dynamics","data analysis;evolutionary computation;learning (artificial intelligence);optimisation;power engineering computing;power grids;power system measurement;power system stability","multiobjective programming;ensemble-based randomized learning model;WAMPAC system;wide-area measurement protection and control system;exceptional assessment accuracy;benchmark power system;voltage recovery phenomenon;voltage instability;real-time STVS assessment;essential yet challenging problem;massive wide-area measurement data;grid sensing backbone;modern power grid;largest dynamic industrial systems;complex systems;real-time power system short-term voltage stability assessment;hierarchical self-adaptive data-analytics method","","56","","39","IEEE","24 Apr 2018","","","IEEE","IEEE Journals"
"Learning of a Decision-Maker’s Preference Zone With an Evolutionary Approach","M. Aggarwal","Indian Institute of Management Ahmedabad, Ahmedabad, India","IEEE Transactions on Neural Networks and Learning Systems","20 Feb 2019","2019","30","3","670","682","A new evolutionary-learning algorithm is proposed to learn a decision maker (DM)'s best solution on a conflicting multiobjective space. Given the exemplary pairwise comparisons of solutions by a DM, we learn an ideal point (for the DM) that is used to evolve toward a better set of solutions. The process is repeated to get the DM's best solution. The comparison of solutions in pairs facilitates the process of eliciting training information for the proposed learning model. Experimental study on standard multiobjective data sets shows that the proposed method accurately identifies a DM's preferred zone in relatively a few generations and with a small number of preferences. Besides, it is found to be robust to inconsistencies in the preference statements. The results obtained are validated through a variant of the established NSGA-2 algorithm.","2162-2388","","10.1109/TNNLS.2018.2847412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418833","Evolutionary;machine learning;multicriteria decision making;preference information;utility preference","Sociology;Statistics;Optimization;Approximation algorithms;Evolutionary computation;Predictive models;Learning systems","decision making;evolutionary computation;genetic algorithms;learning (artificial intelligence)","conflicting multiobjective space;learning model;preference statements;evolutionary approach;evolutionary-learning algorithm;decision-making;DM preferred zone;standard multiobjective data sets","","4","","48","IEEE","24 Jul 2018","","","IEEE","IEEE Journals"
"The <formula formulatype=""inline""><tex Notation=""TeX"">$Q$</tex> </formula>-Norm Complexity Measure and the Minimum Gradient Method: A Novel Approach to the Machine Learning Structural Risk Minimization Problem","D. A. G. Vieira; R. H. C. Takahashi; V. Palade; J. A. Vasconcelos; W. M. Caminhas","Dept. of Electr. Eng., Fed. Univ. of Minas Gerais, Belo Horizonte; NA; NA; NA; NA","IEEE Transactions on Neural Networks","5 Aug 2008","2008","19","8","1415","1430","This paper presents a novel approach for dealing with the structural risk minimization (SRM) applied to a general setting of the machine learning problem. The formulation is based on the fundamental concept that supervised learning is a bi-objective optimization problem in which two conflicting objectives should be minimized. The objectives are related to the empirical training error and the machine complexity. In this paper, one general Q-norm method to compute the machine complexity is presented, and, as a particular practical case, the minimum gradient method (MGM) is derived relying on the definition of the fat-shattering dimension. A practical mechanism for parallel layer perceptron (PLP) network training, involving only quasi-convex functions, is generated using the aforementioned definitions. Experimental results on 15 different benchmarks are presented, which show the potential of the proposed ideas.","1941-0093","","10.1109/TNN.2008.2000442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4560237","Complexity measure;multiobjective training algorithms;neural networks;parallel layer perceptron (PLP);regularization methods;structural risk minimization (SRM)","Machine learning;Risk management;Gradient methods;Neural networks;Support vector machines;Virtual colonoscopy;Sliding mode control;Supervised learning;Machine learning algorithms;Mathematics","gradient methods;learning (artificial intelligence);multilayer perceptrons;optimisation","Q-norm complexity measure;minimum gradient method;machine learning;structural risk minimization problem;biobjective optimization problem;machine complexity;parallel layer perceptron;quasiconvex functions","Algorithms;Artificial Intelligence;Computer Simulation;Models, Theoretical;Neural Networks (Computer);Pattern Recognition, Automated","26","","68","","15 Jul 2008","","","IEEE","IEEE Journals"
"Multi-Query Video Retrieval Based on Deep Learning and Pareto Optimality","C. Vural; E. Akbacak","Elektrik-Elektronik Mühendisliği, Marmara Üniversitesi,İstanbul,Türkiye; Elektrik-Elektronik Mühendisliği, Marmara Üniversitesi,İstanbul,Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","Existing video retrieval studies support single query. To the best of our knowledge, there is no multi-query video retrieval method. In this study, an efficient and fast multi-query video retrieval method is proposed for queries having different semantics. The metod supports unlimited number of queries. Real valued features representing a video are extracted by a deep network and are converted into binary codes. Database items that simultaneously most closely resemble multiple queries are retrieved by Pareto front method. Efficiency of the method is determined by means of a designed graphical user interface.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302123","Hash codes;Pareto optimization;multi-query video retrieval","Matlab;Feature extraction;Sorting;Semantics;Pareto optimization;Optimization;Information systems","binary codes;deep learning (artificial intelligence);feature extraction;graphical user interfaces;query processing;video retrieval","multiquery video retrieval;single query;multiple queries;Pareto optimality;deep learning;deep network;binary codes;database items;Pareto front method;graphical user interface","","","","","","7 Jan 2021","","","IEEE","IEEE Conferences"
"Multi-Query Image Retrieval Based on Deep Learning and Pareto Optimality","C. Vural; E. Akbacak","Marmara Üniversitesi,Elektrik-Elektronik Mühendisliği,İstanbul,Türkiye; Marmara Üniversitesi,Elektrik-Elektronik Mühendisliği,İstanbul,Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","In this study, a method for fast and efficient multiquery image retrieval from large scale databases is introduced. Images used as queries are semantically different from each other. In order to obtain similarity between multiple queries and each item in the database, image features are extracted from a deep networks and then they are converted into binary codes. The database items that simultaneously most closely resemble multiple queries are obtained by the Pareto front method. Furthermore, the method is tested on a designed graphical user interface.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302140","Hash codes;Pareto optimization;multi-query image retrieval","Image retrieval;Databases;Matlab;Feature extraction;Sorting;Pareto optimization;Optimization","binary codes;deep learning (artificial intelligence);graphical user interfaces;image retrieval;Pareto optimisation","multiquery image retrieval;large scale databases;image feature extraction;deep networks;database items;Pareto front method;Pareto optimality;graphical user interface;binary codes;deep learning","","","","","","7 Jan 2021","","","IEEE","IEEE Conferences"
"Automated Deep Neural Learning-Based Optimization for High Performance High Power Amplifier Designs","L. Kouhalvandi; O. Ceylan; S. Ozoguz","Department of Electronics and Communication Engineering, Istanbul Technical University, Istanbul, Turkey; Maury Microwave, Ontario, CA, USA; Department of Electronics and Communication Engineering, Istanbul Technical University, Istanbul, Turkey","IEEE Transactions on Circuits and Systems I: Regular Papers","1 Dec 2020","2020","67","12","4420","4433","This study presents an automated optimization-oriented strategy for designing high power amplifiers (HPAs) using deep neural networks (DNNs). The proposed strategy consists of two optimization phases that are applied sequentially. In the first phase, the circuit topology is optimized by determining the number of passive components in the input and output matching networks using deep learning classification network. In the second optimization phase, component values are estimated using a deep learning regression network with electromagnetic-based Thompson Sampling Efficient Multiobjective Optimization (TSEMO). The proposed approach is compact, in the sense that the optimum solution is automatically generated by the process, opposite to the conventional approaches where manual post-processing is required to prune the process outcomes. It addresses the problem of heavy reliance of the system performance on the designer's experience and automatically generates valid layouts. In the demanding HPA design problem, uses of DNNs have been shown to provide much more accuracy than conventional shallow neural networks. The effectiveness of the proposed method is verified by implementing two designed HPAs, including GaN HEMTs. The efficiency-oriented optimized amplifier reveals higher than 60% drain efficiency, and the gain-oriented optimized amplifier has 17.6-18 dB linear gain in the frequency band of 1.8-2.2 GHz.","1558-0806","","10.1109/TCSI.2020.3008947","Istanbul Technical University the Scientific Research Projects Unit(grant numbers:MDK-2019-41968); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144294","Automated design;deep neural network (DNN);high efficiency;high gain;multiobjective optimization;power amplifiers","Optimization;Integrated circuit modeling;Manganese;Topology;Radio frequency;Gain;Transistors","electronic engineering computing;gallium compounds;high electron mobility transistors;III-V semiconductors;learning (artificial intelligence);network topology;neural nets;optimisation;pattern classification;power amplifiers;regression analysis","GaN HEMTs;TSEMO;input matching networks;circuit topology;automated deep neural learning-based optimization;HPA design;electromagnetic-based Thompson sampling efficient multiobjective optimization;gain-oriented optimized amplifier;efficiency-oriented optimized amplifier;system performance;deep learning regression network;component values;deep learning classification network;output matching networks;passive components;DNNs;deep neural networks;automated optimization-oriented strategy;high performance high power amplifier designs;noise figure 17.6 dB to 18.0 dB;frequency 1.8 GHz to 2.2 GHz","","9","","34","IEEE","20 Jul 2020","","","IEEE","IEEE Journals"
"Pareto-based Multi-Objective Machine Learning","Y. Jin","Honda Research Institute Europe, Germany","7th International Conference on Hybrid Intelligent Systems (HIS 2007)","15 Oct 2007","2007","","","2","2","Machine learning is inherently a multi-objective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multi-objective optimization methodology have gained increasing impetus, particularly thanks to the great success of multi-objective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multi-objective learning approaches are more powerful compared to learning algorithms with a scalar cost functions in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. This talk provides first a brief overview of Pareto-based multi-objective machine learning techniques. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multi-objective ensemble generation are compared and discussed in detail. Most recent results on multi-objective optimization of spiking neural networks will be presented.","","978-0-7695-2946-2","10.1109/HIS.2007.73","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344015","","Machine learning;Cost function;Machine learning algorithms;Hybrid intelligent systems;Europe;Evolutionary computation;Stochastic processes;Search methods;Clustering algorithms;Power generation","evolutionary computation;learning (artificial intelligence);neural nets;Pareto optimisation;search problems;stochastic processes","Pareto-based multi-objective machine learning;scalar cost function;Pareto-based multi-objective optimization methodology;evolutionary algorithms;population-based stochastic search methods;feature selection;knowledge extraction;ensemble generation;Pareto-based multi-objective ensemble generation;spiking neural networks","","2","","","","15 Oct 2007","","","IEEE","IEEE Conferences"
"Intelligent Early Warning of Power System Dynamic Insecurity Risk: Toward Optimal Accuracy-Earliness Tradeoff","Y. Zhang; Y. Xu; Z. Y. Dong; Z. Xu; K. P. Wong","School of Electrical and Information Engineering, University of Sydney, Sydney, N.S.W., Australia; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Information Engineering, University of Sydney, China Southern Power Grid Research Institute, Sydney, Guangzhou, N.S.W., AustraliaChina; Department of Electrical Engineering, The Hong Kong Polytechnic University, Kowloon, Hong Kong; School of Electrical, Electronic and Computer Engineering, The University of Western Australia, Perth, W.A., Australia","IEEE Transactions on Industrial Informatics","5 Oct 2017","2017","13","5","2544","2554","Dynamic insecurity risk of a power system has been increasingly concerned due to the integration of stochastic renewable power sources (such as wind and solar power) and complicated demand response. In this paper, an intelligent early-warning system to achieve reliable online detection of risky operating conditions is proposed. The proposed intelligent system (IS) consists of an ensemble learning model based on extreme learning machine (ELM) and a decision-making process under a multiobjective programming framework. Taking an ensemble form, the randomness existing in individual ELM training is generalized and reliable classification results can be obtained. The decision making is designed for ELM ensemble whose parameters are optimized to search for the optimal tradeoff between the warning accuracy and the warning earliness of the proposed IS. The compromise solution turns out to significantly speed up the overall computation with an acceptable sacrifice in the accuracy (e.g., from 100% to 99.9%). More importantly, the proposed IS can provide multiple and switchable performances to the operators in order to satisfy different local dynamic security assessment requirements.","1941-0050","","10.1109/TII.2017.2676879","China Southern Power Grid Company(grant numbers:WYKJ00000027); Faculty of Engineering and Information Technologies, University of Sydney, under the Faculty Research Cluster Program; Australian Postgraduate Award; Nanyang Assistant Professorship from Nanyang Technological University, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869388","Dynamic insecurity risk;early warning;extreme learning machine (ELM);intelligent system (IS);multiobjective programming (MOP)","Training;Computational modeling;Power system dynamics;Reliability;Databases;Electronic mail;Power system stability","alarm systems;decision making;learning (artificial intelligence);optimisation;power system faults;power system security;reliability;risk management","extreme learning machine;decision-making process;multiobjective programming framework;individual ELM training;power system dynamic insecurity risk;intelligent early-warning system;ensemble learning model;local dynamic security assessment","","58","","40","IEEE","2 Mar 2017","","","IEEE","IEEE Journals"
"Enhancing utility and privacy with noisy minimax filters","J. Hamm","The Ohio State University, Department of Computer Science and Engineering, Columbus, 43210, USA","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","6389","6393","Preserving privacy of continuous and/or high-dimensional data such as images, videos and audios is challenging. Syntactic anonymization methods were proposed typically for discrete data types and can be unsuitable. Differential privacy, which provides a stricter type of privacy, has shown more success in sanitizing continuous data. However, both syntactic and differential privacy are susceptible to inference attacks, i.e., an adversary can accurately guess sensitive attributes from insensitive attributes. On the other hand, minimax filters were proposed previously to minimize the accuracy of inference while maximizing utility at the same time. The paper presents noisy minimax filter that combines minimax filter and differentially private mechanism, which can attain high average utility and protection against inference attacks and a formal worst-case privacy guarantee. The proposed algorithm is demonstrated with real databases of faces, voices, and motion data.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953386","syntactic anonymity;differential privacy;minimax optimization;postprocessing;machine learning","Privacy;Information filters;Data privacy;Filtering algorithms;Nonlinear filters;Databases","data privacy;minimax techniques","syntactic anonymization methods;discrete data types;differential privacy;syntactic privacy;minimax filters;attacks","","8","","16","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Pareto-optimality is everywhere: From engineering design, machine learning, to biological systems","Yaochu Jin",NA,"2008 3rd International Workshop on Genetic and Evolving Systems","11 Apr 2008","2008","","","1","1","This talk attempts to argue that almost all adaptive systems have multiple objectives to achieve. Very often, there is no single solution that can optimize all objectives, in which case, the concept of Pareto-optimization plays an important rule. Examples will be given ranging from engineering design, machine learning, to biological systems to show how Pareto-optimality can make a difference in analyzing these systems. The first example we will discuss is the aerodynamic design optimization of turbine blades, where energy efficiency in terms of pressure loss as well as the variation of pressure distribution must be minimized. One additional difficulty in aerodynamic design optimization is that the quality of candidate designs must be assessed by performing computational fluid dynamics analysis, which is very time consuming. To reduce computation time, computational techniques like parallel computation, and machine learning techniques, such as meta-modeling can be employed. Surprisingly interesting results will also be achieved when the concept of Pareto-optimality is applied to machine learning. Two cases will be provided to illustrate this idea. In the first case, we show how Pareto-based approach can address neural network regularization more elegantly, through which deeper insights into the problem can be gained. In the second case, we show that analysis of the Pareto-optimal solutions will help determine the optimal number of clusters in data clustering, which again shown how the Pareto front can disclose additional knowledge about the problem at hand. The final example is concerned with tradeoffs in simulated evolution of genetic representation. It has been argued that robustness is critical for biological evolution, because without certain degree of robustness to mutations, it is impossible for evolution to create new functionalities. Therefore, evolution must find representations that are sufficiently robust yet have the potential to innovate. Examples will be given to show that such tradeoff does exist in evolving both a stationary genotype-phenotype mapping, and also a gene regulatory network described by a random Boolean network.","","978-1-4244-1612-7","10.1109/GEFS.2008.4484555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4484555","","Design engineering;Machine learning;Biological systems;Evolution (biology);Concurrent computing;Robustness;Pareto analysis;Aerodynamics;Design optimization;Adaptive systems","adaptive systems;Pareto optimisation","Pareto-optimality;engineering design;machine learning;biological systems;adaptive systems;aerodynamic design optimization;turbine blades;computational fluid dynamics analysis;data clustering;genetic representation;genotype-phenotype mapping","","2","","","","11 Apr 2008","","","IEEE","IEEE Conferences"
"Resource-Aware Pareto-Optimal Automated Machine Learning Platform","Y. Yang; A. Nam; M. Nasr-Azadani; T. Tung","Accenture Tech Labs,San Francisco,USA; Accenture Tech Labs,San Francisco,USA; Accenture Tech Labs,San Francisco,USA; Accenture Tech Labs,San Francisco,USA","2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)","13 Jan 2021","2020","","","1","6","In this study, we introduce a novel platform Resource-Aware AutoML (RA-AutoML) which enables flexible and generalized algorithms to build machine learning models subjected to multiple objectives, as well as resource and hardware constraints. RA-AutoML intelligently conducts Hyper-Parameter Search (HPS) as well as Neural Architecture Search (NAS) to build models optimizing predefined objectives. RA-AutoML is a versatile framework that allows user to prescribe many resource/hardware constraints along with objectives demanded by the problem or even business requirements. At its core, RA-AutoML relies on our in-house search-engine algorithm, MOBOGA, which combines a modified constraint-aware Bayesian Osptimization and Genetic Algorithm to construct Pareto optimal candidates. Our experiments on CIFAR-10 dataset shows very good accuracy compared to results obtained by state-of-art neural network models, while subjected to resource constraints in the form of model size.","","978-1-7281-8406-7","10.1109/ISRITI51436.2020.9315336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315336","Automatic Machine Learning;Resource-aware optimization;Hardware-aware Machine;Learning Resource constraints;Bayesian optimization;Pareto optimal;Constraint-aware AutoML Platform","Search problems;Optimization;Bayes methods;Task analysis;Machine learning;Hardware;Computational modeling","genetic algorithms;learning (artificial intelligence);neural nets;Pareto optimisation","flexible algorithms;generalized algorithms;machine learning models;RA-AutoML;predefined objectives;in-house search-engine algorithm;modified constraint-aware Bayesian Osptimization;Pareto optimal candidates;state-of-art neural network models;resource-aware Pareto-optimal automated machine;platform resource-aware AutoML","","","","29","","13 Jan 2021","","","IEEE","IEEE Conferences"
"Decision Variable Learning","M. Santos; J. Alves de Oliveira; A. Britto","Comput. Dept., Fed. Univ. of Sergipe, Sao Cristovao, Brazil; Federal University of Sergipe; Federal University of Sergipe","2019 8th Brazilian Conference on Intelligent Systems (BRACIS)","5 Dec 2019","2019","","","497","502","Many alternatives to traditional Multi-Objective Optimization Algorithms are emerging due to the increasing number of Multi-Objective Problems with a high degree of complexity, such as Many-Objective Problems. Among these alternatives, the methods known as surrogate stand out. These methods seek to construct new models for the objective functions based on the data obtained previously from the actual objective functions. The input of these models are a set of vectors in decision variable space and the output are the values of the objective functions. In this work, the Decision Variable Learning (DVL) algorithm is proposed, which presents an inverse idea to traditional surrogates. In the DVL, machine learning models will be used to learn the behavior of the decision variables in Many-Objective Optimization Problems. In this context, we have enough information to learn from the objective vectors, to predict near optimal solution in decision variable space. DVL algorithm will be evaluated using benchmark problems and its results will be compared with the NSGA-III algorithm.","2643-6264","978-1-7281-4253-1","10.1109/BRACIS.2019.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923866","multiobjective-optimization, machine-learning, complex-problems","Linear programming;Optimization;Machine learning;Machine learning algorithms;Prediction algorithms;Evolutionary computation;Sociology","evolutionary computation;genetic algorithms;learning (artificial intelligence);Pareto optimisation","multiobjective optimization algorithms;surrogate stand;decision variable space;machine learning models;decision variables;many-objective optimization problems;objective vectors;DVL algorithm;NSGA-III algorithm;decision variable learning algorithm","","","","11","","5 Dec 2019","","","IEEE","IEEE Conferences"
"RSSM-Net: Remote Sensing Image Scene Classification Based on Multi-Objective Neural Architecture Search","Y. Wan; Y. Zhong; A. Ma; J. Wang; R. Feng","State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University,Wuhan,China,430079; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University,Wuhan,China,430079; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University,Wuhan,China,430079; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University,Wuhan,China,430079; School of Computer Science, China University of Geosciences,Wuhan,China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1369","1372","The deep learning (DL)-based scene classification methods have been obtained the remarkable attention for the high spatial resolution remote sensing (HRS) imagery. However, from one aspect, the existing DL methods in HRS image scene classification are usually the variations of the natural image processing methods and often the inherent network structures; from another aspect, the strenuous and significant efforts have been devoted to the design of relevant network structures by human experts. In this paper, learning from the natural evolution, the deep neural network is expected to be globally evolved by the machine for automatically adapting the structure of the HRS imagery, a multi-objective neural architecture search based HRS image scene classification method is proposed (RSSM-Net). The two objectives of minimizing a classification error and the computational complexity have been simultaneously optimized through the evolutionary multi-objective method, the competitive neural architectures in a Pareto solution set are then obtained. The effectiveness is proved by the experiment of the UC Merced dataset with several networks designed by human experts.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323429","National Key Research and Development Program of China(grant numbers:2017YFB0504202); National Natural Science Foundation of China(grant numbers:41801267); China Postdoctoral Science Foundation(grant numbers:2017M622522); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323429","Remote sensing;scene classification;neural architecture search;evolutionary algorithm;multiobjective optimization","Image analysis;Neural networks;Feature extraction;Remote sensing;Statistics;Sociology;Search problems","evolutionary computation;geophysical image processing;image classification;learning (artificial intelligence);neural nets;optimisation;Pareto optimisation;remote sensing","remarkable attention;deep learning-based scene classification methods;competitive neural architectures;evolutionary multiobjective method;classification error;RSSM-Net;HRS image scene classification method;multiobjective neural architecture search;HRS imagery;deep neural network;natural evolution;human experts;relevant network structures;strenuous efforts;inherent network structures;natural image processing methods;existing DL methods;high spatial resolution remote sensing imagery","","","","9","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Supervised learning for feed-forward neural networks: a new minimax approach for fast convergence","A. Chella; A. Gentile; F. Sorbello; A. Tarantino","Dept. of Electr. Eng., Palermo Univ., Italy; Dept. of Electr. Eng., Palermo Univ., Italy; Dept. of Electr. Eng., Palermo Univ., Italy; Dept. of Electr. Eng., Palermo Univ., Italy","IEEE International Conference on Neural Networks","6 Aug 2002","1993","","","605","609 vol.1","An approach to the problem of the learning process for feedforward neural networks, based on an optimization point of view, is proposed. The developed algorithm is a minimax method based on a configuration of the quasi-Newton and steepest-descent methods. The optimum point is reached by minimizing the maximum of the error functions of the network without requiring any tuning of internal parameters. The algorithm is tested on several widespread benchmarks and shows superior convergence properties when compared with other algorithms available in the literature. Significant experimental results are included.<<ETX>></ETX>","","0-7803-0999-5","10.1109/ICNN.1993.298626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=298626","","Supervised learning;Feedforward systems;Neural networks;Feedforward neural networks;Minimax techniques;Convergence;Linear matrix inequalities;Electronic mail;Benchmark testing;Computer networks","convergence of numerical methods;feedforward neural nets;learning (artificial intelligence);minimax techniques","quasi-Newton method;supervised learning;fast convergence;learning process;feedforward neural networks;minimax method;steepest-descent methods;error functions;convergence","","3","","13","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A Multi-Criteria Multi-Modal Predictive Trip Planner: Application on Paris Metropolitan Network","P. Benchimol; A. Amrani; M. Khouadjia","Kisio,Paris,France; IRT SystemX,Palaiseau,France; IRT SystemX,Palaiseau,France","2021 IEEE International Smart Cities Conference (ISC2)","15 Oct 2021","2021","","","1","4","Public transport route planning is of growing interest in smart cities and especially in metropolitan areas where congestions and traffic jams are frequently recorded. The availability of multiple data sources, such as passenger load in trains or ticketing logs, provides an interesting opportunity to develop decision support tools to help passengers better plan their trips around the city and to enhance their travel experience. We present, in this paper, a multi-criteria journey planner that incorporates train load predictions as criteria. To this end, on the one hand, we enrich the proposed routes with predictive indicators of passenger flow such as the load on board the trains. These indicators are computed for each section of the itinerary using machine learning algorithms. On the other hand, we design a journey planner that incorporates the predicted load in its search criteria.","2687-8860","978-1-6654-4919-9","10.1109/ISC253183.2021.9562921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9562921","journey planner;machine learning;multicriteria;transport;train load","Machine learning algorithms;Smart cities;Conferences;Tools;Planning","decision support systems;learning (artificial intelligence);public transport;rail traffic;railways;smart cities;traffic engineering computing","congestions;traffic jams;passenger load;ticketing logs;decision support tools;multicriteria journey planner;train load predictions;predictive indicators;passenger flow;predicted load;search criteria;machine learning;travel experience;data sources;metropolitan areas;smart cities;public transport route planning;Paris metropolitan network;multicriteria multimodal predictive trip planner","","","","17","IEEE","15 Oct 2021","","","IEEE","IEEE Conferences"
"Cross-Layer Optimization for High Speed Adders: A Pareto Driven Machine Learning Approach","Y. Ma; S. Roy; J. Miao; J. Chen; B. Yu","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Programmable Solution Group, Intel Corporation, San Jose, CA, USA; DSG Group, Cadence Design Systems, San Jose, CA, USA; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","20 Nov 2019","2019","38","12","2298","2311","In spite of maturity to the modern electronic design automation (EDA) tools, optimized designs at architectural stage may become suboptimal after going through physical design flow. Adder design has been such a long studied fundamental problem in very large-scale integration industry yet designers cannot achieve optimal solutions by running EDA tools on the set of available prefix adder architectures. In this paper, we enhance a state-of-the-art prefix adder synthesis algorithm to obtain a much wider solution space in architectural domain. On top of that, a machine learning-based design space exploration methodology is applied to predict the Pareto frontier of the adders in physical domain, which is infeasible by exhaustively running EDA tools for innumerable architectural solutions. Considering the high cost of obtaining the true values for learning, an active learning algorithm is proposed to select the representative data during learning process, which uses less labeled data while achieving better quality of Pareto frontier. Experimental results demonstrate that our framework can achieve Pareto frontier of high quality over a wide design space, bridging the gap between architectural and physical designs. Source code and data are available at <uri>https://github.com/yuzhe630/adder-DSE</uri>.","1937-4151","","10.1109/TCAD.2018.2878129","Research Grants Council of Hong Kong SAR(grant numbers:CUHK24209017); CUHK Undergraduate Summer Research Internship 2017; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509188","Active learning;design space exploration;machine learning;Pareto optimality;prefix adder","Adders;Physical design;Pareto optimization;Machine learning;Space exploration;Design automation;Machine learning algorithms","","","","6","","38","IEEE","25 Oct 2018","","","IEEE","IEEE Journals"
"Feature Learning in Feature-Sample Networks Using Multi-Objective Optimization","F. A. Neto Verri; R. Tinós; L. Zhao","University of São Paulo - São Carlos, Institute of Mathematical and Computer Sciences, SP, Brazil; Department of Computing and Mathematics, FFCLRP University of São Paulo - Ribeirão Preto, SP, Brazil; University of São Paulo - São Carlos, Institute of Mathematical and Computer Sciences, SP, Brazil","2018 IEEE Congress on Evolutionary Computation (CEC)","4 Oct 2018","2018","","","1","6","Data and knowledge representation are fundamental concepts in machine learning. The quality of the representation impacts the performance of a learning model directly. Feature learning transforms or enhances raw data to structures that are effectively exploited by those methods. In recent years, several works have been using complex networks for data representation and analysis. However, no feature learning method has been proposed to enhance such category of representation. Here, we present an unsupervised feature learning mechanism that works on datasets with binary features. First, the dataset is mapped into a feature-sample network. Then, a multi-objective optimization process selects a set of new vertices to produce an enhanced version of the network. The new features depend on a nonlinear function of a combination of preexisting features. Effectively, the process projects the input data into a higher-dimensional space. To solve the optimization problem, we design two metaheuristics based on the lexicographic genetic algorithm and the improved strength Pareto evolutionary algorithm (SPEA2). We show that the enhanced network contains more useful information and can be exploited to improve the performance of machine learning methods. The advantages and disadvantages of each optimization strategy are discussed.","","978-1-5090-6017-7","10.1109/CEC.2018.8477891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477891","Feature learning;complex networks;multiobjective optimization;genetic algorithm","Optimization;Genetic algorithms;Machine learning;Evolutionary computation;Sociology;Statistics;Learning systems","genetic algorithms;Pareto optimisation;unsupervised learning","feature-sample network;knowledge representation;learning model;complex networks;data representation;feature learning method;unsupervised feature learning mechanism;binary features;multiobjective optimization process;machine learning methods;lexicographic genetic algorithm;improved strength Pareto evolutionary algorithm","","","","16","","4 Oct 2018","","","IEEE","IEEE Conferences"
"Machine Learning in Adversarial Game Using Flight Chess","Y. Liu; D. Li; Y. Hu","Coll. of Comput. Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China; Coll. of Comput. Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China; Coll. of Comput. Sci. & Technol., Huazhong Univ. of Sci. & Technol., Wuhan, China","2011 Third International Conference on Multimedia Information Networking and Security","15 Dec 2011","2011","","","65","68","Game playing is a perfect domain of the study of machine learning for its simplicity that allows the researchers to focus on the learning problems themselves and ignore marginal factors. Many learning techniques derived from games have been applied successfully in other learning problems. In this paper, we introduce a Minimax Recurrence Learning algorithm to reinforce the intelligence of a game agent and a supervised learning technique to train the agent. It proves that our intelligent flight chess agent defeat human players in the flight chess game with high probability. Theory deduction proves that combination of the reinforcement learning and supervised learning techniques used in our agent can learn the essential knowledge in an adversarial game. The infrastructure and the algorithm of our agent can be extended in other learning problems also.","2162-8998","978-1-4577-1795-6","10.1109/MINES.2011.124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6103723","reinforcement learning;supervised learning;machine learning;feature characterization","Games;Training;Machine learning;Learning;Supervised learning;Approximation methods;Transfer functions","computer games;learning (artificial intelligence)","machine learning;adversarial game;flight chess;minimax recurrence learning algorithm;supervised learning technique;reinforcement learning","","","","7","","15 Dec 2011","","","IEEE","IEEE Conferences"
"Supervised Learning Model Predictive Control Trained by ABC Algorithm for Common-Mode Voltage Suppression in NPC Inverter","M. Babaie; M. Sharifzadeh; M. Mehrasa; G. Chouinard; K. Al-Haddad","École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada; École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada; Department of Engineering and Architecture, Universitá degli Studi di Trieste, Trieste, Italy; École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada; École de Technologie Supérieure, University of Quebec, Montreal, QC, Canada","IEEE Journal of Emerging and Selected Topics in Power Electronics","1 Jun 2021","2021","9","3","3446","3456","Training the weighting factors of model predictive control in multiobjective problems is a time consuming and sophisticated process. In this article, conventional model predictive control (CMPC) has been developed as supervised learning model predictive control (SLMPC) to cancel common-mode voltage (CMV) in a three-phase neutral-point-clamped (NPC) inverter, while other control objectives are desirably tracked. SLMPC is accurately and quickly trained through the artificial bee colony (ABC) algorithm to optimize the controller weighting factors. Using the optimized weighting factors, transient response is minimized and CMV is surpassed. After training the weighting factors, SLMPC containing the optimized waiting factors is applied to the three-phase NPC inverter without considering the ABC algorithm in the control loop. By applying the optimized weighting factors to the cost function, SLMPC has been evaluated under several experimental and simulation tests to show that desired control objectives, particularly CMV suppression, have been attained. The proposed training process can be generalized and used for MPC cost functions with more control objectives to obtain the best possible performance.","2168-6785","","10.1109/JESTPE.2020.2984674","Canadian Research Chair in Electric Energy Conversion, Power Electronics (CRC-EECPE); Natural Sciences and Engineering Research Council of Canada (NSERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051689","Artificial bee colony (ABC) algorithm;common-mode voltage (CMV) suppression;optimized weighting factors;supervised learning model predictive control (SLMPC);three-phase neutral-point-clamped (NPC) inverter","Inverters;Capacitors;Load modeling;Cost function;Voltage control;Switches;Predictive control","invertors;learning (artificial intelligence);optimisation;predictive control","three-phase NPC inverter;ABC algorithm;control loop;optimized weighting factors;SLMPC;desired control objectives;training process;supervised learning model predictive control;common-mode voltage suppression;conventional model predictive control;artificial bee colony algorithm;controller weighting factors;optimized waiting factors","","23","","27","IEEE","31 Mar 2020","","","IEEE","IEEE Journals"
"Selective ensemble learning method for belief-rule-base classification system based on PAES","W. Liu; W. Wu; Y. Wang; Y. Fu; Y. Lin","School of Mathematics and Computer Science, Fuzhou University, Fuzhou 350116, China; School of Mathematics and Computer Science, Fuzhou University, Fuzhou 350116, China; Institute of Decision Sciences, Fuzhou University, Fuzhou 350116, China; School of Mathematics and Computer Science, Fuzhou University, Fuzhou 350116, China; School of Mathematics and Computer Science, Fuzhou University, Fuzhou 350116, China","Big Data Mining and Analytics","5 Aug 2019","2019","2","4","306","318","Traditional Belief-Rule-Based (BRB) ensemble learning methods integrate all of the trained sub-BRB systems to obtain better results than a single belief-rule-based system. However, as the number of BRB systems participating in ensemble learning increases, a large amount of redundant sub-BRB systems are generated because of the diminishing difference between subsystems. This drastically decreases the prediction speed and increases the storage requirements for BRB systems. In order to solve these problems, this paper proposes BRBCS-PAES: a selective ensemble learning approach for BRB Classification Systems (BRBCS) based on Pareto-Archived Evolutionary Strategy (PAES) multi-objective optimization. This system employs the improved Bagging algorithm to train the base classifier. For the purpose of increasing the degree of difference in the integration of the base classifier, the training set is constructed by the repeated sampling of data. In the base classifier selection stage, the trained base classifier is binary coded, and the number of base classifiers participating in integration and generalization error of the base classifier is used as the objective function for multi-objective optimization. Finally, the elite retention strategy and the adaptive mesh algorithm are adopted to produce the PAES optimal solution set. Three experimental studies on classification problems are performed to verify the effectiveness of the proposed method. The comparison results demonstrate that the proposed method can effectively reduce the number of base classifiers participating in the integration and improve the accuracy of BRBCS.","2096-0654","","10.26599/BDMA.2019.9020008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787234","belief-rule-base;pareto-archived evolutionary strategy;selective ensemble;classification","Cognition;Optimization;Learning systems;Linear programming;Training;Erbium;Big Data","belief networks;evolutionary computation;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification","selective ensemble learning method;PAES;trained sub-BRB systems;single belief-rule-based system;redundant sub-BRB systems;selective ensemble learning approach;base classifier selection stage;trained base classifier;Pareto-archived evolutionary strategy multiobjective optimization;BRB classification systems;traditional belief-rule-based learning method;belief-rule-base classification system","","1","","","","5 Aug 2019","","","TUP","TUP Journals"
"Classification as Clustering: A Pareto Cooperative-Competitive GP Approach","A. R. McIntyre; M. I. Heywood","Faculty of Computer Science, Dalhousie University, Halifax, B3H 1W5, Canada. armcnty@cs.dal.ca; Faculty of Computer Science, Dalhousie University, Halifax, B3H 1W5, Canada. mheywood@cs.dal.ca","Evolutionary Computation","19 May 2014","2011","19","1","137","166","Intuitively population based algorithms such as genetic programming provide a natural environment for supporting solutions that learn to decompose the overall task between multiple individuals, or a team. This work presents a framework for evolving teams without recourse to prespecifying the number of cooperating individuals. To do so, each individual evolves a mapping to a distribution of outcomes that, following clustering, establishes the parameterization of a (Gaussian) local membership function. This gives individuals the opportunity to represent <italic>subsets</italic> of tasks, where the overall task is that of classification under the supervised learning domain. Thus, rather than each team member representing an entire class, individuals are free to identify unique subsets of the overall classification task. The framework is supported by techniques from evolutionary multiobjective optimization (EMO) and Pareto competitive coevolution. EMO establishes the basis for encouraging individuals to provide accurate yet nonoverlaping behaviors; whereas competitive coevolution provides the mechanism for scaling to potentially large unbalanced datasets. Benchmarking is performed against recent examples of nonlinear SVM classifiers over 12 UCI datasets with between 150 and 200,000 training instances. Solutions from the proposed coevolutionary multiobjective GP framework appear to provide a good balance between classification performance and model complexity, especially as the dataset instance count increases.","1063-6560","","10.1162/EVCO_a_00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6793784","Genetic programming;Pareto multi-objective optimization;coevolution;problem decomposition;classification","","","","","5","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Thirty Years of Machine Learning: The Road to Pareto-Optimal Wireless Networks","J. Wang; C. Jiang; H. Zhang; Y. Ren; K. -C. Chen; L. Hanzo","Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Information Science and Technology, Tsinghua University, Beijing, China; Institute of Artificial Intelligence, Beijing Advanced Innovation Center for Materials Genome Engineering, Beijing Engineering and Technology Research Center for Convergence Networks and Ubiquitous Services, University of Science and Technology Beijing, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Electrical Engineering Department, University of South Florida, Tampa, FL, USA; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.","IEEE Communications Surveys & Tutorials","21 Aug 2020","2020","22","3","1472","1514","Future wireless networks have a substantial potential in terms of supporting a broad range of complex compelling applications both in military and civilian fields, where the users are able to enjoy high-rate, low-latency, low-cost and reliable information services. Achieving this ambitious goal requires new radio techniques for adaptive learning and intelligent decision making because of the complex heterogeneous nature of the network structures and wireless services. Machine learning (ML) algorithms have great success in supporting big data analytics, efficient parameter estimation and interactive decision making. Hence, in this article, we review the thirty-year history of ML by elaborating on supervised learning, unsupervised learning, reinforcement learning and deep learning. Furthermore, we investigate their employment in the compelling applications of wireless networks, including heterogeneous networks (HetNets), cognitive radios (CR), Internet of Things (IoT), machine to machine networks (M2M), and so on. This article aims for assisting the readers in clarifying the motivation and methodology of the various ML algorithms, so as to invoke them for hitherto unexplored services as well as scenarios of future wireless networks.","1553-877X","","10.1109/COMST.2020.2965856","National Natural Science Foundation of China(grant numbers:61922050); Preresearch Fund of Equipments of Ministry of Education of China(grant numbers:6141A02022615); Research Fund of China Academy of Space Technology(grant numbers:Co/Co-20180605-47); National Natural Science Foundation of China(grant numbers:61822104,61771044); Fundamental Research Funds for the Central Universities(grant numbers:RC1631,FRF-TP-19-002C1); Shuimu Tsinghua Scholar Program; Florida Center for Cybersecurity, University of South Florida; Engineering and Physical Sciences Research Council Projects(grant numbers:EP/Noo4558/1,EP/PO34284/1); COALESCE, of the Royal Society’s Global Challenges Research Fund Grant as well as of the European Research Council’s Advanced Fellow Grant QuantCom; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957702","Machine learning (ML);future wireless network;deep learning;regression;classification;clustering;network association;resource allocation","Wireless networks;Wireless sensor networks;Internet of Things;Ad hoc networks;Maximum likelihood estimation;Clustering algorithms","Big Data;cognitive radio;data analysis;decision making;information services;Internet;Internet of Things;learning (artificial intelligence);radio networks;unsupervised learning","Pareto-optimal wireless networks;future wireless networks;substantial potential;complex compelling applications;military fields;civilian fields;reliable information services;ambitious goal;radio techniques;adaptive learning;intelligent decision making;complex heterogeneous nature;network structures;wireless services;machine learning algorithms;big data analytics;efficient parameter estimation;interactive decision making;supervised learning;unsupervised learning;reinforcement learning;deep learning;heterogeneous networks;machine networks;ML algorithms;unexplored services","","189","","373","IEEE","13 Jan 2020","","","IEEE","IEEE Journals"
"Regression Models and Ranking Method for p53 Inhibitor Candidates Using Machine Learning","H. Motohashi; T. Teraoka; S. Aoki; H. Ohwada","Department of Industrial Administration, Tokyo University of Science, Chiba, Japan; Department of Medicinal and Life Science, Tokyo University of Science, Chiba, Japan; Department of Medicinal and Life Science, Tokyo University of Science, Chiba, Japan; Department of Industrial Administration, Tokyo University of Science, Chiba, Japan","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","708","712","Radiation therapy is one of the main treatments for cancer. However, it may cause various side effects owing to the apoptosis activity of the p53 protein in normal cells. Therefore, to avoid the side effects, it is important to protect normal cells against radiation by using p53 inhibitors. It is also expected that p53 inhibitors have low toxicity against patients' bodies. However, the design of p53 inhibitors is not easy because drug discovery requires enormous costs and long time. In this paper, we propose a new method for ranking candidate p53 inhibitors, considering both their radioprotective function and cytotoxicity. We use features of the two- and three-dimensional structures of the compounds, including fingerprints, some machine learning methods such as random forest and SVR (Support Vector Machine), and one method for ranking, i.e., the Pareto ranking method. Therefore, we present the regression models of the cytotoxicity and radioprotective functions of the candidates to determine their ranking. Our proposed methods yield useful rankings for drug discovery.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621142","SVR;p53;Pareto ranking;machine learning","Compounds;Inhibitors;Predictive models;Machine learning;Mathematical model;Proteins;Drugs","cancer;cellular biophysics;drugs;learning (artificial intelligence);molecular biophysics;patient treatment;proteins;radiation therapy;regression analysis;support vector machines;toxicology","useful rankings;drug discovery;regression models;p53 inhibitor candidates;radiation therapy;apoptosis activity;normal cells;low toxicity;patients;ranking candidate p53 inhibitors;radioprotective function;machine learning methods;Pareto ranking method;support vector machine;SVR;cytotoxicity functions","","3","","11","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Using Manifold Learning and Minimax Probability Machine for Face Recognition","X. Sun; L. Li; Z. Wang","Sch. of Comput. Sci. & Technol., Wuhan Univ. of Technol., Wuhan, China; Sch. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou, China; Sch. of Inf. Sci. & Eng., Henan Univ. of Technol., Zhengzhou, China","2010 Second International Conference on Modeling, Simulation and Visualization Methods","26 Aug 2010","2010","","","229","232","Face recognition has become one of the most important research areas of pattern recognition and machine learning due to its potential applications in many fields. To effectively cope with this problem, a novel face recognition algorithm is proposed by using manifold learning and minimax probability machine. Comprehensive comparisons and extensive experiments show that the proposed algorithm achieves much higher recognition rates than the ordinary face recognition algorithms.","","978-1-4244-7078-5","10.1109/WMSVM.2010.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5558313","face recognition;manifold learning;minimax probability machine;pattern recognition","Face recognition;Classification algorithms;Face;Manifolds;Feature extraction;Principal component analysis","face recognition;learning (artificial intelligence);minimax techniques;probability","manifold learning;minimax probability machine;face recognition;pattern recognition;machine learning","","","","12","","26 Aug 2010","","","IEEE","IEEE Conferences"
"Investigating the Creation of a Surrogate Model for Adaptive Control of Amplifier Operating Point Using Machine Learning","C. J. A. Bastos-Filho; L. M. de Freitas; E. de A. Barboza; J. F. Martins-Filho","Polytechnic School of Pernambuco, University of Pernambuco,Recife-PE,Brazil,50720-001; Computing Institute, Federal University of Alagoas,Maceió-AL,Brazil,57072-900; Computing Institute, Federal University of Alagoas,Maceió-AL,Brazil,57072-900; Federal University of Pernambuco,Department of Electronics and Systems,Recife-PE,Brazil,50740-530","2020 22nd International Conference on Transparent Optical Networks (ICTON)","22 Sep 2020","2020","","","1","4","Dynamic operation is one of the current challenges in optical communication and networks, and the adaptive control of optical amplifier (ACOP) is one of the problems in this challenge. The ACOP approaches aim to define the gains of the optical amplifiers dynamically to increase the quality of the transmission after a cascade of amplifiers. The most recent ACOP approach uses a multiobjective evolutionary optimization algorithm to define the gains of the amplifiers to maximize the optical signal to noise ratio (OSNR) and to minimize OSNR ripple. Despite the promising results regarding Quality of Transmission, it is not desirable to rely on an evolutionary algorithm to make decisions in real-time. In this work, we investigate the creation of a surrogate model that can obtain solutions as good as the multiobjective algorithm, but in real-time. We show the results for a machine learning (ML) regression technique, trained with the optimization algorithm solutions, can return configurations with OSNR less than 1 dB close to the best OSNR returned by the optimization algorithm. Moreover, the ML solution answers in milliseconds, whereas the optimization-based approach needs several minutes to find a proper configuration.","2161-2064","978-1-7281-8423-4","10.1109/ICTON51198.2020.9203524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203524","optical communication;optical amplifier;dynamic operation;adaptive control;machine learning","Optical noise;Signal to noise ratio;Optical amplifiers;Gain;Optical fiber communication;Databases;Optimization","adaptive control;evolutionary computation;learning (artificial intelligence);operational amplifiers;optical communication;optimisation;regression analysis","ACOP approaches;multiobjective evolutionary optimization algorithm;OSNR ripple;surrogate model;machine learning regression technique;amplifier operating point;dynamic operation;optical communication networks;adaptive control of optical amplifier;optical signal to noise ratio;Quality of Transmission","","1","","6","","22 Sep 2020","","","IEEE","IEEE Conferences"
"Ensembling of Gene Clusters Utilizing Deep Learning and Protein-Protein Interaction Information","P. Dutta; S. Saha; S. Chopra; V. Miglani","Department of Computer Science and Engineering, Indian Institute of Technology, Bihar, Patna, India; Department of Computer Science and Engineering, Indian Institute of Technology, Bihar, Patna, India; Department of Computer Science and Engineering, Indian Institute of Technology, Bihar, Patna, India; Department of Computer Science and Engineering, Meerut Institute of Engineering and Technology, Meerut, UP, India","IEEE/ACM Transactions on Computational Biology and Bioinformatics","8 Dec 2020","2020","17","6","2005","2016","Cluster ensemble techniques aim to combine the outputs of multiple clustering algorithms to obtain a single consensus partitioning. The current paper reports about the development of a cluster ensemble based technique combining the concepts of multiobjective optimization and deep-learning models for gene clustering where some additional protein-protein interaction information are utilized for generating the consensus partitioning. The proposed ensemble based framework works in four phases: (i) filtering out the irrelevant genes from the microarray dataset: only the statistically significant genes are considered for further data analysis; (ii) generation of diverse base partitionings: a multi-objective optimization-based clustering technique is proposed which simultaneously optimizes three different cluster quality measures and generates a set of partitioning solutions on the Pareto optimal front; (iii) generation of a consensus partitioning: mentha scores, calculated by accessing a highly enriched protein-protein interaction archive named <italic>mentha</italic>, of different clustering solutions are considered for generating a weighted incidence matrix; (iv) finally, two approaches are used to generate a consensus partitioning from the obtained incidence matrix. The first approach is based on a traditional machine learning method, and another approach exploits the graph partitioning algorithm and two deep neural models to generate the final clustering. To validate the efficacy of the proposed ensemble framework, it is applied on five gene expression datasets. We present a comparative analysis of the proposed technique over different clustering algorithms in terms of biological homogeneity index (BHI) and biological stability index (BSI). The traditional approach attains an average 3 and 2 percent improvements over the best non-dominated solution with respect to BHI and BSI, respectively, whereas deep learning models illustrate an average 6.8 and 1.5 percent improvements over the proposed traditional approach with respect to BHI and BSI, respectively. Subsequently, Welch's t-test is executed to prove that the results obtained by the proposed methods are statistically significant. <italic>Availability of data and materials:</italic> <uri>https://github.com/sduttap16/DeepEnsm</uri>.","1557-9964","","10.1109/TCBB.2019.2918523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721175","Protein-protein interactions;deep learning;clustering;ensemble technique","Proteins;Clustering algorithms;Partitioning algorithms;Deep learning;Machine learning algorithms;Gene expression","data analysis;genetics;graph theory;learning (artificial intelligence);neural nets;Pareto optimisation;pattern clustering;proteins","ensembling;gene clusters;cluster ensemble techniques;multiple clustering algorithms;single consensus partitioning;deep-learning models;gene clustering;protein-protein interaction information;ensemble based framework;irrelevant genes;statistically significant genes;diverse base partitionings;multiobjective optimization-based clustering technique;cluster quality measures;partitioning solutions;Pareto optimal front;clustering solutions;weighted incidence matrix;traditional machine learning method;graph partitioning algorithm;deep neural models;final clustering;ensemble framework;gene expression datasets;biological stability index;traditional approach attains;deep learning models;highly enriched protein-protein interaction archive;efficiency 2.0 percent;efficiency 1.5 percent","Cluster Analysis;Computational Biology;Deep Learning;Multigene Family;Phylogeny;Protein Interaction Mapping;Protein Interaction Maps","4","","54","IEEE","23 May 2019","","","IEEE","IEEE Journals"
"The U-Net model application for retinal vessels segmentation using minimax approach","V. Martsenyuk; R. Milian; N. Milian","University of Bielsko-Biala,Department of Computer Science and Automatics,Bielsko-Biala,Poland; Ternopil Volodymyr Hnatiuk National Pedagogical University,Department of Mathematics and Methods of its Teaching,Ternopil,Ukraine; Ternopil Ivan Puluj National Technical University,Department of Cybersecurity,Ternopil,Ukraine","2021 International Conference on Information and Digital Technologies (IDT)","10 Sep 2021","2021","","","366","370","In this article the implementation of neural network architecture based on a dense U-Net network is proposed. It is noted that retinal blood vessels are the basis for clinical diagnosis of some diseases. A review of the convolutional networks use for classification tasks and generalizion retinal vessel segmentation algorithms is performed. The general process of the neural network is presented. The differences between the real and the obtained results were evaluated. Evaluation of the neural network is carried out on several parameters. Indicators of binary cross-entropy and learning time when using different tile sizes are presented, based on these data determined by the solution to the problem of minimax ML for binary cross-entropy and learning time. The Figure with the recognized blood vessels as a result of the model is presented.","2575-677X","978-1-6654-3692-2","10.1109/IDT52577.2021.9532495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532495","machine learning;neural network;machine learning library;retinal vessels segmentation;minimax","Image segmentation;Neural networks;Receivers;Blood vessels;Minimization;Retinal vessels;Time measurement","blood vessels;convolutional neural nets;diseases;entropy;eye;image classification;image segmentation;learning (artificial intelligence);medical image processing;minimax techniques","U-Net model application;minimax approach;neural network architecture;U-Net network;retinal blood vessels;clinical diagnosis;convolutional networks;classification tasks;retinal vessel segmentation algorithms;binary cross-entropy;tile sizes;minimax ML;diseases;learning time","","","","28","","10 Sep 2021","","","IEEE","IEEE Conferences"
"The Blessing of Dimensionality in Many-Objective Search: An Inverse Machine Learning Insight","A. Gupta; Y. -S. Ong; M. Shakeri; X. Chi; A. Z. NengSheng","Singapore Institute of Manufacturing Technology, A*STAR,Singapore.; Nanyang Technological University,School of Computer Science and Engineering,Singapore; Singapore Institute of Manufacturing Technology, A*STAR,Singapore.; Singapore Institute of Manufacturing Technology, A*STAR,Singapore.; Singapore Institute of Manufacturing Technology, A*STAR,Singapore.","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","3896","3902","Sample-based evolutionary algorithms (EAs) are widely used for optimizing problems with multi (greater than one but less than four) or even many (greater than or equal to four) objectives of interest. In general, the difficulty of a problem exponentially increases with the number of objectives, serving as a clear example of the curse of dimensionality. The exploratory approach an EA takes in these cases has led to it being thought of as a big data generator, progressively sampling and evaluating solutions in high performing regions of a decision space to guide the search towards optimal solutions. Notably, in both multi- and many-objective EAs, the sampled data can be further utilized for building inverse generative models, mapping points in objective space back to solutions in the decision space. Such models offer immense flexibility to a decision maker in generating new target solutions on the fly, thereby facilitating real-time a posteriori preference incorporation into the search. In this paper, we show that the data distribution resulting from a many-objective formulation is in fact more conducive to building accurate inverse models than its multiobjective counterpart. Given the potential utility of these models, we in turn shed light on a rare blessing of dimensionality that is yet to be explored in the context of optimization. We first present simple theoretical arguments supporting our claim. Thereafter, experimental studies of Gaussian process-based inverse modeling for a synthetic and a real-world example are carried out to further confirm the theory.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005525","Blessing of dimensionality;inverse modeling;many-objective optimization;Gaussian processes","Inverse problems;Optimization;Manufacturing;Evolutionary computation;Buildings;Gaussian processes;Search problems","decision making;evolutionary computation;Gaussian processes;learning (artificial intelligence);optimisation","decision maker;target solutions;posteriori preference incorporation;data distribution;many-objective formulation;accurate inverse models;potential utility;Gaussian process-based inverse modeling;real-world example;many-objective search;inverse machine;sample-based evolutionary algorithms;EA;optimizing problems;big data generator;high performing regions;decision space;optimal solutions;many-objective EA;sampled data;inverse generative models;objective space;immense flexibility","","","","26","","24 Feb 2020","","","IEEE","IEEE Conferences"
"Adaptive Threshold Non-Pareto Elimination: Re-thinking machine learning for system level design space exploration on FPGAs","P. Meng; A. Althoff; Q. Gautier; R. Kastner","Department of Computer Science and Engineering, University of California, San Diego, USA; Department of Computer Science and Engineering, University of California, San Diego, USA; Department of Computer Science and Engineering, University of California, San Diego, USA; Department of Computer Science and Engineering, University of California, San Diego, USA","2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)","28 Apr 2016","2016","","","918","923","One major bottleneck of the system level OpenCL-to-FPGA design tools is their extremely time consuming synthesis process (including place and route). The design space for a typical OpenCL application contains thousands of possible designs even when considering a small number of design space parameters. It costs months of compute time to synthesize all these possible designs into end-to-end FPGA implementations. Thus, the brute force design space exploration (DSE) is impractical for these design tools. Machine learning is one solution that identifies the valuable Pareto designs by sampling only a small portion of the entire design space. However, most of the existing machine learning frameworks focus on improving the design objective regression accuracy, which is not necessarily suitable for the FPGA DSE task. To address this issue, we propose a novel strategy - Adaptive Threshold Non-Pareto Elimination (ATNE). Instead of focusing on regression accuracy improvement, ATNE focuses on understanding and estimating the inaccuracy. ATNE provides a Pareto identification threshold that adapts to the estimated inaccuracy of the regressor. This adaptive threshold results in a more efficient DSE. For the same prediction quality, ATNE reduces the synthesis complexity by 1.6 - 2.89× (hundreds of synthesis hours) against the other state of the art frameworks for FPGA DSE. In addition, ATNE is capable of identifying the Pareto designs for certain difficult design spaces which the other existing frameworks are incapable of exploring effectively.","1558-1101","978-3-9815-3707-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7459439","","Field programmable gate arrays;Radio frequency;Linear programming;Hardware;Training;Complexity theory;Algorithm design and analysis","field programmable gate arrays;learning (artificial intelligence);logic design;regression analysis","regressor inaccuracy;Pareto identification threshold;ATNE;FPGA DSE task;machine learning frameworks;brute force design space exploration;system level OpenCL-to-FPGA design tools;system level design space exploration;adaptive threshold nonPareto elimination","","20","","14","","28 Apr 2016","","","IEEE","IEEE Conferences"
"Minimax Approach for Semivariogram Fitting in Ordinary Kriging","A. Setiyoko; T. Basaruddin; A. M. Arymurthy","Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia","IEEE Access","13 May 2020","2020","8","","82054","82065","This research paper aims to analyze the minimax approach used in the semivariogram fitting process that forms one stage of the kriging operation performed for interpolation. The conventional method uses the weighted least squares fit for various theoretical functions such as stable, exponential, spherical. However, several recent approaches have been developed using machine learning regression techniques. This research employs the ordinary kriging technique where the proposed minimax approach is expected to increase the accuracy of the interpolation resulted by reducing the error of the final result. Kriging, which is based on the stochastic method, is widely used for spatial values and has been proven to be a better predicting process than deterministic methods. The novel approach to ordinary kriging discussed here, the minimax approach, is able to increase result accuracy based on the experiments performed. Minimax can predict the weights of the semivariogram values better than the weighted least-squares method and performs faster than machine learning approaches.","2169-3536","","10.1109/ACCESS.2020.2991428","Hibah TADOK Program through the Faculty of Computer Science, Universitas Indonesia(grant numbers:NKB-0107/UN2.R3.1/HKP.05.00/2019); LAPAN Scholarship for the Doctoral Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082672","Minimax techniques;interpolation;approximation methods","Interpolation;Fitting;Machine learning;Data models;Mathematical model;Support vector machines","interpolation;learning (artificial intelligence);least squares approximations;minimax techniques;regression analysis","minimax approach;semivariogram fitting process;interpolation;ordinary kriging technique;weighted least-squares method;machine learning approaches","","2","","31","CCBY","30 Apr 2020","","","IEEE","IEEE Journals"
"On the performance of classification algorithms for learning Pareto-dominance relations","S. Bandaru; A. H. C. Ng; K. Deb","Virtual Systems Research Centre, University of Skövde, Skövde, Sweden; Virtual Systems Research Centre, University of Skövde, Skövde, Sweden; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, USA","2014 IEEE Congress on Evolutionary Computation (CEC)","22 Sep 2014","2014","","","1139","1146","Multi-objective evolutionary algorithms (MOEAs) are often criticized for their high-computational costs. This becomes especially relevant in simulation-based optimization where the objectives lack a closed form and are expensive to evaluate. Over the years, meta-modeling or surrogate modeling techniques have been used to build inexpensive approximations of the objective functions which reduce the overall number of function evaluations (simulations). Some recent studies however, have pointed out that accurate models of the objective functions may not be required at all since evolutionary algorithms only rely on the relative ranking of candidate solutions. Extending this notion to MOEAs, algorithms which can ‘learn’ Pareto-dominance relations can be used to compare candidate solutions under multiple objectives. With this goal in mind, in this paper, we study the performance of ten different off-the-shelf classification algorithms for learning Pareto-dominance relations in the ZDT test suite of benchmark problems. We consider prediction accuracy and training time as performance measures with respect to dimensionality and skewness of the training data. Being a preliminary study, this paper does not include results of integrating the classifiers into the search process of MOEAs.","1941-0026","978-1-4799-1488-3","10.1109/CEC.2014.6900641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6900641","Meta-modeling;Multi-objective optimization;Classification algorithms;Pareto-dominance;Machine learning","Training;Optimization;Support vector machines;Vectors;Neurons;Sociology;Statistics","evolutionary computation;learning (artificial intelligence);Pareto optimisation;pattern classification","classification algorithms;learning pareto-dominance relations;multiobjective evolutionary algorithms;MOEA;high-computational costs;optimization;surrogate modeling techniques;metamodeling techniques;ZDT test;benchmark problems;prediction accuracy;training time;training data;machine learning","","22","","23","","22 Sep 2014","","","IEEE","IEEE Conferences"
"Machine-Learning-Aided Optimization Framework for Design of Medium-Voltage Grid-Connected Solid-State Transformers","J. Saha; D. Hazarika; N. B. Y. Gorla; S. K. Panda","Department of Electrical and Computer Engineering, National University of Singapore (NUS), Singapore; School of Computing, National University of Singapore (NUS), Singapore; Energy Research Institute @ NTU (ERI@N), Singapore; Department of Electrical and Computer Engineering, National University of Singapore (NUS), Singapore","IEEE Journal of Emerging and Selected Topics in Power Electronics","30 Nov 2021","2021","9","6","6886","6900","Due to the lack of a comprehensive multiobjective solid-state transformer (SST) design framework, SST designs are mostly obtained through trial/experience. In this article, a machine-learning (ML)-aided optimal SST design framework is proposed, which involves the objectives of maximizing efficiency (<inline-formula> <tex-math notation=""LaTeX"">$\eta $ </tex-math></inline-formula>) and power density (<inline-formula> <tex-math notation=""LaTeX"">$\rho $ </tex-math></inline-formula>). The challenges of computationally expensive magnetics design, coupled with the correlation between magnetics design and performance of semiconductor devices, are tackled by developing a hybrid local optimization algorithm. This local optimization is subsequently learned through ML techniques, using a limited number of optimal design data sets, and, thus, assists in the genesis of optimal SST design limits for several combinations of semiconductor devices and switching frequencies. The proposed framework is implemented for a cascaded matrix-based dual-active-bridge (CMB-DAB) SST comprising of SiC MOSFETs to demonstrate the optimization routine. The optimization results exhibit low-error fits of the selected ML models and the <inline-formula> <tex-math notation=""LaTeX"">$\eta $ </tex-math></inline-formula>–<inline-formula> <tex-math notation=""LaTeX"">$\rho $ </tex-math></inline-formula> limits in different categories of optimal SST designs. The SiC-based SST designs are also observed to offer better <inline-formula> <tex-math notation=""LaTeX"">$\eta $ </tex-math></inline-formula>–<inline-formula> <tex-math notation=""LaTeX"">$\rho $ </tex-math></inline-formula> optimal designs compared to Si-based SSTs. A laboratory-scale CMB-DAB prototype with experimental measurements is also presented to validate the proposed design optimization framework at a scaled-down level.","2168-6785","","10.1109/JESTPE.2021.3074408","National Research Foundation (NRF), Prime Minister’s Office, Singapore, through its Campus for Research Excellence and Technological Enterprise (CREATE) Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409168","Design optimization;machine learning (ML);silicon carbide (SiC);solid-state transformer (SST)","Optimization;MOSFET;Silicon carbide;Topology;Microgrids;Heat sinks;Switches","bridge circuits;DC-DC power convertors;laboratory techniques;learning (artificial intelligence);optimisation;power engineering computing;power grids;power transformers;silicon compounds","machine-learning-aided optimization framework;medium-voltage grid-connected solid-state transformers;solid-state transformer design framework;machine-learning-aided optimal SST design framework;hybrid local optimization algorithm;SiC-based SST designs;semiconductor devices;cascaded matrix-based dual-active-bridge;laboratory-scale CMB-DAB prototype;SiC","","3","","44","IEEE","20 Apr 2021","","","IEEE","IEEE Journals"
"Local Minimax Learning of Functions With Best Finite Sample Estimation Error Bounds: Applications to Ridge and Lasso Regression, Boosting, Tree Learning, Kernel Machines, and Inverse Problems","L. K. Jones","Dept. of Math. Sci., Univ. of Massachusetts, Lowell, MA, USA","IEEE Transactions on Information Theory","17 Nov 2009","2009","55","12","5700","5727","Optimal local estimation is formulated in the minimax sense for inverse problems and nonlinear regression. This theory provides best mean squared finite sample error bounds for some popular statistical learning algorithms and also for several optimal improvements of other existing learning algorithms such as smoothing splines and kernel regularization. The bounds and improved algorithms are not based on asymptotics or Bayesian assumptions and are truly local for each query, not depending on cross validating estimates at other queries to optimize modeling parameters. Results are given for optimal local learning of approximately linear functions with side information (context) using real algebraic geometry. In particular, finite sample error bounds are given for ridge regression and for a local version of lasso regression. The new regression methods require only quadratic programming with linear or quadratic inequality constraints for implementation. Greedy additive expansions are then combined with local minimax learning via a change in metric. An optimal strategy is presented for fusing the local minimax estimators of a class of experts-providing optimal finite sample prediction error bounds from (random) forests. Local minimax learning is extended to kernel machines. Best local prediction error bounds for finite samples are given for Tikhonov regularization. The geometry of reproducing kernel Hilbert space is used to derive improved estimators with finite sample mean squared error (MSE) bounds for class membership probability in two class pattern classification problems. A purely local, cross validation free algorithm is proposed which uses Fisher information with these bounds to determine best local kernel shape in vector machine learning. Finally, a locally quadratic solution to the finite Fourier moments problem is presented. After reading the first three sections the reader may proceed directly to any of the subsequent applications sections.","1557-9654","","10.1109/TIT.2009.2027479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5319754","Fusion;inverse problem;minimax;reproducing kernel;ridge regression","Machine learning;Minimax techniques;Estimation error;Regression tree analysis;Boosting;Kernel;Inverse problems;Information geometry;Statistical learning;Smoothing methods","inverse problems;learning (artificial intelligence);regression analysis","local minimax learning;finite sample estimation error bounds;ridge regression;lasso regression;tree learning;kernel machines;inverse problems;optimal local estimation;nonlinear regression;mean squared finite sample error bounds;statistical learning algorithm;smoothing splines;kernel regularization;Bayesian assumption;optimal local learning;algebraic geometry;quadratic programming;quadratic inequality constraints;greedy additive expansion;optimal finite sample prediction error bounds;Tikhonov regularization;kernel Hilbert space;mean squared error bounds;class membership probability;pattern classification;cross validation free algorithm;Fisher information;vector machine learning;finite Fourier moments","","6","","44","IEEE","17 Nov 2009","","","IEEE","IEEE Journals"
"A multi-objective parallel detection algorithm for images of power transmission line corridors","W. Zheng; C. Li; X. Cui; P. Shang","State Grid Shandong Electric Power Research Institute,Jinan,China; State Grid Shandong Electric Power Research Institute,Jinan,China; State Grid Shandong Electric Power Research Institute,Jinan,China; State Grid Shandong Electric Power Research Institute,Jinan,China","2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)","16 Jul 2020","2020","","","432","436","The application of deep learning-based image recognition technology in remote monitoring of power transmission lines has improved the protection level of power transmission lines. However, since the current hidden danger detection is based on a single general algorithm, the accuracy of the detection results needs to be improved. In this paper, we proposed a multi-objective parallel detection algorithm for images of power transmission line corridors based on basic feature sharing. Firstly, we tested the detection effects of different detection algorithms on various types of hidden danger images, based on which benchmark algorithms are selected and optimized for various types of hidden dangers. After that, we designed a multi-objective parallel detection framework to implement the parallel detection of the above three detection algorithms. The experimental results show that the multiobjective parallel detection algorithm proposed in this paper can improve the detection accuracy, as well the detection speed.","","978-1-7281-4323-1","10.1109/ITOEC49072.2020.9141566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141566","power transmission line;hidden danger;deep learning;image recognition;parallel detection","Feature extraction;Detection algorithms;Object detection;Power transmission lines;Training;Fires;Machinery","feature extraction;image recognition;learning (artificial intelligence);object detection;power engineering computing;power overhead lines;power system measurement;power transmission lines","power transmission line corridors;detection effects;hidden danger images;benchmark algorithms;multiobjective parallel detection algorithm;detection accuracy;detection speed;deep learning-based image recognition technology;power transmission lines;single general algorithm;hidden danger detection","","1","","12","","16 Jul 2020","","","IEEE","IEEE Conferences"
"Machine Learning Enabled Fast Multi-Objective Optimization for Electrified Aviation Power System Design","D. Jackson; S. Belakaria; Y. Cao; J. Rao Doppa; X. Lu","Oregon State University,School of Electrical Engineering and Computer Science,Corvallis,OR,USA; Washington State University,School of Electrical Engineering and Computer Science,Pullman,WA,USA; Oregon State University,School of EECS (EE),Corvallis,OR,USA; Washington State University,School of EECS (CS),Pullman,WA,USA; Temple University,Department of ECE,Philadelphia,PA,USA","2020 IEEE Energy Conversion Congress and Exposition (ECCE)","30 Oct 2020","2020","","","6385","6390","With the rise of more electric and all-electric aviation power systems, engineering efforts of system optimization shift to the electrical domain. A substantial amount of time and resources are dedicated to finding the best system architecture and design specifications to meet energy efficiency goals and physical constraints. Current processes utilize models of power system components to determine the optimal designs. However, such modeling is computationally expensive as numerous iterations are required to settle on an optimal design. This paper proposes a machine learning (ML) enabled constrained multi-objective optimization solver to drastically reduce the amount of design iterations required for Pareto set discovery for power systems. The process contributes significantly to design automation. A heavy-duty vertical-takeoff-landing (VTOL) unmanned aerial vehicle (UAV) power system is selected to demonstrate the efficacy and limitation of ML enabled optimization. Two extreme trials were run: 1) a search throughout the entire design space with only 9% valid designs within constraints; 2) a search throughout the valid design space. While Trial 1 was unsuccessful in discovering the Pareto front, Trial 2 uncovered all Pareto optimal designs with a 99% reduction of iterations compared to a brute force method.","2329-3748","978-1-7281-5826-6","10.1109/ECCE44975.2020.9235599","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9235599","Power Electronics;Power System Design;Machine Learning;Multi-Objective Optimization;Design Automation;Pareto Front;Aviation;UAV;VTOL","Force;Torque;Inverters;Batteries;Data aggregation;Erbium;Optimization","aircraft control;autonomous aerial vehicles;energy conservation;evolutionary computation;iterative methods;learning (artificial intelligence);Pareto optimisation;power control","design iterations;design automation;heavy-duty vertical-takeoff-landing unmanned aerial vehicle power system;valid design space;Pareto optimal designs;machine learning;electrified aviation power system design;all-electric aviation power systems;system optimization shift;electrical domain;system architecture;design specifications;energy efficiency goals;power system components;optimal design;multiobjective optimization solver","","1","","18","","30 Oct 2020","","","IEEE","IEEE Conferences"
"Minimax Learning for Distributed Inference","C. T. Li; X. Wu; A. Özgür; A. El Gamal","Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA","IEEE Transactions on Information Theory","23 Nov 2020","2020","66","12","7929","7938","The classical problem of supervised learning is to infer an accurate estimate of a target variable Y from a measured variable X using a set of labeled training samples. Motivated by the increasingly distributed nature of data and decision making, this paper considers a variation of this classical problem in which the inference is distributed between two nodes, e.g., a mobile device and a cloud, with a rate constraint on the communication between them. The mobile device observes X and sends a description M of X to the cloud, which computes an estimate Y̑ of Y. We follow the recent minimax learning approach to study this inference problem and show that it corresponds to a one-shot minimax noisy lossy source coding problem. We then establish information theoretic bounds on the risk-rate Lagrangian cost, leading to a general method for designing a near-optimal descriptor-estimator pair. A key ingredient in the proof of our result is a refined version of the strong functional representation lemma previously used to establish several one-shot source coding theorems. Our results show that a naive estimate-compress scheme for rate-constrained inference is not optimal in general. When the distribution of (X, Y) is known and the error is measured by the logarithmic loss, our bounds on the risk-rate Lagrangian cost provide a new one-shot operational interpretation of the information bottleneck. We also demonstrate a way to bound the excess risk of the descriptor-estimator pair obtained by our method.","1557-9654","","10.1109/TIT.2020.3029182","Huawei Technologies; Center for Science of Information (CSoI); NSF Science and Technology Center(grant numbers:CCF-0939370); NSF(grant numbers:CCF-1704624); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214839","Minimax learning;distributionally robust learning;information bottleneck;one-shot source coding;functional representation","Training;Source coding;Supervised learning;Robustness;Distributed databases;Noise measurement;Random variables","learning (artificial intelligence);minimax techniques;mobile communication;rate distortion theory;source coding","one-shot operational interpretation;rate-constrained inference;naive estimate-compress scheme;source coding theorems;strong functional representation lemma;near-optimal descriptor-estimator pair;risk-rate Lagrangian cost;information theoretic bounds;one-shot minimax noisy lossy source coding problem;inference problem;recent minimax learning approach;rate constraint;mobile device;decision making;labeled training samples;supervised learning;distributed inference","","1","","20","IEEE","6 Oct 2020","","","IEEE","IEEE Journals"
"Energy-Efficient and Delay Sensitive Routing Paths Using Mobility Prediction in Mobile WSN: Mathematical Optimization, Markov Chains, and Deep Learning Approaches","G. A. Montoya; C. Lozano-Garzon; Y. Donoso","Systems and Computing Engineering Department, Universidad de los Andes, Bogotá, Colombia; Systems and Computing Engineering Department, Universidad de los Andes, Bogotá, Colombia; Systems and Computing Engineering Department, Universidad de los Andes, Bogotá, Colombia","IEEE Access","23 Nov 2021","2021","9","","153382","153400","In Mobile Wireless Sensor Networks there could be scenarios where absolutely all network nodes (including the base station) are mobile, becoming a very hard task to find a communication path between a sensor node and the base station due to many network variables are changing at each moment. In addition, there are delay-sensitive applications that require establishing communication paths as soon as possible to mitigate low network performance in terms of end-to-end delay, reducing, at the same time, the energy consumption of the network. For this reason, we propose a multiobjective mathematical optimization model for finding the optimal communication path between a source node and a sink (base station) considering hard scenarios where all network nodes are mobile and minimizing end-to-end delay and energy consumption. This mathematical model would offer significant advantages to evaluate new algorithms due to we could know how far or close are the algorithm results from the optimal values given by the mathematical model. In addition, we propose a prediction distributed routing algorithm based on Markov Chains that takes into account the network mobility in order to find as fast as possible a communication path between a source node and a sink with minimal energy consumption. We also propose a deep learning approach to predict future nodes’ distances in a mobile network to determine if future movements of nodes will cause communication disruptions in paths. Significant findings were obtained when the Markov Chains and Deep Learning approaches were compared in terms of predicting nodes mobility and reducing the delay and the energy consumption in the network. The performance of our prediction algorithms (Markov Chains and Deep Learning approaches) is evaluated against the mathematical model to determine how good it is. Finally, to analyze our prediction algorithms considering real online scenarios, we compared it against typical routing algorithms, obtaining promising results in terms of delay and energy consumption in all mobile node scenarios.","2169-3536","","10.1109/ACCESS.2021.3124737","Vice Presidency for Research and Creation Publication fund at the Universidad de los Andes, Bogotá, Colombia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9598816","Mathematical optimization model for time-varying graphs;delays;energy consumption;prediction algorithm;Markov chains;deep learning","Mathematical models;Optimization;Prediction algorithms;Delays;Energy consumption;Wireless sensor networks;Routing","learning (artificial intelligence);Markov processes;mathematical programming;minimisation;mobility management (mobile radio);routing protocols;telecommunication computing;telecommunication power management;wireless sensor networks","delay sensitive routing paths;mobility prediction;mobile WSN;mobile wireless sensor networks;mobile node scenarios;typical routing algorithms;prediction algorithms;nodes mobility;communication disruptions;mobile network;future nodes;minimal energy consumption;network mobility;routing algorithm;algorithm results;mathematical model;minimizing end-to-end delay;source node;optimal communication path;multiobjective mathematical optimization model;low network performance;delay-sensitive applications;network variables;sensor node;base station;network nodes;deep learning approach;Markov chains","","","","30","CCBY","2 Nov 2021","","","IEEE","IEEE Journals"
"Rapid Multi-Criterial Antenna Optimization by Means of Pareto Front Triangulation and Interpolative Design Predictors","S. Koziel; A. Pietrenko-Dabrowska","Department of Technology, Engineering Optimization & Modeling Center, Reykjavik University, Reykjavik, Iceland; Faculty of Electronics, Telecommunications and Informatics, Gdaðsk University of Technology, Gdaðsk, Poland","IEEE Access","4 Mar 2021","2021","9","","35670","35680","Modern antenna systems are designed to meet stringent performance requirements pertinent to both their electrical and field properties. The objectives typically stay in conflict with each other. As the simultaneous improvement of all performance parameters is rarely possible, compromise solutions have to be sought. The most comprehensive information about available design trade-offs can be obtained through multi-objective optimization (MO), typically in the form of a Pareto set. Notwithstanding, MO is a numerically challenging task, in a large part due to high CPU cost of evaluating the antenna properties, normally carried out through full-wave electromagnetic (EM) analysis. Surrogate-assisted procedures can mitigate the cost issue to a certain extent but construction of reliable metamodels is hindered by the curse of dimensionality, and often highly nonlinear antenna characteristics. This work proposes an alternative approach to MO of antennas. The major contribution of our work consists in establishing a deterministic machine learning procedure, which involves sequential generation of Pareto-optimal designs based on the knowledge gathered so far in the process (specifically, by triangulation of the already obtained Pareto set), and local surrogate-assisted refinement procedures. Our methodology allows for rendering uniformly-distributed Pareto designs at the cost of a few hundreds of antenna EM simulations, as demonstrated by means of three verification case studies. Benchmarking against state-of-the-art MO techniques is provided as well.","2169-3536","","10.1109/ACCESS.2021.3062449","Rannsóknamiðstöð Íslands (RANNIS)(grant numbers:217771051); National Science Centre of Poland(grant numbers:2020/37/B/ST7/01448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363873","Antenna optimization;EM-driven design;multi-criterial design;Pareto front triangulation;surrogate modeling","Antennas;Optimization;Ultra wideband antennas;Task analysis;Computational modeling;Reflector antennas;Rendering (computer graphics)","antenna arrays;electrical engineering computing;interpolation;learning (artificial intelligence);Pareto optimisation;prediction theory;reliability","multiobjective optimization;Pareto set;numerically challenging task;high CPU cost;full-wave electromagnetic analysis;surrogate-assisted procedures;deterministic machine learning procedure;Pareto-optimal designs;local surrogate-assisted refinement procedures;antenna EM simulations;rapid multicriterial antenna optimization;interpolative design predictors;stringent performance requirements;electrical field properties;nonlinear antenna characteristics;metamodel reliability","","1","","67","CCBY","26 Feb 2021","","","IEEE","IEEE Journals"
"On generalisation of machine learning with neural-evolutionary computations","R. Kumar","Dept. of Comput. Sci., Birla Inst. of Technol. & Sci., Pilani, India","Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300)","6 Aug 2002","1999","","","112","116","Generalisation is a non-trivial problem in machine learning and more so with neural networks which have the capabilities of inducing varying degrees of freedom. It is influenced by many factors in network design, such as network size, initial conditions, learning rate, weight decay factor, pruning algorithms, and many more. In spite of continuous research efforts, we could not arrive at a practical solution which can offer a superior generalisation. We present a novel approach for handling complex problems of machine learning. A multiobjective genetic algorithm is used for identifying (near-) optimal subspaces for hierarchical learning. This strategy of explicitly partitioning the data for subsequent mapping onto a hierarchical classifier is found both to reduce the learning complexity and the classification time. The classification performance of various algorithms is compared and it is argued that the neural modules are superior for learning the localised decision surfaces of such partitions and offer better generalisation.","","0-7695-0300-4","10.1109/ICCIMA.1999.798512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798512","","Machine learning;Learning systems;Robots;Bismuth;Algorithm design and analysis;Genetics;Partitioning algorithms;Lab-on-a-chip;Sampling methods;Interpolation","learning (artificial intelligence);generalisation (artificial intelligence);neural nets;computational complexity;pattern classification;evolutionary computation","machine learning generalisation;neural-evolutionary computations;non-trivial problem;neural networks;network design;network size;initial conditions;learning rate;weight decay factor;pruning algorithms;multiobjective genetic algorithm;hierarchical learning;data partitioning;hierarchical classifier;learning complexity;classification time;classification performance;neural modules;localised decision surfaces","","","","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Fine-Grained Powercap Allocation for Power-Constrained Systems Based on Multi-Objective Machine Learning","M. Hao; W. Zhang; Y. Wang; G. Lu; F. Wang; A. V. Vasilakos","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Electrical and Data Engineering, University Technology Sydney, Ultimo, NSW, Australia","IEEE Transactions on Parallel and Distributed Systems","19 Feb 2021","2021","32","7","1789","1801","Power capping is an important solution to keep the system within a fixed power constraint. However, for the over-provisioned and power-constrained systems, especially the future exascale supercomputers, powercap needs to be reasonably allocated according to the workloads of compute nodes to achieve trade-offs among performance, energy and powercap. Thus it is necessary to model performance and energy and to predict the optimal powercap allocation strategies. Existing power allocation approaches have insufficient granularity within nodes. Modeling approaches usually model performance and energy separately, ignoring the correlation between objectives, and do not expose the Pareto-optimal powercap configurations. Therefore, this article combines the powercap with uncore frequency scaling and proposes an approach to predict the Pareto-optimal powercap configurations on the power-constrained system for input MPI and OpenMP parallel applications. Our approach first uses the elaborately designed micro-benchmarks and a small number of existing benchmarks to build the training set, and then applies a multi-objective machine learning algorithm which combines the stacked single-target method with extreme gradient boosting to build multi-objective models of performance and energy. The models can be used to predict the optimal processor and memory powercap settings, helping compute nodes perform fine-grained powercap allocation. When the optimal powercap configuration is determined, the uncore frequency scaling is used to further optimize the energy consumption. Compared with the reference powercap configuration, the predicted optimal configurations predicted by our method can achieve an average powercap reduction of 31.35 percent, an average energy reduction of 12.32 percent, and average performance degradation of only 2.43 percent.","1558-2183","","10.1109/TPDS.2020.3045983","National Key Research and Development Program of China(grant numbers:2017YFB0202901); Key-Area Research and Development Program of Guangdong Province(grant numbers:2019B010136001); National Natural Science Foundation of China(grant numbers:61672186); Shenzhen Science and Technology Research and Development Foundation(grant numbers:JCYJ20190806143418198); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301369","Power capping;performance and energy modeling;pareto front;multi-objective machine learning","Resource management;Random access memory;Mathematical model;Computational modeling;Energy consumption;Analytical models;Benchmark testing","application program interfaces;energy consumption;learning (artificial intelligence);message passing;microprocessor chips;multiprocessing systems;parallel machines;Pareto optimisation;power aware computing","power constraint;power-constrained systems;future exascale supercomputers;optimal powercap allocation strategies;power allocation approaches;Pareto-optimal powercap configurations;power-constrained system;multiobjective machine learning algorithm;fine-grained powercap allocation;energy consumption;reference powercap configuration;predicted optimal configurations;energy reduction;power capping;powercap reduction;OpenMP parallel application;MPI parallel application;efficiency 31.35 percent;efficiency 12.32 percent;efficiency 2.43 percent","","4","","41","IEEE","21 Dec 2020","","","IEEE","IEEE Journals"
"Design-Space Exploration of Pareto-Optimal Architectures for Deep Learning with DVFS","G. Santoro; M. R. Casu; V. Peluso; A. Calimera; M. Alioto","Politecnico di Torino, DET, Italy; Politecnico di Torino, DET, Italy; Politecnico di Torino, DAUIN, Italy; Politecnico di Torino, DAUIN, Italy; National University of Singapore, ECE","2018 IEEE International Symposium on Circuits and Systems (ISCAS)","4 May 2018","2018","","","1","5","Specialized computing engines are required to accelerate the execution of Deep Learning (DL) algorithms in an energy-efficient way. To adapt the processing throughput of these accelerators to the workload requirements while saving power, Dynamic Voltage and Frequency Scaling (DVFS) seems the natural solution. However, DL workloads need to frequently access the off-chip memory, which tends to make the performance of these accelerators memory-bound rather than computation-bound, hence reducing the effectiveness of DVFS. In this work we use a performance-power analytical model fitted on a parametrized implementation of a DL accelerator in a 28-nm FDSOI technology to explore a large design space and to obtain the Pareto points that maximize the effectiveness of DVFS in the sub-space of throughput and energy efficiency. In our model we consider the impact on performance and power of the off-chip memory using real data of a commercial low-power DRAM.","2379-447X","978-1-5386-4881-0","10.1109/ISCAS.2018.8351685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8351685","","Random access memory;Throughput;Bandwidth;Clocks;Analytical models;Computational modeling;Computer architecture","DRAM chips;low-power electronics;Pareto optimisation;silicon-on-insulator","deep learning algorithms;dynamic voltage;frequency scaling;FDSOI technology;low-power DRAM;energy efficiency;Pareto points;DL accelerator;performance-power analytical model;accelerators memory-bound;off-chip memory;DL workloads;specialized computing engines;DVFS;Pareto-optimal architectures;design-space exploration;size 28 nm;Si","","4","","15","","4 May 2018","","","IEEE","IEEE Conferences"
"Approximating Pareto Optimal Set by An Incremental Learning Model","T. Liu; S. Song; X. Li; L. Tan","Harbin Institute of Technology,Center for Control Theory and Guidance Technology,Harbin,China; Harbin Institute of Technology,Center for Control Theory and Guidance Technology,Harbin,China; Shenzhen Institute of Information Technology,Sino-German Robotics School,Shenzhen,China; Harbin Institute of Technology,Research Center of Basic Space Science,Harbin,China","2021 IEEE Congress on Evolutionary Computation (CEC)","9 Aug 2021","2021","","","169","176","Combining a machine learning model within the search procedure has shown great potentials in evolutionary multiobjective optimization (EMO). The priori knowledge obtained from the property of Pareto optimal set (PS) is a great help for reproducing high-quality offspring solutions. However, the existing learning model in the framework of EMO is also accompanied with a high computational cost resulted from its iterative strategy or repetitive learning. To overcome this shortcoming, the paper proposes to approximate the PS by an incremental learning model. Specifically, it consists of two interdependent parts, i.e., a learning module and a forgetting module. The basic idea is to take the all new high-quality offspring solutions at the current evolution iteration as a data stream, and incrementally train a model based on Gaussian mixture models with the data stream to discover the manifold structure of the PS and guide the evolutionary search. The learning module is used to obtain the knowledge from the data stream in a batch manner, while the forgetting module is applied to delete the information from the relatively poor solution as is removed incrementally. The proposed algorithm is employed to test suites, and the numerical experiments demonstrates that the incremental learning model can help to improve the algorithm performance with less computational cost compared with the representative algorithms.","","978-1-7281-8393-0","10.1109/CEC45853.2021.9504996","National Natural Science Foundation of China; National Natural Science Foundation of China; China Academy of Space Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504996","","Manifolds;Computational modeling;Machine learning;Pareto optimization;Approximation algorithms;Data models;Computational efficiency","evolutionary computation;Gaussian processes;learning (artificial intelligence);mixture models;Pareto optimisation","Pareto optimal set;incremental learning model;machine learning model;evolutionary multiobjective optimization;repetitive learning;data stream;Gaussian mixture models","","","","25","","9 Aug 2021","","","IEEE","IEEE Conferences"
"MLComp: A Methodology for Machine Learning-based Performance Estimation and Adaptive Selection of Pareto-Optimal Compiler Optimization Sequences","A. Colucci; D. Juhász; M. Mosbeck; A. Marchisio; S. Rehman; M. Kreutzer; G. Nadbath; A. Jantsch; M. Shafique","Institute of Computer Engineering, Technische Universität Wien (TUWien),Vienna,Austria; TU Wien, Christian Doppler Laboratory for Embedded Machine Learning,Vienna,Austria; TU Wien, Christian Doppler Laboratory for Embedded Machine Learning,Vienna,Austria; Institute of Computer Engineering, Technische Universität Wien (TUWien),Vienna,Austria; TU Wien, Christian Doppler Laboratory for Embedded Machine Learning,Vienna,Austria; ABIX GmbH,Vienna,Austria; ABIX GmbH,Vienna,Austria; TU Wien, Christian Doppler Laboratory for Embedded Machine Learning,Vienna,Austria; New York University Abu Dhabi,Division of Engineering,UAE","2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)","16 Jul 2021","2021","","","108","113","Embedded systems have proliferated in various consumer and industrial applications with the evolution of Cyber-Physical Systems and the Internet of Things. These systems are subjected to stringent constraints so that embedded software must be optimized for multiple objectives simultaneously, namely reduced energy consumption, execution time, and code size. Compilers offer optimization phases to improve these metrics. However, proper selection and ordering of them depends on multiple factors and typically requires expert knowledge. State-of-the-art optimizers facilitate different platforms and applications case by case, and they are limited by optimizing one metric at a time, as well as requiring a time-consuming adaptation for different targets through dynamic profiling. To address these problems, we propose the novel MLComp methodology, in which optimization phases are sequenced by a Reinforcement Learning-based policy. Training of the policy is supported by Machine Learning-based analytical models for quick performance estimation, thereby drastically reducing the time spent for dynamic profiling. In our framework, different Machine Learning models are automatically tested to choose the best-fitting one. The trained Performance Estimator model is leveraged to efficiently devise Reinforcement Learning-based multi-objective policies for creating quasi-optimal phase sequences. Compared to state-of-the-art estimation models, our Performance Estimator model achieves lower relative error (< 2%) with up to 50 × faster training time over multiple platforms and application domains. Our Phase Selection Policy improves execution time and energy consumption of a given code by up to 12% and 6%, respectively. The Performance Estimator and the Phase Selection Policy can be trained efficiently for any target platform and application domain.","1558-1101","978-3-9819263-5-4","10.23919/DATE51398.2021.9474158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474158","","Measurement;Training;Adaptation models;Analytical models;Energy consumption;Sequential analysis;Estimation","embedded systems;learning (artificial intelligence);optimising compilers;Pareto optimisation","embedded software;reduced energy consumption;execution time;code size;optimization phases;state-of-the-art optimizers;applications case;time-consuming adaptation;dynamic profiling;quick performance estimation;quasioptimal phase sequences;state-of-the-art estimation models;training time;application domains;target platform;application domain;adaptive selection;pareto-optimal compiler optimization sequences;embedded systems;industrial applications;cyber-physical systems;Internet of Things;stringent constraints;machine learning-based performance estimation;phase selection policy;performance estimator model;reinforcement learning-based multiobjective policies;trained performance estimator model;machine learning-based analytical models;reinforcement learning-based policy;MLComp methodology","","","","43","","16 Jul 2021","","","IEEE","IEEE Conferences"
"Multiview Synthetic Aperture Radar Automatic Target Recognition Optimization: Modeling and Implementation","J. Pei; Y. Huang; Z. Sun; Y. Zhang; J. Yang; T. -S. Yeo","Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Geoscience and Remote Sensing","25 Oct 2018","2018","56","11","6425","6439","Multiview synthetic aperture radar (SAR) images could provide much richer information for automatic target recognition (ATR) than from a single-view image. It is desirable to find optimal SAR platform flight paths and acquire a sequence of SAR images from appropriate views, so that multiview SAR ATR can be carried out accurately and efficiently. In this paper, a novel optimization framework for multiview SAR ATR is proposed and implemented. The geometry of the multiview SAR ATR is modeled according to the recognition mission and flight environment. Then, the multiview SAR ATR is abstracted and transformed into a constrained multiobjective optimization problem with objective functions considering the tradeoffs between recognition performance and efficiency and security. A specific approach based on convolutional neural network ensemble and constrained nondominated sorting genetic algorithm II is employed to solve the multiobjective optimization, and optimal flight paths and corresponding imaging viewpoints are obtained. The SAR sensor can thus choose an applicable flight path to acquire the multiview SAR images from different tradeoff solutions according to application requirements. Finally, accurate recognition results can be obtained based on those multiview SAR images. Extensive experiments have shown the validity and superiority of the proposed optimization framework of multiview SAR ATR.","1558-0644","","10.1109/TGRS.2018.2838593","National Natural Science Foundation of China(grant numbers:61671117); Collaborative Innovation Center of Information Sensing and Understanding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383689","Automatic target recognition (ATR);convolutional neural network (CNN);ensemble learning;multiview;optimization;synthetic aperture radar (SAR)","Synthetic aperture radar;Optimization;Image recognition;Target recognition;Reconnaissance;Geometry;Imaging","genetic algorithms;neural nets;object detection;object recognition;optimisation;radar imaging;radar target recognition;synthetic aperture radar","flight environment;constrained multiobjective optimization problem;nondominated sorting genetic algorithm;synthetic aperture radar images;synthetic aperture radar automatic target recognition optimization;multiview SAR images;multiview SAR ATR;optimal SAR platform flight paths","","7","","39","IEEE","12 Jun 2018","","","IEEE","IEEE Journals"
"SPIRIT: Spectral-Aware Pareto Iterative Refinement Optimization for Supervised High-Level Synthesis","S. Xydis; G. Palermo; V. Zaccaria; C. Silvano","Institute of Communication and Computer Systems, National Technical University of Athens, Athens, Greece; Dipartimento di ElettronicaPolitecnico di Milano, Informazione e Bioingegneria, Milan, Italy; Dipartimento di ElettronicaPolitecnico di Milano, Informazione e Bioingegneria, Milan, Italy; Dipartimento di ElettronicaPolitecnico di Milano, Informazione e Bioingegneria, Milan, Italy","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","18 Dec 2014","2015","34","1","155","159","Supervised high-level synthesis (HLS) is a new class of design problems where exploration strategies play the role of supervisor for tuning an HLS engine. The complexity of the problem is increased due to the large set of tunable parameters exposed by the “new wave” of HLS tools that include not only architectural alternatives but also compiler transformations. In this paper, we developed a novel exploration approach, called spectral-aware Pareto iterative refinement, that exploits response surface models (RSMs) and spectral analysis for predicting the quality of the design points without resorting to costly architectural synthesis procedures. We show that the target solution space can be accurately modeled through RSMs, thus enabling a speedup of the overall exploration without compromising the quality of results. Furthermore, we introduce the usage of spectral techniques to find high variance regions of the design space that require analysis for improving the RSMs prediction accuracy.","1937-4151","","10.1109/TCAD.2014.2363392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6930749","system level design;high level synthesis;design space exploration;machine learning;spectral analysis;Design space exploration (DSE);high-level synthesis (HLS);machine learning;spectral analysis;system level design","Spectral analysis;Accuracy;Measurement;Optimization;Space exploration;Training;High level synthesis","circuit optimisation;electronic engineering computing;high level synthesis;integrated circuit design;learning (artificial intelligence);Pareto optimisation;spectral analysis","design points quality prediction;spectral analysis;response surface model;problem complexity;HLS engine tuning;exploration strategy;supervised high level synthesis;spectral aware Pareto iterative refinement optimization;SPIRIT","","29","","26","IEEE","20 Oct 2014","","","IEEE","IEEE Journals"
"PDM: Privacy-Aware Deployment of Machine-Learning Applications for Industrial Cyber–Physical Cloud Systems","X. Xu; R. Mo; X. Yin; M. R. Khosravi; F. Aghaei; V. Chang; G. Li","School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Facility Horticulture Laboratory of Universities in Shandong, Weifang University of Science and Technology, Shouguang, China; Department of Computer Engineering, Persian Gulf University, Bushehr, Iran; Department of Electrical and Electronics Engineering, Ozyegin University, Orman, Istanbul, Turkey; Engineering and Digital Technologies, School of Computing, Teesside University, Middlesbrough, U.K.; School of Computer Science, Qufu Normal University, Qufu, China","IEEE Transactions on Industrial Informatics","4 May 2021","2021","17","8","5819","5828","The cyber-physical cloud systems (CPCSs) release powerful capability in provisioning the complicated industrial services. Due to the advances of machine learning (ML) in attack detection, a wide range of ML applications are involved in industrial CPCSs. However, how to ensure the implementation efficiency of these applications, and meanwhile avoid the privacy disclosure of the datasets due to data acquisition by different operators, remain challenging for the design of the CPCSs. To fill this gap, in this article a privacy-aware deployment method (PDM), named PDM, is devised for hosting the ML applications in the industrial CPCSs. In PDM, the ML applications are partitioned as multiple computing tasks with certain execution order, like workflows. Specifically, the deployment problem is formulated as a multiobjective problem for improving the implementation performance and resource utility. Then, the most balanced and optimal strategy is selected by leveraging an improved differential evolution technique. Finally, through comprehensive experiments and comparison analysis, PDM is fully evaluated.","1941-0050","","10.1109/TII.2020.3031440","Financial and Science Technology Plan Project of Xinjiang Production and Construction Corps(grant numbers:2020DB005); National Natural Science Foundation of China(grant numbers:61702277); Priority Academic Program Development of Jiangsu Higher Education Institutions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226095","Cyber–physical cloud systems (CPCSs);machine learning (ML);nondominated sorting differential evolution (NSDE);privacy-aware deployment","Machine learning;Task analysis;Security;Data acquisition;Cloud computing;Data privacy;Informatics","cloud computing;data acquisition;data privacy;evolutionary computation;learning (artificial intelligence)","machine-learning applications;industrial cyber-physical cloud systems;cyber-physical cloud systems release powerful capability;complicated industrial services;machine learning;ML applications;industrial CPCSs;privacy disclosure;privacy-aware deployment method;deployment problem;named PDM","","13","","26","IEEE","15 Oct 2020","","","IEEE","IEEE Journals"
"NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory Learning for Autonomous Vehicles","S. M. Grigorescu; B. Trasnea; L. Marina; A. Vasilcoi; T. Cocias","Elektrobit Automotive and the Robotics, Vision and Control Lab (ROVIS) (www.rovislab.com), Transilvania University of Braşov, Braşov, Romania; Elektrobit Automotive and the Robotics, Vision and Control Lab (ROVIS) (www.rovislab.com), Transilvania University of Braşov, Braşov, Romania; Elektrobit Automotive and the Robotics, Vision and Control Lab (ROVIS) (www.rovislab.com), Transilvania University of Braşov, Braşov, Romania; Elektrobit Automotive and the Robotics, Vision and Control Lab (ROVIS) (www.rovislab.com), Transilvania University of Braşov, Braşov, Romania; Elektrobit Automotive and the Robotics, Vision and Control Lab (ROVIS) (www.rovislab.com), Transilvania University of Braşov, Braşov, Romania","IEEE Robotics and Automation Letters","24 Jul 2019","2019","4","4","3441","3448","Autonomous vehicles are controlled today either based on sequences of decoupled perception-planning-action operations, either based on End2End or deep reinforcement learning (DRL) systems. Current deep learning solutions for autonomous driving are subject to several limitations (e.g., they estimate driving actions through a direct mapping of sensors to actuators, or require complex reward shaping methods). Although the cost function used for training can aggregate multiple weighted objectives, the gradient descent step is computed by the backpropagation algorithm using a single-objective loss. To address these issues, we introduce NeuroTrajectory, which is a multiobjective neuroevolutionary approach to local state trajectory learning for autonomous driving, where the desired state trajectory of the ego-vehicle is estimated over a finite prediction horizon by a perception-planning deep neural network. In comparison to DRL methods, which predict optimal actions for the upcoming sampling time, we estimate a sequence of optimal states that can be used for motion control. We propose an approach which uses genetic algorithms for training a population of deep neural networks, where each network individual is evaluated based on a multi-objective fitness vector, with the purpose of establishing a so-called Pareto front of optimal deep neural networks. The performance of an individual is given by a fitness vector composed of three elements. Each element describes the vehicle's travel path, lateral velocity and longitudinal speed, respectively. The same network structure can be trained on synthetic, as well as on real-world data sequences. We have benchmarked our system against a baseline Dynamic Window Approach (DWA), as well as against an End2End supervised learning method.","2377-3766","","10.1109/LRA.2019.2926224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752412","","Trajectory;Autonomous vehicles;Neural networks;Task analysis;Estimation;Training;Pipelines","backpropagation;control engineering computing;genetic algorithms;gradient methods;learning (artificial intelligence);mobile robots;motion control;neural nets;robot dynamics;traffic engineering computing;vectors;vehicle dynamics;vehicles","NeuroTrajectory;local state trajectory learning;autonomous vehicles;decoupled perception-planning-action operations;End2End;deep reinforcement learning systems;autonomous driving;multiple weighted objectives;gradient descent step;single-objective loss;multiobjective neuroevolutionary approach;finite prediction horizon;perception-planning deep neural network;DRL methods;multiobjective fitness vector;backpropagation algorithm;genetic algorithms;motion control;dynamic window approach;deep learning","","17","1","18","IEEE","1 Jul 2019","","","IEEE","IEEE Journals"
"Maximizing sensitivity in medical diagnosis using biased minimax probability Machine","Kaizhu Huang; Haiqin Yang; Irwin King; M. R. Lyu","Inf. Technol. Lab., Fujitsu Res. & Dev. Center Co, Beijing, China; NA; NA; NA","IEEE Transactions on Biomedical Engineering","18 Apr 2006","2006","53","5","821","831","The challenging task of medical diagnosis based on machine learning techniques requires an inherent bias, i.e., the diagnosis should favor the ""ill"" class over the ""healthy"" class, since misdiagnosing a patient as a healthy person may delay the therapy and aggravate the illness. Therefore,the objective in this task is not to improve the overall accuracy of the classification,but to focus on improving the sensitivity (the accuracy of the ""ill"" class) while maintaining an acceptable specificity (the accuracy of the ""healthy"" class). Some current methods adopt roundabout ways to impose a certain bias toward the important class, i.e., they try to utilize some intermediate factors to influence the classification. However, it remains uncertain whether these methods can improve the classification performance systematically. In this paper, by engaging a novel learning tool, the biased minimax probability machine(BMPM), we deal with the issue in a more elegant way and directly achieve the objective of appropriate medical diagnosis. More specifically, the BMPM directly controls the worst case accuracies to incorporate a bias toward the ""ill"" class. Moreover, in a distribution-free way, the BMPM derives the decision rule in such a way as to maximize the worst case sensitivity while maintaining an acceptable worst case specificity. By directly controlling the accuracies,the BMPM provides a more rigorous way to handle medical diagnosis; by deriving a distribution-free decision rule, the BMPM distinguishes itself from a large family of classifiers, namely, the generative classifiers, where an assumption on the data distribution is necessary. We evaluate the performance of the model and compare it with three traditional classifiers: the k-nearest neighbor, the naive Bayesian, and the C4.5. The test results on two medical datasets, the breast-cancer dataset and the heart disease dataset, show that the BMPM outperforms the other three models.","1558-2531","","10.1109/TBME.2006.872819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1621133","Biased classification;medical diagnosis;minimax probability machine;worst case accuracy","Medical diagnosis;Minimax techniques;Machine learning;Delay;Medical treatment;Medical control systems;Bayesian methods;Medical tests;Medical diagnostic imaging;Breast cancer","cardiology;biological organs;gynaecology;learning (artificial intelligence);minimax techniques;probability;Bayes methods;medical image processing;image classification","worst case sensitivity;medical diagnosis;biased minimax probability machine;machine learning;distribution-free decision rule;worst case specificity;k-nearest neighbor classifiers;Bayesian classifiers;C4.5 classifiers;breast cancer dataset;heart disease dataset","Algorithms;Breast Neoplasms;Computer Simulation;Decision Support Systems, Clinical;Decision Support Techniques;Diagnosis, Computer-Assisted;Heart Diseases;Humans;Models, Statistical;Reproducibility of Results;Sensitivity and Specificity","28","","35","IEEE","18 Apr 2006","","","IEEE","IEEE Journals"
"A minimax theorem with applications to machine learning, signal processing, and finance","Seung-Jean Kim; S. Boyd","Information Systems Laboratory Electrical Engineering Department, Stanford University, CA 94305-9510 USA; Information Systems Laboratory Electrical Engineering Department, Stanford University, CA 94305-9510 USA","2007 46th IEEE Conference on Decision and Control","21 Jan 2008","2007","","","751","758","This paper concerns a fractional function of the form x<sup>T</sup>a/√x<sup>T</sup>Bx, where B is positive definite. We consider the game of choosing χ from a convex set, to maximize the function, and choosing (a, B) from a convex set, to minimize it. We prove the existence of a saddle point and describe an efficient method, based on convex optimization, for computing it. We describe applications in machine learning (robust Fisher linear discriminant analysis), signal processing (robust beamforming, robust matched filtering), and finance (robust portfolio selection). In these applications, χ corresponds to some design variables to be chosen, and the pair (a, B) corresponds to the statistical model, which is uncertain.","0191-2216","978-1-4244-1497-0","10.1109/CDC.2007.4434853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4434853","","Minimax techniques;Machine learning;Signal processing;Finance;Robustness;Optimization methods;Linear discriminant analysis;Nonlinear filters;Matched filters;Filtering","convex programming;finance;game theory;learning (artificial intelligence);minimax techniques;set theory;signal processing","minimax theorem;game;convex set;convex optimization;machine learning;signal processing;finance;statistical model","","1","","28","","21 Jan 2008","","","IEEE","IEEE Conferences"
"Transfer Learning Through Deep Learning: Application to Topology Optimization of Electric Motor","J. Asanuma; S. Doi; H. Igarashi","Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan","IEEE Transactions on Magnetics","19 Feb 2020","2020","56","3","1","4","This article proposes the use of transfer learning for the deep neural network to reduce the computing cost of the topology optimization of electric motors based on a genetic algorithm (GA). The average torque and torque ripple values are shown to be accurately inferred by the transfer learning with small learning data. The individuals on the Pareto front are only evaluated by the finite-element method, while others are fast evaluated only by convolutional neural networks (CNNs). The proposed method makes it possible to reduce the computing cost to less than 15% of the conventional topology optimization method.","1941-0069","","10.1109/TMAG.2019.2956849","Japan Society for the Promotion of Science(grant numbers:18K18840); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8959397","Deep learning;electric motor;regression;topology optimization;transfer learning","Optimization;Topology;Torque;Training;Computational modeling;Network topology;Data models","convolutional neural nets;electric machine analysis computing;electric motors;finite element analysis;genetic algorithms;learning (artificial intelligence);Pareto optimisation","transfer learning;learning data;convolutional neural networks;computing cost reduction;conventional topology optimization method;deep learning;electric motor;deep neural network;average torque;torque ripple values;Pareto front;finite-element method;CNNs","","13","","9","IEEE","14 Jan 2020","","","IEEE","IEEE Journals"
"Scalable Pareto Front Approximation for Deep Multi-Objective Learning","M. Ruchte; J. Grabocka","University of Freiburg,Freiburg,Germany; University of Freiburg,Freiburg,Germany","2021 IEEE International Conference on Data Mining (ICDM)","24 Jan 2022","2021","","","1306","1311","Multi-objective optimization is important for various Deep Learning applications, however, no prior multi-objective method suits very deep networks. Existing approaches either require training a new network for every solution on the Pareto front or add a considerable overhead to the number of parameters by introducing hyper-networks conditioned on modifiable preferences. In this paper, we present a novel method that contextualizes the network directly on the preferences by adding them to the input space. In addition, we ensure a well-spread Pareto front by forcing the solutions to preserve a small angle to the preference vector. Through extensive experiments, we demonstrate that our Pareto fronts achieve state-of-the-art quality despite being computed significantly faster. Furthermore, we demonstrate the scalability as our method approximates the full Pareto front on the CelebA dataset with an EfficientNet network at a marginal training time overhead of 7% compared to a single-objective optimization. We make the code publicly available at https://github.com/ruchtem/cosmos.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00162","BrainLinks-BrainTools; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679014","Multi-objective optimization;Deep Learning;Fairness","Training;Deep learning;Scalability;Conferences;Neural networks;Predictive models;Data mining","","","","","","26","","24 Jan 2022","","","IEEE","IEEE Conferences"
"Incremental Cross-Domain Adaptation for Robust Retinopathy Screening via Bayesian Deep Learning","T. Hassan; B. Hassan; M. U. Akram; S. Hashmi; A. H. Taguri; N. Werghi","Department of Computer and Software Engineering, National University of Sciences and Technology, Islamabad, Pakistan; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Department of Computer and Software Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Department of Internal Medicine, Mayo Clinic, Rochester, MN, USA; Abu Dhabi Healthcare Company (SEHA), Abu Dhabi, United Arab Emirates; Department of Electrical Engineering and Computer Science, Center for Cyber-Physical Systems (C2PS), Khalifa University, Abu Dhabi, United Arab Emirates","IEEE Transactions on Instrumentation and Measurement","4 Nov 2021","2021","70","","1","14","Retinopathy represents a group of retinal diseases that, if not treated timely, can cause severe visual impairments or even blindness. Many researchers have developed autonomous systems to recognize retinopathy via fundus and optical coherence tomography (OCT) imagery. However, most of these frameworks employ conventional transfer learning and fine-tuning approaches, requiring a decent amount of well-annotated training data to produce accurate diagnostic performance. This article presents a novel incremental cross-domain adaptation instrument that allows any deep classification model to progressively learn abnormal retinal pathologies in OCT and fundus imagery via few-shot training. Furthermore, unlike its competitors, the proposed instrument is driven via a Bayesian multiobjective function that not only enforces the candidate classification network to retain its prior learned knowledge during incremental training, but also ensures that the network understands the structural and semantic relationships between previously learned pathologies and newly added disease categories to effectively recognize them at the inference stage. The proposed framework, evaluated on six public datasets acquired with three different scanners to screen 13 retinal pathologies, outperforms the state-of-the-art competitors by achieving an overall accuracy and F1 score of 0.9826 and 0.9846, respectively.","1557-9662","","10.1109/TIM.2021.3122172","Khalifa University through a Research Fund(grant numbers:CIRA-2019-047); Abu Dhabi Department of Education and Knowledge (ADEK)(grant numbers:AARE19-156); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9584873","Bayesian deep learning;fundus photography;incremental domain adaptation (DA);optical coherence tomography;retinopathy","Retina;Pathology;Training;Retinopathy;Adaptation models;Image recognition;Deep learning","Bayes methods;biomedical optical imaging;diseases;eye;learning (artificial intelligence);medical image processing;optical tomography;pattern classification","well-annotated training data;accurate diagnostic performance;incremental cross-domain adaptation instrument;deep classification model;abnormal retinal pathologies;fundus imagery;few-shot training;Bayesian multiobjective function;candidate classification network;prior learned knowledge;incremental training;structural relationships;semantic relationships;learned pathologies;disease categories;13 retinal pathologies;robust retinopathy screening;Bayesian deep learning;retinal diseases;severe visual impairments;blindness;autonomous systems;conventional transfer learning;fine-tuning approaches","","","","60","IEEE","22 Oct 2021","","","IEEE","IEEE Journals"
"A study of Pareto-based methods for ensemble pool generation and aggregation","V. H. Alves Ribeiro; G. Reynoso-Meza","Industrial and Systems Engineering Graduate Program, Pontifícia Universidade Católica do Paraná (PUCPR), Curitiba, Brazil; Industrial and Systems Engineering Graduate Program, Pontifícia Universidade Católica do Paraná (PUCPR), Curitiba, Brazil","2019 IEEE Congress on Evolutionary Computation (CEC)","8 Aug 2019","2019","","","2145","2152","In the field of machine learning, the application of ensemble methods is one of the most successful techniques in order to achieve a good performance in classification tasks. The combination of multiple classifiers is able to achieve better results than a single model, and much effort has been put into applying multi-objective optimisation for improving results with diverse ensemble generation and classifier aggregation. Most recently, dynamic classifier selection and weighting has acquired relevance in the field of multiple-classifier systems. However, to the authors knowledge, there has not yet been a comparison study of Pareto based techniques and dynamic ensemble methods. Thus, this paper proposes a comparison of two ensemble member generation techniques (Pareto-based diverse ensemble generation and bootstrap aggregating) and five aggregation methods (selection of the best classifier, majority voting with all members, majority voting with members selected with multi-objective optimisation, dynamic classifier selection and dynamic classifier weighting), performed on six binary classification benchmark data sets. Results indicate that the combination of bootstrap aggregating and majority voting with multi-objective ensemble member selection achieves the best performance.","","978-1-7281-2153-6","10.1109/CEC.2019.8790291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790291","Ensemble methods;multi-objective optimisation;supervised learning.","Computational modeling;Predictive models;Data models;Optimization;Bagging;Training","learning (artificial intelligence);Pareto optimisation;pattern classification","ensemble pool generation;multiobjective optimisation;dynamic classifier selection;multiple-classifier systems;dynamic ensemble methods;ensemble member generation techniques;Pareto-based diverse ensemble generation;dynamic classifier weighting;multiobjective ensemble member selection;bootstrap aggregation method","","","","24","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Application of Bayesian Machine Learning To Create A Low-Cost Silicon Failure Mechanism Pareto","C. Schuermyer; S. Palosh; P. Babighian; Y. Pan","Synopsys, Inc., Mountain View, CA, 94043; Synopsys, Inc., Mountain View, CA, 94043; Synopsys, Inc., Mountain View, CA, 94043; Synopsys, Inc., Mountain View, CA, 94043","2019 30th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)","8 Aug 2019","2019","","","1","5","The increasing challenges with relying on Physical Failure Analysis and inline inspection for ramping the yield are the reason that Volume Scan Diagnostics Analysis (VSDA) has become a mainstream methodology that supplements traditional yield learning. Because scan diagnostics are inherently noisy, the results often require expert knowledge to manually select the location that has the highest likelihood of being correct. In this paper, Failure Mechanism Analysis (FMA) applies the technique of Bayesian Machine Learning in a yield analysis system that can empirically estimate sources of yield loss using physical diagnostic information.","2376-6697","978-1-5386-7601-1","10.1109/ASMC.2019.8791833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791833","","Failure analysis;Probability distribution;Bayes methods;Machine learning;Silicon;Sociology;Statistics","Bayes methods;electronic engineering computing;failure analysis;inspection;learning (artificial intelligence);semiconductor device manufacture;semiconductor device reliability;semiconductor device testing","low-cost silicon failure mechanism pareto;inline inspection;Volume Scan Diagnostics Analysis;expert knowledge;Failure Mechanism Analysis;yield analysis system;yield loss;physical diagnostic information;Bayesian machine learning;yield learning;FMA;VSDA;physical failure analysis","","1","","14","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Robust transfer learning in multi-robot systems by using sparse autoencoder","L. V. Utkin; S. G. Popov; Y. A. Zhuk","Telematics Department, Peter the Great Saint-Petersburg Polytechnic University, Russia; Telematics Department, Peter the Great Saint-Petersburg Polytechnic University, Russia; Dept. of Computer Educational Technologies, ITMO University, St. Petersburg, Russia","2016 XIX IEEE International Conference on Soft Computing and Measurements (SCM)","25 Jul 2016","2016","","","224","227","Robust algorithms for transfer learning in multirobot systems based on elements of the deep learning are proposed in the paper. The algorithms are based on using the sparse autoencoder. The main ideas underlying the algorithms are to extend the set of set-valued observations by training examples having uncertain weights and to apply the robust minimax strategy in order to find an optimal autoencoder for dealing with set-valued observations. An interesting scheme for transfer learning is considered for which source learning set is reconstructed by means of the sparse autoencoder trained on the target learning set.","","978-1-4673-8919-8","10.1109/SCM.2016.7519735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7519735","multi-robot system;deep learning;transfer learning;sparse autoencoder;extreme points;minimax strategy","Training;Robots;Sensors;Robustness;Training data;Uncertainty;Machine learning","learning (artificial intelligence);minimax techniques;multi-robot systems;neural nets;robust control;set theory","robust transfer learning;multirobot systems;sparse autoencoder;deep-learning;set-valued observations;uncertain weights;robust minimax strategy;optimal autoencoder;source learning set;target learning set","","2","","10","","25 Jul 2016","","","IEEE","IEEE Conferences"
"sEMG Signal Classification Using Ensemble Learning Classification Approach and DWT","N. Thakur; L. Mathew","Department of Electrical Engineering, National Institute of Technical Teachers Training and Research, Chandigarh, India; Department of Electrical Engineering, National Institute of Technical Teachers Training and Research, Chandigarh, India","2018 International Conference on Current Trends towards Converging Technologies (ICCTCT)","29 Nov 2018","2018","","","1","4","Nowadays surface electromyography (sEMG) signals play a very authoritative role in facilitating a neuromuscular disordered person and disabled person to live a smooth life. This offline study mainly focuses on the denoising, feature extraction and classification of the sEMG signals with discrete wavelet packet transform (DWT) with ensemble support vector machine (SVM) classification approach. In this work DWT (db 2, 4<sup>th</sup> level) is selected for denoising and TFD feature extraction to form feature vectors and soft thresholding method (minimax) was utilized and the threshold value was taken as 2.991. The classification accuracy is 98% is achieved at the better precision and speed of response for elbow movement. feature vectors and soft thresholding method (minimax) was utilized and the threshold value was taken as 2.991. The classification accuracy is 98% is achieved at the better precision and speed of response for elbow movement.","","978-1-5386-3702-9","10.1109/ICCTCT.2018.8551098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8551098","sEMG- Suface Electromyography Signal;DWT- discrete Wavelet Transform;WGN- White Gaussian Noise;SVM- Support Vector Machine","Electromyography;Feature extraction;Discrete wavelet transforms;Wavelet packets;Time-domain analysis;Frequency-domain analysis","discrete wavelet transforms;electromyography;feature extraction;learning (artificial intelligence);medical signal processing;signal classification;support vector machines","neuromuscular disabled person;discrete wavelet packet transform;surface electromyography signals;signal denoising;ensemble support vector machine classification approach;sEMG signals;neuromuscular disordered person;authoritative role;ensemble learning classification approach;sEMG signal classification;elbow movement;classification accuracy;minimax;soft thresholding method;TFD feature extraction","","2","","11","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Study of the approximation of the fitness landscape and the ranking process of scalarizing functions for many-objective problems","G. Toscano; K. Deb","CINVESTAV-Tamaulipas, Cd. Victoria, Tamaulipas, 87130, Mexico; Michigan State University, East Lansing, MI, USA","2016 IEEE Congress on Evolutionary Computation (CEC)","21 Nov 2016","2016","","","4358","4365","Although surrogate models have been successfully adopted by evolutionary algorithms to solve time-consuming multiobjective problems, their use has been confined to solving problems with a low number of objectives. On the other hand, scalarizing functions have proved to work well with many-objective problems. This paper presents a novel study on many-objective optimization concerning the use of surrogate models to approximate both (1) the fitness landscape of traditional multiobjective approaches and (2) the ranking relation imposed by such approaches. Our methodology involves a thorough comparison of four popular surrogate modeling techniques in order to approximate the fitness landscape and the ranking relations of three different scalarizing functions. Additionally, we explored the interactions of these methods through four well-known scalable test problems with four, six, eight, and ten objectives. Besides finding that Tchebycheff scalarizing function and Gaussian processes for machine learning are accurate methods to handle many-objective problems, one of our most important findings involves the capabilities of metamodeling techniques to approximate the ranking procedure from the information gathered from the parameter space. Such a capability can be effectively used for pre-screening purposes on MOEAs.","","978-1-5090-0623-6","10.1109/CEC.2016.7744344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744344","","Metamodeling;Optimization;Evolutionary computation;Linear programming;Computational modeling;Regression tree analysis;Algorithm design and analysis","approximation theory;evolutionary computation;functions;Gaussian processes;learning (artificial intelligence);optimisation","fitness landscape;ranking process;surrogate models;many-objective optimization;ranking relation;Tchebycheff scalarizing function;Gaussian processes;machine learning;metamodeling techniques;parameter space;MOEA;evolutionary algorithms","","3","","34","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Combining Machine Learning and Multi Criteria Decision Analysis Modeling Regulatory, Economic and Social Influences on Wind Turbine Allocation","L. Lück; A. Moser","RWTH Aachen University, Institute of Power Systems and Power Economics, Aachen, Germany; RWTH Aachen University, Institute of Power Systems and Power Economics, Aachen, Germany","2018 15th International Conference on the European Energy Market (EEM)","23 Sep 2018","2018","","","1","5","Knowledge about the future allocation of wind turbines is relevant for assessments of energy markets or necessary grid expansions. In Germany, political decisions drive the allocation together with investment decisions, social rejections, land use planning, regional development and ecological aspects. Taking all influences into account, a standardized multi-criteria optimization problem combining economic suitability, residential burden and site suitability calculates the regional distribution of wind turbines as input for further assessments. By considering the political framework as boundary conditions for the optimization and detailed geographic area suitability factors using a machine learning approach as input parameters, it is possible to assess effects of regulatory restrictions on regional developments. We use a backtesting for validation and weighting of the objectives. Sensitivities of changing regulatory frameworks modeled as different boundary conditions show effects of changing political decisions.","2165-4093","978-1-5386-1488-4","10.1109/EEM.2018.8470016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8470016","Wind Energy Integration;Power System Planning;Distributed Power Generation;Pareto Optimization;Machine Learning","Wind turbines;Resource management;Optimization;Economics;Brain modeling;Entropy;Boundary conditions","decision making;investment;land use planning;learning (artificial intelligence);optimisation;power engineering computing;wind turbines","grid expansions;geographic area suitability factors;regulatory frameworks;regional developments;regulatory restrictions;machine learning approach;political framework;regional distribution;site suitability;residential burden;economic suitability;standardized multicriteria optimization problem;ecological aspects;regional development;land use planning;social rejections;investment decisions;political decisions;energy markets;wind turbines;wind turbine allocation;social influences","","1","","16","","23 Sep 2018","","","IEEE","IEEE Conferences"
"Minimax Modifications of Linear Discriminant Analysis for Classification with Rare Classes","K. Bratanova; I. Kareev; R. Salimov","Kazan Federal University,Department of Mathematical Statistics,Kazan,Russian Federation; Kazan Federal University,Department of Mathematical Statistics,Kazan,Russian Federation; Kazan Federal University,Department of Mathematical Statistics,Kazan,Russian Federation","2020 IEEE East-West Design & Test Symposium (EWDTS)","15 Oct 2020","2020","","","1","5","We consider the problem of classification for imbalanced samples with rare classes. A common problem for machine learning methods in such setting is that a rare class would have extremely high classification error compared to more widespread classes. In general, this problem could be mitigated with re-sampling or fitting additional weights to control the classification errors in classes, though those methods are computationally expensive for large datasets and sometimes fail to attain appropriate results. It this paper we present cost-efficient modifications of Linear Discriminant Analysis allowing to mitigate the problem by minimizing maximal classification error among the classes. For example, this allows achieving more robust machinery malfunction detection algorithms where our expectations on recall would be more consistent among different malfunction types.","2472-761X","978-1-7281-9899-6","10.1109/EWDTS50664.2020.9224895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224895","classification;imbalanced sample dataset;rare class;linear discriminant analysis;minimax error","Decision trees;Random forests;Machine learning;Training;Logistics;Linear discriminant analysis;Glass","learning (artificial intelligence);minimax techniques;pattern classification;statistical analysis","minimax modifications;linear discriminant analysis;cost-efficient modifications;maximal classification error;machinery malfunction detection algorithms","","","","14","","15 Oct 2020","","","IEEE","IEEE Conferences"
"A Robust Machine Learning Method for Cell-Load Approximation in Wireless Networks","D. A. Awan; R. L. G. Cavalcante; S. Stanczak","Technical University of Berlin, Einsteinufer 27, Berlin, 10587, Germany; Technical University of Berlin, Einsteinufer 27, Berlin, 10587, Germany; Technical University of Berlin, Einsteinufer 27, Berlin, 10587, Germany","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","2601","2605","We propose a learning algorithm for cell-load approximation in wireless networks. The proposed algorithm is robust in the sense that it is designed to cope with the uncertainty arising from a small number of training samples. This scenario is highly relevant in wireless networks where training has to be performed on short time scales because of a fast time-varying communication environment. The first part of this work studies the set of feasible rates and shows that this set is compact. We then prove that the mapping relating a feasible rate vector to the unique fixed point of the non-linear cell-load mapping is monotone and uniformly continuous. Utilizing these properties, we apply an approximation framework that achieves the best worst-case performance. Furthermore, the approximation preserves the monotonicity and continuity properties. Simulations show that the proposed method exhibits better robustness and accuracy for small training sets in comparison with standard approximation techniques for multivariate data.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462320","machine learning;5G;multivariate scattered data;data interpolation;minimax approximation","Load modeling;Robustness;Machine learning;Approximation algorithms;Machine learning algorithms;Training;Wireless networks","approximation theory;cellular radio;learning (artificial intelligence);radio networks;time-varying systems","approximation framework;continuity properties;standard approximation techniques;cell-load approximation;wireless networks;nonlinear cell-load mapping;monotonicity properties;robust machine learning","","5","","20","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Constrained Multi-Objective Optimization for Automated Machine Learning","S. Gardner; O. Golovidov; J. Griffin; P. Koch; W. Thompson; B. Wujek; Y. Xu",SAS Institute Inc.; SAS Institute Inc.; SAS Institute Inc.; SAS Institute Inc.; SAS Institute Inc.; SAS Institute Inc.; SAS Institute Inc.,"2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)","23 Jan 2020","2019","","","364","373","Automated machine learning has gained a lot of attention recently. Building and selecting the right machine learning models is often a multi-objective optimization problem. General purpose machine learning software that simultaneously supports multiple objectives and constraints is scant, though the potential benefits are great. In this work, we present a framework called Autotune that effectively handles multiple objectives and constraints that arise in machine learning problems. Autotune is built on a suite of derivative-free optimization methods, and utilizes multi-level parallelism in a distributed computing environment for automatically training, scoring, and selecting good models. Incorporation of multiple objectives and constraints in the model exploration and selection process provides the flexibility needed to satisfy trade-offs necessary in practical machine learning applications. Experimental results from standard multi-objective optimization benchmark problems show that Autotune is very efficient in capturing Pareto fronts. These benchmark results also show how adding constraints can guide the search to more promising regions of the solution space, ultimately producing more desirable Pareto fronts. Results from two real-world case studies demonstrate the effectiveness of the constrained multi-objective optimization capability offered by Autotune.","","978-1-7281-4493-1","10.1109/DSAA.2019.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964219","Multi-objective Optimization;Automated Machine Learning;Distributed Computing System","","evolutionary computation;learning (artificial intelligence);Pareto optimisation","Autotune;derivative-free optimization methods;multilevel parallelism;model exploration;selection process;practical machine learning applications;constrained multiobjective optimization capability","","4","","42","","23 Jan 2020","","","IEEE","IEEE Conferences"
"HyperASPO: Fusion of Model and Hyper Parameter Optimization for Multi-objective Machine Learning","A. Kannan; A. Roy Choudhury; V. Saxena; S. Raje; P. Ram; A. Verma; Y. Sabharwal","IBM Research,India; IBM Research,India; IBM Research,India; University of Utah,United States; IBM Research,United States; IBM Research,United States; IBM Research,India","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","790","800","Current state of the art methods for generating Pareto-optimal solutions for multi-objective optimization problems mostly rely on optimizing the hyper-parameters of the models (HPO - hyper-parameter Optimization). Few recent, less studied methods focus on optimizing over the space of model parameters, leveraging the problem specific knowledge. We present a generic first-of-a-kind method, referred to as HyperASPO, that combines optimization over the spaces of both hyper-parameters and model parameters for multi-objective optimization of learning problems. HyperASPO consists of two stages. First, we perform a coarse HPO to determine a set of favorable hyper-parameter configurations. In the second step, for each of these configurations, we solve a sequence of weighted single objective optimization problems for estimating Pareto-optimal solutions. We generate the weights in the second step using an adaptive mesh constructed iteratively based on the metrics of interest, resulting in further refinement of Pareto frontier efficiently. We consider the widely used XGBoost (Gradient Boosted Trees) model and validate our method on multiple classification datasets. Our proposed method shows up to 20% improvement over the hypervolumes of Pareto fronts obtained through state of the art HPO based methods with up to 2× reduction in computational time.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671604","Hyperparameter optimization;Model parameters;XGBoost;HyperASPO;Pareto Optimization","Measurement;Adaptation models;Computational modeling;Conferences;Machine learning;Big Data;Data models","","","","","","40","","13 Jan 2022","","","IEEE","IEEE Conferences"
"Pareto-Optimal Bit Allocation for Collaborative Intelligence","S. R. Alvar; I. V. Bajić","School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada; School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada","IEEE Transactions on Image Processing","3 Mar 2021","2021","30","","3348","3361","In recent studies, collaborative intelligence (CI) has emerged as a promising framework for deployment of Artificial Intelligence (AI)-based services on mobile/edge devices. In CI, the AI model (a deep neural network) is split between the edge and the cloud, and intermediate features are sent from the edge sub-model to the cloud sub-model. In this article, we study bit allocation for feature coding in multi-stream CI systems. We model task distortion as a function of rate using convex surfaces similar to those found in distortion-rate theory. Using such models, we are able to provide closed-form bit allocation solutions for single-task systems and scalarized multi-task systems. Moreover, we provide analytical characterization of the full Pareto set for 2-stream k-task systems, and bounds on the Pareto set for 3-stream 2-task systems. Analytical results are examined on a variety of DNN models from the literature to demonstrate wide applicability of the results.","1941-0042","","10.1109/TIP.2021.3060875","Natural Sciences and Engineering Research Council (NSERC)(grant numbers:RGPIN-2016-04590); Huawei; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364873","Bit allocation;rate distortion optimization;collaborative intelligence;multi objective optimization;deep learning;multi-task learning","Tensors;Task analysis;Image coding;Bit rate;Nonlinear distortion;Distortion measurement;Optimization","deep learning (artificial intelligence);error statistics;Pareto optimisation;resource allocation;video coding","2-stream k-task systems;edge devices;mobile devices;AI-based services;convex surfaces;model task distortion;multistream CI systems;feature coding;intermediate features;deep neural network;AI model;artificial intelligence-based services;collaborative intelligence;Pareto-optimal bit allocation;DNN models;3-stream 2-task systems;Pareto set;scalarized multitask systems;single-task systems;closed-form bit allocation solutions;distortion-rate theory","","2","","47","IEEE","26 Feb 2021","","","IEEE","IEEE Journals"
"A Deep Learning Model Based on Multi-Objective Particle Swarm Optimization for Scene Classification in Unmanned Aerial Vehicles","A. Rajagopal; G. P. Joshi; A. Ramachandran; R. T. Subhalakshmi; M. Khari; S. Jha; K. Shankar; J. You","Department of IT, Sethu Institute of Technology, Kariapatti, India; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; University College of Engineering, Panruti, India; Department of Information Technology, Sethu Institute of Technology, Kariapatti, India; Computer Science Department, Ambedkar Institute of Technology, New Delhi, Delhi, India; School of Computer Science and Engineering, Lovely Professional University, Phagwara, India; Department of Computer Applications, Karaikudi, India; Seculayer Company, Ltd., Seoul, South Korea","IEEE Access","31 Jul 2020","2020","8","","135383","135393","Recently, the increase in inexpensive and compact unmanned aerial vehicles (UAVs) and light-weight imaging sensors has led to an interest in using them in various remote sensing applications. The processes of collecting, calibrating, registering, and processing data from miniature UAVs and interpreting the data semantically are time-consuming. In UAV aerial imagery, learning effective image representations is central to the scene classification process. Earlier approaches to the scene classification process depended on feature coding methods with low-level hand-engineered features or unsupervised feature learning. These methods could produce mid-level image features with restricted representational abilities, which generally yielded mediocre results. The development of convolutional neural networks (CNNs) has made image classification more efficient. Due to the limited resources in UAVs, it is hard to fine-tune the hyperparameters and the trade-offs between classifier results and computation complexity. This paper introduces a new multi-objective optimization model for evolving state-of-the-art deep CNNs for scene classification, which generates the non-dominant solutions in an automated way at the Pareto front. We use a set of two benchmark datasets to test the performance of the scene classification model and make a detailed comparative study. The proposed method attains a very low computational time of 80 sec and maximum accuracy of 97.88% compared to all other methods. The proposed method is found to be appropriate for the effective scene classification of images captured by UAVs.","2169-3536","","10.1109/ACCESS.2020.3011502","Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea Government (MSIP)(grant numbers:2020-0-00107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146631","Unmanned aerial vehicle;particle swarm optimization;deep learning;convolutional neural networks;machine learning;internet of everything;aerial images;smart environment","Unmanned aerial vehicles;Machine learning;Visualization;Feature extraction;Image classification;Training","autonomous aerial vehicles;convolutional neural nets;feature extraction;geophysical image processing;image classification;image representation;learning (artificial intelligence);particle swarm optimisation;remote sensing;remotely operated vehicles","midlevel image features;effective scene classification;scene classification model;deep CNN;multiobjective optimization model;image classification;restricted representational abilities;unsupervised feature learning;low-level hand-engineered features;scene classification process;effective image representations;UAV aerial imagery;remote sensing applications;light-weight imaging sensors;compact unmanned aerial vehicles;multiobjective particle swarm optimization","","22","","38","CCBY","23 Jul 2020","","","IEEE","IEEE Journals"
"A Multiple Gradient Descent Design for Multi-Task Learning on Edge Computing: Multi-Objective Machine Learning Approach","X. Zhou; Y. Gao; C. Li; Z. Huang","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Kensington, NSW, Australia; School of Automation, Central South University, Changsha, China","IEEE Transactions on Network Science and Engineering","12 Jan 2022","2022","9","1","121","133","Multi-task learning technique is widely utilized in machine learning modeling where commonalities and differences across multiple tasks are exploited. However, multiple conflicting objectives often occur in multi-task learning. Conventionally, a common compromise is to minimize the weighted sum of multiple objectives which may be invalid if the objectives are competing. In this paper, a novel multi-objective machine learning approach is proposed to solve this challenging issue, which reformulates the multi-task learning as multi-objective optimization. To address the issues contributed by existing multi-objective optimization algorithms, a multi-gradient descent algorithm is introduced for the multi-objective machine learning problem by which an innovative gradient-based optimization is leveraged to converge to an optimal solution of the Pareto set. Moreover, the gradient surgery for the multi-gradient descent algorithm is proposed to obtain a stable Pareto optimal solution. As most of the edge computing devices are computational resource-constrained, the proposed method is implemented for optimizing the edge device's memory, computation and communication demands. The proposed method is applied to the multiple license plate recognition problem. The experimental results show that the proposed method outperforms state-of-the-art learning methods and can successfully find solutions that balance multiple objectives of the learning task over different datasets.","2327-4697","","10.1109/TNSE.2021.3067454","National Natural Science Foundation of China(grant numbers:72088101); National Natural Science Foundation of China(grant numbers:61873285); National Key Research and Development Program of China(grant numbers:2018AAA0101603); National Natural Science Foundation of China(grant numbers:61860206014); Hunan Provincial Science and Technology Research Foundation of China(grant numbers:2019RS1003); Australian Research Council(grant numbers:DP200101197,DE210100274); State Key Laboratory of Synthetical Automation for Process Industries; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382101","Deep neural network;edge computing;multi-objective machine learning;multi-task learning;multiple gradient descent","Task analysis;Optimization;Machine learning algorithms;Learning systems;Edge computing;Deep learning;Surgery","gradient methods;learning (artificial intelligence);optimisation;Pareto optimisation","multiple gradient descent design;multitask learning technique;multiple conflicting objectives;novel multiobjective machine learning approach;existing multiobjective optimization algorithms;multigradient descent algorithm;multiobjective machine learning problem;state-of-the-art learning methods;balance multiple objectives;learning task","","1","","28","IEEE","19 Mar 2021","","","IEEE","IEEE Journals"
"Interval-based algorithms to extract fuzzy measures for Software Quality Assessment","X. Wang; A. F. G. Contreras; M. Ceberio; C. Del Hoyo; L. C. Gutierrez; S. Virane","Computer Science Department, The University of Texas at El Paso, El Paso, Texas 79968-0518; Computer Science Department, The University of Texas at El Paso, El Paso, Texas 79968-0518; Computer Science Department, The University of Texas at El Paso, El Paso, Texas 79968-0518; Computer Science Department, The University of Texas at El Paso, El Paso, Texas 79968-0518; Computer Science Department, The University of Texas at El Paso, El Paso, Texas 79968-0518; Computer Science Department, The University of Texas at El Paso, El Paso, Texas 79968-0518","2012 Annual Meeting of the North American Fuzzy Information Processing Society (NAFIPS)","30 Aug 2012","2012","","","1","6","In this paper, we consider the problem of automatically assessing sofware quality. We show that we can look at this problem, called Software Quality Assessment (SQA), as a multicriteria decision-making problem. Indeed, just like software is assessed along different criteria, Multi-Criteria Decision Making (MCDM) is about decisions that are based on several criteria that are usually conflicting and non-homogenously satisfied. Nonadditive (fuzzy) measures along with the Choquet integral can be used to model and aggregate the levels of satisfaction of these criteria by considering their relationships. However, in practice, fuzzy measures are difficult to identify. An automated process is necessary and possible when sample data is available. Several optimization approaches have been proposed to extract fuzzy measures from sample data; e.g., genetic algorithms, gradient descent algorithms, and the Bees algorithm, all local search techniques. In this article, we propose a hybrid approach, combining the Bees algorithm and an interval constraint solver, resulting in a focused search expected to be less prone to falling into local results. Our approach, when tested on SQA decision data, shows promise and compares well to previous approaches to SQA that were using machine learning techniques.","","978-1-4673-2338-3","10.1109/NAFIPS.2012.6291044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6291044","","Object oriented modeling;Software quality;Optimization;Measurement;Predictive models;Data mining","decision making;fuzzy set theory;learning (artificial intelligence);optimisation;software quality","interval-based algorithms;fuzzy measures;software quality assessment;SQA;multicriteria decision making problem;MCDM;Choquet integral;optimization;machine learning","","2","","26","","30 Aug 2012","","","IEEE","IEEE Conferences"
"Autonomic Management of a Building’s Multi-HVAC System Start-Up","J. Aguilar; A. Garcés-Jiménez; J. M. Gómez-Pulido; M. D. R. Moreno; J. A. G. De Mesa; N. Gallego-Salvador","Centro de Microcomputación y Sistemas Distribuidos (CEMISID), Universidad de Los Andes, Mérida, Venezuela; Centro de Innovación Experimental del Conocimiento (CEIEC), Universidad Francisco de Vitoria, Pozuelo de Alarcón, Spain; Departamento Ciencias de la Computación, Universidad de Alcalá, Alcalá de Henares, Spain; Departamento de Automatica, Universidad de Alcalá, Alcalá de Henares, Spain; Departamento Ciencias de la Computación, Universidad de Alcalá, Alcalá de Henares, Spain; Departamento Ciencias de la Computación, Universidad de Alcalá, Alcalá de Henares, Spain","IEEE Access","17 May 2021","2021","9","","70502","70515","Most studies about the control, automation, optimization and supervision of building HVAC systems concentrate on the steady-state regime, i.e., when the equipment is already working at its setpoints. The originality of the current work consists of proposing the optimization of building multi-HVAC systems from start-up until they reach the setpoint, making the transition to steady state-based strategies smooth. The proposed approach works on the transient regime of multi-HVAC systems optimizing contradictory objectives, such as the desired comfort and energy costs, based on the “Autonomic Cycle of Data Analysis Tasks” concept. In this case, the autonomic cycle is composed of two data analysis tasks: one for determining if the system is going towards the defined operational setpoint, and if that is not the case, another task for reconfiguring the operational mode of the multi-HVAC system to redirect it. The first task uses machine learning techniques to build detection and prediction models, and the second task defines a reconfiguration model using multiobjective evolutionary algorithms. This proposal is proven in a real case study that characterizes a particular multi-HVAC system and its operational setpoints. The performance obtained from the experiments in diverse situations is impressive since there is a high level of conformity for the multi-HVAC system to reach the setpoint and deliver the operation to the steady-state smoothly, avoiding overshooting and other non-desirable transitional effects.","2169-3536","","10.1109/ACCESS.2021.3078550","European Union’s Horizon 2020 Research and Innovation Program through the Marie Skłodowska Curie(grant numbers:754382); Smart Energy Campus of International Excellence; Universidad de Alcalá and the Universidad Rey Juan Carlos, Spain, through the research project: Intelligent Management System for Optimizing Energy Consumption in Building Air Conditioning; JCLM Project through the European Regional Development Fund (FEDER)(grant numbers:SBPLY/19/180501/000024); Spanish Ministry of Science and Innovation Project through the European Regional Development Fund (FEDER)(grant numbers:PID2019-109891RB-I00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426915","Energy management;heating;ventilation and air conditioning systems;autonomic computing;machine learning;multi-objective optimization;smart building","HVAC;Buildings;Optimization;Energy consumption;Genetic algorithms;Fault detection;Task analysis","building management systems;civil engineering computing;data analysis;evolutionary computation;HVAC;learning (artificial intelligence);optimisation","steady-state regime;steady state-based strategies;autonomic cycle;data analysis;autonomic management;building multiHVAC system start-up;nondesirable transitional effects;machine learning","","2","","43","CCBY","10 May 2021","","","IEEE","IEEE Journals"
"Minimax lower bounds for ridge combinations including neural nets","J. M. Klusowski; A. R. Barron","Department of Statistics, Yale University, New Haven, CT, USA; Department of Statistics, Yale University, New Haven, CT, USA","2017 IEEE International Symposium on Information Theory (ISIT)","14 Aug 2017","2017","","","1376","1380","Estimation of functions of d variables is considered using ridge combinations of the form Σ<sub>k=1</sub><sup>m</sup> c<sub>1, k</sub>Φ(Σ<sub>j=1</sub><sup>d</sup>c<sub>0, j, k</sub>x<sub>j</sub>-b<sub>k</sub>) where the activation function Φ is a function with bounded value and derivative. These include single-hidden layer neural networks, polynomials, and sinusoidal models. From a sample of size n of possibly noisy values at random sites X ϵ B = [-1, 1]<sup>d</sup>, the minimax mean square error is examined for functions in the closure of the ℓ<sub>1</sub> hull of ridge functions with activation Φ. It is shown to be of order d/n to a fractional power (when d is of smaller order than n), and to be of order (log d)/n to a fractional power (when d is of larger order than n). Dependence on constraints v<sub>0</sub> and v<sub>1</sub> on the ℓ<sub>1</sub> norms of inner parameter co and outer parameter c<sub>1</sub>, respectively, is also examined. Also, lower and upper bounds on the fractional power are given. The heart of the analysis is development of information-theoretic packing numbers for these classes of functions.","2157-8117","978-1-5090-4096-4","10.1109/ISIT.2017.8006754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8006754","Nonparametric regression;nonlinear regression;neural nets;penalization;machine learning;high-dimensional data analysis;learning theory;generalization error;greedy algorithms;metric entropy;packing sets;polynomial nets;sinusoidal nets;constant weight codes","Neural networks;Upper bound;Estimation;Measurement;Entropy;Complexity theory;Information theory","mean square error methods;minimax techniques;neural nets;polynomials;random processes","ridge combinations;single-hidden layer neural networks;polynomials;sinusoidal models;noisy values;random sites;minimax mean square error;fractional power;inner parameter;outer parameter;upper bounds;information-theoretic packing numbers;minimax lower bounds;function estimation","","6","","26","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Sequential Minimax Search for Multi-Layer Gene Grouping","W. Wang; X. Zhou; F. Chen; B. Cao","College of Computer Science and Software Engineering, Big Data Institute, Shenzhen University, Shenzhen, China; Guangdong Academy of Agricultural Sciences, Guangzhou, China; School of International Trade and Economics, University of International Business and Economics, Beijing, China; Department of mathematics, Sun Yat-sen University, Guangzhou, China","IEEE Access","7 Aug 2019","2019","7","","102931","102940","Many areas of exploratory data analysis need to deal with high-dimensional data sets. Some real life data like human gene have an inherent structure of hierarchy, which embeds multi-layer feature groups. In this paper, we propose an algorithm to search for the number of feature groups in high-dimensional data by sequential minimax method and detect the hierarchical structure of high-dimensional data. Several proper numbers of feature grouping can be discovered. The feature grouping and group weights are investigated for each group number. After the comparison of feature groupings, the multi-layer structure of feature groups is detected. The latent feature group learning (LFGL) algorithm is proposed to evaluate the effectiveness of the number of feature groups and provide a method of subspace clustering. In the experiments on several gene data sets, the proposed algorithm outstands several representative algorithms.","2169-3536","","10.1109/ACCESS.2019.2924491","Guangzhou Science and Technology Plan Project “Guangdong Provincial Modern Agri-tech Transfer and Demonstration Center Construction”(grant numbers:201806040001); Guangdong Academy of Agricultural Sciences Dean Fund Project “Research on the Integration of Key Elements in the Construction of Agri-tech Transformation Service Platform”(grant numbers:201829); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744237","Machine learning;evolutionary computing;feature grouping;high-dimensional data analysis;gene grouping;knowledge transfer","Clustering algorithms;Search problems;Biological cells;Machine learning algorithms;Machine learning;Feature extraction;Indexes","bioinformatics;data analysis;genetics;learning (artificial intelligence);minimax techniques;pattern clustering","feature grouping;multilayer structure;latent feature group;gene data sets;high-dimensional data sets;multilayer feature groups;group weights;group number;exploratory data analysis;sequential minimax search;latent feature group learning algorithm;LFGL algorithm","","","","37","CCBY","24 Jun 2019","","","IEEE","IEEE Journals"
"Deep Belief Network Enabled Surrogate Modeling for Fast Preventive Control of Power System Transient Stability","T. Su; Y. Liu; J. Zhao; J. Liu","College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA; College of Electrical Engineering, Sichuan University, Chengdu, China","IEEE Transactions on Industrial Informatics","5 Oct 2021","2022","18","1","315","326","The widely used transient stability-constrained optimal power flow (TSC-OPF) method for power system preventive control is very time-consuming and thus not applicable for large-scale systems. This article proposes a new deep learning-enabled surrogate model that can significantly improve computational efficiency while maintaining high accuracy. To achieve that, the deep belief network (DBN) is strategically integrated with the reference-point-based nondominated sorting genetic algorithm (NSGA-III) to develop a new preventive control framework. The DBN allows us to identify the mapping relationship between the transient stability index and system operational features. The identified functional mapping relationship is further used as the surrogate to connect the DBN results with TSC-OPF for preventive control. The integrated NSGA-III and surrogate model enable the multiobjective optimization to consider various constraints and objectives, such as minimization of costs of generation dispatch cost and load shedding while maintaining the system stability. Extensive simulation results on several IEEE test systems show that the proposed method can achieve highly efficient control solutions and outperform other alternatives in terms of computational efficiency and economic benefits.","1941-0050","","10.1109/TII.2021.3072594","National Natural Science Foundation of China(grant numbers:51977133); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9403930","Deep belief network (DBN);deep learning;nondominated sorting genetic algorithm (NSGA-III);surrogate model;transient stability preventive control","Power system stability;Transient analysis;Stability criteria;Generators;Computational modeling;Load modeling;Optimization","belief networks;genetic algorithms;load flow;load shedding;optimisation;Pareto optimisation;power generation dispatch;power system security;power system transient stability;sorting","TSC-OPF;power system preventive control;large-scale systems;deep learning-enabled surrogate model;computational efficiency;reference-point-based;preventive control framework;transient stability index;system operational features;identified functional mapping relationship;DBN results;integrated NSGA-III;multiobjective optimization;system stability;IEEE test systems;highly efficient control solutions;deep belief network enabled surrogate modeling;fast preventive control;power system transient stability;widely used transient stability-constrained optimal power flow","","","","26","IEEE","13 Apr 2021","","","IEEE","IEEE Journals"
"Feature selection for facilitation of evolutionary multi-objective design optimization: Application to IPM motor design problems","A. Salimi; D. A. Lowther","McGill University, Department of Electrical and Computer Engineering, Montreal QC, Canada; McGill University, Department of Electrical and Computer Engineering, Montreal QC, Canada","2016 IEEE Conference on Electromagnetic Field Computation (CEFC)","16 Jan 2017","2016","","","1","1","This paper discusses the application of statistical analysis and machine learning techniques, more specifically Correlation Feature Selection (CFS), in multi-objective design optimization of problems where the computational cost (of optimization) is dominated by the cost of solution evaluations, e.g. electromagnetic shape design problems. Here, CFS is used in order to reduce the dimensionality of the design space. As demonstrated through an Internal Permanent Magnet (IPM) motor design problem, the reduction information can be useful in decreasing the cost of optimization as well as detecting the dependencies of different variables in the vicinity of the optima.","","978-1-5090-1032-5","10.1109/CEFC.2016.7816205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816205","Design Optimization;Dimensionality Reduction;Feature Selection;Machine Learning;Pareto Optimization","Correlation;Permanent magnet motors;Design optimization;Computational modeling;Permanent magnets;Algorithm design and analysis","learning (artificial intelligence);permanent magnet motors;power engineering computing;statistical analysis","feature selection;evolutionary multiobjective design optimization;IPM motor design problems;correlation feature selection;computational cost;electromagnetic shape design problems;internal permanent magnet motor design;reduction information;optimization cost","","","","4","","16 Jan 2017","","","IEEE","IEEE Conferences"
"Wrapper Framework for Test-Cost-Sensitive Feature Selection","L. Jiang; G. Kong; C. Li","Department of Computer Science, China University of Geosciences, Wuhan, China; Hubei Key Laboratory of Intelligent Geo-Information Processing, China University of Geosciences, Wuhan, China; Department of Mathematics, China University of Geosciences, Wuhan, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","16 Feb 2021","2021","51","3","1747","1756","Feature selection is an optional preprocessing procedure and is frequently used to improve the classification accuracy of a machine learning algorithm by removing irrelevant and/or redundant features. However, in many real-world applications, the test cost is also required for making optimal decisions, in addition to the classification accuracy. To the best of our knowledge, thus far, few studies have been conducted on test-cost-sensitive feature selection (TCSFS). In TCSFS, the objectives are twofold: 1) to improve the classification accuracy and 2) to decrease the test cost. Therefore, in fact, it constitutes a multiobjective optimization problem. In this paper, we transformed this multiobjective optimization problem into a single-objective optimization problem by utilizing a new evaluation function and in this paper, we propose a new general wrapper framework for TCSFS. Specifically, in our proposed framework, we add a new term to the evaluation function of a wrapper feature selection method so that the test cost of measuring features is taken into account. We experimentally tested our proposed framework, using 36 classification problems from the University of California at Irvine (UCI) repository, and compared it to some other state-of-the-art feature selection frameworks. The experimental results showed that our framework allows users to select an optimal feature subset with the minimal test cost, while simultaneously maintaining a high classification accuracy.","2168-2232","","10.1109/TSMC.2019.2904662","NSFC(grant numbers:U1711267,NCET-12-0953,KLIGIP201601); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674538","Classification accuracy;decision making;feature selection;test cost;test-cost-sensitive learning","Feature extraction;Optimization;Support vector machines;Geology;Training;Medical diagnosis;Data mining","cost reduction;feature selection;learning (artificial intelligence);optimisation;pattern classification","classification problems;machine learning algorithms;classification accuracy;evaluation function;feature measurement test cost;single-objective optimization problem;multiobjective optimization problem;test-cost-sensitive feature selection;optimal feature subset;wrapper feature selection method;TCSFS","","18","","52","IEEE","26 Mar 2019","","","IEEE","IEEE Journals"
"Training Confidence-Calibrated Classifier via Distributionally Robust Learning","H. Wu; M. D. Wang","Georgia Institute of Technology, USA; Georgia Institute of Technology and Emory University, USA","2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)","22 Sep 2020","2020","","","295","304","Supervised learning via empirical risk minimization, despite its solid theoretical foundations, faces a major challenge in generalization capability, which limits its application in real-world data science problems. In particular, current models fail to distinguish in-distribution and out-of-distribution and give over confident predictions for out-of-distribution samples. In this paper, we propose an distributionally robust learning method to train classifiers via solving an unconstrained minimax game between an adversary test distribution and a hypothesis. We showed the theoretical generalization performance guarantees, and empirically, our learned classifier when coupled with thresholded detectors, can efficiently detect out-of-distribution samples.","0730-3157","978-1-7281-7303-0","10.1109/COMPSAC48688.2020.0-230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201929","supervised learning;adversarial machine learning;robust machine learning;distributionally robust optimization","Training;Robustness;Supervised learning;Games;Machine learning;Data models;Neural networks","game theory;learning (artificial intelligence);pattern classification","training confidence-calibrated classifier;empirical risk minimization;solid theoretical foundations;generalization capability;real-world data science problems;confident predictions;out-of-distribution samples;distributionally robust learning method;unconstrained minimax game;adversary test distribution;theoretical generalization performance guarantees;learned classifier","","","","31","","22 Sep 2020","","","IEEE","IEEE Conferences"
"Deep Learning Empowered Traffic Offloading in Intelligent Software Defined Cellular V2X Networks","B. Fan; Z. He; Y. Wu; J. He; Y. Chen; L. Jiang","Beijing Key Laboratory of Traffic Engineering, College of Metropolitan Transportation, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Traffic Engineering, College of Metropolitan Transportation, Beijing University of Technology, Beijing, China; State Key Laboratory of Internet of Things for Smart City, University of Macau, Macau, China; Beijing Key Laboratory of Traffic Engineering, College of Metropolitan Transportation, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Traffic Engineering, College of Metropolitan Transportation, Beijing University of Technology, Beijing, China; Guangdong Key Laboratory of IoT Information Technology, School of Automation, Guangdong University of Technology, Guangzhou, China","IEEE Transactions on Vehicular Technology","12 Nov 2020","2020","69","11","13328","13340","The ever-increasing and unbalanced traffic load in cellular vehicle-to-everything (C-V2X) networks have increased the network congestion and led to user dissatisfaction. To relieve the network congestion and improve the traffic load balance, in this paper, we propose an intelligent software defined C-V2X network framework to enable flexible and low-complexity traffic offloading by decoupling the network data plane from the control plane. In the data plane, the cellular traffic offloading and the vehicle assisted traffic offloading are jointly performed. In the control plane, deep learning is deployed to reduce the software defined network (SDN) control complexity and improve the traffic offloading efficiency. Under the proposed framework, we investigate the traffic offloading problem, which can be formulated as a multi-objective optimization problem. Specifically, the first objective maximizes the cellular access point (AP) throughput with consideration of the load balance by associating the users with the APs. The second objective maximizes the vehicle throughput with consideration of the vehicle trajectory by associating the delay-insensitive users with the vehicles. The two objectives are coupled by the association between the cellular APs and the vehicles. A deep learning based online-offline approach is proposed to solve the multi-objective optimization problem. The online stage decouples the optimization problem into two sub-problems and utilizes the `Pareto optimal' to find the solutions. The offline stage utilizes deep learning to learn from the historical optimization information of the online stage and helps predict the optimal solutions with reduced complexity. Numerical results are provided to validate the advantages of our proposed traffic offloading approach via deep learning in C-V2X networks.","1939-9359","","10.1109/TVT.2020.3023194","National Natural Science Foundation of China(grant numbers:61901013,61701125); Macau University of Science and Technology Foundation(grant numbers:0060/2019/A1,0162/2019/A3); FDCT-MOST Joint Project(grant numbers:066/2019/AMJ); Research Grant of University of Macau(grant numbers:SRG2019-00168-IOTSC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195787","C-V2X networks;deep learning;software-defined-networking;traffic offloading","Machine learning;Optimization;Software;Computer architecture;Complexity theory;Quality of service;Throughput","cellular radio;intelligent networks;learning (artificial intelligence);Pareto optimisation;software defined networking;telecommunication traffic;vehicular ad hoc networks","intelligent software defined cellular V2X Networks;traffic offloading approach;online stage;delay-insensitive users;vehicle trajectory;cellular access point;multiobjective optimization problem;traffic offloading problem;traffic offloading efficiency;network control complexity;vehicle assisted traffic offloading;cellular traffic offloading;control plane;network data plane;low-complexity traffic offloading;C-V2X network framework;traffic load balance;user dissatisfaction;network congestion;cellular vehicle-to-everything;unbalanced traffic load;ever-increasing traffic load;deep learning","","3","","40","IEEE","14 Sep 2020","","","IEEE","IEEE Journals"
"An impossibility result for high dimensional supervised learning","M. H. Rohban; P. Ishwar; B. Orten; W. C. Karl; V. Saligrama","ECE Department Boston University; ECE Department Boston University; Turn, Inc. CA USA; ECE Department Boston University; ECE Department Boston University","2013 IEEE Information Theory Workshop (ITW)","23 Dec 2013","2013","","","1","5","We study high-dimensional asymptotic performance limits of binary supervised classification problems where the class conditional densities are Gaussian with unknown means and covariances and the number of signal dimensions scales faster than the number of labeled training samples. We show that the Bayes error, namely the minimum attainable error probability with complete distributional knowledge and equally likely classes, can be arbitrarily close to zero and yet the limiting minimax error probability of every supervised learning algorithm is no better than a random coin toss. In contrast to related studies where the classification difficulty (Bayes error) is made to vanish, we hold it constant when taking high-dimensional limits. In contrast to VC-dimension based minimax lower bounds that consider the worst case error probability over all distributions that have a fixed Bayes error, our worst case is over the family of Gaussian distributions with constant Bayes error. We also show that a nontrivial asymptotic minimax error probability can only be attained for parametric subsets of zero measure (in a suitable measure space). These results expose the fundamental importance of prior knowledge and suggest that unless we impose strong structural constraints, such as sparsity, on the parametric space, supervised learning may be ineffective in high dimensional small sample settings.","","978-1-4799-1323-7","10.1109/ITW.2013.6691252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6691252","","Error probability;Training;Maximum likelihood estimation;Supervised learning;Sensors;Measurement uncertainty;Gaussian distribution","Bayes methods;Gaussian distribution;learning (artificial intelligence);pattern classification","impossibility result;high dimensional supervised learning;high-dimensional asymptotic performance limits;binary supervised classification problems;class conditional densities;signal dimensions;labeled training samples;Bayes error;distributional knowledge;random coin toss;classification difficulty;VC-dimension based minimax lower bounds;worst case error probability;Gaussian distributions;structural constraints;parametric space","","1","","10","","23 Dec 2013","","","IEEE","IEEE Conferences"
"Scheduling of Deep Learning Applications Onto Heterogeneous Processors in an Embedded Device","D. Kang; J. Oh; J. Choi; Y. Yi; S. Ha","Department of Computer Engineering, Seoul National University, Seoul, South Korea; Department of Computer Engineering, Seoul National University, Seoul, South Korea; Department of Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, University of Seoul, Seoul, South Korea; Department of Computer Engineering, Seoul National University, Seoul, South Korea","IEEE Access","10 Mar 2020","2020","8","","43980","43991","As the need for on-device machine learning is increasing recently, embedded devices tend to be equipped with heterogeneous processors that include a multi-core CPU, a GPU, and/or a DNN accelerator called a Neural Processing Unit (NPU). In the scheduling of multiple deep learning (DL) applications in such embedded devices, there are several technical challenges. First, a task can be mapped onto a single core or any number of available cores. So we need to consider various possible configurations of CPU cores. Second, embedded devices usually apply Dynamic Voltage and Frequency Scaling (DVFS) to reduce energy consumption at run-time. We need to consider the effect of DVFS in the profiling of task execution times. Third, to avoid overheat condition, it is recommended to limit the core utilization. Lastly, some cores will be shut-down at run-time if core utilization is not high enough, in case the hot-plugging option is turned on. In this paper, we propose a scheduling technique based on Genetic Algorithm to run DL applications on heterogeneous processors, considering all those issues. First, we aim to optimize the throughput of a single deep learning application. Next, we aim to find the Pareto optimal scheduling of multiple DL applications in terms of the response time of each DL application and overall energy consumption under the given throughput constraints of DL applications. The proposed technique is verified with real DL networks running on two embedded devices, Galaxy S9 and HiKey970.","2169-3536","","10.1109/ACCESS.2020.2977496","National Research Foundation of Korea(grant numbers:2018R1D1A1B07050463); Ministry of Science, ICT and Future Planning(grant numbers:2019R1A2B5B02069406); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9019698","Deep learning scheduling;genetic algorithm;heterogeneous processor;mobile device","Task analysis;Program processors;Processor scheduling;Optimal scheduling;Scheduling;Schedules","embedded systems;genetic algorithms;graphics processing units;learning (artificial intelligence);multiprocessing systems;neural nets;Pareto optimisation;power aware computing;processor scheduling","heterogeneous processors;embedded device;on-device machine learning;multicore CPU;single core;core utilization;DL application;single deep learning application;DNN accelerator;neural processing unit;dynamic voltage and frequency scaling;DVFS;task execution;hot-plugging option;scheduling technique;genetic algorithm;Pareto optimal scheduling;energy consumption","","5","","33","CCBY","2 Mar 2020","","","IEEE","IEEE Journals"
"Minimax Learning for Remote Prediction","C. T. Li; X. Wu; A. Ozgur; A. El Gamal","University of California, Berkeley; Stanford University; Stanford University; Stanford University","2018 IEEE International Symposium on Information Theory (ISIT)","16 Aug 2018","2018","","","541","545","The classical problem of supervised learning is to infer an accurate predictor of a target variable Y from a measured variable X by using a finite number of labeled training samples. Motivated by the increasingly distributed nature of data and decision making, in this paper we consider a variation of this classical problem in which the prediction is performed remotely based on a rate-constrained description M of X. Upon receiving M, the remote node computes an estimate Y of Y. We follow the recent minimax approach to study this learning problem and show that it corresponds to a one-shot minimax noisy source coding problem. We then establish information theoretic bounds on the risk-rate Lagrangian cost and a general method to design a near-optimal descriptor-estimator pair, which can be viewed as a rate-constrained analog to the maximum conditional entropy principle used in the classical minimax learning problem. Our results show that a naive estimate-compress scheme for rate-constrained prediction is not in general optimal.","2157-8117","978-1-5386-4781-3","10.1109/ISIT.2018.8437318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437318","","Training;Supervised learning;Random variables;Entropy;Noise measurement;Source coding","learning (artificial intelligence);maximum entropy methods;minimax techniques;source coding;telecommunication computing","target variable;rate-constrained description;decision making;labeled training samples;finite number;supervised learning;remote prediction;rate-constrained prediction;naive estimate-compress scheme;classical minimax learning problem;rate-constrained analog;near-optimal descriptor-estimator pair;risk-rate Lagrangian cost;information theoretic bounds;one-shot minimax noisy source coding problem;remote node","","4","","16","","16 Aug 2018","","","IEEE","IEEE Conferences"
"The machine learning classifier based on Multi-Objective Genetic Algorithm","Zhou Litao; Wang Tiejun; Jiang Xi; Jin Jin","Science Technology and Information & Communication, Department, Sichuan Electric Power Corporation, Chengdu, China; College of Computer Science and Technology, Chengdu University of Information Technology, China; College of Computer Science and Technology, Chengdu University of Information Technology, China; College of Computer Science and Technology, Chengdu University of Information Technology, China","2012 7th International Conference on Computing and Convergence Technology (ICCCT)","13 Jun 2013","2012","","","405","409","This paper presents a machine learning classifier algorithm based on MOGA (Multi-Objective Genetic Algorithm), which applies the information entropy theory to optimize the MOGA and then can be used to discretize the continuous attributes. According to the practical problems, the fitness vector can be constructed by judging multi-objective functions to find the Pareto optimal solutions. Combining the classic set theories with the two relationships, i.e. coverage and contradictory, between chromosomes, more reasonable selection rules can be worked out to delete the redundant chromosomes and get more efficient classification rules. The new algorithm was applied to Iris and Wine dataset from UCI. By comparison, the algorithm in this paper has higher classification accuracy than KNN, C4.5 and NaiveBayes.","","978-89-94364-22-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6530367","Multi-Objective;MOGA;Pareto Optimization;Learning Classifier;Discrete;Delete Rule","","entropy;genetic algorithms;learning (artificial intelligence);pattern classification;set theory;vectors","machine learning classifier algorithm;MOGA;multiobjective genetic algorithm;information entropy theory;continuous attributes;fitness vector;multiobjective functions;Pareto optimal solutions;classic set theories;chromosomes;selection rules;redundant chromosomes;classification rules;Iris and Wine dataset;UCI;classification accuracy","","","","9","","13 Jun 2013","","","IEEE","IEEE Conferences"
"A Multi-objective Deep Reinforcement Learning Approach for Stock Index Future’s Intraday Trading","W. Si; J. Li; P. Ding; R. Rao","Sch. of Electron. Inf. & Electr. Eng., Shanghai Jiao Tong Univ., Shanghai, China; Sch. of Electron. Inf. & Electr. Eng., Shanghai Jiao Tong Univ., Shanghai, China; China Quantitative Investment Assoc., Shanghai, China; Sch. of Electron. Inf. & Electr. Eng., Shanghai Jiao Tong Univ., Shanghai, China","2017 10th International Symposium on Computational Intelligence and Design (ISCID)","8 Feb 2018","2017","2","","431","436","Modern artificial intelligence has been widely discussed to practice in automated financial asserts trading. Automated intraday trading means that the agent can react to the market conditions automatically, while simultaneously make the right decisions. Besides, the profits will be made within a day considering transaction cost charged by the brokerage company. In this paper, we introduce a multiobjective deep reinforcement learning approach for intraday financial signal representation and trading. We design the deep neural networks to automatically discover the dynamic market features, then a reinforcement learning method implemented by a special kind of recurrent neural network (LSTM) is applied to make continuous trading decisions. In terms of balancing the profit and risk, we implement a multi-objective structure which includes two objectives with different weights. We conduct experiments on stock index futures data, and our analysis and experiments not only offer insights into financial market features mining, but also provide a straightforward and reliable method to make profits, which sheds light on its wide application on automated financial trading.","2473-3547","978-1-5386-3675-6","10.1109/ISCID.2017.210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283307","Deep learning;Reinforcement learning;Intraday trading;Financial signal processing","Learning (artificial intelligence);Feature extraction;Training;Machine learning;Decision making;Contracts;Neural networks","financial data processing;learning (artificial intelligence);recurrent neural nets;stock markets","modern artificial intelligence;automated financial asserts trading;automated intraday trading;market conditions;profits;multiobjective deep reinforcement learning approach;intraday financial signal representation;deep neural networks;dynamic market features;reinforcement learning method;recurrent neural network;continuous trading decisions;risk;multiobjective structure;stock index futures data;financial market features mining;automated financial trading;transaction cost;stock index future intraday trading","","9","","29","","8 Feb 2018","","","IEEE","IEEE Conferences"
"A New Multi-Layer Classification Method Based on Logistic Regression","K. Kang; F. Gao; J. Feng","Technology Innovation Laboratory, Xiamen University Tan Kah Kee College, College of information science and technology & PRT Advanced Printing, Zhangzhou, China; Xiamen University Tan Kah Kee College, College of information science and technology, Zhangzhou, China; Xiamen University Tan Kah Kee College, College of information science and technology, Zhangzhou, China","2018 13th International Conference on Computer Science & Education (ICCSE)","20 Sep 2018","2018","","","1","4","To improve the effect of logistic regression in multiobjective classification and explore its greatest potential, a set of training and classification algorithms is constructed, by using the high accuracy of two-class classification. Multi-layer predictions are made under the premise of ensuring clear structure of the model. The method of outlier detection is introduced to choose a proper number of two-class classifiers for categories that are prone to be confused. Then further predictions are made with these two-class classifiers. The evaluation on MNIST dataset show that this method can effectively improve the classification accuracy of multi-class datasets with limited increase of running time.","2473-9464","978-1-5386-5495-8","10.1109/ICCSE.2018.8468725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468725","logistic regression;multi-objective classification;outlier;machine learning;MNIST","Logistics;Training;Classification algorithms;Prediction algorithms;Error analysis;Filtering;Information science","learning (artificial intelligence);pattern classification;regression analysis","logistic regression;multiobjective classification;classification algorithms;outlier detection;two-class classifiers;training algorithms;machine learning;multilayer classification","","5","","10","","20 Sep 2018","","","IEEE","IEEE Conferences"
"A statistical machine learning based modeling and exploration framework for run-time cross-stack energy optimization","C. Zhang; A. Ravindran","Department of Electrical and Computer Engineering, University of North Carolina at Charlotte, USA; Department of Electrical and Computer Engineering, University of North Carolina at Charlotte, USA","2013 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)","15 Jul 2013","2013","","","136","137","As the complexity of many-core processors grow, meeting performance, energy, temperature, reliability, and noise requirements under dynamically changing operating conditions requires run-time optimization of all parts of the computing stack - architecture, system software, and applications. Unfortunately, the combination of design parameters for the entire computing stack results in an operating space of millions of points that must be explored and evaluated at run-time. In this paper, we present a statistical machine learning (SML) based modeling framework that can be used to rapidly explore such vast operating spaces. We construct a multivariate adaptive regression spline (MARS) based model that uses a number of architecture and application parameters as predictor variables to predict performance and power. We then use a Pareto-front exploring evolutionary algorithm to determine operating points for optimal power and performance. The operating points constituting the Pareto front are stored in look-up tables for runtime use. The proposed framework is applied to an ×264 video encoding application executing on a quad core processor. The microarchitectural predictor variables include core and cache parameters. The application predictor variables include the video resolution, and visual quality determined by the choice of the motion estimation algorithm. The model outputs the average frames per second (FPS) and the average power consumption. The MARS model has an R<sup>2</sup> of 0.9657 and 0.9467 respectively for FPS and power. For a video frame resolution of 480x320, and FPS of 20, a power saving of 55% can be obtained by jointly tuning the microarchitectural parameters and the visual quality.","","978-1-4673-5779-1","10.1109/ISPASS.2013.6557161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6557161","modeling;energy;optimization;run-time;cross stack","Visualization;Microarchitecture;Benchmark testing;Pareto optimization;Adaptation models;Power demand;Measurement","cache storage;computer architecture;evolutionary computation;image resolution;learning (artificial intelligence);motion estimation;multiprocessing systems;Pareto optimisation;power aware computing;regression analysis;splines (mathematics);statistical analysis;video coding","statistical machine learning based modeling framework;statistical machine learning based exploration framework;run-time cross-stack energy optimization;many-core processor complexity;performance requirement;energy requirement;temperature requirement;reliability requirement;noise requirement;run-time optimization;computing stack-architecture;system software;SML;multivariate adaptive regression spline based model;MARS;predictor variables;performance prediction;power prediction;Pareto-front exploring evolutionary algorithm;video encoding application;quad core processor;microarchitectural predictor variables;core parameters;cache parameters;video resolution;visual quality;motion estimation algorithm;average frames-per-second;average power consumption;look-up tables","","","","6","","15 Jul 2013","","","IEEE","IEEE Conferences"
"Multi-Objective Convolutional Neural Networks for Robot Localisation and 3D Position Estimation in 2D Camera Images","J. Miseikis; I. Brijacak; S. Yahyanejad; K. Glette; O. J. Elle; J. Torresen","Department of Informatics, University of Oslo, Oslo, Norwey; The Joanneum Research - Robotics, Klagenfurt am Worthersee, Austria; The Joanneum Research - Robotics, Klagenfurt am Worthersee, Austria; Department of Informatics, University of Oslo, Oslo, Norwey; The Intervention Centre, Oslo University Hospital, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norwey","2018 15th International Conference on Ubiquitous Robots (UR)","23 Aug 2018","2018","","","597","603","The field of collaborative robotics and human-robot interaction often focuses on the prediction of human behaviour, while assuming the information about the robot setup and configuration being known. This is often the case with fixed setups, which have all the sensors fixed and calibrated in relation to the rest of the system. However, it becomes a limiting factor when the system needs to be reconfigured or moved. We present a deep learning approach, which aims to solve this issue. Our method learns to identify and precisely localise the robot in 2D camera images, so having a fixed setup is no longer a requirement and a camera can be moved. In addition, our approach identifies the robot type and estimates the 3D position of the robot base in the camera image as well as 3D positions of each of the robot joints. Learning is done by using a multiobjective convolutional neural network with four previously mentioned objectives simultaneously using a combined loss function. The multi-objective approach makes the system more flexible and efficient by reusing some of the same features and diversifying for each objective in lower layers. A fully trained system shows promising results in providing an accurate mask of where the robot is located and an estimate of its base and joint positions in 3D. We compare the results to our previous approach of using cascaded convolutional neural networks.","","978-1-5386-6334-9","10.1109/URAI.2018.8441813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8441813","","Robot kinematics;Cameras;Robot vision systems;Three-dimensional displays;Collision avoidance","cameras;convolution;estimation theory;feedforward neural nets;human-robot interaction;image sensors;learning (artificial intelligence);mobile robots;robot vision;SLAM (robots)","multiobjective convolutional neural networks;robot localisation;3D position estimation;collaborative robotics;human-robot interaction;robot setup;fixed setup;limiting factor;deep learning approach;robot type;robot base;robot joints;fully trained system;joint positions;human behaviour prediction;2D camera images","","8","","26","","23 Aug 2018","","","IEEE","IEEE Conferences"
"Investigation of the Noise Sensitivity of Machine Learning Algorithms on Credit Card Fraud Detection","İ. Aytutuldu; M. A. Aydin","Gebze Teknik Üniversitesi,Bilgisayar Mühendisliği Bölümü,İstanbul,Türkiye; Doğuş Üniversitesi,Endüstri Mühendisliği Bölümü,İstanbul,Türkiye","2021 29th Signal Processing and Communications Applications Conference (SIU)","19 Jul 2021","2021","","","1","4","The misleading of machine learning based credit card fraud detection systems, due to various cyber attacks and information transfer-related distortions, is highly critical for the financial sector and its effects globally. In this study, the noise sensitivity and reliability of the machine learning algorithms on the credit card transactions database, which was balanced by over sampling method, were investigated. For this purpose, the noise generated in different distributions was added from 5% to 100 percent level and applied on different algorithms. Common noise distributions such as Normal, Poisson, Pareto, Exponential, Power and Uniform have been used. Logistic regression, K nearest neighbor, Decision trees, Random Forest, Extreme Gradient Boosting (XGB) and Gradient Boosting (GB) machine learning algorithms have been used in this study. Results were evaluated by complexity matrix and f1 score. The results include evaluation and comparison of classification criteria for each algorithm and noise level for the noise sensitivity study.","2165-0608","978-1-6654-3649-6","10.1109/SIU53274.2021.9477832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477832","Credit Card Fraud Detection;Machine Learning;Noise;Noise Sensitivity","Boosting;Logistics;Sensitivity;Machine learning algorithms;Signal processing algorithms;Principal component analysis;Credit cards","credit transactions;decision trees;fraud;learning (artificial intelligence);pattern classification;regression analysis;sampling methods;security of data","information transfer-related distortions;financial sector;credit card transactions database;sampling method;common noise distributions;extreme gradient boosting;noise sensitivity study;credit card fraud detection systems;cyber attacks;gradient boosting machine learning algorithms;XGB;logistic regression;K nearest neighbor","","","","","","19 Jul 2021","","","IEEE","IEEE Conferences"
"Machine Learning-Assisted Tolerance Analysis and Its Application to Antennas","Q. Wu; W. Chen; H. Wang; W. Hong","State Key Laboratory of Millimeter Waves, Southeast University,Nanjing,China,210096; State Key Laboratory of Millimeter Waves, Southeast University,Nanjing,China,210096; State Key Laboratory of Millimeter Waves, Southeast University,Nanjing,China,210096; Purple Mountain Laboratories,Nanjing,China,211111","2020 IEEE International Symposium on Antennas and Propagation and North American Radio Science Meeting","17 Feb 2021","2020","","","1853","1854","An efficient machine learning-assisted tolerance analysis (MLATA) method is proposed by applying machine learning (ML) methods into multiple layers of the antenna tolerance analysis. The computational time for operations including worst case performance searching, maximum input tolerance hypervolume searching and robust optimization is greatly reduced while maintaining high reliability due to the introduction of the ML methods. The surrogate models which are built using ML methods have been introduced to predict both antenna performance and tolerance of parameters at given design points. The Pareto front combining antenna performance, robustness and size has been obtained to guide trade-offs for antenna robust design. A planar inverted-L antenna for mobile terminals is simulated to validate the proposed MLATA method.","1947-1491","978-1-7281-6670-4","10.1109/IEEECONF35879.2020.9330387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9330387","","Meetings;Tolerance analysis;Predictive models;Mobile antennas;Robustness;Antennas;Optimization","learning (artificial intelligence);mobile antennas;mobile radio;Pareto optimisation;planar antennas;telecommunication computing;tolerance analysis","machine learning-assisted tolerance analysis;tolerance analysis method;antenna tolerance analysis;maximum input tolerance hypervolume searching;robust optimization;antenna performance;antenna robust design;MLATA method;planar inverted-L antenna;mobile terminals;Pareto front","","1","","6","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Deep-Learning-Based Resource Allocation for Multi-Band Communications in CubeSat Networks","S. Nie; J. M. Jornet; I. F. Akyildiz","Broadband Wireless Networking Lab., Georgia Inst. of Technol., Athens, GA, USA; Dept. of Electr. Eng., State Univ. of New York at Buffalo, New York, NY, USA; Broadband Wireless Networking Lab., Georgia Inst. of Technol., Athens, GA, USA","2019 IEEE International Conference on Communications Workshops (ICC Workshops)","11 Jul 2019","2019","","","1","6","CubeSats, a type of miniaturized satellites with the benefits of low cost and short deployment cycle, are envisioned as a promising solution for future satellite communication networks. Currently, CubeSats communicate only with ground stations under limited spectrum resources and at low data rates, whereas with growing launches of CubeSats and more diverse services expected every year, novel communication techniques and resource allocation schemes should be investigated. In this paper, a multiobjective resource allocation strategy is designed based on deep learning algorithms for autonomous operation in CubeSats across millimeter wave (60-300 GHz) and Terahertz band (300 GHz-1 THz) frequencies with the utilization of reconfigurable plasmonic reflectarrays. Simulation results demonstrate the intersatellite links can achieve multi-gigabits-per-second throughput and ground-to-satellite links with more than 10 times of capacity enhancements in realistic channel conditions.","2474-9133","978-1-7281-2373-8","10.1109/ICCW.2019.8757157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8757157","","CubeSat;Antenna arrays;Orbits;Plasmons;Resource management;Space vehicles","learning (artificial intelligence);metamaterial antennas;millimetre wave antenna arrays;millimetre wave communication;plasmonics;reflectarray antennas;resource allocation;satellite ground stations;satellite links;submillimetre wave antennas;telecommunication computing;wireless channels","CubeSat networks;ground stations;spectrum resources;multiobjective resource allocation strategy;deep learning algorithms;ground-to-satellite links;satellite communication networks;multiband communication techniques;reconfigurable plasmonic reflectarrays;intersatellite links;multigigabits-per-second throughput;channel conditions;frequency 60.0 GHz to 300.0 GHz;frequency 300 GHz to 1 THz","","5","","18","","11 Jul 2019","","","IEEE","IEEE Conferences"
"Feature selection for event extraction in biomedical text","A. Majumder; M. Hasanuzzaman; A. Ekbal","Department of Computer Science and Engineering, Academy of Technology, India; Normandie University, Caen, France; Dept. of Computer Science and Engineering, Indian Institute of Technology Patna, India","2015 Eighth International Conference on Advances in Pattern Recognition (ICAPR)","2 Mar 2015","2015","","","1","6","In this paper we report our work on multiobjective optimization (MOO) based feature selection approach for event extraction in biomedical texts. Event extraction deals with the detection and classification of expressions that represent complex biological phenomenon involving genes and proteins. We perform feature selection within the framework of a robust machine learning algorithm, namely Conditional Random Field (CRF). We implement a set of diverse features that exploit lexical, shallow syntactic and contextual information. At first we develop a single objective optimization (SOO) based feature selection technique where we optimize F-measure function. Thereafter we develop two different models of MOO based feature selection by optimizing different pairs of objective functions, i.e. recall and precision; and feature count and F-measure. We carried out experiments on the benchmark setup of BioNLP-2013 shared task. We obtain the best performance with the overall average recall, precision and F-measure values of 57.04%, 75.08% and 64.77%, respectively. Evaluation shows that the classifier can achieve good performance level when trained with an effective feature set. We also observe that MOO can indeed performs better than the SOO based approach.","","978-1-4799-7458-0","10.1109/ICAPR.2015.7050708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7050708","Text Mining;Event Extraction;Feature Selection;Conditional Random Field","Feature extraction;Proteins;Optimization;Context;Linear programming;Genetic algorithms;Biological cells","data mining;feature selection;genetics;learning (artificial intelligence);medical computing;optimisation;pattern classification;proteins;random processes;text analysis","multiobjective optimization based feature selection approach;event extraction;biomedical texts;expression detection;expression classification;complex biological phenomenon representation;genes;proteins;robust machine learning algorithm;conditional random field;single objective optimization based feature selection technique;lexical information;shallow syntactic information;contextual information;F-measure function optimization;recall objective function;precision objective function;feature count;BioNLP-2013 shared task;text mining","","1","","18","","2 Mar 2015","","","IEEE","IEEE Conferences"
"Adaptive strategy optimization with multi-agent machine learning in the game of radar countermeasure","D. Zhang; Y. Li; Z. Tian; Z. Jiang","Beijing Institute of Technology, School of Information and Electronics, Beijing, China; Beijing Institute of Technology, School of Information and Electronics, Beijing, China; Northern Institute of Electronic Equipment, Beijing, China; Naval Research Academy, Beijing, China","IET International Radar Conference (IET IRC 2020)","22 Sep 2021","2020","2020","","1791","1797","Traditional radar countermeasure usually acts with some pre-defined strategies, ignoring the dynamic changes of both sides. In this paper, the scenario of radar countermeasure is represented as a two-player zero-sum dynamic game, where each player adaptively optimizes its own strategy. Specifically, according to game theory, two effective multi-agent machine learning methods, i.e. multi-stage minimax backward induction and deep counterfactual regret minimization are utilized to obtain the final strategies for both players. The experimental results demonstrate that the learned strategies for both players are more effective and reasonable than some simple strategies.","","","10.1049/icp.2021.0527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545515","","","deep learning (artificial intelligence);game theory;learning (artificial intelligence);minimax techniques;minimisation;multi-agent systems;radar computing","game theory;multistage minimax backward induction;deep counterfactual regret minimization;adaptive strategy optimization;traditional radar countermeasure;pre-defined strategies;two-player zero-sum dynamic game;effective multiagent machine learning methods","","","","","","22 Sep 2021","","","IET","IET Conferences"
"Weather-Driven Predictive Control of a Battery Storage for Improved Microgrid Resilience","D. Gutierrez-Rojas; A. Mashlakov; C. Brester; H. Niska; M. Kolehmainen; A. Narayanan; S. Honkapuro; P. H. J. Nardelli","Department of Electrical Engineering, School of Energy Systems, LUT University, Lappeenranta, Finland; Department of Electrical Engineering, School of Energy Systems, LUT University, Lappeenranta, Finland; Department of Environmental and Biological Sciences, University of Eastern Finland, Kuopio, Finland; Department of Environmental and Biological Sciences, University of Eastern Finland, Kuopio, Finland; Department of Environmental and Biological Sciences, University of Eastern Finland, Kuopio, Finland; Department of Electrical Engineering, School of Energy Systems, LUT University, Lappeenranta, Finland; Department of Electrical Engineering, School of Energy Systems, LUT University, Lappeenranta, Finland; Department of Electrical Engineering, School of Energy Systems, LUT University, Lappeenranta, Finland","IEEE Access","17 Dec 2021","2021","9","","163108","163121","This paper aims to introduce a predictive weather-based control policy for the microgrid energy management to improve the resilience of the microgrid. This policy relies on the application of machine learning models for the prediction of microgrid load demand and solar production and supply interruption in the upstream distribution network. The predictions serve as an input to multiobjective chance constraint optimization that balances the microgrid resilience and economic objectives based on the probability of a supply interruption. The interruption predictions are made with a decision-tree-based model that can predict an upcoming interruption in the distribution network with 78% of the maximum accuracy. The case study microgrid consisting of several customers, solar photovoltaic generation, and battery storage is applied to cluster areas located in Finland. Overall, the developed control policy shows an improvement in the daily resilience of the microgrid in regard to an interruption in the main grid when compared with economic dispatch only.","2169-3536","","10.1109/ACCESS.2021.3133490","Academy of Finland through the EnergyNet Research Fellowship(grant numbers:321265,328869); Analytics Project(grant numbers:324677); FIREMAN Consortium(grant numbers:326270); CHIST-ERA(grant numbers:CHIST-ERA-17-BDSI-003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638664","Microgrid resilience;weather prediction;machine learning;battery storage;chance constraint optimization","Resilience;Microgrids;Predictive models;Batteries;Load modeling;Optimization;Reliability","decision trees;distributed power generation;energy management systems;learning (artificial intelligence);optimisation;photovoltaic power systems;power distribution control;power engineering computing;power generation control;predictive control;probability;secondary cells;weather forecasting","machine learning model;microgrid load demand;supply interruption;upstream distribution network;multiobjective chance constraint optimization;decision-tree-based model;solar photovoltaic generation;battery storage;microgrid resilience;predictive weather-based control policy;economic dispatch;Finland","","","","46","CCBY","6 Dec 2021","","","IEEE","IEEE Journals"
"From minimax value to low-regret algorithms for online Markov decision processes","P. Guan; M. Raginsky; R. Willett","Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, 61801, USA; Department of Electrical and Computer Engineering, University of Wisconsin-Madison, 53796, USA","2014 American Control Conference","21 Jul 2014","2014","","","471","476","The standard Markov Decision Process (MDP) framework assumes a stationary (or at least predictable) environment. Online learning algorithms can deal with non-stationary or unpredictable environments, but there is no notion of a state that might be changing throughout the learning process as a function of past actions. In recent years, there has been a growing interest in combining the above two frameworks and considering an MDP setting, where the cost function is allowed to change arbitrarily after each time step. However, most of the work in this area has been algorithmic: given a problem, one would design an algorithm from scratch and analyze its performance on a case-by-case basis. Moreover, the presence of the state and the assumption of an arbitrarily varying environment complicate both the theoretical analysis and the development of computationally efficient methods. This paper builds on recent results of Rakhlin et al. to give a general framework for deriving algorithms in an MDP setting with arbitrarily changing costs. This framework leads to a unifying view of existing methods and provides a general procedure for constructing new ones.","2378-5861","978-1-4799-3274-0","10.1109/ACC.2014.6858844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6858844","Markov processes;Machine learning","Markov processes;Algorithm design and analysis;Heuristic algorithms;Games;Cost function;Kernel;State feedback","computer aided instruction;interactive programming;Markov processes;minimax techniques","unpredictable environments;nonstationary environments;online learning algorithms;MDP;online Markov decision processes;low-regret algorithms;minimax value","","2","","19","","21 Jul 2014","","","IEEE","IEEE Conferences"
"Minimax strategies for training classifiers under unknown priors","R. Alaiz-Rodriguez; J. Cid-Sueiro","Dpto. Ingenieria Electrica y Electronica, Univ. de Leon, Mexico; NA","Proceedings of the 12th IEEE Workshop on Neural Networks for Signal Processing","7 Nov 2002","2002","","","249","258","Most supervised learning algorithms are based on the assumption that the training data set reflects the underlying statistical model of the real data. However, this stationarity assumption is not always satisfied in practice: quite frequently, class prior probabilities are not in accordance with the class proportions in the training data set. The minimax approach is based on selecting the classifier that minimize the error probability under the worst case conditions. We propose a two-step learning algorithm to train a neural network in order to estimate the minimax classifier that is robust to changes in the class priors. During the first step, posterior probabilities based on training data priors are estimated. During the second step, class priors are modified in order to minimize a cost function that is asymptotically equivalent to the worst-case error rate. This procedure is illustrated on a softmax-based neural network. Several experimental results show the advantages of the proposed method with respect to other approaches.","","0-7803-7616-1","10.1109/NNSP.2002.1030036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1030036","","Minimax techniques;Neural networks;Training data;Error analysis;Robustness;Supervised learning;Error probability;Cost function;Proposals","learning (artificial intelligence);probability;minimax techniques;signal classification","minimax strategies;classifiers training;generalized softmax perceptron;information filtering;supervised learning algorithms;training data set;statistical model;stationarity assumption;class prior probabilities;error probability minimization;worst case conditions;two-step learning algorithm;neural network training;data priors training;class priors;cost function minimization;posterior probabilities;worst-case error rate;softmax-based neural network","","","","10","","7 Nov 2002","","","IEEE","IEEE Conferences"
"The SMART Framework: Selection of Machine Learning Algorithms With ReplicaTions—A Case Study on the Microvascular Complications of Diabetes","B. P. Swan; M. E. Mayorga; J. S. Ivy","Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA","IEEE Journal of Biomedical and Health Informatics","4 Feb 2022","2022","26","2","809","817","Over 34 million people in the US have diabetes, a major cause of blindness, renal failure, and amputations. Machine learning (ML) models can predict high-risk patients to help prevent adverse outcomes. Selecting the ‘best’ prediction model for a given disease, population, and clinical application is challenging due to the hundreds of health-related ML models in the literature and the increasing availability of ML methodologies. To support this decision process, we developed the Selection of Machine-learning Algorithms with ReplicaTions (SMART) Framework that integrates building and selecting ML models with decision theory. We build ML models and estimate performance for multiple plausible future populations with a replicated nested cross-validation technique. We rank ML models by simulating decision-maker priorities, using a range of accuracy measures (e.g., AUC) and robustness metrics from decision theory (e.g., minimax Regret). We present the SMART Framework through a case study on the microvascular complications of diabetes using data from the ACCORD clinical trial. We compare selections made by risk-averse, -neutral, and -seeking decision-makers, finding agreement in 80% of the risk-averse and risk-neutral selections, with the risk-averse selections showing consistency for a given complication. We also found that the models that best predicted outcomes in the validation set were those with low performance variance on the testing set, indicating a risk-averse approach in model selection is ideal when there is a potential for high population feature variability. The SMART Framework is a powerful, interactive tool that incorporates various ML algorithms and stakeholder preferences, generalizable to new data and technological advancements.","2168-2208","","10.1109/JBHI.2021.3094777","NHLBI Biologic Specimen; Data Repository Information Coordinating Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477105","Data-driven modeling;decision theory;diabetes;machine learning","Predictive models;Statistics;Sociology;Measurement;Data models;Robustness;Diabetes","","","Algorithms;Diabetes Complications;Diabetes Mellitus;Humans;Machine Learning","","","47","IEEE","7 Jul 2021","","","IEEE","IEEE Journals"
"Reusing Genetic Programming for Ensemble Selection in Classification of Unbalanced Data","U. Bhowan; M. Johnston; M. Zhang; X. Yao","Knowledge and Data Engineering Group, School of Statistics and Computer Science, Trinity College, Dublin, Ireland; Evolutionary Computation Research Group, University of Wellington, Victoria, Wellington, New Zealand; Evolutionary Computation Research Group, University of Wellington, Victoria, Wellington, New Zealand; School of Computer Science, The University of Birmingham, Birmingham, West Midlands, U.K.","IEEE Transactions on Evolutionary Computation","25 Nov 2014","2014","18","6","893","908","Classification algorithms can suffer from performance degradation when the class distribution is unbalanced. This paper develops a two-step approach to evolving ensembles using genetic programming (GP) for unbalanced data. The first step uses multiobjective (MO) GP to evolve a Pareto-approximated front of GP classifiers to form the ensemble by trading-off the minority and the majority class against each other during learning. The MO component alleviates the reliance on sampling to artificially rebalance the data. The second step, which is the focus this paper, proposes a novel ensemble selection approach using GP to automatically find/choose the best individuals for the ensemble. This new GP approach combines multiple Pareto-approximated front members into a single composite genetic program solution to represent the (optimized) ensemble. This ensemble representation has two main advantages/novelties over traditional genetic algorithm (GA) approaches. First, by limiting the depth of the composite solution trees, we use selection pressure during evolution to find small highly-cooperative groups of individuals for the ensemble. This means that ensemble sizes are not fixed a priori (as in GA), but vary depending on the strength of the base learners. Second, we compare different function set operators in the composite solution trees to explore new ways to aggregate the member outputs and thus, control how the ensemble computes its output. We show that the proposed GP approach evolves smaller more diverse ensembles compared to an established ensemble selection algorithm, while still performing as well as, or better than the established approach. The evolved GP ensembles also perform well compared to other bagging and boosting approaches, particularly on tasks with high levels of class imbalance.","1941-0026","","10.1109/TEVC.2013.2293393","Marsden Fund of the New Zealand Government(grant numbers:VUW0806); Royal Society of New Zealand; NSFC(grant numbers:61329302); European Union Seventh Framework Programme(grant numbers:270428); Royal Society Wolfson Research Merit Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6677603","Classification;ensemble machine learning;genetic programming;unbalanced data","Sociology;Statistics;Training;Accuracy;Genetic algorithms;Silicon;Bagging","approximation theory;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification;trees (mathematics)","genetic programming;ensemble selection approach;unbalanced data classification;Pareto-approximated front;GP classifiers;learning;single composite genetic program solution;composite solution trees;bagging approach;boosting approach","","57","","56","IEEE","28 Nov 2013","","","IEEE","IEEE Journals"
"Advanced Design Optimization Technique for Torque Profile Improvement in Six-Phase PMSM Using Supervised Machine Learning for Direct-Drive EV","H. Dhulipati; E. Ghosh; S. Mukundan; P. Korta; J. Tjong; N. C. Kar","Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada","IEEE Transactions on Energy Conversion","22 Nov 2019","2019","34","4","2041","2051","Few of the challenges with development of a single on-board motor for direct-drive electric vehicles include high torque density and low torque ripple. Therefore, in this paper, a 36-slot, 34-pole consequent pole six-phase permanent magnet synchronous machine (PMSM) has been optimized to address the aforementioned challenges for direct-drive application. Existing literature on optimization processes that rely solely on finite element models are restricted to three-phase machines only and also take longer computation time. Therefore, this paper proposes a novel optimization approach based on supervised machine learning for six-phase PMSM. In this approach, a non-conventional extended dual dq-frame model that accounts for higher order space harmonics in inductances and flux linkages has been developed and used for accurate computation of average torque and torque ripple of six-phase PMSM. Using the performance characteristics obtained from the extended dual dq-frame model for a set of initial design candidates, support vector regression algorithm is employed for supervised machine learning and increasing solutions in the design space. Furthermore, pareto front is used for selecting optimal machine models with maximum torque density and reduced torque ripple. Multi-objective trade-offs and comparison of initial and optimized designs based on average torque, torque ripple, efficiency and cost are performed.","1558-0059","","10.1109/TEC.2019.2933619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789459","Direct–drive;  $dq$  –frame model;electric vehicle;machine learning;permanent magnet synchronous machine;support vector regression;time–step finite element analysis","Torque;Optimization;Computational modeling;Harmonic analysis;Torque measurement;Couplings;Permanent magnet motors","electric vehicles;finite element analysis;machine control;optimisation;permanent magnet motors;regression analysis;support vector machines;synchronous motors;torque;torque control","advanced design optimization technique;torque profile improvement;six-phase PMSM;supervised machine learning;high torque density;low torque ripple;permanent magnet synchronous machine;direct-drive application;optimization processes;finite element models;three-phase machines;average torque;initial design candidates;design space;optimal machine models;maximum torque density;initial designs;nonconventional extended dual dq-frame model;direct-drive electric vehicles","","20","","41","IEEE","6 Aug 2019","","","IEEE","IEEE Journals"
"Wind Turbine Fault Diagnosis and Predictive Maintenance Through Statistical Process Control and Machine Learning","J. -Y. Hsu; Y. -F. Wang; K. -C. Lin; M. -Y. Chen; J. H. -Y. Hsu","Department of Management Information Systems, National Chung Hsing University, Taichung City, Taiwan; Department of Management Information Systems, National Chung Hsing University, Taichung City, Taiwan; Department of Management Information Systems, National Chung Hsing University, Taichung City, Taiwan; Department of Information Management, National Taichung University of Science and Technology, Taichung City, Taiwan; Independent Researcher, San Francisco, CA, USA","IEEE Access","5 Feb 2020","2020","8","","23427","23439","This study applies statistical process control and machine learning techniques to diagnose wind turbine faults and predict maintenance needs by analyzing 2.8 million sensor data collected from 31 wind turbines from 2015 to 2017 in Taiwan. Unlike previous studies that only relied on historical wind turbine data, this study analyzed the sensor data with practitioners' insight by incorporating maintenance check list items into the data mining processes. We used Pareto analyses, scatter plots, and the cause and effect diagram to cluster and classify the failure types of wind turbines. In addition, control charts were used to establish a monitoring mechanism to track whether operation data are deviated from the controls (i.e., standard deviations) as a mean to detect wind turbine abnormalities. While statistical process control was applied to fault diagnosis, machine learning algorithms were used to predict maintenance needs of wind turbines. First, the density-based spatial clustering of applications with noise algorithm was used to classify abnormal-state wind turbine data from normal-state data. Then, random forest and decision tree algorithms were employed to construct the predictive models for wind turbine anomalies and tested with K-fold cross-validation. The results indicate a high level of accuracy: 92.68% for the decision tree model, and 91.98% for the random forest model. The study demonstrates that, by data mining and modeling, the failures of wind turbines can be detected, and the maintenance needs of parts can be predicted. Model results may provide technicians early warnings, improve equipment efficient, and decrease system downtime of wind turbine operation.","2169-3536","","10.1109/ACCESS.2020.2968615","Ministry of Science and Technology, Taiwan(grant numbers:106-2420-H-005-003); Ministry of Science and Technology, Taiwan(grant numbers:108-3116-F-005-001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966331","Decision trees;fault diagnosis;machine learning;predictive maintenance;random forest;statistical process control;wind energy","Wind turbines;Fault diagnosis;Monitoring;Process control;Neural networks;Predictive maintenance","condition monitoring;control charts;data mining;decision trees;fault diagnosis;learning (artificial intelligence);maintenance engineering;pattern classification;power engineering computing;power system faults;statistical analysis;statistical process control;wind turbines","cause and effect diagram;scatter plots;Pareto analyses;density-based spatial clustering;K-fold cross-validation;maintenance check list items;wind turbine anomalies;machine learning algorithms;wind turbine abnormalities;data mining processes;historical wind turbine data;wind turbine faults;statistical process control;predictive maintenance;wind turbine fault diagnosis;wind turbine operation","","24","","15","CCBY","22 Jan 2020","","","IEEE","IEEE Journals"
"Multilevel Sensor Fusion With Deep Learning","V. Vielzeuf; A. Lechervy; S. Pateux; F. Jurie","Orange Labs, Rennes, Cesson-Sevigne, France; Normandie Université, UNICAEN, ENSICAEN, CNRS, Caen, France; Orange Labs, Rennes, Cesson-Sevigne, France; Normandie Université, UNICAEN, ENSICAEN, CNRS, Caen, France","IEEE Sensors Letters","15 Jan 2019","2019","3","1","1","4","In the context of deep learning, this article presents an original deep network, namely CentralNet, for the fusion of information coming from different sensors. This approach is designed to efficiently and automatically balance the tradeoff between early and late fusion (i.e., between the fusion of low-level versus high-level information). More specifically, at each level of abstraction—the different levels of deep networks—unimodal representations of the data are fed to a central neural network which combines them into a common embedding. In addition, a multiobjective regularization is also introduced, helping to both optimize the central network and the unimodal networks. Experiments on four multimodal datasets not only show the state-of-the-art performance but also demonstrate that CentralNet can actually choose the best possible fusion strategy for a given problem.","2475-1472","","10.1109/LSENS.2018.2878908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516399","Sensor data fusion;multimodal fusion;neural networks","Neural networks;Task analysis;Sensor fusion;Videos;Visualization","","","","8","","23","IEEE","31 Oct 2018","","","IEEE","IEEE Journals"
"Pareto-Optimal Model Selection via SPRINT-Race","T. Zhang; M. Georgiopoulos; G. C. Anagnostopoulos","Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, Florida Institute of Technology, Melbourne, FL, USA","IEEE Transactions on Cybernetics","4 Jan 2018","2018","48","2","596","610","In machine learning, the notion of multi-objective model selection (MOMS) refers to the problem of identifying the set of Pareto-optimal models that optimize by compromising more than one predefined objectives simultaneously. This paper introduces SPRINT-Race, the first multi-objective racing algorithm in a fixed-confidence setting, which is based on the sequential probability ratio with indifference zone test. SPRINT-Race addresses the problem of MOMS with multiple stochastic optimization objectives in the proper Pareto-optimality sense. In SPRINT-Race, a pairwise dominance or non-dominance relationship is statistically inferred via a non-parametric, ternary-decision, dual-sequential probability ratio test. The overall probability of falsely eliminating any Pareto-optimal models or mistakenly returning any clearly dominated models is strictly controlled by a sequential Holm's step-down family-wise error rate control method. As a fixed-confidence model selection algorithm, the objective of SPRINT-Race is to minimize the computational effort required to achieve a prescribed confidence level about the quality of the returned models. The performance of SPRINT-Race is first examined via an artificially constructed MOMS problem with known ground truth. Subsequently, SPRINT-Race is applied on two real-world applications: 1) hybrid recommender system design and 2) multi-criteria stock selection. The experimental results verify that SPRINT-Race is an effective and efficient tool for such MOMS problems.<sup>11</sup>MATLAB code of SPRINT-Race is available at https://github.com/watera427/SPRINT-Race.","2168-2275","","10.1109/TCYB.2017.2647821","National Science Foundation (NSF)(grant numbers:1200566,0525429); NSF(grant numbers:1200566,1161228,1356233,1643835); NSF(grant numbers:1263011,1560345); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836308","Model selection (MS);multi-objective optimization;racing algorithm;sequential probability ratio test (SPRT)","Method of moments;Computational modeling;Optimization;Adaptation models;Complexity theory;Probability;US Government","decision making;estimation theory;evolutionary computation;learning (artificial intelligence);Pareto optimisation;probability;stochastic processes","SPRINT-Race;multiple stochastic optimization objectives;multiobjective racing algorithm;multiobjective model selection;Pareto-optimal model selection;fixed-confidence model selection algorithm","","3","","55","IEEE","30 Jan 2017","","","IEEE","IEEE Journals"
"Design of Artificial Neural Networks Using a Memetic Pareto Evolutionary Algorithm Using as Objectives Entropy versus Variation Coefficient","J. C. Fernández; C. Hervás; F. J. Martínez; M. Cruz","Dept. of Comput. Sci., Univ. of Cordoba, Cordoba, Spain; Dept. of Comput. Sci., Univ. of Cordoba, Cordoba, Spain; Dept. of Manage. & Quantitative Methods, ETEA, Cordoba, Spain; Dept. of Comput. Sci., Univ. of Cordoba, Cordoba, Spain","2009 Ninth International Conference on Intelligent Systems Design and Applications","28 Dec 2009","2009","","","408","413","This paper proposes a multi-classification pattern algorithm using multilayer perceptron neural network models which try to boost two conflicting main objectives of a classifier, a high correct classification rate and a high classification rate for each class. To solve this machine learning problem, we consider a Memetic Pareto Evolutionary approach based on the NSGA2 algorithm (MPENSGA2), where we defined two objectives for determining the goodness of a classifier: the cross-entropy error function and the variation coefficient of its sensitivities, because both measures are continuous functions, making the convergence more robust. Once the Pareto front is built, we use an automatic selection methodology of individuals: the best model in accuracy (upper extreme in the Pareto front). This methodology is applied to solve six benchmark classification problems, obtaining promising results and achieving a high classification rate in the generalization set with an acceptable level of accuracy for each class.","2164-7151","978-1-4244-4735-0","10.1109/ISDA.2009.153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5364897","Classification;Neural Networks;Multi-objective;Entropy;Variation Coefficient","Algorithm design and analysis;Artificial neural networks;Evolutionary computation;Entropy;Machine learning algorithms;Multilayer perceptrons;Neural networks;Multi-layer neural network;Machine learning;Convergence","entropy;evolutionary computation;generalisation (artificial intelligence);learning (artificial intelligence);multilayer perceptrons;Pareto optimisation;pattern classification","artificial neural networks;memetic Pareto evolutionary algorithm;objectives entropy;variation coefficient;multiclassification pattern algorithm;multilayer perceptron neural network models;machine learning problem;memetic Pareto evolutionary approach;NSGA2 algorithm;cross-entropy error function;Pareto front;automatic selection methodology;benchmark classification problems;generalization set","","","","20","","28 Dec 2009","","","IEEE","IEEE Conferences"
"A Fast Design Space Exploration Framework for the Deep Learning Accelerators: Work-in-Progress","A. Colucci; A. Marchisio; B. Bussolino; V. Mrazek; M. Martina; G. Masera; M. Shafique","Technische Universität Wien,Vienna,Austria; Technische Universität Wien,Vienna,Austria; Politecnico di Torino,Turin,Italy; Faculty of Information Technology, IT4Innovations Centre of Excellence, Brno University of Technology,Czech Republic; Politecnico di Torino,Turin,Italy; Politecnico di Torino,Turin,Italy; Technische Universität Wien,Vienna,Austria","2020 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)","9 Nov 2020","2020","","","34","36","The Capsule Networks (CapsNets) is an advanced form of Convolutional Neural Network (CNN), capable of learning spatial relations and being invariant to transformations. CapsNets requires complex matrix operations which current accelerators are not optimized for, concerning both <sub>training</sub> and <sub>inference</sub> passes. Current state-of-the-art simulators and design space exploration (DSE) tools for DNN hardware neglect the modeling of training operations, while requiring long exploration times that slow down the complete design flow. These impediments restrict the real-world applications of CapsNets (e.g., autonomous driving and robotics) as well as the further development of DNNs in life-long learning scenarios that require training on low-power embedded devices. Towards this, we present <sub>XploreDL</sub>, a novel framework to perform fast yet high-fidelity DSE for both inference and training accelerators, supporting both CNNs and CapsNets operations. <sub>XploreDL</sub> enables a resource-efficient DSE for accelerators, focusing on power, area, and latency, highlighting Pareto-optimal solutions which can be a green-lit to expedite the design flow. <sub>XploreDL</sub> can reach the same fidelity as ARM's SCALE-sim, while providing 600x speedup and having a 50x lower memory-footprint. Preliminary results with a deep CapsNet model on MNIST for training accelerators show promising Pareto-optimal architectures with up to 0.4 TOPS/squared-mm and 800 fJ/op efficiency. With inference accelerators for AlexNet the Pareto-optimal solutions reach up to 1.8 TOPS/squared-mm and 200 fJ/op efficiency.","","978-1-7281-9198-0","10.1109/CODESISSS51650.2020.9244038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244038","Design Space Exploration;Hardware Accelerator;Capsule Networks;Convolutional Neural Networks;Training","Training;Performance evaluation;Neural networks;Tools;Space exploration;Acceleration;Robots","convolutional neural nets;embedded systems;learning (artificial intelligence);microprocessor chips;multiprocessing systems;Pareto optimisation;power aware computing;system-on-chip","deep CapsNet model;Pareto-optimal architectures;inference accelerators;Pareto-optimal solutions;resource-efficient DSE;training accelerators;high-fidelity DSE;XploreDL;low-power embedded devices;life-long learning scenarios;real-world applications;complete design flow;long exploration times;training operations;DNN hardware neglect;design space exploration tools;state-of-the-art simulators;inference passes;current accelerators;complex matrix operations;spatial relations;convolutional neural network;advanced form;CapsNets;capsule networks;deep learning accelerators;fast design space exploration framework","","","","18","","9 Nov 2020","","","IEEE","IEEE Conferences"
"Learning-Enabled NoC Design for Heterogeneous Manycore Systems","R. G. Kim","Colorado State University,Department of Electrical and Computer Engineering,Fort Collins,CO,80524","2020 21st International Symposium on Quality Electronic Design (ISQED)","9 Jul 2020","2020","","","268","272","As systems grow in specialization (e.g., domain specific architectures), we need the tools to handle the growing design space from increased heterogeneity and system sizes. In this paper, we investigate the specific challenges posed by heterogeneous systems on the NoC in two separate contexts: wireless- and 3D-enabled, formulate each as a separate multiobjective optimization problem, and present a machine learning based design space exploration technique, MOO-STAGE, to intelligently explore this growing design space.","1948-3287","978-1-7281-4207-4","10.1109/ISQED48828.2020.9137000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9137000","NoC;Wireless NoC;3D NoC;Multi-objective optimization;Machine learning;CPU-GPU systems","Wireless communication;Design methodology;Computer architecture;Machine learning;Space exploration;Optimization","graphics processing units;learning (artificial intelligence);multiprocessing systems;network-on-chip;optimisation","learning-enabled NoC design;heterogeneous manycore systems;domain specific architectures;multiobjective optimization problem;machine learning based design space exploration technique;MOO-STAGE;CPU-GPU","","","","16","","9 Jul 2020","","","IEEE","IEEE Conferences"
"Computational Intelligence-Based Methodology for Antenna Development","M. C. D. Melo; P. B. Santos; E. Faustino; C. J. A. Bastos-Filho; A. Cerqueira Sodré","Laboratory WOCA, National Institute of Telecommunications (Inatel), Santa Rita do Sapucaí, Brazil; University of Pernambuco—(POLI-UPE), Recife, Brazil; University of Pernambuco—(POLI-UPE), Recife, Brazil; University of Pernambuco—(POLI-UPE), Recife, Brazil; Laboratory WOCA, National Institute of Telecommunications (Inatel), Santa Rita do Sapucaí, Brazil","IEEE Access","6 Jan 2022","2022","10","","1860","1870","The antenna design is a challenging task, which might be time-consuming using conventional computational methods that typically require high computational capability, due to the need for several sweeps and re-running processes. This work proposes an efficient and accurate computational intelligence-based methodology for the antenna design and optimization. The computational technical solution consists of a surrogate model application, composed of a Multilayer Perceptron (MLP) artificial neural network with backpropagation for the regression process. Combined with the surrogate model, two multiobjective optimization meta-heuristic strategies, Non-dominated Sorting Genetic Algorithm (NSGA-II) and Multiobjective Evolutionary Algorithm based on Decomposition (MOEA/D), are used to overcome the mentioned issues from the traditional antenna design method. A study of case considering a dipole antenna for the 3.5 GHz 5G band is reported, as proof of the proposed methodology concept. Comparisons of antenna impedance matching obtained by the proposed methodology, numerical full-wave results from ANSYS HFSS and experimental result from the antenna prototype are performed for demonstrating its applicability and effectiveness for antenna development.","2169-3536","","10.1109/ACCESS.2021.3137198","Pernambuco’s University [(Universidade de Pernambuco (UPE)], Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES) coordination, and Rede Nacional de Ensino e Pesquisa (RNP), with resources from Ministerio da Ciencia, Tecnologia, Inovacoes e Comunicacoes (MCTIC), through the Radiocommunication Reference Center [Centro de Referencia em Radiocomunicacoes (CRR)] project of the National Institute of Telecommunications [Instituto Nacional de Telecomunicacoes (Inatel)], Brazil(grant numbers:01245.010604/2020-14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9656850","Antennas design;computational intelligence;machine learning;multi-objective optimization","Optimization;Antennas;Computational modeling;Dipole antennas;Reflector antennas;Mathematical models;Training","backpropagation;dipole antennas;evolutionary computation;genetic algorithms;impedance matching;multilayer perceptrons;neural nets;optimisation;Pareto optimisation","antenna development;conventional computational methods;high computational capability;efficient intelligence-based methodology;accurate computational intelligence-based methodology;computational technical solution;surrogate model application;Multilayer Perceptron artificial neural network;regression process;multiobjective optimization meta-heuristic strategies;Nondominated Sorting Genetic Algorithm;Evolutionary Algorithm;traditional antenna design method;dipole antenna;methodology concept;antenna impedance;antenna prototype;frequency 3.5 GHz","","","","57","CCBY","21 Dec 2021","","","IEEE","IEEE Journals"
"Minimax Active Learning Via Minimal Model Capacity","S. Shayovitz; M. Feder","Tel Aviv University,School of Electrical Engineering; Tel Aviv University,School of Electrical Engineering","2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP)","5 Dec 2019","2019","","","1","6","Active learning is a form of machine learning which combines supervised learning and feedback to minimize the training set size, subject to low generalization errors. Since direct optimization of the generalization error is difficult, many heuristics have been developed which lack a firm theoretical foundation. In this paper, a new information theoretic criterion is proposed based on a minimax log-loss regret formulation of the active learning problem. In the first part of this paper, a Redundancy Capacity theorem for active learning is derived along with an optimal learner. Building on this, a new active learning criterion is proposed which naturally induces an exploration - exploitation trade-off in feature selection. In the second part, the linear separator hypotheses class with additive label noise is considered and a low complexity algorithm is proposed which optimizes the active learning criterion from the first part. This greedy algorithm is based on the Posterior Matching scheme for communication with feedback and is shown that for BSC and BEC label noise, the proposed information theoretic criterion decays at an exponential rate.","1551-2541","978-1-7281-0824-7","10.1109/MLSP.2019.8918907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918907","Active Learning;Linear Separator;Posterior Matching","Particle separators;Uncertainty;Entropy;Training;Complexity theory;Mutual information;Feature extraction","computational complexity;greedy algorithms;learning (artificial intelligence);minimax techniques","minimax active learning;minimal model Capacity;machine learning;supervised learning;training set size;low generalization errors;direct optimization;generalization error;firm theoretical foundation;minimax log-loss regret formulation;active learning problem;active learning criterion;information theoretic criterion decays","","1","","14","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Evolutionary Multi-objective Ensemble Learning for Multivariate Electricity Consumption Prediction","H. Song; A. K. Qin; F. D. Salim","Computer Science and Information Technology, School of Science, RMIT University, Melbourne, VIC, 3000, Australia; Computer Science and Software Engineering, School of Software and Electrical Engineering, Swinburne University of Technology, Hawthorn, VIC, 3122, Australia; Computer Science and Information Technology, School of Science, RMIT University, Melbourne, VIC, 3000, Australia","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","Energy consumption prediction typically corresponds to a multivariate time series prediction task where different channels in the multivariate time series represent energy consumption data and various auxiliary data related to energy consumption such as environmental factors. It is non-trivial to resolve this task, which requires finding the most appropriate prediction model and the most useful features (extracted from the raw data) to be used by the model. This work proposes an evolutionary multi-objective ensemble learning (EMOEL) technique which uses extreme learning machines (ELMs) as base predictors due to its highly recognized efficacy. EMOEL employs evolutionary multi-objective optimization to search for the optimal parameters of the model as well as the optimal features fed into the model subjected to two conflicting criteria, i.e., accuracy and diversity. It leads to a Pareto front composed of non-dominated optimal solutions where each solution depicts the number of hidden neurons in the ELM, the selected channels in the multivariate time series, the selected feature extraction methods and the selected time windows applied to the selected channels. The optimal solutions in the Pareto front stand for different end-to-end prediction models which may lead to different prediction results. To boost ultimate prediction accuracy, the models with respect to these optimal solutions are linearly combined with combination coefficients being optimized via an evolutionary algorithm. We evaluate the proposed method in comparison to some existing prediction techniques on an Australian University based dataset, which demonstrates the superiority of the proposed method.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489261","","Feature extraction;Predictive models;Time series analysis;Data models;Optimization;Discrete wavelet transforms;Task analysis","evolutionary computation;feature extraction;feedforward neural nets;Pareto optimisation;power consumption;power engineering computing;time series","extreme learning machines;EMOEL;evolutionary multiobjective optimization;optimal parameters;optimal features;nondominated optimal solutions;ultimate prediction accuracy;evolutionary algorithm;multivariate electricity consumption prediction;energy consumption prediction;multivariate time series prediction task;energy consumption data;environmental factors;evolutionary multiobjective ensemble learning technique;feature extraction methods;time windows;prediction techniques;end-to-end prediction models;Pareto front;hidden neurons","","2","","34","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Software to Predict the Process Parameters of Electron Beam Welding","V. S. Tynchenko; S. O. Kurashkin; V. V. Tynchenko; V. V. Bukhtoyarov; V. V. Kukartsev; R. B. Sergienko; S. V. Tynchenko; K. A. Bashmur","Department of Technological Machines and Equipment of Oil and Gas Complex, School of Petroleum and Natural Gas Engineering, Siberian Federal University, Krasnoyarsk, Russia; Information-Control Systems Department, Institute of Computer Science and Telecommunications, Reshetnev Siberian State University of Science and Technology, Krasnoyarsk, Russia; Department of Computer Science, Institute of Space and Information Technologies, Siberian Federal University, Krasnoyarsk, Russia; Department of Technological Machines and Equipment of Oil and Gas Complex, School of Petroleum and Natural Gas Engineering, Siberian Federal University, Krasnoyarsk, Russia; Department of Computer Science, Institute of Space and Information Technologies, Siberian Federal University, Krasnoyarsk, Russia; Gini Gmbh, Munich, Germany; Department of Computer Science and Computer Engineering, Institute of Computer Science and Telecommunications, Reshetnev Siberian State University of Science and Technology, Krasnoyarsk, Russia; Department of Technological Machines and Equipment of Oil and Gas Complex, School of Petroleum and Natural Gas Engineering, Siberian Federal University, Krasnoyarsk, Russia","IEEE Access","1 Jul 2021","2021","9","","92483","92499","This paper discusses the problem of choosing the effective process parameters of electron beam welding (EBW). To that end, the research team has developed a mathematical model that applies machine learning to predict the effective process parameters. Since predicting process parameters requires a regression model, this research uses regression analysis algorithms such as the ridge regression and the random forest regressor. The paper analyzes whether these algorithms are applicable to the problem and tests the accuracy of their predictions. To generalize the approach and strengthen the justification of choosing the hyperparameters of the regression algorithms studied herein and considering the high variability of these hyperparameters, the multiobjective optimization technique applicable for this combinatorial problem - an (evolutionary) genetic algorithm - is proposed to determine effective sets of hyperparameters. All the models successfully addressed the task, achieving a forecasting accuracy of at least 89%. The article presents the final form of the ridge regression model describing the dependence of the weld’s depth and width: for the weld depth, there is a 2nd degree polynomial dependence with a regularization of 10<sup>−5</sup>, and for the weld width, there is a 3rd degree polynomial dependence with a regularization of 10<sup>−4</sup>. An automated system based on this approach that accurately predicts the process parameters is proposed herein. In addition to performing basic modeling functions, the proposed system allows the visualization of the model-predicted data in the form of an interactive plot. This function could be useful for technologists by allowing them to determine the process parameters that ensure the required weld dimensions. Adopting the proposed EBW parameter prediction method in practice will provide decision support for cases when engineers need to test the EBW process or to start making new products.","2169-3536","","10.1109/ACCESS.2021.3092221","Ministry of Science and Higher Education of the Russian Federation “Development of the Theory of Self-Configuring Machine Learning Algorithms for Modeling and Predicting the Characteristics of Components of Complex Systems”(grant numbers:FEFE-2020-0013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464340","Electron beam welding;choice of process parameters;software;decision support;prediction;ridge regression;random forest;genetic algorithm;algorithm ensembles;machine learning","Welding;Prediction algorithms;Electron beams;Predictive models;Correlation;Random forests;Testing","electron beam welding;genetic algorithms;learning (artificial intelligence);polynomials;production engineering computing;regression analysis","electron beam welding;regression analysis algorithms;genetic algorithm;ridge regression model;weld depth;weld width;weld dimensions;EBW parameter prediction method;EBW process;multiobjective optimization technique","","5","","37","CCBY","24 Jun 2021","","","IEEE","IEEE Journals"
"Smart Multi-Objective Evolutionary GAN","M. Baioletti; G. D. Bari; V. Poggioni; C. A. C. Coello","University of Perugia,Maths and Computer Science Dept.,Italy; University of Perugia,Maths and Computer Science Dept.,Italy; University of Perugia,Maths and Computer Science Dept.,Italy; CINVESTAV-IPN,Departamento de Computacion,Mexico","2021 IEEE Congress on Evolutionary Computation (CEC)","9 Aug 2021","2021","","","2218","2225","Generative Adversarial Network (GAN) is a family of machine learning algorithms designed to train neural networks able to imitate real data distributions. Unfortunately, GAN suffers from problems such as gradient vanishing and mode collapse. In Multi-Objective Evolutionary Generative Adversarial Network (MO-EGAN) these problems were addressed using an evolutionary technique combined with Multi-Objective selection, obtaining better results on synthetic datasets at the expense of larger computation times. In this works, we present the Smart MultiObjective Evolutionary Generative Adversarial Network (SMO-EGAN) algorithm, which reduces the computational cost of MO-EGAN and achieves better results on real data distributions.","","978-1-7281-8393-0","10.1109/CEC45853.2021.9504858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504858","","Machine learning algorithms;Neural networks;Evolutionary computation;Generative adversarial networks;Computational efficiency","data handling;evolutionary computation;learning (artificial intelligence);neural nets;optimisation","machine learning;neural networks;data distributions;multiobjective selection;smart multiobjective evolutionary GAN;smart multiobjective evolutionary generative adversarial network;SMO-EGAN","","","","20","","9 Aug 2021","","","IEEE","IEEE Conferences"
"Assembly Line Anomaly Detection and Root Cause Analysis Using Machine Learning","O. Abdelrahman; P. Keikhosrokiani","School of Computer Sciences, Universiti Sains Malaysia, Minden, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Minden, Malaysia","IEEE Access","23 Oct 2020","2020","8","","189661","189672","Anomaly detection is becoming widely used in Manufacturing Industry to enhance product quality. At the same time, it plays a great role in several other domains due to the fact that anomaly may reveal rare but represent an important phenomenon. The objective of this paper is to detect anomalies and identify the possible variables that caused these anomalies on historical assembly data for two series of products. Multiple anomaly detection techniques were performed; HBOS, IForest, KNN, CBLOF, OCSVM, LOF, and ABOD. Moreover, we used AUROC and Rank Power as performance metrics, followed by Boosting ensemble learning method to ensure the best anomaly detectors robustness. The techniques that gave the highest performance are KNN, ABOD for both product series datasets with 0.95 and 0.99 AUROC respectively. Finally, we applied a statistical root cause analysis on the detected anomalies with the use of Pareto chart to visualize the frequency of the possible causes and its cumulative occurrence. The results showed that there are seven rejection causes for both product series, whereas the first three causes are responsible for 85% of the rejection rates. Besides, assembly machines engineers reported a significant reduction in the rejection rates in both assembly machines after tuning the specification limits of the rejection causes identified by this research results.","2169-3536","","10.1109/ACCESS.2020.3029826","School of Computer Sciences, and Division of Research & Innovation, Universiti Sains Malaysia, Short Term Grant(grant numbers:304/PKOMP/6315435); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218922","Anomaly detection;assembly lines;big data;machine learning;manufacturing industries;root cause analysis;unsupervised learning","Anomaly detection;Machine learning;Measurement;Product design;Inspection;Manufacturing industries","assembling;learning (artificial intelligence);product quality;statistical analysis;support vector machines","assembly line anomaly detection;machine learning;manufacturing industry;product quality;historical assembly data;multiple anomaly detection;KNN;ABOD;performance metrics;anomaly detectors robustness;product series datasets;statistical root cause analysis;rejection rates;assembly machines engineers;rejection causes","","5","","27","CCBY","9 Oct 2020","","","IEEE","IEEE Journals"
"Pareto Self-Supervised Training for Few-Shot Learning","Z. Chen; J. Ge; H. Zhan; S. Huang; D. Wang","Westlake University,Machine Intelligence Lab (MiLAB), AI Division, School of Engineering; Westlake University,Machine Intelligence Lab (MiLAB), AI Division, School of Engineering; Westlake University,Machine Intelligence Lab (MiLAB), AI Division, School of Engineering; Westlake University,Machine Intelligence Lab (MiLAB), AI Division, School of Engineering; Westlake University,Machine Intelligence Lab (MiLAB), AI Division, School of Engineering","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","13658","13667","While few-shot learning (FSL) aims for rapid generalization to new concepts with little supervision, self-supervised learning (SSL) constructs supervisory signals directly computed from unlabeled data. Exploiting the complementarity of these two manners, few-shot auxiliary learning has recently drawn much attention to deal with few labeled data. Previous works benefit from sharing inductive bias between the main task (FSL) and auxiliary tasks (SSL), where the shared parameters of tasks are optimized by minimizing a linear combination of task losses. However, it is challenging to select a proper weight to balance tasks and reduce task conflict. To handle the problem as a whole, we propose a novel approach named as Pareto self-supervised training (PSST) for FSL. PSST explicitly decomposes the few-shot auxiliary problem into multiple constrained multi-objective subproblems with different trade-off preferences, and here a preference region in which the main task achieves the best performance is identified. Then, an effective preferred Pareto exploration is proposed to find a set of optimal solutions in such a preference region. Extensive experiments on several public benchmark datasets validate the effectiveness of our approach by achieving state-of-the-art performance.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.01345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577454","","Training;Computer vision;Pareto optimization;Benchmark testing;Space exploration;Pattern recognition;Task analysis","Pareto optimisation;supervised learning","Pareto self-supervised training;FSL;rapid generalization;self-supervised learning;SSL;supervisory signals;unlabeled data;few-shot auxiliary learning;inductive bias;auxiliary tasks;shared parameters;task losses;task conflict;PSST;few-shot auxiliary problem;multiple constrained multiobjective subproblems;preference region;effective preferred Pareto exploration;few labeled data","","2","","50","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"The Potential of Sentinel Satellites for Large Area Aboveground Forest Biomass Mapping","A. Haywood; C. Stone; S. Jones","School of Mathematical and Geospatial Sciences, RMIT University, Melbourne, Australia; New South Wales Department of Industry - Lands, Sydney, Australia; School of Mathematical and Geospatial Sciences, RMIT University, Melbourne, Australia","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","9030","9033","Estimation of aboveground forest biomass is critical for regional carbon policies and sustainable forest management. Both passive optical remote sensing and active microwave remote sensing can play an important role in the monitoring of forest biomass. In this study, the recently launched Sentinel-2 Multi Spectral Instrument satellite and Sentinel-1 SAR satellite systems were evaluated and integrated to investigate the relative strengths of each sensor for mapping aboveground forest biomass at a regional scale. The Australian state of Victoria, with its wide range of forest vegetation was chosen as the study area to demonstrate the scalability and transferability of the approach. In this study aboveground forest biomass (AGB) was defined as the tons of carbon per hectare for the aboveground components (stem, branches, leaves) of all live large trees greater than 10 cm in diameter at breast height (DBHOB). Sentinel-2 and Sentinel-1 data were fused within a machine learning framework using a boosted regression tree model and high-quality ground survey data. Multicriteria evaluations showed the use of the two independent and fundamentally different Sentinel satellite systems were able to provide robust estimates (R<sup>2</sup> of 0.62, RMSE of 32.2 t.C.ha<sup>-1</sup>) of aboveground forest biomass, with each sensor compensating for the weakness (cloud perturbations and spectral saturation for Sentinel 2, and sensitivity to ground moisture for Sentinel 1) of each other. As archives for Sentinel-2 and Sentinel-1 continue to grow, mapping aboveground forest biomass and dynamics at moderate resolution over large regions should become increasingly feasible.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8517597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517597","biomass estimation;Sentinel-1;Sentinel-2;machine learning;boosted regression tree model;data fusion;Victoria;Australia","Forestry;Biomass;Vegetation;Meteorology;Satellites;Surfaces;Carbon","forestry;geophysical techniques;regression analysis;remote sensing by radar;synthetic aperture radar;vegetation;vegetation mapping","Sentinel satellite systems;Sentinel-2 MultiSpectral Instrument satellite;diameter at breast height;ground moisture;Australian state;Victoria;high-quality ground survey data;boosted regression tree model;Sentinel-1 data;aboveground components;forest vegetation;Sentinel-1 SAR satellite systems;active microwave remote sensing;passive optical remote sensing;sustainable forest management;area aboveground forest biomass mapping","","1","","11","","4 Nov 2018","","","IEEE","IEEE Conferences"
"Imbalanced learning with a biased minimax probability machine","Kaizhu Huang; Haiqin Yang; Irwin King; M. R. Lyu","Inf. Technol. Lab., Fujitsu R&D Center Co. Ltd., Beijing, China; NA; NA; NA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","17 Jul 2006","2006","36","4","913","923","Imbalanced learning is a challenged task in machine learning. In this context, the data associated with one class are far fewer than those associated with the other class. Traditional machine learning methods seeking classification accuracy over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into a majority class, usually the less important class. In this correspondence, the authors describe a new approach named the biased minimax probability machine (BMPM) to deal with the problem of imbalanced learning. This BMPM model is demonstrated to provide an elegant and systematic way for imbalanced learning. More specifically, by controlling the accuracy of the majority class under all possible choices of class-conditional densities with a given mean and covariance matrix, this model can quantitatively and systematically incorporate a bias for the minority class. By establishing an explicit connection between the classification accuracy and the bias, this approach distinguishes itself from the many current imbalanced-learning methods; these methods often impose a certain bias on the minority data by adapting intermediate factors via the trial-and-error procedure. The authors detail the theoretical foundation, prove its solvability, propose an efficient optimization algorithm, and perform a series of experiments to evaluate the novel model. The comparison with other competitive methods demonstrates the effectiveness of this new model.","1941-0492","","10.1109/TSMCB.2006.870610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1658302","Fractional programming (FP);imbalanced learning;receiver operating characteristic (ROC) analysis;worst case accuracy","Machine learning;Minimax techniques;Costs;Sampling methods;Learning systems;Covariance matrix;Performance evaluation;Proposals;Councils;Information technology","learning (artificial intelligence);minimax techniques;probability;covariance matrices","imbalanced learning;biased minimax probability machine;machine learning;covariance matrix;trial-and-error procedure","Algorithms;Artificial Intelligence;Computer Simulation;Models, Statistical;Pattern Recognition, Automated","38","","45","IEEE","17 Jul 2006","","","IEEE","IEEE Journals"
"Chess Moves Prediction using Deep Learning Neural Networks","H. Panchal; S. Mishra; V. Shrivastava","St. Francis Institute of Technology,Computer Engineering,Mumbai,India; St. Francis Institute of Technology,Computer Engineering,Mumbai,India; St. Francis Institute of Technology,Computer Engineering,Mumbai,India","2021 International Conference on Advances in Computing and Communications (ICACC)","15 Feb 2022","2021","","","1","6","Chess is a game that is popular for high intelligence and strategic thinking. There has been a lot of research on chess for predicting chess moves, applying chess game theory, and automating chess games. The art of playing chess using computer vision can be implemented using various learning algorithms. A class of Deep Learning has the ability to solve problems of predicting chess moves although facing the necessity of huge datasets. The traditional chess algorithm Minimax with the Convolutional Neural Network can perceive and learn the patterns and rules in chess i.e., identification of some small and native tactics of the game, and should be trained on this method with appropriate functions for smarter universal play. CNN when trained with appropriate architecture and validation data can learn to function based on the reasoning in complex logical tasks. Training on 15,00,000 board states in the dataset which is a board state represented as 8x8x14 dimensions. Each board state is given as an input to the input layer of the Convolutional Neural Network. The CNN model tested and validated against the stockfish chess engine achieved the best accuracy of 39.16% for board evaluation. However, this doesn’t reflect the actual accuracy of the model since the evaluation by the model is relative for two different board states. CNN learning the game of chess and based on the result of chess is essentially pre-computation on a given situation.","","978-1-6654-3919-0","10.1109/ICACC-202152719.2021.9708405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708405","Chess Moves Prediction;Convolution Neural Network;Deep Learning;Strategy Board Game","Training;Deep learning;Neural networks;Games;Prediction algorithms;Convolutional neural networks;Object recognition","","","","","","11","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Pareto-Optimal Quantized ResNet Is Mostly 4-bit","A. Abdolrashidi; L. Wang; S. Agrawal; J. Malmaud; O. Rybakov; C. Leichner; L. Lew","University of California,Riverside,CA,USA; Google Research,Mountain View,CA,USA; Google Research,Mountain View,CA,USA; Google Research,Mountain View,CA,USA; Google Research,Mountain View,CA,USA; Google Research,Mountain View,CA,USA; Google Research,Mountain View,CA,USA","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","3085","3093","Quantization has become a popular technique to compress neural networks and reduce compute cost, but most prior work focuses on studying quantization without changing the network size. Many real-world applications of neural networks have compute cost and memory budgets, which can be traded off with model quality by changing the number of parameters. In this work, we use ResNet as a case study to systematically investigate the effects of quantization on inference compute cost-quality tradeoff curves. Our results suggest that for each bfloat16 ResNet model, there are quantized models with lower cost and higher ac-curacy; in other words, the bfloat16 compute cost-quality tradeoff curve is Pareto-dominated by the 4-bit and 8-bit curves, with models primarily quantized to 4-bit yielding the best Pareto curve. Furthermore, we achieve state-of-the-art results on ImageNet for 4-bit ResNet-50 with quantization-aware training, obtaining a top-1 eval accuracy of 77.09%. We demonstrate the regularizing effect of quantization by measuring the generalization gap. The quantization method we used is optimized for practicality: It requires little tuning and is designed with hardware capabilities in mind. Our work motivates further research into optimal numeric formats for quantization, as well as the development of machine learning accelerators supporting these formats. As part of this work, we contribute a quantization library written in JAX, which is open-sourced at https://github.com/google-research/google-research/tree/master/aqt.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522934","","Training;Analytical models;Quantization (signal);Computational modeling;Neural networks;Libraries;Hardware","learning (artificial intelligence);neural nets;Pareto optimisation;quantisation (signal)","neural networks;model quality;inference compute cost-quality tradeoff curves;bfloat16 ResNet model;bfloat16 compute cost-quality tradeoff curve;Pareto-dominated;8-bit curves;Pareto curve;4-bit ResNet-50;quantization-aware training;quantization method;quantization library;Pareto-optimal quantized ResNet;studying quantization;network size;JAX","","","","38","","1 Sep 2021","","","IEEE","IEEE Conferences"
"An Integrated Expert System with a Supervised Machine Learning based Probabilistic Approach to Play Tic-Tac-Toe","M. S. K. Inan; R. Hasan; T. T. Prama","East Delta University,Dept. of Computer Science & Engineering,Chittagong,Bangladesh; East Delta University,Dept. of Computer Science & Engineering,Chittagong,Bangladesh; Jahangirnagar University,Dept. of Computer Science & Engineering,Dhaka,Bangladesh","2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","10 Jan 2022","2021","","","0116","0120","Tic-Tac-Toe, also known as Noughts and Crosses, is a widely popular game among people of all ages. In recent times, due to the rapid development of Artificial Intelligence (AI) based algorithms, AI in Games has become an interesting topic for research in both academia and industry. Due to the complicated yet competent nature of AI algorithms, the design and implementation of such AI-driven approaches in games are challenging and time intensive. In this regard, we propose a supervised Machine Learning (ML)-based approach that contributes in designing an innovative and less complex Tic-Tac-Toc expert system. Integrating AI and ML in the solution process will lead the concerned community toward a more lightweight and computationally efficient systems for playing games. In this study, we propose a novel algorithmic solution by combining an ensemble-based boosting approach and rule-based inference to build a probabilistic expert system that strategically chooses the best optimal move for next possible state of the game. A benchmark dataset containing 255,168 unique game states of Tic Tac Toe was utilized at training stage. The proposed strategy is able to successfully settle a draw against never-loosing MiniMax algorithm in 18 standard test cases.","","978-1-6654-0690-1","10.1109/UEMCON53757.2021.9666728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666728","noughts and crosses;machine learning in games;xgboost;tic tac toe;ai in games","Training;Machine learning algorithms;Merging;Games;Reinforcement learning;Probabilistic logic;Mobile communication","","","","","","22","","10 Jan 2022","","","IEEE","IEEE Conferences"
"Pareto-Optimal Active Learning with Cost","S. Adams; T. Cody; P. A. Beling","Virginia Tech.,Hume Center for National Defense and Technology; Virginia Tech.,Hume Center for National Defense and Technology; Virginia Tech.,Intelligent Systems Lab in Hume Center for National Security and Technology,Grado Department of Industrial and Systems Engineering","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1519","1526","Supervised learning algorithms require a set of labeled training data. In many engineering applications, acquiring and accurately labeling the training data can be time consuming, burdensome, and costly. Active learning is an area of machine learning that selects observations in an unlabeled set to be passed to an oracle to retrieve the ground truth label, thereby improving the efficiency of the labeling and training process. However, most active learning algorithms only consider model improvement and, therefore, ignore cost considerations. The active learning algorithms that do consider cost require the practitioner to specify the trade-off between model improvement and cost. We propose an active learning with cost method that does not require this trade-off to be specified by randomly sampling observations from the Pareto optimal frontier. Further, we propose an extension to this method that accounts for uncertainty in the cost estimate of labeling an observation. These methods are evaluated on publicly available data sets, and the numerical experiments demonstrate that the proposed methods can produce models that achieve similar performance to standard active learning algorithms while reducing the labeling cost.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9658761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658761","","Measurement;Training;Costs;Uncertainty;Machine learning algorithms;Training data;Pareto optimization","","","","","","51","","6 Jan 2022","","","IEEE","IEEE Conferences"
"DyBatch: Efficient Batching and Fair Scheduling for Deep Learning Inference on Time-sharing Devices","S. Zhang; W. Li; C. Wang; Z. Tari; A. Y. Zomaya","The University of Sydney,School of Computer Science,Australia; The University of Sydney,School of Computer Science,Australia; CSIRO,Data61,Sydney,Australia; RMIT,School of Science,Melbourne,Australia; The University of Sydney,School of Computer Science,Australia","2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)","14 Jul 2020","2020","","","609","618","Recently, Deep Learning (DL) is widely applied to intelligent systems equipped with resource-constraint hardware accelerators. With multiple DL applications sharing the resource, the execution model can be divided into two stages: (i) batching independent inference tasks initiated by each application, and (ii) scheduling batches to run in a time-sharing manner. The state-of-the-art DL serving systems employ the execution model by organizing sequential tasks into batches and then scheduling batches concerning their targeting deep neural network (DNN) models in a round-robin manner. However, we demonstrated that these practices fail to alleviate the slowdown of tasks, and there is a need to re-visit batching and scheduling in terms of efficiency and fairness. To this end, we formulated batching as a resource allocation problem and investigated scheduling in terms of each application's utilization on the device. Then, we proposed the fine-grained batching scheme and fairness-driven scheduling scheme for DL serving and implemented a prototype system called DyBatch. To be exact, DyBatch accomplishes efficient batching by taking into account Pareto efficiency of and envy between batches. Besides, DyBatch's fair scheduler monitors the resource utilization of all applications and assigns a batch from the application with the lowest utilization for execution first. Evaluation under various benchmarks with comparison to the baseline system Tensorflow Serving (TFS) shows the superiority of DyBatch, which achieves up to 55% reduction of slowdown, and up to 12% improvement of throughput.","","978-1-7281-6095-5","10.1109/CCGrid49817.2020.00-32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139602","deep learning inference;batching;scheduling;efficiency;fairness;model serving","Task analysis;Resource management;Scheduling;Machine learning;Graphics processing units;Data models;Throughput","inference mechanisms;learning (artificial intelligence);neural nets;resource allocation;scheduling","resource-constraint hardware accelerators;multiple DL applications;batching independent inference tasks;resource allocation problem;fine-grained batching scheme;fairness-driven scheduling;resource utilization;tensorflow serving;deep learning inference;time-sharing devices;DL serving systems;deep neural network models;round-robin manner;DyBatch's fair scheduler;batches scheduling","","","","26","","14 Jul 2020","","","IEEE","IEEE Conferences"
"Data Mining-Based Model Simplification and Optimization of an Electrical Power Generation System","Z. Dai; L. Wang; S. Yang","Department of Electrical Engineering, College of Automation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Electrical Engineering, College of Automation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Electrical Engineering, College of Automation, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Transactions on Transportation Electrification","30 Oct 2020","2020","6","4","1665","1678","To assess the performance of electrification in an aircraft, multiphysics modeling becomes a good choice for the design of more-electric equipment. However, the high computational cost and huge design space of this complex model lead to difficulties in the optimal design of the electrical power system, thus model simplification is mandatory. For this purpose, this article first proposes a novel model simplification approach based on data mining, and the design of a small electrical power generation system is investigated to demonstrate it. According to the formulated multiphysics model of the system, this article uses the optimal Latin Hypercube-based design of experiment to generate data for the analysis. Based on the generated data, a fusion algorithm integrating multiple feature selection methods is presented to facilitate the dimensionality reduction of the problem's design space. Also, machine learning algorithms are applied to the surrogate model establishment, allowing the reduction of computational time. The investigation of various optimization routines with various multiobjective genetic algorithms shows that the proposed practices improve the system-level optimization efficiency with low computational complexity, ease of search, and high accuracy, which is competitive compared with state-of-the-arts.","2332-7782","","10.1109/TTE.2020.2995745","National Natural Science Foundation of China(grant numbers:51877102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096396","Classification;data mining (DM);design of experiment (DoE);electric machine;electrified aircraft;feature selection;machine learning;model simplification;system-level design","Machine learning;Data mining;Aircraft;Optimization;Generators;Feature extraction;Data models","aerospace computing;aircraft power systems;computational complexity;data mining;design of experiments;electric power generation;feature selection;genetic algorithms;learning (artificial intelligence);power engineering computing","optimal design;electrical power system;model simplification;multiphysics model;optimal Latin Hypercube-based design;fusion algorithm;surrogate model establishment;feature selection;computational cost;performance assessment;aircraft;multiobjective genetic algorithms;computational complexity;dimensionality reduction;design space;electric equipment;multiphysics modeling;electrical power generation system;data mining;system-level optimization efficiency","","1","","56","IEEE","19 May 2020","","","IEEE","IEEE Journals"
"Deep Neural Language-agnostic Multi-task Text Classifier","K. Gawron; M. Pogoda; N. Ropiak; M. Swędrowski; J. Kocoń","Wrocław University of Science and Technology,Department of Artificial Intelligence,Poland; Wrocław University of Science and Technology,Department of Artificial Intelligence,Poland; Wrocław University of Science and Technology,Department of Artificial Intelligence,Poland; Wrocław University of Science and Technology,Department of Artificial Intelligence,Poland; Wrocław University of Science and Technology,Department of Artificial Intelligence,Poland","2021 International Conference on Data Mining Workshops (ICDMW)","20 Jan 2022","2021","","","136","142","Many publications prove that the creation of a multiobjective machine learning model is possible and reasonable. Moreover, we can see significant gains in expanding the knowledge domain, increasing prediction quality, and reducing the inference time. New developments in cross-lingual knowledge transfer open up a range of possibilities, particularly in working with low-resource languages. With a motivation to explore the latest subfields of natural language processing and their interactions, we decided to create a multi-task multilingual model for the following text classification tasks: functional style, domain, readability, and sentiment. The paper discusses the effectiveness of particular language-agnostic approaches to Polish and English and the effectiveness and validity of the multi-task model.","2375-9259","978-1-6654-2427-1","10.1109/ICDMW53433.2021.00023","Ministry of Education and Science; European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679896","deep learning;language-agnostic;multi-task text classification","Conferences;Text categorization;Machine learning;Multitasking;Natural language processing;Data mining;Task analysis","learning (artificial intelligence);natural language processing;neural nets;pattern classification;text analysis","multitask model;neural language-agnostic multitask text classifier;multiobjective machine learning model;knowledge domain;prediction quality;inference time;cross-lingual knowledge transfer;low-resource languages;natural language processing;multitask multilingual model;text classification tasks;particular language-agnostic approaches","","","","35","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Machine Learning Meets Quantitative Planning: Enabling Self-Adaptation in Autonomous Robots","P. Jamshidi; J. Cámara; B. Schmerl; C. Käestner; D. Garlan",University of South Carolina; University of York; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,"2019 IEEE/ACM 14th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)","5 Aug 2019","2019","","","39","50","Modern cyber-physical systems (e.g., robotics systems) are typically composed of physical and software components, the characteristics of which are likely to change over time. Assumptions about parts of the system made at design time may not hold at run time, especially when a system is deployed for long periods (e.g., over decades). Self-adaptation is designed to find reconfigurations of systems to handle such run-time inconsistencies. Planners can be used to find and enact optimal reconfigurations in such an evolving context. However, for systems that are highly configurable, such planning becomes intractable due to the size of the adaptation space. To overcome this challenge, in this paper we explore an approach that (a) uses machine learning to find Pareto-optimal configurations without needing to explore every configuration and (b) restricts the search space to such configurations to make planning tractable. We explore this in the context of robot missions that need to consider task timeliness and energy consumption. An independent evaluation shows that our approach results in high-quality adaptation plans in uncertain and adversarial environments.","2157-2321","978-1-7281-3368-3","10.1109/SEAMS.2019.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787014","Machine learning, artificial intelligence, quantitative planning, self-adaptive systems, robotics systems","Planning;Robot sensing systems;Adaptation models;Software;Machine learning;Energy consumption","control engineering computing;cyber-physical systems;learning (artificial intelligence);Pareto optimisation;robot programming","Pareto-optimal configurations;search space;robot missions;machine learning;quantitative planning;autonomous robots;modern cyber-physical systems;robotics systems;software components;run-time inconsistencies;optimal reconfigurations;self-adaptation","","19","","59","","5 Aug 2019","","","IEEE","IEEE Conferences"
"A semi-supervised learning-aided evolutionary approach to occupational safety improvement","M. Cococcioni; B. Lazzerini; F. Pistolesi","Department of Information Engineering, University of Pisa, Largo L. Lazzarino 1, 56122 Pisa, IT; Department of Information Engineering, University of Pisa, Largo L. Lazzarino 1, 56122 Pisa, IT; Department of Information Engineering, University of Pisa, Largo L. Lazzarino 1, 56122 Pisa, IT","2016 IEEE Congress on Evolutionary Computation (CEC)","21 Nov 2016","2016","","","3695","3701","Worldwide, four people die every minute as a consequence of illnesses and accidents at work. This considerable number makes occupational safety an important research area aimed at obtaining safer and safer workplaces. This paper presents a semi-supervised learning-aided evolutionary approach to improve occupational safety by classifying workers depending on their own risk perception for the task assigned. More in detail, a semi-supervised learning phase is carried out to initialize a good population of a non-dominated sorting genetic algorithm (NSGA-II). Each chromosome of the population represents a pair of classifiers: one determines a worker's risk perception with respect to a task, the other determines the level of caution of the same worker for the same task. Learning from constraints reinforces the initial training performance. The best Pareto-optimal solution to the problem is selected by means of the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). The proposed framework was tested on real-world data gathered through a website purposely developed. Results showed a good performance of the obtained classifiers, thus validating the effectiveness of the proposed approach in supporting the decision-maker in critical job assignment problems, where risks are a serious threat to the workers' health.","","978-1-5090-0623-6","10.1109/CEC.2016.7744257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744257","","Biological cells;Occupational safety;Accidents;Genetic algorithms;Optimization;Employment;Semisupervised learning","genetic algorithms;learning (artificial intelligence);occupational safety;TOPSIS","semisupervised learning-aided evolutionary approach;occupational safety improvement;safer workplaces;risk perception;semisupervised learning phase;nondominated sorting genetic algorithm;NSGA-II;Pareto optimal solution;Technique for Order of Preference by Similarity to Ideal Solution;TOPSIS;Web site;decision maker;critical job assignment problems;workers health","","8","","15","","21 Nov 2016","","","IEEE","IEEE Conferences"
"A New MCDM Approach to Solve Public Sector Planning Problems","P. O. Kaplan; S. R. Ranjithan","North Carolina State University, Department of Civil, Construction and Environmental Engineering, Raleigh, NC 27695 USA; North Carolina State University, Department of Civil, Construction and Environmental Engineering, Raleigh, NC 27695 USA","2007 IEEE Symposium on Computational Intelligence in Multi-Criteria Decision-Making","4 Jun 2007","2007","","","153","159","An interactive method is developed to aid decision makers in public sector planning and management. The method integrates machine learning algorithms along with multiobjective optimization and modeling-to-generate-alternatives procedures into decision analysis. The implicit preferences of the decision maker are elicited through screening of several alternatives. The alternatives are selected from Pareto front and near Pareto front regions that are identified first in the procedure. The decision maker's selections are input to the machine learning algorithms to generate decision rules, which are then incorporated into the analysis to generate more alternatives satisfying the decision rules. The method is illustrated using a municipal solid waste management planning problem","","1-4244-0702-8","10.1109/MCDM.2007.369430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4222996","MCDM;interactive methods;association rule mining;preference elicitation methods","Decision making;Machine learning algorithms;Delta modulation;Algorithm design and analysis;Data mining;Machine learning;Association rules;Decision trees;Application software;Computational intelligence","data mining;decision making;decision support systems;learning (artificial intelligence);operations research;Pareto optimisation;planning;public administration","public sector planning;interactive multiple criteria decision making;machine learning algorithms;multiobjective optimization;modeling-to-generate-alternatives procedures;Pareto front;municipal solid waste management planning;association rule mining;preference elicitation methods","","5","","26","","4 Jun 2007","","","IEEE","IEEE Conferences"
"Multilayer Value Metrics Using Lexical Link Analysis and Game Theory for Discovering Innovation from Big Data and Crowd-Sourcing","Y. Zhao; C. C. Zhou; J. K. Bellonio","Naval Postgraduate School, Monterey, CA, 93943, USA; Quantum Intelligence Inc., Monterey, CA, 93943, USA; Naval Postgraduate School, Monterey, CA, 93943, USA","2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","25 Oct 2018","2018","","","1145","1151","We demonstrated a machine learning and artificial intelligence method, i.e., lexical link analysis (LLA) to discover different layers of semantic network that contribute to innovative ideas from big data. The LLA is an unsupervised machine learning paradigm that does not require manually labeled training data. Multilayer value metrics are defined based on game theory for LLA. We showed the following results: 1) the value metrics generated from LLA in a use case of an internet game and crowd-sourcing; 2) the results from LLA are validated and correlated with the ground truth; 3) the game-theoretic LLA can help an information provider to present the information in the most valuable way. The information presentation can solve a problem (e.g., a search request of innovation) that no other information providers can solve (i.e., expertise). In addition, it ties also to a broader context that the unique value can propagate through the consensus. Based on the game-theoretic LLA, an information provider should not always present expertise content or authoritative content but rather with a mixed strategy where each type of content is presented with certain probabilities for the best value overall.","2473-991X","978-1-5386-6051-5","10.1109/ASONAM.2018.8508498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8508498","lexical link analysis;crowd-sourcing;game theory;big data;unsupervised learning;Nash equilibrium;social welfare;Pareto superior;Pareto efficient","Measurement;Nonhomogeneous media;Nash equilibrium;Social network services;Games;Technological innovation","game theory;information retrieval;innovation management;Internet;semantic networks;unsupervised learning","multilayer value metrics;lexical link analysis;game theory;innovation;big data;crowd-sourcing;machine learning;artificial intelligence method;innovative ideas;unsupervised machine;manually labeled training data;game-theoretic LLA;information provider;information presentation;Internet game;expertise content;authoritative content","","1","","28","","25 Oct 2018","","","IEEE","IEEE Conferences"
"Improving POF Quality in Multi Objective Optimization of Analog ICs via Deep Learning","T. O. Çakıcı; G. İslamoğlu; Ş. N. Güzelhan; E. Afacan; G. Dündar","Boğaziçi University,Department of Electrical and Electronics Engineering; Boğaziçi University,Department of Electrical and Electronics Engineering; Boğaziçi University,Department of Electrical and Electronics Engineering; Sorbonne University,Laboratoire d’Informatique de Paris 6; Boğaziçi University,Department of Electrical and Electronics Engineering","2020 European Conference on Circuit Theory and Design (ECCTD)","9 Oct 2020","2020","","","1","4","Multi-objective optimization (MOO) is commonly used in analog circuits to reveal the trade-offs among design specifications via Pareto optimal fronts (POF). Although the general trend of POF can be found in a reasonable time with MOO, a high-quality POF requires an excessive number of iterations, which results in extremely long synthesis times. In this paper, single-objective optimization (SOO) is utilized to increase the POF quality rather than running MOO algorithms for long duration. Moreover, deep neural networks (DNN) are used to replace SPICE, which reduces the synthesis time further. This approach provides up to 50.62% improvement in POF quality and DNNs speed up the process up to 29.6x.","2474-9672","978-1-7281-7183-8","10.1109/ECCTD49232.2020.9218272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218272","","Optical fibers;Optimization;Neural networks;Tools;Measurement;Integrated circuits;Analog circuits","analogue integrated circuits;learning (artificial intelligence);neural nets;Pareto optimisation","analog circuits;Pareto optimal fronts;high-quality POF;single-objective optimization;POF quality;MOO algorithms;deep neural networks;multiobjective optimization;analog ICs;deep learning;SOO;DNN;SPICE;design specifications","","","","12","","9 Oct 2020","","","IEEE","IEEE Conferences"
"Genetic algorithm-based optimization of ELM for on-line hyperspectral image classification","J. Echanobe; I. del Campo; V. Martínez; K. Basterretxea","Dep. Electricity and Electronics, University of the Basque Country (UPV/EHU), Leioa, Basque Country, Spain; Dep. Electricity and Electronics, University of the Basque Country (UPV/EHU), Leioa, Basque Country, Spain; Dep. Electricity and Electronics, University of the Basque Country (UPV/EHU), Leioa, Basque Country, Spain; Dep. Electronic Technology, University of the Basque Country (UPV/EHU), Bilbao, Basque Country, Spain","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","4202","4207","Hyperspectral remote sensing is becoming an active research field in the last decades thanks to the availability of efficient machine learning algorithms and also to the ever-increasing computation power. However, there exist application domains (e.g., embedded applications) in which the deployment of this kind of systems becomes unfeasible due to the high requirements related to the size, power consumption or processing speed. A way to overcome this trouble consists on using any method able to scale-down the dimensionality of the problem and/or to reduce the complexity of the machine learning models. In this paper, we propose the use of a multiobjective genetic algorithm to minimize both the dimension of the input space and the size of the machine learning model. In particular, we have developed a hyperspectral image classifier based on an Extreme Learning Machine (ELM) for which the number of system inputs (dimensionality) and the number of hidden neurons are minimized without decreasing its performance. The system is evaluated by using a known benchmark dataset.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966387","Extreme Learning Machines (ELM);Multi-Objective Genetic Algorithm;Machine Learning;Hyperspectral remote sensing;Dimensionality reduction","Genetic algorithms;Hyperspectral imaging;Neurons;Classification algorithms;Optimization;Algorithm design and analysis","computational complexity;genetic algorithms;hyperspectral imaging;image classification;learning (artificial intelligence);remote sensing","genetic algorithm-based optimization;online hyperspectral image classification;hyperspectral remote sensing;machine learning;embedded applications;power consumption;processing speed;complexity reduction;multiobjective genetic algorithm;input space dimension minimization;hyperspectral image classifier;extreme learning machine;ELM","","2","","13","","3 Jul 2017","","","IEEE","IEEE Conferences"
"A Gaussian-Prioritized Approach for Deploying Additional Route on Existing Mass Transportation with Neural-Network-Based Passenger Flow Inference","F. Lin; J. -Y. Fang; H. -P. Hsieh","National Cheng Kung University,Institute of Computer and Communication Engineering,Tainan,Taiwan; National Cheng Kung University,Institute of Computer and Communication Engineering,Tainan,Taiwan; National Cheng Kung University,Department of Electrical Engineering,Tainan,Taiwan","2020 IEEE Congress on Evolutionary Computation (CEC)","3 Sep 2020","2020","","","1","8","Multi-criteria path planning is an important combinatorial optimization problem with broad real-world applications. Finding the Pareto-optimal set of paths ideal for all requiring features is time-consuming and unclear to obtain the subset of optimal paths efficiently for multiple origin states in the planning space. Meanwhile, due to the rise of deep learning, hybrid systems of computational intelligence thrive in recent years. When facing non-monotonic data or heuristics derived from pretrained neural networks, most of the existing methods for the oneto-all path problem fail to find an ideal solution. We employ Gaussian mixture model to propose a target-prioritized searching algorithm called Multi-Source Bidirectional Gaussian-Prioritized Spanning Tree (BiasSpan) in solving this non-monotonic multicriteria route planning problem given constraints including range, must-visit vertices, and the number of recommended vertices. Experimental results on mass transportation system in Tainan and Chicago cities show that BiasSpan outperforms comparative methods from 7% to 24% and runs in a reasonable time compared to state-of-art route-planning algorithms.","","978-1-7281-6929-3","10.1109/CEC48606.2020.9185869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185869","Constrained route planning;Bidirectional spanning tree;Gaussian mixture model (GMM);Non-monotonicity;Deep Neural Network (DNN)","Feature extraction;Planning;Trajectory;Statistics;Roads;Urban areas","collision avoidance;computational complexity;Gaussian processes;learning (artificial intelligence);mobile robots;network theory (graphs);neural nets;optimisation;Pareto optimisation;path planning;search problems;transportation;trees (mathematics)","BiasSpan;nonmonotonic multicriteria route planning problem given constraints including range;mass transportation system;state-of-art route-planning algorithms;gaussian-prioritized approach;additional route;neural-network-based passenger flow inference;Multicriteria path planning;important combinatorial optimization problem;real-world applications;requiring features;optimal paths;multiple origin states;planning space;deep learning;hybrid systems;computational intelligence;facing nonmonotonic data;pretrained neural networks;oneto-all path problem;Gaussian mixture model;target-prioritized searching algorithm;MultiSource Bidirectional Gaussian-Prioritized","","","","43","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Dimensionality reduction based on minimax risk criterion for face recognition","L. Tang; Y. Lei; L. Zhu; D. Huang","Intelligent Computing Lab, Hefei Institute of Intelligent Machines, Chinese Academy of Sciences, P.O.Box 1130, Anhui 230031, China; Intelligent Computing Lab, Hefei Institute of Intelligent Machines, Chinese Academy of Sciences, P.O.Box 1130, Anhui 230031, China; Intelligent Computing Lab, Hefei Institute of Intelligent Machines, Chinese Academy of Sciences, P.O.Box 1130, Anhui 230031, China; Intelligent Computing Lab, Hefei Institute of Intelligent Machines, Chinese Academy of Sciences, P.O.Box 1130, Anhui 230031, China","The 2010 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2010","2010","","","1","6","In the field of pattern recognition and machine learning, many problems are involved in the tasks of dimensionality reduction and then classification. In this paper, we develop an efficient dimensionality reduction method named MiniRisk Supervised Discrimiant Projection (MRSDP), which extracts effective low-dimensional features for classification purpose. The proposed method utilizes discriminant information to guide the procedure of extracting intrinsic low-dimensional features and provides a linear projection matrix. Since MRSDP is based on minimax risk criterion, it can minimize the maximal probability of misclassification in the common borders of different classes of data by contracting within-class scatter and maximizing between-class scatter. The advantage of our method is borne out by comparison with other widely used methods. In the experiments on Yale face database and ORL face database, our method achieves constantly superior performance than those competing methods.","2161-4407","978-1-4244-6918-5","10.1109/IJCNN.2010.5596520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596520","","Databases;Principal component analysis","face recognition;learning (artificial intelligence);minimax techniques","dimensionality reduction method;minimax risk criterion;face recognition;pattern recognition;machine learning;MSRDP;features extraction;linear projection matrix;misclassification probability;Yale face database;ORL face database;minirisk supervised discriminant projection","","1","","23","","14 Oct 2010","","","IEEE","IEEE Conferences"
"Learning classifiers from imbalanced data based on biased minimax probability machine","Kaizhu Huang; Haiqin Yang; I. King; M. R. Lyu","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China; Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, China","Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.","19 Jul 2004","2004","2","","II","II","We consider the problem of the binary classification on imbalanced data, in which nearly all the instances are labelled as one class, while far fewer instances are labelled as the other class, usually the more important class. Traditional machine learning methods seeking an accurate performance over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into the majority, usually the less important class. Moreover, some current methods have tried to utilize some intermediate factors, e.g., the distribution of the training set, the decision thresholds or the cost matrices, to influence the bias of the classification. However, it remains uncertain whether these methods can improve the performance in a systematic way. In this paper, we propose a novel model named biased minimax probability machine. Different from previous methods, this model directly controls the worst-case real accuracy of classification of the future data to build up biased classifier;. Hence, it provides a rigorous treatment on imbalanced data. The experimental results on the novel model comparing with those of three competitive methods, i.e., the naive Bayesian classifier, the k-nearest neighbor method, and the decision tree method C4.5, demonstrate the superiority of our novel model.","1063-6919","0-7695-2158-4","10.1109/CVPR.2004.1315213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315213","","Machine learning;Minimax techniques;Costs;Sampling methods;Classification tree analysis;Educational institutions;Computer science;Data engineering;Learning systems;Bayesian methods","learning (artificial intelligence);minimax techniques;probability;data handling;pattern classification","learning classifiers;imbalanced data;biased minimax probability machine;binary classification;machine learning methods","","12","","12","","19 Jul 2004","","","IEEE","IEEE Conferences"
"Investigating the Robustness and Stability to Noisy Data of a Dynamic Feature Selection Method","J. Jesus; A. Canuto; D. Araújo",Federal University of Rio Grande do Norte - UFRN; Federal University of Rio Grande do Norte - UFRN; Federal University of Rio Grande do Norte - UFRN,"2019 8th Brazilian Conference on Intelligent Systems (BRACIS)","5 Dec 2019","2019","","","180","185","The curse of dimensionality is one of the major problems faced by machine learning researchers. If we consider the fast growing of complex data in real world scenarios, feature selection (FS) becomes a imperative step for many application domains to reduce both data complexity and computing time. Based on that, several studies have been developed in order to create efficient FS methods that performs this task. However, a bad selection of one single criterion to evaluate the attribute importance and the arbitrary choice of the number of features usually leads to a poor analysis. On the other hand, recent studies have successfully created models to select features considering the particularities of the data, known as dynamic feature selection. In this paper, we evaluate one of this successful methods, called pareto front based dynamic feature selection (PF-DFS), to test its stability and robustness in noisy data. We used 15 artificial and real world data with additional noise data. Results shown that the PF-DFS is more stable to noisy scenarios than existing feature selection methods.","2643-6264","978-1-7281-4253-1","10.1109/BRACIS.2019.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923792","feature selection;dynamic feature selection;data analysis;pareto front;supervised learning","Feature extraction;Heuristic algorithms;Noise measurement;Clustering algorithms;Signal processing algorithms;Robustness;Machine learning","data analysis;feature selection;learning (artificial intelligence);Pareto optimisation","robustness;stability;noisy data;machine learning;Pareto front based dynamic feature selection","","","","24","","5 Dec 2019","","","IEEE","IEEE Conferences"
"A Game-Theoretic Lexical Link Analysis for Discovering High-Value Information from Big Data","Y. Zhao; C. C. Zhou","Naval Postgraduate School, Monterey, CA, 93943, USA; Quantum Intelligence, Inc., Monterey, CA, 93943, USA","2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","25 Oct 2018","2018","","","621","625","We demonstrate a machine learning and artificial intelligence method, i.e., lexical link analysis (LLA) to discover high-value information from big data. In this paper, high-value information refers to the information that has the potential to grow its value over time. LLA is a unsupervised learning method that does not require manually labeled training data. New value metrics are defined based on a game-theoretic framework for LLA. In this paper, we show the value metrics generated from LLA in a use case of analyzing business news. We show the results from LLA are validated and correlated with the ground truth. We show that by using game theory, the high-value information selected by LLA reaches a Nash equilibrium by superpositioning popular and anomalous information, and at the same time generates high social welfare, therefore, contains higher intrinsic value.","2473-991X","978-1-5386-6051-5","10.1109/ASONAM.2018.8508317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8508317","high-value;lexical link analysis;game theory;big data;unsupervised learning;Nash equilibrium;social welfare;Pareto superior;Pareto efficient","Nash equilibrium;Games;Correlation;Measurement;Social network services;Eigenvalues and eigenfunctions","game theory;information retrieval;unsupervised learning","game-theoretic lexical link analysis;big data;LLA;value metrics;high-value information discovery;Nash equilibrium;ground truth;business news analysis;unsupervised learning method","","","","18","","25 Oct 2018","","","IEEE","IEEE Conferences"
"Customer Lifetime Value in Video Games Using Deep Learning and Parametric Models","P. P. Chen; A. Guitart; A. F. del Río; Á. Periáñez","Yokozuna Data, a Keywords Studio, Japan; Yokozuna Data, a Keywords Studio, Japan; Yokozuna Data, a Keywords Studio, Japan; Yokozuna Data, a Keywords Studio, Japan","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","2134","2140","Nowadays, video game developers record every virtual action performed by their players. As each player can remain in the game for years, this results in an exceptionally rich dataset that can be used to understand and predict player behavior. In particular, this information may serve to identify the most valuable players and foresee the amount of money they will spend in in-app purchases during their lifetime. This is crucial in free-to-play games, where up to 50% of the revenue is generated by just around 2% of the players, the so-called whales.To address this challenge, we explore how deep neural networks can be used to predict customer lifetime value in video games, and compare their performance to parametric models such as Pareto/NBD. Our results suggest that convolutional neural network structures are the most efficient in predicting the economic value of individual players. They not only perform better in terms of accuracy, but also scale to big data and significantly reduce computational time, as they can work directly with raw sequential data and thus do not require any feature engineering process. This becomes important when datasets are very large, as is often the case with video game logs.Moreover, convolutional neural networks are particularly well suited to identify potential whales. Such an early identification is of paramount importance for business purposes, as it would allow developers to implement in-game actions aimed at retaining big spenders and maximizing their lifetime, which would ultimately translate into increased revenue.","","978-1-5386-5035-6","10.1109/BigData.2018.8622151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622151","lifetime value;deep learning;big data;video games;user behavior;behavioral data","Games;Computational modeling;Predictive models;Deep learning;Parametric statistics;Biological system modeling;Time series analysis","Big Data;computer games;convolutional neural nets;human factors;learning (artificial intelligence)","convolutional neural network structures;video game logs;in-game actions;customer lifetime value;deep learning;player behavior;in-app purchases;free-to-play games;deep neural networks;big data","","12","","46","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Optimizing Coverage and Capacity in Cellular Networks using Machine Learning","R. M. Dreifuerst; S. Daulton; Y. Qian; P. Varkey; M. Balandat; S. Kasturia; A. Tomar; A. Yazdan; V. Ponnampalam; R. W. Heath","The University of Texas at Austin,Wireless Networking and Communications Group,Austin,TX; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; Facebook,Menlo Park,CA; North Carolina State University,Department of Electrical and Computer Engineering,Raleigh,NC","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","8138","8142","Wireless cellular networks have many parameters that are normally tuned upon deployment and re-tuned as the network changes. Many operational parameters affect reference signal received power (RSRP), reference signal received quality (RSRQ), signal-to-interference-plus-noise-ratio (SINR), and, ultimately, throughput. In this paper, we develop and compare two approaches for maximizing coverage and minimizing interference by jointly optimizing the transmit power and downtilt (elevation tilt) settings across sectors. To evaluate different parameter configurations offline, we construct a realistic simulation model that captures geographic correlations. Using this model, we evaluate two optimization methods: deep deterministic policy gradient (DDPG), a reinforcement learning (RL) algorithm, and multi-objective Bayesian optimization (BO). Our simulations show that both approaches significantly outperform random search and converge to comparable Pareto frontiers, but that BO converges with two orders of magnitude fewer evaluations than DDPG. Our results suggest that data-driven techniques can effectively self-optimize coverage and capacity in cellular networks.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414155","coverage and capacity optimization;Bayesian optimization;machine learning;reinforcement learning","Cellular networks;Wireless communication;Signal processing algorithms;Optimization methods;Interference;Reinforcement learning;Signal processing","Bayes methods;cellular radio;learning (artificial intelligence);Pareto optimisation;telecommunication computing","reference signal;signal-to-interference-plus-noise-ratio;minimizing interference;transmit power;downtilt settings;elevation tilt;different parameter configurations offline;realistic simulation model;captures geographic correlations;optimization methods;deep deterministic policy gradient;reinforcement learning algorithm;multiobjective Bayesian optimization;magnitude fewer evaluations;self-optimize coverage;machine learning;wireless cellular networks;operational parameters","","2","","17","","13 May 2021","","","IEEE","IEEE Conferences"
"Multi-objective Support Vector Machines Ensemble Generation for Water Quality Monitoring","V. H. Alves Ribeiro; G. Reynoso-Meza","Pontifical Catholic University of Parana (PUCPR), Industrial and Systems Engineering Graduate Program, Curitiba, Brazil; Pontifical Catholic University of Parana (PUCPR), Industrial and Systems Engineering Graduate Program, Curitiba, Brazil","2018 IEEE Congress on Evolutionary Computation (CEC)","4 Oct 2018","2018","","","1","6","Real-world classification problems generally deal with imbalanced data, where one class represents the majority of the data set. The present work deals with event detection on a drinking-water quality time series, where the presence of a quality event is the minority class. In order to solve such problems, supervised learning algorithms are recommended. Researchers have also used multi-objective optimization (MOO) in order to generate diverse models to build ensembles of classifiers. Although MOO has been used for ensemble member generation, there is a lack on it's application for member selection, which is usually done by selecting a specific subset from the resulting models, or by using meta-algorithms, such as boosting. The proposed work comprises the application of MOO design in the whole process of ensemble generation. To do so, one multi-objective problem (MOP) is defined for the creation of a set of non-dominated solutions with Pareto-optimal support vector machines (SVM). After that, a second MOP is defined for the selection of such SVMs as members of an ensemble. Such methodology is compared to other member selection methods, such as: the single best classifier, an ensemble composed of the full set of non-dominated solutions, and the selection of a specific subset from the Pareto front. Results show that the proposed method is suitable for the creation of ensembles, achieving the highest classification scores.","","978-1-5090-6017-7","10.1109/CEC.2018.8477745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477745","machine learning;supervised learning;ensemble methods;support vector machines;genetic algorithms","Support vector machines;Optimization;Mood;Training;Event detection;Kernel;Supervised learning","learning (artificial intelligence);Pareto optimisation;pattern classification;support vector machines;time series;water quality","imbalanced data;drinking-water quality time series;supervised learning algorithms;multiobjective optimization;ensemble member generation;meta-algorithms;MOO design;multiobjective problem;Pareto-optimal support vector machines;classification problems;SVM;MOO","","1","","26","","4 Oct 2018","","","IEEE","IEEE Conferences"
"A Pareto Corner Search Evolutionary Algorithm and Principal Component Analysis for Objective Dimensionality Reduction","X. H. Nguyen; L. Thu Bui; C. T. Tran","Le Quy Don Technical University; and Military Science Academy,Faculty of Information Technology,Hanoi,Vietnam; Le Quy Don Technical University,Faculty of Information Technology,Hanoi,Vietnam; Le Quy Don Technical University,Faculty of Information Technology,Hanoi,Vietnam","2019 11th International Conference on Knowledge and Systems Engineering (KSE)","5 Dec 2019","2019","","","1","6","Many-objective optimisation problems (MaOPs) cause serious difficulties for existing multi-objective evolutionary algorithms (MOEAs). One common way to alleviate these difficulties is to use objective dimensionality reduction. Most existing objective reduction methods are time-consuming because they require MOEAs to run numerous generations. Pareto corner search evolutionary algorithm (PCSEA) was proposed in [18] to speed up objective reduction methods by only seeking corner solutions instead of whole solutions. However, the PCSEA-based objective reduction method in [18] needs to predefine a threshold to select objectives which strongly depends on problems and is not straightforward to obtain. This paper proposes a new objective dimensionality reduction method by integrating PCSEA and principal component analysis (PCA). Thanks to combining advantages of PCSEA and PCA, the proposed method not only can be efficient to eliminate redundant objectives, but also not require to define any parameter in advanced. The experimental results also show that the proposed method can perform objective reduction more successfully than the PCSEA-based objective reduction method. The results further strengthen the links between evolutionary computation and machine learning to address optimization problems.","2164-2508","978-1-7281-3003-3","10.1109/KSE.2019.8919438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919438","many-objective optimisation;objective dimensionality reduction;feature selection;evolutionary computation","Evolutionary computation;Principal component analysis;Optimization;Dimensionality reduction;Correlation;Search problems;Sociology","evolutionary computation;learning (artificial intelligence);Pareto optimisation;principal component analysis;search problems","principal component analysis;many-objective optimisation problems;multiobjective evolutionary algorithms;PCSEA-based objective reduction method;objective dimensionality reduction method;Pareto corner search evolutionary algorithm;machine learning","","2","","20","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Dynamic Feature Selection Based on Pareto Front Optimization","J. Jesus; A. Canuto; D. Araújo","Department of Informatics and Applied Mathematics – DIMAp, Federal University of Rio Grande do Norte – UFRN, Natal, RN, Brazil; Department of Informatics and Applied Mathematics – DIMAp, Federal University of Rio Grande do Norte – UFRN, Natal, RN, Brazil; Digital Metropolis Institute – IMD, Federal University of Rio Grande do Norte – UFRN, Natal, RN, Brazil","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","One of the main issues of machine learning algorithms is the curse of dimensionality. With the fast growing of complex data in real world scenarios, the feature selection becomes a mandatory preprocessing step in any application to reduce both the complexity of the data and the computing time. Based on that, several works have been produced in order to develop efficient methods to perform this task. Most feature selection methods select the best attributes based on some specific criteria. Additionally, recent studies have successfully constructed models to select features considering the particularities of the data, assuming that similar samples should be treated separately. Although some advance has been made, a bad choice of one single criteria to evaluate the importance of the attributes and the arbitrary choice of the number of features made by the user can lead to a poor analysis. In order to overcome some of these issues, this work brings an improvement of a dynamic feature selection algorithm (DFS) by using the idea of pareto front multi-objective optimization, which allow us to both consider distinct perspectives of the features relevance and automatically set the number of attributes to select. We tested our approach using 15 artificial and real world data and results have shown that when compared to the original DFS method, the performance of the proposed method is remarkable superior. In fact, the results are very promising since the proposed method also achieved better performance than well-established dimensionality reduction methods and when using the original datasets, showing that the reduction of noisy and/or redundant attributes can have a positive effect in the performance of a classification task.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489680","","Feature extraction;Heuristic algorithms;Clustering algorithms;Optimization;Dimensionality reduction;Complexity theory;Task analysis","feature extraction;feature selection;learning (artificial intelligence);Pareto optimisation;pattern classification","machine learning algorithms;complex data;dynamic feature selection algorithm;multiobjective optimization;features relevance;Pareto front optimization;dimensionality reduction methods;DFS method;classification task","","2","","28","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Synthesizing Pareto-Optimal Interpretations for Black-Box Models","H. Torfah; S. Shah; S. Chakraborty; S. Akshay; S. A. Seshia","University of California at Berkeley; Indian Institute of Technology,Bombay; Indian Institute of Technology,Bombay; Indian Institute of Technology,Bombay; University of California at Berkeley","2021 Formal Methods in Computer Aided Design (FMCAD)","29 Nov 2021","2021","","","153","162","We present a new multi-objective optimization approach for synthesizing interpretations that “explain” the behavior of black-box machine learning models. Constructing human-understandable interpretations for black-box models often requires balancing conflicting objectives. A simple interpretation may be easier to understand for humans while being less precise in its predictions vis-a-vis a complex interpretation. Existing methods for synthesizing interpretations use a single objective function and are often optimized for a single class of interpretations. In contrast, we provide a more general and multi-objective synthesis framework that allows users to choose (1) the class of syntactic templates from which an interpretation should be synthesized, and (2) quantitative measures on both the correctness and explainability of an interpretation. For a given black-box, our approach yields a set of Pareto-optimal interpretations with respect to the correctness and explainability measures. We show that the underlying multi-objective optimization problem can be solved via a reduction to quantitative constraint solving, such as weighted maximum satisfiability. To demonstrate the benefits of our approach, we have applied it to synthesize interpretations for black-box neural-network classifiers. Our experiments show that there often exists a rich and varied set of choices for interpretations that are missed by existing approaches.","2708-7824","978-3-85448-046-4","10.34727/2021/isbn.978-3-85448-046-4_24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617578","","Design automation;Computational modeling;Machine learning;Syntactics;Linear programming;Optimization","learning (artificial intelligence);neural nets;Pareto optimisation;pattern classification","black-box machine learning models;human-understandable interpretations;simple interpretation;complex interpretation;single objective function;Pareto-optimal interpretations;multiobjective optimization problem;black-box neural-network classifiers;multiobjective optimization approach;quantitative constraint solving;weighted maximum satisfiability","","","","39","","29 Nov 2021","","","IEEE","IEEE Conferences"
"Plenary Talks","M. Grabisch; S. G. Kong; K. Iwano; P. Sinčák","Univ. of Paris Pantheon-Sorbonne, Paris, France; Sejong Univ., Seoul, South Korea; Center for R&D Strategy, Japan Sci. & Technol. Agency, Tokyo, Japan; Tech. Univ. of Kosice, Kosice, Slovakia","2016 Joint 8th International Conference on Soft Computing and Intelligent Systems (SCIS) and 17th International Symposium on Advanced Intelligent Systems (ISIS)","29 Dec 2016","2016","","","xxvi","xxix","These plenary talks discuss the following: Multicriteria Decision Making with Interacting Criteria; Machine Learning for Computer Vision; Reality 2.0 and Wisdom Computing - our vision toward the future; Cloud Based Intelligent Robotics.","","978-1-5090-2678-4","10.1109/SCIS-ISIS.2016.0009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801596","","","cloud computing;computer vision;decision making;intelligent robots;learning (artificial intelligence)","soft computing and intelligent systems;SCIS;International Symposium on Advanced Intelligent Systems;ISIS;multicriteria decision making;interacting criteria;machine learning;computer vision;reality 2.0;wisdom computing;cloud based intelligent robotics","","","","","","29 Dec 2016","","","IEEE","IEEE Conferences"
"Hybridising rule induction and multi-objective evolutionary search for optimising water distribution systems","L. Jourdan; D. Corne; D. Savic; G. Walters","Dept. of Comput. Sci. & Math., Exeter Univ., UK; Dept. of Comput. Sci. & Math., Exeter Univ., UK; Dept. of Comput. Sci. & Math., Exeter Univ., UK; Dept. of Comput. Sci. & Math., Exeter Univ., UK","Fourth International Conference on Hybrid Intelligent Systems (HIS'04)","4 Apr 2005","2004","","","434","439","In this article, we present our latest work with a hybrid multiobjective evolutionary algorithm called LEMMO (learnable evolution model for multiobjective optimization) which integrates machine learning into evolutionary search based on Michalski's ""LEM"" approach. The objective is to both improve the performance of the MOEA and to reduce the number of evaluations needed when used for optimising the design of water distribution networks (where evaluations are highly computationally costly). We compare LEMMO with NSGA-II and conclude that our approach is very promising for improved speed and quality in the water systems optimisation domain.","","0-7695-2291-2","10.1109/ICHIS.2004.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1410042","","Design optimization;Evolutionary computation;Large-scale systems;Computer science;Mathematics;Mathematical model;Machine learning;Computer networks;Distributed computing;High performance computing","learning (artificial intelligence);search problems;evolutionary computation;water resources;transportation","hybrid multiobjective evolutionary algorithm;LEMMO;learnable evolution model;multiobjective optimization;machine learning;Michalski LEM approach;water distribution networks;NSGA-II;water systems optimisation domain;rule induction;multiobjective evolutionary search","","5","","29","","4 Apr 2005","","","IEEE","IEEE Conferences"
"An Approach to Large Margin Design of Prototype-Based Pattern Classifiers","T. He; Y. Hu; Q. Huo","Department of Computer Science, The University of Hong Kong, Hong Kong, China; Department of Computer Science, The University of Hong Kong, Hong Kong, China; Department of Computer Science, The University of Hong Kong, Hong Kong, China","2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07","4 Jun 2007","2007","2","","II-625","II-628","In this paper, we propose a maximum separation margin (MSM) training method for multiple-prototype (MP)-based pattern classifiers in which a sample separation margin defined as the distance from the training sample to the classification boundary can be calculated precisely. Similar to support vector machine (SVM) methodology, MSM training is formulated as a multicriteria optimization problem which aims at maximizing the separation margin and minimizing the empirical error rate on training data simultaneously. By making certain relaxation assumptions, MSM training can be reformulated as a semidefinite programming (SDP) problem that can be solved efficiently by some standard optimization algorithms designed for SDP. Evaluation experiments are conducted on the task of the recognition of most confusable Kanji character pairs identified from popular Nakayosi and Kuchibue handwritten Japanese character databases. It is observed that the MSM-trained MP-based classifier achieves a similar character recognition accuracy as that of the state-of-the-art SVM-based classifier, yet requires much fewer classifier parameters.","2379-190X","1-4244-0727-3","10.1109/ICASSP.2007.366313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4217486","large margin;pattern classification;support vector machine;machine;machine learning;semidefinite programming","Prototypes;Support vector machines;Support vector machine classification;Character recognition;Optimization methods;Error analysis;Training data;Design optimization;Algorithm design and analysis;Handwriting recognition","character recognition;learning (artificial intelligence);pattern classification;support vector machines","multiple-prototype-based pattern classifiers;maximum separation margin training method;support vector machine;SVM methodology;multicriteria optimization problem;semidefinite programming problem;character recognition accuracy","","2","","13","","4 Jun 2007","","","IEEE","IEEE Conferences"
"Multi-objective parameter configuration of machine learning algorithms using model-based optimization","D. Horn; B. Bischl","TU Dortmund, Computational Statistics, 44227, Germany; LMU München, Computational Statistics, 80539, Germany","2016 IEEE Symposium Series on Computational Intelligence (SSCI)","13 Feb 2017","2016","","","1","8","The performance of many machine learning algorithms heavily depends on the setting of their respective hyperparameters. Many different tuning approaches exist, from simple grid or random search approaches to evolutionary algorithms and Bayesian optimization. Often, these algorithms are used to optimize a single performance criterion. But in practical applications, a single criterion may not be sufficient to adequately characterize the behavior of the machine learning method under consideration and the Pareto front of multiple criteria has to be considered. We propose to use model-based multi-objective optimization to efficiently approximate such Pareto fronts.","","978-1-5090-4240-1","10.1109/SSCI.2016.7850221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850221","","Optimization;Machine learning algorithms;Algorithm design and analysis;Tuning;Prediction algorithms;Numerical models;Support vector machines","Bayes methods;evolutionary computation;learning (artificial intelligence);Pareto optimisation;search problems","multiobjective parameter configuration;machine learning;model-based optimization;grid search approach;random search approach;evolutionary algorithms;Bayesian optimization;Pareto front","","11","","30","","13 Feb 2017","","","IEEE","IEEE Conferences"
"Stochastic performance tuning of complex simulation applications using unsupervised machine learning","O. Shadura; F. Carminati","CERN, Geneve, Switzerland; CERN, Geneve, Switzerland","2016 IEEE Symposium Series on Computational Intelligence (SSCI)","13 Feb 2017","2016","","","1","8","Machine learning for complex multi-objective problems (MOP) can substantially speedup the discovery of solutions belonging to Pareto landscapes and improve Pareto front accuracy. Studying convergence speedup of multi-objective search on well-known benchmarks is an important step in the development of algorithms to optimize complex problems such as High Energy Physics particle transport simulations. In this paper we will describe how we perform this optimization via a tuning based on genetic algorithms and machine learning for MOP. One of the approaches described is based on the introduction of a specific multivariate analysis operator that can be used in case of expensive fitness function evaluations, in order to speed-up the convergence of the “black-box” optimization problem.","","978-1-5090-4240-1","10.1109/SSCI.2016.7850200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850200","","Genetic algorithms;Sociology;Optimization;Principal component analysis;Convergence;Covariance matrices","convergence;genetic algorithms;Pareto analysis;search problems;stochastic processes;unsupervised learning","black-box optimization;fitness function evaluations;multivariate analysis operator;genetic algorithms;high energy physics particle transport simulations;complex problem optimization;multiobjective search;convergence speedup;Pareto front accuracy;Pareto landscapes;solution discovery;MOP;multi-objective problems;unsupervised machine learning;complex simulation applications;stochastic performance tuning","","","","17","","13 Feb 2017","","","IEEE","IEEE Conferences"
"Dynamic Collaborative Charging Algorithm for Mobile and Static Nodes in Industrial Internet of Things","G. Han; Z. Liao; M. Martínez-García; Y. Zhang; Y. Peng","Department of Information and Communication Systems, Hohai University, Changzhou, China; School of Internet of Things, Hohai University, Changzhou, China; Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, U.K.; Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, U.K.; School of Artificial Intelligence, Shanghai University, Shanghai, China","IEEE Internet of Things Journal","7 Dec 2021","2021","8","24","17747","17761","Industrial Internet of Things inevitably leads to the implementation of highly data-intensive devices, where the associated sensing nodes accelerate the energy consumption rate, which ultimately produces an energy bottleneck. To address this issue, this article proposes a <italic>dynamic collaborative charging algorithm</italic> that acts on both the mobile nodes and the static nodes in a sensing node network. The proposed scheme is to design a collaborative group of charging robots that can rendezvous with the sensing nodes. The group includes aerial charging vehicles (ACVs)—able to charge the underpowered mobile nodes, and terrestrial charging vehicles (TCVs), which charge their targeted static nodes. The aim of this study is to optimize the charging effect and the energy cost in the rendezvous process. This approach consists of two subalgorithms: 1) a charging algorithm for mobile nodes (CAMNs) and 2) a charging algorithm for static nodes (CASNs). The CAMNs is designed so that each underpowered mobile node can be charged by a dedicated ACV. For this purpose, a deep learning model is trained to divide the underpowered mobile nodes into appropriate clusters, each of which is equipped with a mobile base station. The rendezvous process is then constructed as a mixed continuous/discrete optimization problem, which is solved by using the firefly algorithm. In addition, the CASNs ensures that the TCVs traverse their routes, charging static nodes as they proceed. This traversing process was formulated as a multiobjective optimization problem, solved by using genetic algorithm. Through various experiments and case studies, the results have demonstrated both the feasibility and the efficiency of the proposed algorithms.","2327-4662","","10.1109/JIOT.2021.3082633","Project of Shenzhen Science and Technology Innovation Committee(grant numbers:JCYJ20190809145407809); Jiangsu Key Research and Development Program(grant numbers:BE2019648); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438635","Collaborative artificial intelligence;deep learning;firefly algorithm;genetic algorithm","Mobile nodes;Robot sensing systems;Sensors;Collaboration;Cloud computing;Industrial Internet of Things;Batteries","energy consumption;genetic algorithms;learning (artificial intelligence);optimisation;wireless sensor networks","mobile nodes;underpowered mobile node;mobile base station;rendezvous process;dynamic collaborative charging algorithm;associated sensing nodes;sensing node network;aerial charging vehicles;terrestrial charging vehicles;targeted static nodes;charging effect","","2","","38","IEEE","21 May 2021","","","IEEE","IEEE Journals"
"A comparison of machine leaming methods using a two player board game","D. Draskovic; M. Brzakovic; B. Nikolic","School of Electrical Engineering, University of Belgrade; School of Electrical Engineering, University of Belgrade; School of Electrical Engineering, University of Belgrade","IEEE EUROCON 2019 -18th International Conference on Smart Technologies","11 Oct 2019","2019","","","1","5","The board games are usually performed by game theory algorithms: minimax and minimax with alpha-beta pruning. Tic-tac-toe (X-O) is the best-known two-player board game. The game tic-tac-toe, based on machine learning algorithms, has been shown in this research. The neural network has been developed and trained to play the game utilizing three implemented agents: an agent based on deep Q-learning, an agent based on policy gradient method and a random agent. The agent can play the game perfectly in the 10-minute training interval, on an average graphics processing unit.","","978-1-5386-9301-8","10.1109/EUROCON.2019.8861927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861927","machine learning;reinforcement learning;neural network;Q-learning;policy gradient method;deep learning","Games;Neural networks;Reinforcement learning;Markov processes;Monte Carlo methods;Decision making","computer games;game theory;gradient methods;learning (artificial intelligence);minimax techniques;neural nets","board games;game theory algorithms;minimax;alpha-beta pruning;two-player board game;tic-tac-toe;machine learning algorithms;neural network;deep Q-learning;policy gradient method;random agent","","1","","13","","11 Oct 2019","","","IEEE","IEEE Conferences"
"Design and Implementation of Fuzzy-PI Controllers for PMSM Based on Multi-Objective Optimization Algorithms","I. Kao; K. Lu; J. Perng","Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-Sen University, Kaohsiung, R. O. C.; Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-Sen University, Kaohsiung, R. O. C.; Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-Sen University, Kaohsiung, R. O. C.","2017 5th International Conference on Mechanical, Automotive and Materials Engineering (CMAME)","18 Nov 2018","2017","","","285","289","Various intelligent algorithms have been applied to our daily lives, such as fuzzy theory, neural networks, and machine learning. These methods are widely used for solving many real-world problems; however, these algorithms also exhibit deficiencies and limitations. This paper introduces the recently improved algorithm, known as multi-objective particle swarm optimization, based on decomposition and dominance (D^2 MOPSO) in order to design the permanent magnet synchronous motor (PMSM) fuzzy controller for different objects. This means that the user can easily change the customized controller, according to their requirements. Furthermore, this paper compares the final decision of the controller parameter with other algorithms: the multiobjective particle swarm optimization with crowding distance (MOPSO-CD), and nondominated sorting genetic algorithm II (NSGA-II). The simulation results of the three algorithms indicate the optimum PMSM controller parameter in the computing software MATLAB. Finally, we implement the fuzzy controller in an embedded system (DSP28069) to demonstrate that our design matches the reality system response and meets the user's demands with ease.","","978-1-5386-0432-8","10.1109/CMAME.2017.8540108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540108","fuzzy control;multi-objective optimization algorithm;multi-objective particle swarm optimization;MOPSO;Nondominated sorting genetic algorithm;NSGA-II","Linear programming;Optimization;Particle swarm optimization;Permanent magnet motors;Genetic algorithms;Signal processing algorithms;Sorting","fuzzy control;fuzzy set theory;genetic algorithms;mathematics computing;Pareto optimisation;particle swarm optimisation;permanent magnet motors;PI control;synchronous motors","fuzzy-PI controllers;multiobjective optimization algorithms;intelligent algorithms;fuzzy theory;neural networks;machine learning;real-world problems;D^2 MOPSO;permanent magnet synchronous motor fuzzy controller;different objects;customized controller;nondominated sorting genetic algorithm II;optimum PMSM controller parameter;decomposition and dominance;multiobjective particle swarm optimization with crowding distance;MATLAB;embedded system;DSP28069","","1","","17","","18 Nov 2018","","","IEEE","IEEE Conferences"
"A Pareto Front Based Evolutionary Model for Airfoil Self-Noise Prediction","A. Tahmassebi; A. H. Gandomi; A. Meyer-Baese","Department of Scientific Computing, Florida State University, Florida, Tallahassee, 32306-4120, USA; Stevens Institute of Technology, School of Business, New Jersey, Hoboken, 07030, USA; Department of Scientific Computing, Florida State University, Florida, Tallahassee, 32306-4120, USA","2018 IEEE Congress on Evolutionary Computation (CEC)","4 Oct 2018","2018","","","1","8","According to NASA's report on the technologies that could reduce external aircraft noise by 10 dB, a challenge equally as important as finding approaches on airframe noise reduction is the demand to bring up strategies by which airframe noise can be predicted both accurately and rapidly. One of the components of the overall airframe noise is the self-noise of the airfoil itself. In this paper, an evolutionary symbolic implementation for airfoil self-noise prediction was proposed. Multi-objective genetic programming as a subset of evolutionary computation along with adaptive regression by mixing algorithm was used to create an executable fused model. The developed model was tested on the airfoil self-noise database and the performance of the developed model was compared to the previous works and benchmark machine learning algorithms. The reasonable results suggest that the proposed model can be applied to noise generation by low-Mach-number turbulent flows in aerospace, automobile, underwater, and wind turbine acoustic communities.","","978-1-5090-6017-7","10.1109/CEC.2018.8477987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477987","","Computational modeling;Adaptation models;Automotive components;Complexity theory;Atmospheric modeling;Sociology;Statistics","acoustic noise;aeroacoustics;aerodynamics;aerospace components;aircraft;genetic algorithms;learning (artificial intelligence);Mach number;noise abatement;Pareto optimisation;regression analysis;turbulence","multiobjective genetic programming;evolutionary computation;noise generation;NASA's report;airframe noise reduction;evolutionary symbolic implementation;airfoil self-noise prediction;adaptive regression;mixing algorithm;creating executable fused model;benchmark machine learning algorithm;low-Mach-number turbulent flows;Pareto front based evolutionary model;aerospace industry;automobile industry;underwater acoustics;wind turbine acoustic communities;noise figure 10.0 dB","","4","","29","","4 Oct 2018","","","IEEE","IEEE Conferences"
"A Probabilistic Machine Learning Approach to Scheduling Parallel Loops With Bayesian Optimization","K. -R. Kim; Y. Kim; S. Park","Department of Electronics Engineering, Sogang University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Sogang University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Sogang University, Seoul, Republic of Korea","IEEE Transactions on Parallel and Distributed Systems","19 Feb 2021","2021","32","7","1815","1827","This article proposes Bayesian optimization augmented factoring self-scheduling (BO FSS), a new parallel loop scheduling strategy. BO FSS is an automatic tuning variant of the factoring self-scheduling (FSS) algorithm and is based on Bayesian optimization (BO), a black-box optimization algorithm. Its core idea is to automatically tune the internal parameter of FSS by solving an optimization problem using BO. The tuning procedure only requires online execution time measurement of the target loop. In order to apply BO, we model the execution time using two Gaussian process (GP) probabilistic machine learning models. Notably, we propose a locality-aware GP model, which assumes that the temporal locality effect resembles an exponentially decreasing function. By accurately modeling the temporal locality effect, our locality-aware GP model accelerates the convergence of BO. We implemented BO FSS on the GCC implementation of the OpenMP standard and evaluated its performance against other scheduling algorithms. Also, to quantify our method's performance variation on different workloads, or workload-robustness in our terms, we measure the minimax regret. According to the minimax regret, BO FSS shows more consistent performance than other algorithms. Within the considered workloads, BO FSS improves the execution time of FSS by as much as 22% and 5% on average.","1558-2183","","10.1109/TPDS.2020.3046461","National Research Foundation of Korea(grant numbers:2017M3C4A7080245); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303443","Parallel loop scheduling;Bayesian optimization;parallel computing;OpenMP","Frequency selective surfaces;Task analysis;Heuristic algorithms;Dynamic scheduling;Optimization;Scheduling algorithms;Copper","Bayes methods;Gaussian processes;learning (artificial intelligence);minimax techniques;optimisation;processor scheduling;program control structures","black-box optimization algorithm;optimization problem;execution time;Gaussian process probabilistic machine learning models;locality-aware GP model;temporal locality effect;BO FSS;scheduling parallel loops;Bayesian optimization;parallel loop scheduling strategy;automatic tuning variant;Bayesian optimization augmented factoring self-scheduling;minimax regret","","1","","58","IEEE","22 Dec 2020","","","IEEE","IEEE Journals"
"Multi-Criteria Evaluation of Publication Impacts: Deep Learning in Autonomous Vehicles","G. Ismayilov; C. D. Yilmaz","Bogazici University,Istanbul,Turkey; Bogazici University,Istanbul,Turkey","2021 29th Conference of Open Innovations Association (FRUCT)","25 May 2021","2021","","","160","168","Deep learning is the state-of-the-art approach that has been extensively used in the recent years to variety of real-world problems in the literature. The autonomous vehicles are among the applications where their integration with deep learning techniques has potential to disruptively change our daily lives. In this work, we have proposed a multi-criteria framework to evaluate the relative impacts of both publications and authors for deep learning in autonomous vehicles. For the framework, we have considered several criteria extracted from the metadata of the publications and the authors. The conflicts among the criteria are also justified through Pearson correlation. For the experiments, two comprehensive datasets for the publication and the author impacts have been constructed. The resulting pareto-fronts of the datasets after ranking are presented. Moreover, top 30 most impactful publications and authors in the literature are identified. We hope that our findings will be useful for researchers to accelerate the further technological advancements.","2305-7254","978-952-69244-5-8","10.23919/FRUCT52173.2021.9435554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9435554","","Deep learning;Technological innovation;Correlation;Metadata;Vehicle dynamics;Autonomous vehicles","decision making;learning (artificial intelligence);meta data;mobile robots;Pareto optimisation","impactful publications;multicriteria evaluation;author impacts;multicriteria framework;deep learning techniques;autonomous vehicles;publication impacts","","","","56","","25 May 2021","","","IEEE","IEEE Conferences"
"Filter Design and Optimization of Electromechanical Actuation Systems Using Search and Surrogate Algorithms for More-Electric Aircraft Applications","Y. Gao; T. Yang; S. Bozhko; P. Wheeler; T. Dragičević","Department of Electrical and Electronic Engineering, University of Nottingham, Nottingham, U.K; Department of Electrical and Electronic Engineering, University of Nottingham, Nottingham, U.K; Department of Electrical and Electronic Engineering, University of Nottingham, Nottingham, U.K; Department of Electrical and Electronic Engineering, University of Nottingham, Nottingham, U.K; Department of Energy Technology, Technical University of Denmark, Lyngby, Denmark","IEEE Transactions on Transportation Electrification","30 Oct 2020","2020","6","4","1434","1447","In this article, the dc filter design and optimization problem is studied for dc electrical power distribution systems onboard more-electric aircraft. Component sizing models are built to serve as the basis of the optimization whose objectives are mass and power loss of this filter. A categorization strategy of search and surrogate algorithms is proposed and used for the target multiobjective optimization problem (MOOP). A genetic algorithm is utilized as a search algorithm to identify potential best solutions based on a set of filter sizing functions (subject to constraints). In addition, two machine learning (ML) algorithms are considered as surrogate algorithms to address the same optimization problem. In the ML training process, a constraint violation model is applied since there are various constraints in optimization, and this kind of classification model is relatively difficult to train. A support vector machine is applied for the constraint violation model; after that, two artificial neural networks are trained as the final surrogate model for mapping design variables to filter performance. To address these issues, a novel category of search and surrogate algorithms is proposed. Both algorithms are explored to solve the filter MOOP, and their optimization results are compared at the end.","2332-7782","","10.1109/TTE.2020.3019729","Clean Sky 2 Joint Undertaking under the European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:807081); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178291","Artificial neural network (ANN);filter design;genetic algorithm (GA);more-electric aircraft (MEA);optimization;search algorithm;support vector machine (SVM);surrogate algorithm","Optimization;Support vector machines;Artificial neural networks;Machine learning algorithms;Genetic algorithms;Aircraft","aircraft power systems;DC distribution systems;genetic algorithms;learning (artificial intelligence);neural nets;power engineering computing;power filters;search problems;support vector machines","artificial neural networks;support vector machine;ML training process;MOOP;onboard more-electric aircraft;electromechanical actuation systems;surrogate algorithms;dc filter design;dc electrical power distribution systems;component sizing models;power loss;genetic algorithm;search algorithm;filter sizing functions;machine learning algorithms;constraint violation model;multiobjective optimization problem","","4","","47","IEEE","26 Aug 2020","","","IEEE","IEEE Journals"
"A Global Bayesian Optimization Algorithm and Its Application to Integrated System Design","H. M. Torun; M. Swaminathan; A. Kavungal Davis; M. L. F. Bellaredj","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","20 Mar 2018","2018","26","4","792","802","Increasing levels of system integration pose difficulties in meeting design specifications for high-performance systems. Oftentimes increased complexity, nonlinearity, and multiple tradeoffs need to be handled simultaneously during the design cycle. Since components in such systems are highly correlated with each other, codesign and co-optimization of the complete system are required. Machine learning (ML) provides opportunities for analyzing such systems with multiple control parameters, where techniques based on Bayesian optimization (BO) can be used to meet or exceed design specifications. In this paper, we propose a new BO-based global optimization algorithm titled Two-Stage BO (TSBO). TSBO can be applied to black box optimization problems where the computational time can be reduced through a reduction in the number of simulations required. Empirical analysis on a set of popular challenge functions with several local extrema and dimensions shows TSBO to have a faster convergence rate as compared with other optimization methods. In this paper, TSBO has been applied for clock skew minimization in 3-D integrated circuits and multiobjective co-optimization for maximizing efficiency in integrated voltage regulators. The results show that TSBO is between 2×-4× faster as compared with previously published BO algorithms and other non-ML-based techniques.","1557-9999","","10.1109/TVLSI.2017.2784783","NSF I/UCRC Center for Advanced Electronics through Machine Learning (CAEML); Power Delivery for Electronic Systems Consortium, Georgia Tech, USA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253829","3-D integration;Bayesian optimization (BO);black box systems;integrated voltage regulator (IVR);machine learning (ML);magnetic core inductor;thermal management","Optimization;Algorithm design and analysis;Bayes methods;Tuning;Minimization;Integrated circuit modeling","Bayes methods;electronic engineering computing;integrated circuit design;learning (artificial intelligence);minimisation;three-dimensional integrated circuits;voltage regulators","machine learning;multiple control parameters;Two-Stage BO;TSBO;black box optimization problems;optimization methods;3-D integrated circuits;multiobjective co-optimization;integrated voltage regulators;global Bayesian optimization algorithm;integrated system design;system integration;high-performance systems;nonlinearity;design cycle;codesign;design specifications;BO-based global optimization algorithm;computational time;clock skew minimization;BO","","52","","29","IEEE","11 Jan 2018","","","IEEE","IEEE Journals"
"Practical Design Space Exploration","L. Nardi; D. Koeplinger; K. Olukotun",Stanford University; Stanford University; Stanford University,"2019 IEEE 27th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)","25 Sep 2019","2019","","","347","358","Multi-objective optimization is a crucial matter in computer systems design space exploration because real-world applications often rely on a trade-off between several objectives. Derivatives are usually not available or impractical to compute and the feasibility of an experiment can not always be determined in advance. These problems are particularly difficult when the feasible region is relatively small, and it may be prohibitive to even find a feasible experiment, let alone an optimal one. We introduce a new methodology and corresponding software framework, HyperMapper 2.0, which handles multi-objective optimization, unknown feasibility constraints, and categorical/ordinal variables. This new methodology also supports injection of the user prior knowledge in the search when available. All of these features are common requirements in computer systems but rarely exposed in existing design space exploration systems. The proposed methodology follows a white-box model which is simple to understand and interpret (unlike, for example, neural networks) and can be used by the user to better understand the results of the automatic search. We apply and evaluate the new methodology to the automatic static tuning of hardware accelerators within the recently introduced Spatial programming language, with minimization of design run-time and compute logic under the constraint of the design fitting in a target field-programmable gate array chip. Our results show that HyperMapper 2.0 provides better Pareto fronts compared to state-of-the-art baselines, with better or competitive hypervolume indicator and with 8x improvement in sampling budget for most of the benchmarks explored.","2375-0227","978-1-7281-4950-9","10.1109/MASCOTS.2019.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843094","Pareto-optimal front;Design space exploration;Hardware design, Performance modeling, Optimizing compilers, Machine learning driven optimization","Optimization;Software;Space exploration;Computational modeling;Linear programming;Hardware;Logic gates","evolutionary computation;field programmable gate arrays;Pareto optimisation;software engineering","field-programmable gate array chip;Spatial programming language;existing design space exploration systems;user prior knowledge;feasibility constraints;HyperMapper 2;software framework;computer systems design space exploration;multiobjective optimization","","8","","34","","25 Sep 2019","","","IEEE","IEEE Conferences"
"Artificial Neural Network (ANN) Based Fast and Accurate Inductor Modeling and Design","T. Guillod; P. Papamanolis; J. W. Kolar","Power Electronic Systems Laboratory, ETH Zurich, Zurich, Switzerland; Power Electronic Systems Laboratory, ETH Zurich, Zurich, Switzerland; Power Electronic Systems Laboratory, ETH Zurich, Zurich, Switzerland","IEEE Open Journal of Power Electronics","19 Aug 2020","2020","1","","284","299","This paper analyzes the potential of Artificial Neural Networks (ANNs) for the modeling and optimization of magnetic components and, specifically, inductors. After reviewing the basic properties of ANNs, several potential modeling and design workflows are presented. A hybrid method, which combines the accuracy of 3D Finite Element Method (FEM) and the low computational cost of ANNs, is selected and implemented. All relevant effects are considered (3D magnetic and thermal field patterns, detailed core loss data, winding proximity losses, coupled loss-thermal model, etc.) and the implemented model is extremely versatile (30 input and 40 output variables). The proposed ANN-based model can compute 50'000 designs per second with less than 3% deviation with respect to 3D FEM simulations. Finally, the inductor of a 2 kW DC-DC buck converter is optimized with the ANN-based workflow. From the Pareto fronts, a design is selected, measured, and successfully compared with the results obtained with the ANNs. The implementation (source code and data) of the proposed workflow is available under an open-source license.","2644-1314","","10.1109/OJPEL.2020.3012777","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152082","Power converters;artificial neural networks;finite element analysis;inductors;machine learning;magnetic devices;open source software;pareto optimization","Training;Neurons;Computational modeling;Optimization;Artificial neural networks;Inductors;Solid modeling","DC-DC power convertors;finite element analysis;neural nets;power engineering computing;power inductors","accurate inductor modeling;artificial neural networks;magnetic components;hybrid method;3D finite element method;core loss data;proximity losses;coupled loss-thermal model;ANN-based model;ANN-based workflow;computational cost;fast inductor modeling;3D magnetic field patterns;3D thermal field patterns;winding proximity losses;DC-DC buck converter;source code;source data;open-source license;power 2.0 kW","","14","","52","CCBY","29 Jul 2020","","","IEEE","IEEE Journals"
"Advanced RF and Microwave Design Optimization: A Journey and a Vision of Future Trends","J. E. Rayas-Sánchez; S. Koziel; J. W. Bandler","Department of Electronics, Systems and Informatics, ITESO – the Jesuit University of Guadalajara, Tlaquepaque, Mexico; Engineering Optimization & Modeling Center, Department of Engineering, Reykjavík University, Reykjavík, Iceland; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada","IEEE Journal of Microwaves","11 Jan 2021","2021","1","1","481","493","In this paper, we outline the historical evolution of RF and microwave design optimization and envisage imminent and future challenges that will be addressed by the next generation of optimization developments. Our journey starts in the 1960s, with the emergence of formal numerical optimization algorithms for circuit design. In our fast historical analysis, we emphasize the last two decades of documented microwave design optimization problems and solutions. From that retrospective, we identify a number of prominent scientific and engineering challenges: 1) the reliable and computationally efficient optimization of highly accurate system-level complex models subject to statistical uncertainty and varying operating or environmental conditions; 2) the computationally-efficient EM-driven multi-objective design optimization in high-dimensional design spaces including categorical, conditional, or combinatorial variables; and 3) the manufacturability assessment, statistical design, and yield optimization of high-frequency structures based on high-fidelity multi-physical representations. To address these major challenges, we venture into the development of sophisticated optimization approaches, exploiting confined and dimensionally reduced surrogate vehicles, automated feature-engineering-based optimization, and formal cognition-driven space mapping approaches, assisted by Bayesian and machine learning techniques.","2692-8388","","10.1109/JMW.2020.3034263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318755","ANN;Bayesian;Broyden;CAD;cognition;design automation;EDA;features;Gaussian process;Kriging;machine learning;multi-objective;multi-physics;optimization;Pareto;polynomial chaos;sensitivity;space mapping;statistical;surrogate;tolerances;uncertainty quantification;yield","Radio frequency;Uncertainty;Microwave theory and techniques;Microwave circuits;Computational efficiency;Optimization;Design optimization","electrical engineering computing;learning (artificial intelligence);microwaves","computationally-efficient EM-driven multiobjective design optimization;high-fidelity multiphysical representations;automated feature-engineering-based optimization;formal numerical optimization algorithms;microwave design optimization problems;machine learning techniques;Bayesian learning techniques","","6","","167","CCBYNCND","11 Jan 2021","","","IEEE","IEEE Journals"
"An Investigation of Pixel-Based and Object-Based Image Classification in Remote Sensing","M. C. Younis; E. Keedwell; D. Savic","Department of Computer Science Physics and Mathematics, University of Exeter, Exeter, UK; Department of Computer Science Physics and Mathematics, University of Exeter, Exeter, UK; Centre for Water Systems, University of Exeter, Exeter, UK","2018 International Conference on Advanced Science and Engineering (ICOASE)","29 Nov 2018","2018","","","449","454","This research evaluates pixel-based and object-based image classification techniques for extracting three land-use categories (buildings, roads, and vegetation areas) from six satellite images. The performance of eight supervised machine learning classifiers with 5-fold cross validation are also compared. Experimental validation found that using 'Bagged Tree' for object-based classification algorithms provides maximum overall accuracy when tested on 10,000 objects produced by the SLIC segmentation method, and improves upon an existing RGB-based approach. Our aforementioned proposed approach takes about 12 times less total runtime than the pixel-based method, demonstrating the power of the combined approach.","","978-1-5386-6696-8","10.1109/ICOASE.2018.8548845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548845","machine learning;image classification;image segmentation;Pareto Analysis;remote sensing","Image segmentation;Runtime;Feature extraction;Remote sensing;Roads;Classification algorithms;Image classification","buildings (structures);geophysical image processing;geophysical techniques;image classification;image segmentation;land use;learning (artificial intelligence);roads;vegetation mapping","remote sensing;image classification techniques;land-use categories;vegetation areas;satellite images;5-fold cross validation;experimental validation;object-based classification algorithms;existing RGB-based approach;pixel-based method;supervised machine learning classifiers;object-based image classification techniques;buildings;roads;SLIC segmentation method","","","","36","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Coordinated Optimal Energy Management and Voyage Scheduling for All-Electric Ships Based on Predicted Shore-Side Electricity Price","S. Wen; T. Zhao; Y. Tang; Y. Xu; M. Zhu; S. Fang; Z. Ding","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Energy Research Institute, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Information Engineering Department, Chinese University of Hong Kong, Hong Kong, China; Academy of Modern Electric Power Research, North China Electric Power University, Beijing, China","IEEE Transactions on Industry Applications","30 Dec 2020","2021","57","1","139","148","Unlike a land-based standalone microgrid, a shipboard microgrid of an all-electric ship (AES) needs to shut down generators during berthing at the port for examination and maintenance. Therefore, the cost of onshore power plays an important role in an economic operation for AESs. In order to fully exploit its potential, a two-stage joint scheduling model is proposed to optimally coordinate the power generation and voyage scheduling of an AES. Different from previous studies that only consider the operation cost of the ship itself, a novel coordinated framework is developed in this article to address the shore-side electricity price variations on the ship navigation route. A deep learning-based forecasting method is utilized to predict the electricity price in various harbors for ship operators. Then, a hybrid optimization algorithm is designed to solve the proposed multiobjective joint scheduling problem. A navigation route in Australia is adopted for case studies and simulation results demonstrate the high energy utilization efficiency of the proposed algorithm and the necessity of on-shore power influence on the AES voyage.","1939-9367","","10.1109/TIA.2020.3034290","National Natural Science Foundation of China(grant numbers:61802087); Shanghai Pujiang Program(grant numbers:20PJ1406700); Nanyang Technological University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244602","All-electric ship;deep learning;energy storage system;joint energy management and voyage scheduling;real-time electricity price prediction","Marine vehicles;Job shop scheduling;Microgrids;Forecasting;Optimization;Energy management;Maintenance engineering","distributed power generation;energy management systems;learning (artificial intelligence);optimisation;power engineering computing;pricing;scheduling;ships","coordinated optimal energy management;voyage scheduling;all-electric ship;predicted shore-side;electricity price;land-based standalone microgrid;shipboard microgrid;maintenance;onshore power;economic operation;two-stage joint scheduling model;power generation;operation cost;novel coordinated framework;ship navigation route;deep learning-based forecasting method;ship operators;hybrid optimization algorithm;multiobjective joint scheduling problem;high energy utilization efficiency;on-shore power influence;AES voyage","","6","","31","IEEE","29 Oct 2020","","","IEEE","IEEE Journals"
"Generative Adversarial Network in the Air: Deep Adversarial Learning for Wireless Signal Spoofing","Y. Shi; K. Davaslioglu; Y. E. Sagduyu","Department of ECE, Virginia Tech, Blacksburg, VA, USA; Intelligent Automation Inc., Rockville, MD, USA; Intelligent Automation Inc., Rockville, MD, USA","IEEE Transactions on Cognitive Communications and Networking","5 Mar 2021","2021","7","1","294","303","The spoofing attack is critical to bypass physical-layer signal authentication. This paper presents a deep learning-based spoofing attack to generate synthetic wireless signals that cannot be statistically distinguished from intended transmissions. The adversary is modeled as a pair of a transmitter and a receiver that build the generator and discriminator of the generative adversarial network, respectively, by playing a minimax game over the air. The adversary transmitter trains a deep neural network to generate the best spoofing signals and fool the best defense trained as another deep neural network at the adversary receiver. Each node (defender or adversary) may have multiple transmitter or receiver antennas. Signals are spoofed by jointly capturing waveform, channel, and radio hardware effects that are inherent to wireless signals under attack. Compared with spoofing attacks using random or replayed signals, the proposed attack increases the probability of misclassifying spoofing signals as intended signals for different network topology and mobility patterns. The adversary transmitter can increase the spoofing attack success by using multiple antennas, while the attack success decreases when the defender receiver uses multiple antennas. For practical deployment, the attack implementation on embedded platforms demonstrates the low latency of generating or classifying spoofing signals.","2332-7731","","10.1109/TCCN.2020.3010330","U.S. Army Research Office(grant numbers:W911NF-17-C-0090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144305","Adversarial machine learning;deep learning;generative adversarial network (GAN);spoofing attack","Wireless communication;Gallium nitride;Machine learning;Receivers;Radio transmitters;Wireless sensor networks;Communication system security","antenna arrays;cryptography;deep learning (artificial intelligence);neural nets;probability;radio receivers;radio transmitters;receiving antennas;signal classification;telecommunication network topology;telecommunication security","generative adversarial network;deep adversarial learning;wireless signal spoofing;physical-layer signal authentication;deep learning-based;synthetic wireless signals;adversary transmitter;deep neural network;adversary receiver;multiple transmitter;receiver antennas;random replayed signals;intended signals;different network topology;mobility patterns;spoofing attack success;multiple antennas;defender receiver;spoofing signals","","6","","60","IEEE","20 Jul 2020","","","IEEE","IEEE Journals"
"Empirical Evaluation of Federated Learning with Local Privacy for Real-World Application","P. L. Li; X. Chai; W. D. Wadsworth; J. Liao; B. Paddock","Microsoft,Redmond,WA,98052; Microsoft,Redmond,WA,98052; Microsoft,Redmond,WA,98052; Microsoft,Redmond,WA,98052; Microsoft,Redmond,WA,98052","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","1574","1583","As Machine Learning-based applications become increasingly pervasive, a growing concern is how to balance the need for large, representative data sets with the need to respect user data privacy. The increased compute and connectivity capabilities of edge devices (e.g. phones, PCs) presents us with new avenues for achieving this balance, including a promising approach known as federated learning with local privacy. However, today we have gaps in practical knowledge about applicability, trade-offs, and benefits for large-scale realworld implementation. In this paper, using large-scale data from a real-world Windows Update ML-driven application (as well as the publicly available CIFAR-10 data set to enhance reproducibility), we report empirical evaluations of four practical considerations: heterogeneity in device availability that may cause bias, resiliency of federated learning with local differential privacy, benefits of time-varying adaptive configurations, and data transmission/storage savings based on the Pareto principle. We discuss the implications of these findings for practitioners and researchers.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378033","learning (artificial intelligence);machine learning;machine learning algorithms;prediction methods;predictive models;big data applications;federated learning;privacy;data privacy","Privacy;Software algorithms;Learning (artificial intelligence);Big Data;Collaborative work;Software;Resilience","data privacy;learning (artificial intelligence);Microsoft Windows (operating systems)","ML-driven application;publicly available CIFAR-10 data;empirical evaluation;device availability;federated learning;local differential privacy;machine learning-based applications;representative data sets;user data privacy;connectivity capabilities;edge devices;real-world Windows Update ML-driven application;Pareto principle","","","","50","","19 Mar 2021","","","IEEE","IEEE Conferences"
"Large margin hidden Markov models for speech recognition","Hui Jiang; Xinwei Li; Chaojun Liu","Dept. of Comput. Sci. & Eng., York Univ., Toronto, Ont., Canada; Dept. of Comput. Sci. & Eng., York Univ., Toronto, Ont., Canada; Dept. of Comput. Sci. & Eng., York Univ., Toronto, Ont., Canada","IEEE Transactions on Audio, Speech, and Language Processing","21 Aug 2006","2006","14","5","1584","1595","In this paper, motivated by large margin classifiers in machine learning, we propose a novel method to estimate continuous-density hidden Markov model (CDHMM) for speech recognition according to the principle of maximizing the minimum multiclass separation margin. The approach is named large margin HMM. First, we show this type of large margin HMM estimation problem can be formulated as a constrained minimax optimization problem. Second, we propose to solve this constrained minimax optimization problem by using a penalized gradient descent algorithm, where the original objective function, i.e., minimum margin, is approximated by a differentiable function and the constraints are cast as penalty terms in the objective function. The new training method is evaluated in the speaker-independent isolated E-set recognition and the TIDIGITS connected digit string recognition tasks. Experimental results clearly show that the large margin HMMs consistently outperform the conventional HMM training methods. It has been consistently observed that the large margin training method yields significant recognition error rate reduction even on top of some popular discriminative training methods.","1558-7924","","10.1109/TASL.2006.879805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1677979","Continuous-density hidden Markov models (CDHMMs);gradient descent search;large margin classifiers;minimax optimization;support vector machine","Hidden Markov models;Speech recognition;Automatic speech recognition;Training data;Minimax techniques;Maximum likelihood estimation;Computer science;Mutual information;Optimization methods;Constraint optimization","speech recognition;hidden Markov models;learning (artificial intelligence);minimax techniques;gradient methods;error statistics","large margin hidden Markov model estimation problem;speech recognition;large margin classifiers;machine learning;continuous-density hidden Markov model;minimum multiclass separation margin;constrained minimax optimization problem;penalized gradient descent algorithm;objective function;minimum margin;differentiable function;penalty terms;speaker-independent isolated E-set recognition;TIDIGITS connected digit string recognition task;recognition error rate reduction;discriminative training methods","","72","","45","IEEE","21 Aug 2006","","","IEEE","IEEE Journals"
"Agile Earth Observation Satellite Scheduling Over 20 Years: Formulations, Methods, and Future Directions","X. Wang; G. Wu; L. Xing; W. Pedrycz","School of Traffic and Transportation Engineering, Central South University, Changsha, China; School of Traffic and Transportation Engineering, Central South University, Changsha, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; Department of Electrical and Computer Engineering, University of Alberta, Warsaw, Poland","IEEE Systems Journal","26 Aug 2021","2021","15","3","3881","3892","Agile satellites with advanced attitude maneuvering capability are the new generation of earth observation satellites (EOSs). The continuous improvement in satellite technology and decrease in launch cost have boosted the development of agile EOSs (AEOSs). To efficiently employ the increasing orbiting AEOSs, the AEOS scheduling problem (AEOSSP) aiming to maximize the entire observation profit while satisfying all complex operational constraints, has received much attention over the past 20 years. The objectives of this article are, thus, to summarize current research on AEOSSP, identify main accomplishments and highlight potential future research directions. To this end, general definitions of AEOSSP with operational constraints are described initially, followed by its three typical variations including different definitions of observation profit, multiobjective function and autonomous model. A detailed literature review from 1997-2019 is then presented in line with four different solution methods, i.e., exact method, heuristic, metaheuristic, and machine learning. Finally, we discuss a number of topics worth pursuing in the future.","1937-9234","","10.1109/JSYST.2020.2997050","Natural Science Fund for Distinguished Young Scholars of Hunan Province(grant numbers:2019JJ20026); National Natural Science Foundation of China(grant numbers:61603404); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115252","Agile earth observation satellite;aerospace engineering;review;earth observing system;scheduling;space systems","Task analysis;Satellites;Orbits;Earth;Earth Observing System;Scheduling","artificial satellites;attitude control;optimisation;scheduling","agile earth observation satellite scheduling;advanced attitude maneuvering capability;continuous improvement;satellite technology;launch cost;agile EOSs;increasing orbiting AEOSs;AEOS scheduling problem;AEOSSP;complex operational constraints;highlight potential future research directions;observation profit","","10","","114","IEEE","11 Jun 2020","","","IEEE","IEEE Journals"
"Seeking Multiple Solutions: An Updated Survey on Niching Methods and Their Applications","X. Li; M. G. Epitropakis; K. Deb; A. Engelbrecht","School of Science (Computer Science and Software Engineering), RMIT University, Melbourne, VIC, Australia; Data Science Institute and the Department of Management Science, Lancaster University Management School, Lancaster University, Lancaster, U.K.; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science, School of Information Technology, University of Pretoria, Pretoria, South Africa","IEEE Transactions on Evolutionary Computation","24 Jul 2017","2017","21","4","518","538","Multimodal optimization (MMO) aiming to locate multiple optimal (or near-optimal) solutions in a single simulation run has practical relevance to problem solving across many fields. Population-based meta-heuristics have been shown particularly effective in solving MMO problems, if equipped with specifically-designed diversity-preserving mechanisms, commonly known as niching methods. This paper provides an updated survey on niching methods. This paper first revisits the fundamental concepts about niching and its most representative schemes, then reviews the most recent development of niching methods, including novel and hybrid methods, performance measures, and benchmarks for their assessment. Furthermore, this paper surveys previous attempts at leveraging the capabilities of niching to facilitate various optimization tasks (e.g., multiobjective and dynamic optimization) and machine learning tasks (e.g., clustering, feature selection, and learning ensembles). A list of successful applications of niching methods to real-world problems is presented to demonstrate the capabilities of niching methods in providing solutions that are difficult for other optimization methods to offer. The significant practical value of niching methods is clearly exemplified through these applications. Finally, this paper poses challenges and research questions on niching that are yet to be appropriately addressed. Providing answers to these questions is crucial before we can bring more fruitful benefits of niching to real-world problem solving.","1941-0026","","10.1109/TEVC.2016.2638437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7782373","Evolutionary computation;meta-heuristics;multimodal optimization (MMO);multisolution methods;niching methods;swarm intelligence","Sociology;Statistics;Two dimensional displays;Problem-solving;Benchmark testing;Optimization methods","learning (artificial intelligence);optimisation;problem solving;simulation","niching methods;multimodal optimization;MMO;simulation;population-based meta-heuristics;machine learning;problem solving","","121","","176","IEEE","13 Dec 2016","","","IEEE","IEEE Journals"
"Machine learning with incomplete datasets using multi-objective optimization models","H. A. Khorshidi; M. Kirley; U. Aickelin","The University of Melbourne,School of Computing and Information Systems,Melbourne,Australia; The University of Melbourne,School of Computing and Information Systems,Melbourne,Australia; The University of Melbourne,School of Computing and Information Systems,Melbourne,Australia","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Machine learning techniques have been developed to learn from complete data. When missing values exist in a dataset, the incomplete data should be preprocessed separately by removing data points with missing values or imputation. In this paper, we propose an online approach to handle missing values while a classification model is learnt. To reach this goal, we develop a multi-objective optimization model with two objective functions for imputation and model selection. We also propose three formulations for imputation objective function. We use an evolutionary algorithm based on NSGA II to find the optimal solutions as the Pareto solutions. We investigate the reliability and robustness of the proposed model using experiments by defining several scenarios in dealing with missing values and classification. We also describe how the proposed model can contribute to medical informatics. We compare the performance of three different formulations via experimental results. The proposed model results get validated by comparing with a comparable literature.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206742","incomplete data;multi-objective model;uncertainty;model selection;classification","Linear programming;Support vector machines;Kernel;Machine learning;Optimization;Biological cells;Correlation","data mining;evolutionary computation;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification","NSGA II;Pareto solutions;incomplete datasets;optimal solutions;imputation objective function;model selection;objective functions;classification model;data points;incomplete data;complete data;machine learning techniques;multiobjective optimization model","","","","33","","28 Sep 2020","","","IEEE","IEEE Conferences"
"An Evolutionary Machine Learning Approach Towards Less Conservative Robust Optimization","P. D. Pantula; K. Mitra","Global Optimization and Knowledge Unearthing Laboratory, Department of Chemical Engineering, Indian Institute of Technology Hyderabad, Telangana, 502 285, INDIA; Global Optimization and Knowledge Unearthing Laboratory, Department of Chemical Engineering, Indian Institute of Technology Hyderabad, Telangana, 502 285, INDIA","2019 IEEE Congress on Evolutionary Computation (CEC)","8 Aug 2019","2019","","","2990","2997","In the recent era, multi-criteria decision making under uncertainty is gaining importance due to its wide range of applicability. Among several types of uncertainty handling techniques, Robust Optimization (RO) is considered as an efficient and tractable approach provided one has accessibility to data in uncertain regions. However, solutions of RO may actually deviate from actual results in real scenarios, due to conservative sampling. This paper proposes a methodology to amalgamate unsupervised machine learning algorithms with RO which thereby makes it data-driven. A novel evolutionary fuzzy clustering mechanism is implemented to transcript the uncertain space such that the exact regions of uncertainty are identified. Subsequently, density based boundary point detection and Delaunay triangulation based boundary construction enables intelligent Sobol based sampling in these regions for use in RO. Results of two test cases with varying dimensions are presented along with a comprehensive comparison between conventional RO approach using box uncertainty set and proposed methodology. Considered case studies include highly nonlinear real life model for continuous casting from steelmaking industries, where a time expensive multi-objective optimization problem under uncertainty is formulated to resolve the conflict in productivity and energy consumption. Optimal Artificial Neural Network (ANN) surrogate assisted optimization under uncertainty for casting model is performed to obtain solutions in realistic time. The resulting RO problem being multi-objective in nature, the Pareto solutions are obtained by NSGA II.","","978-1-7281-2153-6","10.1109/CEC.2019.8790094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790094","Data Driven Robust Optimization;Evolutionary Algorithms;Fuzzy Clustering;ANN surrogate models;Multi objective Optimization","Optimization;Uncertainty;Machine learning algorithms;Linear programming;Casting;Frequency modulation;Decision making","decision making;evolutionary computation;fuzzy set theory;mesh generation;optimisation;pattern clustering;uncertainty handling;unsupervised learning","density based boundary point detection;Delaunay triangulation based boundary construction;intelligent Sobol based sampling;box uncertainty set;time expensive multiobjective optimization problem;uncertain regions;conservative sampling;evolutionary fuzzy clustering mechanism;uncertain space;optimal artificial neural network;evolutionary machine learning;robust optimization;multicriteria decision making;unsupervised machine learning;uncertainty handling techniques","","1","","23","","8 Aug 2019","","","IEEE","IEEE Conferences"
"A Novel Hybrid Machine Learning Algorithm for Limited and Big Data Modeling With Application in Industry 4.0","H. Khayyam; A. Jamali; A. Bab-Hadiashar; T. Esch; S. Ramakrishna; M. Jalili; M. Naebe","School of Engineering, RMIT University, Melbourne, VIC, Australia; Faculty of Mechanical Engineering, University of Guilan, Rasht, Iran; School of Engineering, RMIT University, Melbourne, VIC, Australia; Mechanical Engineering, FH Aachen University of Applied Sciences, Aachen, Germany; Department of Mechanical Engineering, National University of Singapore, Singapore; School of Engineering, RMIT University, Melbourne, VIC, Australia; Institute for Frontier Materials, Deakin University, Burwood, VIC, Australia","IEEE Access","24 Jun 2020","2020","8","","111381","111393","To meet the challenges of manufacturing smart products, the manufacturing plants have been radically changed to become smart factories underpinned by industry 4.0 technologies. The transformation is assisted by employment of machine learning techniques that can deal with modeling both big or limited data. This manuscript reviews these concepts and present a case study that demonstrates the use of a novel intelligent hybrid algorithms for Industry 4.0 applications with limited data. In particular, an intelligent algorithm is proposed for robust data modeling of nonlinear systems based on input-output data. In our approach, a novel hybrid data-driven combining the Group-Method of Data-Handling and Singular-Value Decomposition is adapted to find an offline deterministic model combined with Pareto multi-objective optimization to overcome the overfitting issue. An Unscented-Kalman-Filter is also incorporated to update the coefficient of the deterministic model and increase its robustness against data uncertainties. The effectiveness of the proposed method is examined on a set of real industrial measurements.","2169-3536","","10.1109/ACCESS.2020.2999898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108222","Industry 40;big data modeling;limited data modeling;multi-objective optimization","Data models;Support vector machines;Big Data;Machine learning;Computational modeling;Principal component analysis;Industries","Big Data;data models;factory automation;industrial plants;Kalman filters;learning (artificial intelligence);nonlinear filters;Pareto optimisation;production engineering computing;singular value decomposition","unscented-Kalman-filter;limited data modeling;industry 4.0;hybrid machine learning;intelligent hybrid algorithms;group-method of data-handling;industrial measurements;data uncertainties;Pareto multiobjective optimization;offline deterministic model;singular-value decomposition;input-output data;big data modeling;nonlinear systems;intelligent algorithm;smart factories;manufacturing plants;smart products","","6","","46","CCBY","4 Jun 2020","","","IEEE","IEEE Journals"
"A Genetic Programming-Based Multi-Objective Optimization Approach to Data Replication Strategies for Distributed Systems","S. M. A. Bokhari; O. Theel","University of Oldenburg,Department of Computer Science,Germany; University of Oldenburg,Department of Computer Science,Germany","2020 IEEE Congress on Evolutionary Computation (CEC)","3 Sep 2020","2020","","","1","9","Data replication is the core of distributed systems to enhance their fault tolerance and make services highly available to the end-users. Data replication masks run-time failures and hence, makes the system more reliable. There are many contemporary data replication strategies for this purpose, but the decision to choose an appropriate strategy for a certain environment and a specific scenario is a challenge and full of compromises. There exists a potentially indefinite number of scenarios that cannot be covered entirely by contemporary strategies. It demands designing new data replication strategies optimized for the given scenarios. The constraints of such scenarios are often conflicting in a sense that an increase in one objective could be sacrificial to the others, which implies there is no best solution to the problem but what serves the purpose. In this regard, this research provides a genetic programming-based multi-objective optimization approach that endeavors to not only identify, but also design new data replication strategies and optimize their conflicting objectives as a single-valued metric. The research provides an intelligent, automatic mechanism to generate new replication strategies as well as easing up the decision making so that relevant strategies with satisfactory trade-offs of constraints can easily be picked and used from the generated solutions at run-time. Moreover, it makes the notion of hybrid strategies easier to accomplish which otherwise would have been very cumbersome to achieve, therefore, to optimize.","","978-1-7281-6929-3","10.1109/CEC48606.2020.9185598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185598","Distributed Systems;Fault Tolerance;Data Replication;Quorum Protocols;Operation Availability;Operation Cost;Voting Structures;Optimization;Pareto Front;Machine Learning;Genetic Programming","Optimization;Protocols;Machine learning;Genetic programming;Linear programming;Measurement","data handling;decision making;distributed processing;genetic algorithms;software fault tolerance","genetic programming-based multiobjective optimization approach;distributed systems;run-time failures;data replication strategies;decision making","","2","","21","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Meta-Optimization of Bias-Variance Trade-Off in Stochastic Model Learning","T. Aotani; T. Kobayashi; K. Sugimoto","Nara Institute of Science and Technology, Ikoma, Nara, Japan; Nara Institute of Science and Technology, Ikoma, Nara, Japan; Nara Institute of Science and Technology, Ikoma, Nara, Japan","IEEE Access","9 Nov 2021","2021","9","","148783","148799","Model-based reinforcement learning is expected to be a method that can safely acquire the optimal policy under real-world conditions by using a stochastic dynamics model for planning. Since the stochastic dynamics model of the real world is generally unknown, a method for learning from state transition data is necessary. However, model learning suffers from the problem of bias-variance trade-off. Conventional model learning can be formulated as a minimization problem of expected loss. Failure to consider higher-order statistics for loss would lead to fatal errors in long-term model prediction. Although various methods have been proposed to explicitly handle bias and variance, this paper first formulates a new loss function, especially for sequential training of the deep neural networks. To explicitly consider the bias-variance trade-off, a new multi-objective optimization problem with the augmented weighted Tchebycheff scalarization, is proposed. In this problem, the bias-variance trade-off can be balanced by adjusting a weight hyperparameter, although its optimal value is task-dependent and unknown. We additionally propose a general-purpose and efficient meta-optimization method for hyperparameter(s). According to the validation result on each epoch, the proposed meta-optimization can adjust the hyperparameter(s) towards the preferred solution simultaneously with model learning. In our case, the proposed meta-optimization enables the bias-variance trade-off to be balanced for maximizing the long-term prediction ability. Actually, the proposed method was applied to two simulation environments with uncertainty, and the numerical results showed that the well-balanced bias and variance of the stochastic model suitable for the long-term prediction can be achieved.","2169-3536","","10.1109/ACCESS.2021.3125000","Japan Science and Technology Agency (JST) Precursory Research for Embryonic Science and Technology (PRESTO), Japan(grant numbers:JPMJPR20C3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599708","Machine learning algorithms;systems modeling;Pareto optimization;bias-variance trade-off","Predictive models;Stochastic processes;Uncertainty;Training;Minimization;Planning;Numerical models","learning (artificial intelligence);neural nets;optimisation;stochastic processes","stochastic dynamics model;model learning;long-term model prediction;bias-variance trade-off;multiobjective optimization problem;well-balanced bias;stochastic model learning;model-based reinforcement learning;meta-optimization method;higher-order statistics;augmented weighted Tchebycheff scalarization;weight hyperparameter;hyperparameter","","","","52","CCBY","2 Nov 2021","","","IEEE","IEEE Journals"
"Cost-Time Performance of Scaling Applications on the Cloud","S. Rathnayake; L. Ramapantulu; Y. M. Teo","Dept. of Comput. Sci., Nat. Univ. of Singapore, Singapore, Singapore; Comput. Syst. Group, Int. Inst. of Inf. Technol., Hyderabad, India; Dept. of Comput. Sci., Nat. Univ. of Singapore, Singapore, Singapore","2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)","27 Dec 2018","2018","","","30","33","Recent advancements in big data processing and machine learning, among others, increase the resource demand for running applications with larger problem sizes. Elastic cloud computing resources with pay-per-use pricing offers new opportunities where large application execution is constrained only by the cost budget. Given a cost budget and a time deadline, this paper introduces a measurement-driven analytical modeling approach to determine the largest Pareto-optimal problem size and its corresponding cloud configuration for execution. We evaluate our approach with a set of representative applications that exhibit a range of resource demand growth patterns on Amazon AWS cloud. We show the existence of cost-time-size Pareto-frontier with multiple sweet spots meeting user constraints. To characterize the cost-performance of cloud resources, we use Performance Cost Ratio (PCR) metric. We extend Gustafson's fixed-time scaling in the context of cloud, and, investigate fixed-cost-time scaling of applications and show that using resources with higher PCR yields better cost-time performance. We discuss a number of useful insights on the trade-off between the execution time and the largest Pareto-optimal problem size, and, show that time deadline could be tightened for a proportionately much smaller reduction of problem size.","2330-2186","978-1-5386-7899-2","10.1109/CloudCom2018.2018.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590990","scaling;largest problem size;cloud;cost-time performance;Pareto-optimal configuration","Cloud computing;Scalability;Analytical models;Predictive models;Size measurement;Time measurement;Computational modeling","budgeting data processing;cloud computing;Pareto optimisation","cost-time performance;big data processing;machine learning;application execution;cost budget;representative applications;resource demand growth patterns;Amazon AWS cloud;cost-time-size Pareto-frontier;cloud resources;Gustafson's fixed-time scaling;pay-per-use pricing;cloud configuration;performance cost ratio metric;measurement-driven analytical modeling;Pareto-optimal problem;PCR;elastic cloud computing resources","","","","23","","27 Dec 2018","","","IEEE","IEEE Conferences"
"A new approach on multi-agent Multi-Objective Reinforcement Learning based on agents' preferences","Z. Daavarani Asl; V. Derhami; M. Yazdian-Dehkordi","Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran; Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran; Computer Engineering Department, Faculty of Engineering, Yazd University, Yazd, Iran","2017 Artificial Intelligence and Signal Processing Conference (AISP)","26 Mar 2018","2017","","","75","79","Reinforcement Learning (RL) is a powerful machine learning paradigm for solving Markov Decision Process (MDP). Traditional RL algorithms aim to solve one-objective problems, but many real-world problems have more than one objective which conflict each other. In recent years, Multi-Objective Reinforcement Learning (MORL) algorithms, which employ a reward vector instead of a scalar reward signal, have been proposed to solve multi-objective problems. In MORL, because of conflicting objectives, there is no one optimal solution and a set of solutions named Pareto Front will be learned. In this paper, we proposed a new multi-agent method, which uses a shared Q-table for all agents to solve bi-objective problems. However, each agent selects actions based on its preference. These preferences are different with each other and the agents reach to Pareto Front solutions based on this preferences. The proposed method is simple in understanding and its computational cost is very low. Moreover, after finding the Pareto Front set, we can easily track the policy. Simulation results show that our proposed method outperforms the available methods in the term of learning speed.","","978-1-5386-2585-9","10.1109/AISP.2017.8324111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8324111","reinforcement learning;multi-agent systems;multi-objective;Pareto Front","Signal processing algorithms;Learning (artificial intelligence);Signal processing;Multi-agent systems;Task analysis;Markov processes","decision theory;learning (artificial intelligence);Markov processes;multi-agent systems;Pareto optimisation","multiagent multiobjective reinforcement learning;Markov Decision Process;traditional RL algorithms;one-objective problems;scalar reward signal;multiagent method;bi-objective problems;machine learning paradigm;agent preferences;MDP solving;MORL algorithms;Pareto Front solutions;Q-table","","2","","15","","26 Mar 2018","","","IEEE","IEEE Conferences"
"Adaptive image segmentation using genetic and hybrid search methods","B. Bhanu; Sungkee Lee; S. Das","California Univ., Riverside, CA, USA; NA; NA","IEEE Transactions on Aerospace and Electronic Systems","6 Aug 2002","1995","31","4","1268","1291","This paper describes an adaptive approach for the important image processing problem of image segmentation that relies on learning from experience to adapt and improve the segmentation performance. The adaptive image segmentation system incorporates a feedback loop consisting of a machine learning subsystem, an image segmentation algorithm, and an evaluation component which determines segmentation quality. The machine learning component is based on genetic adaptation and uses (separately) a pure genetic algorithm (GA) and a hybrid of GA and hill climbing (HC). When the learning subsystem is based on pure genetics, the corresponding evaluation component is based on a vector of evaluation criteria. For the hybrid case, the system employs a scalar evaluation measure which is a weighted combination of the different criteria. Experimental results for pure genetic and hybrid search methods are presented using a representative database of outdoor TV imagery. The multiobjective optimization demonstrates the ability of the adaptive image segmentation system to provide high quality segmentation results in a minimal number of generations.<<ETX>></ETX>","1557-9603","","10.1109/7.464350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=464350","","Image segmentation;Search methods;Adaptive systems;Machine learning;Image processing;Feedback loop;Machine learning algorithms;Genetic algorithms;Image databases;TV","adaptive signal processing;image segmentation;genetic algorithms;search problems;learning (artificial intelligence)","adaptive image segmentation;hybrid search method;learning from experience;feedback loop;machine learning subsystem;evaluation component;segmentation quality;genetic adaptation;pure genetic algorithm;hill climbing;vector of evaluation criteria;scalar evaluation measure;outdoor TV imagery;multiobjective optimization;Phoenix algorithm","","47","","27","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"GAN-Based One-Class Classification for Personalized Image Retrieval","S. H. Kim; H. -J. Kim; J. -Y. Kim","Sch. of Electr. & Comput. Eng., Univ. of Seoul, Seoul, South Korea; Sch. of Electr. & Comput. Eng., Univ. of Seoul, Seoul, South Korea; Sch. of Comput. Eng., Hansung Univ., Seoul, South Korea","2018 IEEE International Conference on Big Data and Smart Computing (BigComp)","28 May 2018","2018","","","771","774","One-class classification for a personalized image retrieval system is one of most important research issues in machine learning. However, the conventional one-class classification techniques can have an overfitting problem. Thus, in this paper, we propose a novel one-class classification technique using the framework of generative adversarial nets (GAN) for image data. First, the support model and one-class model are trained with only positive-class data by a minimax game. At the end of this learning process, the one-class model learns the features of positive-class data very well while reducing generation error. One of our important findings is that the negative-class data generated by the support model help the one-class model conceptually and experimentally reduce the generative error. Using CIFAR-10, we show that our proposed technique outperforms the conventional technique by ~10% in terms of F1 measure.","2375-9356","978-1-5386-3649-7","10.1109/BigComp.2018.00147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367227","one class classification;generative adversarial net;deep learning;image retrieval;convolutional neural network","Data models;Gallium nitride;Image retrieval;Training;Support vector machines;Airplanes;Automobiles","game theory;image classification;image retrieval;learning (artificial intelligence);minimax techniques;pattern classification","personalized image retrieval system;important research issues;machine learning;one-class classification technique;generative adversarial nets;image data;support model;one-class model;positive-class data;generation error;negative-class data;generative error;conventional technique;GAN-Based One-Class Classification;CIFAR-10;F1 measure;minimax game","","6","","14","","28 May 2018","","","IEEE","IEEE Conferences"
"Improving Network Slimming With Nonconvex Regularization","K. Bui; F. Park; S. Zhang; Y. Qi; J. Xin","Department of Mathematics, University of California at Irvine, Irvine, CA, USA; Department of Mathematics and Computer Science, Whittier College, Whittier, CA, USA; Department of Mathematics, University of California at Irvine, Irvine, CA, USA; Department of Mathematics, University of California at Irvine, Irvine, CA, USA; Department of Mathematics, University of California at Irvine, Irvine, CA, USA","IEEE Access","23 Aug 2021","2021","9","","115292","115314","Convolutional neural networks (CNNs) have developed to become powerful models for various computer vision tasks ranging from object detection to semantic segmentation. However, most of the state-of-the-art CNNs cannot be deployed directly on edge devices such as smartphones and drones, which need low latency under limited power and memory bandwidth. One popular, straightforward approach to compressing CNNs is network slimming, which imposes <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1}$ </tex-math></inline-formula> regularization on the channel-associated scaling factors via the batch normalization layers during training. Network slimming thereby identifies insignificant channels that can be pruned for inference. In this paper, we propose replacing the <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1}$ </tex-math></inline-formula> penalty with an alternative nonconvex, sparsity-inducing penalty in order to yield a more compressed and/or accurate CNN architecture. We investigate <inline-formula> <tex-math notation=""LaTeX"">$\ell _{p} (0 < p < 1)$ </tex-math></inline-formula>, transformed <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1}$ </tex-math></inline-formula> (<inline-formula> <tex-math notation=""LaTeX"">$\text{T}\ell _{1}$ </tex-math></inline-formula>), minimax concave penalty (MCP), and smoothly clipped absolute deviation (SCAD) due to their recent successes and popularity in solving sparse optimization problems, such as compressed sensing and variable selection. We demonstrate the effectiveness of network slimming with nonconvex penalties on three neural network architectures – VGG-19, DenseNet-40, and ResNet-164 – on standard image classification datasets. Based on the numerical experiments, <inline-formula> <tex-math notation=""LaTeX"">$\text{T}\ell _{1}$ </tex-math></inline-formula> preserves model accuracy against channel pruning, <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1/2, 3/4}$ </tex-math></inline-formula> yield better compressed models with similar accuracies after retraining as <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1}$ </tex-math></inline-formula>, and MCP and SCAD provide more accurate models after retraining with similar compression as <inline-formula> <tex-math notation=""LaTeX"">$\ell _{1}$ </tex-math></inline-formula>. Network slimming with <inline-formula> <tex-math notation=""LaTeX"">$\text{T}\ell _{1}$ </tex-math></inline-formula> regularization also outperforms the latest Bayesian modification of network slimming in compressing a CNN architecture in terms of memory storage while preserving its model accuracy after channel pruning.","2169-3536","","10.1109/ACCESS.2021.3105366","NSF(grant numbers:DMS-1854434,DMS-1952644); Qualcomm Faculty Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514866","Convolutional neural networks (CNN);machine learning;deep learning;network pruning;nonconvex optimization","Convolutional neural networks;Training;Quantization (signal);Sparse matrices;Sensors;Deep learning;Tensors","","","","","","95","CCBY","16 Aug 2021","","","IEEE","IEEE Journals"
"Neural Architecture Search for Robust Networks in 6G-Enabled Massive IoT Domain","K. Wang; P. Xu; C. -M. Chen; S. Kumari; M. Shojafar; M. Alazab","Department of Computer Science, Jinan University, Guangzhou, China; Department of Computer Science, Harbin Institute of Technology, Shenzhen, China; College of Computer Science and Engineering, Shandong University of Science and Technology, Shandong, China; Department of Mathematics, Chaudhary Charan Singh University, Meerut, India; Institute for Communication Systems, 5G/6G Innovation Centre, University of Surrey, Guildford, U.K.; College of Engineering, IT and Environment, Charles Darwin University, Casuarina, NT, Australia","IEEE Internet of Things Journal","24 Mar 2021","2021","8","7","5332","5339","6G technology enables artificial intelligence (AI)-based massive IoT to manage network resources and data with ultra high speed, responsive network, and wide coverage. However, many AI-enabled Internet-of-Things (AIoT) systems are vulnerable to adversarial example attacks. Therefore, designing robust deep learning models that can be deployed on resource-constrained devices has become an important research topic in the field of 6G-enabled AIoT. In this article, we propose a method for automatically searching for robust and efficient neural network structures for AIoT systems. By introducing a skip connection structure, a feature map with reduced front-end influence can be used for calculations during the classification process. Additionally, a novel type of densely connected search space is proposed. By relaxing this space, it is possible to search for network structures efficiently. In addition, combined with adversarial training and model delay constraints, we propose a multiobjective gradient optimization method to realize the automatic searching of network structures. Experimental results demonstrate that our method is effective for AIoT systems and superior to state-of-the-art neural architecture search algorithms.","2327-4662","","10.1109/JIOT.2020.3040281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269354","6G;adversarial example;artificial intelligence-enabled Internet-of-Things (AIoT);massive IoT;neural architecture search","Deep learning;Robustness;6G mobile communication;Search problems;Face recognition;Performance evaluation;Internet of Things","6G mobile communication;deep learning (artificial intelligence);gradient methods;Internet of Things;optimisation;pattern classification;search problems","classification process;AI-enabled Internet-of-Things systems;6G technology;6G-enabled massive IoT domain;neural architecture search algorithms;automatic searching;multiobjective gradient optimization method;model delay constraints;adversarial training;densely connected search space;reduced front-end influence;skip connection structure;neural network structures;robust network structures;6G-enabled AIoT;resource-constrained devices;robust deep learning models;adversarial example attacks;responsive network;ultra high speed;network resources;artificial intelligence-based massive IoT","","3","","27","IEEE","24 Nov 2020","","","IEEE","IEEE Journals"
"Exploration of data-driven methods for multiphysics electromagnetic partial differential equations","H. Fu; W. Cheng; Y. Qin","Fudan University,Key Laboratory of Information Science of Electromagnetic Waves,Shanghai,China; Fudan University,Key Laboratory of Information Science of Electromagnetic Waves,Shanghai,China; Fudan University,Key Laboratory of Information Science of Electromagnetic Waves,Shanghai,China","2020 IEEE MTT-S International Conference on Numerical Electromagnetic and Multiphysics Modeling and Optimization (NEMO)","8 Feb 2021","2020","","","1","4","In a complex electromagnetic environment, numerical solution of partial differential equations (PDEs) and how to sample less data to invert spatio-temporal dynamics to discover potential physical laws or governing equations have been facing quite difficult challenges. With rapid progress of data-driven methods for artificial intelligence and computational physics, this paper would like to discuss our attempt on data-driven inversion and forward model for electromagnetic Maxwell's Equations.First of all, we propose a deep learning neural network in conjunction with sparse regression and pareto analysis to retrieve the hidden governing equations - Maxwell's wave equations of multiphysics electromagnetic systems. The JEC-FDTD algorithm is adopted for calculating interaction between electromagnetic wave with magnetized plasmas. Based on the concept of automatic differentiation, the differentiation operator is approximated by convolution. The neural network by tempo-rally sampling data of few spatial points can retrieve multiple physical electromagnetic and inhomogeneous magnetized plasma parameters. Also, the arctecture with learned PDEs is capable of predicting electric fields throughout the whole process even with noise. The data-driven method for discovery of coupled partial differential equations describing the electromagnetic fields in a complex system may also be applied to solve changeling problems that may not be solvable from first principles.Secondly, we construct the relationship between the Maxwell's wave equations and the recurrent neural network (RNN) for multiphysics electromagnetic systems. Numerical solution and inversion of Maxwell's wave equations are investigated for multiphysics electromagnetic systems. Numerical results by RNN agrees with the traditional JEC-FDTD algorithm. Parameter inversion can be easily achieved with backpropagation.Finally, we would like to compare two methods and then discuss advantages, difficulties and challenges for data-driven method for multiphysics electromagnetic systems.","","978-1-7281-6966-8","10.1109/NEMO49486.2020.9343645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343645","Microwave and plasma interaction;Maxwell’s wave equation;Data-driven discovery;Machine learning;Recur-rent neural network","Recurrent neural networks;Propagation;Partial differential equations;Electromagnetic scattering;Plasmas;Mathematical model;Electromagnetics","backpropagation;finite difference time-domain analysis;learning (artificial intelligence);partial differential equations;plasma electromagnetic wave propagation;plasma simulation;recurrent neural nets","data-driven method;multiphysics electromagnetic partial differential equations;complex electromagnetic environment;numerical solution;sample less data;potential physical laws;data-driven inversion;electromagnetic Maxwell's Equations;deep learning neural network;hidden governing equations;Maxwell's wave equations;multiphysics electromagnetic systems;electromagnetic wave;automatic differentiation;differentiation operator;tempo-rally sampling data;multiple physical electromagnetic plasma parameters;inhomogeneous magnetized plasma parameters;coupled partial differential equations;electromagnetic fields","","","","14","","8 Feb 2021","","","IEEE","IEEE Conferences"
"ApproxFPGAs: Embracing ASIC-Based Approximate Arithmetic Components for FPGA-Based Systems","B. S. Prabakaran; V. Mrazek; Z. Vasicek; L. Sekanina; M. Shafique","Technische Universität Wien (TU Wien),Institute of Computer Engineering,Austria; Brno University of Technology,Faculty of Information Technology,Czech Republic; Brno University of Technology,Faculty of Information Technology,Czech Republic; Brno University of Technology,Faculty of Information Technology,Czech Republic; Technische Universität Wien (TU Wien),Institute of Computer Engineering,Austria","2020 57th ACM/IEEE Design Automation Conference (DAC)","9 Oct 2020","2020","","","1","6","There has been abundant research on the development of Approximate Circuits (ACs) for ASICs. However, previous studies have illustrated that ASIC-based ACs offer asymmetrical gains in FPGA-based accelerators. Therefore, an AC that might be pareto-optimal for ASICs might not be pareto-optimal for FPGAs. In this work, we present the ApproxFPGAs methodology that uses machine learning models to reduce the exploration time for analyzing the state-of-the-art ASIC-based ACs to determine the set of pareto-optimal FPGA-based ACs. We also perform a case-study to illustrate the benefits obtained by deploying these pareto-optimal FPGA-based ACs in a state-of-the-art automation framework to systematically generate pareto-optimal approximate accelerators that can be deployed in FPGA-based systems to achieve high performance or low-power consumption.","0738-100X","978-1-7281-1085-1","10.1109/DAC18072.2020.9218533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218533","Approximate Computing;FPGA;ASIC;Adder;Multiplier;Arithmetic Units;Machine Learning;Statistics;Models;Synthesis","Field programmable gate arrays;Integrated circuit modeling;Libraries;Regression tree analysis;Machine learning;Hardware;Training","application specific integrated circuits;field programmable gate arrays;learning (artificial intelligence);low-power electronics;Pareto optimisation;power aware computing","FPGA based accelerators;ASIC based approximate arithmetic components;ASIC based ACs;Pareto optimal approximate accelerators;Pareto optimal FPGA based ACs;ApproxFPGAs;machine learning;field programmable gate arrays;application specific integrated circuits;high performance consumption;low power consumption","","3","","23","","9 Oct 2020","","","IEEE","IEEE Conferences"
"Invited Talk Abstract: Introducing ReQuEST: An Open Platform for Reproducible and Quality-Efficient Systems-ML Tournaments","G. Fursin",NA,"2018 1st Workshop on Energy Efficient Machine Learning and Cognitive Computing for Embedded Applications (EMC2)","8 Nov 2018","2018","","","3","3","Co-designing efficient machine learning based systems across the whole application/hardware/software stack to trade off speed, accuracy, energy and costs is becoming extremely complex and time consuming. Researchers often struggle to evaluate and compare different published works across rapidly evolving software frameworks, heterogeneous hardware platforms, compilers, libraries, algorithms, data sets, models, and environments. I will present our community effort to develop an open co-design tournament platform with an online public scoreboard based on Collective Knowledge workflow framework (CK). It gradually incorporates best research practices while providing a common way for multidisciplinary researchers to optimize and compare the quality vs. efficiency Pareto optimality of various workloads on diverse and complete hardware/software systems. All the winning solutions will be made available to the community as portable and customizable ""plug&play"" components with a common API to accelerate research and innovation! I will then discuss how our open competition and collaboration can help to achieve energy efficiency for cognitive workloads based on energy-efficient submissions from the 1st ReQuEST tournament co-located with ASPLOS'18. Further details: http://cKnowledge.org/request.","","978-1-5386-7367-6","10.1109/EMC2.2018.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8524014","Tournament;open platform;machine learning","Machine learning;Conferences;Energy efficiency;Cognitive systems;Software;Hardware;Libraries","application program interfaces;hardware-software codesign;learning (artificial intelligence);middleware;Pareto optimisation;software agents","innovation;energy efficiency;energy-efficient submissions;quality-efficient systems-ML;rapidly evolving software frameworks;heterogeneous hardware platforms;data sets;community effort;open co-design tournament platform;online public scoreboard;efficiency Pareto optimality;hardware/software systems;API;collective knowledge workflow framework;ReQuEST;machine learning based systems","","","","","","8 Nov 2018","","","IEEE","IEEE Conferences"
"Multi-Dimensional Dynamic Model Compression for Efficient Image Super-Resolution","Z. Hou; S. -Y. Kung",Princeton University; Princeton University,"2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","15 Feb 2022","2022","","","3492","3502","Modern single image super-resolution (SR) system based on convolutional neural networks achieves substantial progress. However, most SR deep networks are computationally expensive and require excessively large activation memory footprints, impeding their effective deployment to resource-limited devices. Based on the observation that the activation patterns in SR networks exhibit high input-dependency, we propose Multi-Dimensional Dynamic Model Compression method that can reduce both spatial and channel wise redundancy in an SR deep network for different input images. To reduce the spatial-wise redundancy, we propose to perform convolution on scaled-down feature-maps where the down-scaling factor is made adaptive to different input images. To reduce the channel-wise redundancy, we introduce a low-cost channel saliency predictor for each convolution to dynamically skip the computation of unimportant channels based on the Gumbel-Softmax. To better capture the feature-maps information and facilitate input-adaptive decision, we employ classic image processing metrics, e.g., Spatial Information, to guide the saliency predictors. The proposed method can be readily applied to a variety of SR deep networks and trained end-to-end with standard super-resolution loss, in combination with a sparsity criterion. Experiments on several benchmarks demonstrate that our method can effectively reduce the FLOPs of both lightweight and non-compact SR models with negligible PSNR loss. Moreover, our compressed models achieve competitive PSNR-FLOPs Pareto frontier compared with SOTA NAS-based SR methods.","2642-9381","978-1-6654-0915-5","10.1109/WACV51458.2022.00355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706737","Deep Learning Deep Learning -> Efficient Training and Inference Methods for Networks","Performance evaluation;Visualization;Image coding;Convolution;Computational modeling;Redundancy;Superresolution","","","","","","54","","15 Feb 2022","","","IEEE","IEEE Conferences"
"The Trade-off Between Privacy and Utility in Local Differential Privacy","M. Li; Y. Tian; J. Zhang; D. Fan; D. Zhao","Guizhou University,College of Computer Science and Technology,Guiyang,P. R. China,550025; Guizhou University,College of Computer Science and Technology,Guiyang,P. R. China,550025; Hebei Normal University,College of Computer and Cyber Security,Shijiazhuang,P. R. China,050024; Guizhou University,College of Computer Science and Technology,Guiyang,P. R. China,550025; Hebei Normal University,College of Computer and Cyber Security,Shijiazhuang,P. R. China,050024","2021 International Conference on Networking and Network Applications (NaNA)","10 Dec 2021","2021","","","373","378","In statistical queries work, such as frequency estimation, the untrusted data collector could as an honest-but-curious (HbC) or malicious adversary to learn true values. Local differential privacy(LDP) protocols have been applied against the untrusted third party in data collecting. Nevertheless, excessive noise of LDP will reduce data utility, thus affecting the results of statistical queries. Therefore, it is significant to research the trade-off between privacy and utility. In this paper, we first measure the privacy loss by observing the maximum posterior confidence of the adversary (data collector). Then, through theoretical analysis and comparison we obtain the most suitable utility measure that is Wasserstein distance. Based on these, we introduce an originality framework for privacy-utility tradeoff framework, finding that this system conforms to the Pareto optimality state and formalizing a payoff function to find optimal equilibrium point under Pareto efficiency. Finally, we illustrate the efficacy of our system model by the Adult dataset from the UCI machine learning repository.","","978-1-6654-4158-2","10.1109/NaNA53684.2021.00071","National Natural Science Foundation of China; Science and Technology Program of Guizhou Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9634868","data collecting;local differential privacy;privacy metric;utility metric;Pareto optimality","Privacy;Differential privacy;Protocols;Machine learning;Data collection;Loss measurement;Frequency estimation","","","","","","18","","10 Dec 2021","","","IEEE","IEEE Conferences"
"Driver Danger-Level Monitoring System Using Multi-Sourced Big Driving Data","J. -L. Yin; B. -H. Chen; K. -H. R. Lai","Department of Computer Science and Engineering, Yuan Ze University, Taoyuan, Taiwan; Department of Computer Science and Engineering, Yuan Ze University, Taoyuan, Taiwan; Department of Computer Science and Engineering, Yuan Ze University, Taoyuan, Taiwan","IEEE Transactions on Intelligent Transportation Systems","26 Nov 2020","2020","21","12","5271","5282","Danger-level analysis is widely used to prevent potential driving risks based on driving performance. Such analysis is essential for monitoring driver performance. Moreover, danger-level analysis is vital for automotive safety systems and driving assistance applications. However, danger-level analysis that simultaneously considers driver-, vehicle-, and road-related information from driving data has rarely been conducted. Such analysis is very challenging due to the issues associated with the high volume and high variety in multisourced driving data. In this paper, we propose a novel danger-level analysis framework for dealing with high variety and high volume problems of multisourced driving data. Built upon a feature extraction method in the proposed framework, we first profile multisourced driving features for overcoming the variety problem. Next, danger-level analysis is formulated as a multiobjective pursuit problem in a linear model. The problem is then solved using a semisupervised learning strategy to overcome the volume issue. Therefore, the danger level can be accurately estimated from multisourced driving data by using the proposed framework. The experimental results indicate that the proposed framework outperforms existing machine learning techniques for multisourced driving data.","1558-0016","","10.1109/TITS.2019.2954183","Ministry of Science and Technology, Taiwan(grant numbers:MOST 108-2221-E-155-034-MY3,MOST 107-2221-E-155-052-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8915711","Danger-level analysis;driving risks;multi-sourced driving data","Intelligent vehicles;Feature extraction;Biomedical monitoring;Monitoring;Road traffic;Analytical models;Collaboration","Big Data;computerised monitoring;driver information systems;feature extraction;learning (artificial intelligence);risk analysis;road safety;traffic engineering computing","driving risk prevention;automotive safety systems;driving assistance applications;multisourced driving data;multisourced driving features;driver danger-level monitoring system;multisourced big driving data;driver performance monitoring;danger-level analysis;semisupervised learning strategy;machine learning;feature extraction","","6","","38","IEEE","27 Nov 2019","","","IEEE","IEEE Journals"
"Testing Vision-Based Control Systems Using Learnable Evolutionary Algorithms","R. Ben Abdessalem; S. Nejati; L. C. Briand; T. Stifter","SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; SnT Centre, Univ. of Luxembourg, Luxembourg City, Luxembourg; IEE S.A., Luxembourg","2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)","2 Sep 2018","2018","","","1016","1026","Vision-based control systems are key enablers of many autonomous vehicular systems, including self-driving cars. Testing such systems is complicated by complex and multidimensional input spaces. We propose an automated testing algorithm that builds on learnable evolutionary algorithms. These algorithms rely on machine learning or a combination of machine learning and Darwinian genetic operators to guide the generation of new solutions (test scenarios in our context). Our approach combines multiobjective population-based search algorithms and decision tree classification models to achieve the following goals: First, classification models guide the search-based generation of tests faster towards critical test scenarios (i.e., test scenarios leading to failures). Second, search algorithms refine classification models so that the models can accurately characterize critical regions (i.e., the regions of a test input space that are likely to contain most critical test scenarios). Our evaluation performed on an industrial automotive automotive system shows that: (1) Our algorithm outperforms a baseline evolutionary search algorithm and generates 78% more distinct, critical test scenarios compared to the baseline algorithm. (2) Our algorithm accurately characterizes critical regions of the system under test, thus identifying the conditions that are likely to lead to system failures.","1558-1225","978-1-4503-5638-1","10.1145/3180155.3180160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453180","Search-based Software Engineering;Evolutionary algorithms;Software Testing;Automotive Software Systems","Testing;Classification algorithms;Roads;Control systems;Evolutionary computation;Decision trees;Automotive engineering","decision trees;evolutionary computation;genetic algorithms;learning (artificial intelligence);mobile robots;robot vision;search problems","vision-based control systems;learnable evolutionary algorithms;autonomous vehicular systems;complex input spaces;multidimensional input spaces;automated testing algorithm;machine learning;multiobjective population-based search algorithms;decision tree classification models;search-based generation;search algorithms refine classification models;test input space;industrial automotive automotive system;baseline evolutionary search algorithm;distinct test scenarios","","46","","39","","2 Sep 2018","","","IEEE","IEEE Conferences"
"Deception In The Game of Guarding Multiple Territories: A Machine Learning Approach","A. Asgharnia; H. M. Schwartz; M. Atia","Carleton University,Departmant of Systems and Computer Engineering,Ottawa,Canada; Carleton University,Departmant of Systems and Computer Engineering,Ottawa,Canada; Carleton University,Departmant of Systems and Computer Engineering,Ottawa,Canada","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","381","388","In this paper, a deceptive version of guarding a territory in a grid world is proposed. Like the original version, a defender tries to intercept an invader before it invades the targets. However, the discerning invader can deceive the defender about its real goal so that it can improve its performance. On the other hand, the defender tries to confront the invader by guessing its true goal. A two-level policy is obtained via reinforcement learning (RL). In the lower level, the invader and the defender learn their optimal policies to invade or defend a particular territory. In the higher level, the invader learns which territory it should pretend to invade in order to manipulate the defender's belief function. A multiagent reinforcement learning (MARL) algorithm is implemented for obtaining the optimal policies via the minimax Q-learning algorithm at the lower level. Whereas for the higher-level policy a single-agent Q-learning algorithm is utilized. Results of different reward functions are compared. The results show that the invader can improve its performance by taking advantage of deception.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283173","Reinforcement Learning;Multiagent systems;Deception;Belief;Guarding a territory","Machine learning algorithms;Conferences;Reinforcement learning;Games;Cybernetics","computer games;game theory;learning (artificial intelligence);minimax techniques;multi-agent systems","multiagent reinforcement learning algorithm;minimax Q-learning algorithm;single-agent Q-learning algorithm;deception;deceptive version;guarding a territory game;MARL algorithm;guarding multiple territories game","","","","19","","14 Dec 2020","","","IEEE","IEEE Conferences"
"A Deep Learning Approach To Multi-Context Socially-Aware Navigation","S. B. Banisetty; V. Rajamohan; F. Vega; D. Feil-Seifer","University of Nevada,Department of Computer Science and Engineering,Reno,USA,NV; University of Nevada,Department of Computer Science and Engineering,Reno,USA,NV; University of Nevada,Department of Mechanical Engineering,Las Vegas,NV,USA,89154; University of Nevada,Department of Computer Science and Engineering,Reno,USA,NV","2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN)","23 Aug 2021","2021","","","23","30","We present a context classification pipeline to allow a robot to change its navigation strategy based on the observed social scenario. Socially-Aware Navigation considers social behavior in order to improve navigation around people. Most of the existing research uses different techniques to incorporate social norms into robot path planning for a single context. Methods that work for hallway behavior might not work for approaching people, and so on. We developed a high-level decision-making subsystem, a model-based context classifier, and a multi-objective optimization-based local planner to achieve socially-aware trajectories for autonomously sensed contexts. Using a context classification system, the robot can select social objectives that are later used by Pareto Concavity Elimination Transformation (PaCcET) based local planner to generate safe, comfortable, and socially appropriate trajectories for its environment. This was tested and validated in multiple environments on a Pioneer mobile robot platform; results show that the robot could select and account for social objectives related to navigation autonomously.","1944-9437","978-1-6654-0492-1","10.1109/RO-MAN50785.2021.9515424","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515424","","Deep learning;Navigation;Service robots;Pipelines;Decision making;Robot sensing systems;Trajectory","concave programming;control engineering computing;deep learning (artificial intelligence);human-robot interaction;mobile robots;navigation;Pareto optimisation;path planning;robot programming","Pioneer mobile robot platform;social objectives;deep learning;context classification pipeline;navigation strategy;social scenario;social behavior;social norms;robot path planning;high-level decision-making subsystem;model-based context classifier;multiobjective optimization-based local planner;context classification system;multicontext socially-aware navigation;Pareto concavity elimination transformation;PaCcET","","","","30","","23 Aug 2021","","","IEEE","IEEE Conferences"
"Energy-performance design exploration of a low-power microprogrammed deep-learning accelerator","G. Santoro; M. R. Casu; V. Peluso; A. Calimera; M. Alioto","Politecnico di Torino, 10129 Turin, IT; Politecnico di Torino, 10129 Turin, IT; Politecnico di Torino, 10129 Turin, IT; Politecnico di Torino, 10129 Turin, IT; National University of Singapore, 119077 Singapore, SG","2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)","23 Apr 2018","2018","","","1151","1154","This paper presents the design space exploration of a novel microprogrammable accelerator in which PEs are connected with a Network-on-Chip and benefit from low-power features enabled through a practical implementation of a Dual-V<sub>dd</sub> assignment scheme. An analytical model, fitted with postlayout data obtained with a 28nm FDSOI design kit, returns implementations with optimal energy-performance tradeoff by taking into consideration all the key design-space variables. The obtained Pareto analysis helps us infer optimization rules aimed at improving quality of design.","1558-1101","978-3-9819263-0-9","10.23919/DATE.2018.8342185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342185","","Random access memory;Computational modeling;Throughput;Bandwidth;Computer architecture;Analytical models;Data models","integrated circuit design;learning (artificial intelligence);network-on-chip;optimisation;Pareto analysis;programmable circuits;silicon-on-insulator","optimization rules;Pareto analysis;design-space variables;FDSOI design kit;dual-Vdd assignment scheme;network-on-chip;low-power microprogrammed deep-learning accelerator;optimal energy-performance tradeoff;postlayout data;low-power features;novel microprogrammable accelerator;design space exploration;energy-performance design exploration;size 28.0 nm","","3","","12","","23 Apr 2018","","","IEEE","IEEE Conferences"
"Applying Machine Learning in Designing Distributed Auction for Multi-agent Task Allocation with Budget Constraints","C. Luo; Q. Huang; F. Kong; S. Khan; Q. Qiu","Syracuse University,Department of Electrical Engineering & Computer Science,Syracuse,NY; Syracuse University,Department of Electrical Engineering & Computer Science,Syracuse,NY; Syracuse University,Department of Electrical Engineering & Computer Science,Syracuse,NY; Air Force Research Laboratory,Rome,NY; Syracuse University,Department of Electrical Engineering & Computer Science,Syracuse,NY","2021 20th International Conference on Advanced Robotics (ICAR)","5 Jan 2022","2021","","","356","363","The multi-agent task allocation can be solved in a distributed manner using Consensus-Based Bundle Algorithm (CBBA). Under this distributed auction process, each agent greedily maximizes the global score, which is the difference of the reward and the cost, through an iterative bundle construction and conflict resolution procedure. The distributed algorithm has provable convergence and guarantees 50% optimality if the score function satisfies the condition of diminishing marginal gain (DMG). While the previous work focuses on unconstrained optimization of rewards, this paper aims at applying CBBA to task allocation with budget constraints. Several heuristics were proposed to build the bundle and calculate the bidding scores as improvements to the original CBBA algorithm. We then prove that some of the new score functions are DMG, and therefore guarantees the convergence of the distributed process. We also show that these heuristic extended CBBAs are Pareto efficient; using different heuristic extensions under different scenarios is more efficient than consistently using the same one. To decide which heuristic extension should be used for a given task allocation problem, a graph convolutional neural network (GCN) model is trained to extract and analyze the features of the constrained optimization problem as a graph, and predict the potential performance (i.e., global reward) of different heuristic extensions. Based on the prediction, the best heuristic extension will be selected. Experimental results show that the predicted reward has more than 0.98 correlation with the actual reward and for 70% of time the prediction guided selection picks the best heuristic extension for the budget constrained task allocation problem.","","978-1-6654-3684-7","10.1109/ICAR53236.2021.9659364","Air Force Office of Scientific Research(grant numbers:FA2386-20-1-4062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659364","multi-agent;task allocation;GCN;limited budget;graph embedding","Machine learning algorithms;Heuristic algorithms;Predictive models;Feature extraction;Prediction algorithms;Resource management;Task analysis","","","","","","22","","5 Jan 2022","","","IEEE","IEEE Conferences"
"Universal Active Learning via Conditional Mutual Information Minimization","S. Shayovitz; M. Feder","Iby and Aladar Fleischman Faculty of Engineering, Tel Aviv University, Tel Aviv, Israel; Iby and Aladar Fleischman Faculty of Engineering, Tel Aviv University, Tel Aviv, Israel","IEEE Journal on Selected Areas in Information Theory","18 Jun 2021","2021","2","2","720","734","Modern machine learning systems require massive amounts of labeled training data in order to achieve high accuracy rates which is very expensive in terms of time and cost. Active learning is an approach which uses feedback to only label the most informative data points and significantly reduce the labeling effort. Many heuristics for selecting data points have been developed in recent years which are usually tailored to a specific task and a general unified framework is lacking. In this work, a new information theoretic criterion is proposed based on a minimax log-loss regret formulation of the active learning problem. First, a Redundancy Capacity theorem for active learning is derived along with an optimal learner. This leads to a new active learning criterion which naturally induces an exploration - exploitation trade-off in feature selection and generalizes previously proposed heuristic criteria. The new criterion is compared analytically and via empirical simulation to other commonly used information theoretic active learning criteria. Next, the linear hyper-plane hypotheses class with possibly asymmetric label noise is considered. The achievable performance for the proposed criterion is analyzed using a new low complexity greedy algorithm based on the Posterior Matching scheme for communication with feedback. It is shown that for general label noise and bounded feature distribution, the new information theoretic criterion decays exponentially fast to zero.","2641-8770","","10.1109/JSAIT.2021.3073842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411874","Minimax learning;active learning;posterior matching;feedback","Training;Entropy;Uncertainty;Feature extraction;Particle separators;Mutual information;Upper bound","greedy algorithms;learning (artificial intelligence);minimax techniques","universal active learning;conditional mutual information minimization;machine learning systems;labeled training data;informative data points;minimax log-loss regret formulation;heuristic criteria;asymmetric label noise;general label noise;redundancy capacity theorem;feature selection;linear hyper-plane hypotheses class;low complexity greedy algorithm;posterior matching scheme;bounded feature distribution;information theoretic active learning criteria","","","","40","IEEE","23 Apr 2021","","","IEEE","IEEE Journals"
"A Characterization of Stochastic Mirror Descent Algorithms and Their Convergence Properties","N. Azizan; B. Hassibi","California Institute of Technology, Pasadena, CA, 91125; California Institute of Technology, Pasadena, CA, 91125","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","5167","5171","Stochastic mirror descent (SMD) algorithms have recently garnered a great deal of attention in optimization, signal processing, and machine learning. They are similar to stochastic gradient descent (SGD), in that they perform updates along the negative gradient of an instantaneous (or stochastically chosen) loss function. However, rather than update the parameter (or weight) vector directly, they update it in a ""mirrored"" domain whose transformation is given by the gradient of a strictly convex differentiable potential function. SMD was originally conceived to take advantage of the underlying geometry of the problem as a way to improve the convergence rate over SGD. In this paper, we study SMD, for linear models and convex loss functions, through the lens of H<sup>∞</sup> estimation theory and come up with a minimax interpretation of the SMD algorithm which is the counterpart of the H<sup>∞</sup>-optimality of the SGD algorithm for linear models and quadratic loss. In doing so, we identify a fundamental conservation law that SMD satisfies and use it to study the convergence properties of the algorithm. For constant step size SMD, when the linear model is over-parameterized, we give a deterministic proof of convergence for SMD and show that from any initial point, it converges to the closest point in the space of all parameter vectors that interpolate the data, where closest is in the sense of the Bregman divergence of the potential function. This property is referred to as implicit regularization: with an appropriate choice of the potential function one can guarantee convergence to the minimizer of any desired convex regularizer. For vanishing step size SMD, and in the standard stochastic optimization setting, we give a direct and elementary proof of convergence for SMD to the ""true"" parameter vector which avoids ergodic averaging or appealing to stochastic differential equations.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682271","Stochastic gradient descent;mirror descent;minimax optimality;convergence;implicit regularization","Mirrors;Stochastic processes;Convergence;Optimization;Data models;Uncertainty;Interpolation","approximation theory;differential equations;gradient methods;iterative methods;minimisation;stochastic processes","strictly convex differentiable potential function;convergence rate;linear model;convex loss functions;SMD algorithm;SGD algorithm;convergence properties;constant step size SMD;standard stochastic optimization setting;stochastic differential equations;stochastic mirror descent algorithms;stochastic gradient descent;loss function;mirrored domain","","2","","15","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Information-Theoretic Lower Bounds on the Oracle Complexity of Stochastic Convex Optimization","A. Agarwal; P. L. Bartlett; P. Ravikumar; M. J. Wainwright","Department of EECS, University of California, Berkeley, USA; Departments of Statistics and EECS, University of California, Berkeley; Department of Computer Science, University of Texas, Austin, USA; Departments of Statistics and EECS, University of California, Berkeley, USA","IEEE Transactions on Information Theory","18 Apr 2012","2012","58","5","3235","3249","Relative to the large literature on upper bounds on complexity of convex optimization, lesser attention has been paid to the fundamental hardn4516420ess of these problems. Given the extensive use of convex optimization in machine learning and statistics, gaining an understanding of these complexity-theoretic issues is important. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We introduce a new notion of discrepancy between functions, and use it to reduce problems of stochastic convex optimization to statistical parameter estimation, which can be lower bounded using information-theoretic methods. Using this approach, we improve upon known results and obtain tight minimax complexity estimates for various function classes.","1557-9654","","10.1109/TIT.2011.2182178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6142067","Computational learning theory;convex optimization;Fano's inequality;information-based complexity;minimax analysis;oracle complexity","Complexity theory;Convex functions;Stochastic processes;Optimization methods;Upper bound;Power capacitors","computational complexity;convex programming;learning (artificial intelligence);parameter estimation;statistical analysis;stochastic programming","oracle complexity;stochastic convex optimization;upper bounds;machine learning;statistical parameter estimation;information theory lower bound;minimax complexity estimation;function classes","","66","","25","IEEE","30 Jan 2012","","","IEEE","IEEE Journals"
"Speech recognition based chess system for visually challanged","B. Bharathi; S. Kavitha; D. S. Shashaank; S. Priyanka; V. Sriram","Department of CSE SSN College of Engineering Chennai, India; Department of CSE SSN College of Engineering Chennai, India; Department of CSE SSN College of Engineering Chennai, India; Department of CSE SSN College of Engineering Chennai, India; Department of CSE SSN College of Engineering Chennai, India","2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)","21 Jun 2018","2017","","","1797","1801","To overcome the obstacle of visual chess simulators, a system is proposed in which visually impaired individuals can practice by using only voice commands. In addition, this system will be powered using machine learning algorithms with the help of a publicly available repository of over five million games. This will make the user feel like he/she is playing against another human and not a machine. The existing chess systems use a variety of algorithms in order to choose its move. Most of these use tree traversals and the most common one is the min-max algorithm with alpha-beta pruning. Min-max algorithm finds the best move, and alpha-beta pruning prevents it from going into branches of the game tree that cannot yield a better result than previously traversed branches. Since the tree generated in a chess game is very deep and have a lot nodes, these algorithms examine the depth only to a certain amount. Generally, these algorithms are accompanied by an opening repository which bolsters the algorithm's efficiency. Since these algorithms are too strong for a visually impaired individual, a new approach is suggested to choose the computer's move. A publicly available repository of over five million chess games played by humans will be used to train the machine, initially. When the user makes his/her move, it will be converted into text and given as input to both the Minimax and the k-NN algorithms. The moves given as output by both these algorithms are compared using an evaluation function. The move with a higher score is chosen. The game continues till a decisive result is obtained.","","978-1-5386-1887-5","10.1109/ICECDS.2017.8389758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8389758","Speech Recognition;Hidden Markov Model;Minimax model;Alpha-beta pruning;k-nearest neighbour","Games;Speech recognition;Hidden Markov models;Feature extraction;Training;Data analysis;Engines","computer games;handicapped aids;human computer interaction;learning (artificial intelligence);minimax techniques;speech recognition;trees (mathematics)","chess game;visually impaired individual;k-NN algorithms;speech recognition based chess system;visual chess simulators;voice commands;min-max algorithm;alpha-beta pruning;game tree;machine learning algorithms;tree traversals","","","","9","","21 Jun 2018","","","IEEE","IEEE Conferences"
"Predicting biochemical interactions - human P450 2D6 enzyme inhibition","W. B. Langdon; S. J. Barrett; B. F. Buxton","Dept. of Comput. Sci., Univ. Coll. London, UK; NA; NA","The 2003 Congress on Evolutionary Computation, 2003. CEC '03.","24 May 2004","2003","2","","807","814 Vol.2","In silico screening of chemical libraries or virtual chemicals may reduce drug discovery and medicine optimisation lead times and increase the probability of success by directing search through chemical space. About a dozen intelligent pharmaceutical QSAR modelling techniques were used to predict IC50 concentration (three classes) of drug interaction with a cell wall enzyme (P450 CYC2D6). Genetic programming gave comprehensible cheminformatics models which generalised best. This was shown by a blind test on Glaxo Welcome molecules of machine learning knowledge nuggets mined from SmithKline Beecham compounds. Performance on similar chemicals (interpolation) and diverse chemicals (extrapolation) suggest generalisation is more difficult than avoiding over fitting. Two GP approaches, classification via regression using a multiobjective fitness measure and a direct winner takes all (WTA) or one versus all (OVA) classification, are described. Predictive rules were compressed by separate follow up GP runs seeded with the best program.","","0-7803-7804-0","10.1109/CEC.2003.1299750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1299750","","Humans;Biochemistry;Chemicals;Genetic programming;Drugs;Libraries;Lead time reduction;Learning systems;Pharmaceuticals;Predictive models","genetic algorithms;chemistry computing;search problems;regression analysis;learning (artificial intelligence);generalisation (artificial intelligence);drugs;enzymes;biochemistry;medical computing","silico screening;chemical libraries;drug discovery;medicine optimisation;chemical space;intelligent pharmaceutical QSAR modelling techniques;genetic programming;biochemical interactions prediction;human P450 2D6 enzyme inhibition;cheminformatics models;Glaxo Welcome molecules;machine learning knowledge;SmithKline Beecham compounds;GP;regression analysis","","3","","16","","24 May 2004","","","IEEE","IEEE Conferences"
"Real-Time Tracking of Packet-Pair Dispersion Nodes Using the Kernel-Density and Gaussian-Mixture Models","M. Hosseinpour; M. J. Tunnicliffe","Fac. of Comput., Inf. Syst. & Math., Kingston Univ., Kingston-on-Thames; Fac. of Comput., Inf. Syst. & Math., Kingston Univ., Kingston-on-Thames","2009 11th International Conference on Computer Modelling and Simulation","26 May 2009","2009","","","548","552","A brief simulation study of real-time packet dispersion mode-tracking using the Gaussian-mix model (originally devised for real-time background classification in moving pictures) and an adaptation of the kernel-density estimator is presented. The simulated environment consisted of two FIFO store-and-forward nodes where the probe packets interact with Poisson and Pareto-generated cross-traffic with a range of packet sizes. The two models produced broadly similar results, able to track node activity under the dynamically changing conditions associated with the Pareto cross-traffic. The Gaussian model sometimes replaced the primary mode with a double peak, which disappeared when some of the modelpsilas parameters were changed.","","978-1-4244-3771-9","10.1109/UKSIM.2009.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809823","Bandwidth Measurement;Machine Learning","Gaussian processes;Bandwidth;Mathematical model;Computational modeling;Real time systems;Probes;Particle measurements;Delay;Computer simulation;Dispersion","Gaussian processes;Pareto analysis;telecommunication network topology;telecommunication traffic","real-time tracking;packet-pair dispersion nodes;kernel-density model;Gaussian-mixture model;packet dispersion mode-tracking;real-time background classification;kernel-density estimator;FIFO store-and-forward nodes;probe packets;Poisson cross-traffic;Pareto-generated cross-traffic;node activity","","2","","11","","26 May 2009","","","IEEE","IEEE Conferences"
"Adversarially Robust Classification Based on GLRT","B. Puranik; U. Madhow; R. Pedarsani",University of California Santa Barbara; University of California Santa Barbara; University of California Santa Barbara,"ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","3785","3789","Machine learning models are vulnerable to adversarial attacks that can often cause misclassification by introducing small but well designed perturbations. In this paper, we explore, in the setting of classical composite hypothesis testing, a defense strategy based on the generalized likelihood ratio test (GLRT), which jointly estimates the class of interest and the adversarial perturbation. We evaluate the GLRT approach for the special case of binary hypothesis testing in white Gaussian noise under ℓ<inf>∞</inf> norm-bounded adversarial perturbations, a setting for which a minimax strategy optimizing for the worst-case attack is known. We show that the GLRT approach yields performance competitive with that of the minimax approach under the worst-case attack, while yielding a better robustness-accuracy trade-off under weaker attacks. The GLRT defense is applicable in multi-class settings and generalizes naturally to more complex models for which optimal minimax classifiers are not known.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413587","Army Research Office; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413587","Adversarial machine learning;hypothesis testing;robust classification","Perturbation methods;Gaussian noise;Conferences;Detectors;Machine learning;Signal processing;Data models","Gaussian noise;learning (artificial intelligence);minimax techniques;pattern classification;security of data","minimax approach;worst-case attack;weaker attacks;GLRT defense;multiclass settings;complex models;optimal minimax classifiers;robust classification;machine learning models;adversarial attacks;perturbations;classical composite hypothesis testing;defense strategy;generalized likelihood ratio test;adversarial perturbation;binary hypothesis testing;white Gaussian noise;minimax strategy","","","","18","","13 May 2021","","","IEEE","IEEE Conferences"
"Heuristic Edge Server Placement in Industrial Internet of Things and Cellular Networks","S. K. Kasi; M. K. Kasi; K. Ali; M. Raza; H. Afzal; A. Lasebae; B. Naeem; S. u. Islam; J. J. P. C. Rodrigues","Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science, Balochistan University of Information Technology, Engineering and Management Sciences, Quetta, Pakistan; Faculty of Science and Technology, Middlesex University London, London, U.K.; Department of Computer Science, Edge Hill University, Ormskirk, U.K.; Department of Computer Science, Balochistan University of Information Technology, Engineering and Management Sciences, Quetta, Pakistan; Department of Computer Science, Middlesex University London, London, U.K.; Department of Computer Science, Balochistan University of Information Technology, Engineering and Management Sciences, Quetta, Pakistan; Department of Computer Science, Institute of Space Technology, Islamabad, Pakistan; PPGEE, Federal University of Piauí, Teresina, Brazil","IEEE Internet of Things Journal","22 Jun 2021","2021","8","13","10308","10317","Rapid developments in industry 4.0, machine learning, and digital twins have introduced new latency, reliability, and processing restrictions in Industrial Internet of Things (IIoT) and mobile devices. However, using current information and communications technology (ICT), it is difficult to optimally provide services that require high computing power and low latency. To meet these requirements, mobile-edge computing is emerging as a ubiquitous computing paradigm that enables the use of network infrastructure components such as cluster heads/sink nodes in IIoT and cellular network base stations to provide local data storage and computation servers at the edge of the network. However, optimal location selection for edge servers within a network out of a very large number of possibilities, such as to balance workload and minimize access delay, is a challenging problem. In this article, the edge server placement problem is addressed within an existing network infrastructure obtained from Shanghai Telecom's base station data set that includes a significant amount of call data records and locations of actual base stations. The problem of edge server placement is formulated as a multiobjective constraint optimization problem that places edge servers strategically to balance between the workloads of edge servers and reduce access delay between the industrial control center/cellular base stations and edge servers. To search randomly through a large number of possible solutions and selecting those that are most descriptive of optimal solution can be a very time-consuming process, therefore, we apply the genetic algorithm and local search algorithms (hill climbing and simulated annealing) to find the best solution in the least number of solution space explorations. Experimental results are obtained to compare the performance of the genetic algorithm against the above-mentioned local search algorithms. The results show that the genetic algorithm can quickly search through the large solution space as compared to local search optimization algorithms to find an edge placement strategy that minimizes the cost function.","2327-4662","","10.1109/JIOT.2020.3041805","FCT/MCTES through national funds and when applicable cofunded EU funds(grant numbers:UIDB/50008/2020); Brazilian National Council for Scientific and Technological Development (CNPq)(grant numbers:309335/2017-5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274481","Data mining;edge server placement;genetic search;Industrial Internet of Things (IIoT);mobile-edge computing","Servers;Cloud computing;Optimization;Base stations;Genetic algorithms;Edge computing;Delays","cellular radio;genetic algorithms;industrial control;Internet;mobile computing;search problems;simulated annealing;telecommunication network reliability;telecommunication power management;ubiquitous computing","edge servers;local search optimization algorithms;edge placement strategy;heuristic edge server placement;cellular networks;high computing power;mobile-edge computing;ubiquitous computing paradigm;network infrastructure components;cellular network base stations;local data storage;computation servers;optimal location selection;edge server placement problem;existing network infrastructure;Shanghai Telecom's base station data;actual base stations;multiobjective constraint optimization problem","","4","","25","IEEE","1 Dec 2020","","","IEEE","IEEE Journals"
"MoGFT-I: A Multi-objective Optimization approach for the Cart and Pole control problem","R. Ishibashi; C. Lúcio Nascimento Júnior","Instituto Tecnológico de Aeronáutica, Division of Electronic Engineering, 12228-900 - São José dos Campos-SP, Brazil; Instituto Tecnológico de Aeronáutica, Division of Electronic Engineering, 12228-900 - São José dos Campos-SP, Brazil","2015 Annual IEEE Systems Conference (SysCon) Proceedings","4 Jun 2015","2015","","","235","242","In this article a set of well-known computational intelligence techniques such as Decision Trees, Fuzzy Logic, and Multi-objective Optimization Genetic Algorithm are combined to generate a novel hybrid method which is called MoGFT-I: Multi-objective Genetic Fuzzy Rule Based System supported by a Decision Tree with Improved Interpretability. The output of the proposed supervised learning method is a set of Mamdani-type fuzzy systems which are optimized and distributed along a Pareto curve by considering two conflicting attributes: accuracy and interpretability. The MoGFT-I method is then applied to the Cart and Pole control problem such that a set of feedback controller are designed to control this unstable nonlinear dynamical system.","","978-1-4799-5927-3","10.1109/SYSCON.2015.7116758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7116758","Multi-objective Optimization;Knowledge Extraction;Interpretability;Genetic Fuzzy Rule Based System;Fuzzy Controller;Pareto-optimal front","Pareto optimization;Mathematical model;Sociology;Decision trees;Genetic algorithms","control system synthesis;decision trees;feedback;fuzzy control;genetic algorithms;nonlinear dynamical systems;Pareto optimisation;pole assignment","multiobjective optimization approach;cart-and-pole control problem;computational intelligence techniques;decision trees;fuzzy logic;multiobjective optimization genetic algorithm;hybrid method;multiobjective genetic fuzzy rule-based system;interpretability improvement;supervised learning method;Mamdani-type fuzzy systems;Pareto curve;accuracy attribute;interpretability attribute;MoGFT-I method;feedback controller design;unstable nonlinear dynamical system control","","2","","16","","4 Jun 2015","","","IEEE","IEEE Conferences"
"Improving Robustness of DNNs against Common Corruptions via Gaussian Adversarial Training","C. Yi; H. Li; R. Wan; A. C. Kot","Nanyang Technological University,School of Electrical and Electronic Engineering,Singapore; Nanyang Technological University,School of Electrical and Electronic Engineering,Singapore; Nanyang Technological University,School of Electrical and Electronic Engineering,Singapore; Nanyang Technological University,School of Electrical and Electronic Engineering,Singapore","2020 IEEE International Conference on Visual Communications and Image Processing (VCIP)","29 Dec 2020","2020","","","17","20","Deep neural networks have demonstrated tremendous success in image classification, but their performance sharply degrades when evaluated on slightly different test data (e.g., data with corruptions). To address these issues, we propose a minimax approach to improve common corruption robustness of deep neural networks via Gaussian Adversarial Training. To be specific, we propose to train neural networks with adversarial examples where the perturbations are Gaussian-distributed. Our experiments show that our proposed GAT can improve neural networks' robustness to noise corruptions more than other baseline methods. It also outperforms the state-of-the-art method in improving the overall robustness to common corruptions.","2642-9357","978-1-7281-8068-7","10.1109/VCIP49819.2020.9301856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301856","Deep Learning;Robustness to Common Corruptions;Adversarial Training;Data Augmentation","Robustness;Perturbation methods;Training;Neural networks;Standards;Gaussian noise;Tensors","image classification;learning (artificial intelligence);minimax techniques;neural nets","common corruptions;deep neural networks;image classification;minimax approach;common corruption robustness;adversarial examples;noise corruptions;DNN;Gaussian adversarial training;GAT","","1","","23","","29 Dec 2020","","","IEEE","IEEE Conferences"
"Parallelization of <inline-formula><tex-math notation=""LaTeX"">$Top_{k}$</tex-math></inline-formula> Algorithm Through a New Hybrid Recommendation System for Big Data in Spark Cloud Computing Framework","K. El Handri; A. Idrissi","Intelligent Processing Systems Team, Computer Science Laboratory, Department of Computer Science, Faculty of Sciences, Mohammed V University, Rabat, Morocco; Intelligent Processing Systems Team, Computer Science Laboratory, Department of Computer Science, Faculty of Sciences, Mohammed V University, Rabat, Morocco","IEEE Systems Journal","9 Dec 2021","2021","15","4","4876","4886","In the era of big data, parallel <inline-formula><tex-math notation=""LaTeX"">$Top_{k}$</tex-math></inline-formula> query processing under information retrieval has received increasing attention from both the industry and academia. This query handling allows users to retrieve the most useful data objects in a set of choices. This problem is compounded by the use of <inline-formula><tex-math notation=""LaTeX"">$Top_{k}$</tex-math></inline-formula> in cases of multiple dimensions and extensive data analytics. In this article, we provide a novel parallel algorithm in a distributed recommender system based on the Apache Spark platform. The purpose of this approach was to implement the multicriteria decision aiding support and dominating query approach run by using matrix factorization and singular value decomposition (SVD)-based model as a sophisticated machine learning technique. Simultaneously, applying the resilient distributed datasets paradigm in cloud computing, which presents a favorable environment for big data management. Extensive experimental results in terms of accuracy, and scalability indicated the new algorithm’s advantage compared to other <inline-formula><tex-math notation=""LaTeX"">$Top_{k}$</tex-math></inline-formula> algorithms. Accordingly, our recommender system based on the conceived algorithm achieved high precision (62%–82%, depending on the data) to verify the profoundly positive effect of the use of the Spark framework and the SVD-based model while applying the commonly used evaluation metrics in the recommendation systems.","1937-9234","","10.1109/JSYST.2020.3019368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195509","Collaborative filtering (CF);Funk singular value decomposition (SVD);multiple criteria decision aiding (MCDA);Skyline;Spark; $Top_{k}$ ","Collaborationn;Big Data;Query processing;Parallel algorithms;Recommender systems;Machine learning algorithms;Machine learning;Filtering","Big Data;cloud computing;data analysis;data handling;data mining;information retrieval;learning (artificial intelligence);parallel algorithms;query processing;recommender systems;singular value decomposition","new hybrid recommendation system;Spark cloud computing framework;k query;information retrieval;query handling;useful data objects;multiple dimensions;extensive data analytics;parallel algorithm;distributed recommender system;Apache Spark platform;multicriteria decision aiding support;dominating query approach;singular value decomposition-based model;sophisticated machine learning technique;resilient distributed datasets paradigm;big data management;conceived algorithm;Spark framework;SVD-based model;recommendation systems;parallelization","","3","","50","IEEE","14 Sep 2020","","","IEEE","IEEE Journals"
"Study of Over-Sampling Methods Used in Distribution Transformer Connectivity Verification","Z. Tang; Y. Shen; L. Wan; H. Zhou; F. Yu; D. Qiu; W. Wang; X. Cao; T. Li","Electric power research institute State Grid Hubei electric power Co., Ltd,Wuhan,China; Electric power research institute State Grid Hubei electric power Co., Ltd,Wuhan,China; State Grid Hubei electric power Co., Ltd,Internet department,Wuhan,China; State Grid Hubei electric power Co., Ltd,Internet department,Wuhan,China; State Grid Hubei electric power Co., Ltd,Internet department,Wuhan,China; State Grid Hubei electric power Co., Ltd,Internet department,Wuhan,China; Huangshi power supply company State Grid Hubei electric power Co., Ltd,Huangshi,China; Electric power research institute State Grid Hubei electric power Co., Ltd,Wuhan,China; Jingzhou power supply company State Grid Hubei electric power Co., Ltd,Jingzhou,China","2020 IEEE 4th Conference on Energy Internet and Energy System Integration (EI2)","15 Feb 2021","2020","","","4179","4183","Data-driven method has been used to carry out distribution transformer connectivity verification. The imbalanced dataset always results in bad performance of machine learning algorithms. In order to solve this problem, two kinds of over-sampling methods have been studied in this paper. Voltage curves of 3967 distribution transformer which belong to 197 10kV feeders have been collected. The performance of over-sampling methods under different sampling rate has also been studied. Pareto optimality has been carried out in order to obtain the best sampling rate. Results show that with the increase of sampling rate, the value of true negative (TN) increase and the value of true positive (TP) and accuracy decrease. The performance of synthetic minority over-sampling technique (SMOTE) is a little better compared with simple copy method (SCM). When the lower limits of TN, TP and accuracy are set as 0.93, the best sampling rate of SCM is 17 and the values for SMOTE are 16, 17 and 18.","","978-1-7281-9606-0","10.1109/EI250167.2020.9347335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347335","distribution transformer connectivity;imbalance dataset;over-sampling;SMOTE;Pareto optimality","Machine learning algorithms;Conferences;System integration;Internet","learning (artificial intelligence);pattern classification;power engineering computing;power transformers;sampling methods","synthetic minority over-sampling technique;simple copy method;over-sampling methods used;distribution transformer connectivity verification;data-driven method;machine learning algorithms;sampling rate;true positive;voltage curves;Pareto optimality","","","","17","","15 Feb 2021","","","IEEE","IEEE Conferences"
"Anomaly recognition in bursty IP traffic models","J. Smieško; M. Kontšek; R. Hajtmanek","University of Žilina, Univerzitná 8215/1,Faculty of Management Science and Informatics,Žilina,01026; University of Žilina, Univerzitná 8215/1,Faculty of Management Science and Informatics,Žilina,01026; University of Žilina, Univerzitná 8215/1,Faculty of Management Science and Informatics,Žilina,01026","2021 19th International Conference on Emerging eLearning Technologies and Applications (ICETA)","9 Mar 2022","2021","","","351","358","In the first part of this article we deal with two models of IP traffic with bursty period, Poisson process and Pareto process. The paper deals with analysis of their probability structure and their comparison with each other. In the second part we deal with the use of one-parameter machine learning methods (autoregression coefficient and Hurst coefficient) for the recognition of anomalies in the traffic flow. We have created several scenarios for this task. These scenarios model changes of the observed flow structure. This article presents implementation of the Department of InfoComm Networks research, which focuses on computer security, into the curriculum of the master's study program Applied Network Engineering.","","978-1-6654-2102-7","10.1109/ICETA54173.2021.9726543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726543","IP traffic;detection;anomaly;DDoS attacks;autoregression coefficient;Hurst coefficient;bursty period;Poisson process;Pareto process","Electronic learning;Computational modeling;Machine learning;IP networks;Task analysis;Computer security","","","","","","17","","9 Mar 2022","","","IEEE","IEEE Conferences"
"Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine","W. HU; M. JIANG; X. Gao; K. C. TAN; Y. -m. Cheung","Department of Cognitive Science, Xiamen University, Fujian, 361005, China; Department of Cognitive Science, Xiamen University, Fujian, 361005, China; Software School of Xiamen University; Department of Computer Science, City University of Hong Kong; Department of Computer Science, Hong Kong Baptist University","2019 IEEE Congress on Evolutionary Computation (CEC)","8 Aug 2019","2019","","","2794","2799","The main feature of the Dynamic Multi-objective Optimization Problems (DMOPs) is that optimization objective functions will change with times or environments. One of the promising approaches for solving the DMOPs is reusing the obtained Pareto optimal set (POS) to train prediction models via machine learning approaches. In this paper, we train an Incremental Support Vector Machine (ISVM) classifier with the past POS, and then the solutions of the DMOP we want to solve at the next moment are filtered through the trained ISVM classifier. A high-quality initial population will be generated by the ISVM classifier, and a variety of different types of population-based dynamic multi-objective optimization algorithms can benefit from the population. To verify this idea, we incorporate the proposed approach into three evolutionary algorithms, the multi-objective particle swarm optimization(MOPSO), Nondominated Sorting Genetic Algorithm II (NSGA-II), and the Regularity Model-based multi-objective estimation of distribution algorithm(RE-MEDA). We employ experiments to test these algorithms, and experimental results show the effectiveness.","","978-1-7281-2153-6","10.1109/CEC.2019.8790005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790005","Dynamic Multi-objective Optimization Problems;Incremental Support Vector Machine;Pareto Optimal Set","Support vector machines;Heuristic algorithms;Sociology;Pareto optimization;Predictive models","evolutionary computation;genetic algorithms;learning (artificial intelligence);Pareto optimisation;particle swarm optimisation;support vector machines","DMOP;optimization objective functions;Pareto optimal set;population-based dynamic multiobjective optimization algorithms;machine learning;regularity model-based multiobjective estimation;incremental support vector machine classifier;ISVM classifier","","4","","30","","8 Aug 2019","","","IEEE","IEEE Conferences"
"A hybrid evolutionary approach for optimal fuzzy classifier design","A. S. Karthik Kannan; P. Thanapal","Department of Information Technology Mepco Schlenk Engineering College, Sivakasi, India; SITE, VIT University, Vellore, Tamil Nadu, India","2010 INTERNATIONAL CONFERENCE ON COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES","17 Dec 2010","2010","","","835","840","One of the important issues in the design of fuzzy classifier is the formation of fuzzy if-then rules and the membership functions. This paper presents a Niched Pareto Genetic Algorithm (NPGA) approach to obtain the optimal rule-set and the membership function. To develop the fuzzy system the rule set and the membership functions are encoded into the chromosome and evolved simultaneously using NPGA. The performance of the proposed approach is demonstrated through development of fuzzy classifier for Iris data available in the UCI machine learning repository. From the simulation study, it is found that that NPGA produces a fuzzy classifier which has minimum number of rules and high classification accuracy compared with the existing methods.","","978-1-4244-7770-8","10.1109/ICCCCT.2010.5670725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670725","fuzzy classifier;if-then-rules;membership function;Niched Pareto Genetic Algorithm","Classification algorithms;Iris;Input variables;Fuzzy systems;Fuzzy logic;Training;Gallium","fuzzy set theory;fuzzy systems;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification","hybrid evolutionary approach;optimal fuzzy classifier design;Niched Pareto genetic algorithm;membership function;fuzzy system;iris data;UCI machine learning repository","","2","","11","","17 Dec 2010","","","IEEE","IEEE Conferences"
"Adaptive Modulation Using Multi-Objective Reinforcement Learning for LEO Satellites","F. Pasquevich; A. F. Ramirez; J. M. Ayarde; G. C. Briones","National University of Cordoba,National Space Activities, Commission – CONAE,Cordoba,Argentina; National University of Cordoba,National Scientific and Technical, Research Council – CONICET,Cordoba,Argentina; National University of Cordoba,Science and Technology, Secretary – SECyT,Cordoba,Argentina; National University of Cordoba,National Scientific and Technical, Research Council – CONICET,Cordoba,Argentina","2021 IEEE Cognitive Communications for Aerospace Applications Workshop (CCAAW)","6 Sep 2021","2021","","","1","6","In this paper, an emerging Machine Learning technique, named Multi-Objective Reinforcement Learning (MORL), is applied and analyzed aiming to achieve a two-fold optimization in a Satellite-To-Ground communication. The objectives pursued in this work using MORL are to minimize the Bit Error Rate and keep simultaneously the best performance in terms of the maximum bit rate transmission. The scenario under test consists of a Low-Earth Orbit satellite moving in a circular orbit while establishing a line-of-sight communication with a Ground Station. Two approaches are evaluated, the Weighted Sum and the Thresholded Lexicographic Q-Learning. We show that these two approaches can not find all the solutions. To alleviate this situation, a novel proposal is considered based on an inverse scalarization function that allows to select any solution from the Pareto front. We show that the proposed algorithm is able to implement a suitable operation for many different digital modulation schemes to obtain the maximum throughput.","","978-1-6654-1258-2","10.1109/CCAAW50069.2021.9527292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527292","MORL;LEO;ML;Pareto","Satellites;Digital modulation;Conferences;Bit rate;Low earth orbit satellites;Reinforcement learning;Throughput","adaptive modulation;artificial satellites;celestial mechanics;error statistics;learning (artificial intelligence);minimisation;satellite ground stations;telecommunication computing","Pareto front;inverse scalarization function;Thresholded Lexicographic Q-Learning;weighted sum;ground station;line-of-sight communication;circular orbit;low-earth orbit satellite;maximum bit rate transmission;bit error rate minimisation;satellite-to-ground communication;two-fold optimization;MORL;multiobjective reinforcement learning;machine learning technique;LEO satellites;adaptive modulation;digital modulation schemes","","","","13","","6 Sep 2021","","","IEEE","IEEE Conferences"
"Early Prediction of Sepsis from Clinical Data Using Artificial Intelligence","R. M. Demirer; O. Demirer","Industrial Engineering Department, Uskudar University, İstanbul, Turkey; Electrical-Electronic Engineering Department, Arel University, Istanbul, Turkey","2019 Scientific Meeting on Electrical-Electronics & Biomedical Engineering and Computer Science (EBBT)","20 Jun 2019","2019","","","1","4","Sepsis is a major cause of death in the world. World Health Organization estimates 30 million people developing sepsis and 6 million people die from sepsis each year; an estimated 4.2 million newborns and children are affected. The mortality rate is highest in septic shock in poor and developing countries. Early prediction of sepsis is critical for improving sepsis outcomes. The late prediction of sepsis in non-sepsis patients is a challenging problem. The aim of this study is to develop an artificial intelligence-based early warning and therapeutic decision support system which reduces sepsis-associated hospital mortality. We propose two compatible Boolean switchable Partially Observable Markov Decision Processes (POMDP) under a general risk-sensitive optimization criterion with finite time horizon. It is based on Spectral analysis of unevenly sampled (missing) observations with Demographics, Vital Signs, and Laboratory values for the patient. The policy is a common mixture of sepsis and non-sepsis beliefs on own utility functions which favors to achieve Pareto Optimality from this high dimensional belief space.","","978-1-7281-1013-4","10.1109/EBBT.2019.8741834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741834","Sepsis;Artificial Intelligence;Decision Support;Lomb-Scargle Periyodogram;POMDP;Deep Learning","Physiology;Blood;Markov processes;Hospitals;Deep learning;Antibiotics","artificial intelligence;diseases;hospitals;Markov processes;medical diagnostic computing;paediatrics;patient diagnosis;patient treatment","children;sepsis outcomes;nonsepsis patients;artificial intelligence-based early warning;sepsis-associated hospital mortality;partially observable Markov decision process;POMDP;general risk-sensitive optimization criterion;finite time horizon;spectral analysis;Pareto optimality","","1","","8","","20 Jun 2019","","","IEEE","IEEE Conferences"
"Signal Recovery on Graphs: Fundamental Limits of Sampling Strategies","S. Chen; R. Varma; A. Singh; J. Kovačević","Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Machine Learning, Carnegie Mellon University, Pittsburgh, PA, USA; Departments of Electrical and Computer Engineering and Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA","IEEE Transactions on Signal and Information Processing over Networks","20 May 2017","2016","2","4","539","554","This paper builds theoretical foundations for the recovery of a newly proposed class of smooth graph signals, approximately bandlimited graph signals, under three sampling strategies: uniform sampling, experimentally designed sampling, and active sampling. We then state minimax lower bounds on the maximum risk for the approximately bandlimited class under these three sampling strategies and show that active sampling cannot fundamentally outperform experimentally designed sampling. We propose a recovery strategy to compare uniform sampling with experimentally designed sampling. As the proposed recovery strategy lends itself well to statistical analysis, we derive the exact mean square error for each sampling strategy. To study convergence rates, we introduce two types of graphs and find that 1) the proposed recovery strategy achieves the optimal rates; and 2) the experimentally designed sampling fundamentally outperforms uniform sampling for Type-2 class of graphs. To validate our proposed recovery strategy, we test it on five specific graphs: a ring graph with k nearest neighbors, an Erdos-Rényi graph, a random geometric graph, a small-world graph, and a power-law graph and find that experimental results match the proposed theory well. This paper also presents a comprehensive explanation for when and why sampling for semi-supervised learning with graphs works.","2373-776X","","10.1109/TSIPN.2016.2614903","National Science Foundation(grant numbers:1130616,1421919); University Transportation Center(grant numbers:DTRT12-GUTC11); US Department of Transportation; sCMU Carnegie Institute of Technology Infrastructure Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7581102","Active sampling;experimentally designed sampling;semi-supervised learning;signal processing on graphs;signal recovery","Signal processing;Fourier transforms;Eigenvalues and eigenfunctions;Convergence;Semisupervised learning;Information processing;Electronic mail","graph theory;graphs;learning (artificial intelligence)","bandlimited graph signals;uniform sampling strategies;state minimax lower bounds;statistical analysis;optimal rates;Type-2 class;k nearest neighbors;Erdos-Renyi graph;random geometric graph;small-world graph;power-law graph;semisupervised learning;smooth graph signals;active sampling strategies;graphs;signal recovery strategy","","53","","64","IEEE","3 Oct 2016","","","IEEE","IEEE Journals"
"Neural Signature of Efficiency Relations","S. Basterrech; K. Ohnishi; M. Köppen","Nat. Supercomput. Center, VSB Tech. Univ. of Ostrava, Ostrava, Czech Republic; Comput. Sci. & Syst. Eng. Dept., Kyushu Inst. of Technol., Iizuka, Japan; Comput. Sci. & Syst. Eng. Dept., Kyushu Inst. of Technol., Iizuka, Japan","2015 IEEE International Conference on Systems, Man, and Cybernetics","14 Jan 2016","2015","","","2090","2095","In last years -- especially due to the development of telecommunications -- fairness modelling has received a strong attention. This article presents an approach for categorizing unknown relations according to their ""closeness"" to known relations. We consider as reference relations, the well-known: Pareto dominance, Leximin and Proportional fairness relation. We simulate each relation generating a learning dataset that is used for learning Neural Networks. The learning performance evaluation is based in several metrics, which are used as a ""signature"" of each relation. Besides, we develop a new function that gives an estimation about the ""closeness"" between relations. This concept permits us to categorise a new dataset (generated by an unknown relation) according its ""closeness"" with the Pareto dominance, Leximin and Proportional fairness relations know relations. Our experimental results are coherent with the alpha fairness concept.","","978-1-4799-8697-2","10.1109/SMC.2015.365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379497","Fairness;Maxmin Fairness;Priority Fairness;Neural Networks;Supervised Learning","Resource management;Neurons;Computational modeling;Neural networks;Economics;Training;Numerical models","learning (artificial intelligence);neural nets","neural signature;efficiency relations;fairness modelling;Pareto dominance;leximin fairness relation;proportional fairness relation;learning dataset;neural network learning;learning performance evaluation;alpha fairness concept","","","","20","","14 Jan 2016","","","IEEE","IEEE Conferences"
"Simultaneously Structured Models With Application to Sparse and Low-Rank Matrices","S. Oymak; A. Jalali; M. Fazel; Y. C. Eldar; B. Hassibi","Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Department of Electrical Engineering, Technion—Israel Institute of Technology, Haifa, Israel; Department of Electrical Engineering, California Institute of Technology, Pasadena, CA, USA","IEEE Transactions on Information Theory","17 Apr 2015","2015","61","5","2886","2908","Recovering structured models (e.g., sparse or group-sparse vectors, low-rank matrices) given a few linear observations have been well-studied recently. In various applications in signal processing and machine learning, the model of interest is structured in several ways, for example, a matrix that is simultaneously sparse and low rank. Often norms that promote the individual structures are known, and allow for recovery using an order-wise optimal number of measurements (e.g., 11 norm for sparsity, nuclear norm for matrix rank). Hence, it is reasonable to minimize a combination of such norms. We show that, surprisingly, using multiobjective optimization with these norms can do no better, orderwise, than exploiting only one of the structures, thus revealing a fundamental limitation in sample complexity. This result suggests that to fully exploit the multiple structures, we need an entirely new convex relaxation. Further, specializing our results to the case of sparse and low-rank matrices, we show that a nonconvex formulation recovers the model from very few measurements (on the order of the degrees of freedom), whereas the convex problem combining the 11 and nuclear norms requires many more measurements, illustrating a gap between the performance of the convex and nonconvex recovery problems. Our framework applies to arbitrary structure-inducing norms as well as to a wide range of measurement ensembles. This allows us to give sample complexity bounds for problems such as sparse phase retrieval and low-rank tensor completion.","1557-9654","","10.1109/TIT.2015.2401574","National Science Foundation(grant numbers:ECCS-0847077,CCF-1409836); Israel Science Foundation(grant numbers:170/10); SRC; Intel Collaborative Research Institute for Computational Intelligence; National Science Foundation(grant numbers:CNS-0932428,CCF-1018927,CCF-1423663,CCF-1409204); Office of Naval Research through the MURI(grant numbers:N00014-08-0747); Qualcomm Inc., San Diego, CA, USA; King Abdulaziz University, Jeddah, Saudi Arabia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7036090","compressed sensing;convex relaxation;regularization;sample complexity;Compressed sensing;convex relaxation;regularization;sample complexity","Sparse matrices;Vectors;Complexity theory;Tensile stress;Symmetric matrices;Nuclear measurements;Matrix decomposition","compressed sensing;matrix algebra;optimisation","simultaneously structured model;low-rank matrices;sparse matrices;recovering structured models;multiobjective optimization;order-wise optimal number;sample complexity;nonconvex recovery problem;convex recovery problem;sparse phase retrieval;low-rank tensor completion","","119","","69","IEEE","9 Feb 2015","","","IEEE","IEEE Journals"
"Multi-Objective Optimization for Size and Resilience of Spiking Neural Networks","M. Dimovska; T. Johnston; C. D. Schuman; J. P. Mitchell; T. E. Potok","University of Minnesota,Department of Electrical and Computer Engineering,Minneapolis,USA; Oak Ridge National Laboratory,Oak Ridge,USA; Oak Ridge National Laboratory,Oak Ridge,USA; Oak Ridge National Laboratory,Oak Ridge,USA; Oak Ridge National Laboratory,Oak Ridge,USA","2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","13 Feb 2020","2019","","","0433","0439","Inspired by the connectivity mechanisms in the brain, neuromorphic computing architectures model Spiking Neural Networks (SNNs) in silicon. As such, neuromorphic architectures are designed and developed with the goal of having small, low power chips that can perform control and machine learning tasks. However, the power consumption of the developed hardware can greatly depend on the size of the network that is being evaluated on the chip. Furthermore, the accuracy of a trained SNN that is evaluated on chip can change due to voltage and current variations in the hardware that perturb the learned weights of the network. While efforts are made on the hardware side to minimize those perturbations, a software based strategy to make the deployed networks more resilient can help further alleviate that issue. In this work, we study Spiking Neural Networks in two neuromorphic architecture implementations with the goal of decreasing their size, while at the same time increasing their resiliency to hardware faults. We leverage an evolutionary algorithm to train the SNNs and propose a multiobjective fitness function to optimize the size and resiliency of the SNN. We demonstrate that this strategy leads to well-performing, small-sized networks that are more resilient to hardware faults.","","978-1-7281-3885-5","10.1109/UEMCON47517.2019.8992983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8992983","Neuromorphic Computing;Spiking Neural Networks;Multi-objective;Fault Tolerance;Evolutionary Optimization","","evolutionary computation;genetic algorithms;learning (artificial intelligence);neural chips;neural nets","multiobjective optimization;connectivity mechanisms;neuromorphic computing architectures model;SNN;neuromorphic architectures;low power chips;machine learning tasks;power consumption;neuromorphic architecture implementations;hardware faults;small-sized networks;neural networks","","5","","29","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Likelihood-Based Semi-Supervised Model Selection With Applications to Speech Processing","C. M. White; S. P. Khudanpur; P. J. Wolfe","Human Language Technology Center of Excellence (HLT-COE), Johns Hopkins University; Center for Language and Speech Processing, Johns Hopkins University, Baltimore; Statistics and Information Sciences Laboratory, Harvard University","IEEE Journal of Selected Topics in Signal Processing","15 Nov 2010","2010","4","6","1016","1026","In conventional supervised pattern recognition tasks, model selection is typically accomplished by minimizing the classification error rate on a set of so-called development data, subject to ground-truth labeling by human experts or some other means. In the context of speech processing systems and other large-scale practical applications, however, such labeled development data are typically costly and difficult to obtain. This paper investigates an alternative semi-supervised framework for likelihood-based model selection that leverages unlabeled data by using trained classifiers representing each model to automatically generate putative labels. The errors that result from this automatic labeling are shown to be amenable to results from robust statistics, which in turn provide for minimax-optimal censored likelihood ratio tests that recover the nonparametric sign test as a limiting case. This approach is then validated experimentally using a state-of-the-art automatic speech recognition system to select between candidate word pronunciations using unlabeled speech data that only potentially contain instances of the words under test. Results provide supporting evidence for the utility of this approach, and suggest that it may also find use in other applications of machine learning.","1941-0484","","10.1109/JSTSP.2010.2076050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5575383","Likelihood ratio tests;pronunciation modeling;robust statistics;semi-supervised learning;sign test;speech recognition;spoken term detection","Data models;Speech recognition;Speech processing;Hidden Markov models;Semisupervised learning;Training data;Labeling","learning (artificial intelligence);minimax techniques;pattern classification;speech processing;speech recognition","likelihood-based semisupervised model selection;speech processing;supervised pattern recognition;ground-truth labeling;labeled development data;classifier;automatic labeling;minimax-optimal censored likelihood ratio test;automatic speech recognition system;word pronunciation;unlabeled speech data;machine learning","","","","28","IEEE","16 Sep 2010","","","IEEE","IEEE Journals"
"Learning Variable Importance to Guide Recombination on Many-Objective Optimization","M. Sagawa; H. Aguirre; F. Daolio; A. Liefooghe; B. Derbel; S. Verel; K. Tanaka","Shinshu Univ., Nagano, Japan; Shinshu Univ., Nagano, Japan; Univ. of Stirling, Stirling, UK; Inria Lille-Nord Eur., Univ. Lille, Lille, France; Inria Lille-Nord Eur., Univ. Lille, Lille, France; LISIC, Univ. Littoral Cote d'Opale, Wimereux, France; Shinshu Univ., Nagano, Japan","2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)","16 Nov 2017","2017","","","874","879","There are numerous many-objective real-world problems in various application domains for which it is difficult or time-consuming to derive Pareto optimal solutions. In an evolutionary algorithm, variation operators such as recombination and mutation are extremely important to obtain an effective solution search. In this paper, we study a machine learning-enhanced recombination that incorporates an intelligent variable selection method. The method is based on the importance of variables with respect to convergence to the Pareto front. We verify the performance of the enhanced recombination on benchmark test problems with three or more objectives using the many-objective evolutionary algorithm AϵSϵH as a baseline algorithm. Results show that variable importance can enhance the performance of many-objective evolutionary algorithms.","","978-1-5386-0621-6","10.1109/IIAI-AAI.2017.158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113366","Multi-objective optimization;Many-objective optimization;Evolutionary algorithm;Machine learning;Random forest;Variable importance","Convergence;Vegetation;Optimization;Evolutionary computation;Testing;Sociology;Statistics","evolutionary computation;learning (artificial intelligence);mathematics computing;Pareto optimisation;search problems","benchmark test problems;many-objective evolutionary algorithm;guide recombination;many-objective optimization;variation operators;effective solution search;intelligent variable selection method;Pareto front;variable importance learning;many-objective real-world problems;mutation operators;machine learning-enhanced recombination","","","","17","","16 Nov 2017","","","IEEE","IEEE Conferences"
"Analytics of Heterogeneous Breast Cancer Data Using Neuroevolution","B. Abdikenov; Z. Iklassov; A. Sharipov; S. Hussain; P. K. Jamwal","Electrical and Computer Engineering Department, Nazarbayev University, Astana, Kazakhstan; Electrical and Computer Engineering Department, Nazarbayev University, Astana, Kazakhstan; Electrical and Computer Engineering Department, Nazarbayev University, Astana, Kazakhstan; Human Centred Technology Research Centre, Faculty of Science and Technology, University of Canberra, Canberra, ACT, Australia; Electrical and Computer Engineering Department, Nazarbayev University, Astana, Kazakhstan","IEEE Access","17 Feb 2019","2019","7","","18050","18060","Breast cancer prognostic modeling is difficult since it is governed by many diverse factors. Given the low median survival and large scale breast cancer data, which comes from high throughput technology, the accurate and reliable prognosis of breast cancer is becoming increasingly difficult. While accurate and timely prognosis may save many patients from going through painful and expensive treatments, it may also help oncologists in managing the disease more efficiently and effectively. Data analytics augmented by machine-learning algorithms have been proposed in past for breast cancer prognosis; and however, most of these could not perform well owing to the heterogeneous nature of available data and model interpretability related issues. A robust prognostic modeling approach is proposed here whereby a Pareto optimal set of deep neural networks (DNNs) exhibiting equally good performance metrics is obtained. The set of DNNs is initialized and their hyperparameters are optimized using the evolutionary algorithm, NSGAIII. The final DNN model is selected from the Pareto optimal set of many DNNs using a fuzzy inferencing approach. Contrary to using DNNs as the black box, the proposed scheme allows understanding how various performance metrics (such as accuracy, sensitivity, F1, and so on) change with changes in hyper-parameters. This enhanced interpretability can be further used to improve or modify the behavior of DNNs. The heterogeneous breast cancer database requires preprocessing for better interpretation of categorical variables in order to improve prognosis from classifiers. Furthermore, we propose to use a neural network-based entity-embedding method for categorical features with high cardinality. This approach can provide a vector representation of categorical features in multidimensional space with enhanced interpretability. It is shown with evidence that DNNs optimized using evolutionary algorithms exhibit improved performance over other classifiers mentioned in this paper.","2169-3536","","10.1109/ACCESS.2019.2897078","Faculty Development Competitive Research Grants, Nazarbayev University(grant numbers:090118FD5322); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632897","Breast cancer prognostic modelling;entity embedding;deep learning networks;evolutionary algorithms;fuzzy inferencing","Breast cancer;Databases;Prognostics and health management;Evolutionary computation;Measurement;Artificial neural networks","cancer;data analysis;evolutionary computation;feature extraction;fuzzy reasoning;learning (artificial intelligence);medical diagnostic computing;neural nets;Pareto optimisation;patient diagnosis;pattern classification","breast cancer prognostic modeling;low median survival;painful treatments;expensive treatments;machine-learning algorithms;Pareto optimal set;evolutionary algorithm;fuzzy inferencing approach;neural network-based entity-embedding method;categorical features;deep neural networks;DNN model;heterogeneous breast cancer data analytics;neuroevolution;classifiers","","11","","58","OAPA","1 Feb 2019","","","IEEE","IEEE Journals"
"Mimicking the Human Approach in the Game of Hive","D. Kampert; A. -L. Varbanescu; M. Müller-Brockhausen; A. Plaat","University of Amsterdam,The Netherlands; University of Amsterdam,The Netherlands; Leiden University,The Netherlands; Leiden University,The Netherlands","2021 IEEE Symposium Series on Computational Intelligence (SSCI)","24 Jan 2022","2021","","","1","8","While Deep Blue and AlphaGo make it seem like board games have been solved, there are still plenty of games for which no good game playing program exists. Hive is such a game. It is, combinatorically, of similar complexity as chess or Go, yet the rules of the game are such that current methods can barely beat a randomly playing agent. A major bottleneck for progress is the high branching factor of the game. We apply state of the art methods for which we develop new heuristics that are based on human domain-knowledge, attempting to improve upon the current dire state of Hive agents. Our methods have improved playing strength compared to the state of the art, although our AI still fails against actual Humans. We also find that, while in most board games, brute force or deep learning approaches work best, in Hive, an approach based on mimicking human knowledge outperforms these other approaches, including Monte Carlo Tree Search or Deep Reinforcement Learning. Future work will show if this anomalous situation is inherent to the game.","","978-1-7281-9048-8","10.1109/SSCI50451.2021.9659999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659999","heuristic;the game Hive;game-playing agents;artificial-intelligence (AI);minimax;Monte-Carlo Tree Search (MCTS)","Deep learning;Monte Carlo methods;Force;Games;Transforms;Reinforcement learning;Complexity theory","","","","","","27","","24 Jan 2022","","","IEEE","IEEE Conferences"
"Network Intrusion Detection Using Multi-Criteria PROAFTN Classification","F. N. Al-Obeidat; E. M. El-Alfy","Fac. of Comput. Sci., Univ. of New Brunswick, Fredericton, NB, Canada; Coll. of Comput. Sci. & Eng., King Fahd Univ. of Pet. & Miner., Dhahran, Saudi Arabia","2014 International Conference on Information Science & Applications (ICISA)","8 Jul 2014","2014","","","1","5","Network intrusion is recognized as a chronic and recurring problem. Hacking techniques continually change and several countermeasure methods have been suggested in the literature including statistical and machine learning approaches. However, no single solution can be claimed as a rule of thumb for the wide spectrum of attacks. In this paper, a novel methodology is proposed for network intrusion detection based on the multicriteria PROAFTN classification. The algorithm is evaluated and compared on a publicly available and widely used dataset. The results in this paper show that the proposed algorithm is promising in detecting various types of intrusions with high classification accuracy.","2162-9048","978-1-4799-4441-5","10.1109/ICISA.2014.6847436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6847436","","Intrusion detection;Prototypes;Accuracy;Support vector machines;Computers;Decision making;Educational institutions","computer crime;learning (artificial intelligence);statistical analysis","network intrusion detection;multicriteria PROAFTN classification;hacking techniques;statistical approach;machine learning approach","","1","","25","","8 Jul 2014","","","IEEE","IEEE Conferences"
"Improving Dependability of Neuromorphic Computing With Non-Volatile Memory","S. Song; A. Das; N. Kandasamy",Drexel University; Drexel University; Drexel University,"2020 16th European Dependable Computing Conference (EDCC)","23 Oct 2020","2020","","","17","24","As process technology continues to scale aggressively, circuit aging in a neuromorphic hardware due to negative bias temperature instability (NBTI) and time-dependent dielectric breakdown (TDDB) is becoming a critical reliability issue and is expected to proliferate when using non-volatile memory (NVM) for synaptic storage. This is because NVM devices require high voltages and currents to access their synaptic weights, which further accelerate the circuit aging in neuromorphic hardware. Current methods for qualifying reliability are overly conservative, since they estimate circuit aging considering worst-case operating conditions and unnecessarily constrain performance. This paper proposes RENEU, a reliability-oriented approach to map machine learning applications to neuromorphic hardware, with the aim of improving system-wide reliability, without compromising key performance metrics such as execution time of these applications on the hardware. Fundamental to RENEU is a novel formulation of the aging of CMOS-based circuits in a neuromorphic hardware considering different failure mechanisms. Using this formulation, RENEU develops a system- wide reliability model which can be used inside a design-space exploration framework involving the mapping of neurons and synapses to the hardware. To this end, RENEU uses an instance of Particle Swarm Optimization (PSO) to generate mappings that are Pareto-optimal in terms of performance and reliability. We evaluate RENEU using different machine learning applications on a state-of-the-art neuromorphic hardware with NVM synapses. Our results demonstrate an average 38% reduction in circuit aging, leading to an average 18% improvement in the lifetime of the hardware compared to current practices. RENEU only introduces a marginal performance overhead of 5% compared to a performance-oriented state-of-the-art.","2641-810X","978-1-7281-8936-9","10.1109/EDCC51268.2020.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237025","Neuromorphic Computing;Spiking Neural Network (SNN);Negative Bias Temperature Instability (NBTI);Time Dependent Dielectric Breakdown (TDDB);Hot Carrier Injection (HCI);Dependability;Machine Learning;Particle Swarm Optimization (PSO)","Hardware;Aging;Reliability;Integrated circuit reliability;Nonvolatile memory;Thermal variables control;Neurons","ageing;CMOS memory circuits;electric breakdown;integrated circuit reliability;learning (artificial intelligence);negative bias temperature instability;neuromorphic engineering;Pareto optimisation;particle swarm optimisation;random-access storage","TDDB;time-dependent dielectric breakdown;NBTI;negative bias temperature instability;PSO;particle swarm optimization;nonvolatile memory;neuromorphic computing;neuromorphic hardware;machine learning applications;system- wide reliability model;CMOS-based circuits;RENEU;map machine learning applications","","9","","42","","23 Oct 2020","","","IEEE","IEEE Conferences"
"APENAS: An Asynchronous Parallel Evolution Based Multi-objective Neural Architecture Search","M. Hu; L. Liu; W. Wang; Y. Liu","School of Data Science and Engineering, East China Normal University,Shanghai,China; School of Data Science and Engineering, East China Normal University,Shanghai,China; School of Data Science and Engineering, East China Normal University,Shanghai,China; School of Data Science and Engineering, East China Normal University,Shanghai,China","2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","4 Jun 2021","2020","","","153","159","Machine learning is widely used in pattern classification, image processing and speech recognition. Neural architecture search (NAS) could reduce the dependence of human experts on machine learning effectively. Due to the high complexity of NAS, the tradeoff between time consumption and classification accuracy is vital. This paper presents APENAS, an asynchronous parallel evolution based multi-objective neural architecture search, using the classification accuracy and the number of parameters as objectives, encoding the network architectures as individuals. To make full use of computing resource, we propose a multi-generation undifferentiated fusion scheme to achieve asynchronous parallel evolution on multiple GPUs or CPUs, which speeds up the process of NAS. Accordingly, we propose an election pool and a buffer pool for two-layer filtration of individuals. The individuals are sorted in the election pool by non-dominated sorting and filtered in the buffer pool by the roulette algorithm to improve the elitism of the Pareto front. APENAS is evaluated on the CIFAR-10 and CIFAR-100 datasets [25]. The experimental results demonstrate that APENAS achieves 90.05% accuracy on CIFAR-10 with only 0.07 million parameters, which is comparable to state of the art. Especially, APENAS has high parallel scalability, achieving 92.5% parallel efficiency on 64 nodes.","","978-1-6654-1485-2","10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00045","National Key Research and Development Program of China(grant numbers:2020YFA0607902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443883","automated machine learning;neural architecture search;multi-objective;asynchronous parallel evolution","Scalability;Voting;Pattern classification;Machine learning;Computer architecture;Speech recognition;Network architecture","genetic algorithms;image classification;learning (artificial intelligence);neural nets;Pareto optimisation;pattern classification;sorting;speech recognition","machine learning;pattern classification;image processing;speech recognition;NAS;classification accuracy;APENAS;asynchronous parallel evolution;multiobjective neural architecture search;network architectures;multigeneration undifferentiated fusion scheme;election pool;buffer pool","","1","","26","","4 Jun 2021","","","IEEE","IEEE Conferences"
"The Use of NSGA - II for Optimal Placement and Management of Renewable Energy Sources When Considering Network Uncertainty and Fault Current Limiters","A. A. Farahani; S. H. H. Sadeghi","Amirkabir University of Technology,Electrical Engineering Department,Tehran,Iran; Amirkabir University of Technology,Electrical Engineering Department,Tehran,Iran","2021 29th Iranian Conference on Electrical Engineering (ICEE)","4 Oct 2021","2021","","","437","442","Due to the abundant benefits of renewable energy sources (RESs), their participation in distribution networks is booming. However, they could have adverse effects on the protection coordination schemes. This paper proposes a nondominated sorting genetic algorithm (NSGA-II) that is a multiobjective optimization procedure to obtain the best locations and sizes of renewable energy sources (RESs) with fault current limiters (FCLs), reducing the short-circuit level of buses. The support vector regression, a supervised time series prediction approach in machine learning, is introduced to consider the uncertainty of load demands, network bid changes, and the generated powers of some RESs based on probabilistic states. The efficiency of the proposed procedure is established on the IEEE 33-bus test network.","2642-9527","978-1-6654-3365-5","10.1109/ICEE52715.2021.9544336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544336","Renewable energy sources;network uncertainty;support vector regression;multi-objective optimization;fault current limiters","Support vector machines;Renewable energy sources;Uncertainty;Simulation;Time series analysis;Machine learning;Distribution networks","distributed power generation;distribution networks;genetic algorithms;optimisation;renewable energy sources;support vector machines;time series","NSGA - II;optimal placement;renewable energy sources;considering network uncertainty;fault current limiters;RESs;distribution networks;nondominated sorting genetic algorithm;NSGA-II;multiobjective optimization procedure;network bid changes","","","","21","","4 Oct 2021","","","IEEE","IEEE Conferences"
"Many-objective feature selection for motor imagery EEG signals using differential evolution and support vector machine","M. Pal; S. Bandyopadhyay","Machine Intelligence Unit, Indian Statistical Institute, 203, B. T. Road, Kolkata - 700108, India; Machine Intelligence Unit, Indian Statistical Institute, 203, B. T. Road, Kolkata - 700108, India","2016 International Conference on Microelectronics, Computing and Communications (MicroCom)","28 Jul 2016","2016","","","1","6","Processing of the movement related task under planning by artificial means provides a means to those people whose natural modality of performing the task is bottlenecked by physical disability or neuro-motor disorders. Electroencephalography (EEG) based Brain-Computer Interfacing (BCI) systems can be defined to be a non-muscular pathway to operate rehabilitative devices using motor imagery signals captured from the motor activation areas in the brain. Supervised learning can help in prediction of motor imagery actions by processing raw EEG signals. However, dimension of the feature space plays a crucial role in this process. Large dimensional features not only increase the computational complexity but also the presence of redundant features causes reduction in classification accuracy. In this work, we intend to select the relevant features from the feature vector obtained by Power Spectrum Density estimation of the left/right motor imagery signals. BCI Competition 2008 - Graz dataset B has been used as the source of raw EEG data. To achieve this goal, we have used single-objective as well as many-objective version of Differential Evolution which optimizes the classifier's performance in terms of five metrics obtained from the Confusion Matrix. Support Vector Machine is used for fitness evaluation of the chosen feature subset as well as for classification of mental states. This work demonstrates the superiority of many-objective Differential Evolution in improving the accuracy due to reduction in feature dimension from an average of 60.56% to 82.60% while processing time of a test EEG sample reduces from 6.1 milliseconds to 5.6 milliseconds. The results obtained in this work are validated using Friedman Test.","","978-1-4673-6621-2","10.1109/MicroCom.2016.7522574","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7522574","Brain — Computer Interfacing;Electroencephalography;Differential Evolution;Many-Objective Optimization;Pareto-Optimality;Power Spectral Density;Support Vector Machine","Electroencephalography;Optimization;Feature extraction;Classification algorithms;Algorithm design and analysis;Sociology","brain-computer interfaces;electroencephalography;evolutionary computation;feature selection;medical disorders;medical signal processing;pattern classification;support vector machines","Friedman test;feature dimension;confusion matrix;differential evolution;EEG data;power spectrum density estimation;EEG signal processing;rehabilitative device;EEG based BCI system;EEG based brain-computer interfacing system;electroencephalography;neuromotor disorder;physical disability;support vector machine;EEG signal motor imagery;feature selection","","10","","28","","28 Jul 2016","","","IEEE","IEEE Conferences"
"An Automatic Weak Learner Formulation for Lithium-Ion Battery State of Health Estimation","J. Meng; L. Cai; D. -I. Stroe; X. Huang; J. Peng; T. Liu; R. Teodorescu","College of Electrical Engineering, Sichuan University, Chengdu, China; Faculty of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; Department of Energy Technology, Aalborg University, Aalborg, Denmark; Department of Energy Technology, Aalborg University, Aalborg, Denmark; Smart Grid Research Institute, Nanjing Institute of Technology, Nanjing, China; College of Electrical Engineering, Sichuan University, Chengdu, China; Department of Energy Technology, Aalborg University, Aalborg, Denmark","IEEE Transactions on Industrial Electronics","6 Dec 2021","2022","69","3","2659","2668","Current pulses are convenient to be actively implemented by a battery management system. However, the short-term features (STF) from current pulses originate from various sensors with uneven qualities, which hinder one powerful and strong learner with STF for the battery state of health (SOH) estimation. This article, thus, proposes an optimized weak learner formulation procedure for lithium-ion battery SOH estimation, which further enables the automatic initialization and integration of the weak learners with STF into an efficient SOH estimation framework. A Pareto front-based selection strategy is designed to select the representative solutions from the nondominated solutions fed by a knee point driven evolutionary algorithm, which guarantees both the diversity and accuracy of the weak learners. Afterward, the weak learners, whose coefficients are obtained by self-adaptive differential evolution, are integrated by a weight-based structure. The proposed method utilizes the weak learners with STF to boost the overall performance of the SOH estimation. The validation of the proposed method is proved by LiFePO<inline-formula><tex-math notation=""LaTeX"">${_4}$</tex-math></inline-formula>/C batteries under accelerated cycling ageing test including one mission profile providing primary frequency regulation service to the grid and one constant current profile.","1557-9948","","10.1109/TIE.2021.3065594","Fundamental Research Funds for the Central Universities(grant numbers:YJ202013); China Postdoctoral Science Foundation(grant numbers:2020M673218); Fund of Robot Technology Used for Special Environment Key Laboratory of Sichuan Province(grant numbers:20KFKT02); National Natural Science Foundation of China(grant numbers:61973042); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2019JQ-746); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380967","Automatic weak learner formulation;ensemble learning;lithium-ion (Li-ion) battery;state of health (SOH) estimation","Estimation;Battery charge measurement;Resistance;Lithium-ion batteries;Aging;Degradation;Training","ageing;battery management systems;carbon;evolutionary computation;frequency control;lithium compounds;Pareto optimisation;power grids;secondary cells","optimized weak learner formulation procedure;lithium-ion battery SOH estimation;weak learners;STF;SOH estimation framework;automatic weak learner formulation;current pulses;battery management system;lithium-ion battery state of health estimation;Pareto front-based selection strategy;knee point driven evolutionary algorithm;self-adaptive differential evolution;weight-based structure;frequency regulation service;power grid;LiFePO4-C","","8","","41","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"Apollo - A Hybrid Recommender for Museums and Cultural Tourism","G. Pavlidis","Athena Research Centre, University Campus at Kimmeria, Xanthi, Greece","2018 International Conference on Intelligent Systems (IS)","9 May 2019","2018","","","94","101","This paper introduces Apollo, a novel hybrid recommender for free-roaming or guided museum visits and cultural tourism. The recommender is based on a new conceptualisation of a visit and the adoption of a minimax (or `conservative') approach towards user satisfaction modelling. The approach is based on the integration of temporal, spatial and content dynamics captured during a visit and contribute to an estimate of the user satisfaction and a development of an optimal route as a sequence of points of interest. Apollo follows a minimax approach by targeting the minimisation of the highest possible user dissatisfaction or disengagement, rather than looking for a maximisation of the user satisfaction. A considerable effort has been dedicated to the creation of realistic simulation data for items (the exhibits), users (the visitors), and a small amount of ratings of the items by some of the users with specific characteristics selected to represent a realistic scenario. Extensive visit simulations have been conducted and results show a considerable decrease of the probable user dissatisfaction in relation to a baseline recommender.","1541-1672","978-1-5386-7097-2","10.1109/IS.2018.8710494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710494","Recommender;recommender system;recommendation;cultural heritage;electronic guide;machine learning;artificial intelligence","Cultural differences;Recommender systems;Machine learning;Adaptation models;Sociology;Statistics;Data models","interactive systems;minimax techniques;mobile computing;museums;probability;recommender systems;travel industry","Apollo;museums;cultural tourism;free-roaming;guided museum visits;user satisfaction modelling;temporal dynamics;spatial dynamics;content dynamics;optimal route;realistic simulation data;extensive visit simulations;probable user dissatisfaction;baseline recommender;hybrid recommender","","3","","30","","9 May 2019","","","IEEE","IEEE Conferences"
"Formal Analysis, Hardness, and Algorithms for Extracting Internal Structure of Test-Based Problems","W. Jaśkowski; K. Krawiec","Institute of Computing Science, Poznan University of Technology, Piotrowo 2, 60965 Poznań, Poland. wjaskowski@cs.put.poznan.pl; Institute of Computing Science, Poznan University of Technology, Piotrowo 2, 60965 Poznań, Poland. kkrawiec@cs.put.poznan.pl","Evolutionary Computation","19 May 2014","2011","19","4","639","671","Problems in which some elementary entities interact with each other are common in computational intelligence. This scenario, typical for coevolving artificial life agents, learning strategies for games, and machine learning from examples, can be formalized as a test-based problem and conveniently embedded in the common conceptual framework of coevolution. In test-based problems, candidate solutions are evaluated on a number of test cases (agents, opponents, examples). It has been recently shown that every test of such problem can be regarded as a separate objective, and the whole problem as multi-objective optimization. Research on reducing the number of such objectives while preserving the relations between candidate solutions and tests led to the notions of underlying objectives and internal problem structure, which can be formalized as a coordinate system that spatially arranges candidate solutions and tests. The coordinate system that spans the minimal number of axes determines the so-called dimension of a problem and, being an inherent property of every problem, is of particular interest. In this study, we investigate in-depth the formalism of a coordinate system and its properties, relate them to properties of partially ordered sets, and design an exact algorithm for finding a minimal coordinate system. We also prove that this problem is NP-hard and come up with a heuristic which is superior to the best algorithm proposed so far. Finally, we apply the algorithms to three abstract problems and demonstrate that the dimension of the problem is typically much lower than the number of tests, and for some problems converges to the intrinsic parameter of the problem–its a priori dimension.","1063-6560","","10.1162/EVCO_a_00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6793223","Coevolution;co-optimization;games;test-based problem;interactive domains;pareto coevolution;underlying objectives;internal problem structure;NP-hardness","","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Clustering by multi objective genetic algorithm","D. Dutta; P. Dutta; J. Sil","Dept. of CSE and IT, U.I.T., The University of Burdwan, W.B., India; Dept. of Computer and System Sciences, Visva Bharati University, Santiniketan, W.B., India; Dept. of Computer Science and Technology, Bengal Engineering and Science University, Shibpur, W.B., India","2012 1st International Conference on Recent Advances in Information Technology (RAIT)","7 May 2012","2012","","","548","553","The aim of the paper is to study a real coded multi objective genetic algorithm based K-clustering, where K represents the number of clusters, may be known or unknown. If the value of K is known, it is called K-clustering algorithm. The searching power of Genetic Algorithm (GA) is exploited to get for proper clusters and centers of clusters in the feature space to optimize simultaneously intra-cluster distance (Homogeneity) (H) and inter-cluster distances (Separation) (S). Maximization of 1/H and S are the twin objectives of Multi Objective Genetic Algorithm (MOGA) achieved by measuring H and S using Euclidean distance metric, suitable for continuous features (attributes). We have selected 10 data sets from the UCI machine learning repository containing continuous features only to validate the proposed algorithms. All-important steps of algorithms are shown here. At the end, classification accuracies obtained by best chromosomes are shown.","","978-1-4577-0697-4","10.1109/RAIT.2012.6194619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6194619","Clustering;homogeneity and separation;real coded multi objective genetic algorithm;Pareto optimal front","Biological cells;Genetic algorithms;Optimization;Clustering algorithms;Buildings;Vectors;Mathematical model","data mining;genetic algorithms;learning (artificial intelligence);pattern classification;pattern clustering","multiobjective genetic algorithm;K-clustering algorithm;intracluster distance;intercluster distance;homogeneity cluster;separation cluster;maximization;Euclidean distance metric;UCI machine learning repository;classification accuracy","","10","","35","","7 May 2012","","","IEEE","IEEE Conferences"
"Unreliable-to-Reliable Instance Translation for Semi-Supervised Pedestrian Detection","S. Lin; W. Wu; S. Wu; Y. Xu; H. -S. Wong","School of Computer Science and Engineering, South China University of Technology, Guangzhou, Guangdong, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, Guangdong, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, Guangdong, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, Guangdong, China; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong","IEEE Transactions on Multimedia","8 Feb 2022","2022","24","","728","739","Generating realistic pedestrian instances in a semi-supervised setting is promising but challenging due to the limited labeled data. We propose an unreliable-to-reliable instance translation model (Un2Reliab) conditioned on unreliable instances which poorly align with pedestrians. Un2Reliab mainly consists of an encoder-decoder-like generative network and a discriminative network, which are jointly trained in a minimax game. We adopt regularization to ensure that the synthesized instances are semantically similar to the corresponding ground truth. Furthermore, to preserve the identities of persons, we propose another regularization to ensure that the synthesized instances associated with the same person should be consistent in appearance. As a result, Un2Reliab learns to restore the missing parts of the original instances. As a side benefit, the synthesized instances are brought into better alignment. Inclusion of the synthesized data improves both the diversity and quality of training data, which eventually leads to better generalization performance. Extensive experiments indicate that Un2Reliab is able to synthesize high-fidelity pedestrian instances and improve the previous state-of-the-art results on multiple semi-supervised pedestrian detection benchmarks.","1941-0077","","10.1109/TMM.2021.3058546","National Natural Science Foundation of China(grant numbers:62072189); Research Grants Council of the Hong Kong Special Administration Region(grant numbers:11201220); Natural Science Foundation of Guangdong Province(grant numbers:2020A1515010484); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352521","Generative adversarial network;image-to-image translation;pedestrian detection;semi-supervised learning","Data models;Training;Reliability;Detectors;Task analysis;Semantics;Visualization","","","","","","59","IEEE","10 Feb 2021","","","IEEE","IEEE Journals"
"A Generative Adversarial Gated Recurrent Unit Model for Precipitation Nowcasting","L. Tian; X. Li; Y. Ye; P. Xie; Y. Li","Department of Computer Science, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, Shenzhen PolyTechnic, Shenzhen, China","IEEE Geoscience and Remote Sensing Letters","25 Mar 2020","2020","17","4","601","605","Precipitation nowcasting is an important task in operational weather forecasts. The key challenge of the task is the radar echo map extrapolation. The problem is mainly solved by an optical-flow method in existing systems. However, the method cannot model rapid and nonlinear movements. Recently, a convolutional gated recurrent unit (ConvGRU) method is developed, which aims to model such movements based on deep learning techniques. Despite the promising performance, ConvGRU tends to yield blurring extrapolation images and fails to multi-modal and skewed intensity distribution. To overcome the limitations, we propose in this letter a generative adversarial ConvGRU (GA-ConvGRU) model. The model is composed of two adversarial learning systems, which are a ConvGRU-based generator and a convolution neural network-based discriminator. The two systems are trained by playing a minimax game. With the adversarial learning scheme, GA-ConvGRU can yield more realistic and more accurate extrapolation. Experiments on real data sets have been conducted and the results demonstrate that the proposed GA-ConvGRU significantly outperforms state-of-the-art extrapolation methods ConvGRU and optical flow.","1558-0571","","10.1109/LGRS.2019.2926776","National Basic Research Program of China (973 Program)(grant numbers:2018YFB0504900,2018YFB0504905); Shenzhen Science and Technology Program(grant numbers:JCYJ20170811160212033,JCYJ20180507183823045,JCYJ20170413105929681); National Natural Science Foundation of China(grant numbers:61602132); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777193","Deep learning;image sequence prediction;nowcasting;radar echo extrapolation","Generators;Extrapolation;Radar imaging;Image sequences;Optical imaging;Optical network units","extrapolation;image sequences;learning (artificial intelligence);meteorological radar;neural nets;recurrent neural nets;weather forecasting","optical flow;state-of-the-art extrapolation methods ConvGRU;adversarial learning scheme;convolution neural network-based discriminator;ConvGRU-based generator;adversarial learning systems;GA-ConvGRU;generative adversarial ConvGRU model;skewed intensity distribution;blurring extrapolation images;deep learning techniques;convolutional gated recurrent unit method;optical-flow method;radar echo map extrapolation;operational weather forecasts;generative adversarial gated recurrent unit model","","18","","14","IEEE","26 Jul 2019","","","IEEE","IEEE Journals"
"Worst-Case Prediction Performance Analysis of the Kalman Filter","S. Yasini; K. Pelckmans","Department of Information Technology, Division of Systems and Control, Uppsala University, Uppsala, Sweden; Department of Information Technology, Division of Systems and Control, Uppsala University, Uppsala, Sweden","IEEE Transactions on Automatic Control","25 May 2018","2018","63","6","1768","1775","In this paper, we study the prediction performance of the Kalman filter (KF) in a worst case minimax setting as studied in online machine learning, information, and game theory. The aim is to predict the sequence of observations almost as well as the best reference predictor (comparator) sequence in a comparison class. We prove worst-case bounds on the cumulative squared prediction errors using a priori knowledge about the complexity of reference predictor sequence. In fact, the performance of the KF is derived as a function of the performance of the best reference predictor and the total amount of drift that occurs in the schedule of the best comparator.","1558-2523","","10.1109/TAC.2017.2757908","Vetenskapsrådet(grant numbers:621-2007-6364); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052565","  $H_{\infty}$   estimation;Kalman filter (KF);online machine learning;tracking worst-case bounds","Prediction algorithms;Complexity theory;Stochastic processes;Predictive models;Kalman filters;Machine learning algorithms;Estimation","estimation theory;game theory;Kalman filters;learning (artificial intelligence);minimax techniques","worst-case prediction performance analysis;Kalman filter;KF;worst case minimax setting;online machine learning;game theory;reference predictor sequence;comparator;cumulative squared prediction errors","","7","","25","IEEE","28 Sep 2017","","","IEEE","IEEE Journals"
"REPAIR: Removing Representation Bias by Dataset Resampling","Y. Li; N. Vasconcelos",UC San Diego; UC San Diego,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","9564","9573","Modern machine learning datasets can have biases for certain representations that are leveraged by algorithms to achieve high performance without learning to solve the underlying task. This problem is referred to as “representation bias”. The question of how to reduce the representation biases of a dataset is investigated and a new dataset REPresentAtion bIas Removal (REPAIR) procedure is proposed. This formulates bias minimization as an optimization problem, seeking a weight distribution that penalizes examples easy for a classifier built on a given feature representation. Bias reduction is then equated to maximizing the ratio between the classification loss on the reweighted dataset and the uncertainty of the ground-truth class labels. This is a minimax problem that REPAIR solves by alternatingly updating classifier parameters and dataset resampling weights, using stochastic gradient descent. An experimental set-up is also introduced to measure the bias of any dataset for a given representation, and the impact of this bias on the performance of recognition models. Experiments with synthetic and action recognition data show that dataset REPAIR can significantly reduce representation bias, and lead to improved generalization of models trained on REPAIRed datasets. The tools used for characterizing representation bias, and the proposed dataset REPAIR algorithm, are available at https://github.com/JerryYLi/Dataset-REPAIR/.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953550","Datasets and Evaluation;Action Recognition ; Deep Learning ; Representation Learning; Video Analytics","","gradient methods;learning (artificial intelligence);minimax techniques;pattern classification","machine learning datasets;bias minimization;feature representation;bias reduction;dataset resampling weights;dataset REPAIR algorithm;dataset representation bias removal","","29","1","40","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Variational Bound of Mutual Information for Fairness in Classification","Z. Alsulaimawi","Oregon State University,School of Electrical Engineering and Computer Science,Corvallis,OR,USA","2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)","16 Dec 2020","2020","","","1","6","Machine learning applications have emerged in many aspects of our lives, such as for credit lending, insurance rates, and employment applications. Consequently, it is required that such systems be nondiscriminatory and fair in sensitive features user, e.g., race, sexual orientation, and religion. To address this issue, this paper develops a minimax adversarial framework, called features protector (FP) framework, to achieve the information-theoretical trade-off between minimizing distortion of target data and ensuring that sensitive features have similar distributions. We evaluate the performance of the proposed framework on two real-world datasets. Preliminary empirical evaluation shows that our framework provides both accurate and fair decisions.","2473-3628","978-1-7281-9320-5","10.1109/MMSP48831.2020.9287139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287139","Fairness;privacy-preserving;adversarial learning;variational mutual information;big data security;deep learning","Conferences;Employment;Insurance;Machine learning;Distortion;Mutual information;Image reconstruction","learning (artificial intelligence);minimax techniques;pattern classification","machine learning applications;credit lending;insurance rates;employment applications;sexual orientation;religion;minimax adversarial framework;FP;sensitive features;similar distributions;preliminary empirical evaluation;accurate decisions;fair decisions;variational bound;mutual information;information-theoretical trade-off;features protector framework;minimizing distortion","","","","25","","16 Dec 2020","","","IEEE","IEEE Conferences"
"Simultaneous Human Health Monitoring and Time-Frequency Sparse Representation Using EEG and ECG Signals","W. He; G. Wang; J. Hu; C. Li; B. Guo; F. Li","School of Aerospace Science and Technology, Xidian University, Xi’an, China; School of Aerospace Science and Technology, Xidian University, Xi’an, China; School of Aerospace Science and Technology, Xidian University, Xi’an, China; School of Aerospace Science and Technology, Xidian University, Xi’an, China; School of Aerospace Science and Technology, Xidian University, Xi’an, China; Institute of Laser and Optoelectronics Intelligent Manufacturing, Wenzhou University, Wenzhou, China","IEEE Access","11 Jul 2019","2019","7","","85985","85994","In the field of human health monitoring, intelligent diagnostic methods have drawn much attention recently to tackle the health problems and challenges faced by patients. In this paper, an efficient and flexible diagnostic method is proposed, which enables the simultaneous use of a machine learning method and sparsity-based representation technique. Specifically, the proposed method is based on a convolutional neural network (CNN) and generalized minimax-concave (GMC) method. First, measured potential signals, for instance, electroencephalogram (EEG) and electrocardiogram (ECG) signals are directly inputted into the designed network based on CNN for health conditions classification. The designed network adopts small convolution kernels to enhance the performance of feature extraction. In the training process, small batch samples are applied to improve the generalization of the model. Meanwhile, the “Dropout” strategy is applied to overcome the overfitting problem in fully connected layers. Then, for a record of the interested EEG or ECG signal, the sparse representation of useful time-frequency features can be estimated via the GMC method. Case studies of seizure detection and arrhythmia signal analysis are adopted to verify the performance of the proposed method. The experimental results demonstrate that the proposed method can effectively identify different health conditions and maximally enhance the sparsity of time-frequency features.","2169-3536","","10.1109/ACCESS.2019.2921568","Laser Manufacturing and Additive Manufacturing Project of National Key Research and Development Program of China(grant numbers:2018YFB1108000); Wenzhou Municipal Key Science and Research Program(grant numbers:ZG2017003); National Natural Science Foundation of China(grant numbers:51805398); Natural Science Foundation of Shaanxi Province(grant numbers:2018JQ5106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732935","Feature extraction;convolutional neural network;deep learning;sparse representation;health monitoring","Feature extraction;Convolution;Time-frequency analysis;Electrocardiography;Electroencephalography;Neurons;Monitoring","electrocardiography;electroencephalography;feature extraction;learning (artificial intelligence);medical signal detection;medical signal processing;neural nets;signal classification;time-frequency analysis","simultaneous human health monitoring;time-frequency sparse representation;intelligent diagnostic methods;health problems;efficient method;flexible diagnostic method;machine learning method;sparsity;CNN;measured potential signals;ECG;designed network;health conditions classification;convolution kernels;overfitting problem;useful time-frequency features;GMC method;seizure detection;arrhythmia signal analysis;health conditions;electrocardiogram;convolutional neural network;electroencephalogram;EEG","","7","","30","OAPA","10 Jun 2019","","","IEEE","IEEE Journals"
"Pruning In Time (PIT): A Lightweight Network Architecture Optimizer for Temporal Convolutional Networks","M. Risso; A. Burrello; D. J. Pagliari; F. Conti; L. Lamberti; E. Macii; L. Benini; M. Poncino","Politecnico di Torino,Turin,Italy; University of Bologna,Bologna,Italy; Politecnico di Torino,Turin,Italy; University of Bologna,Bologna,Italy; University of Bologna,Bologna,Italy; Politecnico di Torino,Turin,Italy; University of Bologna,Bologna,Italy; Politecnico di Torino,Turin,Italy","2021 58th ACM/IEEE Design Automation Conference (DAC)","8 Nov 2021","2021","","","1015","1020","Temporal Convolutional Networks (TCNs) are promising Deep Learning models for time-series processing tasks. One key feature of TCNs is time-dilated convolution, whose optimization requires extensive experimentation. We propose an automatic dilation optimizer, which tackles the problem as a weight pruning on the time-axis, and learns dilation factors together with weights, in a single training. Our method reduces the model size and inference latency on a real SoC hardware target by up to 7.4× and 3×, respectively with no accuracy drop compared to a network without dilation. It also yields a rich set of Pareto-optimal TCNs starting from a single model, outperforming hand-designed solutions in both size and accuracy.","0738-100X","978-1-6654-3274-0","10.1109/DAC18074.2021.9586187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9586187","Neural Architecture Search;Temporal Convolutional Networks;Edge Computing;Deep Learning","Training;Deep learning;Design automation;Neural networks;Computer architecture;Tools;Network architecture","deep learning (artificial intelligence);lightweight structures;Pareto optimisation;system-on-chip;time series","lightweight network architecture optimizer;temporal convolutional networks;deep learning models;time-series processing tasks;time-dilated convolution;automatic dilation optimizer;dilation factors;pareto-optimal;pruning in time;PIT;TCN;SoC hardware","","1","","20","IEEE","8 Nov 2021","","","IEEE","IEEE Conferences"
"AI Assisted Optimization of Unimorph Tapered Cantilever for Piezoelectric Energy Harvesting","O. Pertin; K. Guha; O. Jakšić; Z. Jakšić","National MEMS Design Centre, National Institute of Technology,Department of Electronics and Communication Engineering,Silchar,Assam,India,788010; National MEMS Design Centre, National Institute of Technology,Department of Electronics and Communication Engineering,Silchar,Assam,India,788010; Center of Microelectronic Technologies, Institute of Chemistry, Technology and Metallurgy - National Institute of the Republic of Serbia, University of Belgrade,Belgrade,Serbia,11000; Center of Microelectronic Technologies, Institute of Chemistry, Technology and Metallurgy - National Institute of the Republic of Serbia, University of Belgrade,Belgrade,Serbia,11000","2021 IEEE 32nd International Conference on Microelectronics (MIEL)","25 Oct 2021","2021","","","285","288","This paper presents the results of the deploying machine learning models in the design and optimization of a unimorph tapered cantilever with proof mass, aimed for piezoelectric energy harvesting. Multiobjective optimization as described in the paper was performed in order to find the optimal dimensions of the structure, its length, its width at the anchor and the ratio between widths at the anchor and at the tip, with respect to the salient parameters for the energy harvesting applications, namely low frequency and high power generated by the structure. The method is applicable for the optimization of the design of more complex MEMS structures aimed for energy harvesting applications.","2159-1679","978-1-6654-4528-3","10.1109/MIEL52794.2021.9569184","Ministry of Education, Science and Technological Development of Republic of Serbia(grant numbers:451-03-9/2021-14/200026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9569184","","Micromechanical devices;Conferences;Resonant frequency;Machine learning;Power systems;Microelectronics;Complexity theory","cantilevers;energy harvesting;learning (artificial intelligence);micromechanical devices;piezoelectric transducers;power engineering computing","machine learning models;unimorph tapered cantilever;proof mass;piezoelectric energy harvesting;multiobjective optimization;energy harvesting applications;AI assisted optimization;MEMS structures","","","","11","IEEE","25 Oct 2021","","","IEEE","IEEE Conferences"
"Transfer Learning for Design-Space Exploration with High-Level Synthesis","J. Kwon; L. P. Carloni","Columbia University,Department of Computer Science,New York,NY,USA; Columbia University,Department of Computer Science,New York,NY,USA","2020 ACM/IEEE 2nd Workshop on Machine Learning for CAD (MLCAD)","9 Apr 2021","2020","","","163","168","High-level synthesis (HLS) raises the level of design abstraction, expedites the process of hardware design, and enriches the set of final designs by automatically translating a behavioral specification into a hardware implementation. To obtain different implementations, HLS users can apply a variety of knobs, such as loop unrolling or function inlining, to particular code regions of the specification. The applied knob configuration significantly affects the synthesized design's performance and cost, e.g., application latency and area utilization. Hence, HLS users face the design-space exploration (DSE) problem, i.e. determine which knob configurations result in Pareto-optimal implementations in this multi-objective space. Whereas it can be costly in time and resources to run HLS flows with an enormous number of knob configurations, machine learning approaches can be employed to predict the performance and cost. Still, they require a sufficient number of sample HLS runs. To enhance the training performance and reduce the sample complexity, we propose a transfer learning approach that reuses the knowledge obtained from previously explored design spaces in exploring a new target design space. We develop a novel neural network model for mixed-sharing multi-domain transfer learning. Experimental results demonstrate that the proposed model outperforms both single-domain and hard-sharing models in predicting the performance and cost at early stages of HLS-driven DSE.","","978-1-4503-7519-1","10.1145/3380446.3430636","NSF(grant numbers:1527821,1764000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394634","high-level synthesis;design space exploration;neural networks;machine learning;transfer learning;multi-task learning","Training;Solid modeling;Transfer learning;Predictive models;Tools;Hardware;Space exploration","circuit optimisation;electronic engineering computing;high level synthesis;learning (artificial intelligence);logic circuits;logic design;neural nets;Pareto optimisation","high-level synthesis;design abstraction;hardware design;behavioral specification;hardware implementation;loop unrolling;particular code regions;knob configuration;design-space exploration problem;Pareto-optimal implementations;multiobjective space;machine learning approaches;sample HLS runs;training performance;transfer learning approach;explored design spaces;target design space;mixed-sharing multidomain transfer learning;HLS-driven DSE;function inlining;applied knob configuration;DSE problem;neural network model;single-domain models;hard-sharing models","","4","","25","","9 Apr 2021","","","IEEE","IEEE Conferences"
"A Multi-objective Rule Optimizer with an Application to Risk Management","P. Pulkkinen; N. Tiwari; A. Kumar; C. Jones","Amazon, Seattle, WA, USA; Amazon, Seattle, WA, USA; Amazon, Seattle, WA, USA; Amazon, Seattle, WA, USA","2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","66","72","Managing risk is important to any E-commerce merchant. Various machine learning (ML) models combined with a rule set as the decision layer is a common practice to manage the risks. Unlike the ML models that can be automatically refreshed periodically based on new risk patterns, rules are generally static and rely on manual updates. To tackle that, this paper presents a data-driven and automated rule optimization method that generates multiple Pareto-optimal rule sets representing different trade-offs between business objectives. This enables business owners to make informed decisions when choosing between optimized rule sets for changing business needs and risks. Furthermore, manual work in rule management is greatly reduced. For scalability this method leverages Apache Spark and runs either on a single host or in a distributed environment in the cloud. This allows us to perform the optimization in a distributed fashion using millions of transactions, hundreds of variables and hundreds of rules during the training. The proposed method is general but we used it for optimizing real-world E-commerce (Amazon) risk rule sets. It could also be used in other fields such as finance and medicine.","","978-1-5386-6805-4","10.1109/ICMLA.2018.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614043","Big data, spark, cloud computing, risk management, multi-objective optimization, machine learning","Genetic algorithms;Optimization;Risk management;Sociology;Statistics;Encoding","business data processing;decision making;electronic commerce;knowledge based systems;learning (artificial intelligence);Pareto optimisation;pattern classification;risk management","Pareto-optimal rule sets;Apache Spark;risk patterns;ML models;decision layer;machine learning models;E-commerce merchant;risk management;multiobjective rule optimizer;rule management;business objectives;rule optimization method","","2","","26","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Discovering Knowledge Rules with Multi-Objective Evolutionary Computing","R. Giusti; G. E. A. P. A. Batista","Inst. de Cienc. Mat. e de Computaςao, Univ. de Sao Paulo, São Carlos, Brazil; Inst. de Cienc. Mat. e de Computaςao, Univ. de Sao Paulo, São Carlos, Brazil","2010 Ninth International Conference on Machine Learning and Applications","4 Feb 2011","2010","","","119","124","Most Machine Learning systems target into inducing classifiers with optimal coverage and precision measures. Although this constitutes a good approach for prediction, it might not provide good results when the user is more interested in description. In this case, the induced models should present other properties such as novelty, interestingness and so forth. In this paper we present a research work based in Multi-Objective Evolutionary Computing to construct individual knowledge rules targeting arbitrary user-defined criteria via objective quality measures such as precision, support, novelty etc. This paper also presents a comparison among multi-objective and ranking composition techniques. It is shown that multi-objective-based methods attain better results than ranking-based methods, both in terms of solution dominance and diversity of solutions in the Pareto front.","","978-1-4244-9211-4","10.1109/ICMLA.2010.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708822","Multi-Objective Machine Learning;Knowledge Discovery in Databases;Evolutionary Computing","Optimization;Sorting;Machine learning;Euclidean distance;Evolutionary computation;Harmonic analysis","data mining;evolutionary computation;knowledge based systems;learning (artificial intelligence);learning systems;pattern classification","knowledge rules discovery;multiobjective evolutionary computing;machine learning system;user defined criteria;ranking composition technique","","","","15","","4 Feb 2011","","","IEEE","IEEE Conferences"
"Capacity Planning as a Service for Enterprise Standard Software","H. Müller; S. Bosse; M. Pohl; K. Turowski","Fac. of Comput. Sci., Otto-von-Guericke-Univ., Magdeburg, Germany; Fac. of Comput. Sci., Otto-von-Guericke-Univ., Magdeburg, Germany; Fac. of Comput. Sci., Otto-von-Guericke-Univ., Magdeburg, Germany; Fac. of Comput. Sci., Otto-von-Guericke-Univ., Magdeburg, Germany","2017 IEEE 19th Conference on Business Informatics (CBI)","21 Aug 2017","2017","01","","167","175","Too often, capacity planning activities that are crucial to software performance are being pushed to late development phases where trivial measurement-based assessment techniques can be employed on enterprise applications that are nearing completion. This procedure is highly inefficient, time consuming, and may result in disproportionately high correction costs to meet existing service level agreements. However, enterprise applications nowadays excessively make use of standard software that is shipped by large software vendors to a wide range of customers. Therefore, an application similar to the one whose capacity is being planned may already be in production state and constantly produce log data as part of application performance monitoring facilities. In this paper, we demonstrate how potential capacity planning service providers can leverage the dissemination effects of standard software by applying machine learning techniques on measurement data from various running enterprise applications. Utilizing prediction models that were trained on a large scale of monitoring data enables cost-efficient measurement-based prediction techniques to be used in early design phases. Therefore, we integrate knowledge discovery activities into wellknown capacity planning steps, which we adapt to the special characteristics of enterprise applications. We evaluate the feasibility of the modeled process using measurement data from more than 1,800 productively running enterprise applications in order to predict the response time of a widely used standard business transaction. Based on the trained model, we demonstrate how to simulate and analyze future workload scenarios. Using a Pareto approach, we were able to identify cost-effective design alternatives for a planned enterprise application.","2378-1971","978-1-5386-3035-8","10.1109/CBI.2017.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010719","prediction model;machine learning;big data;service design;business transaction;response time","Capacity planning;Unified modeling language;Predictive models;Software;Standards;Data models","business data processing;contracts;learning (artificial intelligence)","capacity planning as a service;enterprise standard software;software performance;measurement-based assessment techniques;service level agreements;log data;application performance monitoring facilities;capacity planning service providers;standard software dissemination effects;cost-efficient measurement-based prediction techniques;measurement data;standard business transaction;Pareto approach;machine learning techniques","","","1","49","","21 Aug 2017","","","IEEE","IEEE Conferences"
"Predicting Cloud Performance for HPC Applications: A User-Oriented Approach","G. Mariani; A. Anghel; R. Jongerius; G. Dittmann","IBM Res., Amsterdam, Netherlands; IBM Res. - Zurich, Zurich, Switzerland; IBM Res., Amsterdam, Netherlands; IBM Res. - Zurich, Zurich, Switzerland","2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)","13 Jul 2017","2017","","","524","533","Cloud computing enables end users to execute high-performance computing applications by renting the required computing power. This pay-for-use approach enables small enterprises and startups to run HPC-related businesses with a significant saving in capital investment and a short time to market. When deploying an application in the cloud, the users may a) fail to understand the interactions of the application with the software layers implementing the cloud system, b) be unaware of some hardware details of the cloud system, and c) fail to understand how sharing part of the cloud system with other users might degrade application performance. These misunderstandings may lead the users to select suboptimal cloud configurations in terms of cost or performance. To aid the users in selecting the optimal cloud configuration for their applications, we suggest that the cloud provider generate a prediction model for the provided system. We propose applying machine-learning techniques to generate this prediction model. First, the cloud provider profiles a set of training applications by means of a hardware-independent profiler and then executes these applications on a set of training cloud configurations to collect actual performance values. The prediction model is trained to learn the dependencies of actual performance data on the application profile and cloud configuration parameters. The advantage of using a hardware-independent profiler is that the cloud users and the cloud provider can analyze applications on different machines and interface with the same prediction model. We validate the proposed methodology for a cloud system implemented with OpenStack. We apply the prediction model to the NAS parallel benchmarks. The resulting relative error is below 15% and the Pareto optimal cloud configurations finally found when maximizing application speed and minimizing execution cost on the prediction model are also at most 15% away from the actual optimal solutions.","","978-1-5090-6611-7","10.1109/CCGRID.2017.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973739","Cloud;machine learning;design of experiments;high performance computing;random forest;performance prediction","Cloud computing;Predictive models;Training;Optimization;Hardware;Measurement;Computational modeling","cloud computing;learning (artificial intelligence);parallel processing","high-performance computing;machine-learning techniques;hardware-independent profiler;OpenStack;NAS parallel benchmarks;Pareto optimal cloud configurations;HPC applications;cloud performance prediction;cloud computing","","10","","36","","13 Jul 2017","","","IEEE","IEEE Conferences"
"DESCNet: Developing Efficient Scratchpad Memories for Capsule Network Hardware","A. Marchisio; V. Mrazek; M. A. Hanif; M. Shafique","Department of Informatics, Institute of Computer Engineering, Technische Universität Wien, Vienna, Austria; Department of Computer Systems, Brno University of Technology, Brno, Czech Republic; Department of Informatics, Institute of Computer Engineering, Technische Universität Wien, Vienna, Austria; Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","19 Aug 2021","2021","40","9","1768","1781","Deep neural networks (DNNs) have been established as the state-of-the-art method for advanced machine learning applications. Recently proposed by the Google Brain's team, the capsule networks (CapsNets) have improved the generalization ability, as compared to DNNs, due to their multidimensional capsules and preserving the spatial relationship between different objects. However, they pose significantly high computational and memory requirements, making their energy-efficient inference a challenging task. This article provides, for the first time, an in-depth analysis to highlight the design and runtime challenges for the (on-chip scratchpad) memories deployed in hardware accelerators executing fast CapsNets inference. To enable an efficient design, we propose an application-specific memory architecture, called DESCNet, which minimizes the off-chip memory accesses, while efficiently feeding the data to the hardware accelerator executing CapsNets inference. We analyze the corresponding on-chip memory requirement and leverage it to propose a methodology for exploring different scratchpad memory (SPM) designs and their energy/area tradeoffs. Afterward, an application-specific power-gating technique for the on-chip SPM is employed to further reduce its energy consumption, depending upon the mapped dataflow of the CapsNet and the utilization across different operations of its processing. We integrated our DESCNet memory design, as well as another state-of-the-art memory design Marchisio et al. [2018] for comparison studies, with an opensource DNN accelerator executing Google's CapsNet model Sabour et al. [2017] for the MNIST dataset. We also enhanced the design to execute the recent deep CapsNet model Rajasegaran et al. [2019] for the CIFAR10 dataset. Note: we use the same benchmarks and test conditions for which these CapsNets have been proposed and evaluated by their respective teams. The complete hardware is synthesized for a 32-nm CMOS technology using the ASIC-design flow with Synopsys tools and CACTI-P, and detailed area, performance, and power/energy estimation is performed using different configurations. Our results for a selected Pareto-optimal solution demonstrate no performance loss and an energy reduction of 79% for the complete accelerator, including computational units and memories, when compared to the state-of-the-art design.","1937-4151","","10.1109/TCAD.2020.3030610","Doctoral College Resilient Embedded Systems which is run jointly by TU Wien’s Faculty of Informatics and FH-Technikum Wien; Czech Science Foundation(grant numbers:19-10137S); Czech Ministry of Education of Youth and Sports from the Operational Program Research, Development and Education project International Researcher Mobility of the Brno University of Technology(grant numbers:CZ.02.2.69/0.0/0.0/16_027/0008371); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222370","Capsule networks (CapsNets);design space exploration (DSE);energy efficiency;machine learning (ML);memory design;memory management;performance;power gating;scratchpad memory (SPM);special-purpose hardware","Memory management;Hardware;System-on-chip;Two dimensional displays;Memory architecture;Routing","application specific integrated circuits;deep learning (artificial intelligence);memory architecture;optimisation;Pareto optimisation;power aware computing;storage management","capsule network hardware;deep neural networks;DNNs;machine learning;hardware accelerator;CapsNets inference;application-specific memory architecture;DESCNet;off-chip memory accesses;on-chip memory requirement;scratchpad memory designs;application-specific power-gating technique;on-chip SPM;energy consumption;ASIC-design flow;Synopsys tools;Pareto-optimal solution","","2","","32","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Low Power Design of Runtime Reconfigurable FPGAs through Contexts Approximations","S. Xu; B. Carrion Schafer","The University of Texas at Dallas, USA; The University of Texas at Dallas, USA","2019 IEEE 37th International Conference on Computer Design (ICCD)","10 Feb 2020","2019","","","524","531","This paper presents a method to improve the performance and reduce the energy of applications mapped onto coarse-grain runtime reconfigurable arrays (CGRRAs) by substituting and merging different contexts by approximate predictive models. In CGRRAs applications are split into contexts. The CGRRA is then reconfigured every clock cycle by loading a new context onto the reconfigurable fabric. In this work, we propose to substitute contexts by approximate expressions using machine learning models of different complexities like linear regression (LR) and multi-layer perceptrons (MLPs) such that the CGRRA area and energy can be reduced albeit introducing different levels of errors at the output. Moreover, we propose a technique to merged these approximated contexts with other contexts leading to a set of Pareto-optimal configurations. Experimental results show that our proposed method works well and it can trade-off area, performance and energy with output error of several computationally intensive applications mapped onto a commercial CGRRA.","2576-6996","978-1-5386-6648-7","10.1109/ICCD46524.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8988751","Approximate Computing;High level Synthesis;Machine Learning;Hardware Accelerator;Coarse grain Runtime Reconfigurable Architecture","","energy conservation;field programmable gate arrays;learning (artificial intelligence);low-power electronics;multilayer perceptrons;Pareto optimisation;reconfigurable architectures;regression analysis","low power design;runtime reconfigurable FPGAs;contexts approximations;machine learning models;linear regression;multilayer perceptrons;runtime reconfigurable arrays;Pareto-optimal configurations;energy efficient computing systems","","","","30","","10 Feb 2020","","","IEEE","IEEE Conferences"
"Autonomous Virulence Adaptation Improves Coevolutionary Optimization","J. Cartlidge; D. Ait-Boudaoud","School of Computing, Engineering and Physical Sciences, University of Central Lancashire, Preston, U.K.; School of Computing, Engineering and Physical Sciences, University of Central Lancashire, Preston, U.K.","IEEE Transactions on Evolutionary Computation","28 Mar 2011","2011","15","2","215","229","A novel approach for the autonomous virulence adaptation (AVA) of competing populations in a coevolutionary optimization framework is presented. Previous work has demonstrated that setting an appropriate virulence, v, of populations accelerates coevolutionary optimization by avoiding detrimental periods of disengagement. However, since the likelihood of disengagement varies both between systems and over time, choosing the ideal value of v is problematic. The AVA technique presented here uses a machine learning approach to continuously tune v as system engagement varies. In a simple, abstract domain, AVA is shown to successfully adapt to the most productive values of v. Further experiments, in more complex domains of sorting networks and maze navigation, demonstrate AVA's efficiency over reduced virulence and the layered Pareto coevolutionary archive.","1941-0026","","10.1109/TEVC.2010.2073471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685267","Autonomous virulence adaptation;coevolution;disengagement;genetic algorithms;machine learning;maze navigation;optimization methods;reduced virulence;sorting networks","Games;Sorting;Pathology;Stability analysis;Optimization;Machine learning;Delta modulation","evolutionary computation;learning (artificial intelligence);Pareto optimisation","autonomous virulence adaptation;coevolutionary optimization;AVA technique;machine learning approach;productive values;complex domains;maze navigation;reduced virulence;layered Pareto coevolutionary archive","","6","","56","IEEE","10 Jan 2011","","","IEEE","IEEE Journals"
"Using Polynomial Regression and Artificial Neural Networks for Reusable Analog IC Sizing","N. Lourenço; E. Afacan; R. Martins; F. Passos; A. Canelas; R. Póvoa; N. Horta; G. Dundar","Instituto de Telecomunicações/Instituto Superior Técnico, Universidade de Lisboa, Portugal; Electronics and Communications Enginnering, Kocaeli University, Kocaeli, Turkey; Instituto de Telecomunicações/Instituto Superior Técnico, Universidade de Lisboa, Portugal; IMSE-CNM, Instituto de Microelectrónica de Sevilla, CSIC - Universidad de Sevilla, Seville, Spain; Instituto de Telecomunicações/Instituto Superior Técnico, Universidade de Lisboa, Portugal; Instituto de Telecomunicações/Instituto Superior Técnico, Universidade de Lisboa, Portugal; Instituto de Telecomunicações/Instituto Superior Técnico, Universidade de Lisboa, Portugal; Electrical and Electronics Engineering, Boğaziçi University, Istanbul, Turkey","2019 16th International Conference on Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design (SMACD)","15 Aug 2019","2019","","","13","16","In this paper, the use of machine learning techniques to repurpose already available Pareto optimal fronts of analog integrated circuit blocks for new contexts (loads, supply voltage, etc.) is explored. Data from previously sized circuits is used to train models that predict both circuit performance under the new context and the corresponding device sizes. A two-model chain is proposed, where, in the first layer, a multivariate polynomial regression estimates the performance tradeoffs. The output of this performance model is then used as input of an artificial neural network that predicts the device sizing that corresponds to that performance. Moreover, the models are trained with optimized sizing solutions, leading almost instantly to predicted solutions that are near optimal for the new context. The proposed methodology was integrated into a new framework and tested against a real circuit topology, with promising results. The model was able to predict wider and, in some cases, better, performance tradeoff, when compared to independent optimization runs for the same context, despite requiring 400 times fewer circuit simulations.","","978-1-7281-1201-5","10.1109/SMACD.2019.8795282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795282","Analog IC Sizing;Retargeting;Data Mining;Artificial Neural Networks;Deep Learning","","analogue integrated circuits;circuit simulation;data mining;learning (artificial intelligence);neural nets;Pareto optimisation;polynomials;regression analysis","optimized sizing solutions;circuit topology;performance tradeoff;artificial neural network;analog integrated circuit blocks;circuit performance;two-model chain;multivariate polynomial regression;performance model;optimization;circuit simulations;analog IC sizing;Pareto optimal fronts;machine learning","","4","","19","","15 Aug 2019","","","IEEE","IEEE Conferences"
"A learning bridge from architectural synthesis to physical design for exploring power efficient high-performance adders","S. Roy; Y. Ma; J. Miao; B. Yu","Cadence Design Systems, San Jose, CA, USA; CSE Department, The Chinese University of Hong Kong, NT, Hong Kong; Cadence Design Systems, San Jose, CA, USA; CSE Department, The Chinese University of Hong Kong, NT, Hong Kong","2017 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)","14 Aug 2017","2017","","","1","6","In spite of maturity to the modern electronic design automation (EDA) tools, optimized designs at architectural stage may become sub-optimal after going through physical design flow. Adder design has been such a long studied fundamental problem in VLSI industry yet designers cannot achieve optimal solutions by running EDA tools on the set of available prefix adder architectures. In this paper, we enhance a state-of-the-art prefix adder synthesis algorithm to obtain a much wider solution space in architectural domain. On top of that, a machine learning based design space exploration methodology is applied to predict the Pareto frontier of the adders in physical domain, which is infeasible by exhaustively running EDA tools for innumerable architectural solutions. Experimental results demonstrate that our framework can achieve near-optimal delay vs. power/area Pareto frontier over a wide design space, bridging the gap between architeon the set of available prefix adder architectures. In this paper, we enhance a state-of-the-art prefix adder synthesis algorithm to obtain a much wider solution space in architectural domain. On top of that, a machine learning based design space exploration methodology is applied to predict the Pareto frontier of the adders in physical domain, which is infeasible by exhaustively running EDA tools for innumerable architectural solutions. Experimental results demonstrate that our framework can achieve near-optimal delay vs. power/area Pareto frontier over a wide design space, bridging the gap between architectural andctural and physical designs.","","978-1-5090-6023-8","10.1109/ISLPED.2017.8009168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8009168","","Adders;Physical design;Algorithm design and analysis;Tools;Delays;Machine learning algorithms","adders;electronic design automation;learning (artificial intelligence)","learning bridge;architectural synthesis;power efficient high-performance adders;modern electronic design automation tools;physical design flow;VLSI industry;prefix adder architectures;machine learning;design space exploration methodology;Pareto frontier;design space","","4","","26","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Heuristically-Accelerated Multiagent Reinforcement Learning","R. A. C. Bianchi; M. F. Martins; C. H. C. Ribeiro; A. H. R. Costa","Department of Electrical Engineering, Centro Universitário da FEI, São Bernardo do Campo, Brazil; Department of Electrical Engineering, Centro Universitário da FEI, São Bernardo do Campo, Brazil; Computer Science Division, Technological Institute of Aeronautics, São José dos Campos, Brazil; Escola Politécnica, Universidade of São Paulo, São Paulo, Brazil","IEEE Transactions on Cybernetics","14 Jan 2014","2014","44","2","252","265","This paper presents a novel class of algorithms, called Heuristically-Accelerated Multiagent Reinforcement Learning (HAMRL), which allows the use of heuristics to speed up well-known multiagent reinforcement learning (RL) algorithms such as the Minimax-Q. Such HAMRL algorithms are characterized by a heuristic function, which suggests the selection of particular actions over others. This function represents an initial action selection policy, which can be handcrafted, extracted from previous experience in distinct domains, or learnt from observation. To validate the proposal, a thorough theoretical analysis proving the convergence of four algorithms from the HAMRL class (HAMMQ, HAMQ(λ), HAMQS, and HAMS) is presented. In addition, a comprehensive systematical evaluation was conducted in two distinct adversarial domains. The results show that even the most straightforward heuristics can produce virtually optimal action selection policies in much fewer episodes, significantly improving the performance of the HAMRL over vanilla RL algorithms.","2168-2275","","10.1109/TCYB.2013.2253094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6502216","Artificial intelligence;heuristic algorithms;machine learning;multiagent systems","","learning (artificial intelligence);multi-agent systems","heuristically accelerated multiagent reinforcement learning;HAMRL algorithms;heuristic function;systematical evaluation;virtually optimal action selection","Algorithms;Artificial Intelligence;Biomimetics;Computer Simulation;Models, Theoretical;Reinforcement (Psychology)","53","","39","IEEE","15 Apr 2013","","","IEEE","IEEE Journals"
"Model Change Detection With the MDL Principle","K. Yamanishi; S. Fukushima","Graduate School of Information Science and Technologies, The University of Tokyo, Tokyo, Japan; Graduate School of Information Science and Technologies, The University of Tokyo, Tokyo, Japan","IEEE Transactions on Information Theory","16 Aug 2018","2018","64","9","6115","6126","We are concerned with the issue of detecting model changes in probability distributions. We specifically consider the strategies based on the minimum description length (MDL) principle. We theoretically analyze their basic performance from the two aspects: data compression and hypothesis testing. From the view of data compression, we derive a new bound on the minimax regret for model changes. Here, the mini-max regret is defined as the minimum of the worst-case code-length relative to the least normalized maximum likelihood code-length over all model changes. From the view of hypothesis testing, we reduce the model change detection into a simple hypothesis testing problem. We thereby derive upper bounds on error probabilities for the MDL-based model change test. The error probabilities are valid for finite sample size and are related to the information-theoretic complexity as well as the discrepancy measure of the hypotheses to be tested.","1557-9654","","10.1109/TIT.2018.2852747","JST CREST(grant numbers:JPMJCR1304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403258","MDL principle;change detection;hypothesis testing;machine learning","Error probability;Testing;Analytical models;Hidden Markov models;Data models;Prediction algorithms;Data compression","data compression;maximum likelihood estimation;minimax techniques;probability","model change detection;probability distributions;minimum description length principle;data compression;minimax regret;worst-case code-length;normalized maximum likelihood code-length;simple hypothesis testing problem;error probabilities;MDL-based model change test","","8","","40","IEEE","4 Jul 2018","","","IEEE","IEEE Journals"
"Multiagent Multi-Armed Bandit Schemes for Gateway Selection in UAV Networks","S. Hashima; K. Hatano; E. M. Mohamed","Computational Learning Theory Team, RIKEN-Advanced Intelligent Project,Japan,819-0395; Computational Learning Theory Team, RIKEN-Advanced Intelligent Project,Japan,819-0395; Prince Sattam Bin Abdulaziz University,College of Engineering,Electrical Engineering Dept,Wadi Addwasir,Saudi Arabia,11991","2020 IEEE Globecom Workshops (GC Wkshps","5 Mar 2021","2020","","","1","6","Lately, unmanned aerial vehicles (UAVs) communications acquired great attention because of its weighty new applications, particularly in rescue services. In such a case, access and gateway UAVS are spread to cover and fully support communications over disaster areas where the ground network is malfunctioned or wholly damaged. Each access UAV collects essential information from its assigned area, then flies and transfers it to the nearby gateway UAVs that deliver this collected information to the closest operating ground network. Meanwhile, collisions may occur as two or more access UAVs might target the same gateway UAV. This paper leverages and modifies two multi-armed bandit (MAB) based algorithms, namely, Kullback Leibler upper confidence bound (KLUCB) and minimax optimal stochastic strategy (MOSS) to formulate the gateway UAV selection issue. The issue is modeled as a budget-constrained multiagent MAB (MA-MAB) that maximizes data rates while considering access UAVs' flight battery consumption. Hence, MA battery aware KLUCB (MABA-KLUCB) and battery aware MOSS (MA-BA-MOSS) algorithms are proposed for efficient gateway UAV selection. The proposed MAB algorithms maximize the UAV network's total sum rate over the conventional selection techniques with assuring good convergence performance.","","978-1-7281-7307-8","10.1109/GCWkshps50303.2020.9367568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367568","Multiagent MAB;Machine learning;UAV;Gateway UAV selection;KLUCB;MOSS","Conferences;Stochastic processes;Logic gates;Unmanned aerial vehicles;Data models;Batteries;Convergence","aircraft communication;autonomous aerial vehicles;internetworking;minimax techniques;multi-agent systems;stochastic processes","convergence performance;UAV network total sum rate minimization;MA-MAB-MOSS algorithms;data rate maximization;KLUCB;Kullback Leibler upper confidence bound;MAB based algorithms;UAV flight battery consumption;efficient gateway UAV selection;MA battery aware KLUCB;budget-constrained multiagent MAB;minimax optimal stochastic strategy;multiarmed bandit based algorithms;closest operating ground network;nearby gateway UAVs;disaster areas;unmanned aerial vehicles communications;UAV networks;multiagent multiarmed bandit schemes","","1","","19","","5 Mar 2021","","","IEEE","IEEE Conferences"
"Decision Support System with K-Means Clustering Algorithm for Detecting the Optimal Store Location Based on Social Network Events","M. A. Hamada; L. Naizabayeva","IITU International IT University,Information System Department,Almaty,Kazakhstan; IITU International IT University,Information System Department,Almaty,Kazakhstan","2020 IEEE European Technology and Engineering Management Summit (E-TEMS)","9 Jun 2020","2020","","","1","4","Nowadays, the business market is more complicated and comprises many challenges; it became more competitive and surrounded by high-risk patterns. Seeking for new technologies and adopting innovation is becoming an important and crucial issue to eliminate the complexity of the decision-making process and failure probability. Decision support system (DSS) is a computerized system that encompasses mathematical and analytical models, knowledge base and a user interface to help managers for making better decisions. This research aims to develop a decision support system based on K-means clustering algorithm to detect the optimal store location through social network events. Also, this research explains how to extract data from one social network channel ""Instagram"" using the ""Octoparse API"" as a web data extraction tool. K-means algorithm identifies k- number of centroids, and allocates every data point to the nearest cluster. As a result, we analyzed 12754 posts started on the 1st of January 2019. Cleaned data are transformed using Minimax and K-means algorithms. As an output, we have got json format data file with centres which are placed on the map to provide a better understanding. The Result of this research is a visualized map pointed with places to define the optimal location of a specific store at the selected region. The practical value of this DSS tool is to help users to make a more valuable and accurate decision which lead to a decrease in the probability of ineffective business decision and minimize the business losses.","","978-1-7281-0903-9","10.1109/E-TEMS46250.2020.9111758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9111758","classification model;decision support system;machine learning;optimal store location;social network events;K-means clustering algorithm","Decision support systems;Technological innovation;Social networking (online);Multimedia Web sites;Knowledge based systems;Clustering algorithms;Europe","data integrity;data mining;decision support systems;minimax techniques;pattern clustering;social networking (online);XML","business decision;decision support system;clustering algorithm;optimal store location;social network events;decision-making process;knowledge base;web data extraction tool;social network channel;Instagram;k-means algorithm;minimax algorithm;Octoparse API;business market","","2","","13","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"On Stabilizing Generative Adversarial Training With Noise","S. Jenni; P. Favaro",Universität Bern; Univ. of Bern,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","12137","12145","We present a novel method and analysis to train generative adversarial networks (GAN) in a stable manner. As shown in recent analysis, training is often undermined by the probability distribution of the data being zero on neighborhoods of the data space. We notice that the distributions of real and generated data should match even when they undergo the same filtering. Therefore, to address the limited support problem we propose to train GANs by using different filtered versions of the real and generated data distributions. In this way, filtering does not prevent the exact matching of the data distribution, while helping training by extending the support of both distributions. As filtering we consider adding samples from an arbitrary distribution to the data, which corresponds to a convolution of the data distribution with the arbitrary one. We also propose to learn the generation of these samples so as to challenge the discriminator in the adversarial training. We show that our approach results in a stable and well-behaved training of even the original minimax GAN formulation. Moreover, our technique can be incorporated in most modern GAN formulations and leads to a consistent improvement on several common datasets.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953819","Image and Video Synthesis;Deep Learning","","data handling;learning (artificial intelligence);minimax techniques;neural nets;statistical distributions","data distribution;arbitrary distribution;generative adversarial networks;GAN;probability distribution;data space;generative adversarial training;minimax GAN formulation","","6","","25","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Model-Driven GAN-Based Channel Modeling for IRS-Aided Wireless Communication","Y. Wei; M. -M. Zhao; M. -J. Zhao","College of Information Science and Electronic Engineering, Zhejiang University,Hangzhou,China,310027; College of Information Science and Electronic Engineering, Zhejiang University,Hangzhou,China,310027; College of Information Science and Electronic Engineering, Zhejiang University,Hangzhou,China,310027","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","Intelligent reflecting surface (IRS) is a promising new technology that is able to create a favorable wireless signal propagation environment by collaboratively reconfiguring the passive reflecting elements, yet with low hardware and energy cost. In IRS-aided wireless communication systems, channel modeling is a fundamental task for communication algorithm design and performance optimization, which however is also very challenging since in-depth domain knowledge and technical expertise in radio signal propagations are required, especially for modeling the high-dimensional cascaded base station (BS)-IRS and IRS-user channels (also referred to as the reflected channels). In this paper, we propose a model-driven generative adversarial network (GAN)-based channel modeling framework to autonomously learn the reflected channel distribution, without complex theoretical analysis or data processing. The designed GAN (also named as IRS-GAN) is trained to reach the Nash equilibrium of a minimax game between a generative model and a discriminative model, where the special structure of the reflected channels is incorporated to improve the modeling accuracy. Simulation results are presented to validate the effectiveness of the proposed IRS-GAN framework for IRS-related channel modeling.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685602","National Natural Science Foundation of China(grant numbers:62001417,91938202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685602","Intelligent reflecting surface (IRS);generative adversarial network (GAN);deep learning;channel modeling;multiple-output single-input (MISO)","Wireless communication;Analytical models;Simulation;MISO communication;Generative adversarial networks;Data processing;Nash equilibrium","","","","","","22","","2 Feb 2022","","","IEEE","IEEE Conferences"
"Renewable Scenario Generation Based on Improved Generative Adversarial Networks","K. Wang; M. Ren; T. Qian; X. Li; L. Pei; X. Zhang","State Grid Shaanxi Electric Power Research Institue,Xi'an,China; School of Electrical Engineering, Xi'an Jiaotong University,Xi'an,China; School of Electrical Engineering, Xi'an Jiaotong University,Xi'an,China; Shaanxi Electric Power Trading Center Co., Ltd,Xi'an,China; Shaanxi Electric Power Trading Center Co., Ltd,Xi'an,China; Shaanxi Electric Power Trading Center Co., Ltd,Xi'an,China","2021 IEEE 5th Conference on Energy Internet and Energy System Integration (EI2)","25 Feb 2022","2021","","","3155","3159","With the increasing penetration rate of renewable energy sources in power systems, it is vital to characterize renewables' intrinsic variability and uncertainty. Scenario generation is a key approach which could provide a series of possible power scenarios in the future for the system planner and operator to make decisions. In this paper, a data-driven renewable scenario generation method is proposed, which utilizes improved generative adversarial networks. The minimax normalization method is used to improve the training stability of the model. And after training, the generalization performance of the proposed model is verified. Moreover, several metrics are used to assess the quality of the scenarios. The results show that the proposed model can accurately describe the uncertainty of wind and photovoltaic power.","","978-1-6654-3425-6","10.1109/EI252483.2021.9713244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9713244","scenario generation;renewable energy;neural network;deep learning;generative adversarial networks","Training;Wind energy generation;Photovoltaic systems;Renewable energy sources;Uncertainty;Stochastic processes;System integration","","","","","","15","","25 Feb 2022","","","IEEE","IEEE Conferences"
"Partially Adversarial Learning and Adaptation","J. -T. Chien; Y. -Y. Lyu","National Chiao Tung University,Department of Electrical and Computer Engineering,Hsinchu,Taiwan; National Chiao Tung University,Department of Electrical and Computer Engineering,Hsinchu,Taiwan","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","An image classification system for a specific target domain is usually trained with initialization from a source domain given with a large number of classes, particularly in an application of image recognition. The classes in target domain are usually seen as a subset in source domain. Partial domain adaptation aims to tackle this generalization issue where no labeled data are provided in target domain. This paper presents an adversarial learning for partial domain adaptation where a symmetric metric based on the Wasserstein distance is adopted in an adversarial learning objective. We build a Wasserstein partial transfer network where the Wasserstein adversarial objective is jointly optimized to partially transfer the relevance knowledge from source to target domains. The geometric property for optimal transport is assured to mitigate the gradient vanishing problem in adversarial training. The neural network components for feature extraction, relevance transfer, domain matching and task classification are jointly trained by solving a minimax optimization over multiple objectives. Experiments on image classification show the merits of the proposed partially adversarial domain adaptation over different tasks.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903147","image classification;domain adaptation;deep learning;adversarial learning;partial transfer","Feature extraction;Generative adversarial networks;Gallium nitride;Task analysis;Training;Optimization;Measurement","feature extraction;image classification;image recognition;learning (artificial intelligence);minimax techniques;neural nets","source domain;image recognition;partial domain adaptation;adversarial learning objective;Wasserstein partial transfer network;Wasserstein adversarial objective;domain matching;task classification;partially adversarial domain adaptation;image classification system;target domain;minimax optimization;partially adversarial learning;neural network;feature extraction;relevance transfer","","5","","20","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Transferable Representation Learning with Deep Adaptation Networks","M. Long; Y. Cao; Z. Cao; J. Wang; M. I. Jordan","School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; Department of EECS, Department of Statistics, University of California, Berkeley, Berkeley, CA, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Nov 2019","2019","41","12","3071","3085","Domain adaptation studies learning algorithms that generalize across source domains and target domains that exhibit different distributions. Recent studies reveal that deep neural networks can learn transferable features that generalize well to similar novel tasks. However, as deep features eventually transition from general to specific along the network, feature transferability drops significantly in higher task-specific layers with increasing domain discrepancy. To formally reduce the effects of this discrepancy and enhance feature transferability in task-specific layers, we develop a novel framework for deep adaptation networks that extends deep convolutional neural networks to domain adaptation problems. The framework embeds the deep features of all task-specific layers into reproducing kernel Hilbert spaces (RKHSs) and optimally matches different domain distributions. The deep features are made more transferable by exploiting low-density separation of target-unlabeled data in very deep architectures, while the domain discrepancy is further reduced via the use of multiple kernel learning that enhances the statistical power of kernel embedding matching. The overall framework is cast in a minimax game setting. Extensive empirical evidence shows that the proposed networks yield state-of-the-art results on standard visual domain-adaptation benchmarks.","1939-3539","","10.1109/TPAMI.2018.2868685","National Key R&D Program of China(grant numbers:2016YFB1000701); National Natural Science Foundation of China(grant numbers:61772299,71690231,61502265); DARPA Program on Lifelong Learning Machines; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454781","Domain adaptation;deep learning;convolutional neural network;two-sample test;multiple kernel learning","Task analysis;Learning systems;Adaptation models;Convolutional neural networks;Deep learning","convolutional neural nets;feature extraction;game theory;generalisation (artificial intelligence);Hilbert spaces;learning (artificial intelligence);minimax techniques","deep features;feature transferability;domain discrepancy;deep adaptation networks;deep convolutional neural networks;domain distributions;deep architectures;multiple kernel learning;transferable representation learning;deep neural networks;transferable feature learning;visual domain-adaptation;learning algorithms;generalization;reproducing kernel Hilbert spaces;kernel embedding matching;minimax game","","120","","56","IEEE","5 Sep 2018","","","IEEE","IEEE Journals"
"Unsupervised Visual Domain Adaptation: A Deep Max-Margin Gaussian Process Approach","M. Kim; P. Sahu; B. Gholami; V. Pavlovic","SeoulTech, Rutgers Univ.; Rutgers Univ.; Rutgers Univ.; Rutgers Univ.","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","4375","4385","For unsupervised domain adaptation, the target domain error can be provably reduced by having a shared input representation that makes the source and target domains indistinguishable from each other. Very recently it has been shown that it is not only critical to match the marginal input distributions, but also align the output class distributions. The latter can be achieved by minimizing the maximum discrepancy of predictors. In this paper, we take this principle further by proposing a more systematic and effective way to achieve hypothesis consistency using Gaussian processes (GP). The GP allows us to induce a hypothesis space of classifiers from the posterior distribution of the latent random functions, turning the learning into a large-margin posterior separation problem, significantly easier to solve than previous approaches based on adversarial minimax optimization. We formulate a learning objective that effectively influences the posterior to minimize the maximum discrepancy. This is shown to be equivalent to maximizing margins and minimizing uncertainty of the class predictions in the target domain. Empirical results demonstrate that our approach leads to state-to-the-art performance superior to existing methods on several challenging benchmarks for domain adaptation.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953535","Deep Learning;Recognition: Detection;Categorization;Retrieval; Statistical Learning","","Gaussian processes;image classification;image representation;minimax techniques;minimisation;neural nets;random processes;statistical distributions;unsupervised learning","uncertainty minimization;class predictions;unsupervised visual domain adaptation;deep max-margin Gaussian process approach;unsupervised domain adaptation;target domain error;shared input representation;marginal input distributions;output class distributions;maximum discrepancy;hypothesis consistency;Gaussian processes;GP;posterior distribution;latent random functions;large-margin posterior separation problem;adversarial minimax optimization;learning objective;hypothesis space","","16","1","71","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Leveraging the Invariant Side of Generative Zero-Shot Learning","J. Li; M. Jing; K. Lu; Z. Ding; L. Zhu; Z. Huang",Univ. of Electronic Science and Technology of China; Univ. of Electronic Science and Technology of China; Univ. of Electronic Science and Technology of China; Indiana Univ.-Purdue Univ. Indianapolis; Shandong Normal Unversity; Univ. of Queensland,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","7394","7403","Conventional zero-shot learning (ZSL) methods generally learn an embedding, e.g., visual-semantic mapping, to handle the unseen visual samples via an indirect manner. In this paper, we take the advantage of generative adversarial networks (GANs) and propose a novel method, named leveraging invariant side GAN (LisGAN), which can directly generate the unseen features from random noises which are conditioned by the semantic descriptions. Specifically, we train a conditional Wasserstein GANs in which the generator synthesizes fake unseen features from noises and the discriminator distinguishes the fake from real via a minimax game. Considering that one semantic description can correspond to various synthesized visual samples, and the semantic description, figuratively, is the soul of the generated features, we introduce soul samples as the invariant side of generative zero-shot learning in this paper. A soul sample is the meta-representation of one class. It visualizes the most semantically-meaningful aspects of each sample in the same category. We regularize that each generated sample (the varying side of generative ZSL) should be close to at least one soul sample (the invariant side) which has the same class label with it. At the zero-shot recognition stage, we propose to use two classifiers, which are deployed in a cascade way, to achieve a coarse-to-fine result. Experiments on five popular benchmarks verify that our proposed approach can outperform state-of-the-art methods with significant improvements.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953480","Recognition: Detection;Categorization;Retrieval;Deep Learning ; Image and Video Synthesis","","computer vision;image recognition;image representation;learning (artificial intelligence);neural nets;object recognition","conditional Wasserstein GANs;semantic description;generative zero-shot learning;generative ZSL;zero-shot recognition stage;zero-shot learning methods;visual-semantic mapping;generative adversarial networks;leveraging invariant side GAN","","62","","40","","9 Jan 2020","","","IEEE","IEEE Conferences"
"ACQUA: Adaptive and cooperative quality-aware control for automotive cyber-physical systems","K. Vatanpavar; M. A. Al Faruque","Henry Samueli School of Engineering, EECS Department, University of California, Irvine, Irvine, California, USA; Henry Samueli School of Engineering, EECS Department, University of California, Irvine, Irvine, California, USA","2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","14 Dec 2017","2017","","","193","200","Controllers in cyber-physical systems integrate a design-time behavioral model of the system under design to improve their own quality. In the state-of-the-art control designs, behavioral models of other interacting neighbor systems are also integrated to form a centralized behavioral model and to enable a system-level optimization and control. Although this ideal embedded control design may result in pareto-optimal solutions, it is not scalable to larger number of systems. Moreover, the behavior of the multi-domain physical systems may be too complex for a control designer to model and may dynamically change at run time. In this paper, we propose a novel Adaptive and Cooperative Quality-Aware (ACQUA) control design which addresses these challenges. In this control design, an ACQUA-based controller for the system under design will monitor the quality of the neighbor systems to dynamically learn their behavior. Therefore, it can quickly adapt its control to cooperate with other neighbor controllers for improving the quality of not only itself, but also other neighbor systems. We apply ACQUA to design a cooperative controller for automotive navigation system, motor control unit, and battery management system in an electric vehicle. We use this automotive example to analyze the performance of the design. We show that by using our ACQUA control, we can reach up to 86% improvements achievable by an ideal embedded control design such that energy consumption reduces by 18% and battery capacity loss decreases by 12% compared to the state-of-the-art on average.","1558-2434","978-1-5386-3093-8","10.1109/ICCAD.2017.8203778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8203778","CPS;Automotive;Electric Vehicle;Regression Modeling;Machine Learning;Model Predictive Control;Power Optimization","Batteries;Mathematical model;Control design;Electric motors;Automotive engineering;Energy consumption","automotive engineering;control system synthesis;cyber-physical systems;electric vehicles;embedded systems;optimisation","battery management system;ACQUA control;ideal embedded control design;adaptive and cooperative quality-aware control;motor control unit;automotive navigation system;multidomain physical systems;system-level optimization;centralized behavioral model;interacting neighbor systems;automotive cyber-physical systems","","1","","32","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Dual-Objective Mixed Integer Linear Program and Memetic Algorithm for an Industrial Group Scheduling Problem","Z. Zhao; S. Liu; M. Zhou; A. Abusorrah","State Key Laboratory of Synthetical Automation for Process Industries and the College of Information Science and Engineering, Northeastern University,Shenyang,China,110819; State Key Laboratory of Synthetical Automation for Process Industries and the College of Information Science and Engineering, Northeastern University,Shenyang,China,110819; New Jersey Institute of Technology,Department of Electrical and Computer Engineering,Newark,NJ,USA,07102; Faculty of Engineering, and Center of Research Excellence in Renewable Energy and Power Systems, King Abdulaziz University,Department of Electrical and Computer Engineering,Jeddah,Saudi Arabia,21481","IEEE/CAA Journal of Automatica Sinica","11 May 2021","2021","8","6","1199","1209","Group scheduling problems have attracted much attention owing to their many practical applications. This work proposes a new bi-objective serial-batch group scheduling problem considering the constraints of sequence-dependent setup time, release time, and due time. It is originated from an important industrial process, i.e., wire rod and bar rolling process in steel production systems. Two objective functions, i.e., the number of late jobs and total setup time, are minimized. A mixed integer linear program is established to describe the problem. To obtain its Pareto solutions, we present a memetic algorithm that integrates a population-based nondominated sorting genetic algorithm II and two single-solution-based improvement methods, i.e., an insertion-based local search and an iterated greedy algorithm. The computational results on extensive industrial data with the scale of a one-week schedule show that the proposed algorithm has great performance in solving the concerned problem and outperforms its peers. Its high accuracy and efficiency imply its great potential to be applied to solve industrial-size group scheduling problems.","2329-9274","","10.1109/JAS.2020.1003539","China Scholarship Council; National Key Research and Development Program of China(grant numbers:2017YFB0306400); National Natural Science Foundation of China(grant numbers:62073069); Deanship of Scientific Research (DSR) at King Abdulaziz University(grant numbers:RG-48-135-40); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310662","Insertion-based local search;iterated greedy algorithm;machine learning;memetic algorithm;nondominated sorting genetic algorithm II (NSGA-II);production scheduling","Job shop scheduling;Single machine scheduling;Steel;Memetics;Task analysis;Linear programming;Sorting","genetic algorithms;greedy algorithms;integer programming;linear programming;minimisation;Pareto optimisation;scheduling;search problems;single machine scheduling;sorting","industrial-size group scheduling problems;concerned problem;one-week schedule show;extensive industrial data;iterated greedy algorithm;insertion-based local search;single-solution-based improvement methods;genetic algorithm II;population-based;total setup time;steel production systems;bar rolling process;wire rod;important industrial process;release time;sequence-dependent setup time;bi-objective serial-batch group scheduling problem;industrial group scheduling problem;memetic algorithm;dual-objective mixed integer linear program","","14","","66","","29 Dec 2020","","","IEEE","IEEE Journals"
"Automatic Decision Making for Parameters in Kernel Method","Y. Pei","University of Aizu,Computer Science Division,Aizu-wakamatsu Fukushima,Japan,965-8580","2019 IEEE Symposium Series on Computational Intelligence (SSCI)","20 Feb 2020","2019","","","3207","3214","We propose to use the relationship between the parameter of kernel function and its decisional angle or distance metrics for selecting the optimal setting of the parameter of kernel functions in kernel method-based algorithms. Kernel method is established in the reproducing kernel Hilbert space, the angle and distance are two metrics in such space. We analyse and investigate the relationship between the parameter of kernel function and the metrics (distance or angle) in the reproducing kernel Hilbert space. We design a target function of optimization to model the relationship between these two variables, and found that (1) the landscape shapes of parameter and the metrics are the same in Gaussian kernel function because the norm of all the vectors are equal to one in reproducing kernel Hilbert space; (2) the landscape monotonicity of that are opposite in polynomial kernel function from that of Gaussian kernel. The monotonicity of designed target functions of optimization using Gaussian kernel and polynomial kernel is different as well. The distance metric and angle metric have different distribution characteristics for the decision of parameter setting in kernel function. It needs to balance these two metrics when selecting a proper parameter of the kernel function in kernel-based algorithms. We use evolutionary multi-objective optimization algorithms to obtain the Pareto solutions for optimal selection of the parameter in kernel functions. We found that evolutionary multi-objective optimization algorithms are useful tools to balance the distance metric and angle metric in the decision of parameter setting in kernel method-based algorithms.","","978-1-7281-2485-8","10.1109/SSCI44817.2019.9002691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9002691","kernel method;kernel function;reproducing kernel Hilbert space;machine learning;decision making;evolutionary multi-objective optimization","Kernel;Nickel;Optimization;Hilbert space;Machine learning algorithms;Data models","decision making;evolutionary computation;Gaussian processes;Hilbert spaces;Pareto optimisation;polynomials","decisional angle;kernel method-based algorithms;kernel Hilbert space;Gaussian kernel function;polynomial kernel function;automatic decision making;distance metrics;landscape monotonicity;evolutionary multi-objective optimization algorithms;Pareto solutions","","2","","12","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Fast and Accurate PPA Modeling with Transfer Learning","W. R. Davis; P. Franzon; L. Francisco; B. Huggins; R. Jain","North Carolina State University,Department of Electrical and Computer Engineering,Raleigh,NC,USA; North Carolina State University,Department of Electrical and Computer Engineering,Raleigh,NC,USA; North Carolina State University,Department of Electrical and Computer Engineering,Raleigh,NC,USA; North Carolina State University,Department of Electrical and Computer Engineering,Raleigh,NC,USA; Qualcomm,San Diego,CA,USA","2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)","23 Dec 2021","2021","","","1","8","The power, performance and area (PPA) of digital blocks can vary 10:1 based on their synthesis, place, and route tool recipes. With rapid increase in number of PVT corners and complexity of logic functions approaching 10M gates, industry has an acute need to minimize the human resources, compute servers, and EDA licenses needed to achieve a Pareto optimal recipe. We first present models for fast accurate PPA prediction that can reduce the manual optimization iterations with EDA tools. Secondly we investigate techniques to automate the PPA optimization using evolutionary algorithms. For PPA prediction, a baseline model is trained on a known design using Latin hypercube sample runs of the EDA tool, and transfer learning is then used to train the model for an unseen design. For a known design the baseline needed 150 training runs to achieve a 95% accuracy. With transfer learning the same accuracy was achieved on a different (unseen) design in only 15 runs indicating the viability of transfer learning to generalize PPA models. The PPA optimization technique, based on evolutionary algorithms, effectively combines the PPA modeling and optimization. Our approach reached the same PPA solution as human designers in the same or fewer runs for a CORTEX-M0 system design. This shows potential for automating the recipe optimization without needing more runs than a human designer would need.","1558-2434","978-1-6654-4507-8","10.1109/ICCAD51958.2021.9643533","National Science Foundation(grant numbers:CNS 16-244770); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643533","PPA;Machine Learning;Power;Performance;Area;Gradient Boost;Neural Network;Transfer Learning;Surrogate Modeling","Training;Computational modeling;Transfer learning;Evolutionary computation;Predictive models;Logic gates;Data models","","","","","","18","","23 Dec 2021","","","IEEE","IEEE Conferences"
"PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning","R. Roy; J. Raiman; N. Kant; I. Elkin; R. Kirby; M. Siu; S. Oberman; S. Godil; B. Catanzaro","NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA; NVIDIA,Santa Clara,CA,USA","2021 58th ACM/IEEE Design Automation Conference (DAC)","8 Nov 2021","2021","","","853","858","In this work, we present a reinforcement learning (RL) based approach to designing parallel prefix circuits such as adders or priority encoders that are fundamental to high-performance digital design. Unlike prior methods, our approach designs solutions tabula rasa purely through learning with synthesis in the loop. We design a grid-based state-action representation and an RL environment for constructing legal prefix circuits. Deep Convolutional RL agents trained on this environment produce prefix adder circuits that Pareto-dominate existing baselines with up to 16.0% and 30.2% lower area for the same delay in the 32b and 64b settings respectively. We observe that agents trained with open-source synthesis tools and cell library can design adder circuits that achieve lower area and delay than commercial tool adders in an industrial cell library.","0738-100X","978-1-6654-3274-0","10.1109/DAC18074.2021.9586094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9586094","machine learning;reinforcement learning;datapath optimization","Training;Machine learning algorithms;Reinforcement learning;Tools;Libraries;Delays;Task analysis","adders;learning (artificial intelligence);logic design","parallel prefix circuits;deep reinforcement learning;reinforcement learning based approach;priority encoders;high-performance digital design;approach designs solutions tabula rasa;grid-based state-action representation;RL environment;legal prefix circuits;Convolutional RL agents;prefix adder circuits;commercial tool adders","","1","","27","","8 Nov 2021","","","IEEE","IEEE Conferences"
"Multi-Objective Learning of Multi-Dimensional Bayesian Classifiers","J. D. Rodríguez; J. A. Lozano","Dept. of Comput. Sci. & Artificial Intell., Univ. of the Basque Country, San Sebastian; Dept. of Comput. Sci. & Artificial Intell., Univ. of the Basque Country, San Sebastian","2008 Eighth International Conference on Hybrid Intelligent Systems","19 Sep 2008","2008","","","501","506","Multi-dimensional classification is a generalization of supervised classification that considers more than one class variable to classify. In this paper we review the existing multi-dimensional Bayesian classifiers and introduce a new one: the KDB multi-dimensional classifier. Then we define different classification rules for multi-dimensional scope. Finally, we introduce a structural learning approach of a multi-dimensional Bayesian classifier based on the multi-objective evolutionary algorithm NSGA-II. The solution of the learning approach is a Pareto front representing different multi-dimensional classifiers and their accuracy values for the different classes, so a decision maker can easily choose the classifier which is more interesting for the particular problem and domain.","","978-0-7695-3326-1","10.1109/HIS.2008.143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4626679","Machine Learning;multi-dimensional classification;Bayesian classifiers;multi-objective;NSGA-II","Bayesian methods;Classification algorithms;Accuracy;Joints;Optimization;Diseases;Classification tree analysis","Bayes methods;decision making;evolutionary computation;generalisation (artificial intelligence);learning (artificial intelligence);Pareto optimisation;pattern classification","multiobjective learning;multidimensional Bayesian classifiers;supervised classification generalization;KDB multidimensional classifier;structural learning approach;multiobjective evolutionary algorithm;NSGA-II;Pareto front;decision making","","16","","12","","19 Sep 2008","","","IEEE","IEEE Conferences"
"Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces","B. Moons; P. Noorzad; A. Skliar; G. Mariani; D. Mehta; C. Lott; T. Blankevoort",Qualcomm AI Research; Qualcomm AI Research; Qualcomm AI Research; Qualcomm AI Research; Qualcomm AI Research; Qualcomm AI Research; Qualcomm AI Research,"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","12209","12218","Current state-of-the-art Neural Architecture Search (NAS) methods neither efficiently scale to multiple hardware platforms, nor handle diverse architectural search-spaces. To remedy this, we present DONNA (Distilling Optimal Neural Network Architectures), a novel pipeline for rapid, scalable and diverse NAS, that scales to many user scenarios. DONNA consists of three phases. First, an accuracy predictor is built using blockwise knowledge distillation from a reference model. This predictor enables searching across diverse networks with varying macro-architectural parameters such as layer types and attention mechanisms, as well as across micro-architectural parameters such as block repeats and expansion rates. Second, a rapid evolutionary search finds a set of pareto-optimal architectures for any scenario using the accuracy predictor and on-device measurements. Third, optimal models are quickly fine-tuned to training-from-scratch accuracy. DONNA is up to 100× faster than MNasNet in finding state-of-the-art architectures on-device. Classifying ImageNet, DONNA architectures are 20% faster than EfficientNet-B0 and Mo-bileNetV2 on a Nvidia V100 GPU and 10% faster with 0.5% higher accuracy than MobileNetV2-1.4x on a Samsung S20 smartphone. In addition to NAS, DONNA is used for search-space extension and exploration, as well as hardware-aware model compression.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710864","Machine learning architectures and formulations; Efficient training and inference methods; Optimization and learning methods; Recognition and classification; Segmentation;grouping and shape","Knowledge engineering;Computer vision;Image coding;Pipelines;Neural networks;Graphics processing units;Computer architecture","","","","","","43","","28 Feb 2022","","","IEEE","IEEE Conferences"
"Probabilistic Sequential Multi-Objective Optimization of Convolutional Neural Networks","Z. Yin; W. Gross; B. H. Meyer","McGill University,Montreal; McGill University,Montreal; McGill University,Montreal","2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)","15 Jun 2020","2020","","","1055","1060","With the advent of deeper, larger and more complex convolutional neural networks (CNN), manual design has become a daunting task, especially when hardware performance must be optimized. Sequential model-based optimization (SMBO) is an efficient method for hyperparameter optimization on highly parameterized machine learning (ML) algorithms, able to find good configurations with a limited number of evaluations by predicting the performance of candidates before evaluation. A case study on MNIST shows that SMBO regression model prediction error significantly impedes search performance in multi-objective optimization. To address this issue, we propose probabilistic SMBO, which selects candidates based on probabilistic estimation of their Pareto efficiency. With a formulation that incorporates error in accuracy prediction and uncertainty in latency measurement, probabilistic Pareto efficiency quantifies a candidate's quality in two ways: its likelihood of being Pareto optimal, and the expected number of current Pareto optimal solutions that it will dominate. We evaluate our proposed method on four image classification problems. Compared to a deterministic approach, probabilistic SMBO consistently generates Pareto optimal solutions that perform better, and that are competitive with state-of-the-art efficient CNN models, offering tremendous speedup in inference latency while maintaining comparable accuracy.","1558-1101","978-3-9819263-4-7","10.23919/DATE48585.2020.9116535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116535","","Probabilistic logic;Pareto optimization;Training;Prediction algorithms;Measurement uncertainty;Task analysis","convolutional neural nets;learning (artificial intelligence);Pareto optimisation;probability;regression analysis","SMBO regression model prediction error;probabilistic SMBO;probabilistic estimation;probabilistic Pareto efficiency;probabilistic sequential multiobjective optimization;convolutional neural networks;sequential model-based optimization;hyperparameter optimization;parameterized machine learning algorithms;CNN models","","2","","32","","15 Jun 2020","","","IEEE","IEEE Conferences"
"Learning with Privileged Tasks","Y. Song; Z. Lou; S. You; E. Yang; F. Wang; C. Qian; C. Zhang; X. Wang","University of California San Diego; SenseTime Research; SenseTime Research; Xidian University; University of Science and Technology of China; SenseTime Research; Tsinghua University Institute for Artificial Intelligence, Tsinghua University (THUAI) Beijing National Research Center for Information Science and Technology (BNRist),Department of Automation; SenseTime Research","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","10665","10674","Multi-objective multi-task learning aims to boost the performance of all tasks by leveraging their correlation and conflict appropriately. Nevertheless, in real practice, users may have preference for certain tasks, and other tasks simply serve as privileged or auxiliary tasks to assist the training of target tasks. The privileged tasks thus possess less or even no priority in the final task assessment by users. Motivated by this, we propose a privileged multiple descent algorithm to arbitrate the learning of target tasks and privileged tasks. Concretely, we introduce a privileged parameter so that the optimization direction does not necessarily follow the gradient from the privileged tasks, but concentrates more on the target tasks. Besides, we also encourage a priority parameter for the target tasks to control the potential distraction of optimization direction from the privileged tasks. In this way, the optimization direction can be more aggressively determined by weighting the gradients among target and privileged tasks, and thus highlight more the performance of target tasks under the unified multi-task learning context. Extensive experiments on synthetic and real-world datasets indicate that our method can achieve versatile Pareto solutions under varying preference for the target tasks.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01051","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710687","Machine learning architectures and formulations; Recognition and classification","Training;Analytical models;Adaptation models;Computer vision;Correlation;Computational modeling;Multitasking","","","","","","52","","28 Feb 2022","","","IEEE","IEEE Conferences"
"Substituting Convolutions for Neural Network Compression","E. J. Crowley; G. Gray; J. Turner; A. Storkey","School of Engineering, The University of Edinburgh, Edinburgh, U.K.; Vector Institute, University of Toronto, Toronto, Canada; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.","IEEE Access","14 Jun 2021","2021","9","","83199","83213","Many practitioners would like to deploy deep, convolutional neural networks in memory-limited scenarios, e.g., on an embedded device. However, with an abundance of compression techniques available it is not obvious how to proceed; many bring with them additional hyperparameter tuning, and are specific to particular network types. In this paper, we propose a simple compression technique that is general, easy to apply, and requires minimal tuning. Given a large, trained network, we propose (i) substituting its expensive convolutions with cheap alternatives, leaving the overall architecture unchanged; (ii) treating this new network as a student and training it with the original as a teacher through distillation. We demonstrate this approach separately for (i) networks predominantly consisting of full 3 ×3 convolutions and (ii) 1 ×1 or pointwise convolutions which together make up the vast majority of contemporary networks. We are able to leverage a number of methods that have been developed as efficient alternatives to fully-connected layers for pointwise substitution, allowing us provide Pareto-optimal benefits in efficiency/accuracy.","2169-3536","","10.1109/ACCESS.2021.3086321","Engineering and Physical Sciences Research Council (EPSRC) Scholarship from the Neuroinformatics and Computational Neuroscience Doctoral Training Centre; EPSRC Centre for Doctoral Training in Pervasive Parallelism; Huawei DDMPLab Innovation Research Grant; European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:732204 (Bonseyes)); Swiss State Secretariat for Education, Research and Innovation (SERI)(grant numbers:16.0159); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446890","Machine learning;deep neural networks;computer vision;DNN compression","Computer architecture;Neural networks;Transforms;Training;Tuning;Tensors;Technological innovation","computer vision;convolutional neural nets;data compression;image coding;Pareto optimisation","memory-limited scenarios;compression techniques;hyperparameter tuning;compression technique;pointwise convolutions;contemporary networks;pointwise substitution;neural network compression;deep networks;convolutional neural networks;Pareto-optimal benefits;computer vision","","","","73","CCBY","4 Jun 2021","","","IEEE","IEEE Journals"
"Towards Organization Management Using Exploratory Screening and Big Data Tests: A Case Study of the Spanish Red Cross","M. Rodríguez-Ibáñez; S. Muñoz-Romero; C. Soguero-Ruiz; F. Gimeno-Blanes; J. L. Rojo-Álvarez","Department of Business Economics, Universidad Rey Juan Carlos, Madrid, Spain; Department of Business Economics, Universidad Rey Juan Carlos, Madrid, Spain; Department of Signal Theory and Communications, Universidad Rey Juan Carlos, Madrid, Spain; Department of Communications Engineering, Universidad Miguel Hernández, Elche, Spain; Department of Business Economics, Universidad Rey Juan Carlos, Madrid, Spain","IEEE Access","28 Jun 2019","2019","7","","80661","80674","With the emergence of information and communication technologies, a large amount of data has turned available for the organizations, which creates expectations on their value and content for management purposes. However, the exploratory analysis of available organizational data based on emerging Big Data technologies are still developing in terms of operative tools for solid and interpretable data description. In this work, we addressed the exploratory analysis of organization databases at early stages where little quantitative information is available about their efficiency. Categorical and metric single-variable tests are proposed and formalized in order to provide a mass criterion to identify regions in forms with clusters of significant variables. Bootstrap resampling techniques are used to provide nonparametric criteria in order to establish easy-to-use statistical tests, so that single-variable tests are represented each on a visual and quantitative statistical plot, whereas all the variables in a given form are jointly visualized in the so-called chromosome plots. More detailed profile plots offer deep comparison knowledge for categorical variables across the organization physical and functional structures, while histogram plots for numerical variables incorporate the statistical significance of the variables under study for preselected Pareto groups. Performance grouping is addressed by identifying two or three groups according to some representative empirical distribution of some convenient grouping feature. The method is applied to perform a Big-Data exploratory analysis on the follow-up forms of Spanish Red Cross, based on the number of interventions and on a by-record basis. Results showed that a simple one-variable blind-knowledge exploratory Big-Data analysis, as the one developed in this paper, offers unbiased comparative graphical and numerical information that characterize organizational dynamics in terms of applied resources, available capacities, and productivity. In particular, the graphical and numerical outputs of the present analysis proved to be a valid tool to isolate the underlying overloaded or under-performing resources in complex organizations. As a consequence, the proposed method allows a systematic and principled way for efficiency analysis in complex organizations, which combined with organizational internal knowledge could leverage and validate efficient decision-making.","2169-3536","","10.1109/ACCESS.2019.2923533","FINALE Project(grant numbers:TEC2016-75161-C2-1-R); KERMES Network from Spanish Government(grant numbers:TEC2016-81900-REDT/AEI); DTS(grant numbers:17/00158); Institute of Health Carlos III (Spain); Cruz Roja Española (Spanish Red Cross); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737934","Big Data;machine learning;organization management;organization efficiency;prediction model","Organizations;Databases;Big Data;Data mining;Tools;Measurement;Project management","Big Data;data analysis;data visualisation;decision making;emergency management;humanities;medical computing;organisational aspects;statistical testing","Spanish Red Cross;Big Data technologies;organization databases;bootstrap resampling techniques;statistical tests;quantitative statistical plot;chromosome plots;Big-Data exploratory analysis;Big-Data analysis;organization management;information and communication technologies;data description;exploratory screening;Big Data rests;visual statistical plot;Pareto groups;data visualization","","6","","32","CCBY","17 Jun 2019","","","IEEE","IEEE Journals"
"A Many-Objective Evolutionary Algorithm With Two Interacting Processes: Cascade Clustering and Reference Point Incremental Learning","H. Ge; M. Zhao; L. Sun; Z. Wang; G. Tan; Q. Zhang; C. L. P. Chen","College of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science, McGill Univeristy, Montreal, QC, Canada; College of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Mathematical Sciences, Dalian University of Technology, Dalian, China; College of Computer Science and Technology, Dalian University of Technology, Dalian, China; College of Computer Science and Technology, Dalian University of Technology, Dalian, China; Department of Computer and Information Science, University of Macau, Macau, China","IEEE Transactions on Evolutionary Computation","30 Jul 2019","2019","23","4","572","586","Researches have shown difficulties in obtaining proximity while maintaining diversity for many-objective optimization problems. Complexities of the true Pareto front pose challenges for the reference vector-based algorithms for their insufficient adaptability to the diverse characteristics with no priori. This paper proposes a many-objective optimization algorithm with two interacting processes: cascade clustering and reference point incremental learning (CLIA). In the population selection process based on cascade clustering (CC), using the reference vectors provided by the process based on incremental learning, the nondominated and the dominated individuals are clustered and sorted with different manners in a cascade style and are selected by round-robin for better proximity and diversity. In the reference vector adaptation process based on reference point incremental learning, using the feedbacks from the process based on CC, proper distribution of reference points is gradually obtained by incremental learning. Experimental studies on several benchmark problems show that CLIA is competitive compared with the state-of-the-art algorithms and has impressive efficiency and versatility using only the interactions between the two processes without incurring extra evaluations.","1941-0026","","10.1109/TEVC.2018.2874465","National Natural Science Foundation of China(grant numbers:61572104,61751203,51579040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485382","Clustering;incremental machine learning;interacting processes;many-objective optimization;reference vector","Sociology;Statistics;Optimization;Clustering algorithms;Evolutionary computation;Sun;Complexity theory","evolutionary computation;learning (artificial intelligence);Pareto optimisation;pattern clustering;sorting;vectors","many-objective evolutionary algorithm;interacting processes;reference vector-based algorithms;many-objective optimization algorithm;cascade clustering;population selection process;reference vector adaptation process;reference point incremental learning;round-robin selection;Pareto front","","18","","57","IEEE","8 Oct 2018","","","IEEE","IEEE Journals"
"Algorithmic Performance-Accuracy Trade-off in 3D Vision Applications Using HyperMapper","L. Nardi; B. Bodin; S. Saeedi; E. Vespa; A. J. Davison; P. H. J. Kelly","Dept. of Comput., Imperial Coll. London, London, UK; Inst. for Comput. Syst. Archit., Univ. of Edinburgh, Edinburgh, UK; Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK; Dept. of Comput., Imperial Coll. London, London, UK","2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)","3 Jul 2017","2017","","","1434","1443","In this paper we investigate an emerging application, 3D scene understanding, likely to be significant in the mobile space in the near future. The goal of this exploration is to reduce execution time while meeting our quality of result objectives. In previous work, we showed for the first time that it is possible to map this application to power constrained embedded systems, highlighting that decision choices made at the algorithmic design-level have the most significant impact. As the algorithmic design space is too large to be exhaustively evaluated, we use a previously introduced multi-objective random forest active learning prediction framework dubbed HyperMapper, to find good algorithmic designs. We show that HyperMapper generalizes on a recent cutting edge 3D scene understanding algorithm and on a modern GPU-based computer architecture. HyperMapper is able to beat an expert human hand-tuning the algorithmic parameters of the class of computer vision applications taken under consideration in this paper automatically. In addition, we use crowd-sourcing using a 3D scene understanding Android app to show that the Pareto front obtained on an embedded system can be used to accelerate the same application on all the 83 smart-phones and tablets with speedups ranging from 2x to over 12x.","","978-1-5386-3408-0","10.1109/IPDPSW.2017.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965204","design space exploration;machine learning;computer vision;SLAM;embedded systems;GPU;crowd- sourcing","Algorithm design and analysis;Simultaneous localization and mapping;Three-dimensional displays;Cameras;Benchmark testing;Prediction algorithms;Measurement","Android (operating system);computer vision;embedded systems;learning (artificial intelligence);stereo image processing","3D scene understanding;constrained embedded systems;multiobjective random forest active learning prediction framework;HyperMapper;modern GPU-based computer architecture;computer vision;Android app","","9","","48","","3 Jul 2017","","","IEEE","IEEE Conferences"
"FasTrCaps: An Integrated Framework for Fast yet Accurate Training of Capsule Networks","A. Marchisio; B. Bussolino; A. Colucci; M. A. Hanif; M. Martina; G. Masera; M. Shafique","Technische Universität Wien,Vienna,Austria; Politecnico di Torino,Turin,Italy; Technische Universität Wien,Vienna,Austria; Technische Universität Wien,Vienna,Austria; Politecnico di Torino,Turin,Italy; Politecnico di Torino,Turin,Italy; Technische Universität Wien,Vienna,Austria","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Recently, Capsule Networks (CapsNets) have shown improved performance compared to the traditional Convolutional Neural Networks (CNNs), by encoding and preserving spatial relationships between the detected features in a better way. This is achieved through the so-called Capsules (i.e., groups of neurons) that encode both the instantiation probability and the spatial information. However, one of the major hurdles in the wide adoption of CapsNets is their gigantic training time, which is primarily due to the relatively higher complexity of their new constituting elements that are different from CNNs.In this paper, we implement different optimizations in the training loop of the CapsNets, and investigate how these optimizations affect their training speed and the accuracy. Towards this, we propose a novel framework FasTrCaps that integrates multiple lightweight optimizations and a novel learning rate policy called WarmAdaBatch (that jointly performs warm restarts and adaptive batch size), and steers them in an appropriate way to provide high training-loop speedup at minimal accuracy loss. We also propose weight sharing for capsule layers. The goal is to reduce the hardware requirements of CapsNets by removing unused/redundant connections and capsules, while keeping high accuracy through tests of different learning rate policies and batch sizes. We demonstrate that one of the solutions generated by the FasTrCaps framework can achieve 58.6% reduction in the training time, while preserving the accuracy (even 0.12% accuracy improvement for the MNIST dataset), compared to the CapsNet by Google Brain [25]. Moreover, the Pareto-optimal solutions generated by FasTrCaps can be leveraged to realize trade-offs between training time and achieved accuracy. We have open-sourced our framework on GitHub<sup>1</sup>.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207533","Machine Learning;Capsule Networks;Training;Accuracy;Efficiency;Performance;Weight Sharing;Decoder;Batch Sizing;Adaptivity","Training;Optimization;Decoding;Neurons;Complexity theory;Image reconstruction;Feature extraction","convolutional neural nets;feature extraction;learning (artificial intelligence);Pareto optimisation;probability","training speed;adaptive batch size;CapsNet;learning rate policies;FasTrCaps framework;Pareto-optimal solutions;capsule networks;convolutional neural networks;feature detection;instantiation probability;spatial information;CNN;training loop;spatial relationship encoding;spatial relationship preservation;WarmAdaBatch;capsule layer weight sharing","","4","","34","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Statistical Relational Learning for Game Theory","M. Lippi","Dipartimento di Informatica-Scienza e Ingegneria, Università degli Studi di Bologna, Italy","IEEE Transactions on Computational Intelligence and AI in Games","13 Dec 2016","2016","8","4","412","425","In this paper, we motivate the use of models and algorithms from the area of Statistical Relational Learning (SRL) as a framework for the description and the analysis of games. SRL combines the powerful formalism of first-order logic with the capability of probabilistic graphical models in handling uncertainty in data and representing dependencies between random variables: for this reason, SRL models can be effectively used to represent several categories of games, including games with partial information, graphical games and stochastic games. Inference algorithms can be used to approach the opponent modeling problem, as well as to find Nash equilibria or Pareto optimal solutions. Structure learning algorithms can be applied, in order to automatically extract probabilistic logic clauses describing the strategies of an opponent with a high-level, human-interpretable formalism. Experiments conducted using Markov logic networks, one of the most used SRL frameworks, show the potential of the approach.","1943-0698","","10.1109/TCIAIG.2015.2490279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7297840","Machine learning;probabilistic logic","Games;Game theory;Inference algorithms;Probabilistic logic;Markov random fields;Graphical models","learning (artificial intelligence);Pareto analysis;probabilistic logic;probability;stochastic games;uncertainty handling","statistical relational learning;game theory;SRL;first-order logic;probabilistic graphical models;uncertainty handling;partial information;graphical games;stochastic games;inference algorithms;opponent modeling problem;Nash equilibria;Pareto optimal solutions;logic clauses;high-level formalism;human-interpretable formalism;Markov logic networks","","2","","85","IEEE","13 Oct 2015","","","IEEE","IEEE Journals"
"Practitioner-Centric Approach for Early Incident Detection Using Crowdsourced Data for Emergency Services","Y. Senarath; A. Mukhopadhyay; S. M. Vazirizade; H. Purohit; S. Nannapaneni; A. Dubey","George Mason University,USA; Vanderbilt University,USA; Vanderbilt University,USA; George Mason University,USA; Wichita State University,USA; Vanderbilt University,USA","2021 IEEE International Conference on Data Mining (ICDM)","24 Jan 2022","2021","","","1318","1323","Emergency response is highly dependent on the time of incident reporting. Unfortunately, the traditional approach to receiving incident reports (e.g., calling 911 in the USA) has time delays. Crowdsourcing platforms such as Waze provide an opportunity for early identification of incidents. However, detecting incidents from crowdsourced data streams is difficult due to the challenges of noise and uncertainty associated with such data. Further, simply optimizing over detection accuracy can compromise spatial-temporal localization of the inference, thereby making such approaches infeasible for real-world deployment. This paper presents a novel problem formulation and solution approach for practitioner-centered incident detection using crowdsourced data by using emergency response management as a case-study. The proposed approach CROME (Crowdsourced Multi-objective Event Detection) quantifies the relationship between the performance metrics of incident classification (e.g., F1 score) and the requirements of model practitioners (e.g., 1 km. radius for incident detection). First, we show how crowdsourced reports, ground-truth historical data, and other relevant determinants such as traffic and weather can be used together in a Convolutional Neural Network (CNN) architecture for early detection of emergency incidents. Then, we use a Pareto optimization-based approach to optimize the output of the CNN in tandem with practitioner-centric parameters to balance detection accuracy and spatial-temporal localization. Finally, we demonstrate the applicability of this approach using crowdsourced data from Waze and traffic accident reports from Nashville, TN, USA. Our experiments demonstrate that the proposed approach outperforms existing approaches in incident detection while simultaneously optimizing the needs for real-world deployment and usability.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00164","George Mason University; National Science Foundation; Tennessee Department of Transportation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679106","Crowdsourcing;Emergency Response;Deep Learning;Waze;Multi-Objective Optimization","Location awareness;Uncertainty;Event detection;Pareto optimization;Emergency services;Convolutional neural networks;Data mining","","","","","","10","","24 Jan 2022","","","IEEE","IEEE Conferences"
"HAO: Hardware-aware Neural Architecture Optimization for Efficient Inference","Z. Dong; Y. Gao; Q. Huang; J. Wawrzynek; H. K. H. So; K. Keutzer","University of California,Berkeley; University of California,Berkeley; University of California,Berkeley; University of California,Berkeley; University of California,Berkeley; University of California,Berkeley","2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)","2 Jun 2021","2021","","","50","59","Automatic algorithm-hardware co-design for DNN has shown great success in improving the performance of DNNs on FPGAs. However, this process remains challenging due to the intractable search space of neural network architectures and hardware accelerator implementation. Differing from existing hardware-aware neural architecture search (NAS) algorithms that rely solely on the expensive learning-based approaches, our work incorporates integer programming into the search algorithm to prune the design space. Given a set of hardware resource constraints, our integer programming formulation directly outputs the optimal accelerator configuration for mapping a DNN subgraph that minimizes latency. We use an accuracy predictor for different DNN subgraphs with different quantization schemes and generate accuracy-latency pareto frontiers. With low computational cost, our algorithm can generate quantized networks that achieve state-of-the-art accuracy and hardware performance on Xilinx Zynq (ZU3EG) FPGA for image classification on ImageNet dataset. The solution searched by our algorithm achieves 72.5% top-1 accuracy on ImageNet at framerate 50, which is 60% faster than MnasNet [37] and 135% faster than FBNet [43] with comparable accuracy.","2576-2621","978-1-6654-3555-0","10.1109/FCCM51124.2021.00014","Facebook; Google; Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444059","HW SW Codesign;Quantization;Neural Architecture Optimization;Image Classification;Neural Architecture Search;Efficient Deep Learning","Integer programming;Quantization (signal);Computer architecture;Predictive models;Prediction algorithms;Search problems;Hardware","field programmable gate arrays;image classification;integer programming;learning (artificial intelligence);neural nets;search problems","neural network architectures;hardware accelerator implementation;existing hardware-aware;expensive learning-based approaches;search algorithm;design space;hardware resource constraints;integer programming formulation;optimal accelerator configuration;DNN subgraph;accuracy predictor;different DNN subgraphs;different quantization schemes;accuracy-latency pareto frontiers;hardware performance;hardware-aware neural architecture optimization;automatic algorithm-hardware co-design;intractable search space","","3","","55","","2 Jun 2021","","","IEEE","IEEE Conferences"
"Wiretap Code Design by Neural Network Autoencoders","K. Besser; P. Lin; C. R. Janda; E. A. Jorswieck","Communications Lab, Technische Universität Dresden, Dresden, Germany; Communications Lab, Technische Universität Dresden, Dresden, Germany; Communications Lab, Technische Universität Dresden, Dresden, Germany; Communications Lab, Technische Universität Dresden, Dresden, Germany","IEEE Transactions on Information Forensics and Security","11 May 2020","2020","15","","3374","3386","In industrial machine type communications, an increasing number of wireless devices communicate under reliability, latency, and confidentiality constraints, simultaneously. From information theory, it is known that wiretap codes can asymptotically achieve reliability (vanishing block error rate (BLER) at the legitimate receiver Bob) while also achieving secrecy (vanishing information leakage (IL) to an eavesdropper Eve). However, under finite block length, there exists a tradeoff between the BLER at Bob and the IL at Eve. In this work, we propose a flexible wiretap code design for degraded Gaussian wiretap channels under finite block length, which can change the operating point on the Pareto boundary of the tradeoff between BLER and IL given specific code parameters. To attain this goal, we formulate a multi-objective programming problem, which takes the BLER at Bob and the IL at Eve into account. During training, we approximate the BLER by the mean square error and the IL by schemes based on Jensen's inequality and the Taylor expansion and then solve the optimization problem by neural network autoencoders. Simulation results show that the proposed scheme can find codes outperforming polar wiretap codes (PWC) with respect to both BLER and IL simultaneously. We show that the codes found by the autoencoders could be implemented with real modulation schemes with only small losses in performance.","1556-6021","","10.1109/TIFS.2019.2945619","Deutsche Forschungsgemeinschaft (DFG)(grant numbers:JO801/23-1,LI 2886/2-1); Bundesministerium für Bildung und Forschung (BMBF) FastCloud and FastSecure(grant numbers:03ZZ0517A,03ZZ0522A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859269","Physical layer security;wiretap codes;deep learning;autoencoders","Reliability;Computational modeling;Decoding;Artificial neural networks;Mutual information;Neurons","block codes;Gaussian channels;mean square error methods;neural nets;Pareto optimisation;polar codes","optimization problem;Taylor expansion;Jensen inequality;Pareto boundary;block error rate;confidentiality constraints;wireless devices;industrial machine type communications;polar wiretap codes;neural network autoencoders;mean square error;multiobjective programming problem;specific code parameters;Gaussian wiretap channels;flexible wiretap code design;finite block length;eavesdropper Eve;legitimate receiver Bob;information theory","","14","","51","IEEE","4 Oct 2019","","","IEEE","IEEE Journals"
"Automated Test Input Generation for Convolutional Neural Networks by Implementing Multi-objective Evolutionary Algorithms","L. ZHANG; H. SATO","The University of Tokyo,Department of Electrical Engineering and Information Systems,Tokyo,Japan; The University of Tokyo,Department of Electrical Engineering and Information Systems,Tokyo,Japan","2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW)","22 Feb 2021","2020","","","157","163","Deep Neural Networks (DNNs) have been widely applied in safety- and security-critical aspects, where the robustness of the system is of great significance, especially for corner case inputs. Traditionally, a DNN is tested with manually labeled data, which is not only labor-consuming, but also unable to contain statistically rare case inputs.In our work, we design, implement and evaluate the test input generation framework guided by multi-objective functions. The multi-objective functions are formed from neuron coverage, behavioral divergence and perturbation degree. We leverage evolutionary algorithms (EAs) to resolve such optimization problem by generating approximation to Pareto-optimal solutions. By implementing our framework, we successfully generated more than 6,000 test inputs for a convolutional neural network. And the generated test inputs help to improve the system’s accuracy by up to 4.4%.","","978-1-7281-9919-1","10.1109/CANDARW51189.2020.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9355866","Deep learning testing;Automated test input generation;Evolutionary algorithms","Statistical analysis;Perturbation methods;Neurons;Evolutionary computation;Robustness;Convolutional neural networks;Optimization","evolutionary computation;genetic algorithms;learning (artificial intelligence);neural nets;optimisation;Pareto optimisation;program testing","leverage evolutionary algorithms;6 test inputs;000 test inputs;convolutional neural network;generated test inputs;convolutional Neural Networks;implementing multiobjective evolutionary algorithms;Deep Neural Networks;security-critical aspects;corner case inputs;manually labeled data;labor-consuming;statistically rare case inputs;test input generation framework;multiobjective functions;behavioral divergence;perturbation degree","","","","15","","22 Feb 2021","","","IEEE","IEEE Conferences"
"TEA-DNN: the Quest for Time-Energy-Accuracy Co-optimized Deep Neural Networks","L. Cai; A. Barneche; A. Herbout; C. S. Foo; J. Lin; V. R. Chandrasekhar; M. M. Sabry Aly","I2R, Singapore; SUPELEC, France; ECP, France; I2R, Singapore; I2R, Singapore; I2R, Singapore; NTU, Singapore","2019 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)","5 Sep 2019","2019","","","1","6","Embedded deep learning platforms have witnessed two simultaneous improvements. First, the accuracy of convolutional neural networks (CNNs) has been significantly improved through the use of automated neural-architecture search (NAS) algorithms to determine CNN structure. Second, there has been increasing interest in developing hardware accelerators for CNNs that provide improved inference performance and energy consumption compared to GPUs. Such embedded deep learning platforms differ in the amount of compute resources and memory-access bandwidth, which would affect performance and energy consumption of CNNs. It is therefore critical to consider the available hardware resources in the network architecture search. To this end, we introduce TEA-DNN, a NAS algorithm targeting multi-objective optimization of execution time, energy consumption, and classification accuracy of CNN workloads on embedded architectures. TEA-DNN leverages energy and execution time measurements on embedded hardware when exploring the Pareto-optimal curves across accuracy, execution time, and energy consumption and does not require additional effort to model the underlying hardware. We apply TEA-DNN for image classification on actual embedded platforms (NVIDIA Jetson TX2 and Intel Movidius Neural Compute Stick). We highlight the Pareto-optimal operating points that emphasize the necessity to explicitly consider hardware characteristics in the search process. To the best of our knowledge, this is the most comprehensive study of Pareto-optimal models across a range of hardware platforms using actual measurements on hardware to obtain objective values.","","978-1-7281-2954-9","10.1109/ISLPED.2019.8824934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8824934","Neural architecture search;hardware constraints;multi-objective optimization","Computer architecture;Optimization;Hardware;Microprocessors;Bayes methods;Computational modeling;Network architecture","computer architecture;convolutional neural nets;coprocessors;embedded systems;learning (artificial intelligence);microprocessor chips;multiprocessing systems;Pareto optimisation;performance evaluation;power aware computing","embedded deep learning platforms;convolutional neural networks;CNNs;neural-architecture search algorithms;hardware accelerators;energy consumption;network architecture search;execution time;classification accuracy;embedded architectures;embedded hardware;Pareto-optimal curves;Intel Movidius Neural Compute Stick;Pareto-optimal operating points;hardware characteristics;Pareto-optimal models;hardware platforms;NAS algorithm;TEA-DNN;co-optimized deep neural networks;NVIDIA Jetson TX2","","8","","23","","5 Sep 2019","","","IEEE","IEEE Conferences"
"Optimal v-SVM parameter estimation using multi objective evolutionary algorithms","J. Ethridge; G. Ditzler; R. Polikar","Dept. of Electrical and Computer Engineering at Rowan University and are a part of the Signal Processing & Pattern Recognition Laboratory, Glassboro, NJ, 08028, USA; Dept. of Electrical and Computer Engineering at Rowan University and are a part of the Signal Processing & Pattern Recognition Laboratory, Glassboro, NJ, 08028, USA; Dept. of Electrical and Computer Engineering at Rowan University and are a part of the Signal Processing & Pattern Recognition Laboratory, Glassboro, NJ, 08028, USA","IEEE Congress on Evolutionary Computation","27 Sep 2010","2010","","","1","8","Using a machine learning algorithm for a given application often requires tuning design parameters of the classifier to obtain optimal classification performance without overfitting. In this contribution, we present an evolutionary algorithm based approach for multi-objective optimization of the sensitivity and specificity of a v-SVM. The v-SVM is often preferred over the standard C-SVM due to smaller dynamic range of the v parameter compared to the unlimited dynamic range of the C parameter. Instead of looking for a single optimization result, we look for a set of optimal solutions that lie along the Pareto optimality front. The traditional advantage of using the Pareto optimality is of course the flexibility to choose any of the solutions that lies on the Pareto optimality front. However, we show that simply maximizing sensitivity and specificity over the Pareto front leads to parameters that appear to be mathematically optimal yet still cause overfitting. We propose a multiple objective optimization approach with three objective functions to find additional parameter values that do not cause overfitting.","1941-0026","978-1-4244-6911-6","10.1109/CEC.2010.5586029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5586029","multi-objective optimization;v-SVM;evolutionary algorithms","Optimization;Classification algorithms;Sensitivity and specificity;Kernel;Databases;Support vector machines;Sensitivity","evolutionary computation;learning (artificial intelligence);parameter estimation;Pareto optimisation;pattern classification;support vector machines","optimal v-SVM parameter estimation;multiobjective evolutionary algorithm;machine learning algorithm;Pareto optimality","","3","","17","","27 Sep 2010","","","IEEE","IEEE Conferences"
"Enhancing Cloud Energy Models for Optimizing Datacenters Efficiency","E. Outin; J. Dartois; O. Barais; J. Pazat","b-com, Rennes, France; b-com, Rennes, France; INRIA, Univ. de Rennes 1, Rennes, France; b-com, IRISA, Rennes, France","2015 International Conference on Cloud and Autonomic Computing","29 Oct 2015","2015","","","93","100","Due to high electricity consumption in the Cloud datacenters, providers aim at maximizing energy efficiency through VM consolidation, accurate resource allocation or adjusting VM usage. More generally, the provider attempts to optimize resource utilization. However, while minimizing expenses, the Cloud operator still needs to conform to SLA constraints negotiated with customers (such as latency, downtime, affinity, placement, response time or duplication). Consequently, optimizing a Cloud configuration is a multi-objective problem. As a nontrivial multi-objective optimization problem, there does not exist a single solution that simultaneously optimizes each objective. There exists a (possibly infinite) number of Pareto optimal solutions. Evolutionary algorithms are popular approaches for generating Pareto optimal solutions to a multi-objective optimization problem. Most of these solutions use a fitness function to assess the quality of the candidates. However, regarding the energy consumption estimation, the fitness function can be approximative and lead to some imprecisions compared to the real observed data. This paper presents a system that uses a genetic algorithm to optimize Cloud energy consumption and machine learning techniques to improve the fitness function regarding a real distributed cluster of server. We have carried out experiments on the OpenStack platform to validate our solution. This experimentation shows that the machine learning produces an accurate energy model, predicting precise values for the simulation.","","978-1-4673-9566-3","10.1109/ICCAC.2015.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7312144","Cloud computing;energy efficiency;model","Computational modeling;Servers;Energy consumption;Random access memory;Measurement;Adaptation models;Hardware","cloud computing;computer centres;contracts;cost reduction;energy conservation;genetic algorithms;learning (artificial intelligence);Pareto optimisation;power consumption;resource allocation;virtual machines","cloud energy model;cloud data center efficiency optimization;electricity consumption;energy efficiency maximization;VM consolidation;resource allocation;VM usage adjustment;resource utilization optimization;expense minimization;cloud operation;SLA constraint;latency;downtime;affinity;placement;response time;duplication);cloud configuration optimization;nontrivial multiobjective optimization problem;Pareto optimal solution;evolutionary algorithm;fitness function;energy consumption estimation;genetic algorithm;machine learning technique;distributed server cluster;OpenStack platform","","5","","27","","29 Oct 2015","","","IEEE","IEEE Conferences"
"BEOL stack-aware routability prediction from placement using data mining techniques","W. -T. J. Chan; Y. Du; A. B. Kahng; S. Nath; K. Samadi","ECE Department, UC San Diego, La Jolla, 92093, United States; Qualcomm Research, San Diego, CA, United States; CSE Department, UC San Diego, La Jolla, 92093, United States; CSE Department, UC San Diego, La Jolla, 92093, United States; Qualcomm Research, San Diego, CA, United States","2016 IEEE 34th International Conference on Computer Design (ICCD)","24 Nov 2016","2016","","","41","48","In advanced technology nodes, physical design engineers must estimate whether a standard-cell placement is routable (before invoking the router) in order to maintain acceptable design turnaround time. Modern SoC designs consume multiple compute servers, memory, tool licenses and other resources for several days to complete routing. When the design is unroutable, resources are wasted, which increases the design cost. In this work, we develop machine learning-based models that predict whether a placement solution is routable without conducting trial or early global routing. We also use our models to accurately predict iso-performance Pareto frontiers of utilization, aspect ratio and number of layers in the back-end-of-line (BEOL) stack. Furthermore, using data mining and machine learning techniques, we develop new methodologies to generate training examples given very few placements. We conduct validation experiments in three foundry technologies (28nm FDSOI, 28nm LP and 45nm GS), and demonstrate accuracy ≥ 85.9% in predicting routability of a placement. Our predictions of Pareto frontiers in the three technologies are pessimistic by at most 2% with respect to the maximum achievable utilization for a given design in a given BEOL stack.","","978-1-5090-5142-7","10.1109/ICCD.2016.7753259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753259","","Routing;Metals;Pins;Predictive models;Ciphers;Physical design;Silicon-on-insulator","data mining;learning (artificial intelligence);system-on-chip","BEOL stack-aware routability prediction;data mining;standard-cell placement;SoC designs;compute servers;tool licenses;machine learning-based models;placement solution;early global routing;iso-performance Pareto frontiers;back-end-of-line;foundry technologies","","20","","41","","24 Nov 2016","","","IEEE","IEEE Conferences"
"cSmartML: A Meta Learning-Based Framework for Automated Selection and Hyperparameter Tuning for Clustering","R. ElShawi; H. Lekunze; S. Sakr","University of Tartu,Institute of Computer Science,Tartu,Estonia; University of Tartu,Institute of Computer Science,Tartu,Estonia; University of Tartu,Institute of Computer Science,Tartu,Estonia","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","1119","1126","Novel technologies in automated machine learning ease the complexity of algorithm selection and hyper-parameter optimization. However, these are usually restricted to supervised learning tasks such as classification and regression, while unsupervised learning remains a largely unexplored problem. In this paper, we offer a solution for automating machine learning specifically for the case of unsupervised learning with clustering, in a domain-agnostic manner. This is achieved through a combination of state-of-the-art processes based on meta-learning for algorithm and evaluation criteria selection, and evolutionary algorithm for hyper-parameter tuning. We introduce a robust and scalable interactive tool, named cSmartML, built on scikit-learn with 8 clustering algorithms. In order to capture more than a single measure of goodness of the output clustering solution, cSmartML optimizes multiple objective functions. A pareto-approach evaluates each objective simultaneously for each clustering solution. On each of the 27 real and synthetic benchmark datasets, we show that the performance of cSmartML is often much better than using standard selection and hyper-parameter optimization methods. In addition, experimentation reveals that cSmartML takes advantage of the defined objective functions on multi-objective functions framework.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671542","European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671542","clustering;meta-learning;hyper-parameter optimization","Machine learning algorithms;Supervised learning;Clustering algorithms;Machine learning;Big Data;Linear programming;Classification algorithms","","","","","","51","","13 Jan 2022","","","IEEE","IEEE Conferences"
"Clockwork: Scheduling Cloud Requests in Mobile Applications","Y. Chen; Z. Yu; B. Li","State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China; State Key Lab. of Software Eng., Wuhan Univ., Wuhan, China; Dept. of Electr. & Comput. Eng., Univ. of Toronto, Toronto, ON, Canada","2017 14th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)","3 Jul 2017","2017","","","1","9","It is essential for mobile application developers to manage backend resources to serve dynamic user requests from the frontend. For a typical mobile application, the rate at which the user requests arrive at the backend fluctuates dramatically. However, it is difficult or expensive to frequently adjust the capacity of the backend to meet the request demand. In this paper, we present Clockwork, a third-party cloud service, which smooths the demand profile by redistributing delay-tolerant requests and prioritizing delay-sensitive requests, so that sufficient capacity can be provided with reduced cost and wastage. To begin with, Clockwork plans the optimal backend capacity on a relatively long timescale based on future demand estimated by machine learning algorithms. We discuss pros and cons of various simple machine learning algorithms and advanced deep learning algorithms, in terms of their prediction accuracy and training time. Then, Clockwork schedules user requests on a shorter timescale through a fair and Pareto- optimal rate allocation. We implemented a fully-functional prototype of Clockwork on cloud servers and user mobile devices. The experimental results show that Clockwork can effectively help developers cut cost, as well as improve the backend utilization.","2155-5494","978-1-5090-6599-8","10.1109/SAHCN.2017.7964910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964910","","Capacity planning;Machine learning algorithms;Mobile applications;Resource management;Delays;Optimization;Prediction algorithms","cloud computing;learning (artificial intelligence);mobile computing","Clockwork;mobile applications;third-party cloud service;delay-tolerant requests;delay-sensitive requests;optimal backend capacity;machine learning algorithms;advanced deep learning algorithms","","","","19","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Robust Model Predictive Control of Nonlinear Systems With Unmodeled Dynamics and Bounded Uncertainties Based on Neural Networks","Z. Yan; J. Wang","Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Neural Networks and Learning Systems","20 May 2017","2014","25","3","457","469","This paper presents a neural network approach to robust model predictive control (MPC) for constrained discrete-time nonlinear systems with unmodeled dynamics affected by bounded uncertainties. The exact nonlinear model of underlying process is not precisely known, but a partially known nominal model is available. This partially known nonlinear model is first decomposed to an affine term plus an unknown high-order term via Jacobian linearization. The linearization residue combined with unmodeled dynamics is then modeled using an extreme learning machine via supervised learning. The minimax methodology is exploited to deal with bounded uncertainties. The minimax optimization problem is reformulated as a convex minimization problem and is iteratively solved by a two-layer recurrent neural network. The proposed neurodynamic approach to nonlinear MPC improves the computational efficiency and sheds a light for real-time implementability of MPC technology. Simulation results are provided to substantiate the effectiveness and characteristics of the proposed approach.","2162-2388","","10.1109/TNNLS.2013.2275948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6582522","Extreme learning machine (ELM);real-time optimization;recurrent neural networks (RNNs);robust model predictive control (MPC);unmodeled dynamics","Optimization;Vectors;Artificial neural networks;Robustness;Uncertainty;Nonlinear systems","discrete time systems;Jacobian matrices;learning (artificial intelligence);minimax techniques;neurocontrollers;nonlinear control systems;predictive control;recurrent neural nets;robust control;uncertain systems","robust model predictive control;nonlinear system;unmodeled dynamics;bounded uncertainty;MPC;constrained discrete-time system;Jacobian linearization;extreme learning machine;supervised learning;minimax optimization problem;convex minimization problem;two-layer recurrent neural network;neurodynamic approach","Algorithms;Artificial Intelligence;Computer Simulation;Humans;Models, Neurological;Neural Networks (Computer);Nonlinear Dynamics;Time Factors;Uncertainty","103","","62","IEEE","16 Aug 2013","","","IEEE","IEEE Journals"
"Pattern Classification by Evolutionary RBF Networks Ensemble Based on Multi-objective Optimization","N. Kondo; T. Hatanaka; K. Uosaki","Department of Information and Physical Sciences, Graduate School of Information Science and Technology, Osaka University, Suita, 565-0871, Japan. phone: +81-6-6879-7834; fax: +81-6-6879-7836; email: nobuhiko@ist.osaka-u.ac.jp; Osaka Univ., Suita; Osaka Univ., Suita","The 2006 IEEE International Joint Conference on Neural Network Proceedings","30 Oct 2006","2006","","","2919","2925","In this paper, evolutionary multi-objective selection method of RBF networks structure and its application to the ensemble learning is considered. The candidates of RBF network structure are encoded into the chromosomes in GAs. Then, they evolve toward Pareto-optimal front defined by several objective functions concerning with model accuracy, model complexity and model smoothness. RBF network ensemble is constructed of the obtained Pareto-optimal models since such models are diverse. This method is applied to the pattern classification problem. Experiments on the benchmark problem demonstrate that the proposed method has comparable generalization ability to conventional ensemble methods.","2161-4407","0-7803-9490-9","10.1109/IJCNN.2006.247224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1716494","","Pattern classification;Radial basis function networks;Neurons;Neural networks;Optimization methods;Multilayer perceptrons;Artificial neural networks;Learning systems;Machine learning;Evolutionary computation","evolutionary computation;pattern classification;radial basis function networks","pattern classification;evolutionary RBF networks ensemble;multi-objective optimization;ensemble learning;radial basis function","","3","","23","","30 Oct 2006","","","IEEE","IEEE Conferences"
"Deconstructing Generative Adversarial Networks","B. Zhu; J. Jiao; D. Tse","Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA","IEEE Transactions on Information Theory","21 Oct 2020","2020","66","11","7155","7179","Generative Adversarial Networks (GANs) are a thriving unsupervised machine learning technique that has led to significant advances in various fields such as computer vision, natural language processing, among others. However, GANs are known to be difficult to train and usually suffer from mode collapse and the discriminator winning problem. To interpret the empirical observations of GANs and design better ones, we deconstruct the study of GANs into three components and make the following contributions. Formulation: we propose a perturbation view of the population target of GANs. Building on this interpretation, we show that GANs can be connected to the robust statistics framework, and propose a novel GAN architecture, termed as Cascade GANs, to provably recover meaningful low-dimensional generator approximations when the real distribution is high-dimensional and corrupted by outliers. Generalization: given a population target of GANs, we design a systematic principle, projection under admissible distance, to design GANs to meet the population requirement using only finite samples. We implement our principle in three cases to achieve polynomial and sometimes near-optimal sample complexities: (1) learning an arbitrary generator under an arbitrary pseudonorm; (2) learning a Gaussian location family under total variation distance, where we utilize our principle to provide a new proof for the near-optimality of the Tukey median viewed as GANs; (3) learning a low-dimensional Gaussian approximation of a high-dimensional arbitrary distribution under Wasserstein distance. We demonstrate a fundamental trade-off in the approximation error and statistical error in GANs, and demonstrate how to apply our principle in practice with only empirical samples to predict how many samples would be sufficient for GANs in order not to suffer from the discriminator winning problem. Optimization: we demonstrate alternating gradient descent is provably not locally asymptotically stable in optimizing the GAN formulation of PCA. We found that the minimax duality gap being non-zero might be one of the causes, and propose a new GAN architecture whose duality gap is zero, where the value of the game is equal to the previous minimax value (not the maximin value). We prove the new GAN architecture is globally asymptotically stable in solving PCA under alternating gradient descent.","1557-9654","","10.1109/TIT.2020.2983698","NSF(grant numbers:CIF-1909499); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9049093","Generative Adversarial Networks (GANs);wasserstein distance;optimal transport;generalization error;information-theoretic limit;robust statistics","Gallium nitride;Generators;Perturbation methods;Generative adversarial networks;TV;Sociology;Statistics","approximation theory;duality (mathematics);Gaussian processes;gradient methods;learning (artificial intelligence);minimax techniques;neural nets;polynomials;principal component analysis","generative adversarial networks;GAN formulation;cascade GAN;minimax duality","","3","","66","IEEE","27 Mar 2020","","","IEEE","IEEE Journals"
"Large margin HMMs for speech recognition","Xinwei Li; Hui Jiang; Chaojun Liu","Dept. of Comput. Sci. & Eng., York Univ., Toronto, Ont., Canada; Dept. of Comput. Sci. & Eng., York Univ., Toronto, Ont., Canada; Dept. of Comput. Sci. & Eng., York Univ., Toronto, Ont., Canada","Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.","9 May 2005","2005","5","","v/513","v/516 Vol. 5","Motivated by large margin classifiers in machine learning, we propose a novel method to estimate a continuous density hidden Markov model (CDHMM) in speech recognition according to the principle of maximizing the minimum multi-class separation margin. The approach is named large margin HMM. First, we show that this type of large margin HMM estimation problem can be formulated as a standard constrained minimax optimization problem. Second, we propose an iterative localized optimization approach to perform the minimax optimization for one model at a time to guarantee that the optimal value of the objective function always exists in the course of model parameter optimization. Then, we show that during each step the optimization can be solved by the GPD (generalized probabilistic descent) algorithm if we approximate the objective function by a differentiable function, such as summation of exponential functions. The large margin HMM-based classifiers are evaluated in a speaker-independent E-set speech recognition task using the OGI ISOLET database. Experimental results show that the large margin HMMs can achieve significant word error rate (WER) reduction over conventional HMM training methods, such as maximum likelihood estimation (MLE) and minimum classification error (MCE) training.","2379-190X","0-7803-8874-7","10.1109/ICASSP.2005.1416353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1416353","","Hidden Markov models;Speech recognition;Maximum likelihood estimation;Machine learning;Minimax techniques;Databases;Error analysis;Pattern classification;Boosting;Support vector machines","learning (artificial intelligence);minimax techniques;hidden Markov models;speech recognition;iterative methods;approximation theory;functions;error statistics;parameter estimation","large margin HMM estimation;speech recognition;large margin classifiers;continuous density hidden Markov model;minimum multi-class separation margin maximization;constrained minimax optimization;iterative localized optimization approach;objective function;model parameter optimization;generalized probabilistic descent algorithm;differentiable function;exponential functions;word error rate;HMM training methods;maximum likelihood estimation;minimum classification error","","10","2","11","","9 May 2005","","","IEEE","IEEE Conferences"
"Sharp Characterization of Optimal Minibatch Size for Stochastic Finite Sum Convex Optimization","A. Nitanda; T. Murata; T. Suzuki",The University of Tokyo / RIKEN AIP; NTT DATA Mathematical Systems Inc.; The University of Tokyo / RIKEN AIP,"2019 IEEE International Conference on Data Mining (ICDM)","30 Jan 2020","2019","","","488","497","The minibatching technique has been extensively adopted to facilitate stochastic first-order methods because of their computational efficiency in parallel computing for large-scale machine learning and data mining. However, the optimal minibatch size determination for accelerated stochastic gradient methods is not completely understood. Actually, there appears trade-off between the iteration complexity and the total computational complexity; that is, the number of iterations (minibatch queries) can be decreased by increasing the minibatch size, but too large minibatch size would result in an unnecessarily large total computational cost. In this study, we give a sharp characterization of the minimax optimal minibatch size to achieve the optimal iteration complexity by providing a reachable lower bound for minimizing finite sum of convex functions and, surprisingly, show that the optimal method with the minimax optimal minibatch size can achieve both of the optimal iteration complexity and the optimal total computational complexity simultaneously. Finally, this feature is verified experimentally.","2374-8486","978-1-7281-4604-1","10.1109/ICDM.2019.00059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970843","finite-sum problem, optimal minibatch method","","computational complexity;convex programming;data mining;gradient methods;iterative methods;learning (artificial intelligence);minimax techniques;stochastic processes","minimax optimal minibatch size;optimal iteration complexity;finite sum minimization;optimal total computational complexity;stochastic finite sum convex optimization;minibatching technique;stochastic first-order methods;parallel computing;machine learning;data mining","","","","22","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Surrogate-based Multi-Objective Particle Swarm Optimization","L. V. Santana-Quintero; C. A. Coello Coello; A. G. Hernandez-Diaz; J. M. O. Velazquez","CINVESTAV-IPN, Computer Science Department, Mexico City, MEXICO; CINVESTAV-IPN, Computer Science Department, Mexico City, MEXICO; Pablo de Olavide University, Department of Quantitative Methods, Seville, SPAIN; Instituto Tecnológico de Culiacán, Systems and Informatics Department, Sinaloa, MEXICO","2008 IEEE Swarm Intelligence Symposium","7 Nov 2008","2008","","","1","8","This paper presents a new algorithm that approximates real function evaluations using supervised learning with a surrogate method called support vector machine (SVM). We perform a comparative study among different leader selection schemes in a Multi-Objective Particle Swarm Optimizer (MOPSO), in order to determine the most appropriate approach to be adopted for solving the sort of problems of our interest. The resulting hybrid presents a poor spread of solutions, which motivates the introduction of a second phase to our algorithm, in which an approach called rough sets is adopted in order to improve the spread of solutions along the Pareto front. Rough sets are used as a local search engine, which is able to generate solutions in the neighborhood of the nondominated solutions previously generated by the surrogate-based algorithm. The resulting approach is able to generate reasonably good approximations of the Pareto front of problems of up to 30 decision variables with only 2,000 fitness function evaluations. Our results are compared with respect to the NSGA-II, which is a multi-objective evolutionary algorithm representative of the state-of-the-art in the area.","","978-1-4244-2704-8","10.1109/SIS.2008.4668300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4668300","Multi-objective optimization;surrogates;support vector machines;PSO;rough sets;hybrid algorithms","Particle swarm optimization;Support vector machines;Rough sets;Evolutionary computation;Supervised learning;Computational efficiency;Machine learning algorithms;USA Councils;Search engines;Pareto optimization","evolutionary computation;learning (artificial intelligence);Pareto optimisation;particle swarm optimisation;rough set theory;support vector machines","multiobjective particle swarm optimization;supervised learning;support vector machine;rough set;Pareto front;local search engine;surrogate-based algorithm;NSGA-II;multiobjective evolutionary algorithm","","5","","21","","7 Nov 2008","","","IEEE","IEEE Conferences"
"Applying one-class learning algorithms to predict phage-bacteria interactions","J. F. López; J. A. L. Sotelo; D. Leite; C. Peña-Reyes","Universidad Autónoma de Occidente,Department of Electrical and Automation,Cali,Colombia; Universidad Autónoma de Occidente,Department of Electrical and Automation,Cali,Colombia; School of Bussiness and Engineering Vaud (HEIG-VD),Computational Intelligence for Computational Biology,Yverdon-les-Bains,Switzerland; School of Bussiness and Engineering Vaud (HEIG-VD),Computational Intelligence for Computational Biology,Yverdon-les-Bains,Switzerland","2019 IEEE Latin American Conference on Computational Intelligence (LA-CCI)","19 Mar 2020","2019","","","1","6","The need to predict phage-bacteria interactions is a nowadays concern to overcome bacterial resistance issue; public genome databases contain highly imbalanced datasets which have hindered this task. Throughout this paper we will investigate, implement and evaluate One-Class Learning algorithms in order to predict phage-bacteria interactions using only positive samples. We will use the programming language Python aided by Scikit-Learn, Tensorflow and keras to develop the machine learning models and test them with real phage-bacteria interactions datasets. We trained the models using cross validation technique generating a gridsearch with all the datasets to find several combinations of hyperparameters available. Furthermore, we optimized those hyperparameters by using Pareto fronts based on seven different performance metrics, improving the efficiency of each algorithm for a given dataset. To refine each algorithm's performance separately we used the ensemble learning technique with an odd number of algorithms by simple voting. Finally, we managed to achieve an overall performance of 80% in predicting phage-bacteria interactions trained only with positive classes, this percentage in practice means that when a patient has an infection resistant to antibiotics, we have 80% of saving the life rather than maybe a 0% while finding the correct phage for the pathogenic host.","","978-1-7281-5666-8","10.1109/LA-CCI47412.2019.9037032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9037032","phage-bacteria interaction;One-Class Learning;optimization;imbalanced datasets","Microorganisms;Databases;Proteins;Prediction algorithms;Machine learning algorithms;Medical treatment;Feature extraction","biology computing;genomics;learning (artificial intelligence);microorganisms;pattern classification","one-class learning algorithms;machine learning models;phage-bacteria interactions datasets;ensemble learning technique;Python programming language;Scikit-Learn;Tensorflow;keras","","1","","17","","19 Mar 2020","","","IEEE","IEEE Conferences"
"Supervised tensor learning","Dacheng Tao; Xuelong Li; Weiming Hu; S. Maybank; Xindong Wu","Sch. of Comput. Sci. & Inf. Syst., Birkbeck Coll., London Univ., UK; Sch. of Comput. Sci. & Inf. Syst., Birkbeck Coll., London Univ., UK; NA; NA; NA","Fifth IEEE International Conference on Data Mining (ICDM'05)","3 Jan 2006","2005","","","8 pp.","","This paper aims to take general tensors as inputs for supervised learning. A supervised tensor learning (STL) framework is established for convex optimization based learning techniques such as support vector machines (SVM) and minimax probability machines (MPM). Within the STL framework, many conventional learning machines can be generalized to take n/sup th/-order tensors as inputs. We also study the applications of tensors to learning machine design and feature extraction by linear discriminant analysis (LDA). Our method for tensor based feature extraction is named the tenor rank-one discriminant analysis (TR1DA). These generalized algorithms have several advantages: 1) reduce the curse of dimension problem in machine learning and data mining; 2) avoid the failure to converge; and 3) achieve better separation between the different categories of samples. As an example, we generalize MPM to its STL version, which is named the tensor MPM (TMPM). TMPM learns a series of tensor projections iteratively. It is then evaluated against the original MPM. Our experiments on a binary classification problem show that TMPM significantly outperforms the original MPM.","2374-8486","0-7695-2278-5","10.1109/ICDM.2005.139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1565711","","Tensile stress;Machine learning;Support vector machines;Supervised learning;Data mining;Support vector machine classification;Computer science;Minimax techniques;Feature extraction;Linear discriminant analysis","tensors;learning (artificial intelligence);data mining;minimax techniques;support vector machines;statistical analysis","supervised tensor learning;supervised learning;convex optimization;support vector machines;minimax probability machines;learning machine design;feature extraction;linear discriminant analysis;tenor rank-one discriminant analysis;machine learning;data mining","","4","1","19","","3 Jan 2006","","","IEEE","IEEE Conferences"
"Adaptive critic design in learning to play game of Go","R. Zaman; D. Prokhorov; D. C. Wunsch","Dept. of Electr. Eng., Texas Tech. Univ., Lubbock, TX, USA; NA; NA","Proceedings of International Conference on Neural Networks (ICNN'97)","6 Aug 2002","1997","1","","1","4 vol.1","This paper examines the performance of an HDP-type adaptive critic design (ACD) of the game Go. The game Go is an ideal problem domain for exploring machine learning; it has simple rules but requires complex strategies to play well. All current commercial Go programs are knowledge based implementations; they utilize input feature and pattern matching along with minimax type search techniques. But the extremely high branching factor puts a limit on their capabilities, and they are very weak compared to the relative strengths of other game programs like chess. In this paper, the Go-playing ACD consists of a critic network and an action network. The HDP type critic network learns to predict the cumulative utility function of the current board position from training games, and, the action network chooses a next move which maximizes critics next step cost-to-go. After about 6000 different training games against a public domain program, WALLY, the network (playing WHITE) began to win in some of the games and showed slow but steady improvements on test games.","","0-7803-4122-8","10.1109/ICNN.1997.611623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=611623","","Machine learning;Minimax techniques;Computational intelligence;Laboratories;Pattern matching;Testing;Law;Legal factors;Humans;Prediction algorithms","learning (artificial intelligence);games of skill;neural net architecture","adaptive critic design;game of Go;learning;critic network;action network;cumulative utility function","","12","","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Multi-objective cost-sensitive attribute reduction","B. Xu; H. Chen; W. Zhu; X. Zhu","College of IOT Engineering, Hohai University, Changzhou 213022, China; College of IOT Engineering, Hohai University, Changzhou 213022, China; College of IOT Engineering, Hohai University, Changzhou 213022, China; College of IOT Engineering, Hohai University, Changzhou 213022, China","2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS)","26 Sep 2013","2013","","","1377","1381","Cost-sensitive learning is both hot and difficult in data mining and machine learning applications. Some research considers only one type of cost. Others convert two or more types of cost into the same unit, and then deal with a single-objective optimization problem. However, in many cases different types of cost cannot be converted. In this paper, we define and tackle multi-objective attribute reduct problem with multiple types of test cost. First, we compute all reducts of a decision system. Then, we separately calculate the money cost and time cost of these reducts and compare them according to the two kinds of test cost. Finally, the worse ones are removed. The remaining reducts form a Pareto optimal solution set. We tested our algorithm with three representative cost distributions on four UCI datasets. Experimental results indicate that a Pareto optimal solution set is usually very small compared with the size of all reducts. Hence our approach is effective in filtering out worse solutions and helping users in scheme selection.","","978-1-4799-0348-1","10.1109/IFSA-NAFIPS.2013.6608602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6608602","Cost-sensitive learning;rough sets;attribute reduction;money cost;time cost","Pareto optimization;Rough sets;Entropy;Cognition;Approximation methods;Decision trees","data mining;learning (artificial intelligence);Pareto optimisation","multiobjective cost sensitive attribute reduction;cost sensitive learning;data mining;machine learning applications;single-objective optimization problem;decision system;Pareto optimal solution set;UCI datasets","","2","","21","","26 Sep 2013","","","IEEE","IEEE Conferences"
"A Design Flow for Mapping Spiking Neural Networks to Many-Core Neuromorphic Hardware","S. Song; M. L. Varshika; A. Das; N. Kandasamy","Drexel University,Electrical and Computer Engineering,Philadelphia,PA,USA; Drexel University,Electrical and Computer Engineering,Philadelphia,PA,USA; Drexel University,Electrical and Computer Engineering,Philadelphia,PA,USA; Drexel University,Electrical and Computer Engineering,Philadelphia,PA,USA","2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)","23 Dec 2021","2021","","","1","9","The design of many-core neuromorphic hardware is becoming increasingly complex as these systems are now expected to execute large machine-learning models. A predictable design flow is needed to guarantee real-time performance such as latency and throughput without significantly increasing the buffer requirement of computing cores. Synchronous Data Flow Graphs (SDFGs) have been previously used for predictable mapping of streaming applications to multiprocessor systems. We propose an SDFG-based design flow to map spiking neural networks (SNNs) to many-core neuromorphic hardware with the objective of exploring the tradeoff between throughput and buffer-size requirements. The proposed design flow integrates an iterative partitioning approach based on Kernighan-Lin graph partitioning heuristic to create SNN clusters such that each cluster can be mapped to a core of the hardware. The partitioning approach minimizes inter-cluster spike communication, which improves latency on the shared interconnect of the hardware. Next, the design flow maps clusters to cores using Particle Swarm Optimization (PSO), an evolutionary algorithm, while exploring the design space of throughput and buffer size. Pareto-optimal mappings are retained from the design flow, allowing system designers to select a Pareto mapping that satisfies throughput and buffer-size requirements of the design. We evaluated the developed design flow using five large-scale convolutional neural network (CNN) models. Results demonstrate 63% higher maximum throughput and 10% lower buffer-size requirement compared to state-of-the-art dataflow-based mapping solutions.","1558-2434","978-1-6654-4507-8","10.1109/ICCAD51958.2021.9643500","U.S. Department of Energy(grant numbers:DE-SC0022014); National Science Foundation(grant numbers:CNS-2008167,CCF-1937419); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643500","neuromorphic computing;spiking neural network (SNN);design-space exploration (DSE);oxide-based resistive random access memory (OxRRAM);dataflow","Neuromorphics;Computational modeling;Neural networks;Machine learning;Throughput;Hardware;Space exploration","data flow graphs;evolutionary computation;graph theory;learning (artificial intelligence);multiprocessing systems;network topology;network-on-chip;neural nets;optimisation;Pareto optimisation;particle swarm optimisation","mapping spiking neural networks;many-core neuromorphic hardware;predictable design flow;buffer requirement;computing cores;Synchronous Data Flow Graphs;predictable mapping;SDFG-based design flow;buffer-size requirements;Kernighan-Lin graph partitioning;partitioning approach minimizes inter-cluster spike communication;design flow maps clusters;design space;Pareto-optimal mappings;system designers;Pareto mapping;developed design flow;large-scale convolutional neural network models;lower buffer-size requirement;state-of-the-art dataflow-based mapping solutions","","2","","65","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"Self-Configuring Ensemble of Neural Network Classifiers for Emotion Recognition in the Intelligent Human-Machine Interaction","E. Sopov; I. Ivanov","Dept. of Syst. Anal. & Oper. Res., Siberian State Aerosp. Univ., Krasnoyarsk, Russia; Dept. of Syst. Anal. & Oper. Res., Siberian State Aerosp. Univ., Krasnoyarsk, Russia","2015 IEEE Symposium Series on Computational Intelligence","11 Jan 2016","2015","","","1808","1815","Reducing the dimensionality of datasets and configuring learning algorithms for solving particular practical tasks are the main problems in machine learning. In this work we propose multi-objective optimization approach to feature selection and base learners hyper-parameter optimization. The effectiveness of the proposed multi-objective approach is compared to the single-objective approach. We have chosen emotion recognition problem by audio-visual data as a benchmark for comparing the two mentioned approaches. We have chosen neural network as a base learning algorithm for testing the proposed approach to parameter optimization. As a result of multi-objective optimization applied to parameter configuration we get the Pareto set of neural networks with optimal parameter values. In order to get the single output, the Pareto optimal neural networks were combined into an ensemble. We have examined several ensemble model fusion techniques including voting, average class probabilities and meta-classification. According to results, multi-objective optimization approach to feature selection provides an average 2.8% better emotion classification rate on the given datasets than single-objective approach. Multi-objective approach is 5.4% more effective compared to principal components analysis, and 13.9% more effective compared to not using any dimensionality reduction at all. Multi-objective approach applied to neural networks parameter optimization provided on average 7.1% better classification rate than single-objective approach. The results suggest that the proposed multi-objective optimization approach is more effective at solving considered emotion recognition problem.","","978-1-4799-7560-0","10.1109/SSCI.2015.252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7376829","","Optimization;Neural networks;Emotion recognition;Sociology;Statistics;Algorithm design and analysis;Feature extraction","emotion recognition;feature selection;human computer interaction;learning (artificial intelligence);neural nets;Pareto optimisation;pattern classification","neural network parameter optimization;dimensionality reduction;principal components analysis;emotion classification rate;meta-classification;average class probability;voting;ensemble model fusion technique;Pareto optimal neural network;optimal parameter value;Pareto set;parameter configuration;base learning algorithm;audio-visual data;emotion recognition problem;hyper-parameter optimization;feature selection;multiobjective optimization approach;machine learning;intelligent human-machine interaction;neural network classifier;self-configuring ensemble","","","","19","","11 Jan 2016","","","IEEE","IEEE Conferences"
"Multi-Objective Model Selection via Racing","T. Zhang; M. Georgiopoulos; G. C. Anagnostopoulos","Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, Florida Institute of Technology, Melbourne, FL, USA","IEEE Transactions on Cybernetics","20 May 2017","2016","46","8","1863","1876","Model selection is a core aspect in machine learning and is, occasionally, multi-objective in nature. For instance, hyper-parameter selection in a multi-task learning context is of multi-objective nature, since all the tasks' objectives must be optimized simultaneously. In this paper, a novel multi-objective racing algorithm (RA), namely S-Race, is put forward. Given an ensemble of models, our task is to reliably identify Pareto optimal models evaluated against multiple objectives, while minimizing the total computational cost. As a RA, S-Race attempts to eliminate non-promising models with confidence as early as possible, so as to concentrate computational resources on promising ones. Simultaneously, it addresses the problem of multi-objective model selection (MOMS) in the sense of Pareto optimality. In S-Race, the nonparametric sign test is utilized for pair-wise dominance relationship identification. Moreover, a discrete Holm's step-down procedure is adopted to control the family-wise error rate of the set of hypotheses made simultaneously. The significance level assigned to each family is adjusted adaptively during the race. In order to illustrate its merits, S-Race is applied on three MOMS problems: (1) selecting support vector machines for classification; (2) tuning the parameters of artificial bee colony algorithms for numerical optimization; and (3) constructing optimal hybrid recommendation systems for movie recommendation. The experimental results confirm that S-Race is an efficient and effective MOMS algorithm compared to a brute-force approach.","2168-2275","","10.1109/TCYB.2015.2456187","National Science Foundation (NSF)(grant numbers:1200566,0525429); NSF(grant numbers:0806931,0963146,1200566,1161228,1356233); NSF(grant numbers:1263011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192610","Discrete Holm’s step-down procedure;model selection;multi-objective optimization;racing algorithm (RA);sign test (ST)","Computational modeling;Method of moments;Pareto optimization;Algorithm design and analysis;Linear programming;Context","learning (artificial intelligence);minimisation;nonparametric statistics;Pareto optimisation;statistical testing","multiobjective model selection;machine learning;hyper-parameter selection;multitask learning;multiobjective racing algorithm;S-Race;Pareto optimal models;total computational cost minimization;RA;computational resources;MOMS;nonparametric sign test;pair-wise dominance relationship identification;discrete Holm step-down procedure;family-wise error rate control;support vector machines;parameter tuning;artificial bee colony algorithms;numerical optimization;optimal hybrid recommendation systems;movie recommendation","","6","","57","IEEE","12 Aug 2015","","","IEEE","IEEE Journals"
"Looking for Software Defects? First Find the Nonconformists","S. Moshtari; J. C. S. Santos; M. Mirakhorli; A. Okutan","Rochester Institute of Technology,Rochester,United States; Rochester Institute of Technology,Rochester,United States; Rochester Institute of Technology,Rochester,United States; Rochester Institute of Technology,Rochester,United States","2020 IEEE 20th International Working Conference on Source Code Analysis and Manipulation (SCAM)","11 Nov 2020","2020","","","75","86","Software defect prediction models play a key role to increase the quality and reliability of software systems. Because, they are used to identify defect prone source code components and assist testing activities during the development life cycle. Prior research used supervised and unsupervised Machine Learning models for software defect prediction. Supervised defect prediction models require labeled data, however it might be time consuming and expensive to obtain labeled data that has the desired quality and volume. The unsupervised defect prediction models usually use clustering techniques to relax the labeled data requirement, however labeling detected clusters as defective is a challenging task. The Pareto principle states that a small number of modules contain most of the defects. Getting inspired from the Pareto principle, this work proposes a novel, unsupervised learning approach that is based on outlier detection. We hypothesize that defect prone software components have different characteristics when compared to others and can be considered as outliers, therefore outlier detection techniques can be used to identify them. The experiment results on 16 software projects from two publicly available datasets (PROMISE and GitHub) indicate that the k-Nearest Neighbor (KNN) outlier detection method can be used to identify the majority of software defects. It could detect 94% of expected defects at best case and more than 63% of the defects in 75% of the projects. We compare our approach with the state-of-the-art supervised and unsupervised defect prediction approaches. The results of rigorous empirical evaluations indicate that the proposed approach outperforms existing unsupervised models and achieves comparable results with the leading supervised techniques that rely on complex training and tuning algorithms.","2470-6892","978-1-7281-9248-2","10.1109/SCAM51674.2020.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252071","Defect prediction;unsupervised learning;outlier detection;software metrics;software quality","Training;Software algorithms;Training data;Predictive models;Prediction algorithms;Software;Anomaly detection","pattern classification;software metrics;software reliability;unsupervised learning","software defect prediction models;reliability;software systems;defect prone source code components;development life cycle;supervised machine learning;unsupervised machine learning;supervised defect prediction models;unsupervised defect prediction models;labeled data requirement;detected clusters;Pareto principle states;defect prone software components;outlier detection techniques;software projects;k-Nearest Neighbor outlier detection method;expected defects;unsupervised defect prediction approaches;unsupervised models","","","","67","","11 Nov 2020","","","IEEE","IEEE Conferences"
"A Spectral Convolutional Net for Co-Optimization of Integrated Voltage Regulators and Embedded Inductors","H. M. Torun; H. Yu; N. Dasari; V. C. K. Chekuri; A. Singh; J. Kim; S. K. Lim; S. Mukhopadhyay; M. Swaminathan",3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC); 3D Systems Packaging Research Center (PRC),"2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","27 Dec 2019","2019","","","1","8","Integrated voltage regulators (IVR) with embedded inductors is an emerging technology that provides point-of-load voltage regulation to high-performance systems. Conventional two-step approaches to the design of IVRs can suffer from suboptimal design as the optimal inductor depends on the characteristics of the buck converter (BC). Furthermore, inductor-level trade-offs such as AC and DC resistance, inductance and area can not be determined independently from the BC. This co-dependency of the BC and the inductor creates a highly non-linear response surface, which raises the necessity of co-optimization, involving multiple time-consuming electromagnetics (EM) simulations. In this paper, we propose a machine learning based optimization methodology that eliminates EM simulations from the optimization loop to significantly reduce the optimization complexity. A novel technique named as Spectral Transposed Convolutional Neural Network (S-TCNN) is presented to derive an accurate predictive model of the inductor frequency response using a small amount of training data. The derived S-TCNN is then used along with a time-domain model of the BC to perform multi-objective optimization that approximates the Pareto front for 5 objectives, namely inductor area, BC settling time, voltage conversion efficiency, droop and ripple. The resulting methodology provides multiple Pareto optimal inductors in an efficient and fully automated fashion, thereby allows to rapidly determine the optimal trade-offs for possibly contradicting design objectives. We demonstrate the proposed framework on co-optimization of solenoidal inductor with magnetic core and BC that are integrated on silicon interposer.","1558-2434","978-1-7281-2350-9","10.1109/ICCAD45719.2019.8942109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942109","convolutional networks;integrated voltage regulators;embedded inductors;system-level optimization","Inductors;Frequency response;Optimization;Correlation;Training;Inductance;Voltage control","convolutional neural nets;frequency response;learning (artificial intelligence);magnetic cores;optimisation;Pareto optimisation;power inductors;solenoids;voltage control;voltage regulators","spectral convolutional net;integrated voltage regulators;embedded inductors;IVR;point-of-load voltage regulation;high-performance systems;suboptimal design;optimal inductor;inductor-level trade-offs;nonlinear response surface;optimization complexity;inductor frequency response;time-domain model;multiobjective optimization;BC settling time;voltage conversion efficiency;optimal trade-offs;solenoidal inductor;multiple time-consuming electromagnetics simulations;machine learning based optimization methodology;spectral transposed convolutional neural network;Pareto optimal inductors","","7","","18","","27 Dec 2019","","","IEEE","IEEE Conferences"
"Online knowledge-based evolutionary multi-objective optimization","B. Zhang; K. Shafi; H. Abbass","School of Engineering and Information Technology, University of New South Wales, Canberra, Australian Capital Territory, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australian Capital Territory, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australian Capital Territory, Australia","2014 IEEE Congress on Evolutionary Computation (CEC)","22 Sep 2014","2014","","","2222","2229","Knowledge extraction from a multi-objective optimization process has important implications including a better understanding of the optimization process and the relationship between decision variables. The extant approaches, in this respect, rely on processing the post-optimization Pareto sets for automatic rule discovery using statistical or machine learning methods. However such approaches fall short of providing any information during the progress of the optimization process, which can be critical for decision analysis especially if the problem is dynamic. In this paper, we present a multi-objective optimization framework that uses a knowledge-based representation to search for patterns of Pareto optimal design variables instead of conventional point form solution search. The framework facilitates the online discovery of knowledge during the optimization process in the form of interpretable rules. The core contributing idea of our research is that we apply multi-objective evolutionary process on a population of bounding hypervolumes, or rules, instead of evolving individual point-based solutions. The framework is generic in a sense that any existing multi-objective optimization algorithm can be adapted to evaluate the rule quality based on the sampled solutions from the bounded space. An instantiation of the framework using hyperrectangular representation and non-dominated sorting based rule evaluation is presented in this paper. Experimental results on a specifically designed test function as well as some standard test functions are presented to demonstrate the working and convergence properties of our algorithm.","1941-0026","978-1-4799-1488-3","10.1109/CEC.2014.6900610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6900610","","Sociology;Algorithm design and analysis;Pareto optimization;Sorting;Evolutionary computation","data mining;decision theory;evolutionary computation;knowledge representation;learning (artificial intelligence);Pareto optimisation;search problems;sorting","online knowledge-based evolutionary multiobjective optimization process;knowledge extraction;decision variables;post-optimization Pareto set processing;automatic rule discovery;machine learning methods;statistical methods;decision analysis;knowledge-based representation;Pareto optimal design variables;online knowledge discovery;bounding hypervolumes;point-based solutions;bounded space;hyperrectangular representation;nondominated sorting;point form solution search;rule quality evaluation","","1","","27","","22 Sep 2014","","","IEEE","IEEE Conferences"
"Simultaneous feature selection and clustering for categorical features using multi objective genetic algorithm","D. Dutta; P. Dutta; J. Sil","Department of Computer Science and Information Technology, University Institute of Technology, The University of Burdwan, Golapbug (North), West Bengal, India PIN-713104; Department of Computer and System Sciences, Visva-Bharati University, Santiniketan, West Bengal, India; Department of Computer Science and Technology, Bengal Engineering and Science University, Shibpur, West Bengal, India PIN-711103","2012 12th International Conference on Hybrid Intelligent Systems (HIS)","28 Jan 2013","2012","","","191","196","Clustering is unsupervised learning where ideally class levels and number of clusters (K) are not known. K-clustering can be categorized as semi-supervised learning where K is known. Here we have considered K-Clustering with simultaneous feature selection. Feature subset selection helps to identify relevant features for clustering, increase understandability, better scalability and improve accuracy. Here we have used two measures, intra-cluster distance (Homogeneity, H) and inter-cluster distances (Separation, S) for clustering. Measures are using mod distance per feature suitable for categorical features (attributes). Rather than combining H and S to frame the problem as single objective optimization problem, we use multi objective genetic algorithm (MOGA) to find out diverse solutions near to Pareto optimal front in the two-dimensional objective space. Each evolved solution represents a set of cluster modes (CMs) build by selected feature subset. Here, K-modes is hybridized with MOGA. We have used hybridized GA to combine global searching powers of GA with local searching powers of K-modes. Considering context sensitivity, we have used a special crossover operator called “pairwise crossover” and “substitution”. The main contribution of this paper is simultaneous dimensionality reduction and optimization of objectives using MOGA. Results on 3 benchmark data sets from UCI Machine Learning Repository containing categorical features shows the superiority of the algorithm.","","978-1-4673-5116-4","10.1109/HIS.2012.6421332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6421332","","Biological cells;Sociology;Statistics;Clustering algorithms;Equations;Mathematical model;Buildings","genetic algorithms;pattern clustering;unsupervised learning","simultaneous feature selection;simultaneous feature clustering;multiobjective genetic algorithm;unsupervised learning;class levels;k-clustering;semisupervised learning;feature subset selection;feature identification;intra-cluster distance;mod distance per feature;categorical features;objective optimization problem;MOGA","","6","","27","","28 Jan 2013","","","IEEE","IEEE Conferences"
"Improving generalization of radial basis function network with adaptive multi-objective particle swarm optimization","S. N. Qasem; S. M. H. Shamsuddin","Soft Computing Research Group, Faculty of Computer Science and Information System, Universiti Teknologi Malaysia, Skudai, 81300 Johor, Malaysia; Soft Computing Research Group, k-Economy Research Alliance, Universiti Teknologi Malaysia, Skudai, 81300 Johor, Malaysia","2009 IEEE International Conference on Systems, Man and Cybernetics","4 Dec 2009","2009","","","534","540","In this paper, an adaptive evolutionary multi-objective selection method of RBF Networks structure is discussed. The candidates of RBF Network structures are encoded into particles in Particle Swarm Optimization (PSO). These particles evolve toward Pareto-optimal front defined by several objective functions with model accuracy and complexity. The problem of unsupervised and supervised learning is discussed with Adaptive Multi-Objective PSO (AMOPSO). This study suggests an approach of RBF Network training through simultaneous optimization of architectures and weights with Adaptive PSO-based multi-objective algorithm. Our goal is to determine whether Adaptive Multi-objective PSO can train RBF Networks, and the performance is validated on accuracy and complexity. The experiments are conducted on two benchmark datasets obtained from the machine learning repository. The results show that our proposed method provides an effective means for training RBF Networks that is competitive with PSO-based multi-objective algorithm.","1062-922X","978-1-4244-2793-2","10.1109/ICSMC.2009.5346876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346876","Radial basis function network;Adaptive Multi-objective particle swarm optimization;Multi-Objective particle swarm optimization","Radial basis function networks;Adaptive systems;Particle swarm optimization;Neurons;Supervised learning;Computer networks;Machine learning algorithms;Pareto optimization;Cybernetics;USA Councils","evolutionary computation;learning (artificial intelligence);particle swarm optimisation;radial basis function networks","radial basis function network;generalization;adaptive multiobjective particle swarm optimization;RBF network;Pareto-optimal front;unsupervised learning;supervised learning;adaptive multiobjective PSO;machine learning repository","","3","","21","","4 Dec 2009","","","IEEE","IEEE Conferences"
"Radial basis function Network based on multi-objective particle swarm optimization","S. N. Qasem; S. M. H. Shamsuddin","University Technology Malaysia, Faculty of Computer Science and Information System, Skudai, Johor, Malaysia; University Technology Malaysia, Faculty of Computer Science and Information System, Skudai, Johor, Malaysia","2009 6th International Symposium on Mechatronics and its Applications","14 Jul 2009","2009","","","1","6","The problem of unsupervised and supervised learning is discussed within the context of multi-objective optimization. In this paper, an evolutionary multi-objective selection method of RBF networks structure is discussed. The candidates of RBF network structure are encoded into the particles in PSO. Then, they evolve toward Pareto-optimal front defined by several objective functions concerning with model accuracy and model complexity. This study suggests an approach of RBF network training through simultaneous optimization of architectures and weights with PSO-based multi-objective algorithm. Our goal is to determine whether multi-objective PSO can train RBF networks, and the performance is validated on accuracy and complexity. The experiments are conducted on benchmark datasets obtained from the UCI machine learning repository. The results show that our proposed method provides an effective means for training RBF networks that is competitive with other evolutionary computational-based methods.","","978-1-4244-3480-0","10.1109/ISMA.2009.5164833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5164833","","Radial basis function networks;Particle swarm optimization;Evolutionary computation;Neurons;Computer science;Information systems;Pareto optimization;Pattern classification;Supervised learning;Genetic algorithms","evolutionary computation;Pareto optimisation;particle swarm optimisation;radial basis function networks;unsupervised learning","supervised learning;multiobjective particle swarm optimization;unsupervised learning;evolutionary multiobjective selection method;radial basis function network structure;Pareto-optimal front;objective functions;radial basis function network training;UCI machine learning repository","","11","","19","","14 Jul 2009","","","IEEE","IEEE Conferences"
"Unsupervised Adversarial Instance-Level Image Retrieval","C. Bai; H. Li; J. Zhang; L. Huang; L. Zhang","College of Computer Science, Zhejiang University of Technology, Hangzhou, China; College of Computer Science, Zhejiang University of Technology, Hangzhou, China; School of Artificial Intelligence, Hebei University of Technology, Tianjin, China; College of Computer Science, Zhejiang University of Technology, Hangzhou, China; INSA Rennes, CNRS, IETR - UMR 6164, Univ Rennes, Rennes, France","IEEE Transactions on Multimedia","30 Jul 2021","2021","23","","2199","2207","With the wide use of visual sensors in the Internet of Things (IoT) in the past decades, huge amounts of images are captured in people's daily lives, which poses challenges to traditional deep-learning-based image retrieval frameworks. Most such frameworks need a large amount of annotated training data, which are expensive. Moreover, machines still lack human intelligence, as illustrated by the fact that they pay less attention to the interesting regions that humans generally focus on when searching for images. Hence, this paper proposes a novel unsupervised framework that focuses on the instance object in the image and integrates human intelligence into the deep-learning-based image retrieval. This framework is called adversarial instance-level image retrieval (AILIR). We incorporate adversarial training and an attention mechanism into this framework that considers human intelligence with artificial intelligence. The generator and discriminator are redesigned to guarantee that the generator retrieves similar images while the discriminator selects unmatched images and creates an adversarial reward for the generator. A minimax game is conducted by the adversarial reward retrieval mechanism until the discriminator is unable to judge whether the image sequence retrieved matches the query. Comparison and ablation experiments on four benchmark datasets prove that the proposed adversarial training framework indeed improves instance retrieval and outperforms the state-of-the-art methods focused on instance retrieval.","1941-0077","","10.1109/TMM.2021.3065578","National Natural Science Foundation of China(grant numbers:61976192,U1908210); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LR21F020002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376904","Generative adversarial training;human intelligence simulation;instance level image retrieval;unsupervised training","Image retrieval;Training;Generators;Generative adversarial networks;Feature extraction;Gallium nitride;Task analysis","content-based retrieval;game theory;image retrieval;image sequences;Internet of Things;learning (artificial intelligence);minimax techniques","instance object;human intelligence;attention mechanism;artificial intelligence;unmatched images;adversarial reward retrieval mechanism;image sequence;adversarial training framework;unsupervised adversarial instance-level image retrieval;visual sensors;image retrieval frameworks;annotated training data;minimax game","","4","","54","IEEE","12 Mar 2021","","","IEEE","IEEE Journals"
"A hyper-heuristic multi-criteria decision support system for eco-efficient product life cycle","J. R. Woodward; N. Gindy",The University of Nottingham Ningbo China (UNNC); The University of Nottingham Ningbo China (UNNC),"5th International Conference on Responsive Manufacturing - Green Manufacturing (ICRM 2010)","11 Nov 2010","2010","","","201","205","Decision support is required when complex situations arise during product development which takes into account the whole product life cycle. This is especially true when impacted by the ill-defined consequences on the environment in an ever increasingly eco-conscious world. Analytical Hierarchy process (AHP) is one method of providing decision support, and is an instance of a decision support heuristic. Machine learning methods have proved themselves on many well defined problems with clearly defined objectives. In particular, we focus on the recently emerging field of hyper-heuristics which is a blend of human designed heuristics, with the extension of machine designed heuristics. In essence humans can operate at the higher concept or abstract level, while machine heuristics can operate at a lower level. There are a number of issues within the proposed framework, including visualizing a multi-dimensional surface of designs along the Pareto front, as well as dealing with different types of data during the decision making process. It is proposed that Hyper-heuristics, supplemented with other methodologies to deal with vague or missing data, offer a framework in which to begin to address several of the complex compromises that arise during product development.","","978-1-84919-199-9","10.1049/cp.2010.0436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5629174","Hyper-heuristics;genetic programming;analytical hierarchal process;decision support system","","decision support systems;design for environment;learning (artificial intelligence);Pareto optimisation;product development","multicriteria decision support system;ecoefficient product life cycle;product development;analytical hierarchy process;machine learning methods;hyper heuristics;human designed heuristics;machine designed heuristics;Pareto front","","","","","","11 Nov 2010","","","IET","IET Conferences"
"Resource-Constrained Neural Architecture Search on Edge Devices","B. Lyu; H. Yuan; L. Lu; Y. Zhang","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China","IEEE Transactions on Network Science and Engineering","20 Jan 2022","2022","9","1","134","142","The performance requirement of deep learning inevitably brings up with the expense of high computational complexity and memory requirements, to make it problematic for the deployment on resource-constrained devices. Edge computing, which distributedly organizes the computing node close to the data source and end-device, provides a feasible way to tackle the high-efficiency demand and substantial computational load. Whereas given edge device is resource-constrained and energy-sensitive, designing effective neural network architecture for specific edge device is urgent in the sense that deploys the deep learning application by the edge computing solution. Undoubtedly manually design the high-performing neural architectures is burdensome, let alone taking account of the resource-constraint for the specific platform. Fortunately, the success of Neural Architecture Search techniques come up with hope recently. This paper dedicates to directly employ multi-objective NAS on the resource-constrained edge devices. We first propose the framework of multi-objective NAS on edge device, which comprehensively considers the performance and real-world efficiency. Our improved MobileNet-V2 search space also strikes the scalability and practicality, so that a series of Pareto-optimal architectures are received. Benefits from the directness and specialization during search procedure, our experiment on JETSON NANO shows the comparable result with the state-of-the-art models on ImageNet.","2327-4697","","10.1109/TNSE.2021.3054583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9336306","Edge computing;multi-objective;neural architecture search;reinforcement learning.","Computer architecture;Training;Edge computing;Computational modeling;Search problems;Deep learning;Task analysis","","","","1","","45","IEEE","26 Jan 2021","","","IEEE","IEEE Journals"
"Characterising Across-Stack Optimisations for Deep Convolutional Neural Networks","J. Turner; J. Cano; V. Radu; E. J. Crowley; M. O’Boyle; A. Storkey","School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK","2018 IEEE International Symposium on Workload Characterization (IISWC)","13 Dec 2018","2018","","","101","110","Convolutional Neural Networks (CNNs) are extremely computationally demanding, presenting a large barrier to their deployment on resource-constrained devices. Since such systems are where some of their most useful applications lie (e.g. obstacle detection for mobile robots, vision-based medical assistive technology), significant bodies of work from both machine learning and systems communities have attempted to provide optimisations that will make CNNs available to edge devices. In this paper we unify the two viewpoints in a Deep Learning Inference Stack and take an across-stack approach by implementing and evaluating the most common neural network compression techniques (weight pruning, channel pruning, and quantisation) and optimising their parallel execution with a range of programming approaches (OpenMP, OpenCL) and hardware architectures (CPU, GPU). We provide comprehensive Pareto curves to instruct trade-offs under constraints of accuracy, execution time, and memory space.","","978-1-5386-6780-4","10.1109/IISWC.2018.8573503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573503","","Neural networks;Quantization (signal);Hardware;Optimization;Image coding","convolution;data compression;feedforward neural nets;inference mechanisms;learning (artificial intelligence);Pareto optimisation","across-stack optimisations;deep convolutional neural networks;resource-constrained devices;obstacle detection;mobile robots;vision-based medical assistive technology;machine learning;across-stack approach;weight pruning;channel pruning;CNNs;neural network compression techniques;deep learning inference stack;quantisation;OpenMP;OpenCL;hardware architectures;Pareto curves","","13","","39","","13 Dec 2018","","","IEEE","IEEE Conferences"
"A Weak Supervision Technique with a Generative Model for Improved Gene Clustering","P. Dutta; S. Saha","Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, Bihar, India; Department of Computer Science and Engineering, Indian Institute of Technology Patna, Patna, Bihar, India","2019 IEEE Congress on Evolutionary Computation (CEC)","8 Aug 2019","2019","","","2521","2528","In the field of computational bioinformatics, for tasks such as medical diagnosis or disease gene classification, acquiring class labels is very much essential and costly. Now a days, labelling biomedical data became one of the crucial bottlenecks for developing supervised machine learning systems, as well as deep learning systems. On the contrary, weak supervision sources that generate diverse, semi-accurate or programmatically-generated labels are comparatively cheaper and less time consuming. In this paper, we have proposed a framework for integrating weak supervision sources with a generative model to estimate probabilistic class labels of the gene expression data. Here as the weak supervision source, a multi-objective optimization (MOO) based clustering technique is utilized. The non-dominated solutions of Pareto optimal front are viewed as the weak supervised labels. These weak supervised labels are fed to a generative model, which finally assigns probabilistic class labels to different genes. In this work, we have shown that our proposed generative model based clustering technique attains better Silhouette score (some quality measure of clustering) for three real-life NCBI gene expression data sets than other stateof-the-art methods, without using any labeled data. Finally, the superiority of the proposed method is validated by using a statistical and a biological significance test.","","978-1-7281-2153-6","10.1109/CEC.2019.8790052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790052","","Biological cells;Labeling;Gene expression;Optimization;Probabilistic logic;Data models","bioinformatics;diseases;genetics;optimisation;pattern classification;pattern clustering","gene clustering;clustering technique;computational bioinformatics;Pareto optimal front;Silhouette score;real-life NCBI gene expression data sets;weak supervised labels;probabilistic class labels;programmatically-generated labels;weak supervision source;deep learning systems;disease gene classification;medical diagnosis;generative model;weak supervision technique","","1","","50","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Automated High-Level Generation of Low-Power Approximate Computing Circuits","K. Nepal; S. Hashemi; H. Tann; R. I. Bahar; S. Reda","Brown University, Providence, RI; Brown University, Providence, RI; Brown University, Providence, RI; Brown University, Providence, RI; Brown University, Providence, RI","IEEE Transactions on Emerging Topics in Computing","6 Mar 2019","2019","7","1","18","30","Numerous application domains (e.g., signal and image processing, computer graphics, computer vision, and machine learning) are inherently error tolerant, which can be exploited to produce approximate ASIC implementations with low power consumption at the expense of negligible or small reductions in application quality. A major challenge is the need for approximate and high-level design generation tools that can automatically work on arbitrary designs. In this article, we provide an expanded and improved treatment of our ABACUS methodology, which aims to automatically generate approximate designs directly from their behavioral register-transfer level (RTL) descriptions, enabling a wider range of possible approximations. ABACUS starts by creating an abstract syntax tree (AST) from the input behavioral RTL description of a circuit, and then applies variant operators to the AST to create acceptable approximate designs. The devised variant operators include data type simplifications, arithmetic operation approximations, arithmetic expressions transformations, variable-to-constant substitutions, and loop transformations. A design space exploration technique is devised to explore the space of possible variant approximate designs and to identify the designs along the Pareto frontier that represents the trade-off between accuracy and power consumption. In addition, ABACUS prioritizes generating approximate designs that, when synthesized, lead to circuits with simplified critical paths, which are exploited to realize complementary power savings through standard voltage scaling. We integrate ABACUS with a standard ASIC design flow, and evaluate it on four realistic benchmarks from three different domains-machine learning, signal processing, and computer vision. Our tool automatically generates many approximate design variants with large power savings, while maintaining good accuracy. We demonstrate the scalability of ABACUS by parallelizing the flow and use of recent standard synthesis tools. Compared to our previous efforts, the new ABACUS tool provides up to 20.5× speed-up in runtime, while able to generate approximate circuits that lead to additional power savings reaching up to 40 percent.","2168-6750","","10.1109/TETC.2016.2598283","US National Science Foundation(grant numbers:1420864); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533498","Approximate computing;design space exploration;low power circuits;low area circuits;voltage scaling;critical path optimization","Logic gates;Adders;Standards;Approximation algorithms;Signal processing algorithms;Algorithm design and analysis;Power demand","application specific integrated circuits;approximation theory;formal verification;hardware description languages;high level synthesis;integrated circuit design;learning (artificial intelligence);logic design;low-power electronics;network synthesis;Pareto optimisation;power aware computing;trees (mathematics)","ABACUS tool;approximate circuits;additional power savings;automated high-level generation;low-power approximate computing circuits;computer graphics;computer vision;approximate ASIC implementations;low power consumption;high-level design generation tools;behavioral register-transfer level descriptions;acceptable approximate designs;devised variant operators;arithmetic operation approximations;design space exploration technique;possible variant approximate designs;complementary power savings;standard ASIC design flow;machine learning","","29","","33","IEEE","4 Aug 2016","","","IEEE","IEEE Journals"
"ABACUS: A technique for automated behavioral synthesis of approximate computing circuits","K. Nepal; Y. Li; R. I. Bahar; S. Reda","School of Engineering, Brown University, Providence, RI 02912; School of Engineering, Brown University, Providence, RI 02912; School of Engineering, Brown University, Providence, RI 02912; School of Engineering, Brown University, Providence, RI 02912","2014 Design, Automation & Test in Europe Conference & Exhibition (DATE)","21 Apr 2014","2014","","","1","6","Many classes of applications, especially in the domains of signal and image processing, computer graphics, computer vision, and machine learning, are inherently tolerant to inaccuracies in their underlying computations. This tolerance can be exploited to design approximate circuits that perform within acceptable accuracies but have much lower power consumption and smaller area footprints (and often better run times) than their exact counterparts. In this paper, we propose a new class of automated synthesis methods for generating approximate circuits directly from behavioral-level descriptions. In contrast to previous methods that operate at the Boolean level or use custom modifications, our automated behavioral synthesis method enables a wider range of possible approximations and can operate on arbitrary designs. Our method first creates an abstract synthesis tree (AST) from the input behavioral description, and then applies variant operators to the AST using an iterative stochastic greedy approach to identify the optimal inexact designs in an efficient way. Our method is able to identify the optimal designs that represent the Pareto frontier trade-off between accuracy and power consumption. Our methodology is developed into a tool we call ABACUS, which we integrate with a standard ASIC experimental flow based on industrial tools. We validate our methods on three realistic Verilog-based benchmarks from three different domains - signal processing, computer vision and machine learning. Our tool automatically discovers optimal designs, providing area and power savings of up to 50% while maintaining good accuracy.","1558-1101","978-3-9815370-2-4","10.7873/DATE.2014.374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6800575","","Approximation methods;Accuracy;Standards;Finite impulse response filters;Hardware design languages;Approximation algorithms;Algorithm design and analysis","application specific integrated circuits;approximation theory;hardware description languages;network synthesis;Pareto optimisation;trees (mathematics)","ABACUS technique;automated behavioral synthesis;approximate computing circuits;signal processing;image processing;computer graphics;computer vision;machine learning;power consumption;behavioral-level descriptions;approximations;abstract synthesis tree;AST;variant operators;iterative stochastic greedy approach;optimal designs;Pareto frontier trade-off;standard ASIC experimental flow;industrial tools;Verilog-based benchmarks","","","","20","","21 Apr 2014","","","IEEE","IEEE Conferences"
"Towards Intelligent Architecting of Aerospace System-of-Systems","C. Guariniello; L. Mockus; A. K. Raz; D. A. DeLaurentis","Sch. of Aeronaut. & Astronaut., Purdue Univ., West Lafayette, IN, USA; Sch. of Aeronaut. & Astronaut., Purdue Univ., West Lafayette, IN, USA; Sch. of Aeronaut. & Astronaut., Purdue Univ., West Lafayette, IN, USA; Sch. of Aeronaut. & Astronaut., Purdue Univ., West Lafayette, IN, USA","2019 IEEE Aerospace Conference","20 Jun 2019","2019","","","1","11","System-of-Systems (SoS) are composed of large scale independent and complex heterogeneous systems which collaborate to create capabilities not achievable by a single system, for example air transportation system, satellite constellations, and space exploration architectures. Much of the research effort in the field of SoS has focused on the analysis of these complex entities, while there are still major gaps in developing tools for automated synthesis and engineering of SoS that consider all the various aspects in this problem domain. The gap we address in this paper is a mapping of clusters of SoS architecture alternatives, segmented by performance along multiple metrics, to architectural features. Building upon our previous research where we used a SoS Analytic Work Bench in combination with Model-Based Systems Engineering artifacts to perform analysis of aerospace systems, we propose to build a process for intelligent architecting of aerospace SoS. This process discovers and employs pertinent features in a complex design space to effectively meet the user needs, elevating SoS engineering from retrospective architectural analysis to automated synthesis of new architectures. As a first step towards intelligent architecture of aerospace SoS, we propose to utilize Machine Learning techniques to automate the synthesis phase of SoS. Our hypothesis is that a set of holistic metrics of aerospace architectures (cost, performance, robustness, operational risk, average delay, etc.) can be used to characterize a measure of goodness of architectures, with good architectures on a Pareto front of the multi-dimensional space of holistic metrics of interest. Each architecture or cluster may be then mapped to a set of architectural features, with the goal of identifying which features belong to good architectures. Specifically, we propose to utilize non-parametric regression on a set of training architectures (for example, Neural Networks can deal with mixed real and integer variables) to associate each one with a pattern of features. This mapping will allow the automated process to predict what metrics will be expected from SoS architectures with specific features, and therefore to automatically synthesize architectures that exhibit desired characteristics of goodness. For example, for constellations of satellites, a group of good architecture might have medium cost, high resilience, medium robustness, and low risk, and the architectural features to be mapped to each group can include number of satellites, number of components, type of orbit, type of power system, etc. Since the environment constantly evolves, architectures must adapt, and stochastic optimization can be used to switch between architectures with minimal effort. In this work we illustrate the new version of our aerospace SoS analysis and synthesis framework, which includes Machine Learning techniques to support synthesis of SoS architectures. We demonstrate the application of this process on satellite constellations and discuss challenges of this approach and future steps.","1095-323X","978-1-5386-6854-2","10.1109/AERO.2019.8742173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742173","","Measurement;Computer architecture;Tools;Analytical models;Machine learning","aerospace computing;learning (artificial intelligence);optimisation;pattern clustering;regression analysis;systems engineering","aerospace system-of-systems;complex heterogeneous systems;satellite constellations;space exploration architectures;automated synthesis;architectural features;pertinent features;complex design space;SoS engineering;retrospective architectural analysis;intelligent architecture;aerospace architectures;operational risk;automated process;SoS architectures;power system;aerospace SoS analysis;air transportation system;SoS architecture;model-based systems engineering artifacts;SoS analytic work;machine learning techniques;nonparametric regression;stochastic optimization","","3","","23","","20 Jun 2019","","","IEEE","IEEE Conferences"
"Learning variable importance to guide recombination","M. Sagawa; H. Aguirre; F. Daolio; A. Liefooghe; B. Derbel; S. Verel; K. Tanaka","Faculty of Engineering, Shinshu University, Nagano, Japan; Faculty of Engineering, Shinshu University, Nagano, Japan; Faculty of Engineering, Shinshu University, Nagano, Japan; Univ. Lille, CNRS, UMR 9189 - CRIStAL / Inria Lille-Nord Europe, France; Univ. Lille, CNRS, UMR 9189 - CRIStAL / Inria Lille-Nord Europe, France; Univ. Littoral Côte d'Opale, LISIC, France; Faculty of Engineering, Shinshu University, Nagano, Japan","2016 IEEE Symposium Series on Computational Intelligence (SSCI)","13 Feb 2017","2016","","","1","7","In evolutionary multi-objective optimization, variation operators are crucially important to produce improving solutions, hence leading the search towards the most promising regions of the solution space. In this paper, we propose to use a machine learning modeling technique, namely random forest, in order to estimate, at each iteration in the course of the search process, the importance of decision variables with respect to convergence to the Pareto front. Accordingly, we are able to propose an adaptive mechanism guiding the recombination step with the aim of stressing the convergence of the so-obtained offspring. By conducting an experimental analysis using some of the WFG and DTLZ benchmark test problems, we are able to elicit the behavior of the proposed approach, and to demonstrate the benefits of incorporating machine learning techniques in order to design new efficient adaptive variation mechanisms.","","978-1-5090-4240-1","10.1109/SSCI.2016.7850229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850229","","Convergence;Vegetation;Pareto optimization;Sociology;Benchmark testing","benchmark testing;evolutionary computation;learning (artificial intelligence);Pareto optimisation","DTLZ benchmark test;WFG benchmark test;Pareto front;decision variables;random forest;machine learning modeling;variation operators;evolutionary multiobjective optimization;learning variable","","3","","11","","13 Feb 2017","","","IEEE","IEEE Conferences"
"Neural networks designing neural networks: Multi-objective hyper-parameter optimization","S. C. Smithson; Guang Yang; W. J. Gross; B. H. Meyer","Department of Electrical and Computer Engineering, McGill University, Montreal, Canada; Department of Electrical and Computer Engineering, McGill University, Montreal, Canada; Department of Electrical and Computer Engineering, McGill University, Montreal, Canada; Department of Electrical and Computer Engineering, McGill University, Montreal, Canada","2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)","23 Jan 2017","2016","","","1","8","Artificial neural networks have gone through a recent rise in popularity, achieving state-of-the-art results in various fields, including image classification, speech recognition, and automated control. Both the performance and computational complexity of such models are heavily dependant on the design of characteristic hyper-parameters (e.g., number of hidden layers, nodes per layer, or choice of activation functions), which have traditionally been optimized manually. With machine learning penetrating low-power mobile and embedded areas, the need to optimize not only for performance (accuracy), but also for implementation complexity, becomes paramount. In this work, we present a multi-objective design space exploration method that reduces the number of solution networks trained and evaluated through response surface modelling. Given spaces which can easily exceed 10<sup>20</sup> solutions, manually designing a near-optimal architecture is unlikely as opportunities to reduce network complexity, while maintaining performance, may be overlooked. This problem is exacerbated by the fact that hyper-parameters which perform well on specific datasets may yield sub-par results on others, and must therefore be designed on a per-application basis. In our work, machine learning is leveraged by training an artificial neural network to predict the performance of future candidate networks. The method is evaluated on the MNIST and CIFAR-10 image datasets, optimizing for both recognition accuracy and computational complexity. Experimental results demonstrate that the proposed method can closely approximate the Pareto-optimal front, while only exploring a small fraction of the design space.","1558-2434","978-1-4503-4466-1","10.1145/2966986.2967058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827681","","Optimization;Neural networks;Computational modeling;Training;Feature extraction;Space exploration;Computational complexity","computational complexity;learning (artificial intelligence);neural nets;Pareto optimisation;response surface methodology","multiobjective hyper-parameter optimization;artificial neural network training;multiobjective design space exploration;response surface modelling;near-optimal architecture;network complexity;machine learning;future candidate network performance prediction;MNIST image datasets;CIFAR-10 image datasets;recognition accuracy;computational complexity;Pareto-optimal front","","12","2","22","","23 Jan 2017","","","IEEE","IEEE Conferences"
"Incremental information gain analysis of input attribute impact on RBF-kernel SVM spam detection","H. He; A. Tiwari; J. Mehnen; T. Watson; C. Maple; Y. Jin; B. Gabrys","School of Aerospace, Transport and Manufacturing, Cranfield University, Cranfield, MK43 OAL, UK; School of Aerospace, Transport and Manufacturing, Cranfield University, Cranfield, MK43 OAL, UK; School of Aerospace, Transport and Manufacturing, Cranfield University, Cranfield, MK43 OAL, UK; Cyber Security Centre - WMG, University of Warwick, UK; Cyber Security Centre - WMG, University of Warwick, UK; Department of Computer Science, University of Surrey, UK; School of Design, Engineering & Computing, Bournemouth University, UK","2016 IEEE Congress on Evolutionary Computation (CEC)","21 Nov 2016","2016","","","1022","1029","The massive increase of spam is posing a very serious threat to email and SMS, which have become an important means of communication. Not only do spams annoy users, but they also become a security threat. Machine learning techniques have been widely used for spam detection. Email spams can be detected through detecting senders' behaviour, the contents of an email, subject and source address, etc, while SMS spam detection usually is based on the tokens or features of messages due to short content. However, a comprehensive analysis of email/SMS content may provide cures for users to aware of email/SMS spams. We cannot completely depend on automatic tools to identify all spams. In this paper, we propose an analysis approach based on information entropy and incremental learning to see how various features affect the performance of an RBF-based SVM spam detector, so that to increase our awareness of a spam by sensing the features of a spam. The experiments were carried out on the spambase and SMSSpemCollection databases in UCI machine learning repository. The results show that some features have significant impacts on spam detection, of which users should be aware, and there exists a feature space that achieves Pareto efficiency in True Positive Rate and True Negative Rate.","","978-1-5090-0623-6","10.1109/CEC.2016.7743901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743901","","Electronic mail;Support vector machines;Feature extraction;Decision making;Entropy;Kernel;Frequency measurement","entropy;feature extraction;learning (artificial intelligence);radial basis function networks;security of data;support vector machines;unsolicited e-mail","incremental information gain analysis;input attribute impact;RBF-kernel SVM spam detection;SMS spam detection;email content analysis;email spams;information entropy;incremental learning;spambase;SMSSpemCollection databases;UCI machine learning repository;Pareto efficiency;true positive rate;true negative rate;SMS content analysis","","8","","24","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Efficient Bitrate Ladder Construction for Content-Optimized Adaptive Video Streaming","A. V. Katsenou; J. Sole; D. R. Bull","University of Bristol, Bristol, U.K.; Netflix, Inc, Los Gatos, California, CA, USA; University of Bristol, Bristol, U.K.","IEEE Open Journal of Signal Processing","28 Sep 2021","2021","2","","496","511","One of the challenges faced by many video providers is the heterogeneity of network specifications, user requirements, and content compression performance. The universal solution of a fixed bitrate ladder is inadequate in ensuring a high quality of user experience without re-buffering or introducing annoying compression artifacts. However, a content-tailored solution, based on extensively encoding across all resolutions and over a wide quality range is highly expensive in terms of computational, financial, and energy costs. Inspired by this, we propose an approach that exploits machine learning to predict a content-optimized bitrate ladder for on-demand video services. The method extracts spatio-temporal features from the uncompressed content, trains machine-learning models to predict the Pareto front parameters and, based on that, builds the ladder within a defined bitrate range. The method has the benefit of significantly reducing the number of encodes required per sequence. The presented results, based on 100 HEVC-encoded sequences, demonstrate a reduction in the number of encodes required when compared to an exhaustive search and an interpolation-based method, by 89.06% and 61.46%, respectively, at the cost of an average Bjøntegaard Delta Rate difference of 1.78% compared to the exhaustive approach. Finally, a hybrid method is introduced that selects either the proposed or the interpolation-based method depending on the sequence features. This results in an overall 83.83% reduction of required encodings at the cost of an average Bjøntegaard Delta Rate difference of 1.26%.","2644-1322","","10.1109/OJSP.2021.3086691","Leverhulme Early Career Fellowship(grant numbers:ECF-2017-413); Netflix Inc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447213","Bitrate ladder;adaptive video streaming;rate-quality curves;video compression;HEVC","Bit rate;Streaming media;Spatial resolution;Video compression;High efficiency video coding;Feature extraction","","","","","","60","CCBY","4 Jun 2021","","","IEEE","IEEE Journals"
"Gram-Schmidt orthogonalization neural nets for OCR","Szu; Scheff","US Naval Res. Lab., Washington, DC, USA; NA","International 1989 Joint Conference on Neural Networks","6 Aug 2002","1989","","","547","555 vol.1","A description is given of a three-layer neural network for pattern classification/character recognition. The first layer is a heteroassociative feedforward network with bipolar output (+or-1) and zero threshold neurons. The second layer is an autoassociative memory whose input-output characteristics are the same as those in the first layer. The third layer is used to recognize the pattern and control whether the new orthogonal feature vector should be installed by the outer product formula to increase the memory capacity to M'=M+1. With this network, conventional pattern recognition of the minimax type is used to determine the initial interconnection matrix. The samples are classified by means of supervised learning. Only a single physical layer need be built, since the same layer can repeatedly be used three times in series. The performance of the network is studied.<<ETX>></ETX>","","","10.1109/IJCNN.1989.118632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=118632","","Minimax methods;Neural networks;Optical character recognition","minimax techniques;neural nets;optical character recognition","optical character recognition;Gram-Schmidt orthogonalization neural nets;OCR;heteroassociative feedforward network;bipolar output;zero threshold neurons;autoassociative memory;pattern recognition;minimax;interconnection matrix","","5","","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Universal Learning of Individual Data","Y. Fogel; M. Feder","School of Electrical Engineering, Tel Aviv University; School of Electrical Engineering, Tel Aviv University","2019 IEEE International Symposium on Information Theory (ISIT)","26 Sep 2019","2019","","","2289","2293","Universal supervised learning of individual data is considered from an information theoretic point of view in the standard supervised “batch” learning where prediction is done on a test sample once the entire training data is observed. In this individual setting the features and labels, both in the training and the test, are specific individual, deterministic quantities. Prediction loss is naturally measured by the log-loss. The presented results provide a minimax universal learning scheme, termed the Predictive Normalized Maximum Likelihood (pNML) that competes with a “genie” (or reference) that knows the true test label. In addition, a pointwise learnability measure associated with the pNML, for the specific training and test, is provided. This measure may also indicate the performance of the commonly used Empirical Risk Minimizer (ERM) learner.","2157-8117","978-1-5386-9291-2","10.1109/ISIT.2019.8849222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8849222","","Data handling;Learning (artificial intelligence);Maximum likelihood estimation;Supervised learning;Minimax techniques","data handling;learning (artificial intelligence);maximum likelihood estimation;minimax techniques","standard supervised batch learning;test sample;specific individual quantities;deterministic quantities;prediction loss;log-loss;minimax universal learning scheme;test label;pointwise learnability measure;training data;predictive normalized maximum likelihood","","1","","16","","26 Sep 2019","","","IEEE","IEEE Conferences"
"Semi-Supervised Multiple Instance Learning and its application in visual tracking","Y. Zhou; A. Ming","School of Computer Science, Institute of Sensing Technology and Business (WuXi), Beijing University of Posts and Telecommunications, Beijing, P.R. China; School of Computer Science, Institute of Sensing Technology and Business (WuXi), Beijing University of Posts and Telecommunications, Beijing, P.R. China","2016 8th International Conference on Wireless Communications & Signal Processing (WCSP)","24 Nov 2016","2016","","","1","5","In this paper, a novel Semi-Supervised Multiple Instance Learning (Semi-MIL) approach is presented. Compared with conventional approaches, we utilize a kind of “bag of instances” representation in the semi-supervised learning process, which provides an effective way to use the unlabeled data in multiple instance learning problem. We formulate the problem with a graph model based on the Minimax kernel. In addition, the Semi-MIL algorithm is readily applied for visual tracking, which can resolve the ambiguities during the tracking process. The presented approach is validated on several benchmark videos for visual tracking and MUSKs dataset for classification, the competitive experimental results demonstrate the effectiveness of our approach.","2472-7628","978-1-5090-2860-3","10.1109/WCSP.2016.7752532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7752532","","Adaptation models;Visualization;Videos;Kernel;Semisupervised learning;Target tracking","graph theory;learning (artificial intelligence);minimax techniques;tracking;video signal processing","semisupervised multiple instance learning;visual tracking;semiMIL approach;bag of instances representation;graph model;minimax kernel;tracking process;MUSK dataset;benchmark videos","","","","19","","24 Nov 2016","","","IEEE","IEEE Conferences"
"A Multi-objective Learning Algorithm for RBF Neural Network","I. Kokshenev; A. P. Braga","Depto. Eng. Eletron., Univ. Fed. de Minas Gerais, Belo Horizonte; Depto. Eng. Eletron., Univ. Fed. de Minas Gerais, Belo Horizonte","2008 10th Brazilian Symposium on Neural Networks","5 Nov 2008","2008","","","9","14","In this paper, the problem of multi-objective supervised learning is discussed within the non-evolutionary optimization framework. The proposed MOBJ learning algorithm performs the search of Pareto-optimal models determining weights,width, prototype vectors, and the quantity of basis functions of the RBF network. In combination with the Akaike information criterion, the algorithm provides high quality solutions.","2375-0235","978-1-4244-3219-6","10.1109/SBRN.2008.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665884","multi-objective learning;radial basis functions;generalization;regularization;LASSO","Neural networks;Supervised learning;Optimization methods;Minimization methods;Prototypes;Radial basis function networks;Machine learning algorithms;Machine learning;Statistical learning;Risk management","learning (artificial intelligence);Pareto optimisation;radial basis function networks;search problems","multiobjective supervised learning algorithm;RBF neural network;nonevolutionary optimization framework;Pareto-optimal search;Akaike information criterion","","3","","20","","5 Nov 2008","","","IEEE","IEEE Conferences"
"Multi-Source Spatial Entity Linkage","S. Isaj; T. B. Pedersen; E. Zimányi","Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer and Decision Engineering, Université libre de Bruxelles, Bruxelles, Belgium","IEEE Transactions on Knowledge and Data Engineering","3 Feb 2022","2022","34","3","1344","1358","Besides the traditional cartographic data sources, spatial information can also be derived from location-based sources. However, even though different location-based sources refer to the same physical world, each one has only partial coverage of the spatial entities, describe them with different attributes, and sometimes provide contradicting information. Hence, we introduce the spatial entity linkage problem, which finds which pairs of spatial entities belong to the same physical spatial entity. Our proposed solution (<italic>QuadSky</italic>) starts with a time-efficient spatial blocking technique (<italic>QuadFlex</italic>), compares pairwise the spatial entities in the same block, ranks the pairs using Pareto optimality with the <italic>SkyRank</italic> algorithm, and finally, classifies the pairs with our novel <italic>SkyEx-*</italic> family of algorithms that yield 0.85 <italic>precision</italic> and 0.85 <italic>recall</italic> for a manually labeled dataset of 1,500 pairs and 0.87 <italic>precision</italic> and 0.6 <italic>recall</italic> for a semi-manually labeled dataset of 777,452 pairs. Moreover, we provide a theoretical guarantee and formalize the <italic>SkyEx-FES</italic> algorithm that explores only 27 percent of the skylines without any loss in <italic>F-measure</italic>. Furthermore, our fully unsupervised algorithm <italic>SkyEx-D</italic> approximates the optimal result with an <italic>F-measure</italic> loss of just 0.01. Finally, <italic>QuadSky</italic> provides the best trade-off between <italic>precision</italic> and <italic>recall</italic>, and the best <italic>F-measure</italic> compared to the existing baselines and clustering techniques, and approximates the results of supervised learning solutions.","1558-2191","","10.1109/TKDE.2020.2990491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079585","spatial data;entity resolution;spatial blocking;skyline-based","Couplings;Spatial resolution;Spatial databases;Approximation algorithms;Clustering algorithms;Tools;Data integration","","","","","","52","CCBY","27 Apr 2020","","","IEEE","IEEE Journals"
"ADA: Adaptive Deep Log Anomaly Detector","Y. Yuan; S. Srikant Adhatarao; M. Lin; Y. Yuan; Z. Liu; X. Fu","University of Göttingen,Germany; University of Göttingen,Germany; Nanjing University,Nanjing,China; University of Göttingen,Germany; Nankai University,Tianjin,China; University of Göttingen,Germany","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications","4 Aug 2020","2020","","","2449","2458","Large private and government networks are often subjected to attacks like data extrusion and service disruption. Existing anomaly detection systems use offline supervised learning and employ experts for labeling. Hence they cannot detect anomalies in real-time. Even though unsupervised algorithms are increasingly used nowadays, they cannot readily adapt to newer threats. Moreover, many such systems also suffer from high cost of storage and require extensive computational resources. In this paper, we propose ADA: Adaptive Deep Log Anomaly Detector, an unsupervised online deep neural network framework that leverages LSTM networks and regularly adapts to newer log patterns to ensure accurate anomaly detection. In ADA, an adaptive model selection strategy is designed to choose pareto-optimal configurations and thereby utilize resources efficiently. Further, a dynamic threshold algorithm is proposed to dictate the optimal threshold based on recently detected events to improve the detection accuracy. We also use the predictions to guide storage of abnormal data and effectively reduce the overall storage cost. We compare ADA with state-of-the-art approaches through leveraging the Los Alamos National Laboratory cyber security dataset and show that ADA accurately detects anomalies with high F1-score ~95% and it is 97 times faster than existing approaches and incurs very low storage cost.","2641-9874","978-1-7281-6412-0","10.1109/INFOCOM41043.2020.9155487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155487","Anomaly detection;deep neural networks;logs;online training;unsupervised;log-normal;threshold","Adaptation models;Anomaly detection;Computational modeling;Predictive models;Neural networks;Machine learning;Heuristic algorithms","learning (artificial intelligence);neural nets;security of data","anomaly detection systems;offline supervised learning;employ experts;ADA;Adaptive Deep Log Anomaly Detector;unsupervised online deep neural network framework;newer log patterns;accurate anomaly detection;adaptive model selection strategy;recently detected events;detection accuracy;private government networks;data extrusion;service disruption","","7","","34","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Adversarial Feature Augmentation for Unsupervised Domain Adaptation","R. Volpi; P. Morerio; S. Savarese; V. Murino",NA; NA; NA; NA,"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","5495","5504","Recent works showed that Generative Adversarial Networks (GANs) can be successfully applied in unsupervised domain adaptation, where, given a labeled source dataset and an unlabeled target dataset, the goal is to train powerful classifiers for the target samples. In particular, it was shown that a GAN objective function can be used to learn target features indistinguishable from the source ones. In this work, we extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation. While data augmentation in the image space is a well established technique in deep learning, feature augmentation has not yet received the same level of attention. We accomplish it by means of a feature generator trained by playing the GAN minimax game against source features. Results show that both enforcing domain-invariance and performing feature augmentation lead to superior or comparable performance to state-of-the-art results in several unsupervised domain adaptation benchmarks.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578674","","Feature extraction;Gallium nitride;Training;Games;Generative adversarial networks;Generators;Neural networks","feature extraction;image classification;learning (artificial intelligence);object recognition;unsupervised learning","labeled source dataset;unlabeled target dataset;powerful classifiers;target samples;GAN objective function;target features;data augmentation;feature space;feature generator;GAN minimax game;source features;unsupervised domain adaptation benchmarks;generative adversarial networks;feature extractor;feature augmentation;adversarial feature augmentation","","81","1","37","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Transferring Structured Knowledge in Unsupervised Domain Adaptation of a Sleep Staging Network","C. Yoo; H. W. Lee; J. -W. Kang","Department of Electronic and Electrical Engineering and Graduate Program in Smart Factory, Ewha Womans University, Seoul, Korea; Departments of Neurology, Medical Science, Computational Medicine, College of Medicine, and Graduate Program in System Health Science and Engineering, Ewha Womans University, Seoul, Korea; Department of Electronic and Electrical Engineering and Graduate Program in Smart Factory, Ewha Womans University, Seoul, Korea","IEEE Journal of Biomedical and Health Informatics","7 Mar 2022","2022","26","3","1273","1284","Automatic sleep staging based on deep learning (DL) has been attracting attention for analyzing sleep quality and determining treatment effects. It is challenging to acquire long-term sleep data from numerous subjects and manually labeling them even though most DL-based models are trained using large-scale sleep data to provide state-of-the-art performance. One way to overcome this data shortage is to create a pre-trained network with an existing large-scale dataset (source domain) that is applicable to small cohorts of datasets (target domain); however, discrepancies in data distribution between the domains prevent successful refinement of this approach. In this paper, we propose an unsupervised domain adaptation method for sleep staging networks to reduce discrepancies by re-aligning the domains in the same space and producing domain-invariant features. Specifically, in addition to a classical domain discriminator, we introduce local discriminators - <italic>subject and stage</italic> - to maintain the intrinsic structure of sleep data to decrease local misalignments while using adversarial learning to play a minimax game between the feature extractor and discriminators. Moreover, we present several optimization schemes during training because the conventional adversarial learning is not effective to our training scheme. We evaluate the performance of the proposed method by examining the staging performances of a baseline network compared with direct transfer (DT) learning in various conditions. The experimental results demonstrate that the proposed domain adaptation significantly improves the performance though it needs no labeled sleep data in target domain.","2168-2208","","10.1109/JBHI.2021.3103614","National Research Foundation of Korea; Ministry of Science and ICT, South Korea(grant numbers:NRF-2019M3C1B8090803,NRF-2019M3C1B8090804); Ewha Womans University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513578","Sleep staging;unsupervised domain adaptation;local alignment;knowledge transfer","Sleep;Training;Feature extraction;Brain modeling;Electroencephalography;Adversarial machine learning;Adaptation models","","","Attention;Humans;Sleep;Sleep Stages","1","","45","IEEE","13 Aug 2021","","","IEEE","IEEE Journals"
"Feature-Level Frankenstein: Eliminating Variations for Discriminative Recognition","X. Liu; S. Li; L. Kong; W. Xie; P. Jia; J. You; B. V. K. Kumar","CMU; CMU; Carnegie Mellon Univ.; Changchun Institute of Optics, Fine Mechanics and Physics; Harvard Medical School; HK Poly U; Changchun Institute of Optics, Fine Mechanics and Physics","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","637","646","Recent successes of deep learning-based recognition rely on maintaining the content related to the main-task label. However, how to explicitly dispel the noisy signals for better generalization remains an open issue. We systematically summarize the detrimental factors as task-relevant/irrelevant semantic variations and unspecified latent variation. In this paper, we cast these problems as an adversarial minimax game in the latent space. Specifically, we propose equipping an end-to-end conditional adversarial network with the ability to decompose an input sample into three complementary parts. The discriminative representation inherits the desired invariance property guided by prior knowledge of the task, which is marginally independent to the task-relevant/irrelevant semantic and latent variations. Our proposed framework achieves top performance on a serial of tasks, including digits recognition, lighting, makeup, disguise-tolerant face recognition, and facial attributes recognition.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954357","Recognition: Detection;Categorization;Retrieval;Biometrics","","face recognition;feature extraction;game theory;image representation;learning (artificial intelligence)","facial attributes recognition;feature-level frankenstein;discriminative recognition;deep learning-based recognition;main-task label;noisy signals;detrimental factors;unspecified latent variation;adversarial minimax game;latent space;end-to-end conditional adversarial network;discriminative representation;desired invariance property;latent variations;digits recognition;disguise-tolerant face recognition","","20","","65","","9 Jan 2020","","","IEEE","IEEE Conferences"
"NAS-OoD: Neural Architecture Search for Out-of-Distribution Generalization","H. Bai; F. Zhou; L. Hong; N. Ye; S. . -H. G. Chan; Z. Li",The Hong Kong University of Science and Technology; Huawei Noah’s Ark Lab; Huawei Noah’s Ark Lab; Shanghai Jiao Tong University; The Hong Kong University of Science and Technology; Huawei Noah’s Ark Lab,"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","8300","8309","Recent advances on Out-of-Distribution (OoD) generalization reveal the robustness of deep learning models against distribution shifts. However, existing works focus on OoD algorithms, such as invariant risk minimization, domain generalization, or stable learning, without considering the influence of deep model architectures on OoD generalization, which may lead to sub-optimal performance. Neural Architecture Search (NAS) methods search for architecture based on its performance on the training data, which may result in poor generalization for OoD tasks. In this work, we propose robust Neural Architecture Search for OoD generalization (NAS-OoD), which optimizes the architecture with respect to its performance on generated OoD data by gradient descent. Specifically, a data generator is learned to synthesize OoD data by maximizing losses computed by different neural architectures, while the goal for architecture search is to find the optimal architecture parameters that minimize the synthetic OoD data losses. The data generator and the neural architecture are jointly optimized in an end-to-end manner, and the minimax training process effectively discovers robust architectures that generalize well for different distribution shifts. Extensive experimental results show that NAS-OoD achieves superior performance on various OoD generalization benchmarks with deep models having a much fewer number of parameters. In addition, on a real industry dataset, the proposed NAS-OoD method reduces the error rate by more than 70% compared with the state-of-the-art method, demonstrating the proposed method’s practicality for real applications.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.00821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711448","Transfer/Low-shot/Semi/Unsupervised Learning; Visual reasoning and logical representation","Training;Industries;Error analysis;Training data;Computer architecture;Network architecture;Generators","","","","","","49","","28 Feb 2022","","","IEEE","IEEE Conferences"
"A Unified Classification Model Based on Robust Optimization","A. Takeda; H. Mitsugi; T. Kanamori","NA; Department of Administration Engineering, Keio University, Kouhoku, Yokohama, Kanagawa 223-8522, Japan kiyurohi7@z2.keio.jp; Nagoya University, Chikusa-ku, Nagoya-shi, Aichi 464-8603, Japan kanamori@is.nagoya-u.ac.jp","Neural Computation","19 May 2014","2013","25","3","759","804","A wide variety of machine learning algorithms such as the support vector machine (SVM), minimax probability machine (MPM), and Fisher discriminant analysis (FDA) exist for binary classification. The purpose of this letter is to provide a unified classification model that includes these models through a robust optimization approach. This unified model has several benefits. One is that the extensions and improvements intended for SVMs become applicable to MPM and FDA, and vice versa. For example, we can obtain nonconvex variants of MPM and FDA by mimicking Perez-Cruz, Weston, Hermann, and Schölkopf's (<xref ref-type=""bibr"" rid=""B19"">2003</xref>) extension from convex ν-SVM to nonconvex Eν-SVM. Another benefit is to provide theoretical results concerning these learning methods at once by dealing with the unified model. We give a statistical interpretation of the unified classification model and prove that the model is a good approximation for the worst-case minimization of an expected loss with respect to the uncertain probability distribution. We also propose a nonconvex optimization algorithm that can be applied to nonconvex variants of existing learning methods and show promising numerical results.","0899-7667","","10.1162/NECO_a_00412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797475","","","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"A Military Chess Game Tree Algorithm Based on Refresh Probability Table","S. Pan; J. Wu; Y. Sun; Y. Qu","Shenyang Aerospace University,School of computer science,Shenyang,110136; Shenyang Aerospace University,School of computer science,Shenyang,110136; Shenyang Aerospace University,School of computer science,Shenyang,110136; Shenyang Aerospace University,School of computer science,Shenyang,110136","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","4818","4823","Computer game is divided into complete information game and incomplete information game. As a kind of incomplete information game, military chess game has many shortcomings in game-tree algorithm. In view of the fact that it is difficult to develop the game-tree because the specific information of the opponent's chess pieces can not be obtained accurately in military chess game, this paper proposes an algorithm to expand the game tree by refreshing the probability table formed by the rules of military chess, the result of the opponent's chess game and the result of the collision of the two opponents' chess pieces. The algorithm of the refresh probability table is used to provide the score support of the expanded game tree for the military chess game, thereby ensuring the expansion of the game tree. The initial values and weights in the refresh probability table algorithm are optimized by machine learning to improve the speed and accuracy of the refresh probability table, and the game tree is optimized by the minimax algorithm and the Alpha-beta pruning algorithm. Experiments show that the refresh probability table algorithm based on the game tree improves the winning rate in the game and has achieved good results.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164878","Computer Game;Military chess;Probability table and Game tree","Games;Weapons;Data structures;Probability;Machine learning algorithms;Military computing;Companies","computer games;learning (artificial intelligence);minimax techniques;probability;trees (mathematics)","Alpha-beta pruning algorithm;minimax algorithm;machine learning;incomplete information game;complete information game;computer game;military chess game tree algorithm;refresh probability table algorithm","","1","","20","","11 Aug 2020","","","IEEE","IEEE Conferences"
"Divergence-based characterization of fundamental limitations of adaptive dynamical systems","M. Raginsky","Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA","2010 48th Annual Allerton Conference on Communication, Control, and Computing (Allerton)","4 Feb 2011","2010","","","107","114","Adaptive dynamical systems arise in a multitude of contexts, e.g., optimization, control, communications, signal processing, and machine learning. A precise characterization of their fundamental limitations is therefore of paramount importance. In this paper, we consider the general problem of adaptively controlling and/or identifying a stochastic dynamical system, where our a priori knowledge allows us to place the system in a subset of a metric space (the uncertainty set). We present an information-theoretic meta-theorem that captures the trade-off between the metric complexity (or richness) of the uncertainty set, the amount of information acquired online in the process of controlling and observing the system, and the residual uncertainty remaining after the observations have been collected. Following the approach of Zames, we quantify a priori information by the Kolmogorov (metric) entropy of the uncertainty set, while the information acquired online is expressed as a sum of information divergences. The general theory is used to derive new minimax lower bounds on the metric identification error, as well as to give a simple derivation of the minimum time needed to stabilize an uncertain stochastic linear system.","","978-1-4244-8216-0","10.1109/ALLERTON.2010.5706895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706895","","Uncertainty;Measurement;Yttrium;Markov processes;Kernel;Control systems","adaptive systems;entropy;linear systems;stochastic systems;uncertain systems","divergence-based characterization;adaptive dynamical systems;stochastic dynamical system;information-theoretic metatheorem;metric complexity;Kolmogorov entropy;information divergence;metric identification error;uncertain stochastic linear system","","5","","24","","4 Feb 2011","","","IEEE","IEEE Conferences"
"One-Shot Face Recognition via Generative Learning","Z. Ding; Y. Guo; L. Zhang; Y. Fu","Dept. of Electr. & Comput. Eng., Northeastern Univ., Boston, MA, USA; Microsoft Res., Redmond, WA, USA; Microsoft Res., Redmond, WA, USA; Dept. of Electr. & Comput. Eng., Northeastern Univ., Boston, MA, USA","2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)","7 Jun 2018","2018","","","1","7","One-shot face recognition measures the ability to recognize persons with only seeing them once, which is a hallmark of human visual intelligence. It is challenging for existing machine learning approaches to mimic this way, since limited data cannot well represent the data variance. To this end, we propose to build a large-scale face recognizer, which is capable to fight off the data imbalance difficulty. To seek a more effective general classifier, we develop a novel generative model attempting to synthesize meaningful data for one-shot classes by adapting the data variances from other normal classes. Specifically, we formulate conditional generative adversarial networks and the general Softmax classifier into a unified framework. Such a two-player minimax optimization can guide the generation of more effective data, which benefit the classifier learning for one-shot classes. The experimental results on a large-scale face benchmark with 21K persons verify the effectiveness of our proposed algorithm in one-shot classification, as our generative model significantly improves the recognition coverage rate from 25:65% to 94:84% at the precision of 99% for the one-shot classes, while still keeps an overall Top-1 accuracy at 99:80% for the normal classes.","","978-1-5386-2335-0","10.1109/FG.2018.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373804","one shot learning;face recognition;generative model","Face recognition;Face;Training;Generators;Data models;Adaptation models;Feature extraction","face recognition;image classification;learning (artificial intelligence);minimax techniques","one-shot face recognition;generative learning;human visual intelligence;machine learning;data variance;large-scale face recognizer;data imbalance difficulty;one-shot classes;normal classes;conditional generative adversarial networks;general Softmax classifier;one-shot classification;recognition coverage rate;two-player minimax optimization;classifier learning","","18","","34","","7 Jun 2018","","","IEEE","IEEE Conferences"
"Development of a Software Library for Game Artificial Intelligence","B. Maksim; W. Pavel; V. Irina; S. Mikhail; C. Margarita","School of Electronic Engineering and Computer Science, South Ural State University,Chelyabinsk,Russia; School of Electronic Engineering and Computer Science, South Ural State University,Chelyabinsk,Russia; School of Electronic Engineering and Computer Science, South Ural State University,Chelyabinsk,Russia; School of Electronic Engineering and Computer Science, South Ural State University,Chelyabinsk,Russia; School of Electronic Engineering and Computer Science, South Ural State University,Chelyabinsk,Russia","2020 International Conference Quality Management, Transport and Information Security, Information Technologies (IT&QM&IS)","21 Jan 2021","2020","","","188","192","Today, technologies of artificial neural networks are very popular and are used in various fields and tasks, such as pattern recognition, classification. To create artificial neural networks, constructors or software libraries for machine learning can be used. However, they do not always contain the necessary functions. In some cases, you need to write your own software library to solve non-standard tasks. The article discusses the development of a software library for creating artificial neural networks. Using the developed library is demonstrated in the task of implementing the game artificial intelligence of the opponent in a simple computer game “Tic-tac-toe”. The effectiveness of the opponent's game is compared with the implementations of opponents based on the minimax algorithm and the random behavior algorithm.","","978-1-7281-8179-0","10.1109/ITQMIS51053.2020.9322928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322928","artificial neural networks;gaming artificial intelligence;game “Tic-tac-toe”;library","Games;Neurons;Biological neural networks;Training;Task analysis;Software libraries;Artificial neural networks","computer games;learning (artificial intelligence);minimax techniques;neural nets;pattern recognition;software libraries","software library;game artificial intelligence;artificial neural networks;software libraries;nonstandard tasks;Tic-tac-toe computer game;random behavior algorithm","","","","24","","21 Jan 2021","","","IEEE","IEEE Conferences"
"A Goal-Prioritized Algorithm for Additional Route Deployment on Existing Mass Transportation System","F. Lin; H. -P. Hsieh","Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","2020 IEEE International Conference on Data Mining (ICDM)","9 Feb 2021","2020","","","1130","1135","Multi-criteria path planning is an important combinatorial optimization problem with broad real-world applications. Finding the Pareto-optimal set of paths ideal for all requiring features is time-consuming and unclear to obtain the subset of optimal paths efficiently for multiple origin states in the planning space. Meanwhile, due to the rise of deep learning, hybrid systems of computational intelligence thrive in recent years. When facing non-monotonic data or heuristics derived from pre-trained neural networks, most of the existing methods for the one-to-all path problem fail to find an ideal solution. We employ Gaussian mixture model to propose a target-prioritized searching algorithm called Multi-Source Bidirectional Gaussian-Prioritized Spanning Tree (BiasSpan) in solving this non-monotonic multi-criteria route planning problem given constraints including range, must-visit vertices, and the number of recommended vertices. Experimental results on mass transportation system in Tainan and Chicago cities show that BiasSpan outperforms comparative methods from 7% to 24<sup>%</sup> and runs in a reasonable time compared to state-of-art route-planning algorithms.","2374-8486","978-1-7281-8316-9","10.1109/ICDM50108.2020.00137","MOST(grant numbers:108-2221-E-006-142,108-2636-E-006-013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338323","Constrained route planning, Bidirectional spanning tree;Gaussian mixture model (GMM);Non-monotonicity;Deep Neural Network (DNN)","Heuristic algorithms;Neural networks;Urban areas;Transportation;Search problems;Path planning;Planning","deep learning (artificial intelligence);Gaussian processes;Pareto optimisation;search problems;trees (mathematics);vehicle routing","mass transportation system;additional route deployment;combinatorial optimization problem;optimal paths;multiple origin states;planning space;deep learning;hybrid systems;computational intelligence;nonmonotonic data;pre-trained neural networks;Gaussian mixture model;target-prioritized searching algorithm;nonmonotonic multicriteria route planning problem;one-to-all path problem;multicriteria path planning;goal-prioritized algorithm;Pareto-optimal set;multisource bidirectional Gaussian-prioritized spanning tree;BiasSpan;Tainan;Chicago cities;range must-visit vertices","","","","39","","9 Feb 2021","","","IEEE","IEEE Conferences"
"NetCut: Real-Time DNN Inference Using Layer Removal","M. Zandigohar; D. Erdoğmuş; G. Schirner","Northeastern University,Department of Electrical and Computer Engineering,USA; Northeastern University,Department of Electrical and Computer Engineering,USA; Northeastern University,Department of Electrical and Computer Engineering,USA","2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)","16 Jul 2021","2021","","","1845","1850","Deep Learning plays a significant role in assisting humans in many aspects of their lives. As these networks tend to get deeper over time, they extract more features to increase accuracy at the cost of additional inference latency. This accuracy-performance trade-off makes it more challenging for Embedded Systems, as resource-constrained processors with strict deadlines, to deploy them efficiently. This can lead to selection of networks that can prematurely meet a specified deadline with excess slack time that could have potentially contributed to increased accuracy. In this work, we propose: (i) the concept of layer removal as a means of constructing TRimmed Networks (TRNs) that are based on removing problem-specific features of a pretrained network used in transfer learning, and (ii) NetCut, a methodology based on an empirical or an analytical latency estimator, which only proposes and retrains TRNs that can meet the application's deadline, hence reducing the exploration time significantly. We demonstrate that TRNs can expand the Pareto frontier that trades off latency and accuracy to provide networks that can meet arbitrary deadlines with potential accuracy improvement over off-the-shelf networks. Our experimental results show that such utilization of TRNs, while transferring to a simpler dataset, in combination with NetCut, can lead to the proposal of networks that can achieve relative accuracy improvement of up to 10.43% among existing off-the-shelf neural architectures while meeting a specific deadline, and 27x speedup in exploration time.","1558-1101","978-3-9819263-5-4","10.23919/DATE51398.2021.9474052","NSF(grant numbers:CPS-1544895,CPS-1544636,CPS-1544815); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9474052","","Deep learning;Embedded systems;Program processors;Transfer learning;Estimation;Grasping;Computer architecture","deep learning (artificial intelligence);embedded systems;inference mechanisms","NetCut;real-time DNN inference;layer removal;accuracy-performance trade-off;Embedded Systems;resource-constrained processors;excess slack time;TRimmed Networks;TRNs;removing problem-specific features;pretrained network;transfer learning;analytical latency estimator;exploration time;arbitrary deadlines;potential accuracy improvement;off-the-shelf networks;relative accuracy improvement","","1","","21","","16 Jul 2021","","","IEEE","IEEE Conferences"
"On Resource-Efficient Bayesian Network Classifiers and Deep Neural Networks","W. Roth; F. Pernkopf; G. Schindler; H. Fröning","Signal Processing and Speech Communication Laboratory, Graz University of Technology,Graz,Austria; Signal Processing and Speech Communication Laboratory, Graz University of Technology,Graz,Austria; Institute of Computer Engineering, Ruprecht Karls University,Heidelberg,Germany; Institute of Computer Engineering, Ruprecht Karls University,Heidelberg,Germany","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","10297","10304","We present two methods to reduce the complexity of Bayesian network (BN) classifiers. First, we introduce quantization-aware training using the straight-through gradient estimator to quantize the parameters of BNs to few bits. Second, we extend a recently proposed differentiable tree-augmented naive Bayes (TAN) structure learning approach by also considering the model size. Both methods are motivated by recent developments in the deep learning community, and they provide effective means to trade off between model size and prediction accuracy, which is demonstrated in extensive experiments. Furthermore, we contrast quantized BN classifiers with quantized deep neural networks (DNNs) for small-scale scenarios which have hardly been investigated in the literature. We show Pareto optimal models with respect to model size, number of operations, and test error and find that both model classes are viable options.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9413156","FWF(grant numbers:I2706-N31); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413156","","Training;Deep learning;Quantization (signal);Neural networks;Memory management;Predictive models;Pareto optimization","Bayes methods;belief networks;deep learning (artificial intelligence);estimation theory;gradient methods;pattern classification;trees (mathematics)","deep learning;Pareto optimal models;Bayesian network classifiers;quantization-aware training;gradient estimator;tree-augmented naive Bayes structure learning","","","","25","","5 May 2021","","","IEEE","IEEE Conferences"
"Image Transfer Applied in Electric Machine Optimization","S. Yang; Y. Meng; X. Meng","Hitachi (China) R&D Cooperation, Shanghai, China; Hitachi (China) R&D Cooperation, Shanghai, China; Hitachi (China) R&D Cooperation, Shanghai, China","2020 IEEE 61th International Scientific Conference on Power and Electrical Engineering of Riga Technical University (RTUCON)","13 Jan 2021","2020","","","1","6","Researches have been conducted on the surrogate-modeling for better trade-off between solution accuracy and solving effort in design space exploration. In this paper, a robust method combining the deep-learning technique, image-transfer, with finite-element-modeling (FEM) in the electric machine optimization to accelerate the convergence is proposed. Specifically, a conditional generative-adversarial network is built to learn from the FEM simulated data about the relationship between the geometric drawing input and magnetic field plot output. The learned model can obtain the result 24x faster than finite-element modeling while maintaining the accuracy. This approximation model is then applied as the sample filter prior to the FEM in the genetic-algorithm powered optimization framework. The test done on a V-shape magnet motor optimization shows that closely matched Pareto-frontier can be found by this approach while the computing time is reduced by >50% at beginning stage for acceleration.","","978-1-7281-9510-0","10.1109/RTUCON51174.2020.9316579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316579","Statistical learning;Design optimization;Permanent magnet machines","Optimization;Task analysis;Training;Magnetic resonance imaging;Finite element analysis;Magnetic flux;Geometry","electric machine analysis computing;electric machines;finite element analysis;genetic algorithms;learning (artificial intelligence);Pareto optimisation","image transfer;electric machine optimization;design space exploration;robust method;deep-learning technique;image-transfer;finite-element-modeling;FEM;generative-adversarial network;geometric drawing input;magnetic field plot output;approximation model;genetic-algorithm powered optimization framework;V-shape magnet motor optimization;surrogate-modeling;Pareto-frontier","","","","32","","13 Jan 2021","","","IEEE","IEEE Conferences"
"Reliable lymph node metastasis prediction in head & neck cancer through automated multi-objective model","Z. Zhou; M. Dohopolski; L. Chen; X. Chen; S. Jiang; D. Sher; J. Wang","University of Texas, Southwestern Medical Center, Dallas, TX, 75390, USA; University of Texas, Southwestern Medical Center, Dallas, TX, 75390, USA; University of Texas, Southwestern Medical Center, Dallas, TX, 75390, USA; School of Electronic and Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi, China; University of Texas, Southwestern Medical Center, Dallas, TX, 75390, USA; University of Texas, Southwestern Medical Center, Dallas, TX, 75390, USA; University of Texas, Southwestern Medical Center, Dallas, TX, 75390, USA","2019 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","12 Sep 2019","2019","","","1","4","Lymph node metastasis (LNM) plays an important role for accurately diagnosing and treating the patients with head & neck cancer. Positron emission tomography (PET) and computed tomography (CT) are two primary imaging modalities used for identifying LNM status. However, the uncertainty of LNM may exist especially for reactive or small nodes. Furthermore, identifying the LNM on PET or CT is greatly dependent on the physician's experience. Therefore, developing a reliable and automatic model is essential for accurately identifying LNM. Multi-objective models have shown promising predictive results by considering different objectives such as sensitivity and specificity. However, most multi-objective models need to choose an optimal model manually. In this work, we proposed an automated multi-objective learning model (AutoMO) for predicting LNM reliably. Instead of picking one optimal model, all the Pareto-optimal models with the calculated relative weights are used in AutoMO. Then the evidential reasoning (ER) approach is used for fusing the output probability for obtaining more reliable results than traditional fusion method. We built three models for PET, CT and PET&CT and the results showed that PET&CT outperformed two single modality based models. The comparative study demonstrated that AutoMO obtained better performance than current available multi-objective and deep learning methods, and more reliable results can be acquired when using ER fusion.","2641-3604","978-1-7281-0848-3","10.1109/BHI.2019.8834658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834658","Lymph node metastasis;Head & neck cancer;Automated multi-objective learning (AutoMO);Multi-objective optimization;Evidential reasoning","Reliability;Cancer;Predictive models;Computed tomography;Training;Positron emission tomography;Sensitivity and specificity","cancer;computerised tomography;image fusion;image reconstruction;learning (artificial intelligence);medical image processing;Pareto optimisation;positron emission tomography;tumours","lymph node metastasis;head cancer;neck cancer;single-modality-based models;lymph node metastasis;positron emission tomography;evidential reasoning approach;ER fusion;automated multiobjective model;Pareto-optimal models;AutoMO;multiobjective learning model;LNM status;computed tomography","","2","","14","","12 Sep 2019","","","IEEE","IEEE Conferences"
"A novel algorithm to keep the formation for multiple vehicles based on NSGA and DCNN","Z. Huai; H. Wang; M. Gong","China Academy of Launch Vehicle Technology,Beijing,People’s Republic of China; China Academy of Launch Vehicle Technology,Beijing,People’s Republic of China; China Academy of Launch Vehicle Technology,Beijing,People’s Republic of China","2020 3rd International Conference on Unmanned Systems (ICUS)","7 Dec 2020","2020","","","99","106","To address the problem of keeping the formation for multiple vehicles, this paper proposes a novel algorithm based on non-dominated sorting genetic algorithm II (NSGA- II) and deep convolutional neural network(DCNN). Firstly, the problem of keeping the formation for multiple vehicles is translated into three objective functions. Secondly, NSGA- II is used to optimize and a strategy is designed to choose the guidance command from Pareto solution set. Thirdly, in order to improve the calculation speed, a 19-layer deep learning model is built based on DCNN, residual network and batch normalization layer, then a correction part is designed to avoid the phenomenon that the accumulation of generalization error will brings obvious error on keeping the formation. Finally, three sets of simulation demonstrate the effectiveness of this algorithm.","","978-1-7281-8025-0","10.1109/ICUS50048.2020.9275022","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275022","keeping the formation;multiple vehicles;nondominated sorting genetic;deep convolutional neural network","Sorting;Linear programming;Deep learning;Convolutional neural networks;Zirconium;Vehicle dynamics;Optimization","autonomous aerial vehicles;convolutional neural nets;genetic algorithms;learning (artificial intelligence);multi-robot systems;Pareto optimisation","multiple vehicles;nondominated sorting genetic algorithm II;NSGA- II;19-layer deep learning model;residual network;batch normalization layer;DCNN;generalization error;deep convolutional neural network(","","","","25","","7 Dec 2020","","","IEEE","IEEE Conferences"
"Towards Intelligent Architecting of Aerospace System-of-Systems: Part II","C. Guariniello; L. Mockus; A. K. Raz; D. A. DeLaurentis","Purdue University, School of Aeronautics and Astronautics,West Lafayette,IN; Purdue University, School of Aeronautics and Astronautics,West Lafayette,IN; Purdue University, School of Aeronautics and Astronautics,West Lafayette,IN; Purdue University, School of Aeronautics and Astronautics,West Lafayette,IN","2020 IEEE Aerospace Conference","21 Aug 2020","2020","","","1","9","System-of-Systems (SoS) are composed of large scale independent and complex heterogeneous systems which collaborate to create capabilities not achievable by a single system, for example air transportation system, satellite constellations, and space exploration architectures. To support architecting of aerospace SoS, in this work we present a methodology to accurately predict different aspects of performance for design/operation and SoS architecting, expanding previous work on intelligent architecting of aerospace SoS, by adding rigorous Uncertainty Quantification via Bayesian Neural Networks. A Bayesian Neural Network is a neural network with a-priori distribution on its weights. In addition to solving the overfit problem, which is common to traditional deep neural networks, Bayesian Neural Networks provide automated model pruning (or reduction of feature design space), that addresses a well-known dimensionality curse in the SoS domain. We enable SoS design/operation by using modeling and simulation, quantifying the uncertainty inherently present in SoS, and utilizing Artificial Intelligence and optimization techniques to design and operate the system so that its expected performance or behavior when the unexpected occurs (for example, a failure) still satisfies user requirements. Much of the research effort in the field of SoS has focused on the analysis of these complex entities, while there are still gaps in developing tools for automated synthesis and engineering of SoS that consider all the various aspects in this problem domain. In this expansion of the use of Artificial Intelligence towards automated design, these techniques are used not only to discover and employ features of interest in a complex design space, but also to assess how uncertainty can affect performance. This capability supports the automated design of robust architectures, that can effectively meet the user needs even in presence of uncertainty. The SoS design and evaluation methodology presented in this paper and demonstrated on a synthetic modular satellites problem starts from modeling and simulation, and design of experiments to explore the design space. The following step is deep learning, to develop a model which relates SoS architectural features with performance metrics. Uncertainty Quantification techniques are then applied to assess the performance metrics for different architectures. Once the most critical features that affect the SoS performance are identified, stochastic optimization of the SoS on a reduced design space can be performed to determine Pareto optimal features. The final step is determining if any additional design/operation measures need to be explored to further maximize the SoS performance.","1095-323X","978-1-7281-2734-7","10.1109/AERO47225.2020.9172585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172585","","Measurement;Deep learning;Uncertainty;Satellites;Neural networks;Stochastic processes;Space exploration","artificial intelligence;learning (artificial intelligence);neural nets;optimisation;Pareto optimisation;software architecture","Uncertainty Quantification techniques;performance metrics;SoS performance;reduced design space;towards intelligent architecting;aerospace system-of-Systems;complex heterogeneous systems;example air transportation system;space exploration architectures;aerospace SoS;SoS architecting;rigorous Uncertainty Quantification;Bayesian Neural Network;traditional deep neural networks;feature design space;SoS domain;Artificial Intelligence;automated design;complex design space;SoS architectural features;design of experiments","","","","19","","21 Aug 2020","","","IEEE","IEEE Conferences"
"BioNetExplorer: Architecture-Space Exploration of Biosignal Processing Deep Neural Networks for Wearables","B. S. Prabakaran; A. Akhtar; S. Rehman; O. Hasan; M. Shafique","Institute of Computer Engineering, Technische Universität Wien, Vienna, Austria; School of Electrical Engineering and Computer, National University of Science and Technology, Islamabad, Pakistan; Institute of Computer Technology, Technische Universität Wien, Vienna, Austria; School of Electrical Engineering and Computer, National University of Science and Technology, Islamabad, Pakistan; Division of Engineering, New York University Abu Dhabi, Abu Dhabi, UAE","IEEE Internet of Things Journal","23 Aug 2021","2021","8","17","13251","13265","Deep learning (DL) has been shown to be highly effective in solving various problems across numerous applications and domains, such as autonomous driving and image recognition. Due to the advent of DL, plenty of research works have explored the applicability of DL, more specifically deep neural networks (DNNs), to solve pattern recognition and computer vision challenges. More recently, researchers have focused on the topic of automated generation and exploration of DNN architectures, which tend to mostly focus on image recognition or visual data sets, primarily, due to the computer vision-related DL advancements. In this work, we propose the BioNetExplorer framework to systematically generate and explore multiple DNN architectures for biosignal processing in wearable devices. Our framework varies key neural architecture parameters to search for an embedded DNN architecture with a low hardware overhead, which can be deployed in wearable edge devices to analyze the biosignal data and to extract the relevant information, such as arrhythmia and seizure. Furthermore, BioNetExplorer reduces the exploration time by deploying genetic algorithms, such as NSGA-II, SPEA-2, etc. Our framework also enables the hardware-aware DNN architecture search by imposing user requirements and hardware constraints (storage, FLOPs, etc.) during the exploration stage, thereby limiting the number of networks explored. Moreover, BioNetExplorer can also be used to search for DNNs based on the user-required output classes; for instance, a user might require a specific output class, attributed toward ventricular fibrillation, due to genetic predisposition or a preexisting heart condition. The use of genetic algorithms reduces the exploration time, on average, by 9×, compared to exhaustive exploration. We are successful in identifying Pareto-optimal designs, which can reduce the storage overhead of DNN by ~ 30 MB for a quality loss of less than 0.5%. To enable low-cost embedded DNNs, BioNetExplorer also employs different model compression techniques to further reduce the storage overhead of the network by up to 53× for a quality loss of $ <; 0.2\%$ .","2327-4662","","10.1109/JIOT.2021.3065815","Doctoral College Resilient Embedded Systems, which is run jointly by the TU Wien’s Faculty of Informatics and the UAS Technikum Wien; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377449","Bio-signals;convolution;deep neural networks (DNNs);efficiency;embedded systems;exploration;healthcare;long short-term memory (LSTM);performance;wearables","Hardware;Wearable computers;Computer architecture;Quantization (signal);Electrocardiography;Biological system modeling;Monitoring","computer vision;data compression;deep learning (artificial intelligence);genetic algorithms;image recognition;medical signal processing;neural net architecture;Pareto optimisation","architecture-space exploration;biosignal processing deep neural networks;deep learning;autonomous driving;image recognition;pattern recognition;automated generation;visual data sets;computer vision-related DL advancements;BioNetExplorer framework;multiple DNN architectures;neural architecture parameters;embedded DNN architecture;wearable edge devices;genetic algorithms;hardware-aware DNN architecture search;user-required output classes;genetic predisposition;low-cost embedded DNNs;Pareto-optimal designs;biosignal data analysis;model compression techniques","","2","","70","IEEE","12 Mar 2021","","","IEEE","IEEE Journals"
"A Bi-objective Hyper-Heuristic Support Vector Machines for Big Data Cyber-Security","N. R. Sabar; X. Yi; A. Song","Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia; School of Computer Science and Information Technology, RMIT University, Melbourne, VIC, Australia; School of Computer Science and Information Technology, RMIT University, Melbourne, VIC, Australia","IEEE Access","13 Mar 2018","2018","6","","10421","10431","Cyber security in the context of big data is known to be a critical problem and presents a great challenge to the research community. Machine learning algorithms have been suggested as candidates for handling big data security problems. Among these algorithms, support vector machines (SVMs) have achieved remarkable success on various classification problems. However, to establish an effective SVM, the user needs to define the proper SVM configuration in advance, which is a challenging task that requires expert knowledge and a large amount of manual effort for trial and error. In this paper, we formulate the SVM configuration process as a bi-objective optimization problem in which accuracy and model complexity are considered as two conflicting objectives. We propose a novel hyper-heuristic framework for bi-objective optimization that is independent of the problem domain. This is the first time that a hyper-heuristic has been developed for this problem. The proposed hyper-heuristic framework consists of a high-level strategy and low-level heuristics. The high-level strategy uses the search performance to control the selection of which low-level heuristic should be used to generate a new SVM configuration. The low-level heuristics each use different rules to effectively explore the SVM configuration search space. To address bi-objective optimization, the proposed framework adaptively integrates the strengths of decompositionand Paretobased approaches to approximate the Pareto set of SVM configurations. The effectiveness of the proposed framework has been evaluated on two cyber security problems: Microsoft malware big data classification and anomaly intrusion detection. The obtained results demonstrate that the proposed framework is very effective, if not superior, compared with its counterparts and other algorithms.","2169-3536","","10.1109/ACCESS.2018.2801792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307061","Hyper-heuristics;big data;cyber security;optimisation","Malware;Big Data;Support vector machines;Kernel;Computer security;Optimization","Big Data;evolutionary computation;learning (artificial intelligence);optimisation;pattern classification;search problems;security of data;support vector machines","bi-objective optimization problem;novel hyper-heuristic framework;high-level strategy;low-level heuristic;SVM configuration search space;cyber security problems;machine learning algorithms;SVM configuration process;Big Data classification;bi-objective hyper-heuristic support vector machines;Big Data cyber-security","","21","","57","OAPA","6 Mar 2018","","","IEEE","IEEE Journals"
"Non-symmetric Preferences in the IPA Market with Reinforcement Learning","E. R. Gomes; R. Kowalczyk","Fac. of Inf. & Commun. Technol., Swinburne Univ. of Technol., Hawthorn, VIC; Fac. of Inf. & Commun. Technol., Swinburne Univ. of Technol., Hawthorn, VIC","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","6 Jan 2009","2008","2","","424","430","Machine Learning has been proposed to support and optimize market-based resource allocation. In particular, reinforcement learning (RL) has been used to improve the allocation in terms of the utility received by resource requesting agents in the iterative price adjustment (IPA) mechanism. In such an approach, utility functions describe the agents' preferences for resource attributes and are the basis for RL to learn demand functions that are optimized for the market. It has been shown that the reward functions based on the individual utility of the agents and the social welfare of the allocation can deliver similar social results when the market consists only of learning agents with symmetric preferences. In this paper we investigate the IPA market-based resource allocation with RL for the case of agents with non-symmetric preferences. We show through experimental investigation that the results observed above are also held in this case. In particular, we show that the individual-based reward function is able to approximate the solution to the fairest Pareto-optimal allocation in situations where the social-based reward function fails.","","978-0-7695-3496-1","10.1109/WIIAT.2008.77","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740660","Market-based Resource Allocation;Iterative Price Adjustment;Reinforcement Learning;Individual;Social Rewards","Resource management;Intelligent agent;Pricing;Learning systems;Communications technology;Australia;Machine learning;Large-scale systems;Service oriented architecture;Distributed computing","learning (artificial intelligence);Pareto optimisation;pricing;resource allocation","nonsymmetric preferences;IPA market-based resource allocation;reinforcement learning;machine learning;iterative price adjustment mechanism;learning agents;individual-based reward function;Pareto-optimal allocation;social-based reward function","","","","17","","6 Jan 2009","","","IEEE","IEEE Conferences"
"Multi-Task Learning for Multi-Objective Evolutionary Neural Architecture Search","R. Cai; J. Luo","Shenzhen University,The Guangdong Key Laboratory of Intelligent Information Processing,Shenzhen,China,518060; Shenzhen University,College of Electronics and Information Engineering,The Shenzhen Key Laboratory of Media Security,Shenzhen,China,518060","2021 IEEE Congress on Evolutionary Computation (CEC)","9 Aug 2021","2021","","","1680","1687","Neural architecture search (NAS) is an exciting new field in automating machine learning. It can automatically search for the architecture of neural networks. But the current NAS has extremely high requirements for hardware equipment and time costs. In this work, we propose a predictor based on Radial basis function neural network (RBFNN) as a surrogate model of Bayesian optimization to predict the performance of neural architecture. The existing work does not consider the difficulty of directly searching for neural architectures that meet the performance requirements of NAS in real-world applications. Meanwhile, NAS needs to execute multiple times independently when facing multiple similar tasks. Therefore, we further propose a multi-task learning surrogate model with multiple RBFNNs. The model not only functions as a predictor, but also learns knowledge of similar tasks jointly. The performance of NAS is improved by processing multiple tasks simultaneously. Also, the current NAS is committed to searching for very high-performance networks and does not take into account that neural architectures are limited by device memory during actual deployment. The scale of architecture also needs to be considered. We use a multi-objective optimization algorithm to simultaneously balance the performance and the scale, and build a multi-objective evolutionary search framework to find the Pareto optimal front. Once the NAS is completed, decision-makers can choose the appropriate architecture for deployment according to different performance requirements and hardware conditions. Compared with existing NAS work, our proposed MT-ENAS algorithm is able to find a neural architecture with competitive performance and smaller scale in a shorter time.","","978-1-7281-8393-0","10.1109/CEC45853.2021.9504721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504721","neural architecture search;multi-task learning;surrogate model;multi-objective optimization","Performance evaluation;Computational modeling;Training data;Computer architecture;Predictive models;Search problems;Prediction algorithms","evolutionary computation;learning (artificial intelligence);neural net architecture;Pareto optimisation;radial basis function networks;search problems","high-performance networks;multiobjective optimization algorithm;performance requirements;multiobjective evolutionary neural architecture search;automating machine learning;neural networks;radial basis function neural network;multiple similar tasks;multitask learning surrogate model;NAS;Pareto optimal front","","","","40","","9 Aug 2021","","","IEEE","IEEE Conferences"
"Boosting the Efficiency of the Harmonics Elimination VLSI Architecture by Arithmetic Approximations","P. da Costa; P. T. L. Pereira; G. Paim; E. da Costa; S. Bampi","Graduate Program in Microelectronics (PGMICRO) - Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Graduate Program in Microelectronics (PGMICRO) - Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Graduate Program in Microelectronics (PGMICRO) - Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Graduate Program in Electronic Engineering and Computing - Catholic University of Pelotas (UCPel),Pelotas,Brazil; Graduate Program in Microelectronics (PGMICRO) - Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil","2021 28th IEEE International Conference on Electronics, Circuits, and Systems (ICECS)","10 Jan 2022","2021","","","1","4","Approximate computing emerged as a key alternative for trading off accuracy against energy efficiency and area reduction. Error-tolerant applications, such as multimedia processing, machine learning, and signal processing, can process the information with lower-than-standard accuracy at the circuit level while still fulfilling a good and acceptable service quality at the application level. Adaptive filtering-based systems have been demonstrating high resiliency against hardware errors due to their intrinsic self-healing characteristic. This paper investigates the design space exploration of arithmetic approximations in a Very Large-Scale Integration (VLSI) harmonic elimination (HE) hardware architecture based on Least Mean Square (LMS) adaptive filters. We evaluate the Pareto front of the area- and power versus quality curves by relaxing the arithmetic precision and by adopting both approximate multipliers (AxMs) in combination with approximate adders (AxAs). This paper explores the benefits and impacts of the Dynamic Range Unbiased (DRUM), Rounding-based Approximate (RoBA), and Leading one Bit-based Approximate (LoBA) multipliers in the power dissipation, circuit area, and quality of the VLSI HE architectures. Our results highlight the LoBA 0 as the most efficient AxM applied in the HE architecture. We combine the LoBA 0 with Copy and LOA AxAs with variations in the approximation level (L). Notably, LoBA 0 and LOA with <tex>$L=6$</tex> resulted in savings of 43.7% in circuit area and 45.2% in power dissipation, compared to the exact HE, which uses multiplier and adder automatically selected by the logic synthesis tool. Finally, we demonstrate that the best hardware architecture found in our investigation successfully eliminates the contaminating spurious noise (i.e., 60 Hz and its harmonics) from the signal.","","978-1-7281-8281-0","10.1109/ICECS53924.2021.9665538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665538","Approximate Computing;Approximate multipliers;VLSI Design;LMS;Harmonics Suppression","Power quality;Computer architecture;Very large scale integration;Harmonic analysis;Boosting;Hardware;Power dissipation","","","","","","12","","10 Jan 2022","","","IEEE","IEEE Conferences"
"NASCaps: A Framework for Neural Architecture Search to Optimize the Accuracy and Hardware Efficiency of Convolutional Capsule Networks","A. Marchisio; A. Massa; V. Mrazek; B. Bussolino; M. Martina; M. Shafique","Institute of Computer Engineering, Technische Universität Wien,Vienna,Austria; Politecnico di Torino,Department of Electronics and Telecommunications,Turin,Italy; Brno University of Technology,Faculty of Information Technology,Brno,Czech Republic; Politecnico di Torino,Department of Electronics and Telecommunications,Turin,Italy; Politecnico di Torino,Department of Electronics and Telecommunications,Turin,Italy; New York University,Division of Engineering,Abu Dhabi,UAE","2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD)","25 Nov 2020","2020","","","1","9","Deep Neural Networks (DNNs) have made significant improvements to reach the desired accuracy to be employed in a wide variety of Machine Learning (ML) applications. Recently the Google Brain's team demonstrated the ability of Capsule Networks (CapsNets) to encode and learn spatial correlations between different input features, thereby obtaining superior learning capabilities compared to traditional (i.e., non-capsule based) DNNs. However, designing CapsNets using conventional methods is a tedious job and incurs significant training effort. Recent studies have shown that powerful methods to automatically select the best/optimal DNN model configuration for a given set of applications and a training dataset are based on the Neural Architecture Search (NAS) algorithms. Moreover, due to their extreme computational and memory requirements, DNNs are employed using the specialized hardware accelerators in IoT-Edge/CPS devices. In this paper, we propose NASCaps, an automated framework for the hardware-aware NAS of different types of DNNs, covering both traditional convolutional DNNs and CapsNets. We study the efficacy of deploying a multi-objective Genetic Algorithm (e.g., based on the NSGA-II algorithm). The proposed framework can jointly optimize the network accuracy and the corresponding hardware efficiency, expressed in terms of energy, memory, and latency of a given hardware accelerator executing the DNN inference. Besides supporting the traditional DNN layers (such as, convolutional and fully-connected), our framework is the first to model and supports the specialized capsule layers and dynamic routing in the NAS-flow. We evaluate our framework on different datasets, generating different network configurations, and demonstrate the tradeoffs between the different output metrics. We will open-source the complete framework and configurations of the Pareto-optimal architectures at https://github.com/ehw-fit/nascaps.","1558-2434","978-1-6654-2324-3","","Czech Science Foundation(grant numbers:GJ20-02328Y); Ministry of Education, Youth and Sports(grant numbers:LM2018140); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256635","Deep Neural Networks;DNNs;Capsule Networks;Evolutionary Algorithms;Genetic Algorithms;Neural Architecture Search;Hardware Accelerators;Accuracy;Energy Efficiency;Memory;Latency;Design Space;Multi-Objective;Optimization","Hardware;Training;Memory management;Routing;Image reconstruction;Optimization;Neurons","convolutional neural nets;encoding;genetic algorithms;learning (artificial intelligence);neural net architecture;Pareto optimisation","convolutional capsule networks;deep neural networks;Google Brain;learning capabilities;CapsNets;neural architecture search algorithms;computational memory;specialized hardware accelerators;hardware-aware NAS;convolutional DNNs;multiobjective genetic algorithm;NSGA-II algorithm;hardware accelerator;DNN inference;specialized capsule layers;NAS-flow;Pareto-optimal architectures;NASCaps","","","","38","","25 Nov 2020","","","IEEE","IEEE Conferences"
"Hybrid knowledge-based evolutionary many-objective optimization","B. Zhang; K. Shafi; H. A. Abbass","School of Engineering and Information Technology, University of New South Wales, Canberra, Australian Capital Territory, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australian Capital Territory, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australian Capital Territory, Australia","2016 IEEE Congress on Evolutionary Computation (CEC)","21 Nov 2016","2016","","","1007","1014","Knowledge-based optimization is a recent direction in evolutionary optimization research which aims at understanding the optimization process, discovering relationships between decision variables and performance parameters, and using discovered knowledge to improve the optimization process, using machine learning techniques. A novel evolutionary optimization framework that incorporates a knowledge-based representation to search for Pareto optimal patterns in decision space was proposed earlier. This paper extends this framework to problems with four and more objectives, commonly referred to as many-objective optimization problems, using a hybridization approach with NSGA3. Experimental results on standard test functions are presented to demonstrate the advantages of the proposed hybrid algorithm in both objective and decision spaces.","","978-1-5090-0623-6","10.1109/CEC.2016.7743899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743899","","Knowledge based systems;Sociology;Switches;Convergence;Pareto optimization","evolutionary computation;learning (artificial intelligence)","hybrid knowledge-based evolutionary many-objective optimization;machine learning techniques;knowledge-based representation;Pareto optimal patterns;decision space;hybridization approach;NSGA3","","1","","11","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Alleviating Catastrophic Forgetting via Multi-Objective Learning","Yaochu Jin; B. Sendhoff","Senior Member, IEEE, Honda Research Institute Europe, Carl-Legien-Str. 30, 63073 Offenbach, Germany. email: yaochu.jin@honda-ri.de; Honda Res. Inst. Europe, Offenbach","The 2006 IEEE International Joint Conference on Neural Network Proceedings","30 Oct 2006","2006","","","3335","3342","Handling catastrophic forgetting is an interesting and challenging topic in modeling the memory mechanisms of the human brain using machine learning models. From a more general point of view, catastrophic forgetting reflects the stability-plasticity dilemma, which is one of the several dilemmas to be addressed in learning systems: to retain the stored memory while learning new information. Different to the existing approaches, we introduce a Pareto-optimality based multi-objective learning framework for alleviating catastrophic learning. Compared to the single-objective learning methods, multi-objective evolutionary learning with the help of pseudo-rehearsal is shown to be more promising in dealing with the stability-plasticity dilemma.","2161-4407","0-7803-9490-9","10.1109/IJCNN.2006.247332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1716554","","Machine learning;Brain modeling;Stability;Learning systems;Humans;Biological neural networks;Hippocampus;Machine learning algorithms;Interference;Europe","learning (artificial intelligence);Pareto optimisation","catastrophic forgetting;memory mechanisms;machine learning models;stability-plasticity dilemma;Pareto-optimality;multi-objective evolutionary learning;pseudo-rehearsal","","2","","37","","30 Oct 2006","","","IEEE","IEEE Conferences"
"Personalized Neural Architecture Search","C. Kulbach; S. Thoma","FZI Research Center for Information Technology,Karlsruhe,Germany,76131; FZI Research Center for Information Technology,Karlsruhe,Germany,76131","2021 International Conference on Data Mining Workshops (ICDMW)","20 Jan 2022","2021","","","581","590","Existing approaches for Neural Architecture Search (NAS) aim at efficiently maximizing individual or sets of objectives (e.g. high accuracy or a low number of parameters) by exploiting Reinforcement Learning (RL), evolutionary algorithms, or Bayesian optimization. Most multi-objective NAS algorithms assume that all objectives are fully known and require them to be broadly explored to successfully approximate the Pareto front, which results in computational expensive search algorithms. To address this problem, we propose an interactive machine learning approach based on preference elicitation which enables end-users to explore and find a custom loss function and can be directly used for State-of-the-Art single-objective black-box optimization. We integrate our approach into State-of-the-Art single objective NAS algorithms and evaluate it against multi-objective approaches on the NATS-Bench benchmark dataset. Furthermore, we show that diverse end-user preferences can be successfully approximated in terms of loss functions, leading to suitable neural architectures.","2375-9259","978-1-6654-2427-1","10.1109/ICDMW53433.2021.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679916","Neural Architecture Search;Personalization;User Centric AI;Ranking","Measurement;Machine learning algorithms;Computer architecture;Evolutionary computation;Reinforcement learning;Search problems;Approximation algorithms","","","","","","35","","20 Jan 2022","","","IEEE","IEEE Conferences"
"PASAPTO: Policy-aware Security and Performance Trade-off Analysis--Computation on Encrypted Data with Restricted Leakage","A. Fischer; J. Janneck; J. Kussmaul; N. Krätzschmar; F. Kerschbaum; E. Bodden","SAP Security Research; SAP Security Research; SAP Security Research; SAP Security Research; University of Waterloo,School of Computer Science,Canada; Paderborn University, Heinz Nixdorf Institute & Fraunhofer IEM,Department of Computer Science","2020 IEEE 33rd Computer Security Foundations Symposium (CSF)","4 Aug 2020","2020","","","230","245","This work considers the trade-off between security and performance when revealing partial information about encrypted data computed on. The focus of our work is on information revealed through control flow side-channels when executing programs on encrypted data. We use quantitative information flow to measure security, running time to measure performance and program transformation techniques to alter the trade-off between the two. Combined with information flow policies, we perform a policy-aware security and performance trade-off (PASAPTO) analysis. We formalize the problem of PASAPTO analysis as an optimization problem, prove the NP-hardness of the corresponding decision problem and present two algorithms solving it heuristically. We implemented our algorithms and combined them with the Dataflow Authentication (DFAuth) approach for outsourcing sensitive computations. Our DFAuth Trade-off Analyzer (DFATA) takes Java Bytecode operating on plaintext data and an associated information flow policy as input. It outputs semantically equivalent program variants operating on encrypted data which are policy-compliant and approximately Pareto-optimal with respect to leakage and performance. We evaluated DFATA in a commercial cloud environment using Java programs, e.g., a decision tree program performing machine learning on medical data. The decision tree variant with the worst performance is 357% slower than the fastest variant. Leakage varies between 0% and 17% of the input.","2374-8303","978-1-7281-6572-1","10.1109/CSF49147.2020.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155204","","Cryptography;Optimization;Time measurement;Heuristic algorithms;Java;Decision trees","cloud computing;computational complexity;cryptography;data flow computing;decision trees;Java;learning (artificial intelligence);optimisation;outsourcing;program processors","Java programs;machine learning;decision tree variant;commercial cloud environment;Pareto-optimal;Java bytecode;sensitive computation outsourcing;data flow authentication approach;optimization problem;NP-hardness problem;policy-aware security and performance trade-off analysis;restricted leakage;DFAuth trade-off analyzer;medical data;decision tree program;policy-compliant;semantically equivalent program;associated information flow policy;plaintext data;decision problem;PASAPTO analysis;information flow policies;program transformation techniques;quantitative information flow;control flow side-channels;partial information;encrypted data","","","","58","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Throughput-Oriented Spatio-Temporal Optimization in Approximate High-Level Synthesis","M. T. Leipnitz; G. L. Nazar","Informatics Institute - Federal University of Rio Grande do Sul,Porto Alegre,Brazil; Informatics Institute - Federal University of Rio Grande do Sul,Porto Alegre,Brazil","2020 IEEE 38th International Conference on Computer Design (ICCD)","21 Dec 2020","2020","","","316","323","Current and emerging systems for high-throughput applications, such as machine learning, cloud computing, and real-time video encoding demand real-time processing computations, heavily constrained by latency and power requirements. To deal with the increasing computational complexity, designers may resort to approximate accelerators for error-resilient compute-intensive kernels to meet such requirements with acceptable deviation from the exact implementation. However, since time-to-market is crucial when dealing with evolving applications, technologies, and standards, hand-crafting approximate accelerators may impose prohibitive development time and cost overheads. In this scenario, approximate High-Level Synthesis (HLS) methodologies have been proposed to deal with the complexity of exploring approximation techniques. Nevertheless, current tools are not suitable for exploring throughput optimizations, being instead constrained to perform specific improvements on area, power, and performance. In this work, we propose the use of HLS to generate Pareto-optimal accelerators for throughput-constrained applications. Particularly, we present a throughput-oriented approximate HLS methodology that explores both delay and area optimizations to increase the reuse over time and parallelism of such accelerators. Results show that our method is able to improve throughput by up to 80 % with no additional area costs or to sustain the same throughput of the exact design with about 45 % less area while introducing manageable error for most applications. Moreover, our method can attain throughput improvements of up to 18% when compared with recent works focusing only on performance or area optimizations, with no additional costs.","2576-6996","978-1-7281-9710-4","10.1109/ICCD50377.2020.00060","Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES); Fundacao de Amparo a Pesquisa do Estado do Rio Grande do Sul (FAPERGS); Conselho Nacional de Desenvolvimento Cientifico e Tecnológico (CNPq); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283566","High-Level Synthesis;Approximate Computing;Design Space Exploration","Tools;Parallel processing;Throughput;Real-time systems;Space exploration;Delays;Optimization","cloud computing;computational complexity;high level synthesis;learning (artificial intelligence);optimisation;Pareto optimisation;video coding","real-time video;demand real-time processing computations;increasing computational complexity;error-resilient compute-intensive kernels;acceptable deviation;exact implementation;time-to-market;evolving applications;hand-crafting approximate accelerators;prohibitive development time;cost overheads;approximate High-Level Synthesis methodologies;approximation techniques;throughput optimizations;specific improvements;Pareto-optimal accelerators;throughput-constrained applications;throughput-oriented approximate HLS methodology;parallelism;additional area costs;exact design;throughput improvements;area optimizations;throughput-oriented spatio-temporal optimization;high-throughput applications;machine learning;cloud computing","","1","","30","","21 Dec 2020","","","IEEE","IEEE Conferences"
"Automatic Fuzzy Clustering Using Non-Dominated Sorting Particle Swarm Optimization Algorithm for Categorical Data","T. P. Q. Nguyen; R. J. Kuo","Department of Industrial Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Industrial Management, National Taiwan University of Science and Technology, Taipei, Taiwan","IEEE Access","5 Aug 2019","2019","7","","99721","99734","Categorical data clustering has been attracted a lot of attention recently due to its necessary in the real-world applications. Many clustering methods have been proposed for categorical data. However, most of the existing algorithms require the predefined number of clusters which is usually unavailable in real-world problems. Only a few works focused on automatic clustering, but mainly handled for numerical data. This study develops a novel automatic fuzzy clustering using non-dominated sorting particle swarm optimization (AFC-NSPSO) algorithm for categorical data. The proposed AFC-NSPSO algorithm can automatically identify the optimal number of clusters and exploit the clustering result with the corresponding selected number of clusters. In addition, a new technique is investigated to identify the maximum number of clusters in a dataset based on the local density. To select a final solution in the first Pareto front, some internal validation indices are used. The performance of the proposed AFC-NSPSO on the real-world datasets collected from the UCI machine learning repository exhibits effectiveness compared with some other existing automatic categorical clustering algorithms. Besides, this study also applies the proposed algorithm to analyze a real-world case study with an unknown number of clusters.","2169-3536","","10.1109/ACCESS.2019.2927593","Ministry of Science and Technology, Taiwan(grant numbers:MOST 105-2410-H-011-017-MY3,106-2811-H-011-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758118","Automatic clustering;categorical data;local density;NSPSO","Clustering algorithms;Partitioning algorithms;Entropy;Sorting;Particle swarm optimization;Machine learning algorithms;Genetic algorithms","fuzzy set theory;learning (artificial intelligence);Pareto optimisation;particle swarm optimisation;pattern clustering;sorting","UCI machine learning repository;Pareto front;automatic fuzzy clustering using nondominated sorting particle swarm optimization algorithm;automatic categorical clustering algorithms;AFC-NSPSO algorithm;numerical data;categorical data clustering","","6","","48","CCBY","9 Jul 2019","","","IEEE","IEEE Journals"
"A Chance Constrained Programming Based Multi-Criteria Decision Making Under Uncertainty","P. D. Pantula; S. S. Miriyala; K. Mitra","Department of Chemical Engineering, Indian Institute of Technology, Kandi, Sangareddy, 502285, India; Department of Chemical Engineering, Indian Institute of Technology, Kandi, Sangareddy, 502285, India; Department of Chemical Engineering, Indian Institute of Technology, Kandi, Sangareddy, 502285, India","2019 Fifth Indian Control Conference (ICC)","16 May 2019","2019","","","359","364","Multi-criteria decision making under uncertainty is a common practice followed in industries and academia. Among several types of uncertainty handling techniques, Chance Constrained Programming (CCP) is considered as an efficient and tractable approach provided one has accessibility to distribution of the data for uncertain parameters. However, the assumption that the uncertain parameters must follow some well-behaved probability distribution is a myth for most of the practical applications. This paper proposes a methodology to amalgamate machine learning algorithms with CCP and thereby make it data-driven. A novel fuzzy clustering mechanism is implemented to transcript the uncertain space such that the exact regions of uncertainty are identified. Subsequently, density based boundary point detection and Delaunay triangulation based boundary construction enable intelligent Sobol based sampling in these regions for use in CCP. The Fuzzy clustering mechanism used in the proposed method transforms the existing fuzzy C-means technique such that the decision variables are significantly reduced. This enables evolutionary optimizers to obtain better approximations of the uncertain space by identifying the true clusters. A highly nonlinear real life model for continuous casting from steelmaking industries is considered as a case study for testing the efficiency of data based CCP along with a comprehensive comparison between conventional CCP approach using box uncertainty set and proposed methodology. As the resulting CCP problem is multi-objective in nature, the Pareto solutions are obtained by NSGA II.","","978-1-5386-6246-5","10.1109/INDIANCC.2019.8715586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715586","Data Driven Chance Constrained Programming;Fuzzy Clustering;Multi-objective Optimization","Optimization;Uncertainty;Programming;Linear programming;Decision making;Indexes;Probabilistic logic","constraint handling;decision making;evolutionary computation;fuzzy set theory;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern clustering;uncertainty handling","well-behaved probability distribution;density based boundary point detection;Delaunay triangulation based boundary construction;intelligent Sobol based sampling;conventional CCP approach;box uncertainty set;multicriteria decision;chance constrained programming;fuzzy clustering mechanism;fuzzy C-means technique;Pareto solutions;NSGA II","","1","","19","","16 May 2019","","","IEEE","IEEE Conferences"
"A Novel Feature Selection with Many-Objective Optimization and Learning Mechanism","L. Shu; F. He; X. Hu; H. Li","School of Computer Science, Wuhan University,Wuhan,China; School of Computer Science, Wuhan University,Wuhan,China; School of Computer Science, Wuhan University,Wuhan,China; School of Computer Science, Wuhan University,Wuhan,China","2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","28 May 2021","2021","","","684","689","Feature selection is extremely important in machine learning and data mining. Typical two-objective feature selection methods aim to minimize the number of features and maximize classification performance. However, they overlook the fact that there may be multiple subsets with similar information content for a given cardinality. The paper presents a many-objective feature selection approach to address this problem. Firstly, we establish a five-objective optimization model, which consists of classification accuracy, the number of features, feature relevance, feature redundancy, and feature complementarity. Therefore, the proposed model can enlarge the search space with more Pareto solutions. Secondly, we propose a wrapper structure for many-objective feature selection, which integrates a learning algorithm. Thirdly, in order to reduce the computional overhead, we propose a filter structure, which separates the learning algorithm. For implementation, we adopt NSGA-III multi-objective evolutionary algorithm and extreme learning machine. The experiments on mainstream datasets confirm the superiority of the proposed method.","","978-1-7281-6597-4","10.1109/CSCWD49262.2021.9437707","National Natural Science Foundation of China(grant numbers:62072348); National Key R&D Program of China(grant numbers:2017YFB0503004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437707","optimization driven design;intelligent cloud manufacturing;collaborative processing of big data;feature selection;classification;many-objective optimization;extreme learning machine","Learning systems;Extreme learning machines;Conferences;Redundancy;Machine learning;Evolutionary computation;Filtering algorithms","data mining;feature selection;feedforward neural nets;genetic algorithms;learning (artificial intelligence);Pareto optimisation;pattern classification;search problems;sorting","many objective optimization;machine learning;data mining;classification;similar information content;feature relevance;feature redundancy;feature complementarity;NSGA-III multiobjective evolutionary algorithm;extreme learning machine;many objective feature selection;search space;Pareto solutions;wrapper structure;filter structure","","","","12","","28 May 2021","","","IEEE","IEEE Conferences"
"Ready-to-Fabricate RF Circuit Synthesis Using a Layout- and Variability-Aware Optimization-Based Methodology","F. Passos; E. Roca; R. Martins; N. Lourenço; S. Ahyoune; J. Sieiro; R. Castro-López; N. Horta; F. V. Fernández","Instituto de Microelectrónica de Sevilla, CSIC and Universidad de Sevilla, Sevilla, Spain; Instituto de Microelectrónica de Sevilla, CSIC and Universidad de Sevilla, Sevilla, Spain; Instituto de Telecomunicações, Lisbon, Portugal; Instituto de Telecomunicações, Lisbon, Portugal; Radiofrequency Group, University of Barcelona, Barcelona, Spain; Radiofrequency Group, University of Barcelona, Barcelona, Spain; Instituto de Microelectrónica de Sevilla, CSIC and Universidad de Sevilla, Sevilla, Spain; Instituto de Telecomunicações, Lisbon, Portugal; Instituto de Microelectrónica de Sevilla, CSIC and Universidad de Sevilla, Sevilla, Spain","IEEE Access","19 Mar 2020","2020","8","","51601","51609","In this paper, physical implementations and measurement results are presented for several Voltage Controlled Oscillators that were designed using a fully-automated, layout- and variability-aware optimization-based methodology. The methodology uses a highly accurate model, based on machine-learning techniques, to characterize inductors, and a multi-objective optimization algorithm to achieve a Pareto-optimal front containing optimal circuit designs offering different performance trade-offs. The final outcome of the proposed methodology is a set of design solutions (with their GDSII description available and ready-to-fabricate) that need no further designer intervention. Two key elements of the proposed methodology are the use of an optimization algorithm linked to an off-the-shelf simulator and an inductor model that yield EM-like accuracy but with much shorter evaluation times. Furthermore, the methodology guarantees the same high level of robustness against layout parasitics and variability that an expert designer would achieve with the verification tools at his/her disposal. The methodology is technology-independent and can be used for the design of radio frequency circuits. The results are validated with experimental measurements on a physical prototype.","2169-3536","","10.1109/ACCESS.2020.2980211","AEI/FEDER, UE, and by FCT/MCTES through national funds and when applicable co-funded EU funds(grant numbers:TEC2016-75151-C3-3-R,TEC2017-83524-R,UIDB/EEA/50008/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9032117","Integrated circuit synthesis;electronic design automation and methodology;inductors;metamodeling;radio frequency;voltage-controlled oscillator","Inductors;Integrated circuit modeling;Optimization;Layout;Radio frequency;Optical fibers","circuit CAD;integrated circuit design;integrated circuit layout;network synthesis;Pareto optimisation;voltage-controlled oscillators","ready-to-fabricate RF circuit synthesis;variability-aware optimization-based methodology;multiobjective optimization algorithm;Pareto-optimal front;optimal circuit designs;layout-aware optimization-based methodology;voltage controlled oscillators","","3","","19","CCBY","11 Mar 2020","","","IEEE","IEEE Journals"
"Rapid Generation of High-Quality RISC-V Processors from Functional Instruction Set Specifications","G. Liu; J. Primmer; Z. Zhang","School of Electrical and Computer Engineering, Cornell University, Ithaca, NY; School of Electrical and Computer Engineering, Cornell University, Ithaca, NY; School of Electrical and Computer Engineering, Cornell University, Ithaca, NY","2019 56th ACM/IEEE Design Automation Conference (DAC)","22 Aug 2019","2019","","","1","6","The increasing popularity of compute acceleration for emerging domains such as artificial intelligence and computer vision has led to the growing need for domain-specific accelerators, often implemented as specialized processors that execute a set of domain-optimized instructions. The ability to rapidly explore (1) various possibilities of the customized instruction set, and (2) its corresponding micro-architectural features is critical to achieve the best quality-of-results (QoRs). However, this ability is frequently hindered by the manual design process at the register transfer level (RTL). Such an RTL-based methodology is often expensive and slow to react when the design specifications change at the instruction-set level and/or micro-architectural level.We address this deficiency in domain-specific processor design with ASSIST, a behavior-level synthesis framework for RISC-V processors. From an untimed functional instruction set description, ASSIST generates a spectrum of RISC-V processors implementing varying micro-architectural design choices, which enables effective tradeoffs between different QoR metrics. We demonstrate the automatic synthesis of more than 60 in-order processor implementations with varying pipeline structures from the RISC-V 32I instruction set, some of which dominate the manually optimized counterparts in the area-performance Pareto frontier. In addition, we propose an autotuning-based approach for optimizing the implementations under a given performance constraint and the technology target. We further present case studies of synthesizing various custom instruction extensions and customized instruction sets for cryptography and machine learning applications.","0738-100X","978-1-4503-6725-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806953","","Instruction sets;Registers;Pipelines;Tools;Pipeline processing;Schedules","circuit optimisation;high level synthesis;integrated circuit design;microprocessor chips;Pareto optimisation;reduced instruction set computing","functional instruction set specifications;compute acceleration;domain-specific accelerators;specialized processors;domain-optimized instructions;customized instruction set;microarchitectural features;quality-of-results;manual design process;register transfer level;RTL-based methodology;instruction-set level;microarchitectural level;domain-specific processor design;ASSIST;behavior-level synthesis framework;untimed functional instruction set description;microarchitectural design choices;custom instruction extensions;machine learning applications;cryptography;performance constraint;autotuning-based approach;area-performance Pareto frontier;RISC-V 32I instruction set;pipeline structures;QoR metrics;high-quality RISC-V processor generation;in-order processor;design specifications","","","","21","","22 Aug 2019","","","IEEE","IEEE Conferences"
"ParDen: Surrogate Assisted Hyper-Parameter Optimisation for Portfolio Selection","T. L. van Zyl; M. Woolway; A. Paskaramoorthy","University of Johannesburg,Institute for Intelligent Systems,Johannesburg,South Africa; University of Johannesburg,Engineering and the Built Environment,Johannesburg,South Africa; University of the Witwatersrand,Computer Science and Applied Mathematics,Johannesburg,South Africa","2021 8th International Conference on Soft Computing & Machine Intelligence (ISCMI)","29 Dec 2021","2021","","","101","107","Portfolio optimisation is a multi-objective optimisation problem (MOP), where an investor aims to optimise the conflicting criteria of maximising a portfolio’s expected return whilst minimising its risk and other costs. However, selecting a portfolio is a computationally expensive problem because of the cost associated with performing multiple evaluations on test data (""backtesting"") rather than solving the convex optimisation problem itself. In this research, we present ParDen, an algorithm for the inclusion of any discriminative or generative machine learning model as a surrogate to mitigate the computationally expensive backtest procedure. In addition, we compare the performance of alternative metaheuristic algorithms: NSGA-II, R-NSGA-II, NSGA-III, R-NSGA-III, U-NSGA-III, MO-CMA-ES, and COMO-CMA-ES. We measure performance using multi-objective performance indicators, including Generational Distance Plus, Inverted Generational Distance Plus and Hypervol-ume. We also consider meta-indicators, Success Rate and Average Executions to Success Rate, of the Hypervolume to provide more insight into the quality of solutions. Our results show that ParDen can reduce the number of evaluations required by almost a third while obtaining an improved Pareto front over the state-of-the-art for the problem of portfolio selection.","2640-0146","978-1-7281-8683-2","10.1109/ISCMI53840.2021.9654934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9654934","metaheuristics;genetic algorithms;surrogate modelling;multi-objective optimisation;portfolio selection;hyper-parameter optimisation","Measurement;Machine learning algorithms;Costs;Computational modeling;Metaheuristics;Machine learning;Optimization","","","","","","33","","29 Dec 2021","","","IEEE","IEEE Conferences"
"Multi-Objective Optimization for Personalized Prediction of Venous Thromboembolism in Ovarian Cancer Patients","M. E. Frésard; R. Erices; M. L. Bravo; M. Cuello; G. I. Owen; C. Ibáñez; M. Rodriguez-Fernandez","Institute for Biological and Medical Engineering, Schools of Engineering, Medicine and Biological Sciences, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Physiology, Faculty of Biological Sciences, Pontificia Universidad Católica de Chile, Santiago, Chile; Support Team for Oncological Research and Medicine, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Gynecology, Faculty of Medicine, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Physiology, Faculty of Biological Sciences, Millennium Institute for Immunology and Immunotherapy, Advanced Center for Chronic Diseases, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Hematology, Faculty of Medicine, Millennium Institute for Immunology and Immunotherapy, Centro del Cáncer UC-Christus, Pontificia Universidad Católica de Chile, Santiago, Chile; Institute for Biological and Medical Engineering, Schools of Engineering, Medicine and Biological Sciences, Pontificia Universidad Católica de Chile, Santiago, Chile","IEEE Journal of Biomedical and Health Informatics","5 May 2020","2020","24","5","1500","1508","Thrombotic events are one of the leading causes of mortality and morbidity related to cancer, with ovarian cancer having one of the highest incidence rates. The need to prevent these events through the prescription of adequate schemes of antithrombotic prophylaxis has motivated the development of models that aid the identification of patients at higher risk of thrombotic events with lethal consequences. However, antithrombotic prophylaxis increases the risk of bleeding and this risk depends on the class and intensity of the chosen antithrombotic prophylactic scheme, the clinical and personal condition of the patient and the disease characteristics. Moreover, the datasets used to obtain current models are imbalanced, i.e., they incorporate more patients who did not suffer thrombotic events than patients who experienced them what can lead to wrong predictions, especially for the clinically relevant patient group at high risk of thrombosis. Herein, predictive models based on machine learning were developed utilizing 121 high-grade serous ovarian carcinoma patients, considering the clinical variables of the patients and those typical of the disease. To properly manage the data imbalance, cost-sensitive classification together with multi-objective optimization was performed considering different combinations of metrics. In this way, five Pareto fronts and a series of optimal models with different false positive and false negative rates were obtained. With this novel approach to the development of clinical predictive models, personalized models can be developed, helping the clinician to achieve a better balance between the risk of bleeding and the risk of thrombosis.","2168-2208","","10.1109/JBHI.2019.2943499","FONDECYT(grant numbers:1181094,1180241,1160800); IMII(grant numbers:P09/016-F); CONICYT(grant numbers:FONDAP-15130011); Concurso Semilla Interdisciplinario 2015(grant numbers:15-158); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847419","Clinical biomarkers;prediction models;ovarian cancer;venous thromboembolism;multi-objective optimization","Predictive models;Measurement;Cancer;Thrombosis;Hemorrhaging;Biological system modeling;Optimization","biological organs;biomedical optical imaging;cancer;diseases;image classification;learning (artificial intelligence);medical image processing","clinical predictive models;personalized models;antithrombotic prophylactic scheme;clinical variables;high-grade serous ovarian carcinoma patients;clinical condition;antithrombotic prophylaxis;thrombotic events;ovarian cancer patients;venous thromboembolism;multiobjective optimization","Adult;Aged;Aged, 80 and over;Algorithms;Biomarkers;Databases, Factual;Female;Humans;Machine Learning;Middle Aged;Models, Statistical;Ovarian Neoplasms;Precision Medicine;Risk Assessment;Venous Thromboembolism","6","","54","IEEE","24 Sep 2019","","","IEEE","IEEE Journals"
"HL-Pow: A Learning-Based Power Modeling Framework for High-Level Synthesis","Z. Lin; J. Zhao; S. Sinha; W. Zhang","Hong Kong University of Science and Technology,Hong Kong; Hong Kong University of Science and Technology,Hong Kong; Indian Institute of Technology (IIT),Goa,India; Hong Kong University of Science and Technology,Hong Kong","2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC)","26 Mar 2020","2020","","","574","580","High-level synthesis (HLS) enables designers to customize hardware designs efficiently. However, it is still challenging to foresee the correlation between power consumption and HLS-based applications at an early design stage. To overcome this problem, we introduce HL-Pow, a power modeling framework for FPGA HLS based on state-of-the-art machine learning techniques. HL-Pow incorporates an automated feature construction flow to efficiently identify and extract features that exert a major influence on power consumption, simply based upon HLS results, and a modeling flow that can build an accurate and generic power model applicable to a variety of designs with HLS. By using HL-Pow, the power evaluation process for FPGA designs can be significantly expedited because the power inference of HL-Pow is established on HLS instead of the time-consuming register-transfer level (RTL) implementation flow. Experimental results demonstrate that HL-Pow can achieve accurate power modeling that is only 4.67% (24.02 mW) away from onboard power measurement. To further facilitate power-oriented optimizations, we describe a novel design space exploration (DSE) algorithm built on top of HL-Pow to trade off between latency and power consumption. This algorithm can reach a close approximation of the real Pareto frontier while only requiring running HLS flow for 20% of design points in the entire design space.","2153-697X","978-1-7281-4123-7","10.1109/ASP-DAC47756.2020.9045442","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045442","","Power demand;Hardware;Field programmable gate arrays;Estimation;Training;Power measurement;Feature extraction","electronic engineering computing;field programmable gate arrays;high level synthesis;learning (artificial intelligence);logic design;power aware computing","time-consuming register-transfer level implementation flow;HL-Pow;onboard power measurement;power-oriented optimizations;power consumption;running HLS flow;learning-based power modeling framework;high-level synthesis;HLS-based applications;accurate power model;generic power model;power evaluation process;power inference;FPGA HLS;machine learning;automated feature construction flow;feature extraction;design space exploration;Pareto frontier;power 24.02 mW","","4","","25","","26 Mar 2020","","","IEEE","IEEE Conferences"
"VeriGOOD-ML: An Open-Source Flow for Automated ML Hardware Synthesis","H. Esmaeilzadeh; S. Ghodrati; J. Gu; S. Guo; A. B. Kahng; J. K. Kim; S. Kinzer; R. Mahapatra; S. D. Manasi; E. Mascarenhas; S. S. Sapatnekar; R. Varadarajan; Z. Wang; H. Xu; B. R. Yatham; Z. Zeng","UC,San Diego; UC,San Diego; Northwestern University; Northwestern University; UC,San Diego; UC,San Diego; UC,San Diego; UC,San Diego; University of Minnesota; UC,San Diego; University of Minnesota; UC,San Diego; UC,San Diego; UC,San Diego; UC,San Diego; University of Minnesota","2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)","23 Dec 2021","2021","","","1","7","This paper introduces VeriGOOD-ML, an automated methodology for generating Verilog with no human in the loop, starting from a high-level description of a machine learning (ML) algorithm in a standard format such as ONNX. The Verilog RTL is then translated through a back-end design flow to GDSII, driven by a design planning approach that is well tailored to the macro-intensive nature of ML platforms. VeriGOOD-ML uses three approaches to build ML hardware: the TABLA platform uses a dataflow architecture that is well suited to non-DNN ML algorithms; the GeneSys platform, with a systolic array and a SIMD array, is optimized for implementing DNNs; and the Axiline approach synthesizes small ML algorithms by hardcoding the structure of the algorithm into hardware, thus trading off flexibility for performance and power. The overall approach explores the design space of platform configurations and Pareto-optimal-PPA back-end implementations to yield designs that represent different tradeoffs at the algorithmic level between area, power, performance, and execution time. The overall methodology, from architecture to back-end design to hardware implementation, is described in this paper, and the results of VeriGOOD-ML are demonstrated on a set of ML benchmarks.","1558-2434","978-1-6654-4507-8","10.1109/ICCAD51958.2021.9643449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643449","","Machine learning algorithms;Computer architecture;Machine learning;Hardware;Systolic arrays;Space exploration;Planning","","","","","","10","","23 Dec 2021","","","IEEE","IEEE Conferences"
"Shallow Versus Deep Neural Networks in Gear Fault Diagnosis","G. Cirrincione; R. R. Kumar; A. Mohammadi; S. H. Kia; P. Barbiero; J. Ferretti","Lab. LTI, University of Picardie Jules Verne, Amiens, France; Department of Industrial Engineering, University of Padova, Padova, Italy; School of Engineering and Physics, University of the South Pacific, Suva, Fiji; Lab. MIS, University of Picardie Jules Verne, Amiens, France; Department of Mathematical Sciences, Politecnico Di Torino, Turin, Italy; DET - Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy","IEEE Transactions on Energy Conversion","19 Aug 2020","2020","35","3","1338","1347","Accurate gear defect detection in induction machine-based systems is a fundamental issue in several industrial applications. At this aim, shallow neural networks, i.e., architectures with only one hidden layer, have been used after a feature extraction step from vibration, torque, acoustic pressure and electrical signals. Their additional complexity is justified by their ability in extracting its own features and in the very high-test classification rates. These signals are here analyzed, both geometrically and topologically, in order to estimate the class manifolds and their reciprocal positioning. At this aim, the different states of the gears are studied by using linear (Pareto charts, biplots, principal angles) and nonlinear (curvilinear component analysis) techniques, while the class clusters are visualized by using the parallel coordinates. It is deduced that the class manifolds are compact and well separated. This result justifies the use of a shallow neural network, instead of a deep one, as already remarked in the literature, but with no theoretical justification. The experimental section confirms this assertion, and also compares the shallow neural network results with the other machine learning techniques used in the literature.","1558-0059","","10.1109/TEC.2020.2978155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022881","Classification algorithm;fault detection;fault diagnosis;gears;induction motors;multilayer perceptron;neural networks;principal component analysis;vibrations","Gears;Feature extraction;Vibrations;Neural networks;Principal component analysis;Electronic mail;Fault detection","fault diagnosis;feature extraction;gears;learning (artificial intelligence);mechanical engineering computing;neural nets;pattern classification;principal component analysis;vibrations","linear techniques;principal angles;biplots;Pareto charts;shallow neural network results;class clusters;nonlinear techniques;class manifolds;high-test classification rates;electrical signals;acoustic pressure;feature extraction step;hidden layer;industrial applications;induction machine-based systems;accurate gear defect detection;gear fault diagnosis;deep neural networks","","6","","41","IEEE","3 Mar 2020","","","IEEE","IEEE Journals"
"Predicting best design trade-offs: A case study in processor customization","M. Zuluaga; E. Bonilla; N. Topham","ETH Zürich, Switzerland; NICTA & Australian National University, Australia; University of Edinburgh, UK","2012 Design, Automation & Test in Europe Conference & Exhibition (DATE)","3 Apr 2012","2012","","","1030","1035","Given the high level description of a task, many different hardware modules may be generated while meeting its behavioral requirements. The characteristics of the generated hardware can be tailored to favor energy efficiency, performance, accuracy or die area. The inherent trade-offs between such metrics need to be explored in order to choose a solution that meets design and cost expectations. We address the generic problem of automatically deriving a hardware implementation from a high-level task description. In this paper we present a novel technique that exploits previously explored implementation design spaces in order to find optimal trade-offs for new high-level descriptions. This technique is generalizable to a range of high-level synthesis problems in which trade-offs can be exposed by changing the parameters of the hardware generation tool. Our strategy, based upon machine learning techniques, models the impact of the parameterization of the tool on the target objectives, given the characteristics of the input. Thus, a predictor is able to suggest a subset of parameters that are likely to lead to optimal hardware implementations. The proposed method is evaluated on a resource sharing problem which is typical in high level synthesis, where the trade-offs between area and performance need to be explored. In this case study, we show that the technique can reduce by two orders of magnitude the number of design points that need to be explored in order to find the Pareto optimal solutions.","1558-1101","978-1-4577-2145-8","10.1109/DATE.2012.6176647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6176647","","Training;Hardware;Measurement;Predictive models;Feature extraction;Space exploration;Resource management","electronic engineering computing;high level synthesis;integrated circuit design;learning (artificial intelligence);VLSI","processor customization;hardware modules;energy efficiency;high-level task description;high-level synthesis problems;hardware generation tool;machine learning techniques;resource sharing problem;Pareto optimal solutions;VLSI designs;best design trade-off prediction","","6","","16","","3 Apr 2012","","","IEEE","IEEE Conferences"
"autoAx: An Automatic Design Space Exploration and Circuit Building Methodology utilizing Libraries of Approximate Components","V. Mrazek; M. A. Hanif; Z. Vasicek; L. Sekanina; M. Shafique","Faculty of Information Technology, IT4Innovations Centre of Excellence, Brno University of Technology, Czech Republic; Institute of Computer Engineering, Vienna University of Technology (TU Wien), Austria; Faculty of Information Technology, IT4Innovations Centre of Excellence, Brno University of Technology, Czech Republic; Faculty of Information Technology, IT4Innovations Centre of Excellence, Brno University of Technology, Czech Republic; Institute of Computer Engineering, Vienna University of Technology (TU Wien), Austria","2019 56th ACM/IEEE Design Automation Conference (DAC)","22 Aug 2019","2019","","","1","6","Approximate computing is an emerging paradigm for developing highly energy-efficient computing systems such as various accelerators. In the literature, many libraries of elementary approximate circuits have already been proposed to simplify the design process of approximate accelerators. Because these libraries contain from tens to thousands of approximate implementations for a single arithmetic operation it is intractable to find an optimal combination of approximate circuits in the library even for an application consisting of a few operations. An open problem is “how to effectively combine circuits from these libraries to construct complex approximate accelerators”. This paper proposes a novel methodology for searching, selecting and combining the most suitable approximate circuits from a set of available libraries to generate an approximate accelerator for a given application. To enable fast design space generation and exploration, the methodology utilizes machine learning techniques to create computational models estimating the overall quality of processing and hardware cost without performing full synthesis at the accelerator level. Using the methodology, we construct hundreds of approximate accelerators (for a Sobel edge detector) showing different but relevant tradeoffs between the quality of processing and hardware cost and identify a corresponding Pareto-frontier. Furthermore, when searching for approximate implementations of a generic Gaussian filter consisting of 17 arithmetic operations, the proposed approach allows us to identify approximately 10<sup>3</sup> highly relevant implementations from 10<sup>23</sup> possible solutions in a few hours, while the exhaustive search would take four months on a high-end processor.","0738-100X","978-1-4503-6725-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806857","","Libraries;Hardware;Integrated circuit modeling;Computational modeling;Space exploration;Machine learning algorithms;Adders","circuit optimisation;combinational circuits;learning (artificial intelligence);logic design;Pareto optimisation","autoAx;circuit building methodology;energy-efficient computing systems;single arithmetic operation;machine learning techniques;computational models;Sobel edge detector;Pareto-frontier;generic Gaussian filter;arithmetic operations;high-end processor;complex approximate accelerators;design process;elementary approximate circuits;approximate computing;approximate components;automatic design space exploration;hardware cost;fast design space generation","","","","16","","22 Aug 2019","","","IEEE","IEEE Conferences"
"An Agent-Based Hierarchical Bargaining Framework for Power Management of Multiple Cooperative Microgrids","K. Dehghanpour; H. Nehrir","Department of Electrical and Computer Engineering, Montana State University, Bozeman, MT, USA; Department of Electrical and Computer Engineering, Montana State University, Bozeman, MT, USA","IEEE Transactions on Smart Grid","28 Dec 2018","2019","10","1","514","522","In this paper, we propose an agent-based hierarchical power management model in a power distribution system composed of several microgrids (MGs). At the lower level of the model, multiple MGs bargain with each other to cooperatively obtain a fair, and Pareto-optimal solution to their power management problem, employing the concept of Nash bargaining solution and using a distributed optimization framework. At the highest level of the model, a distribution system power supplier, e.g., a utility company, interacts with both the cluster of the MGs and the wholesale market. The goal of the utility company is to facilitate power exchange between the regional distribution network consisting of multiple MGs and the wholesale market to achieve its own private goals. The power exchange is controlled through dynamic energy pricing at the distribution level, at the day-ahead and real-time stages. To implement energy pricing at the utility company level, an iterative machine learning mechanism is employed, where the utility company develops a price-sensitivity model of the aggregate response of the MGs to the retail price signal through a learning process. This learned model is then used to perform optimal energy pricing. To verify its applicability, the proposed decision model is tested on a system with multiple MGs, with each MG having different load/generation data.","1949-3061","","10.1109/TSG.2017.2746014","Montana State University; U.S. Department of Energy(grant numbers:# DE-FG02-11ER46817); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017431","Microgrids;bargaining games;distributed optimization;agent-based modeling;power management","Companies;Pricing;Linear programming;Optimization;NIST;Power markets;Load modeling","distributed power generation;distribution networks;game theory;learning (artificial intelligence);multi-agent systems;Pareto optimisation;power engineering computing;power markets;power system management;pricing","price-sensitivity model;optimal energy pricing;decision model;agent-based hierarchical bargaining framework;agent-based hierarchical power management model;power distribution system;multiple MGs bargain;power management problem;Nash bargaining solution;distributed optimization framework;distribution system power supplier;wholesale market;power exchange;regional distribution network;dynamic energy pricing;distribution level;utility company level;Pareto-optimal solution;multiple cooperative microgrids;iterative machine learning mechanism","","47","","27","IEEE","29 Aug 2017","","","IEEE","IEEE Journals"
"Yield Learning for Complex FinFET Defect Mechanisms Based on Volume Scan Diagnosis Results","H. Tang; M. Sharma; W. -T. Cheng; G. Veda; D. Gehringer; M. Knowles; J. D’Souza; K. Sekar; N. Bawaskar; Y. Pan","Mentor, A Siemens Business, Wilsonville, OR, 97070; Mentor, A Siemens Business, Wilsonville, OR, 97070; Mentor, A Siemens Business, Wilsonville, OR, 97070; Mentor, A Siemens Business, Wilsonville, OR, 97070; Mentor, A Siemens Business, Wilsonville, OR, 97070; Mentor, A Siemens Business, Wilsonville, OR, 97070; Mentor, A Siemens Business, Wilsonville, OR, 97070; GLOBALFOUNDRIES, NY, 1202; GLOBALFOUNDRIES, NY, 1202; GLOBALFOUNDRIES, NY, 1202","2019 30th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)","8 Aug 2019","2019","","","1","7","Device complexity is reaching all-time highs with the adoption of high aspect ratio FinFETs created using multi- patterning process technologies. Simultaneously, new product segments such as AI and automotive are being fabricated on such advanced processes. In this dynamic environment, new complex defect modes have challenged manufacturers to ramp and sustain quality and yield at advanced nodes. Process variability of the standard cell introduces new transistor-level defect modes. Meanwhile the cost of traditional failure analysis has continued to skyrocket. How will the industry reduce the defect-rate and ramp yield to meet these aggressive market demands? This article will detail a new breakthrough in the field of scan diagnosis using machine learning. For the first time, cell-internal defects are detected, diagnosed and now resolved with RCD (Root Cause Deconvolution). Experimental FA results will show how RCD is used to build an accurate defect pareto and pick targeted die for FA for faster and cheaper root cause identification.","2376-6697","978-1-5386-7601-1","10.1109/ASMC.2019.8791755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791755","scan diagnosis;volume diagnosis;yield analysis;root cause identification;cell aware diagnosis","Logic gates;Layout;Transistors;Integrated circuit interconnections;Bridges;Deconvolution;Libraries","electronic engineering computing;failure analysis;fault diagnosis;learning (artificial intelligence);MOSFET;semiconductor device reliability","complex FinFET defect mechanisms;device complexity;complex defect modes;process variability;transistor-level defect modes;ramp yield;machine learning;yield learning;volume scan diagnosis;high aspect ratio FinFETs;multipatterning process technologies;failure analysis;defect-rate reduction;cell-internal defect detection;root cause deconvolution;RCD;root cause identification","","2","","31","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Solving Combinatorial Multi-Objective Bi-Level Optimization Problems Using Multiple Populations and Migration Schemes","R. Said; S. Bechikh; A. Louati; A. Aldaej; L. B. Said","Strategies for Modelling and Artificial inTelligence (SMART) Laboratory, ISG, University of Tunis, Tunis, Tunisia; Strategies for Modelling and Artificial inTelligence (SMART) Laboratory, ISG, University of Tunis, Tunis, Tunisia; Department of Information Systems, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia; Department of Information Systems, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia; Strategies for Modelling and Artificial inTelligence (SMART) Laboratory, ISG, University of Tunis, Tunis, Tunisia","IEEE Access","10 Aug 2020","2020","8","","141674","141695","Many decision making situations are characterized by a hierarchical structure where a lower-level (follower) optimization problem appears as a constraint of the upper-level (leader) one. Such kind of situations is usually modeled as a BLOP (Bi-Level Optimization Problem). The resolution of the latter usually has a heavy computational cost because the evaluation of a single upper-level solution requires finding its corresponding (near) optimal lower-level one. When several objectives are optimized in each level, the BLOP becomes a multi-objective task and more computationally costly as the optimum corresponds to a whole non-dominated solution set, called the PF (Pareto Front). Despite the considerable number of recent works in multi-objective evolutionary bi-level optimization, the number of methods that could be applied to the combinatorial (discrete) case is much reduced. Motivated by this observation, we propose in this paper an Indicator-Based version of our recently proposed Co-Evolutionary Migration-Based Algorithm (CEMBA), that we name IB-CEMBA, to solve combinatorial multi-objective BLOPs. The indicator-based search choice is justified by two arguments. On the one hand, it allows selecting the solution having the maximal marginal contribution in terms of the performance indicator from the lower-level PF. On the other hand, it encourages both convergence and diversity at the upper-level. The comparative experimental study reveals the outperformance of IB-CEMBA on a multi-objective bi-level production-distribution problem. From the effectiveness viewpoint, the upper-level hyper-volume values and inverted generational distance ones vary in the intervals [0.8500, 0.9710] and [0.0072, 0.2420], respectively. From the efficiency viewpoint, IB-CEMBA has a good reduction rate of the Number of Function Evaluations (NFEs), lying in the interval [30.13%, 54.09%]. To further show the versatility of our algorithm, we have developed a case study in machine learning, and more specifically we have addressed the bi-level multi-objective feature construction problem.","2169-3536","","10.1109/ACCESS.2020.3013568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154441","Combinatorial bi-level multi-objective optimization;computational cost;indicator-based evolutionary algorithms;population decomposition;migration schemes","Optimization;Linear programming;Sociology;Statistics;Computational efficiency;Genetic algorithms;Decision making","combinatorial mathematics;decision making;genetic algorithms;Pareto optimisation;statistical analysis","coevolutionary migration-based algorithm;indicator-based version;multiobjective evolutionary bilevel optimization;optimal lower-level solution;combinatorial multiobjective bilevel optimization problems;bilevel multiobjective feature construction problem;combinatorial case;multiobjective task;upper-level solution;lower-level optimization problem;decision making situations;upper-level hyper-volume values;multiobjective bi-level production-distribution problem;IB-CEMBA;lower-level PF;indicator-based search choice;combinatorial multiobjective BLOPs","","4","","63","CCBY","3 Aug 2020","","","IEEE","IEEE Journals"
"Determination of Event Patterns for Complex Event Processing Using Fuzzy Unordered Rule Induction Algorithm with Multi-objective Evolutionary Feature Subset Selection","N. Mehdiyev; J. Krumeich; D. Werth; P. Loos",NA; NA; NA; NA,"2016 49th Hawaii International Conference on System Sciences (HICSS)","10 Mar 2016","2016","","","1719","1728","Complex Event Processing (CEP) is an emerging technology to process streaming data and to generate response actions in real time. CEP systems treat all sensor data as primitive events and attempt to detect semantically high level events and related actions by matching them using event patterns. These event patterns are the rules which combine primitive events according to temporal, logical, or spatial correlations among them. Although event patterns (decision rules) can be provided by experts in simplistic scenarios, the huge amount of sensor data makes this unfeasible. The main purpose of the underlying paper is replacing manual identification of event patterns. Considering the uncertainty related to the sensor data, Fuzzy Unordered Rule Induction Algorithm (FURIA) was implemented to identify event patterns after selecting the relevant feature subset using Elitist Pareto-based Multi-Objective Evolutionary Algorithm for Diversity Reinforcement (ENORA). The results were compared to the alternative machine learning approaches.","1530-1605","978-0-7695-5670-3","10.1109/HICSS.2016.216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427396","Complex Event Processing;Fuzzy Unordered Rule Induction;Multi-Objective Evolutionary Feature Subset Selection","Classification algorithms;Filtering algorithms;Uncertainty;Machine learning algorithms;Pattern matching;Optimization;Real-time systems","data analysis;evolutionary computation;fuzzy set theory;Pareto optimisation","event pattern;complex event processing;fuzzy unordered rule induction algorithm;multiobjective evolutionary feature subset selection;streaming data;response action;CEP system;sensor data;primitive event;FURIA;relevant feature subset;elitist Pareto-based multiobjective evolutionary algorithm for diversity reinforcement;ENORA;machine learning approach","","10","","52","","10 Mar 2016","","","IEEE","IEEE Conferences"
"Corrections to “Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies” [May 08 397-415]","Y. Jin; B. Sendhoff",NA; NA,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","14 Apr 2009","2009","39","3","373","373","In the above titled paper (ibid., vol. 38, no. 3, pp. 397-415, May 08), there are three sites where an inequality is put wrongly.  The corrections are presented here.","1558-2442","","10.1109/TSMCC.2009.2018893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813238","","Machine learning;Europe","","","","8","","1","IEEE","10 Apr 2009","","","IEEE","IEEE Journals"
"Guest Editorial Evolutionary Computation Meets Deep Learning","W. Ding; W. Pedrycz; G. G. Yen; B. Xue","School of Information Science and Technology, Nantong University, Nantong, China; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","810","814","Deep learning is a timely research direction in machine learning, where breakthrough progress has been made in both academe and industries, bringing promising results in speech recognition, computer vision, industrial control and automation, etc. The motivation of deep learning is primarily to establish a model to simulate the neural connection structure of the human brain. While dealing with complex tasks, deep learning adopts a number of transformation stages to deliver the in-depth description and interpretation of the data. Deep learning achieves exceptional power and flexibility by learning to represent the task through a nested hierarchy of layers, with more abstract representations formed successively in terms of less abstract ones. One of the key issues of existing deep learning approaches is that the meaningful representations can be learned only when their hyperparameter settings are properly specified beforehand, and general parameters are learned during the training process. Until now, not much research has been dedicated to automatically set the hyperparameters, and accurately find the globally optimal general parameters. However, this problem can be formulated as optimization problems, including discrete optimization, constrained optimization, large-scale global optimization, and multiobjective optimization, by engaging mechanisms of evolutionary computation.","1941-0026","","10.1109/TEVC.2021.3096336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552976","","","","","","","","0","IEEE","30 Sep 2021","","","IEEE","IEEE Journals"
"Keynote talks: Evolutionary feature selection and dimensionality reduction","M. Zhang","Victoria University of Wellington, New Zealand","2017 21st Asia Pacific Symposium on Intelligent and Evolutionary Systems (IES)","25 Dec 2017","2017","","","ix","xii","In data mining and machine learning, many real-world problems such as bio-data classification and biomarker detection, image analysis, text mining often involve a large number of features/attributes. However, not all the features are essential since many of them are redundant or even irrelevant, and the useful features are typically not equally important. Using all the features for classification or other data mining tasks typically does not produce good results due to the big dimensionality and the large search space. This problem can be solved by feature selection to select a small subset of original (relevant) features or feature construction to create a smaller set of high-level features using the original low-level features. Feature selection and construction are very challenging tasks due to the large search space and feature interaction problems. Exhaustive search for the best feature subset of a given dataset is practically impossible in most situations. A variety of heuristic search techniques have been applied to feature selection and construction, but most of the existing methods still suffer from stagnation in local optima and/or high computational cost. Due to the global search potential and heuristic guidelines, evolutionary computation techniques such as genetic algorithms, genetic programming, particle swarm optimisation, ant colony optimisation, differential evolution and evolutionary multiobjective optimisation have been recently used for feature selection and construction for dimensionality reduction, and achieved great success. Many of these methods only select/construct a small number of important features, produce higher accuracy, and generated small models that are efficient on unseen data. Evolutionary computation techniques have now become an important means for handle big dimensionality and feature selection and construction. The talk will introduce the general framework within which evolutionary feature selection and construction can be studied and applied, sketching a schematic taxonomy of the field and providing examples of successful real-world applications. The application areas to be covered will include bio-data classification and biomarker detection, image analysis and object recognition and pattern classification, symbolic regression, network security and intrusion detection, and text mining. EC techniques to be covered will include genetic algorithms, genetic programming, particle swarm optimisation, differential evolution, ant colony optimisation, artificial bee colony optimisation, and evolutionary multi-objective optimisation. We will show how such evolutionary computation techniques can be effectively applied to feature selection/construction and dimensionality reduction and provide promising results.","","978-1-5386-0743-5","10.1109/IESYS.2017.8233551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233551","","","ant colony optimisation;data mining;evolutionary computation;feature selection;genetic algorithms;learning (artificial intelligence);particle swarm optimisation;pattern classification;search problems","evolutionary feature selection;machine learning;bio-data classification;text mining;data mining tasks;feature construction;high-level features;low-level features;feature interaction problems;evolutionary computation techniques;particle swarm optimisation;evolutionary multiobjective optimisation;object recognition;biomarker detection;intrusion detection;network security;symbolic regression;pattern classification;genetic algorithms;genetic programming;differential evolution;ant colony optimisation;artificial bee colony optimisation","","","","","","25 Dec 2017","","","IEEE","IEEE Conferences"
"[Front cover]","",,"2010 Ninth International Conference on Machine Learning and Applications","4 Feb 2011","2010","","","C1","C1","The following topics are dealt with: machine learning; data acquisition, cleansing and categorization; planning and reinforcement learning; supervised learning; multiparty, multimodal and multiobjective learning; feature selection; probabilistic and model based learning; similarity learning; pattern recognition; kernel learning; unsupervised learning; bioinformatics and computational biology; parallel computing; ensemble learning; Bayesian learning; incremental learning; biomedical literature analysis and text retrieval; dynamic learning; multimedia data; and cancer and radiation therapy.","","978-1-4244-9211-4","10.1109/ICMLA.2010.172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5708996","","","Bayes methods;bioinformatics;cancer;data acquisition;data analysis;feature extraction;information retrieval;learning (artificial intelligence);multimedia computing;parallel processing;planning (artificial intelligence);probability;radiation therapy;text analysis","machine learning;data acquisition;data cleansing;data categorization;planning;reinforcement learning;multiparty learning;multimodal learning;multiobjective learning;feature selection;probabilistic learning;model based learning;similarity learning;pattern recognition;kernel learning;unsupervised learning;bioinformatics;computational biology;parallel computing;ensemble learning;Bayesian learning;incremental learning;biomedical literature analysis;text retrieval;dynamic learning;multimedia data;cancer;radiation therapy","","","","","","4 Feb 2011","","","IEEE","IEEE Conferences"
"Table of contents","",,"2014 IEEE Congress on Evolutionary Computation (CEC)","22 Sep 2014","2014","","","I","XXIV","The following topics are dealt with: computational intelligence; computational games; memetic computing; evolutionary computer vision; bio-inspired computation; evolutionary multiobjective optimization; decision making; differential evolution; combinatorial optimization; artificial bee colony algorithms; swarm intelligence; real-world engineering optimization; complex networks; machine learning; statistical learning; nature-inspired constrained optimization; bioinformatics; data mining; evolutionary games; multiagent systems; hybrid evolutionary computational methods; large scale global optimization; cloud computing; learning classifier systems; opposition-based learning; genetic programming; hyperheuristics; predictive maintenance; cultural algorithms; knowledge extraction; single objective numerical optimization; process mining; estimation of distribution algorithms; biomedical applications; robotics applications; engineering applications; constraint handling; preference handling; and firework algorithms.","1941-0026","978-1-4799-1488-3","10.1109/CEC.2014.6900664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6900664","","","artificial intelligence;biocomputing;bioinformatics;cloud computing;combinatorial mathematics;computer vision;constraint handling;data mining;decision making;game theory;multi-agent systems;optimisation;pattern classification;robots","computational intelligence;computational games;memetic computing;evolutionary computer vision;bio-inspired computation;evolutionary multiobjective optimization;decision making;differential evolution;combinatorial optimization;artificial bee colony algorithms;swarm intelligence;real-world engineering optimization;complex networks;machine learning;statistical learning;nature-inspired constrained optimization;bioinformatics;data mining;evolutionary games;multiagent systems;hybrid evolutionary computational methods;large scale global optimization;cloud computing;learning classifier systems;opposition-based learning;genetic programming;hyperheuristics;predictive maintenance;cultural algorithms;knowledge extraction;single objective numerical optimization;process mining;estimation of distribution algorithms;biomedical applications;robotics applications;engineering applications;constraint handling;preference handling;firework algorithms","","","","","","22 Sep 2014","","","IEEE","IEEE Conferences"
"[Title page i]","",,"2015 IEEE International Conference on Systems, Man, and Cybernetics","14 Jan 2016","2015","","","i","i","The following topics are dealt with: Systems Science and Engineering; Decision Support Systems Based on Multicriteria Models; Distributed Adaptive Systems; Intelligent Learning in Control Systems; Robotics, Human Machine Interface, and Haptics; Intelligent Manufacturing Processes and Innovative Applications; Discrete Event and Hybrid Systems; Meta-synthesis and Complex Systems; Conflict Resolution; Grey Systems: Theory and Applications; Global Energy Internet; Medical Mechatronics; SMC: Systems Science; Human-Machine Systems; Automation Design and Intelligence Control Applications; Risk Management of Information and Control Systems; Proactive Health Care Systems: Methodologies and Applications; Human Centered Transportation Systems; Collaborative Wireless Sensor Networks and Internet of Things; Collaborative Technologies and Applications; Interaction-Centered Analytics and Design for Human-Centric Systems; Assistive and Rehabilitative Technology and Applications; Cybernetics; Intelligent Internet Systems; Fuzzy Methods for Uncertain Data Mining; Quantum Cybernetics and Learning Systems; Soft Computing; Machine Learning and Information Retrieval in Big Data Environment; Matrix and Tensor Analysis for Big Vision; Innovations in Fuzzy Systems and Applications; Knowledge Engineering in Medical Informatics; Medical and Health Care Engineering; Cognitive Agents and Robotics for Human-Centric Systems: New Models and Challenges; Intelligent Healthcare; Intelligent Vehicle Systems and Control; Granular Computing; Tensor Product Applications; Computing Aspects of Big Data; Emerging Technologies and Applications in Computer Intelligence; Computational Intelligence Methods for Big Data Analytics; BMI Workshop; Shared Control; Multimodal Brain Computer Interface and Physiological Computing; Real World Applications of Brain Computer Interface Systems; User-Training in EEG-Based Brain-Computer Interfaces; Computational Intelligence and Machine Learning for BCI.","","978-1-4799-8697-2","10.1109/SMC.2015.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379133","","","Big Data;brain-computer interfaces;control systems;cybernetics;decision support systems;electroencephalography;granular computing;grey systems;haptic interfaces;health care;information retrieval;Internet of Things;man-machine systems;mechatronics;risk management;robots;systems engineering","proactive health care systems;human centered transportation systems;collaborative wireless sensor networks;Internet of Things;interaction-centered analytics;human-centric systems;rehabilitative technology;intelligent Internet systems;fuzzy methods;uncertain data mining;quantum cybernetics;learning systems;soft computing;machine learning;information retrieval;Big Data environment;matrix;tensor analysis;big vision;innovations;fuzzy systems;risk management;intelligence control applications;automation design;human-machine systems;medical mechatronics;global energy Internet;grey systems;conflict resolution;complex systems;hybrid systems;discrete event;innovative applications;intelligent manufacturing processes;haptics;human machine interface;robotics;control systems;intelligent learning;distributed adaptive systems;multicriteria models;decision support systems;systems engineering;systems science;SMC;knowledge engineering;medical informatics;health care engineering;cognitive agents;intelligent healthcare;intelligent vehicle systems;granular computing;tensor product applications;computing aspects;emerging technologies;computer intelligence;computational intelligence methods;Big Data analytics;BMI workshop;shared control;multimodal brain computer interface;physiological computing;brain computer interface systems;user-training;EEG-based brain-computer interfaces;BCI","","","","","","14 Jan 2016","","","IEEE","IEEE Conferences"
"Table of contents","",,"2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","4 Dec 2014","2014","","","I","XLVI","The following topics are dealt with: collaborative wireless sensor networks; agent-based modeling; human performance modeling; biometric systems and bioinformatics; heuristic algorithms; advance on discrete event systems: theory and applications; image processing/pattern recognition; innovative technologies and applications in computer intelligence; machine vision; optimization; swarm intelligence; decision support systems based on multicriteria models; sytems engineering; ecological interface design: 25 years and counting; computational intelligence; human-machine systems; medical informatics; cybernetics for informatics; workshop on system engineering human-centered intelligent vehicles; computational awareness; computational intelligence methods for big data processing; modelling, analysis and control of human-machine motor coordination; intelligent robots and systems; human-machine systems; distributed intelligent systems & micro and/or nano systems; neural networks and applications; frontiers in model-based systems engineering; brain machine interfaces for practical applications; non-BMI assistive technologies; collaborative technologies and applications; emerging technologies in medical mechatronics; fuzzy systems and applications; discrete event systems and Petri nets; distributed adaptive systems; shared control; human centered transportation systems; conflict resolution; large-scale system of systems; machine learning; grey systems: theory and applications; proactive health care systems: methodologies and applications; intelligent learning in control systems; intelligent Internet systems; brain computer interface for communication, control and rehabilitation; assistive technology & human machine interface; human factors; expert and knowledge-based systems; friendly design for disability in intelligent transportation systems; human machine interface, haptics and robotics; assistive and rehabilitative technology; BMI methods; uncertainly in big data; data science for big data; collaborative processing of big data; automated intelligence and innovative applications; evolutionary computation; model-based healthcare; knowledge engineering in medicine and health informatics; manufacturing systems and automation; medical informatics; fault monitoring and diagnosis; granular computing; intelligent power grid; eye-tracking; image quality assessment, security, and systems; control of uncertain systems; enterprise architecture and engineering; soft computing; intelligent media and new-generarion software; and mechatronics.","1062-922X","978-1-4799-3840-7","10.1109/SMC.2014.6973874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6973874","","","Big Data;bioinformatics;biometrics (access control);brain-computer interfaces;control systems;cybernetics;decision support systems;discrete event systems;haptic interfaces;image processing;intelligent transportation systems;knowledge based systems;man-machine systems;manufacturing systems;mechatronics;medicine;neural nets;optimisation;pattern recognition;Petri nets;robots;security of data;uncertain systems;wireless sensor networks","modelling;human-machine motor coordination;intelligent robots;distributed intelligent systems;micro systems;nano systems;neural networks;model-based systems engineering;brain machine interfaces;non-BMI assistive technologies;collaborative technologies;medical mechatronics;fuzzy systems;Petri nets;distributed adaptive systems;shared control;human centered transportation systems;conflict resolution;machine learning;grey systems;proactive health care systems;intelligent learning;control systems;intelligent Internet systems;brain computer interface;human machine interface;human factors;expert systems;knowledge-based systems;intelligent transportation systems;haptics;robotics;rehabilitative technology;big data processing;computational intelligence methods;computational awareness;human-centered intelligent vehicles;medical informatics;human-machine systems;ecological interface design;multicriteria models;decision support systems;swarm intelligence;optimization;machine vision;computer intelligence;innovative technologies;pattern recognition;image processing;discrete event systems;heuristic algorithms;bioinformatics;biometric systems;human performance modeling;agent-based modeling;collaborative wireless sensor networks;cybernetics;BMI methods;data science;collaborative processing;automated intelligence;innovative applications;evolutionary computation;model-based healthcare;knowledge engineering;medicine;health informatics;manufacturing systems;automation;fault monitoring;granular computing;intelligent power grid;eye-tracking;image quality assessment;image security;uncertain systems;enterprise architecture;soft computing;intelligent media;new generarion software","","","","","","4 Dec 2014","","","IEEE","IEEE Conferences"
"The 2005 IEEE Congress on Evolutionary Computation","",,"2005 IEEE Congress on Evolutionary Computation","12 Dec 2005","2005","2","","nil2","nil2","The following topics are dealt with: evolutionary multiobjective optimization; bioinformatics and bioscience applications; particle swarm optimisation; complex adaptive systems; real-parameter optimization; evolutionary design; artificial life; classifier systems; machine learning; data mining; genome informatics; combinatorial and numerical optimization; games; hybridization; adaptation; evolutionary clustering; evolvable hardware; genetic programming; probabilistic models; ant systems, collective behaviour and co-evolution; dynamic and uncertain environments; and planning and scheduling","1941-0026","0-7803-9363-5","10.1109/CEC.2005.1554789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1554789","","","adaptive systems;artificial life;data mining;evolutionary computation;learning (artificial intelligence);optimisation","evolutionary multiobjective optimization;bioinformatics;bioscience applications;genome informatics;combinatorial optimization;numerical optimization;games;hybridization;adaptation;evolutionary clustering;evolvable hardware;genetic programming;probabilistic models;evolutionary programming;ant systems;collective behaviour;coevolution;fitness landscape studies;dynamic environments;uncertain environments;planning;scheduling;particle swarm optimisation;complex adaptive systems;real-parameter optimization;evolutionary design;artificial life;classifier systems;machine learning;data mining","","","","","","12 Dec 2005","","","IEEE","IEEE Conferences"
"The 2005 IEEE Congress on Evolutionary Computation (IEEE Cat. No. 05TH8834)","",,"2005 IEEE Congress on Evolutionary Computation","12 Dec 2005","2005","1","","nil2","nil2","The following topics are dealt with: evolutionary multiobjective optimization; bioinformatics and bioscience applications; particle swarm optimisation; complex adaptive systems; real-parameter optimization; evolutionary design; artificial life; classifier systems; machine learning; data mining; genome informatics; combinatorial and numerical optimization; games; hybridization; adaptation; evolutionary clustering; evolvable hardware; genetic programming; probabilistic models; ant systems, collective behaviour and co-evolution; dynamic and uncertain environments; and planning and scheduling.","1941-0026","0-7803-9363-5","10.1109/CEC.2005.1554654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1554654","","","optimisation;evolutionary computation;adaptive systems;learning (artificial intelligence);data mining;artificial life","evolutionary multiobjective optimization;bioinformatics;bioscience applications;genome informatics;combinatorial optimization;numerical optimization;games;hybridization;adaptation;evolutionary clustering;evolvable hardware;genetic programming;probabilistic models;evolutionary programming;ant systems;collective behaviour;coevolution;fitness landscape studies;dynamic environments;uncertain environments;planning;scheduling;particle swarm optimisation;complex adaptive systems;real-parameter optimization;evolutionary design;artificial life;classifier systems;machine learning;data mining","","","","","","12 Dec 2005","","","IEEE","IEEE Conferences"
"Table of contents","",,"2013 Brazilian Conference on Intelligent Systems","30 Jan 2014","2013","","","v","viii","The following topics are dealt with: machine learning and data mining; agent-based and multi-agent systems; evolutionary computation and swarm intelligence; pattern recognition and cluster analysis; logic-based knowledge representation and reasoning; constraints and search planning and scheduling; and multiobjective optimization.","","978-0-7695-5092-3","10.1109/BRACIS.2013.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726411","","","data mining;evolutionary computation;inference mechanisms;knowledge representation;learning (artificial intelligence);multi-agent systems;pattern recognition;swarm intelligence","multiobjective optimization;scheduling;search planning;constraints;reasoning;logic-based knowledge representation;cluster analysis;pattern recognition;swarm intelligence;evolutionary computation;multiagent systems;agent-based systems;data mining;machine learning;intelligent systems","","","","","","30 Jan 2014","","","IEEE","IEEE Conferences"
"Table of contents","",,"2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","13 Dec 2012","2012","","","I","XL","The following topics are dealt with: grey system; intelligent systems; intelligent control; biological systems; biological evolution; innovative soft computing methodologies; pattern recognition; medical imaging; computer vision; body signal analysis; brain signal analysis; multiagent systems; decision support systems; multicriteria models; business applications; discrete event; machine vision; collaborative manufacturing; supply chains; human-computer interaction; collaborative computing; Petri net; biometric systems; machine learning; health care technology; medical care technology; collaborative technologies; cognitive engineering; human centered transportation systems; new-generation software; intelligent media; complex systems; artificial intelligence; human perception; human-oriented convergence research; intelligent learning; control systems; intelligent multimedia-mobile communications; information assurance; intelligent Internet systems; intelligent vehicular systems; neural computation; knowledge representation; data mining; nature-inspired algorithms; computational collective intelligence; computational awareness; human machine interface; system modeling; ambient-adaptive intelligent lighting systems; knowledge acquisition; knowledge mining; video processing; image processing; communication systems; human centered tagging; shared control; and 3D visualization.","1062-922X","978-1-4673-1714-6","10.1109/ICSMC.2012.6377666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6377666","","","cybernetics;man-machine systems;systems engineering","grey system;intelligent systems;intelligent control;biological systems;biological evolution;pattern recognition;medical imaging;computer vision;body signal analysis;brain signal analysis;multiagent systems;decision support systems;multicriteria models;business applications;discrete event;machine vision;collaborative manufacturing;supply chains;human-computer interaction;collaborative computing;Petri net;biometric systems;machine learning;health care technology;medical care technology;collaborative technologies;cognitive engineering;human centered transportation systems;new-generation software;intelligent media;complex systems;artificial intelligence;human perception;human-oriented convergence research;intelligent learning;control systems;intelligent multimedia-mobile communications;information assurance;intelligent Internet systems;intelligent vehicular systems;neural computation;knowledge representation;data mining;nature-inspired algorithms;computational collective intelligence;computational awareness;human machine interface;system modeling;ambient-adaptive intelligent lighting systems;knowledge acquisition;knowledge mining;video processing;image processing;communication systems;human centered tagging;shared control;3D visualization;innovative soft computing methodologies","","","","","","13 Dec 2012","","","IEEE","IEEE Conferences"
"Table of contents","",,"2011 IEEE Symposium on Computational Intelligence in Multicriteria Decision-Making (MDCM)","11 Jul 2011","2011","","","iii","vi","The following topics are dealt with: computational intelligence; decision making; evolutionary multiobjective optimization; and machine learning.","","978-1-61284-069-7","10.1109/SMDCM.2011.5949294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5949294","","","decision making;learning (artificial intelligence);optimisation","computational intelligence;decision making;multiobjective optimization;machine learning","","","","","","11 Jul 2011","","","IEEE","IEEE Conferences"
"[Title Page i]","",,"2012 Brazilian Symposium on Neural Networks","6 Dec 2012","2012","","","i","i","The following topics are dealt with: unsupervised machine learning; bioinformatics; semisupervised learning; neural networks; robotics; evolutionary systems; swarm intelligence; hybrid intelligent systems; multiobjective optimization and pattern recognition.","2375-0235","978-1-4673-2641-4","10.1109/SBRN.2012.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374859","","","bioinformatics;neural nets;optimisation;pattern recognition;robots;swarm intelligence;unsupervised learning","unsupervised machine learning;bioinformatics;semisupervised learning;neural networks;robotics;evolutionary systems;swarm intelligence;hybrid intelligent systems;multiobjective optimization;pattern recognition","","","","","","6 Dec 2012","","","IEEE","IEEE Conferences"
"[Front cover]","",,"2009 Ninth International Conference on Intelligent Systems Design and Applications","28 Dec 2009","2009","","","C1","C1","The following topics are dealt with: intelligent systems design; evolutionary algorithms; soft computing in intelligent agents and Web technologies; genetic fuzzy systems; intelligent image processing and artificial vision; hybrid learning for artificial neural networks; swarm intelligence; tags and recommendations in Web 2.0; representation and approximation of fuzzy numbers; from business intelligence to business artificial intelligence; evolutionary multiobjective optimization design and applications; designing comprehensible intelligent systems; computational intelligence in business management and risk analysis; hybrid metaheuristics; intelligent systems for data reduction; intelligent signal and image analysis in remote sensing; human monitoring and machine learning strategies; innovative networking and communication techniques; intelligent control and automation; intelligent Internet modeling; consensus and decision making; education and learning models; provisioning of smart services in ontology-based systems; intelligent e-learning systems; intelligent systems for industrial processes; intelligent data mining; educational data mining; intelligent knowledge management; bioinformatics; neural networks and neuro-fuzzy systems.","2164-7151","978-1-4244-4735-0","10.1109/ISDA.2009.262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5363298","","","bioinformatics;competitive intelligence;computer aided instruction;cooperative systems;data mining;evolutionary computation;fuzzy neural nets;fuzzy set theory;image processing;intelligent control;Internet;knowledge management;ontologies (artificial intelligence)","intelligent systems design;evolutionary algorithms;soft computing;intelligent agents;Web technology;genetic fuzzy systems;intelligent image processing;artificial vision;hybrid learning;artificial neural networks;swarm intelligence;fuzzy numbers;business intelligence;business artificial intelligence;evolutionary multiobjective optimization design;computational intelligence;business management;risk analysis;hybrid metaheuristics;data reduction;intelligent signal analysis;image analysis;remote sensing;human monitoring;machine learning strategy;innovative networking;intelligent control;intelligent Internet modeling;decision making;smart services;ontology-based systems;intelligent e-learning systems;industrial processes;intelligent data mining;educational data mining;intelligent knowledge management;bioinformatics;neuro-fuzzy systems","","","","","","28 Dec 2009","","","IEEE","IEEE Conferences"
"Table of contents","",,"2014 Brazilian Conference on Intelligent Systems","15 Dec 2014","2014","","","v","xi","The following topics are dealt with: machine learning; data mining; natural language processing; social media analysis; recommender systems; neural networks; agents; planning; scheduling; regression; classification; knowledge representation; reasoning; information retrieval; pattern recognition; fuzzy systems; multiobjective optimization; concept drift; adaptive method; dynamic model and complex network.","","978-1-4799-5618-0","10.1109/BRACIS.2014.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984790","","","complex networks;data mining;fuzzy systems;inference mechanisms;information retrieval;knowledge representation;learning (artificial intelligence);multi-agent systems;natural language processing;neural nets;optimisation;pattern classification;planning;recommender systems;regression analysis;scheduling;social networking (online)","complex network;dynamic model;adaptive method;concept drift;multiobjective optimization;fuzzy systems;pattern recognition;information retrieval;reasoning;knowledge representation;classification;regression;scheduling;planning;agents;neural networks;recommender systems;social media analysis;natural language processing;data mining;machine learning","","","","","","15 Dec 2014","","","IEEE","IEEE Conferences"
"Seventh International Conference on Intelligent Systems Design and Applications - Title page","",,"Seventh International Conference on Intelligent Systems Design and Applications (ISDA 2007)","27 Nov 2007","2007","","","i","iii","The following topics are dealt with: intelligent business systems; intelligent agents; artificial neural networks; data clustering; bioinformatics; intelligent control; intelligent educational systems; fuzzy systems; genetic algorithms; genetic programming; intelligent image processing; intelligent Internet modeling; intelligent knowledge management; machine learning; intelligent data mining; natural language processing; neural systems; mobile robots; computer security; information security; intelligent signal processing; swarm intelligent systems; intelligent text categorization; intelligent text clustering; parallel evolutionary computation; biometrics; evolutionary multiobjective optimisations; nature imitation methods; dynamic intelligent systems.","2164-7151","978-0-7695-2976-9","10.1109/ISDA.2007.167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4389568","","","artificial intelligence;knowledge based systems;neural nets","intelligent business systems;intelligent agents;artificial neural networks;data clustering;bioinformatics;intelligent control;intelligent educational systems;fuzzy systems;genetic algorithms;genetic programming;intelligent image processing;intelligent Internet modeling;intelligent knowledge management;machine learning;intelligent data mining;natural language processing;neural systems;mobile robots;computer security;information security;intelligent signal processing;swarm intelligent systems;intelligent text categorization;intelligent text clustering;parallel evolutionary computation;biometrics;evolutionary multiobjective optimisations;nature imitation methods;dynamic intelligent systems","","","","","","27 Nov 2007","","","IEEE","IEEE Conferences"
"Keynote3: Contention and disruption","J. van den Herik","Vrije Univ. Amsterdam, Amsterdam, Netherlands","2016 Conference on Technologies and Applications of Artificial Intelligence (TAAI)","20 Mar 2017","2016","","","22","23","The development of science is clear. From 1950 to 1990 we lived in a world of Contention, with as main question: Will Contention between Paradigms lead to a Paradigm Shift? This development is nicely described by Popper (Logic of Scientific Discovery), Kuhn (The Structure of Scientific Revolutions), Lakatos (The Methodology of Scientific Research Programmes), and Feyerabend (Against Method). In the world of Games, this development is seen in the transition from Minimax to Monte Carlo Tree Search (MCTS). Apparently, the successor of Contention is called Disruption. Currently, we live in a world full of disruptions (1990-2030). In the lecture, I will show the current development by Daniel Dennett (Consciousness Explained, 1990), Richard Susskind (The Future of Law, 1998), Nick Bostron (Superintelligence, 2014), and my own thoughts on Intuition is Programmable (Van den Herik, 2016). The latter is extremely well identified by the power of Deep Learning in the Game of Go (congratulations to Aja Huang). Around 2030 we may expect to see a quantum computer in operation. It will not only produce prime numbers, but also give us the solution of the game of chess (draw or a win for White), and thereafter even for Go (i.e., at a later date). Next to game results, we will observe a continuous development: from decisions made by humans to decisions made by computers. Here, moral constraints are important. Examples will be given.","2376-6824","978-1-5090-5732-0","10.1109/TAAI.2016.7880106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7880106","","","artificial intelligence","contention;disruption;Popper;scientific discovery logic;Kuhn;scientific revolution structure;Lakatos;scientific research programme methodology;Feyerabend;minimax;Monte Carlo tree search;MCTS;Daniel Dennett;Richard Susskind;Nick Bostron;continuous development;human decisions;computer decisions;artificial intelligence","","","","","","20 Mar 2017","","","IEEE","IEEE Conferences"
