@article{10.1016/j.neunet.2019.12.014,
author = {Hayakawa, Satoshi and Suzuki, Taiji},
title = {On the Minimax Optimality and Superiority of Deep Neural Network Learning over Sparse Parameter Spaces},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {123},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2019.12.014},
doi = {10.1016/j.neunet.2019.12.014},
journal = {Neural Netw.},
month = {mar},
pages = {343–361},
numpages = {19},
keywords = {Linear estimator, Neural network, Minimax optimality, Nonparametric regression, Deep learning}
}

@inproceedings{10.1145/3109984.3110007,
author = {Santos, Carlos Eduardo and Coelho, Leandro dos S. and Sampaio, Renato Coral and Jacobi, Ricardo and Ayala, Helon and Llanos, Carlos H.},
title = {A SVM Optimization Tool and FPGA System Architecture Applied to NMPC},
year = {2017},
isbn = {9781450351065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109984.3110007},
doi = {10.1145/3109984.3110007},
abstract = {Support Vector Machines (SVMs) are supervised learning models of the machine learning field whose performance strongly depended on its hyperparameters. The Bio-inspired Optimization Tool for SVM (BIOTS) tool is based on a Multi-Objective Particle Swarm Algorithm (MOPSO) to tune hyperparameters of SVMs. In this work, BIOTS is proposed along with a custom hardware design generator (VHDL) that implements the SVM in a Field-Programmable Gate Array (FPGA). Both tools are combined to create an approximate Nonlinear Model Predictive Controller (NMPC) applied to a single-link robotic arm. The result is a generated SVM implemented in a FPGA yielding better results in terms of speed and simplicity compared to our previous work that addressed the same problem with a Radial Basis Functions Neural Networks (RBFNN).},
booktitle = {Proceedings of the 30th Symposium on Integrated Circuits and Systems Design: Chip on the Sands},
pages = {96–102},
numpages = {7},
keywords = {SVM/SVR training tool, NMPC, FPGA},
location = {Fortaleza, Cear\'{a}, Brazil},
series = {SBCCI '17}
}

@article{10.1109/MCI.2015.2471235,
author = {Ren, Ye and Zhang, Le and Suganthan, P.N.},
title = {Ensemble Classification and Regression-Recent Developments, Applications and Future Directions [Review Article]},
year = {2016},
issue_date = {Feb. 2016},
publisher = {IEEE Press},
volume = {11},
number = {1},
issn = {1556-603X},
url = {https://doi.org/10.1109/MCI.2015.2471235},
doi = {10.1109/MCI.2015.2471235},
abstract = {Ensemble methods use multiple models to get better performance. Ensemble methods have been used in multiple research fields such as computational intelligence, statistics and machine learning. This paper reviews traditional as well as state-of-the-art ensemble methods and thus can serve as an extensive summary for practitioners and beginners. The ensemble methods are categorized into conventional ensemble methods such as bagging, boosting and random forest, decomposition methods, negative correlation learning methods, multi-objective optimization based ensemble methods, fuzzy ensemble methods, multiple kernel learning ensemble methods and deep learning based ensemble methods. Variations, improvements and typical applications are discussed. Finally this paper gives some recommendations for future research directions. },
journal = {Comp. Intell. Mag.},
month = {feb},
pages = {41–53},
numpages = {13}
}

@article{10.1016/j.engappai.2015.10.003,
author = {Coca\~{n}a-Fern\'{a}ndez, Alberto and S\'{a}nchez, Luciano and Ranilla, Jos\'{e}},
title = {Leveraging a Predictive Model of the Workload for Intelligent Slot Allocation Schemes in Energy-Efficient HPC Clusters},
year = {2016},
issue_date = {February 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {48},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.10.003},
doi = {10.1016/j.engappai.2015.10.003},
abstract = {A proactive mechanism to learn an efficient strategy for adaptive resource clusters is proposed. In contrast to reactive techniques, that rescale the cluster to fit the past load, a predictive strategy is adopted. The cluster incoming workload is forecasted and an optimization problem is defined whose solution is the optimal action according to a utility function. Genetic-based machine learning techniques are used, including multi-objective evolutionary algorithms under the distal supervised learning setup. Experimental evaluations show that the proactive system presented in this work improves either the energetic efficiency or the number of reconfigurations of previous approaches without a loss in the quality of service. Depending on the predictability of the workload, in real world cluster scenarios additional energy savings of up to approximately 40% were measured over the best previous approach, with a 2 factor increment in the number of reconfigurations.},
journal = {Eng. Appl. Artif. Intell.},
month = {feb},
pages = {95–105},
numpages = {11},
keywords = {Distal learning, Multi-criteria decision making, Energy-efficient cluster computing, Evolutionary algorithms}
}

@article{10.1016/j.eswa.2016.06.005,
title = {A Multiobjective Weighted Voting Ensemble Classifier Based on Differential Evolution Algorithm for Text Sentiment Classification},
year = {2016},
issue_date = {November 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {62},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.06.005},
doi = {10.1016/j.eswa.2016.06.005},
abstract = {A novel multi-objective differential evolution algorithm based classifier ensemble for text sentiment classification. An empirical comparison of weighted and unweighted voting schemes. Extensive empirical analysis on metaheuristic based voting schemes for sentiment analysis. High classification accuracies for text sentiment classification (98.86% for Laptop dataset). Typically performed by supervised machine learning algorithms, sentiment analysis is highly useful for extracting subjective information from text documents online. Most approaches that use ensemble learning paradigms toward sentiment analysis involve feature engineering in order to enhance the predictive performance. In response, we sought to develop a paradigm of a multiobjective, optimization-based weighted voting scheme to assign appropriate weight values to classifiers and each output class based on the predictive performance of classification algorithms, all to enhance the predictive performance of sentiment classification. The proposed ensemble method is based on static classifier selection involving majority voting error and forward search, as well as a multiobjective differential evolution algorithm. Based on the static classifier selection scheme, our proposed ensemble method incorporates Bayesian logistic regression, na\"{\i}ve Bayes, linear discriminant analysis, logistic regression, and support vector machines as base learners, whose performance in terms of precision and recall values determines weight adjustment. Our experimental analysis of classification tasks, including sentiment analysis, software defect prediction, credit risk modeling, spam filtering, and semantic mapping, suggests that the proposed classification scheme can predict better than conventional ensemble learning methods such as AdaBoost, bagging, random subspace, and majority voting. Of all datasets examined, the laptop dataset showed the best classification accuracy (98.86%).},
journal = {Expert Syst. Appl.},
month = {nov},
pages = {1–16},
numpages = {16}
}

@article{10.1007/s00521-019-04331-5,
author = {Barushka, Aliaksandr and Hajek, Petr},
title = {Spam Detection on Social Networks Using Cost-Sensitive Feature Selection and Ensemble-Based Regularized Deep Neural Networks},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {9},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04331-5},
doi = {10.1007/s00521-019-04331-5},
abstract = {Spam detection on social networks is increasingly important owing to the rapid growth of social network user base. Sophisticated spam filters must be developed to deal with this complex problem. Traditional machine learning approaches such as neural networks, support vector machines and Na\"{\i}ve Bayes classifiers are not effective enough to process and utilize complex features present in high-dimensional data on social network spam. Moreover, the traditional objective criteria of social network spam filters cannot cope with different costs assigned to type I and type II errors. To overcome these problems, here we propose a novel cost-sensitive approach to social network spam filtering. The proposed approach is composed of two stages. In the first stage, multi-objective evolutionary feature selection is used to minimize both the misclassification cost of the proposed model and the number of attributes necessary for spam filtering. Then, the approach uses cost-sensitive ensemble learning techniques with regularized deep neural networks as base learners. We demonstrate that this approach is effective for social network spam filtering on two benchmark datasets. We also show that the proposed approach outperforms other popular algorithms used in social network spam filtering, such as random forest, Na\"{\i}ve Bayes or support vector machines.},
journal = {Neural Comput. Appl.},
month = {may},
pages = {4239–4257},
numpages = {19},
keywords = {Neural network, Regularization, Ensemble learning, Social networks, Misclassification cost}
}

@inproceedings{10.1145/3448891.3448936,
author = {Duddu, Vasisht and Rao, D Vijay and Balas, Valentina},
title = {Towards Enhancing Fault Tolerance in Neural Networks},
year = {2020},
isbn = {9781450388405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448891.3448936},
doi = {10.1145/3448891.3448936},
abstract = { Deep Learning Accelerators and Neuromorphic hardware, used in many real-time safety-critical applications, are prone to faults that manifest in the form of errors in Neural Networks. Fault Tolerance in Neural Networks is a critical attribute for applications that require reliable computation for long duration such as IoT and mobile devices. The inherent fault tolerance of Neural Networks can be improved with regularization, however, the current techniques exhibit a trade-off between generalization and classification accuracy. To this extent, in this work, a Neural Network is modelled as two distinct functional components: a Feature Extractor with an unsupervised learning objective and a Fully Connected Classifier with a supervised learning objective. Traditional approaches to train the entire network using a single supervised learning objective are insufficient to achieve the objectives of the individual functional goals optimally. In this work, a novel two phase framework with multi-criteria objective function combining unsupervised training of the Feature Extractor followed by supervised training of the Classifier Network is proposed. In the Phase I, the unsupervised training of the Feature Extractor is modeled using two games solved simultaneously in the presence of Neural Networks with conflicting objectives. The first game with a generative model, trains the Feature Extractor to generate robust features for the input image by minimizing a reconstruction loss between the input and reconstructed image. The second game with a binary classification network, updates the Feature Extractor to smoothen the feature space and match with a prior Gaussian distribution. In Phase II, the resultant Feature Extractor, which is strongly regularized, is combined with the Fully Connected Classifier for fine-tuning on the classification task. The proposed two phase training algorithm is evaluated on four architectures with varying model complexity on standard image classification datasets: FashionMNIST and CIFAR10. The proposed framework is scalable and independent of the network architecture that provides superior tolerance to stuck at “0” faults as compared to existing regularization functions without loss in classification accuracy.},
booktitle = {MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {59–68},
numpages = {10},
keywords = {Fault Tolerance, Regularization., Neural Networks, Adversarial Game, Classification},
location = {Darmstadt, Germany},
series = {MobiQuitous '20}
}

@inproceedings{10.1145/3229762.3229766,
author = {Moreau, Thierry and Chen, Tianqi and Ceze, Luis},
title = {Leveraging the VTA-TVM Hardware-Software Stack for FPGA Acceleration of 8-Bit ResNet-18 Inference},
year = {2018},
isbn = {9781450359238},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229762.3229766},
doi = {10.1145/3229762.3229766},
abstract = {We present a full-stack design to accelerate deep learning inference with FPGAs. Our contribution is two-fold. At the software layer, we leverage and extend TVM, the end-to-end deep learning optimizing compiler, in order to harness FPGA-based acceleration. At the the hardware layer, we present the Versatile Tensor Accelerator (VTA) which presents a generic, modular, and customizable architecture for TPU-like accelerators. Our results take a ResNet-18 description in MxNet and compiles it down to perform 8-bit inference on a 256-PE accelerator implemented on a low-cost Xilinx Zynq FPGA, clocked at 100MHz. Our full hardware acceleration stack will be made available for the community to reproduce, and build upon at http://github.com/uwsaml/vta.},
booktitle = {Proceedings of the 1st on Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning},
articleno = {5},
location = {Williamsburg, VA, USA},
series = {ReQuEST '18}
}

@inproceedings{10.1145/3324921.3329695,
author = {Shi, Yi and Davaslioglu, Kemal and Sagduyu, Yalin E.},
title = {Generative Adversarial Network for Wireless Signal Spoofing},
year = {2019},
isbn = {9781450367691},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324921.3329695},
doi = {10.1145/3324921.3329695},
abstract = {The paper presents a novel approach of spoofing wireless signals by using a general adversarial network (GAN) to generate and transmit synthetic signals that cannot be reliably distinguished from intended signals. It is of paramount importance to authenticate wireless signals at the PHY layer before they proceed through the receiver chain. For that purpose, various waveform, channel, and radio hardware features that are inherent to original wireless signals need to be captured. In the meantime, adversaries become sophisticated with the cognitive radio capability to record, analyze, and manipulate signals before spoofing. Building upon deep learning techniques, this paper introduces a spoofing attack by an adversary pair of a transmitter and a receiver that assume the generator and discriminator roles in the GAN and play a minimax game to generate the best spoofing signals that aim to fool the best trained defense mechanism. The output of this approach is two-fold. From the attacker point of view, a deep learning-based spoofing mechanism is trained to potentially fool a defense mechanism such as RF ingerprinting. From the defender point of view, a deep learning-based defense mechanism is trained against potential spooing attacks when an adversary pair of a transmitter and a receiver cooperates. The probability that the spooing signal is misclassified as the intended signal is measured for random signal, replay, and GAN-based spoofing attacks. Results show that the GAN-based spooing attack provides a major increase in the success probability of wireless signal spoofing even when a deep learning classifier is used as the defense.},
booktitle = {Proceedings of the ACM Workshop on Wireless Security and Machine Learning},
pages = {55–60},
numpages = {6},
keywords = {spoofing attack, general adversarial network (GAN), adversarial machine learning, deep learning},
location = {Miami, FL, USA},
series = {WiseML 2019}
}

@article{10.1016/j.eswa.2021.115722,
author = {Nilashi, Mehrbakhsh and Minaei-Bidgoli, Behrouz and Alrizq, Mesfer and Alghamdi, Abdullah and Alsulami, Abdulaziz A. and Samad, Sarminah and Mohd, Saidatulakmal},
title = {An Analytical Approach for Big Social Data Analysis for Customer Decision-Making in Eco-Friendly Hotels},
year = {2022},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {186},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115722},
doi = {10.1016/j.eswa.2021.115722},
journal = {Expert Syst. Appl.},
month = {dec},
numpages = {15},
keywords = {Big social data, Eco-friendly hotels, Sustainable tourism, Electronic word-of-mouth, Machine learning techniques}
}

@inproceedings{10.1145/3229762.3229763,
author = {Gong, Jiong and Shen, Haihao and Zhang, Guoming and Liu, Xiaoli and Li, Shane and Jin, Ge and Maheshwari, Niharika and Fomenko, Evarist and Segal, Eden},
title = {Highly Efficient 8-Bit Low Precision Inference of Convolutional Neural Networks with IntelCaffe},
year = {2018},
isbn = {9781450359238},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229762.3229763},
doi = {10.1145/3229762.3229763},
abstract = {High throughput and low latency inference of deep neural networks are critical for the deployment of deep learning applications. This paper presents the efficient inference techniques of IntelCaffe, the first Intel(R) optimized deep learning framework that supports efficient 8-bit low precision inference and model optimization techniques of convolutional neural networks on Intel(R) Xeon(R) Scalable Processors. The 8-bit optimized model is automatically generated with a calibration process from FP32 model without the need of fine-tuning or retraining. We show that the inference throughput and latency with ResNet-50, Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively with neglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and 26X-37X from BVLC Caffe. All these techniques have been open-sourced on IntelCaffe GitHub (https://github.com/intel/caffe), and the artifact is provided to reproduce the result on Amazon AWS Cloud.},
booktitle = {Proceedings of the 1st on Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning},
articleno = {2},
keywords = {Model Optimization, Deep Learning, Convolutional Neural Network, Intel Caffe},
location = {Williamsburg, VA, USA},
series = {ReQuEST '18}
}

@inbook{10.1145/3449726.3463221,
author = {Thite, Anish and Dodda, Mohan and Liu, Alex and Agarwal, Pulak and Zutty, Jason},
title = {Concurrent Neural Tree and Data Preprocessing AutoML for Image Classification},
year = {2021},
isbn = {9781450383516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449726.3463221},
abstract = {Deep Neural Networks (DNN's) are a widely-used solution for a variety of machine learning problems. However, it is often necessary to invest a significant amount of a data scientist's time to pre-process input data, test different neural network architectures, and tune hyper-parameters for optimal performance. Automated machine learning (autoML) methods automatically search the architecture and hyper-parameter space for optimal neural networks. However, current state-of-the-art (SOTA) methods do not include traditional methods for manipulating input data as part of the algorithmic search space. We adapt the Evolutionary Multi-objective Algorithm Design Engine (EMADE), a multi-objective evolutionary search framework for traditional machine learning methods, to perform neural architecture search. We also integrate EMADE's signal processing and image processing primitives. These primitives allow EMADE to manipulate input data before ingestion into the simultaneously evolved DNN. We show that including these methods as part of the search space shows potential to provide benefits to performance on the CIFAR-10 image classification benchmark dataset.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1990–1993},
numpages = {4}
}

@article{10.1016/j.knosys.2016.07.018,
author = {Abbasi, Elham and Shiri, Mohammad Ebrahim and Ghatee, Mehdi},
title = {A Regularized Root-Quartic Mixture of Experts for Complex Classification Problems},
year = {2016},
issue_date = {October 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {110},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2016.07.018},
doi = {10.1016/j.knosys.2016.07.018},
abstract = {Mixture of experts is a neural network based ensemble learning approach consisting of several experts and a gating network. In this paper, we introduce regularized root-quartic mixture of experts (R-RTQRT-ME) by incorporating a regularization term into the error function to control the complexity of model and to increase robustness in confronting with over-fitting and noise. The average of the results of R-RTQRT-ME on 20 classification benchmark datasets, shows that this algorithm performs 1.75%, 2.50%, 2.29% better than multi objective regularized negative correlation learning, multi objective negative correlation learning and multi objective neural network, respectively. Also, the average of improvements of R-RTQRT-ME is 1.16%, 2.31%, 3.40%, 3.39% in comparison with root-quartic mixture of experts, mixture of negatively correlated experts, mixture of experts and negative correlation learning, respectively. Furthermore, the effect of the regularization penalty term in R-RTQRT-ME on noisy data is analyzed which shows the robustness of R-RTQRT-ME in these situations.},
journal = {Know.-Based Syst.},
month = {oct},
pages = {98–109},
numpages = {12},
keywords = {Negative correlation learning, Mixture of experts, Generalization ability, Ensemble learning, Diversity, Regularization}
}

@article{10.1016/j.comnet.2017.08.013,
author = {Viegas, Eduardo K. and Santin, Altair O. and Oliveira, Luiz S.},
title = {Toward a Reliable Anomaly-Based Intrusion Detection in Real-World Environments},
year = {2017},
issue_date = {November 2017},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {127},
number = {C},
issn = {1389-1286},
url = {https://doi.org/10.1016/j.comnet.2017.08.013},
doi = {10.1016/j.comnet.2017.08.013},
abstract = {A popular approach for detecting network intrusion attempts is to monitor the network traffic for anomalies. Extensive research effort has been invested in anomaly-based network intrusion detection using machine learning techniques; however, in general these techniques remain a research topic, rarely being used in real-world environments. In general, the approaches proposed in the literature lack representative datasets and reliable evaluation methods that consider real-world network properties during the system evaluation. In general, the approaches adopt a set of assumptions about the training data, as well as about the validation methods, rendering the created system unreliable for open-world usage. This paper presents a new method for creating intrusion databases. The objective is that the databases should be easy to update and reproduce with real and valid traffic, representative, and publicly available. Using our proposed method, we propose a new evaluation scheme specific to the machine learning intrusion detection field. Sixteen intrusion databases were created, and each of the assumptions frequently adopted in studies in the intrusion detection literature regarding network traffic behavior was validated. To make machine learning detection schemes feasible, we propose a new multi-objective feature selection method that considers real-world network properties. The results show that most of the assumptions frequently applied in studies in the literature do not hold when using a machine learning detection scheme for network-based intrusion detection. However, the proposed multi-objective feature selection method allows the system accuracy to be improved by considering real-world network properties during the model creation process.},
journal = {Comput. Netw.},
month = {nov},
pages = {200–216},
numpages = {17},
keywords = {Multi-objective feature selection, Machine learning-based intrusion detection, Intrusion databases, Anomaly-based classifier}
}

@article{10.14778/3461535.3463474,
author = {Salazar, Ricardo and Neutatz, Felix and Abedjan, Ziawasch},
title = {Automated Feature Engineering for Algorithmic Fairness},
year = {2021},
issue_date = {May 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/3461535.3463474},
doi = {10.14778/3461535.3463474},
abstract = {One of the fundamental problems of machine ethics is to avoid the perpetuation and amplification of discrimination through machine learning applications. In particular, it is desired to exclude the influence of attributes with sensitive information, such as gender or race, and other causally related attributes on the machine learning task. The state-of-the-art bias reduction algorithm Capuchin breaks the causality chain of such attributes by adding and removing tuples. However, this horizontal approach can be considered invasive because it changes the data distribution. A vertical approach would be to prune sensitive features entirely. While this would ensure fairness without tampering with the data, it could also hurt the machine learning accuracy. Therefore, we propose a novel multi-objective feature selection strategy that leverages feature construction to generate more features that lead to both high accuracy and fairness. On three well-known datasets, our system achieves higher accuracy than other fairness-aware approaches while maintaining similar or higher fairness.},
journal = {Proc. VLDB Endow.},
month = {may},
pages = {1694–1702},
numpages = {9}
}

@article{10.1109/TVLSI.2009.2017196,
author = {Stratigopoulos, Haralampos-G. and Drineas, Petros and Slamani, Mustapha and Makris, Yiorgos},
title = {RF Specification Test Compaction Using Learning Machines},
year = {2010},
issue_date = {June 2010},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {18},
number = {6},
issn = {1063-8210},
url = {https://doi.org/10.1109/TVLSI.2009.2017196},
doi = {10.1109/TVLSI.2009.2017196},
abstract = {We present a machine learning approach to the problem of RF specification test compaction. The proposed compaction flow relies on a multi-objective genetic algorithm, which searches in the power-set of specification tests to select appropriate subsets, and a classifier, which makes pass/fail decisions based solely on these subsets. The method is demonstrated on production test data from an RF device fabricated by IBM. The results indicate that machine learning can identify intricate correlations between specification tests, which allows us to infer the outcome of all tests from a subset of tests. Thereby, the number of tests that need to be explicitly carried out and the corresponding cost are reduced significantly without adversely impacting test accuracy.},
journal = {IEEE Trans. Very Large Scale Integr. Syst.},
month = {jun},
pages = {998–1002},
numpages = {5},
keywords = {RFICs, Artificial intelligence, circuit testing, artificial intelligence}
}

@inproceedings{10.1145/3380446.3430636,
author = {Kwon, Jihye and Carloni, Luca P.},
title = {Transfer Learning for Design-Space Exploration with High-Level Synthesis},
year = {2020},
isbn = {9781450375191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380446.3430636},
doi = {10.1145/3380446.3430636},
abstract = {High-level synthesis (HLS) raises the level of design abstraction, expedites the process of hardware design, and enriches the set of final designs by automatically translating a behavioral specification into a hardware implementation. To obtain different implementations, HLS users can apply a variety of knobs, such as loop unrolling or function inlining, to particular code regions of the specification. The applied knob configuration significantly affects the synthesized design's performance and cost, e.g., application latency and area utilization. Hence, HLS users face the design-space exploration (DSE) problem, i.e. determine which knob configurations result in Pareto-optimal implementations in this multi-objective space. Whereas it can be costly in time and resources to run HLS flows with an enormous number of knob configurations, machine learning approaches can be employed to predict the performance and cost. Still, they require a sufficient number of sample HLS runs. To enhance the training performance and reduce the sample complexity, we propose a transfer learning approach that reuses the knowledge obtained from previously explored design spaces in exploring a new target design space. We develop a novel neural network model for mixed-sharing multi-domain transfer learning. Experimental results demonstrate that the proposed model outperforms both single-domain and hard-sharing models in predicting the performance and cost at early stages of HLS-driven DSE.},
booktitle = {Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD},
pages = {163–168},
numpages = {6},
keywords = {neural networks, high-level synthesis, transfer learning, machine learning, multi-task learning, design space exploration},
location = {Virtual Event, Iceland},
series = {MLCAD '20}
}

@inproceedings{10.1145/3093172.3093232,
author = {Verma, Siddhartha and Hadjidoukas, Panagiotis and Wirth, Philipp and Rossinelli, Diego and Koumoutsakos, Petros},
title = {Pareto Optimal Swimmers},
year = {2017},
isbn = {9781450350624},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093172.3093232},
doi = {10.1145/3093172.3093232},
abstract = {A fundamental understanding of how various biological traits and features provide organisms with a competitive advantage can help us improve the design of a number of mechanical systems. Numerical optimization can play an invaluable role for this purpose, by allowing us to scrutinize the evolution of specific biological adaptations in nature. Importantly, the use of numerical optimization can help us overcome limiting constraints that restrict the evolutionary capability of biological species. We capitalize on these advantages by coupling high-fidelity simulations of self-propelled swimmers with evolutionary optimization algorithms, to examine peculiar swimming patterns observed in a number of fish species. More specifically, we investigate the intermittent form of locomotion referred to as 'burst-and-coast' swimming, which involves a few quick flicks of the fish's tail followed by a prolonged unpowered glide. This mode of swimming is believed to confer energetic benefits, in addition to several other advantages. We discover a range of intermittent-swimming patterns, the most efficient of which resembles the swimming behaviour observed in live fish. We also discover patterns which lead to a marked increase in swimming-speed, albeit with a significant increase in energy expenditure. Notably, the use of multi-objective optimization reveals locomotion patterns that strike the perfect balance between speed and efficiency, which can be invaluable for use in robotic applications. As an additional goal of the paper, we highlight the ease with which disparate codes can be coupled via the software framework used, without encumbering the user with the details of efficient parallelization and machine-learning based task-scheduling.},
booktitle = {Proceedings of the Platform for Advanced Scientific Computing Conference},
articleno = {7},
numpages = {11},
keywords = {Burst-and-coast Swimming, Energy-efficient Locomotion, Multi-objective Optimization, Task-based Parallelism},
location = {Lugano, Switzerland},
series = {PASC '17}
}

@article{10.1109/TC.2018.2889053,
author = {Joardar, Biresh Kumar and Kim, Ryan Gary and Doppa, Janardhan Rao and Pande, Partha Pratim and Marculescu, Diana and Marculescu, Radu},
title = {Learning-Based Application-Agnostic 3D NoC Design for Heterogeneous Manycore Systems},
year = {2019},
issue_date = {June 2019},
publisher = {IEEE Computer Society},
address = {USA},
volume = {68},
number = {6},
issn = {0018-9340},
url = {https://doi.org/10.1109/TC.2018.2889053},
doi = {10.1109/TC.2018.2889053},
abstract = {The rising use of deep learning and other big-data algorithms has led to an increasing demand for hardware platforms that are computationally powerful, yet energy-efficient. Due to the amount of data parallelism in these algorithms, high-performance three-dimensional (3D) manycore platforms that incorporate both CPUs and GPUs present a promising direction. However, as systems use heterogeneity (e.g., a combination of CPUs, GPUs, and accelerators) to improve performance and efficiency, it becomes more pertinent to address the distinct and likely conflicting communication requirements (e.g., CPU memory access latency or GPU network throughput) that arise from such heterogeneity. Unfortunately, it is difficult to quickly explore the hardware design space and choose appropriate tradeoffs between these heterogeneous requirements. To address these challenges, we propose the design of a 3D Network-on-Chip (NoC) for heterogeneous manycore platforms that considers the appropriate design objectives for a 3D heterogeneous system and explores various tradeoffs using an efficient machine learning (ML)-based multi-objective optimization (MOO) technique. The proposed design space exploration considers the various requirements of its heterogeneous components and generates a set of 3D NoC architectures that efficiently trades off these design objectives. Our findings show that by jointly considering these requirements (latency, throughput, temperature, and energy), we can achieve 9.6 percent better Energy-Delay Product on average at nearly iso-temperature conditions when compared to a thermally-optimized design for 3D heterogeneous NoCs. More importantly, our results suggest that our 3D NoCs optimized for a few applications can be generalized for unknown applications as well. Our results show that these generalized 3D NoCs only incur a 1.8 percent (36-tile system) and 1.1 percent (64-tile system) average performance loss compared to application-specific NoCs.},
journal = {IEEE Trans. Comput.},
month = {jun},
pages = {852–866},
numpages = {15}
}

@article{10.1016/j.patcog.2021.108242,
author = {Guarrasi, Valerio and D’Amico, Natascha Claudia and Sicilia, Rosa and Cordelli, Ermanno and Soda, Paolo},
title = {Pareto Optimization of Deep Networks for COVID-19 Diagnosis from Chest X-Rays},
year = {2022},
issue_date = {Jan 2022},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2021.108242},
doi = {10.1016/j.patcog.2021.108242},
journal = {Pattern Recogn.},
month = {jan},
numpages = {13},
keywords = {Multi-expert systems, X-ray, Optimization, COVID-19, Convolutional neural networks, Deep-learning}
}

@inproceedings{10.1145/1389095.1389229,
author = {Dos Santos, Eulanda M. and Sabourin, Robert and Maupin, Patrick},
title = {Pareto Analysis for the Selection of Classifier Ensembles},
year = {2008},
isbn = {9781605581309},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1389095.1389229},
doi = {10.1145/1389095.1389229},
abstract = {The overproduce-and-choose strategy involves the generation of an initial large pool of candidate classifiers and it is intended to test different candidate ensembles in order to select the best performing solution. The ensemble's error rate, ensemble size and diversity measures are the most frequent search criteria employed to guide this selection. By applying the error rate, we may accomplish the main objective in Pattern Recognition and Machine Learning, which is to find high-performance predictors. In terms of ensemble size, the hope is to increase the recognition rate while minimizing the number of classifiers in order to meet both the performance and low ensemble size requirements. Finally, ensembles can be more accurate than individual classifiers only when classifier members present diversity among themselves. In this paper we apply two Pareto front spread quality measures to analyze the relationship between the three main search criteria used in the overproduce-and-choose strategy. Experimental results conducted demonstrate that the combination of ensemble size and diversity does not produce conflicting multi-objective optimization problems. Moreover, we cannot decrease the generalization error rate by combining this pair of search criteria. However, when the error rate is combined with diversity or the ensemble size, we found that these measures are conflicting objective functions and that the performances of the solutions are much higher.},
booktitle = {Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation},
pages = {681–688},
numpages = {8},
keywords = {classifier ensembles, ensemble selection, Pareto analysis, diversity measures},
location = {Atlanta, GA, USA},
series = {GECCO '08}
}

@inproceedings{10.1145/3299815.3314427,
author = {Govindaiah, Swetha and Petty, Mikel D.},
title = {Applying Reinforcement Learning to Plan Manufacturing Material Handling Part 2: Experimentation and Results},
year = {2019},
isbn = {9781450362511},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3299815.3314427},
doi = {10.1145/3299815.3314427},
abstract = {Applying machine learning to improve the efficiency of complex manufacturing processes, particularly logistics and material handling, can be a challenging problem. The interconnectedness of the multiple components that compose such processes and the typically large number of variables required to specify procedures and plans within those processes combine to make it very difficult to map the details of real-world manufacturing processes to an abstract mathematical representation suitable for machine learning methods. In this paper, we report on the application of machine learning methods, in particular reinforcement learning, to generate increasingly efficient plans for material handling to satisfy temporally varying product demands in a representative manufacturing facility. The essential steps in the research included defining a formal representation of a realistically complex material handling plan, defining a set of suitable two-stage plan change operators as reinforcement learning actions, implementing a simulation-based multi-objective reward function that considers multiple components of material handling costs, and abstracting the many possible material handling plans into a state set small enough to enable reinforcement learning. Extensive experimentation with multiple starting plans showed that the reinforcement learning process could consistently reduce the material handling plans' costs over time. This work may be one of the first applications of reinforcement learning with a multi-objective reward function to a realistically complex material handling process. This paper first provides an explanation of how the material handling plans and rewards were abstracted into a manageable state set. It then details the various initial plans and experimental trials used to test the plans. Finally, it reports the results of those experimental trials, including the plan change policies learned and the reductions in material handling costs achieved.},
booktitle = {Proceedings of the 2019 ACM Southeast Conference},
pages = {16–23},
numpages = {8},
keywords = {reinforcement learning, multi-objective learning, planning, machine learning, Material handling},
location = {Kennesaw, GA, USA},
series = {ACM SE '19}
}

@article{10.1109/TSMCB.2006.870610,
author = {Huang, Kaizhu and Yang, Haiqin and King, Irwin and Lyu, M. R.},
title = {Imbalanced Learning with a Biased Minimax Probability Machine},
year = {2006},
issue_date = {August 2006},
publisher = {IEEE Press},
volume = {36},
number = {4},
issn = {1083-4419},
url = {https://doi.org/10.1109/TSMCB.2006.870610},
doi = {10.1109/TSMCB.2006.870610},
abstract = {Imbalanced learning is a challenged task in machine learning. In this context, the data associated with one class are far fewer than those associated with the other class. Traditional machine learning methods seeking classification accuracy over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into a majority class, usually the less important class. In this correspondence, the authors describe a new approach named the biased minimax probability machine (BMPM) to deal with the problem of imbalanced learning. This BMPM model is demonstrated to provide an elegant and systematic way for imbalanced learning. More specifically, by controlling the accuracy of the majority class under all possible choices of class-conditional densities with a given mean and covariance matrix, this model can quantitatively and systematically incorporate a bias for the minority class. By establishing an explicit connection between the classification accuracy and the bias, this approach distinguishes itself from the many current imbalanced-learning methods; these methods often impose a certain bias on the minority data by adapting intermediate factors via the trial-and-error procedure. The authors detail the theoretical foundation, prove its solvability, propose an efficient optimization algorithm, and perform a series of experiments to evaluate the novel model. The comparison with other competitive methods demonstrates the effectiveness of this new model},
journal = {Trans. Sys. Man Cyber. Part B},
month = {aug},
pages = {913–923},
numpages = {11},
keywords = {imbalanced learning, Fractional programming (FP), receiver operating characteristic (ROC) analysis, worst case accuracy}
}

@article{10.1109/TNN.2007.905855,
author = {Huang, Kaizhu and Yang, Haiqin and King, I. and Lyu, M. R.},
title = {Maxi–Min Margin Machine: Learning Large Margin Classifiers Locally and Globally},
year = {2008},
issue_date = {February 2008},
publisher = {IEEE Press},
volume = {19},
number = {2},
issn = {1045-9227},
url = {https://doi.org/10.1109/TNN.2007.905855},
doi = {10.1109/TNN.2007.905855},
abstract = {In this paper, we propose a novel large margin classifier, called the maxi-min margin machine (M4). This model learns the decision boundary both locally and globally. In comparison, other large margin classifiers construct separating hyperplanes only either locally or globally. For example, a state-of-the-art large margin classifier, the support vector machine (SVM), considers data only locally, while another significant model, the minimax probability machine (MPM), focuses on building the decision hyperplane exclusively based on the global information. As a major contribution, we show that SVM yields the same solution as M4 when data satisfy certain conditions, and MPM can be regarded as a relaxation model of M4. Moreover, based on our proposed local and global view of data, another popular model, the linear discriminant analysis, can easily be interpreted and extended as well. We describe the M4 model definition, provide a geometrical interpretation, present theoretical justifications, and propose a practical sequential conic programming method to solve the optimization problem. We also show how to exploit Mercer kernels to extend M4 for nonlinear classifications. Furthermore, we perform a series of evaluations on both synthetic data sets and real-world benchmark data sets. Comparison with SVM and MPM demonstrates the advantages of our new model.},
journal = {Trans. Neur. Netw.},
month = {feb},
pages = {260–272},
numpages = {13},
keywords = {second-order cone programming, Classification, large margin, learning locally and globally, kernel methods}
}

@inbook{10.1145/3449726.3463146,
author = {Lomurno, Eugenio and Samele, Stefano and Matteucci, Matteo and Ardagna, Danilo},
title = {Pareto-Optimal Progressive Neural Architecture Search},
year = {2021},
isbn = {9781450383516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449726.3463146},
abstract = {Neural Architecture Search (NAS) is the process of automating architecture engineering, searching for the best deep learning configuration. One of the main NAS approaches proposed in the literature, Progressive Neural Architecture Search (PNAS), seeks for the architectures with a sequential model-based optimization strategy: it defines a common recursive structure to generate the networks, whose number of building blocks rises through iterations. However, NAS algorithms are generally designed for an ideal setting without considering the needs and the technical constraints imposed by practical applications. In this paper, we propose a new architecture search named Pareto-Optimal Progressive Neural Architecture Search (POPNAS) that combines the benefits of PNAS to a time-accuracy Pareto optimization problem. POPNAS adds a new time predictor to the existing approach to carry out a joint prediction of time and accuracy for each candidate neural network, searching through the Pareto front. This allows us to reach a trade-off between accuracy and training time, identifying neural network architectures with competitive accuracy in the face of a drastically reduced training time.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1726–1734},
numpages = {9}
}

@inproceedings{10.1145/3368926.3369720,
author = {Nguyen, Xuan Hung and Bui, Lam Thu and Tran, Cao Truong},
title = {Clustering Method Using Pareto Corner Search Evolutionary Algorithm for Objective Reduction in Many-Objective Optimization Problems},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369720},
doi = {10.1145/3368926.3369720},
abstract = {Many-objective optimization problems (MaOPs) have been gained considerable attention for researcher, recently. MaOPs make a number of difficulties for multi-objective optimization evolutionary algorithms (MOEAs) when solving them. Although, there exist a number of many-objective optimization evolutionary algorithms (MaOEAs) for solving MaOPs, they still face difficulties when the number of objectives of MaOPs increases. One common method to reduce or alleviate these difficulties is to use objective dimensionality reduction (or objective reduction for briefly). Moreover, instead of searching the whole of objective space like existing MOEAs or MaOEAs, Pareto Corner Search Evolutionary (PCSEA) concentrates only on some places of objective space, so it decreases time consuming and then speeds up objective reduction. However, PCSEA-based objective reduction needs to specify a threshold to select or remove objectives, which is not straightforward to do. Based on the idea that more conflict two objectives are, more distant two objectives are; in this paper, we introduce a new objective reduction by integrating PCSEA and k-means, DBSCAN clustering algorithms for solving MaOPs which are assumed containing redundant objectives. The experimental results show that the introduced method can reducing redundant objectives better than PCSEA-based objective reduction. The results further strengthen the links between evolutionary computation and machine learning to address optimization problems.},
booktitle = {Proceedings of the Tenth International Symposium on Information and Communication Technology},
pages = {78–84},
numpages = {7},
keywords = {clustering, objective reduction, many-objective optimization},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT 2019}
}

@inproceedings{10.1145/3503162.3503173,
author = {Joshi, Raviraj and Kannan, Venkateshan},
title = {Attention Based End to End Speech Recognition for Voice Search in Hindi and English},
year = {2021},
isbn = {9781450395960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503162.3503173},
doi = {10.1145/3503162.3503173},
abstract = { We describe here our work with automatic speech recognition (ASR) in the context of voice search functionality on the Flipkart e-Commerce platform. Starting with the deep learning architecture of Listen-Attend-Spell (LAS), we build upon and expand the model design and attention mechanisms to incorporate innovative approaches including multi-objective training, multi-pass training, and external rescoring using language models and phoneme based losses. We report a relative WER improvement of 15.7% on top of state-of-the-art LAS models using these modifications. Overall, we report an improvement of 36.9% over the phoneme-CTC system on the Flipkart Voice Search dataset. The paper also provides an overview of different components that can be tuned in a LAS based system.},
booktitle = {Forum for Information Retrieval Evaluation},
pages = {107–113},
numpages = {7},
keywords = {encoder-decoder models, listen attend spell, automatic speech recognition, attention},
location = {Virtual Event, India},
series = {FIRE 2021}
}

@inproceedings{10.5555/1460232.1460245,
author = {Thiemjarus, Surapa and Yang, Guang-Zhong},
title = {An Autonomic Sensing Framework for Body Sensor Networks},
year = {2007},
isbn = {9789630621939},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
abstract = {This paper presents an autonomic sensing framework for distributed inferencing, which consists of several self-contained machine learning techniques. A multi-objective Bayesian framework for feature selection is used for learning the relationship of the variables. To cater for fault tolerance and minimal resource utilisation, feature redundancy and network complexity measures have been introduced. We demonstrate how factor graphs and the sum-product algorithm can be used for model representation and inferencing. We will also show how they can be used to facilitate the mapping of model architecture onto the physical sensor networks.},
booktitle = {Proceedings of the ICST 2nd International Conference on Body Area Networks},
articleno = {13},
numpages = {8},
keywords = {pervasive monitoring, factor graphs, activity recognition, multi-objective feature selection, context sensing},
location = {Florence, Italy},
series = {BodyNets '07}
}

@inproceedings{10.5555/3398761.3399122,
author = {K\"{a}llstr\"{o}m, Johan},
title = {Adaptive Agent-Based Simulation for Individualized Training},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Agent-based simulation can be used for efficient and effective training of human operators and decision-makers. However, constructing realistic behavior models for the agents is challenging and time-consuming, especially for subject matter experts, who may not have expertise in artificial intelligence. In this work, we investigate how machine learning can be used to adapt simulation contents to the current needs of individual trainees. Our initial results demonstrate that multi-objective multi-agent reinforcement learning is a promising approach for creating agents with diverse and adaptive characteristics, which can stimulate humans in training.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2193–2195},
numpages = {3},
keywords = {agents for improving human cooperative activities, agents competing and collaborating with humans, modelling for agent based simulation, multi-agent learning, reinforcement learning},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{10.1145/2588555.2588559,
author = {Liu, Siyuan and Wang, Shuhui and Zhu, Feida and Zhang, Jinbo and Krishnan, Ramayya},
title = {HYDRA: Large-Scale Social Identity Linkage via Heterogeneous Behavior Modeling},
year = {2014},
isbn = {9781450323765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2588555.2588559},
doi = {10.1145/2588555.2588559},
abstract = {We study the problem of large-scale social identity linkage across different social media platforms, which is of critical importance to business intelligence by gaining from social data a deeper understanding and more accurate profiling of users. This paper proposes HYDRA, a solution framework which consists of three key steps: (I) modeling heterogeneous behavior by long-term behavior distribution analysis and multi-resolution temporal information matching; (II) constructing structural consistency graph to measure the high-order structure consistency on users' core social structures across different platforms; and (III) learning the mapping function by multi-objective optimization composed of both the supervised learning on pair-wise ID linkage information and the cross-platform structure consistency maximization. Extensive experiments on 10 million users across seven popular social network platforms demonstrate that HYDRA correctly identifies real user linkage across different platforms, and outperforms existing state-of-the-art algorithms by at least 20% under different settings, and 4 times better in most settings.},
booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
pages = {51–62},
numpages = {12},
keywords = {user linkage, heterogeneous behavior model, social networks, multiple information},
location = {Snowbird, Utah, USA},
series = {SIGMOD '14}
}

@inproceedings{10.1145/3377930.3390202,
author = {Berveglieri, Nicolas and Derbel, Bilel and Liefooghe, Arnaud and Aguirre, Hern\'{a}n and Zhang, Qingfu and Tanaka, Kiyoshi},
title = {Designing Parallelism in Surrogate-Assisted Multiobjective Optimization Based on Decomposition},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377930.3390202},
doi = {10.1145/3377930.3390202},
abstract = {On the one hand, surrogate-assisted evolutionary algorithms are established as a method of choice for expensive black-box optimization problems. On the other hand, the growth in computing facilities has seen a massive increase in potential computational power, granted the users accommodate their approaches with the offered parallelism. While a number of studies acknowledge the impact of parallelism for single-objective expensive optimization assisted by surrogates, extending such techniques to the multi-objective setting has not yet been properly investigated, especially within the state-of-the-art decomposition framework. We first highlight the different degrees of parallelism in existing surrogate-assisted multi-objective evolutionary algorithms based on decomposition (S-MOEA/D). We then provide a comprehensive analysis of the key steps towards a successful parallel S-MOEA/D approach. Through an extensive benchmarking effort relying on the well-established bbob-biobj test functions, we analyze the performance of the different algorithm designs with respect to the problem dimensionality and difficulty, the amount of parallel cores available, and the supervised learning models considered. In particular, we show the difference in algorithm scalability based on the selected surrogate-assisted approaches, the performance impact of distributing the model training task and the efficacy of the designed parallel-surrogate methods.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {462–470},
numpages = {9},
keywords = {parallelism benchmarking, multiobjective optimization, surrogates},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inproceedings{10.1145/3071178.3071234,
author = {Zutty, Jason and Rohling, Gregory},
title = {Solving Test Case Based Problems with Fuzzy Dominance},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071234},
doi = {10.1145/3071178.3071234},
abstract = {Genetic algorithms and genetic programming lend themselves well to the field of machine learning, which involves solving test case based problems. However, most traditional multi-objective selection methods work with scalar objectives, such as minimizing false negative and false positive rates, that are computed from underlying test cases.In this paper, we propose a new fuzzy selection operator that takes into account the statistical nature of machine learning problems based on test cases. Rather than use a Pareto rank or strength computed from scalar objectives, such as with NSGA2 or SPEA2, we will compute a probability of Pareto optimality. This will be accomplished through covariance estimation and Markov chain Monte Carlo simulation in order to generate probabilistic objective scores for each individual. We then compute a probability that each individual will generate a Pareto optimal solution. This probability is directly used with a roulette wheel selection technique.Our method's performance is evaluated on the evolution of a feature selection vector for a binary classification on each of eight different activities. Fuzzy selection performance varies, outperforming both NSGA2 and SPEA2 in both speed (measured in generations) and solution quality (measured by area under the curve) in some cases, while underperforming in others.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {529–536},
numpages = {8},
keywords = {pareto dominance, genetic algorithms, markov chain monte carlo, machine learning},
location = {Berlin, Germany},
series = {GECCO '17}
}

@article{10.1145/3442203,
author = {Liu, Yan and Guo, Bin and Zhang, Daqing and Zeghlache, Djamal and Chen, Jingmin and Hu, Ke and Zhang, Sizhe and Zhou, Dan and Yu, Zhiwen},
title = {Knowledge Transfer with Weighted Adversarial Network for Cold-Start Store Site Recommendation},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1556-4681},
url = {https://doi.org/10.1145/3442203},
doi = {10.1145/3442203},
abstract = {Store site recommendation aims to predict the value of the store at candidate locations and then recommend the optimal location to the company for placing a new brick-and-mortar store. Most existing studies focus on learning machine learning or deep learning models based on large-scale training data of existing chain stores in the same city. However, the expansion of chain enterprises in new cities suffers from data scarcity issues, and these models do not work in the new city where no chain store has been placed (i.e., cold-start problem). In this article, we propose a unified approach for cold-start store site recommendation, Weighted Adversarial Network with Transferability weighting scheme (WANT), to transfer knowledge learned from a data-rich source city to a target city with no labeled data. In particular, to promote positive transfer, we develop a discriminator to diminish distribution discrepancy between source city and target city with different data distributions, which plays the minimax game with the feature extractor to learn transferable representations across cities by adversarial learning. In addition, to further reduce the risk of negative transfer, we design a transferability weighting scheme to quantify the transferability of examples in source city and reweight the contribution of relevant source examples to transfer useful knowledge. We validate WANT using a real-world dataset, and experimental results demonstrate the effectiveness of our proposed model over several state-of-the-art baseline models.},
journal = {ACM Trans. Knowl. Discov. Data},
month = {apr},
articleno = {47},
numpages = {27},
keywords = {store site recommendation, neural networks, Urban computing, cold-start problem, transfer learning}
}

@article{10.1016/j.patrec.2017.01.004,
author = {Das, Ayan and Das, Swagatam},
title = {Feature Weighting and Selection with a Pareto-Optimal Trade-off between Relevancy and Redundancy},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {88},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2017.01.004},
doi = {10.1016/j.patrec.2017.01.004},
abstract = {Presents a simultaneous feature weighting and selection method.Uses non-linear information measure with L1 penalty to form the objective function.Experimentally determines the best constraint on weight vectors.Uses MOEA/D to solve the bi-objective optimization problem.Compares results with eminent state-of-the-art techniques. Feature Selection (FS) is an important pre-processing step in machine learning and it reduces the number of features/variables used to describe each member of a dataset. Such reduction occurs by eliminating some of the non-discriminating and redundant features and selecting a subset of the existing features with higher discriminating power among various classes in the data. In this paper, we formulate the feature selection as a bi-objective optimization problem of some real-valued weights corresponding to each feature. A subset of the weighted features is thus selected as the best subset for subsequent classification of the data. Two information theoretic measures, known as relevancy and redundancy are chosen for designing the objective functions for a very competitive Multi-Objective Optimization (MOO) algorithm called Multi-Objective Evolutionary Algorithm based on Decomposition (MOEA/D). We experimentally determine the best possible constraints on the weights to be optimized. We evaluate the proposed bi-objective feature selection and weighting framework on a set of 15 standard datasets by using the popular k-Nearest Neighbor (k-NN) classifier. As is evident from the experimental results, our method appears to be quite competitive to some of the state-of-the-art FS methods of current interest. We further demonstrate the effectiveness of our framework by changing the choices of the optimization scheme and the classifier to Non-dominated Sorting Genetic Algorithm (NSGA)-II and Support Vector Machines (SVMs) respectively.},
journal = {Pattern Recogn. Lett.},
month = {mar},
pages = {12–19},
numpages = {8},
keywords = {Feature weighting, Classification, Information measure, Feature selection, Multi-objective optimization}
}

@inproceedings{10.1145/3331184.3331218,
author = {Lu, Shuqi and Dou, Zhicheng and Jun, Xu and Nie, Jian-Yun and Wen, Ji-Rong},
title = {PSGAN: A Minimax Game for Personalized Search with Limited and Noisy Click Data},
year = {2019},
isbn = {9781450361729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331184.3331218},
doi = {10.1145/3331184.3331218},
abstract = {Personalized search aims to adapt document ranking to user's personal interests. Traditionally, this is done by extracting click and topical features from historical data in order to construct a user profile. In recent years, deep learning has been successfully used in personalized search due to its ability of automatic feature learning. However, the small amount of noisy personal data poses challenges to deep learning models to learn the personalized classification boundary between relevant and irrelevant results. In this paper, we propose PSGAN, a Generative Adversarial Network (GAN) framework for personalized search. By means of adversarial training, we enforce the model to pay more attention to training data that are difficult to distinguish. We use the discriminator to evaluate personalized relevance of documents and use the generator to learn the distribution of relevant documents. Two alternative ways to construct the generator in the framework are tested: based on the current query or based on a set of generated queries. Experiments on data from a commercial search engine show that our models can yield significant improvements over state-of-the-art models.},
booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {555–564},
numpages = {10},
keywords = {personalized web search, generative adversarial network},
location = {Paris, France},
series = {SIGIR'19}
}

@inproceedings{10.1145/2908812.2908918,
author = {Olson, Randal S. and Bartley, Nathan and Urbanowicz, Ryan J. and Moore, Jason H.},
title = {Evaluation of a Tree-Based Pipeline Optimization Tool for Automating Data Science},
year = {2016},
isbn = {9781450342063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908812.2908918},
doi = {10.1145/2908812.2908918},
abstract = {As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},
pages = {485–492},
numpages = {8},
keywords = {python, pipeline optimization, Pareto optimization, hyperparameter optimization, machine learning, genetic programming, data science},
location = {Denver, Colorado, USA},
series = {GECCO '16}
}

@article{10.1016/j.neucom.2016.02.074,
author = {Yu, Yang and Li, Yancheng and Li, Jianchun and Gu, Xiaoyu},
title = {Self-Adaptive Step Fruit Fly Algorithm Optimized Support Vector Regression Model for Dynamic Response Prediction of Magnetorheological Elastomer Base Isolator},
year = {2016},
issue_date = {October 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {211},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2016.02.074},
doi = {10.1016/j.neucom.2016.02.074},
abstract = {Parameter optimization of support vector regression (SVR) plays a challenging role in improving the generalization ability of machine learning. Fruit fly optimization algorithm (FFOA) is a recently developed swarm optimization algorithm for complicated multi-objective optimization problems and is also suitable for optimizing SVR parameters. In this work, parameter optimization in SVR using FFOA is investigated. In view of problems of premature and local optimum in FFOA, an improved FFOA algorithm based on self-adaptive step update strategy (SSFFOA) is presented to obtain the optimal SVR model. Moreover, the proposed method is utilized to characterize magnetorheological elastomer (MRE) base isolator, a typical hysteresis device. In this application, the obtained displacement, velocity and current level are used as SVR inputs while the output is the shear force response of the device. Experimental testing of the isolator with two types of excitations is applied for model performance evaluation. The results demonstrate that the proposed SSFFOA-optimized SVR (SSFFOA_SVR) has perfect generalization ability and more accurate prediction accuracy than other machine learning models, and it is a suitable and effective method to predict the dynamic behaviour of MRE isolator.},
journal = {Neurocomput.},
month = {oct},
pages = {41–52},
numpages = {12},
keywords = {Support vector regression, Magnetorheological elastomer base isolator, Self-adaptive step, Dynamic response prediction, Fruit fly optimization algorithm}
}

@inproceedings{10.1145/3319619.3326846,
author = {Barbiero, Pietro and Squillero, Giovanni and Tonda, Alberto},
title = {Evolutionary Discovery of Coresets for Classification},
year = {2019},
isbn = {9781450367486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319619.3326846},
doi = {10.1145/3319619.3326846},
abstract = {When a machine learning algorithm is able to obtain the same performance given a complete training set, and a small subset of samples from the same training set, the subset is termed coreset. As using a coreset improves training speed and allows human experts to gain a better understanding of the data, by reducing the number of samples to be examined, coreset discovery is an active line of research. Often in literature the problem of coreset discovery is framed as i. single-objective, attempting to find the candidate coreset that best represents the training set, and ii. independent from the machine learning algorithm used. In this work, an approach to evolutionary coreset discovery is presented. Building on preliminary results, the proposed approach uses a multi-objective evolutionary algorithm to find compromises between two conflicting objectives, i. minimizing the number of samples in a candidate coreset, and ii. maximizing the accuracy of a target classifier, trained with the coreset, on the whole original training set. Experimental results on popular classification benchmarks show that the proposed approach is able to identify candidate coresets with better accuracy and generality than state-of-the-art coreset discovery algorithms found in literature.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1747–1754},
numpages = {8},
keywords = {evolutionary algorithms, multi-objective, explain AI, coreset discovery, classification, machine learning},
location = {Prague, Czech Republic},
series = {GECCO '19}
}

@inbook{10.1145/3449726.3463133,
author = {Vargas-H\'{a}kim, Gustavo-Adolfo and Mezura-Montes, Efr\'{e}n and Acosta-Mesa, H\'{e}ctor-Gabriel},
title = {Hybrid Encodings for Neuroevolution of Convolutional Neural Networks: A Case Study},
year = {2021},
isbn = {9781450383516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449726.3463133},
abstract = {The Neuroevolution of Convolutional Neural Networks have yield into highly competitive results in the field of visual recognition in contemporary years. Some of the most recent advances in this field have been related to the design of neural encodings to represent these highly complex Deep Learning structures. Hybrid encodings have shown potential at distributing the representation of these networks into different sub-structures and thus improving the search. In this paper, we propose a compact hybrid encoding, which is used in an evolutionary framework called Deep Genetic Algorithm (DeepGA). We assess the performance of our simple representation against a hybrid encoding based on DenseBlocks, to evaluate how certain encodings might bias the search towards larger CNNs, in both single- and multi-objective scenarios. Our case study is the classification of lung conditions in chest X-ray images.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1762–1770},
numpages = {9}
}

@inproceedings{10.1109/ASP-DAC47756.2020.9045324,
author = {Li, Wenshuo and Ning, Xuefei and Ge, Guangjun and Chen, Xiaoming and Wang, Yu and Yang, Huazhong},
title = {FTT-NAS: Discovering Fault-Tolerant Neural Architecture},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASP-DAC47756.2020.9045324},
doi = {10.1109/ASP-DAC47756.2020.9045324},
abstract = {With the fast evolvement of deep-learning specific embedded computing systems, applications powered by deep learning are moving from the cloud to the edge. When deploying NNs onto the edge devices under complex environments, there are various types of possible faults: soft errors caused by atmospheric neutrons and radioactive impurities, voltage instability, aging, temperature variations, and malicious attackers. Thus the safety risk of deploying neural networks at edge computing devices in safety-critic applications is now drawing much attention. In this paper, we implement the random bit-flip, Gaussian, and Salt-and-Pepper fault models and establish a multi-objective fault-tolerant neural architecture search framework. On top of the NAS framework, we propose Fault-Tolerant Neural Architecture Search (FT-NAS) to automatically discover convolutional neural network (CNN) architectures that are reliable to various faults in nowadays edge devices. Then we incorporate fault-tolerant training (FTT) in the search process to achieve better results, which we called FTT-NAS. Experiments show that the discovered architecture FT-NAS-Net and FTT-NAS-Net outperform other hand-designed baseline architectures (58.1%/86.6% VS. 10.0%/52.2%), with comparable FLOPs and less parameters. What is more, the architectures trained under a single fault model can also defend against other faults. By inspecting the discovered architecture, we find that there are redundant connections learned to protect the sensitive paths. This insight can guide future fault-tolerant neural architecture design, and we verify it by a modification on ResNet-20–ResNet-M.},
booktitle = {2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC)},
pages = {211–216},
numpages = {6},
location = {Beijing, China}
}

@article{10.1016/j.patcog.2021.108393,
author = {Ad\i{}yeke, Esra and Baydo\u{g}an, Mustafa G\"{o}k\c{c}e},
title = {Semi-Supervised Extensions of Multi-Task Tree Ensembles},
year = {2022},
issue_date = {Mar 2022},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {123},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2021.108393},
doi = {10.1016/j.patcog.2021.108393},
journal = {Pattern Recogn.},
month = {mar},
numpages = {16},
keywords = {Ensemble learning, Multi-task learning, Totally randomized trees, Semi-supervised learning, Multi-objective trees}
}

@article{10.1016/j.neucom.2016.08.003,
author = {Kishor, Avadh and Singh, Pramod Kumar and Prakash, Jay},
title = {NSABC},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {216},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2016.08.003},
doi = {10.1016/j.neucom.2016.08.003},
abstract = {This paper presents a non-dominated sorting based multi-objective artificial bee colony algorithm NSABC to solve multi-objective optimization problems. It is an extension of the artificial bee colony algorithm ABC, which is a single objective optimization algorithm, to the multi-objective optimization domain. It uses a novel approach in the employee bee phase to steer the solutions to simultaneously achieve both the orthogonal goals in the multi-objective optimization convergence and diversity. The onlooker bee phase is similar to the ABC except for the fitness computation to exploit the promising solutions whereas there is no change in the scout bee phase, which is used to get rid of bad solutions and add diversity in the swarm by introducing random solutions. Along with a novel way of exploring new solutions, it uses non-dominated sorting and crowding distance, inspired by the NSGA-II, to maintain the best and diverse solutions in the swarm. It is tested on the 10 two-objective and three-objective unconstrained benchmark problems of varying nature and complexities from the CEC09 suite of test problems and is found better than or commensurable to thirteen state-of-the-art significant multi-objective optimization algorithms as well as other multi-objective variants of the ABC. Further, it is tested on the nine real-life data clustering problems considered from the UCI machine learning repository and proved itself better in comparison to the NSGA-II, MOVGA, and a recent multi-objective variant of the ABC named MOABC. Thus, it is observed that the NSABC is comparatively a simple, light, and powerful algorithm to solve multi-objective problems.},
journal = {Neurocomput.},
month = {dec},
pages = {514–533},
numpages = {20},
keywords = {Crowding distance, Non-dominated sorting, Multi-objective optimization, Artificial bee colony algorithm, Augmented population}
}

@inproceedings{10.1145/3078714.3078722,
author = {Hasanuzzaman, Mohammed and Way, Andy},
title = {Place-Type Detection in Location-Based Social Networks},
year = {2017},
isbn = {9781450347082},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3078714.3078722},
doi = {10.1145/3078714.3078722},
abstract = {Determining the type of places in location-based social networks will contribute to the success of various downstream tasks such as POI recommendation, location search, automatic place name database creation, and data cleaning.In this paper, we propose a multi-objective ensemble learning framework that (i) allows the accurate tagging of places into one of the three categories: public, private, or virtual, and (ii) identifying a set of solutions thus offering a wide range of possible applications. Based on the check-in records, we compute two types of place features from (i) specific patterns of individual places and (ii) latent relatedness among similar places. The features extracted from specific patterns (SP) are derived from all check-ins at a specific place. The features from latent relatedness (LR) are computed by building a graph of related places where similar types of places are connected by virtual edges. We conduct an experimental study based on a dataset of over 2.7M check-in records collected by crawling Foursquare-tagged tweets from Twitter. Experimental results demonstrate the effectiveness of our approach to this new problem and show the strength of taking various methods into account in feature extraction. Moreover, we demonstrate how place type tagging can be beneficial for place name recommendation services.},
booktitle = {Proceedings of the 28th ACM Conference on Hypertext and Social Media},
pages = {75–83},
numpages = {9},
keywords = {poi recommendation, location-based social networks, place-type tagging},
location = {Prague, Czech Republic},
series = {HT '17}
}

@inbook{10.1145/3368089.3409739,
author = {Ghamizi, Salah and Cordy, Maxime and Gubri, Martin and Papadakis, Mike and Boystov, Andrey and Le Traon, Yves and Goujon, Anne},
title = {Search-Based Adversarial Testing and Improvement of Constrained Credit Scoring Systems},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409739},
abstract = {Credit scoring systems are critical FinTech applications that concern the analysis of the creditworthiness of a person or organization. While decisions were previously based on human expertise, they are now increasingly relying on data analysis and machine learning. In this paper, we assess the ability of state-of-the-art adversarial machine learning to craft attacks on a real-world credit scoring system. Interestingly, we find that, while these techniques can generate large numbers of adversarial data, these are practically useless as they all violate domain-specific constraints. In other words, the generated examples are all false positives as they cannot occur in practice. To circumvent this limitation, we propose CoEvA2, a search-based method that generates valid adversarial examples (satisfying the domain constraints). CoEvA2 utilizes multi-objective search in order to simultaneously handle constraints, perform the attack and maximize the overdraft amount requested. We evaluate CoEvA2 on a major bank's real-world system by checking its ability to craft valid attacks. CoEvA2 generates thousands of valid adversarial examples, revealing a high risk for the banking system. Fortunately, by improving the system through adversarial training (based on the produced examples), we increase its robustness and make our attack fail.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1089–1100},
numpages = {12}
}

@article{10.1109/TIT.2020.3029182,
author = {Li, Cheuk Ting and Wu, Xiugang and \"{O}zg\"{u}r, Ayfer and El Gamal, Abbas},
title = {Minimax Learning for Distributed Inference},
year = {2020},
issue_date = {Dec. 2020},
publisher = {IEEE Press},
volume = {66},
number = {12},
issn = {0018-9448},
url = {https://doi.org/10.1109/TIT.2020.3029182},
doi = {10.1109/TIT.2020.3029182},
abstract = {The classical problem of supervised learning is to infer an accurate estimate of a target variable <inline-formula> <tex-math notation="LaTeX">$Y$ </tex-math></inline-formula> from a measured variable <inline-formula> <tex-math notation="LaTeX">$X$ </tex-math></inline-formula> using a set of labeled training samples. Motivated by the increasingly distributed nature of data and decision making, this paper considers a variation of this classical problem in which the inference is distributed between two nodes, e.g., a mobile device and a cloud, with a rate constraint on the communication between them. The mobile device observes <inline-formula> <tex-math notation="LaTeX">$X$ </tex-math></inline-formula> and sends a description <inline-formula> <tex-math notation="LaTeX">$M$ </tex-math></inline-formula> of <inline-formula> <tex-math notation="LaTeX">$X$ </tex-math></inline-formula> to the cloud, which computes an estimate <inline-formula> <tex-math notation="LaTeX">$hat {Y}$ </tex-math></inline-formula> of <inline-formula> <tex-math notation="LaTeX">$Y$ </tex-math></inline-formula>. We follow the recent minimax learning approach to study this inference problem and show that it corresponds to a one-shot minimax noisy lossy source coding problem. We then establish information theoretic bounds on the risk-rate Lagrangian cost, leading to a general method for designing a near-optimal descriptor-estimator pair. A key ingredient in the proof of our result is a refined version of the strong functional representation lemma previously used to establish several one-shot source coding theorems. Our results show that a naive estimate-compress scheme for rate-constrained inference is not optimal in general. When the distribution of <inline-formula> <tex-math notation="LaTeX">$(X,Y)$ </tex-math></inline-formula> is known and the error is measured by the logarithmic loss, our bounds on the risk-rate Lagrangian cost provide a new one-shot operational interpretation of the information bottleneck. We also demonstrate a way to bound the excess risk of the descriptor-estimator pair obtained by our method.},
journal = {IEEE Trans. Inf. Theor.},
month = {dec},
pages = {7929–7938},
numpages = {10}
}

@inproceedings{10.1145/3205455.3205550,
author = {Garciarena, Unai and Santana, Roberto and Mendiburu, Alexander},
title = {Evolved GANs for Generating Pareto Set Approximations},
year = {2018},
isbn = {9781450356183},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205455.3205550},
doi = {10.1145/3205455.3205550},
abstract = {In machine learning, generative models are used to create data samples that mimic the characteristics of the training data. Generative adversarial networks (GANs) are neural-network based generator models that have shown their capacity to produce realistic samples in different domains. In this paper we propose a neuro-evolutionary approach for evolving deep GAN architectures together with the loss function and generator-discriminator synchronization parameters. We also propose the problem of Pareto set (PS) approximation as a suitable benchmark to evaluate the quality of neural-network based generators in terms of the accuracy of the solutions they generate. The covering of the Pareto front (PF) by the generated solutions is used as an indicator of the mode-collapsing behavior of GANs. We show that it is possible to evolve GANs that generate good PS approximations. Our method scales to up to 784 variables and that it is capable to create architecture transferable across dimensions and functions.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {434–441},
numpages = {8},
keywords = {machine learning, neuroevolution, generative adversarial network},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@article{10.1016/j.ins.2015.05.034,
author = {Aggarwal, Manish},
title = {On Learning of Weights through Preferences},
year = {2015},
issue_date = {November 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {321},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2015.05.034},
doi = {10.1016/j.ins.2015.05.034},
abstract = {We present a method to learn the criteria weights in multi-criteria decision making (MCDM) by applying emerging learning-to-rank machine learning techniques. Given the pairwise preferences by a decision maker (DM), we learn the weights that the DM attaches to the multiple criteria, characterizing each alternative. As the training information, our method requires the pairwise preferences of alternatives, as revealed by the DM. Once, the DM's decision model is learnt in terms of the criteria weights, it can be applied to predict his choices for any new set of alternatives. The empirical validation of the proposed approach is done on a collection of 12 standard datasets. The accuracy values are compared with those obtained for the state-of-the-art methods such as ranking-SVM and TOPSIS.},
journal = {Inf. Sci.},
month = {nov},
pages = {90–102},
numpages = {13},
keywords = {Multi-criteria decision making, Preference learning, OWA, Learning-to-rank, Learning weights, Ordered weighted averaging}
}

@inproceedings{10.1145/2676662.2676676,
author = {Samreen, Faiza and Blair, Gordon S. and Rowe, Matthew},
title = {Adaptive Decision Making in Multi-Cloud Management},
year = {2014},
isbn = {9781450332330},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676662.2676676},
doi = {10.1145/2676662.2676676},
abstract = {The more cloud providers in the market the more information users have to handle to choose the best and suitable option for their application or business. The diversity in cloud services is a challenge for automated decision making in the multi-cloud environment. These decisions become more complex when the application's requirements and the application owner's constraints need to be satisfied throughout the application life cycle.This paper presents the concept of an Adaptive Decision Making Broker (ADMB) for multi-cloud management. ADMB aims to provide multi-criteria decision making using machine learning in a multi-cloud environment. In this context, we believe that our proposed methodology has the potential to provide optimal solutions as well as handle trade-offs between the functional and the non-functional requirements of given application.},
booktitle = {Proceedings of the 2nd International Workshop on CrossCloud Systems},
articleno = {4},
numpages = {6},
keywords = {machine learning, multi-criteria decision making, multi-cloud management},
location = {Bordeaux, France},
series = {CCB '14}
}

@inproceedings{10.1145/3437801.3441621,
author = {Liu, Yang and Sid-Lakhdar, Wissam M. and Marques, Osni and Zhu, Xinran and Meng, Chang and Demmel, James W. and Li, Xiaoye S.},
title = {GPTune: Multitask Learning for Autotuning Exascale Applications},
year = {2021},
isbn = {9781450382946},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437801.3441621},
doi = {10.1145/3437801.3441621},
abstract = {Multitask learning has proven to be useful in the field of machine learning when additional knowledge is available to help a prediction task. We adapt this paradigm to develop autotuning frameworks, where the objective is to find the optimal performance parameters of an application code that is treated as a black-box function. Furthermore, we combine multitask learning with multi-objective tuning and incorporation of coarse performance models to enhance the tuning capability. The proposed framework is parallelized and applicable to any application, particularly exascale applications with a small number of function evaluations. Compared with other state-of-the-art single-task learning frameworks, the proposed framework attains up to 2.8X better code performance for at least 80% of all tasks using up to 2048 cores.},
booktitle = {Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {234–246},
numpages = {13},
keywords = {multitask learning, autotuning, exascale computing project, machine learning, bayesian optimization},
location = {Virtual Event, Republic of Korea},
series = {PPoPP '21}
}

@article{10.1155/2019/4042624,
author = {Meng, Qiao and Song, Huansheng and Li, Gang and Zhang, Yu’an and Zhang, Xiangqing and Deng, Ke},
title = {A Block Object Detection Method Based on Feature Fusion Networks for Autonomous Vehicles},
year = {2019},
issue_date = {2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2019},
issn = {1076-2787},
url = {https://doi.org/10.1155/2019/4042624},
doi = {10.1155/2019/4042624},
abstract = {Nowadays, automatic multi-objective detection remains a challenging problem for autonomous vehicle technologies. In the past decades, deep learning has been demonstrated successful for multi-objective detection, such as the Single Shot Multibox Detector (SSD) model. The current trend is to train the deep Convolutional Neural Networks (CNNs) with online autonomous vehicle datasets. However, network performance usually degrades when small objects are detected. Moreover, the existing autonomous vehicle datasets could not meet the need for domestic traffic environment. To improve the detection performance of small objects and ensure the validity of the dataset, we propose a new method. Specifically, the original images are divided into blocks as input to a VGG-16 network which add the feature map fusion after CNNs. Moreover, the image pyramid is built to project all the blocks detection results at the original objects size as much as possible. In addition to improving the detection method, a new autonomous driving vehicle dataset is created, in which the object categories and labelling criteria are defined, and a data augmentation method is proposed. The experimental results on the new datasets show that the performance of the proposed method is greatly improved, especially for small objects detection in large image. Moreover, the proposed method is adaptive to complex climatic conditions and contributes a lot for autonomous vehicle perception and planning.},
journal = {Complex.},
month = {jan},
numpages = {14}
}

