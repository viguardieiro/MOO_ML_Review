Authors,Title,Year,Source title,Cited by,DOI,Link,Abstract,Author Keywords,Publisher
"Kozdrowicki E.W., Cooper D.W.","COKO III: The Cooper-Koz Chess Program",1973,"Communications of the ACM",4,"10.1145/362280.362288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0015646338&doi=10.1145%2f362280.362288&partnerID=40&md5=58a343186f44652289116b8bb971fd0b","OKO III is a chess player written entirely in Fortran. On the IBM 360-65, COKO III plays a minimal chess game at the rate of.2 sec cpu time per move, with a level close to lower chess club play. A selective tree searching procedure controlled by tactical chess logistics allows a deployment of multiple minimal game calculations to achieve some optimal move selection. The tree searching algorithms are the heart of COKO's effectiveness, yet they are conceptually simple. In addition, an interesting phenomenon called a tree searching catastrophe has plagued COKO's entire development just as it troubles a human player. Standard exponential growth is curbed to a large extent by the definition and trimming of the Fisher set. A clear distinction between tree pruning and selective tree searching is also made. Representation of the chess environment is described along with a strategical preanalysis procedure that maps the Lasker regions. Specific chess algorithms are described which could be used as a command structure by anyone desiring to do some chess program experimentation. A comparison is made of some mysterious actions of human players and COKO III. © 1973, ACM. All rights reserved.","alpha beta; artificial intelligence; auxiliary minimal game; chess algorithms; command structure; computer chess tournament; concept formation; Fischer set; game playing; heuristic programming; Lasker regions; machine learning; minimal chess game; minimax; selective searching; strategical; tactical; tactical control mode; tree searching; tree searching catastrophe",
"Szu Harold, Scheff Kim","Gram-Schmidt orthogonalization neural nets for O.C.R",1989,,1,"10.1109/ijcnn.1989.118632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024877305&doi=10.1109%2fijcnn.1989.118632&partnerID=40&md5=3701e34d2937ffd40cc7d8ec99599343","A description is given of a three-layer neural network for pattern classification/character recognition. The first layer is a heteroassociative feedforward network with bipolar output (±1) and zero threshold neurons. The second layer is an autoassociative memory whose input-output characteristics are the same as those in the first layer. The third layer is used to recognize the pattern and control whether the new orthogonal feature vector should be installed by the outer product formula to increase the memory capacity to M′ = M + 1. With this network, conventional pattern recognition of the minimax type is used to determine the initial interconnection matrix. The samples are classified by means of supervised learning. Only a single physical layer need be built, since the same layer can repeatedly be used three times in series. The performance of the network is studied.",,"Publ by IEEE, Piscataway"
"Katz William T., Pham Son","Experience-based learning experiments using Go-Moku",1991,"Proceedings of the IEEE International Conference on Systems, Man and Cybernetics",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026391196&partnerID=40&md5=a7dbc53a132d901738191dc946244f17","Three experience-based learning techniques are explored using the game Go-Moku (Connect-5). The first method, an exception tree, is used to prevent poor lines of play by recording critical moves in a move tree. The second method simply records all games in a large experience tree, backtracking the eventual outcomes in traditional minimax fashion. Both techniques allow a computer player to modify its behavior based on past experience, and, therefore, typically defeat static game programs. The last method explored is the use of a multilayer feedforward artificial neural network for strategy calculation. The network was trained on selected interior nodes of the experience tree using the backpropagation algorithm. The neural network strategy algorithm compares favorably with a fine-tuned hand-crafted strategy algorithm.",,"Publ by IEEE, Piscataway, NJ, United States"
"Carpenter G.A., Grossberg S., Markuzon N., Reynolds J.H., Rosen D.B.","Fuzzy ARTMAP: A Neural Network Architecture for Incremental Supervised Learning of Analog Multidimensional Maps",1992,"IEEE Transactions on Neural Networks",1488,"10.1109/72.159059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026923589&doi=10.1109%2f72.159059&partnerID=40&md5=1faab4b2320953563d85b205fa5f8679","— A new neural network architecture is introduced for incremental supervised learning of recognition categories and multidimensional maps in response to arbitrary sequences of analog or binary input vectors, which may represent fuzzy or crisp sets of features. The architecture, called fuzzy ARTMAP, achieves a synthesis of fuzzy logic and adaptive resonance theory (ART) neural networks by exploiting a close formal similarity between the computations of fuzzy subsethood and ART category choice, resonance, and learning. Fuzzy ARTMAP also realizes a new minimax learning rule that conjointly minimizes predictive error and maximizes code compression, or generalization. This is achieved by a match tracking process that increases the ART vigilance parameter by the minimum amount needed to correct a predictive error. As a result, the system automatically learns a minimal number of recognition categories, or “hidden units,” to meet accuracy criteria. Category proliferation is prevented by normalizing input vectors at a preprocessing stage. A normalization procedure called complement coding leads to a symmetric theory in which the and operator (V) and the OR operator (A) of fuzzy logic play complementary roles. Complement coding uses on cells and off cells to represent the input pattern, and preserves individual feature amplitudes while normalizing the total on cell/off cell vector. Learning is stable because all adaptive weights can only decrease in time. Decreasing weights correspond to increasing sizes of category “boxes.” Smaller vigilance values lead to larger category boxes. Improved prediction is achieved by training the system several times using different orderings of the input set. This voting strategy can also be used to assign confidence estimates to competing predictions given small, noisy, or incomplete training sets. Four classes of simulations illustrate fuzzy ARTMAP performance in relation to benchmark backpropagation and genetic algorithm systems. These simulations include (i) finding points inside versus outside a circle; (ii) learning to tell two spirals apart, (iii) incremental approximation of a piecewise-continuous function; and (iv) a letter recognition database. The fuzzy ARTMAP system is also compared with Salzberg’s NGE system and with Simpson’s FMMC system. © 1992 IEEE",,
"Ahmad Z., Guez A.","Preliminary report on machine learning via multiobjective optimization",1992,"Proceedings of SPIE - The International Society for Optical Engineering",,"10.1117/12.140027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075545536&doi=10.1117%2f12.140027&partnerID=40&md5=f4011bdd76e2c86d6b4c540be318b771","We believe that an essential feature in machine learning is the real time satisfaction of multiple objectives such as identification, tracking etc. The machine learning problem may be viewed as a nonlinear adaptive control problem where the environment plays the role of the 'plant', while the learner is the controller. Multiobjective optimization (MOO) in the control problem typically deals with simultaneous optimization of more than one objective, where each objective is described via a cost functional. In such a situation there often exists a region of tradeoff wherein one cost may be improved at the expense of others. Such a region is called the Pareto optimal (P0) set. A parameterization of this set simplifies the attainment of the existing tradeoff. Working within the Pareto set guaranties optimum tradeoff. As an example this algorithm is applied to the control of a D.C. motor. © 1992 SPIE. All rights reserved.",,"SPIE"
"Chella A., Gentile A., Sorbello F., Tarantino A.","Supervised learning for feed-forward neural networks: A new minimax approach for fast convergence",1993,"1993 IEEE International Conference on Neural Networks",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943261866&partnerID=40&md5=01795d059fedc012fbe20936148fb17d","In this paper a new approach to the problem of the learning process for feed-forward neural networks, based on an optimization point of view, is proposed. The developed algorithm is a minimax method based on a combination of the Quasi-Newton and Steepest-Descent methods: the optimum point is reached by minimizing the maximum of the error functions of the network without requiring any tuning of internal parameters. The algorithm has been tested on several widespread benchmarks and showed, in all the cases, superior convergence properties when compared with other algorithms available in literature. Significant experimental results are also included.",,"Publ by IEEE, Piscataway, NJ, United States"
"Karni R., Fournier F.","Knowledge extraction for production management",1994,"Journal of Intelligent Manufacturing",1,"10.1007/BF00123921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028459901&doi=10.1007%2fBF00123921&partnerID=40&md5=0cb7d6a30e2d5359d79faa8c995128e9","A procedure and underlying algorithm for extracting knowledge from production and inventory databases to support engineering management activities is described. The process searches for, detects and isolates behaviour patterns inherent in the data. It relates these patterns to production irregularities, suggests connections with specific causes and helps propose possible corrective or preventive actions. The approach is based on a four-phase procedure: (1) the decision-maker focuses on the subject or difficulty at issue, represented by a target concept; (2) the KEDB algorithm, based on a machine learning approach, processes the relevant database and provides knowledge characterizing and classifying the target concept; (3) the output is interpreted in Pareto fashion as a series of possible circumstances explaining the target concept behaviour; and (4) based on these causes, the decision-maker decides on possible corrective actions to improve the situation, or preventive actions to forestall unfavourable conditions. A case study based on an actual quality control database is detailed. © 1994 Chapman & Hall.","industrial databases; knowledge extraction; machine learning; Production management","Kluwer Academic Publishers"
"Ham Fredric M., Han Gabsoo, Fausett Laurene V.","Fuzzy LAPART: a neural architecture for supervised learning through inferencing for stable category recognition",1995,"Journal of artificial neural networks",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029542336&partnerID=40&md5=9780cd7d98bb2f454223910328f17eb6","Laterally primed adaptive resonance theory (LAPART), a neural network architecture for logical inferencing and supervised learning, has been adapted with fuzzy adaptive resonance theory (ART) modules, match tracking, and slow learning capabilities. Fuzzy LAPART consists of interconnected fuzzy ART networks, thus allowing for the use of analog inputs. The interconnections enable fuzzy LAPART to infer one pattern class from another to form a predictive pattern class. Slow learning, with fast-commit and slow-recode options, has also been incorporated for efficient coding of noisy input sets. Fuzzy LAPART realizes a minimax learning rule that conjointly minimizes predictive error and maximizes code compression, or generalization. This is achieved by a match tracking process that increases the ART vigilance parameter by the minimum amount needed to correct a predictive error. To illustrate the ability of fuzzy LAPART to perform stable category recognition for the separation of a spirals benchmark test, performance results are compared with two different types of counterpropagation clustering networks, with and without topological structure. Fuzzy LAPART shows outstanding performance results with more efficient clustering than either counterpropagation network.",,"Ablex Publ Corp, Norwood, NJ, United States"
"Szepesvári C.","Learning and exploitation do not conflict under minimax optimality",1997,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",6,"10.1007/3-540-62858-4_89","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947910334&doi=10.1007%2f3-540-62858-4_89&partnerID=40&md5=7f1601838af3d3595ee6e88e64b578ca","We show that adaptive real time dynamic programming extended with the action selection strategy which chooses the best action according to the latest estimate of the cost function yields asymptotically optimal policies within finite time under the minimax optimality criterion. From this it follows that learning and exploitation do not conflict under this special optimality criterion. We relate this result to learning optimal strategies in repeated two-player zero-sum deterministic games. © Springer-Verlag Berlin Heidelberg 1997.","Dynamic games; Reinforcement learning; Self-optimizing systems","Springer Verlag"
"Zaman R., Prokhorov D., Wunsch D.C.","Adaptive critic design in learning to play game of Go",1997,"IEEE International Conference on Neural Networks - Conference Proceedings",12,"10.1109/ICNN.1997.611623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030650665&doi=10.1109%2fICNN.1997.611623&partnerID=40&md5=5ae63cefe283739c98c689b33d3e168b","This paper examines the performance of an HDP-type adaptive critic design (ACD) of the game Go. The game Go is an ideal problem domain for exploring machine learning; it has simple rules but requires complex strategies to play well. All current commercial Go programs are knowledge based implementations; they utilize input feature and pattern matching along with minimax type search techniques. But the extremely high branching factor puts a limit on their capabilities, and they are very weak compared to the relative strengths of other game programs like chess. In this paper, the Go-playing ACD consists of a critic network and an action network. The HDP type critic network learns to predict the cumulative utility function of the current board position from training games, and, the action network chooses a next move which maximizes critics next step cost-to-go. After about 6000 different training games against a public domain program, WALLY, the network (playing WHITE) began to win in some of the games and showed slow but steady improvements on test games. © 1997 IEEE.",,
"Ichiro Tajik A., Takimotq E., Maruokat A.","An on-line prediction algorithm combining several prediction strategies in the shared bet model",1999,"IEICE Transactions on Information and Systems",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033341816&partnerID=40&md5=a5e0ec9bab75eb1e119b3cc1c7cbff6c","One of the most important problems in machine learning is to predict a binary value by observing a sequence of outcomes, up to the present time step, generated from some unknown source. Vovk and Cesa-Bianchi et al. independently proposed an on-line prediction model where prediction algorithms are assumed to be given a collection of prediction strategies called experts and hence be allowed to use the predictions they make. In this model, no assumption is made about the way the sequence of bits to be predicted is generated, and the performance of the algorithm is measured by the difference between the number of mistakes it makes on the bit sequence and the number of mistakes made by the best expert on the same sequence. In this paper we extend the model by introducing a notion of investment. That is, both the prediction algorithm and the experts are required to make bets on their predictions at each time step, and the performance of the algorithm is now measured with respect to the total money lost, rather than the number of mistakes. We analyze our algorithms in the particular situation where all the experts share the same amount of bets at each time step. In this shared bet model, we give a prediction algorithm that is in some sense optimal but impractical, and we also give an efficient prediction algorithm that turns out to be nearly optimal.","Minimax strategy; On-line prediction model; Prediction strategy; Weighted majority algorithm","Institute of Electronics, Information and Communication, Engineers, IEICE"
"Langdon W.B., Nordin J.P.","Seeding genetic programming populations",2000,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",34,"10.1007/978-3-540-46239-2_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958773394&doi=10.1007%2f978-3-540-46239-2_23&partnerID=40&md5=8257734a30076f76cc6e1022a5ca46e3","We show genetic programming (GP) populations can evolve under the influence of a Pareto multi-objective fitness and program size selection scheme, from “perfect.” programs which match the training material to general solutions. The technique is demonstrated with programmatic image compression, two machine learning benchmark problems (Pima Diabetes and Wisconsin Breast Cancer) and an insurance customer profiling task (Benelearn99 data mining). © Springer-Verlag Berlin Heidelberg 2000.",,"Springer Verlag"
"Mariano C., Morales E.","A new distributed reinforcement learning algorithm for multiple objective optimization problems",2000,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",14,"10.1007/3-540-44399-1_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650142747&doi=10.1007%2f3-540-44399-1_30&partnerID=40&md5=8c8481d102044f6821f82176c4854703","This paper describes a new algorithm, called MDQL, for the solution of multiple objective optimization problems. MDQL is based on a new distributed Q-learning algorithm, called DQL, which is also introduced in this paper. In DQL a family of independent agents, exploring different options, finds a common policy in a common environment. Information about action goodness is transmitted using traces over state-action pairs. MDQL extends this idea to multiple objectives, assigning a family of agents for each objective involved. A non-dominant criterion is used to construct Pareto fronts and by delaying adjustments on the rewards MDQL achieves better distributions of solutions. Furthermore, an extension for applying reinforcement learning to continuous functions is also given. Successful results of MDQL on several test-bed problems suggested in the literature are described. © Springer-Verlag 2000.",,"Springer Verlag"
"Beal D.F., Smith M.C.","Temporal difference learning applied to game playing and the results of application to shogi",2001,"Theoretical Computer Science",10,"10.1016/S0304-3975(00)00078-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034916755&doi=10.1016%2fS0304-3975%2800%2900078-5&partnerID=40&md5=8d98d1311652df3835400370245b5cca","This paper describes the application of temporal difference (TD) learning to minimax searches in general, and presents results from shogi. TD learning is used to adjust the weights for evaluation features over the course of a series of games, starting from arbitrary initial values. For some games, to obtain weights accurate enough for high-performance play will require the TD learning phase to make use of minimax searches. A theoretical description of TD applied to minimax search is given, and we discuss how the theoretical characteristics of the method interact with practical considerations. These include the depth of search appropriate for successful learning and the use of self-play to enable the algorithm to be independent of human knowledge. We then report on experiments that obtained values for use in shogi-playing programs. Unlike chess, shogi has no generally agreed standardized set of values for pieces, so there is more need for machine learning. We compare our machine-learnt values, obtained without any human knowledge input, with hand-crafted values. TD learning was successful in obtaining values that performed well in matches against hand-crafted values. © 2001 Elsevier Science B.V. All rights reserved.","Learning; Minimax; Search; Shogi; Temporal difference",
"Kang D.-O., Bien Z.","Model-based multiobjective fuzzy control using a new multiobjective dynamic programming approach",2001,"Annual Conference of the North American Fuzzy Information Processing Society - NAFIPS",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035791974&partnerID=40&md5=b9158495ca9612b2d51bf9c015d10f17","In this paper, we propose a model-based multi-objective fuzzy control method which is optimized on-line via a new multiobjective dynamic programming. The new multiobjective dynamic programming is guaranteed to derive a Pareto optimal solution. To estimate the effect of each candidate for control input in the dynamic programming procedure, we use state-value predictors of multiple objectives based on the plant model. Temporal difference learning and supervised learning are used for update of the predictors and the plant model. As the learning proceeds, the proposed method derives the compromised solution among multiple objectives. To show the effectiveness of the proposed method, some simulation results are given.",,
"Alaiz-Rodríguez R., Cid-Sueiro J.","Minimax strategies for training classifiers under unknown priors",2002,"Neural Networks for Signal Processing - Proceedings of the IEEE Workshop",,"10.1109/NNSP.2002.1030036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953710219&doi=10.1109%2fNNSP.2002.1030036&partnerID=40&md5=a19310d19a6e73e1be01403b46df5fe1","Most supervised learning algorithms are based on the assumption that the training data set reflects the underlying statistical model of the real data. However, this stationarity assumption is not always satisfied in practice: quite frequently, class prior probabilities are not in accordance with the class proportions in the training data set. The minimax approach is based on selecting the classifier that minimize the error probability under the worst case conditions. We propose a two-step learning algorithm to train a neural network in order to estimate the minimax classifier that is robust to changes in the class priors. During the first step, posterior probabilities based on training data priors are estimated. During the second step, class priors are modified in order to minimize a cost function that is asymptotically equivalent to the worst-case error rate. This procedure is illustrated on a softmax-based neural network. Several experimental results show the advantages of the proposed method with respect to other approaches. © 2002 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Alaiz-Rodríguez R., Cid-Sueiro J.","Neural minimax classifiers",2002,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/3-540-46084-5_66","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902135022&doi=10.1007%2f3-540-46084-5_66&partnerID=40&md5=32f35692018eb54d6fbf728bc114e265","Many supervised learning algorithms are based on the assumption that the training data set reflects the underlying statistical model of the real data. However, this stationarity assumption may be partially violated in practice: for instance, if the cost of collecting data is class dependent, the class priors of the training data set may be different from that of the test set. A robust solution to this problem is selecting the classifier that minimize the error probability under the worst case conditions. This is known as the minimax strategy. In this paper we propose a mechanism to train a neural network in order to estimate the minimax classifier that is robust to changes in the class priors. This procedure is illustrated on a softmax-based neural network, although it can be applied to other structures. Several experimental results show the advantages of the proposed methods with respect to other approaches. © Springer-Verlag Berlin Heidelberg 2002.",,"Springer Verlag"
"Kilic A., Arslan A.","Minimax fuzzy Q-learning in cooperative multi-agent systems",2002,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/3-540-36077-8_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053654030&doi=10.1007%2f3-540-36077-8_27&partnerID=40&md5=76ec884c7bacf686abff1cb2c9b45a9d","Recently, delayed reinforcement learning (RL) has been proposed as a strong method for learning in multi-agent systems (MASs). In this method, agents are concerned with the problem of discovering an optimal policy, a function mapping states to actions. The most popular RL technique, Q-learning, has been proven to produce an optimal policy under certain conditions. In this paper, we consider a multi-agent cooperation problem, and propose a multiagent reinforcement learning method based on the other agents’ actions. In our learning method, the agent under consideration observes other agents’ action, and uses the minimax Q-learning using fuzzy state and fuzzy goal representation for updating fuzzy Q values. © Springer-Verlag Berlin Heidelberg 2002.",,"Springer Verlag"
"Kim Y., Street W.N., Menczer F.","Evolutionary model selection in unsupervised learning",2002,"Intelligent Data Analysis",76,"10.3233/ida-2002-6605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-24344503628&doi=10.3233%2fida-2002-6605&partnerID=40&md5=ad3193fc5956bad8b84255f0bddf205b","Feature subset selection is important not only for the insight gained from determining relevant modeling variables but also for the improved understandability, scalability, and possibly, accuracy of the resulting models. Feature selection has traditionally been studied in supervised learning situations, with some estimate of accuracy used to evaluate candidate subsets. However, we often cannot apply supervised learning for lack of a training signal. For these cases, we propose a new feature selection approach based on clustering. A number of heuristic criteria can be used to estimate the quality of clusters built from a given feature subset. Rather than combining such criteria, we use ELSA, an evolutionary local selection algorithm that maintains a diverse population of solutions that approximate the Pareto front in a multi-dimensional objective space. Each evolved solution represents a feature subset and a number of clusters; two representative clustering algorithms, K-means and EM, are applied to form the given number of clusters based on the selected features. Experimental results on both real and synthetic data show that the method can consistently find approximate Pareto-optimal solutions through which we can identify the significant features and an appropriate number of clusters. This results in models with better and clearer semantic relevance. © 2002-IOS Press. All rights reserved.",,"IOS Press"
"Abbass H.A.","Pareto neuro-ensembles",2003,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",28,"10.1007/978-3-540-24581-0_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-7444246843&doi=10.1007%2f978-3-540-24581-0_47&partnerID=40&md5=13c93889bc712f01360d88f7f7badeac","The formation of a neural network ensemble has attracted much attention in the machine learning literature. A set of trained neural networks are combined using a post-gate to form a single super-network. One main challenge in the literature is to decide on which network to include in, or exclude from the ensemble. Another challenge is how to define an optimum size for the ensemble. Some researchers also claim that for an ensemble to be effective, the networks need to be different. However, there is not a consistent definition of what “different” means. Some take it to mean weakly correlated networks, networks with different bias-variance trade-off, and/or networks which are specialized on different parts of the input space. In this paper, we present a theoretically sound approach for the formation of neural network ensembles. The approach is based on the dominance concept that determines which network to include/exclude, identifies a suitable size for the ensemble, and provides a mechanism for quantifying differences between networks. The approach was tested on a number of standard dataset and showed competitive results. © Springer-Verlag Berlin Heidelberg 2003.",,"Springer Verlag"
"Mellor D.","Model-based reinforcement learning for alternating markov games",2003,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-540-24581-0_44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0348216602&doi=10.1007%2f978-3-540-24581-0_44&partnerID=40&md5=d6c95661ec76e9fee4521435f669cb87","Online training is a promising technique for training reinforcement learning agents to play strategy board games over the internet against human opponents. But the limited training experience that can be generated by playing against real humans online means that learning must be data-efficient. Data-efficiency has been achieved in other domains by augmenting reinforcement learning with a model: model-based reinforcement learning. In this paper the Minimax-MBTD algorithm is presented, which extends model-based reinforcement learning to deterministic alternating Markov games, a generalisation of two-player zerosum strategy board games like chess and Go. By using a minimax measure of optimality the strategy learnt generalises to arbitrary opponents, unlike approaches that explicitly model specific opponents. Minimax- MBTD is applied to Tic-Tac-Toe and found to converge faster than direct reinforcement learning, but focussing planning on successors to the current state resulted in slower convergence than unfocussed random planning. © Springer-Verlag Berlin Heidelberg 2003.","Game playing; Machine learning; Planning; Reinforcement learning; Search","Springer Verlag"
"Liu J., Zhou H.-B.","Tumor classification based on gene microarray data and hybrid learning method",2003,"International Conference on Machine Learning and Cybernetics",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542285298&partnerID=40&md5=e30dc9204e1c0914eec6fea9a0641489","Gene expression microarray data can be used to classify tumor types. We proposed a new procedure to classify human tumor samples based on microarray gene expressions by using a hybrid supervised learning method called MOEA/WV (Multi-Objective Evolutionary Algorithm/ Weighted Voting). MOEA is used to search for a relatively few subsets of informative genes from the high-dimensional gene space, and WV is used as a classification tool. This new method has been applied to predicate the subtypes of lymphoma and outcomes of medulloblastoma. The results are relatively accurate and meaningful compared with those from other methods.","MOEA; Pareto Optimization; Tumor Classification",
"Liu J., Iba H.","Prediction of tumor outcome based on gene expression data",2004,"Wuhan University Journal of Natural Sciences",1,"10.1007/bf02830598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-2942746634&doi=10.1007%2fbf02830598&partnerID=40&md5=e159d0e46b807f247efd48d22f123789","Gene expression microarray data can be used to classify tumor types. We proposed a new procedure to classify human tumor samples based on microarray gene expressions by using a hybrid supervised learning method called MOEA-WV (Multi-Objective Evolutionary Algorithm + Weighted Voting). MOEA is used to search for a relatively few subsets ill informative genes from the high-dimensional gene space, mid WV is used as a classification toot. This new method has been applied to predicate the subtypes of lymphoma and outlines of medulloblastoma. The results are relatively accurate and meaningful compared to those from other methods.","Bioinformatics; MOEA; Pareto optimization; Tumor classification","Wuhan University"
"Lin Y., Brown L.D.","Statistical properties of the method of regularization with periodic Gaussian reproducing kernel",2004,"Annals of Statistics",14,"10.1214/009053604000000454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-24344444131&doi=10.1214%2f009053604000000454&partnerID=40&md5=8e5adebaf735d3a1ea8aeed939b9ba50","The method of regularization with the Gaussian reproducing kernel is popular in the machine learning literature and successful in many practical applications. In this paper we consider the periodic version of the Gaussian kernel regularization. We show in the white noise model setting, that in function spaces of very smooth functions, such as the infinite-order Sobolev space and the space of analytic functions, the method under consideration is asymptotically minimax; in finite-order Sobolev spaces, the method is rate optimal, and the efficiency in terms of constant when compared with the minimax estimator is reasonably high. The smoothing parameters in the periodic Gaussian regularization can be chosen adaptively without loss of asymptotic efficiency. The results derived in this paper give a partial explanation of the success of the Gaussian reproducing kernel in practice. Simulations are carried out to study the finite sample properties of the periodic Gaussian regularization. © Institute of Mathematical Statistics, 2004.","Asymptotic minimax risk; Gaussian reproducing kernel; Nonparametric estimation; Rate of convergence; Sobolev spaces; White noise model",
"Huang K., Yang H., King I., Lyu M.R.","Learning classifiers from imbalanced data based on biased minimax probability machine",2004,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",86,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-5044220135&partnerID=40&md5=656398519dd417a0b3483c50b4a9bc60","We consider the problem of the binary classification on imbalanced data, in which nearly all the instances are labelled as one class, while far fewer instances are labelled as the other class, usually the more important class. Traditional machine learning methods seeking an accurate performance over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into the majority, usually the less important class. Moreover, some current methods have tried to utilize some intermediate factors, e.g., the distribution of the training set, the decision thresholds or the cost matrices, to influence the bias of the classification. However, it remains uncertain whether these methods can improve the performance in a systematic way. In this paper, we propose a novel model named Biased Minimax Probability Machine. Different from previous methods, this model directly controls the worst-case real accuracy of classification of the future data to build up biased classifiers. Hence, it provides a rigorous treatment on imbalanced data. The experimental results on the novel model comparing with those of three competitive methods, i.e., the Naive Bayesian classifier, the k-Nearest Neighbor method, and the decision tree method C4.5, demonstrate the superiority of our novel model.",,
"Hammer P.L., Kogan A., Simeone B., Szedmák S.","Pareto-optimal patterns in logical analysis of data",2004,"Discrete Applied Mathematics",60,"10.1016/j.dam.2003.08.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-4544297313&doi=10.1016%2fj.dam.2003.08.013&partnerID=40&md5=54389aa7e98f69fa37e58648dd0f955f","Patterns are the key building blocks in the logical analysis of data (LAD). It has been observed in empirical studies and practical applications that some patterns are more ""suitable"" than others for use in LAD. In this paper, we model various such suitability criteria as partial preorders defined on the set of patterns. We introduce three such preferences, and describe patterns which are Pareto-optimal with respect to any one of them, or to certain combinations of them. We develop polynomial time algorithms for recognizing Pareto-optimal patterns, as well as for transforming an arbitrary pattern to a better Pareto-optimal one with respect to any one of the considered criteria, or their combinations. We obtain analytical representations characterizing some of the sets of Pareto-optimal patterns, and investigate the computational complexity of generating all Pareto-optimal patterns. The empirical evaluation of the relative merits of various types of Pareto-optimality is carried out by comparing the classification accuracy of Pareto-optimal theories on several real life data sets. This evaluation indicates the advantages of ""strong patterns"", i.e. those patterns which are Pareto-optimal with respect to the ""evidential preference"" introduced in this paper. © 2004 Elsevier B.V. All rights reserved.","Boolean functions; Classification accuracy; Extremal patterns, Data mining; Machine learning",
"Yun Y., Nakayama H., Arakawa M., Shiraki W., Ishikawa H.","Multi-objective optimization technique using computational intelligence",2004,"Proceedings - 2004 International Conference on Intelligent Mechatronics and Automation",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-8844221292&partnerID=40&md5=2e2ab30ceaf2bd16aa0292f0f45d011e","In many practical engineering design problems, the form of objective functions is not given explicitly in terms of design variables. Given the value of design variables, under this circumstance, the values of objective functions are obtained by real/computational experiments such as structural analysis, fluid-mechanical analysis, ihermodynamic analysis, and so on. Since those experiments are considerably expensive and also time consuming, thus it is actually almost impossible to find the exact solution to those problems by using conventional optimization methods. Recently, approximation methods using computational intelligence, for example, evolutionary algorithms and neural networks have been developed remarkably. Even those algorithms need a tremendous number of experiments to obtain an approximate solution. Furthermore, most engineering design problems should be formulated as multi-objective optimization problems so as to meet the diversified demands of designer. It also causes that the number of experiments goes on increasing. This paper proposes a new method using computational intelligence methods, which are a machine learning algorithm and an evolutionary algorithm, in order to make the number of experiments for finding the solution of problem with multi-objective functions as few as possible. Furthermore, this paper shows that the proposed method combining a machine learning algorithm and an evolutionary algorithm can generate well approximate Pareto frontier, and a decision making with two or three objective functions can be easily performed on the basis of visualized Pareto frontiers by our method. Finally, the effectiveness of the proposed method will be illustrated through several numerical and practical examples.",,
"Barros Carrijo I.T., Ribeiro Reis L.F.","Extraction of optimal operation rules for water distribution systems using multi-objective genetic algorithms and machine learning",2005,"Proceedings of the 8th International Conference on Computing and Control for the Water Industry, CCWI 2005: Water Management for the 21st Century",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906230220&partnerID=40&md5=3ad7f4c5aaca3e1c63a5c425e456a83e","The growth of cities, associated with the lack of investment in basic infrastructure, has rendered water supply systems complex and difficult to operate. The efficient operation of such systems is a fundamental tool for extending the system's service life as much as possible, thus ensuring reliable service to consumers while keeping electrical energy and maintenance costs at acceptable levels. Efficient operation requires knowledge of the system, supported by tools such as models for hydraulic simulation, optimization, and definition of rules. These tools provides the operator with proper conditions for the rational operation of the system's units. This paper aims to develop a computational model for the optimal operation of water distribution systems, essentially macro systems (skeleton), concerning the costs of operation and hydraulic benefits. It represents an attempt to provide adequate operation rules in order to minimize cost and maximize hydraulic benefits. Based on the knowledge of the system supported by technical and commercial geo-referenced records, the intention is to hydraulically simulate the system using the EPANET2 hydraulic simulator, optimize its operation though multiobjective genetic algorithms (MOGAs) and produce operational rules through the machine learning process. In this study a multi-objective genetic algorithm, called strength Pareto evolutionary algorithm (SPEA), is used to obtain a Pareto front. The optimal operation analyses were conducted on the macro water system of the city of Goiânia in Brazil. This was in order to minimize the cost of electric energy at the pump stations and to maximize the hydraulic benefits in terms of the required pressure at the demand nodes and of adequate reservoir levels, showing that solutions for satisfactory operation system can be quickly produced as a substitute for the personal judgment of the operator.","Genetic algorithms; Machine learning; Multi-objective optimization; Optimal operation","Centre for Water Systems"
"Li X., Jiang H., Liu C.","Large margin HMMS for speech recognition",2005,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",41,"10.1109/ICASSP.2005.1416353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646799820&doi=10.1109%2fICASSP.2005.1416353&partnerID=40&md5=c4d8db9078b5d9fceb7d32b5c927671f","In this paper, motivated by large margin classifiers in machine learning, we propose a novel method to estimate continuous density hidden Markov model (CDHMM) in speech recognition according to the principle of maximizing the minimum multi-class separation margin. The approach is named as large margin HMM. Firstly, we will show that this type of large margin HMM estimation problem can be formulated as a standard constrained minimax optimization problem. Secondly, we propose an iterative localized optimization approach to perform the above minimax optimization for one model at each time to guarantee that the optimal value of the objective function always exists in the course of model parameter optimization. Then, we show that during each step the optimization can be solved by the GPD (generalized probabilistic descent) algorithm if we approximate the objective function by a differentiable function, such as summation of exponential functions. The large margin HMM-based classifiers are evaluated in a speaker-independent E-set speech recognition task by using the OGI ISOLET database. Experimental results show that the large margin HMMs can achieve significant word error rate (WER) reduction over the conventional HMM training methods, such as maximum likelihood estimation (MLE) and minimum classification error (MCE) training. © 2005 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Tao D., Li X., Hu W., Maybank S., Wu X.","Supervised tensor learning",2005,"Proceedings - IEEE International Conference on Data Mining, ICDM",131,"10.1109/ICDM.2005.139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947638842&doi=10.1109%2fICDM.2005.139&partnerID=40&md5=7cdbb3614db5100deef6f1591c496d9f","This paper aims to take general tensors as inputs for supervised learning. A supervised tensor learning (STL) framework is established for convex optimization based learning techniques such as support vector machines (SVM) and minimax probability machines (MPM). Within the STL framework, many conventional learning machines can be generalized to take nth-order tensors as inputs. We also study the applications of tensors to learning machine design and feature extraction by linear discriminant analysis (LDA). Our method for tensor based feature extraction is named the tenor rank-one discriminant analysis (TR1DA). These generalized algorithms have several advantages: 1) reduce the curse of dimension problem in machine learning and data mining; 2) avoid the failure to converge; and 3) achieve better separation between the different categories of samples. As an example, we generalize MPM to its STL version, which is named the tensor MPM (TMPM). TMPM learns a series of tensor projections iteratively. It is then evaluated against the original MPM. Our experiments on a binary classification problem show that TMPM significantly outperforms the original MPM. © 2005 IEEE.",,
"Handl J., Knowles J.","Semi-supervised feature selection via multiobjective optimization",2006,"IEEE International Conference on Neural Networks - Conference Proceedings",17,"10.1109/ijcnn.2006.247330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-40649125308&doi=10.1109%2fijcnn.2006.247330&partnerID=40&md5=340cad4c55bba23208801357e8f4686c","In previous work, we have shown that both unsupervised feature selection and the semi-supervised clustering problem can be usefully formulated as multiobjective optimization problems. In this paper, we discuss the logical extension of this prior work to cover the problem of semi-supervised feature selection. Our extensive experimental results provide evidence for the advantages of semi-supervised feature selection when both labelled and unlabelled data are available. Moreover, the particular effectiveness of a Pareto-based optimization approach can also be seen. © 2006 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Kondo N., Hatanaka T., Uosaki K.","Pattern classification by evolutionary RBF networks ensemble based on multi-objective optimization",2006,"IEEE International Conference on Neural Networks - Conference Proceedings",8,"10.1109/ijcnn.2006.247224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-40649091876&doi=10.1109%2fijcnn.2006.247224&partnerID=40&md5=c24b231754447492c3ac2c656665d4fb","In this paper, evolutionary multi-objective selection method of RBF networks structure and its application to the ensemble learning is considered. The candidates of RBF network structure are encoded into the chromosomes in GAs. Then, they evolve toward Pareto-optimal front defined by several objective functions concerning with model accuracy, model complexity and model smoothness. RBF network ensemble is constructed of the obtained Pareto-optimal models since such models are diverse. This method is applied to the pattern classification problem. Experiments on the benchmark problem demonstrate that the proposed method has comparable generalization ability to conventional ensemble methods. © 2006 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Peng X., King I.","Imbalanced learning in relevance feedback with biased minimax probability machine for image retrieval tasks",2006,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/11893028_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750577216&doi=10.1007%2f11893028_39&partnerID=40&md5=42e70e940a3b836170dd58a041fa3a74","In recent years, Minimax Probability Machine (MPM) have demonstrated excellent performance in a variety of pattern recognition problems. At the same time various machine learning methods have been used on relevance feedback tasks in Content-based Image Retrieval (CBIR). One of the problems in typical techniques for relevance feedback is that they treat the relevant feedback and irrelevant feedback equally. In other words, the negative instances largely outnumber the positive instances. Hence, the assumption that they are balanced is incorrect. In this paper we study how MPM can be applied to image retrieval, more precisely, Biased MPM during the relevance feedback iterations. We formulate the relevance feedback based on a modified MPM called Biased Minimax Probability Machine (BMPM). Different from previous methods, this model directly controls the accuracy of classification of the future data to build up biased classifiers. Hence, it provides a rigorous treatment on imbalanced data. Mathematical formulation and explanations are provided for showing the advantages. Experiments are conducted to evaluate the performance of our proposed framework, in which encouraging and promising experimental results are obtained. © Springer-Verlag Berlin Heidelberg 2006.",,"Springer Verlag"
"Lemczyk V., Heywood M.","Pareto-coevolutionary genetic programming classifier",2006,"GECCO 2006 - Genetic and Evolutionary Computation Conference",4,"10.1145/1143997.1144162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750259112&doi=10.1145%2f1143997.1144162&partnerID=40&md5=adcb1fbe9238adc3d2eba00a54208dd7","The conversion and extension of the Incremental Pareto-Coevolution Archive algorithm (IPCA) into the domain of Genetic Programming classifier evolution is presented. In order to accomplish efficiency in regards to classifier evaluation on training data, the coevolutionary aspect of the IPCA algorithm is utilized to simultaneously evolve a subset of the training data that provides distinctions between candidate classifiers. The algorithm is compared in terms of classification ""score"" (equal weight to detection rate, and 1 - false positive rate), and run-time against a traditional GP classifier using the entinety of the training data for evaluation, and a GP classifier which performs Dynamic Subset Selection. The results indicate that the presented algorithm outperforms the subset, selection algorithm in terms of classification score, and outperforms the traditional classifier while requiring roughly 1/430 of the wall-clock time.","Co-evolution; Evolutionary Computation; Genetic Programming; Subset Selection; Supervised Learning","Association for Computing Machinery (ACM)"
"Mierswa I., Wurst M.","Information preserving multi-objective feature selection for unsupervised learning",2006,"GECCO 2006 - Genetic and Evolutionary Computation Conference",34,"10.1145/1143997.1144248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750237835&doi=10.1145%2f1143997.1144248&partnerID=40&md5=df70a008f60d69d406b57e68e53224d6","In this work we propose a novel, sound framework for evolutionary feature selection in unsupervised machine learning problems. We show that unsupervised feature selection is inhemulti-objectiverently multi-objective and behaves differently from supervised feature selection in that the number of features must be maximized instead of being minimized. Although this might sound surprising from a supervised learning point of view, we exemplify this relationship on the problem of data clustering and show that existing approaches do not pose the optimization problem in an appropriate way. Another important consequence of this paradigm change is a method which segments the Pareto sets produced by our approach. Inspecting only prototypical points from these segments drastically reduces the amount of work for selecting a final solution. We compare our methods against existing approaches on eight data sets. Copyright 2006 ACM.","Multi-objective feature selection; Pareto front segmentation; Unsupervised learning","Association for Computing Machinery"
"Tan K.C., Yu Q., Ang J.H.","A dual-objective evolutionary algorithm for rules extraction in data mining",2006,"Computational Optimization and Applications",22,"10.1007/s10589-005-3907-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745167714&doi=10.1007%2fs10589-005-3907-9&partnerID=40&md5=76f062cbd80e69a769bba402b6c8cb9f","This paper presents a dual-objective evolutionary algorithm (DOEA) for extracting multiple decision rule lists in data mining, which aims at satisfying the classification criteria of high accuracy and ease of user comprehension. Unlike existing approaches, the algorithm incorporates the concept of Pareto dominance to evolve a set of non-dominated decision rule lists each having different classification accuracy and number of rules over a specified range. The classification results of DOEA are analyzed and compared with existing rule-based and non-rule based classifiers based upon 8 test problems obtained from UCI Machine Learning Repository. It is shown that the DOEA produces comprehensible rules with competitive classification accuracy as compared to many methods in literature. Results obtained from box plots and t-tests further examine its invariance to random partition of datasets. © 2006 Springer + Business Media, Inc.","Classification; Data mining; Evolutionary algorithm; Rules extraction","Springer Netherlands"
"Shi T., Yu B.","Binning in Gaussian kernel regularization",2006,"Statistica Sinica",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746123943&partnerID=40&md5=d7ef6cad47a4975f1e910daf541ecc4a","Gaussian kernel regularization is widely used in the machine learning literature and has proved successful in many empirical experiments. The periodic version of Gaussian kernel regularization has been shown to be minimax rate optimal in estimating functions in any finite order Sobolev space. However, for a data set with n points, the computation complexity of the Gaussian kernel regularization method is of order O(n 3). In this paper we propose to use binning to reduce the computation of Gaussian kernel regularization in both regression and classification. For periodic Gaussian kernel regression, we show that the binned estimator achieves the same minimax rates as the unbinned estimator, but the computation is reduced to O(m 3) with m as the number of bins. To achieve the minimax rate in the kth order Sobolev space, m needs to be in the order of O(kn 1/(2k+1)), which makes the binned estimator computation of order O(n) for k = 1, and even less for larger k. Our simulations show that the binned estimator (binning 120 data points into 20 bins in our simulation) provides almost the same accuracy with only 0.4% of computation time. For classification, binning with L2-loss Gaussian kernel regularization and Gaussian kernel Support Vector Machines is tested in a polar cloud detection problem.","Asymptotic minimax risk; Binning; Gaussian kernel; Rate of convergence; Regularization; Sobolev space; Support vector machines",
"Ince H., Trafalis T.B.","Kernel methods for short-term portfolio management",2006,"Expert Systems with Applications",19,"10.1016/j.eswa.2005.10.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-30944443762&doi=10.1016%2fj.eswa.2005.10.008&partnerID=40&md5=c6a78f1ab55c94f2ff8a7e7c7cfdc132","Portfolio optimization problem has been studied extensively. In this paper, we look at this problem from a different perspective. Several researchers argue that the USA equity market is efficient. Some of the studies show that the stock market is not efficient around the earning season. Based on these findings, we formulate the problem as a classification problem by using state of the art machine learning techniques such as minimax probability machine (MPM) and support vector machines (SVM). The MPM method finds a bound on the misclassification probabilities. On the other hand, SVM finds a hyperplane that maximizes the distance between two classes. Both methods prove similar results for short-term portfolio management. © 2005 Elsevier Ltd. All rights reserved.","Earning announcements; Kernel methods; Minimax probability machine; Portfolio management; Support vector machines",
"Huang K., Yang H., King I., Lyu M.R.","Maximizing sensitivity in medical diagnosis using biased minimax probability machine",2006,"IEEE Transactions on Biomedical Engineering",33,"10.1109/TBME.2006.872819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646373698&doi=10.1109%2fTBME.2006.872819&partnerID=40&md5=e975698595c68933b751805100f1d78d","The challenging task of medical diagnosis based on machine learning techniques requires an inherent bias, i.e., the diagnosis should favor the ""ill"" class over the ""healthy"" class, since misdiagnosing a patient as a healthy person may delay the therapy and aggravate the illness. Therefore, the objective in this task is not to improve the overall accuracy of the classification, but to focus on improving the sensitivity (the accuracy of the ""ill"" class) while maintaining an acceptable specificity (the accuracy of the ""healthy"" class). Some current methods adopt roundabout ways to impose a certain bias toward the important class, i.e., they try to utilize some intermediate factors to influence the classification. However, it remains uncertain whether these methods can improve the classification performance systematically. In this paper, by engaging a novel learning tool, the biased minimax probability machine (BMPM), we deal with the issue in a more elegant way and directly achieve the objective of appropriate medical diagnosis. More specifically, the BMPM directly controls the worst case accuracies to incorporate a bias toward the ""ill"" class. Moreover, in a distribution-free way, the BMPM derives the decision rule in such a way as to maximize the worst case sensitivity while maintaining an acceptable worst case specificity. By directly controlling the accuracies, the BMPM provides a more rigorous way to handle medical diagnosis; by deriving a distribution-free decision rule, the BMPM distinguishes itself from a large family of classifiers, namely, the generative classifiers, where an assumption on the data distribution is necessary. We evaluate the performance of the model and compare it with three traditional classifiers: the k-nearest neighbor, the naive Bayesian, and the C4.5. The test results on two medical datasets, the breast-cancer dataset and the heart disease dataset, show that the BMPM outperforms the other three models. © 2006 IEEE.","Biased classification; Medical diagnosis; Minimax probability machine; Worst case accuracy",
"Sadikov A., Bratko I.","Learning long-term chess strategies from databases",2006,"Machine Learning",6,"10.1007/s10994-006-6747-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744789157&doi=10.1007%2fs10994-006-6747-7&partnerID=40&md5=0f4a21ca21ce9b642d54efc0ee02ca00","We propose an approach to the learning of long-term plans for playing chess endgames. We assume that a computer-generated database for an endgame is available, such as the king and rook vs. king, or king and queen vs. king and rook endgame. For each position in the endgame, the database gives the ""value"" of the position in terms of the minimum number of moves needed by the stronger side to win given that both sides play optimally. We propose a method for automatically dividing the endgame into stages characterised by different objectives of play. For each stage of such a game plan, a stage-specific evaluation function is induced, to be used by minimax search when playing the endgame. We aim at learning playing strategies that give good insight into the principles of playing specific endgames. Games played by these strategies should resemble human expert's play in achieving goals and subgoals reliably, but not necessarily as quickly as possible.","Chess da-ta-ba-ses; Chess endgames; Computer chess; Long-term Strategy; Machine learning",
"Huang K., Yang H., King I., Lyu M.R.","Imbalanced learning with a biased minimax probability machine",2006,"IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics",47,"10.1109/TSMCB.2006.870610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746839186&doi=10.1109%2fTSMCB.2006.870610&partnerID=40&md5=37eb17284d1df6b3db3cb96ae3271158","Imbalanced learning is a challenged task in machine learning. In this context, the data associated with one class are far fewer than those associated with the other class. Traditional machine learning methods seeking classification accuracy over a full range of instances are not suitable to deal with this problem, since they tend to classify all the data into a majority class, usually the less important class. In this correspondence, the authors describe a new approach named the biased minimax probability machine (BMPM) to deal with the problem of imbalanced learning. This BMPM model is demonstrated to provide an elegant and systematic way for imbalanced learning. More specifically, by controlling the accuracy of the majority class under all possible choices of class-conditional densities with a given mean and covariance matrix, this model can quantitatively and systematically incorporate a bias for the minority class. By establishing an explicit connection between the classification accuracy and the bias, this approach distinguishes itself from the many current imbalanced-learning methods; these methods often impose a certain bias on the minority data by adapting intermediate factors via the trial-and-error procedure. The authors detail the theoretical foundation, prove its solvability, propose an efficient optimization algorithm, and perform a series of experiments to evaluate the novel model. The comparison with other competitive methods demonstrates the effectiveness of this new model. © 2006 IEEE.","Fractional programming (FP); Imbalanced learning; Receiver operating characteristic (ROC) analysis; Worst case accuracy",
"Jiang H., Li X., Liu C.","Large margin hidden Markov models for speech recognition",2006,"IEEE Transactions on Audio, Speech and Language Processing",102,"10.1109/TASL.2006.879805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047115134&doi=10.1109%2fTASL.2006.879805&partnerID=40&md5=971bcb91369e2e9a18b682bd28c532a8","In this paper, motivated by large margin classifiers in machine learning, we propose a novel method to estimate continuous-density hidden Markov model (CDHMM) for speech recognition according to the principle of maximizing the minimum multiclass separation margin. The approach is named large margin HMM. First, we show this type of large margin HMM estimation problem can be formulated as a constrained minimax optimization problem. Second, we propose to solve this constrained minimax optimization problem by using a penalized gradient descent algorithm, where the original objective function, i.e., minimum margin, is approximated by a differentiate function and the constraints arc cast as penalty terms in the objective function. The new training method is evaluated in the speaker-independent isolated E-sct recognition and the TIDIGITS connected digit string recognition tasks. Experimental results clearly show that the large margin HMMs consistently outperform the conventional HMM training methods. It has been consistently observed that the large margin training method yields significant recognition error rate reduction even on top of some popular discriminative training methods. © 2006 IEEE.","Continuous-density hidden Markov models (CDHMMs); Gradient descent search; Large margin classifiers; Minimax optimization; Support vector machine",
"Argyriou A., Hauser R., Micchelli C.A., Pontil M.","A DC-programming algorithm for kernel selection",2006,"ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning",47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749254646&partnerID=40&md5=d39db434524a145c09e40a11825ec8b7","We address the problem of learning a kernel for a given supervised learning task. Our approach consists in searching within the convex hull of a prescribed set of basic kernels for one which minimizes a convex regularization functional. A unique feature of this approach compared to others in the literature is that the number of basic kernels can be infinite. We only require that they are continuously parameterized. For example, the basic kernels could be isotropic Gaussians with variance in a prescribed interval or even Gaussians parameterized by multiple continuous parameters. Our work builds upon a formulation involving a minimax optimization problem and a recently proposed greedy algorithm for learning the kernel. Although this optimization problem is not convex, it belongs to the larger class of DC (difference of convex functions) programs. Therefore, we apply recent results from DC optimization theory to create a new algorithm for learning the kernel. Our experimental results on benchmark data sets show that this algorithm outperforms a previously proposed method.",,
"Jin Y., Sendhoff B.","Alleviating catastrophic forgetting via multi-objective learning",2006,"IEEE International Conference on Neural Networks - Conference Proceedings",11,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-40649088885&partnerID=40&md5=5e1898e1be994e56a9e49ff9945e8329","Handling catastrophic forgetting is an interesting and challenging topic in modeling the memory mechanisms of the human brain using machine learning models. From a more general point of view, catastrophic forgetting reflects the stability-plasticity dilemma, which is one of the several dilemmas to be addressed in learning systems: to retain the stored memory while learning new information. Different to the existing approaches, we introduce a Pareto-optimality based multi-objective learning framework for alleviating catastrophic learning. Compared to the single-objective learning methods, multi-objective evolutionary learning with the help of pseudorehearsal is shown to be more promising in dealing with the stability-plasticity dilemma. © 2006 IEEE.",,
"Argyriou A., Hauser R., Micchelli C.A., Pontil M.","A DC-programming algorithm for kernel selection",2006,"ACM International Conference Proceeding Series",31,"10.1145/1143844.1143850","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250779439&doi=10.1145%2f1143844.1143850&partnerID=40&md5=c2c7d9ba26eeb7d794b270f327096980","We address the problem of learning a kernel for a given supervised learning task. Our approach consists in searching within the convex hull of a prescribed set of basic kernels for one which minimizes a convex regularization functional. A unique feature of this approach compared to others in the literature is that the number of basic kernels can be infinite. We only require that they are continuously parameterized. For example, the basic kernels could be isotropic Gaussians with variance in a prescribed interval or even Gaussians parameterized by multiple continuous parameters. Our work builds upon a formulation involving a minimax optimization problem and a recently proposed greedy algorithm for learning the kernel. Although this optimization problem is not convex, it belongs to the larger class of DC (difference of convex functions) programs. Therefore, we apply recent results from DC optimization theory to create a new algorithm for learning the kernel. Our experimental results on benchmark data sets show that this algorithm outperforms a previously proposed method.",,
"Bulitko V., Sturtevant N.","State abstraction for real-time moving target pursuit: A pilot study",2006,"AAAI Workshop - Technical Report",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846012562&partnerID=40&md5=56c6003e902c0e62381aa5c1eb7c20cb","The pursuit of moving targets in real-time environments such as computer games and robotics presents several challenges to situated agents. A priori unknown state spaces and the need to interleave acting and planning limits the applicability of traditional search, learning, and adversarial game-tree search methods. In this paper we build on the previous idea of hierarchical state abstraction, showing how it can be effectively applied to each of the problems in moving target pursuit. First, we develop new algorithms for both chasing agents and target agents that automatically build and refine a hierarchical state abstraction. We then demonstrate the improvements in performance that the state abstraction affords when applied to incremental A* search, learning real-time heuristic search, and minimax adversarial search. Finally, we propose and evaluate a systematic and efficient method of using single-agent techniques in adversarial domains. This leads to a diverse family of new moving target pursuit algorithms which draw on recent advances in single-agent search. In a preliminary empirical evaluation, we demonstrate effects of state abstraction on search and learning in the agents. Copyright © 2006, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.","Computer games; Game-tree search; Machine learning; Search",
"Mariano-Romero C.E., Morales M E.F.","Incremental refinement of solutions for dynamic multi objective optimization problems",2007,"Proceedings - 2007 6th Mexican International Conference on Artificial Intelligence, Special Session, MICAI 2007",1,"10.1109/MICAI.2007.47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57749201592&doi=10.1109%2fMICAI.2007.47&partnerID=40&md5=9cbaf22ebff1e05229774c514e698f2f","MDQL is an algorithm, based on reinforcement learning, for solving multiple objective optimization problems, that has been tested on several applications with promising results [6, 7]. MDQL discretizes the decision variables into a set of states, each associated with actions to move agents to contiguous states. A group of agents explore this state space and are able to find Pareto sets applying a distributed reinforcement learning algorithm. The precision of the Pareto solutions depends on the chosen granularity of the states. A finer granularity on the states creates more precise solutions but at the expense of a larger search space, and consequently the need for more computational resources. In this paper, a very important improvement is introduced into the original MDQL algorithm to incrementally refined the Pareto solutions. The new algorithm, called IMDQL, starts with a coarse granularity to find an initial Pareto set. A vicinity for each of the Pareto solutions in refined and a new Pareto set is founded in this refined state space. This process continues until there is no more improvement within a small threshold value. It is shown that IMDQL not only improves the solutions found by MDQL, but also converges faster. MDQL has also been tested on the solutions of dynamic optimization problems. In this paper, it is also shown that the adaptation capabilities observed in MDQL can be improved with IMDQL. IMDQL was tested on the benchmark problems proposed by Jin [4]. Performance evaluation was made using the Collective Mean Fitness metric proposed by Morrison [10]. IMDQL was compared against an standard evolution strategy with the covariance matrix adaptation (CMA-ES) with very promising results. © 2008 IEEE.",,"IEEE Computer Society"
"Czarnowski I., Jȩdrzejowicz P.","An agent-based approach to the multiple-objective selection of reference vectors",2007,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",7,"10.1007/978-3-540-73499-4_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37249078634&doi=10.1007%2f978-3-540-73499-4_10&partnerID=40&md5=9a0bd35a49730962b798816779225e1f","The paper proposes an agent-based approach to the multipleobjective selection of reference vectors from original datasets. Effective and dependable selection procedures are of vital importance to machine learning and data mining. The suggested approach is based on the multiple agent paradigm. The authors propose using JABAT middleware as a tool and the original instance reduction procedure as a method for selecting reference vectors under multiple objectives. The paper contains a brief introduction to the multiple objective optimization, followed by the formulation of the multiple-objective, agent-based, reference vectors selection optimization problem. Further sections of the paper provide details on the proposed algorithm generating a non-dominated (or Pareto-optimal) set of reference vector sets. To validate the approach the computational experiment has been planned and carried out. Presentation and discussion of experiment results conclude the paper. © Springer-Verlag Berlin Heidelberg 2007.",,"Springer Verlag"
"Tao D., Li X., Wu X., Hu W., Maybank S.J.","Supervised tensor learning",2007,"Knowledge and Information Systems",286,"10.1007/s10115-006-0050-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36148990993&doi=10.1007%2fs10115-006-0050-6&partnerID=40&md5=da4f18cfa573222ac144b65891c9f475","Tensor representation is helpful to reduce the small sample size problem in discriminative subspace selection. As pointed by this paper, this is mainly because the structure information of objects in computer vision research is a reasonable constraint to reduce the number of unknown parameters used to represent a learning model. Therefore, we apply this information to the vector-based learning and generalize the vector-based learning to the tensor-based learning as the supervised tensor learning (STL) framework, which accepts tensors as input. To obtain the solution of STL, the alternating projection optimization procedure is developed. The STL framework is a combination of the convex optimization and the operations in multilinear algebra. The tensor representation helps reduce the overfitting problem in vector-based learning. Based on STL and its alternating projection optimization procedure, we generalize support vector machines, minimax probability machine, Fisher discriminant analysis, and distance metric learning, to support tensor machines, tensor minimax probability machine, tensor Fisher discriminant analysis, and the multiple distance metrics learning, respectively. We also study the iterative procedure for feature extraction within STL. To examine the effectiveness of STL, we implement the tensor minimax probability machine for image classification. By comparing with minimax probability machine, the tensor version reduces the overfitting problem. © Springer-Verlag London Limited 2006.","Alternating projection; Convex optimization; Supervised learning; Tensor","Springer London"
"Zhang Y., Rockett P.","A Comparison of three evolutionary strategies for multiobjective genetic programming",2007,"Artificial Intelligence Review",8,"10.1007/s10462-008-9093-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-55649084793&doi=10.1007%2fs10462-008-9093-2&partnerID=40&md5=4119d199462b4c22a6f2c1d00640d78c","We report what we believe to be the first comparative study of multi-objective genetic programming (GP) algorithms on benchmark symbolic regression and machine learning problems. We compare the Strength Pareto Evolutionary Algorithm (SPEA2), the Non-dominated Sorting Genetic Algorithm (NSGA-II) and the Pareto Converging Genetic Algorithm (PCGA) evolutionary paradigms. As well as comparing the quality of the final solutions, we also examine the speed of convergence of the three evolutionary algorithms. Based on our observations, the SPEA2-based algorithm appears to have problems controlling tree bloat-that is, the uncontrolled growth in the size of the chromosomal tree structures. The NSGA-II-based algorithm on the other hand seems to experience difficulties in locating low error solutions. Overall, the PCGA-based algorithm gives solutions with the lowest errors and the lowest mean complexity. © 2008 Springer Science+Business Media B.V.","Genetic programming; Machine learning; Multiobjective optimisation; Symbolic regression",
"Caponnetto A., De Vito E.","Optimal rates for the regularized least-squares algorithm",2007,"Foundations of Computational Mathematics",310,"10.1007/s10208-006-0196-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548537866&doi=10.1007%2fs10208-006-0196-8&partnerID=40&md5=49ae9df3e02320d45eebb2c204e163f1","We develop a theoretical analysis of the performance of the regularized least-square algorithm on a reproducing kernel Hilbert space in the supervised learning setting. The presented results hold in the general framework of vector-valued functions; therefore they can be applied to multitask problems. In particular, we observe that the concept of effective dimension plays a central role in the definition of a criterion for the choice of the regularization parameter as a function of the number of samples. Moreover, a complete minimax analysis of the problem is described, showing that the convergence rates obtained by regularized least-squares estimators are indeed optimal over a suitable class of priors defined by the considered kernel. Finally, we give an improved lower rate result describing worst asymptotic behavior on individual probability measures rather than over classes of priors. © 2006 Springer.","Learning theory; Least squares; Model selection; Optimal rates",
"Kim K.-H., Choi S.","Neighbor search with global geometry: A minimax message passing algorithm",2007,"ACM International Conference Proceeding Series",18,"10.1145/1273496.1273547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547964789&doi=10.1145%2f1273496.1273547&partnerID=40&md5=7b6ca07f577ac1004784c9dc43a3b50f","Neighbor search is a fundamental task in machine learning, especially in classification and retrieval. Efficient nearest neighbor search methods have been widely studied, with their emphasis on data structures but most of them did not consider the underlying global geometry of a data set. Recent graph-based semi-supervised learning methods capture the global geometry, but suffer from scalability and parameter tuning problems. In this paper we present a (nearest) neighbor search method where the underlying global geometry is incorporated and the parameter tuning is not required. To this end, we introduce deterministic walks as a deterministic counterpart of Markov random walks, leading us to use the minimax distance as a global dissimilarity measure. Then we develop a message passing algorithm for efficient minimax distance calculation, which scales linearly in both time and space. Empirical study reveals the useful behavior of the method in image retrieval and semi-supervised learning.",,
"Mierswa I.","Controlling overfitting with multi-objective support vector machines",2007,"Proceedings of GECCO 2007: Genetic and Evolutionary Computation Conference",20,"10.1145/1276958.1277323","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548099480&doi=10.1145%2f1276958.1277323&partnerID=40&md5=080d3a732a8bd58b74d6f2609d2b4d96","Recently, evolutionary computation has been successfully integrated into statistical learning methods. A Support Vector Machine (SVM) using evolution strategies for its optimization problem frequently deliver better results with respect to the optimization criterion and the prediction accuracy. Moreover, evolutionary computation allows for the efficient large margin optimization of a huge family of new kernel functions, namely non-positive semi definite kernels as the Epanechnikov kernel. For these kernel functions, evolutionary SVM even outperform other learning methods like the Relevance Vector Machine. In this paper, we will discuss another major advantage of evolutionary SVM compared to traditional SVM solutions: we can explicitly optimize the inherent trade-off between training error and model complexity by embedding multi-objective optimization into the evolutionary SVM. This leads to three advantages: first, it is no longer necessary to tune the SVM parameter C which weighs both conflicting criteria. This is a very time-consuming task for traditional SVM. Second, the shape and size of the Pareto front give interesting insights about the complexity of the learning task at hand. Finally, the user can actually see the point where overfitting occurs and can easily select a solution from the Pareto front best suiting his or her needs. Copyright 2007 ACM.","Evolution strategies; Kernel methods; Machine learning; Support vector machines",
"Lichodzijewski P., Heywood M.I.","Pareto-coevolutionary genetic programming for problem decomposition in multi-class classification",2007,"Proceedings of GECCO 2007: Genetic and Evolutionary Computation Conference",17,"10.1145/1276958.1277058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548077217&doi=10.1145%2f1276958.1277058&partnerID=40&md5=e344ec77612799f120752756582d6584","A bid-based approach for coevolving Genetic Programming classifiers is presented. The approach coevolves a population of learners thatdecompose the instance space by way of their aggregate bidding behaviour. To reduce computation overhead, a small, relevant, subsetof training exemplars is (competitively) coevolved alongside the learners. The approach solves multi-class problems using a single population and is evaluated on three large datasets. It is found tobe competitive, especially compared to classifier systems, whilesignificantly reducing the computation overhead associated withtraining. Copyright 2007 ACM.","Classification; Coevolution; Genetic programming; Problem decomposition; Subset selection; Supervised learning; Training efficiency",
"Mariano C.E., Alcocer V.H., Morales E.F.","Incremental refinement of solutions for multiple objective optimization problems",2007,"Proceedings of GECCO 2007: Genetic and Evolutionary Computation Conference",,"10.1145/1276958.1277140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548073388&doi=10.1145%2f1276958.1277140&partnerID=40&md5=19de79e8310ff26a2a76d2fce3d58ab2","MDQL is an algorithm, based on reinforcement learning, for solving multiple objective optimization problems, that has been tested on several applications with promising results [1]. MDQL discretizes the decision variables into a set of states, each associated with actions to move agents to contiguous states. A group of agents explore this state space and are able to find Pareto sets applying a distributed reinforcement learning algorithm. The precision of the Pareto solutions depends on the chosen granularity of the states. A finer granularity on the states creates more precise solutions but at the expense of a larger search space, and consequently the need for more computational resources. An important improvement is presented. The new algorithm, called IMDQL, starts with a coarse granularity to find an initial Pareto set. A vicinity for each of the Pareto solutions in refined and a new Pareto set is founded in this refined state space. It is shown that IMDQL not only improves the solutions found by MDQL, but also converges faster and is capable to approximate dynamic Pareto fronts. The main consideration in the application of IMDQL to dynamic environments is that the agents in the algorithm start from the Pareto solutions obtained. Agents start with a deterministic environment constructed with fixed values for the value functions for the first dynamic parameters; when convergence is reached and a Pareto set is obtained, a new cycle is started, changing to the next value for the dynamic parameters. Agents start searching (adapting solutions) from the existing environments which correspond to the Pareto solutions obtained for the previous value for the dynamic parameters. Searching for new solutions, from the last Pareto set, given the new values for the dynamic parameters, significantly reduces the convergence time. IMDQL is tested on a real water distribution network design involving water-reusing treatment plants and different contaminants concentrations [1]. In this problem, the concentration of contaminants can change over time so the search for optimal solutions becomes a continuous process. It is shown that IMDQL improves on the solutions found by MDQL with fixed concentrations and, that due to its incremental nature, it is able to adequately adjust its Pareto set solutions with dynamic changes in the contaminants con-centrations as long as they are within the vicinity of the previous Pareto set. This is, to our knowledge, the first multi-objective optimization algorithm that is able to dynamically adjust the Pareto set with changing conditions and that can adjust the accuracy of its solutions. The solutions were also compared against MDQL that was compared against a reduced gradient method using a weighted combination of the two objective functions [1], see Figures 1 and 2 for comparisons of Pareto fronts obtained with MDQL, ×, and IMDQL.","Machine learning; Multiobjective optimization",
"Kaplan P.O., Ranjithan S.R.","A new MCDM approach to solve public sector planning problems",2007,"Proceedings of the 2007 IEEE Symposium on Computational Intelligence in Multicriteria Decision Making, MCDM 2007",6,"10.1109/MCDM.2007.369430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548795999&doi=10.1109%2fMCDM.2007.369430&partnerID=40&md5=1e130c52d50c9421df4856a69dbce40d","An interactive multiple criteria decision making method is developed to aid decision makers in public sector planning and management. The method integrates machine learning algorithms along with multiobjective optimization and modeling-to-generate-alternatives procedures into decision analysis. The implicit preferences of the decision maker are elicited through screening of several alternatives. The alternatives are selected from Pareto front and near Pareto front regions that are identified first in the procedure. The decision maker's selections are input to the machine learning algorithms to generate decision rules, which are then incorporated into the analysis to generate more alternatives satisfying the decision rules. The method is illustrated using a municipal solid waste management planning problem. © 2007 IEEE.","Association rule mining; Interactive methods; MCDM; Preference elicitation methods",
"Ng J.K.C., Zhong Y., Yang S.","A comparative study of Minimax Probability Machine-based approaches for face recognition",2007,"Pattern Recognition Letters",13,"10.1016/j.patrec.2007.05.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548677961&doi=10.1016%2fj.patrec.2007.05.021&partnerID=40&md5=57819de56b9f17480cde537b60fce677","Automatic face recognition is a challenging problem in the biometric recognition area. Minimax Probability Machine (MPM) and its extension, Minimum Error Minimax Probability Machine, have shown advantages in the machine learning literature. In this paper, we incorporate the MPM-based approaches into our face recognition system for further study. To test the performance of our new system, we compare the MPM-based approaches with SVM, a PCA-based and a LDA-based algorithms on the FERET database for both verification and identification. The experimental results demonstrate that MPM-based approaches are promising for automatic face recognition. © 2007 Elsevier B.V. All rights reserved.","Face recognition; Minimax Probability Machine; Minimum Error Minimax Probability Machine; Support Vector Machine",
"Cheng W., Hüllermeier E., Seeger B., Vladimirskiy I.","Interactive ranking of skylines using machine learning techniques",2007,"LWA 2007 - Lernen - Wissen - Adaptivitat - Learning, Knowledge, and Adaptivity, Workshop Proceedings",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955277502&partnerID=40&md5=14b3242a6cc87e9bb606f1aa196d8848","So-called skyline queries have received considerable attention in the eld of databases in recent years. Roughly speaking, the skyline of a given set of objects, represented in terms of attributes with preferentially ordered domains, is given by the Pareto-optimal elements of this set. An important problem of Skyline queries is that answer sets can become extremely large. From an application point of view, a system response in terms of a ranking of elements, ordered according to the user's preferences, would hence be more desirable than an unordered set. In this paper, we propose a method for constructing such a ranking in an interactive way. The key idea of our approach is to ask for user feedback on intermediate results, and to use this feedback to improve, via the induction of a latent utility function, the current ranking so as to represent the user's preferences in a more faithful way.",,
"Medeiros T.H., Takahashi R.H.C., Braga A.P.","A new decision strategy in multi-objective training of artificial neural networks",2007,"ESANN 2007 Proceedings - 15th European Symposium on Artificial Neural Networks",6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-65749119086&partnerID=40&md5=c39c1b99a594d3a093329eaaaf5db913","In this work it is presented a new proposal to select a model in the multi-objective training method of the Artificial Neural Network (NN). In order to do this, information from the residue of the Pareto optimal solution is used. The principle to decide for minimum autocorrelation of the data is a criteria that guarantees the extraction of the current information in the noisy data. The experiments show the performance of the proposed DM for variations of the supervised learning problems.",,
"Kim S.-J., Boyd S.","A minimax theorem with applications to machine learning, signal processing, and finance",2007,"Proceedings of the IEEE Conference on Decision and Control",4,"10.1109/CDC.2007.4434853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62749086414&doi=10.1109%2fCDC.2007.4434853&partnerID=40&md5=3d761d41ecb34a11f7cdbce21262050a","This paper concerns a fractional function of the form xTa/ √xTBx, where B is positive definite. We consider the game of choosing x from a convex set, to maximize the function, and choosing (a, B) from a convex set, to minimize it. We prove the existence of a saddle point and describe an efficient method, based on convex optimization, for computing it. We describe applications in machine learning (robust Fisher linear discriminant analysis), signal processing (robust beam-forming, robust matched filtering), and finance (robust portfolio selection). In these applications, x corresponds to some design variables to be chosen, and the pair (a, B) corresponds to the statistical model, which is uncertain. © 2007 IEEE.",,
"Carrijo I.B., Reis L.F.R.","Acquisition of optimal operational strategies for water distribution systems using evolutionary algorithms, machine learning and preference oredering routine",2007,"8th Annual Water Distribution Systems Analysis Symposium 2006",,"10.1061/40941(247)80","https://www.scopus.com/inward/record.uri?eid=2-s2.0-40549131086&doi=10.1061%2f40941%28247%2980&partnerID=40&md5=2db93208c2a9835dc47f5584824f1e90","The efficient operation of a system is a fundamental tool to postpone the system's service life as much as possible, thus ensuring a good service to the consumer while keeping electrical energy and maintenance costs at acceptable levels. Efficient operation requires knowledge of the system, for this knowledge, supported by tools such as models for hydraulic simulation, optimization, and definition of rules, provides the operator with proper conditions for the rational operating of the system's units without depending exclusively on personal experience while maintaining the system's reliability. The purpose of this work is to present a methodology to achieve the optimal operation of water distribution systems, essentially macro systems (skeleton), concerning to the costs of operation and hydraulic benefits. It represents an attempt to provide adequate operation rules in order to minimize cost and maximize hydraulic benefits. Based on the knowledge of the system supported by technical and commercial geo-referenced records, the intention is hydraulically simulate the system using EPANET 2, optimize its operation though multi-objective genetic algorithms (MOGAs) and produce operational rules through machine learning (ML) and the preference ordering routine (POR). In this study an elitist multi-objective genetic algorithm, called strength Pareto evolutionary algorithm (SPEA) is used to obtain a Pareto front. The optimal operation analyses were conducted on the macro water system of the city of Goiania in Brazil. This was in order to minimize the cost of the electrical energy in the pump stations and to maximize the hydraulic benefits in terms of the required pressure at the demand nodes and of adequate reservoir levels. The results show that solutions for satisfactory operation can be quickly produced as a substitute to the personal judgment of the operator. Copyright ASCE 2006.","Genetic algorithms; Machine learning; Multi-objective optimization; Optimal operation; Preference ordering",
"Ishibuchi H., Kuwajima I., Nojima Y.","Prescreening of candidate rules using association rule mining and pareto-optimality in genetic rule selection",2007,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",13,"10.1007/978-3-540-74827-4_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049079730&doi=10.1007%2f978-3-540-74827-4_64&partnerID=40&md5=9a1aed988cb286c417721ec349ddb4ae","Genetic rule selection is an approach to the design of classifiers with high accuracy and high interpretability. It searches for a small number of simple classification rules from a large number of candidate rules. The effectiveness of genetic rule selection strongly depends on the choice of candidate rules. If we have hundreds of thousands of candidate rules, it is very difficult to efficiently search for their good subsets. On the other hand, if we have only a few candidate rules, rule selection does not make sense. In this paper, we examine the use of Pareto-optimal and near Pareto-optimal rules with respect to support and confidence as candidate rules in genetic rule selection. © Springer-Verlag Berlin Heidelberg 2007.","Classifier design; Data mining; Evolutionary multiobjective optimization; Genetic rule selection; Multiobjective machine learning",
"Lichodzijewski P., Heywood M.I.","Managing team-based problem solving with symbiotic bid-based genetic programming",2008,"GECCO'08: Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation 2008",44,"10.1145/1389095.1389162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349174964&doi=10.1145%2f1389095.1389162&partnerID=40&md5=4130aadaaeeae5d4dd5d5cbbabdca4d5","Bid-based Genetic Programming (GP) provides an elegant mechanism for facilitating cooperative problem decomposition without an a priori specification of the number of team members. This is in contrast to existing teaming approaches where individuals learn a direct input-output map (e.g., from exemplars to class labels), allowing the approach to scale to problems with multiple outcomes (classes), while at the same time providing a mechanism for choosing an outcome from those suggested by team members. This paper proposes a symbiotic relationship that continues to support the cooperative bid-based process for problem decomposition while making the credit assignment process much clearer. Specifically, team membership is defined by a team population indexing combinations of GP individuals in a separate team member population. A Pareto-based competitive coevolutionary component enables the approach to scale to large problems by evolving informative test points in a third population. The ensuing Symbiotic Bid-Based (SBB) model is evaluated on three large classification problems and compared to the XCS learning classifier system (LCS) formulation and to the support vector machine (SVM) implementation LIBSVM. On two of the three problems investigated the overall accuracy of the SBB classifiers was found to be competitive with the XCS and SVM results. At the same time, on all problems, the SBB classifiers were able to detect instances of all classes whereas the XCS and SVM models often ignored exemplars of minor classes. Moreover, this was achieved with a level of model complexity significantly lower than that identified by the SVM and XCS solutions. Copyright 2008 ACM.","Active learning; Classification; Coevolution; Efficiency; Genetic programming; Problem decomposition; Supervised learning; Teaming","Association for Computing Machinery (ACM)"
"Dos Santos E.M., Sabourin R., Maupin P.","Pareto analysis for the selection of classifier ensembles",2008,"GECCO'08: Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation 2008",10,"10.1145/1389095.1389229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349172056&doi=10.1145%2f1389095.1389229&partnerID=40&md5=5a2bf54bc8f829a801a84e3aee3fb841","The overproduce-and-choose strategy involves the generation of an initial large pool of candidate classifiers and it is intended to test different candidate ensembles in order to select the best performing solution. The ensemble's error rate, ensemble size and diversity measures are the most frequent search criteria employed to guide this selection. By applying the error rate, we may accomplish the main objective in Pattern Recognition and Machine Learning, which is to find high-performance predictors. In terms of ensemble size, the hope is to increase the recognition rate while minimizing the number of classifiers in order to meet both the performance and low ensemble size requirements. Finally, ensembles can be more accurate than individual classifiers only when classifier members present diversity among themselves. In this paper we apply two Pareto front spread quality measures to analyze the relationship between the three main search criteria used in the overproduce-and-choose strategy. Experimental results conducted demonstrate that the combination of ensemble size and diversity does not produce conflicting multi-objective optimization problems. Moreover, we cannot decrease the generalization error rate by combining this pair of search criteria. However, when the error rate is combined with diversity or the ensemble size, we found that these measures are conflicting objective functions and that the performances of the solutions are much higher. Copyright 2008 ACM.","Classifier ensembles; Diversity measures; Ensemble selection; Pareto analysis","Association for Computing Machinery (ACM)"
"Robles V., Bielza C., Larrañaga P., González S., Ohno-Machado L.","Optimizing logistic regression coefficients for discrimination and calibration using estimation of distribution algorithms",2008,"TOP",6,"10.1007/s11750-008-0054-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-56249124589&doi=10.1007%2fs11750-008-0054-3&partnerID=40&md5=a9c52f981504ba7f1158ab03144b2a46","Logistic regression is a simple and efficient supervised learning algorithm for estimating the probability of an outcome or class variable. In spite of its simplicity, logistic regression has shown very good performance in a range of fields. It is widely accepted in a range of fields because its results are easy to interpret. Fitting the logistic regression model usually involves using the principle of maximum likelihood. The Newton-Raphson algorithm is the most common numerical approach for obtaining the coefficients maximizing the likelihood of the data. This work presents a novel approach for fitting the logistic regression model based on estimation of distribution algorithms (EDAs), a tool for evolutionary computation. EDAs are suitable not only for maximizing the likelihood, but also for maximizing the area under the receiver operating characteristic curve (AUC). Thus, we tackle the logistic regression problem from a double perspective: likelihood-based to calibrate the model and AUC-based to discriminate between the different classes. Under these two objectives of calibration and discrimination, the Pareto front can be obtained in our EDA framework. These fronts are compared with those yielded by a multiobjective EDA recently introduced in the literature. © Sociedad de Estadística e Investigación Operativa 2008.","Calibration and discrimination; Estimation of distribution algorithms; Evolutionary algorithms; Logistic regression","Springer Verlag"
"Alatas B., Akin E., Karci A.","MODENAR: Multi-objective differential evolution algorithm for mining numeric association rules",2008,"Applied Soft Computing Journal",170,"10.1016/j.asoc.2007.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548472851&doi=10.1016%2fj.asoc.2007.05.003&partnerID=40&md5=8726e318d0b7bda683ffa1e3e29310af","In this paper, a Pareto-based multi-objective differential evolution (DE) algorithm is proposed as a search strategy for mining accurate and comprehensible numeric association rules (ARs) which are optimal in the wider sense that no other rules are superior to them when all objectives are simultaneously considered. The proposed DE guided the search of ARs toward the global Pareto-optimal set while maintaining adequate population diversity to capture as many high-quality ARs as possible. ARs mining problem is formulated as a four-objective optimization problem. Support, confidence value and the comprehensibility of the rule are maximization objectives while the amplitude of the intervals which conforms the itemset and rule is minimization objective. It has been designed to simultaneously search for intervals of numeric attributes and the discovery of ARs which these intervals conform in only single run of DE. Contrary to the methods used as usual, ARs are directly mined without generating frequent itemsets. The proposed DE performs a database-independent approach which does not rely upon the minimum support and the minimum confidence thresholds which are hard to determine for each database. The efficiency of the proposed DE is validated upon synthetic and real databases. © 2007 Elsevier B.V. All rights reserved.","Data mining; Differential evolution; Evolutionary computation; Machine learning; Multi-objective optimization",
"Peng X., King I.","Robust BMPM training based on second-order cone programming and its application in medical diagnosis",2008,"Neural Networks",23,"10.1016/j.neunet.2007.12.051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-40649114452&doi=10.1016%2fj.neunet.2007.12.051&partnerID=40&md5=f6fd2062333a2d352a9bdaea3c116d0a","The Biased Minimax Probability Machine (BMPM) constructs a classifier which deals with the imbalanced learning tasks. It provides a worst-case bound on the probability of misclassification of future data points based on reliable estimates of means and covariance matrices of the classes from the training data samples, and achieves promising performance. In this paper, we develop a novel yet critical extension training algorithm for BMPM that is based on Second-Order Cone Programming (SOCP). Moreover, we apply the biased classification model to medical diagnosis problems to demonstrate its usefulness. By removing some crucial assumptions in the original solution to this model, we make the new method more accurate and robust. We outline the theoretical derivatives of the biased classification model, and reformulate it into an SOCP problem which could be efficiently solved with global optima guarantee. We evaluate our proposed SOCP-based BMPM (BMPMSOCP) scheme in comparison with traditional solutions on medical diagnosis tasks where the objectives are to focus on improving the sensitivity (the accuracy of the more important class, say ""ill"" samples) instead of the overall accuracy of the classification. Empirical results have shown that our method is more effective and robust to handle imbalanced classification problems than traditional classification approaches, and the original Fractional Programming-based BMPM (BMPMFP). © 2008 Elsevier Ltd. All rights reserved.","Biased minimax probability machine; Medical diagnosis; Second-order cone programming",
"Ishibuchi H., Kuwajima I., Nojima Y.","Evolutionary multi-objective rule selection for classification rule mining",2008,"Studies in Computational Intelligence",8,"10.1007/978-3-540-77467-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-40449103702&doi=10.1007%2f978-3-540-77467-9_3&partnerID=40&md5=f6eb88937d2711c23fa49a6d07c94732","This chapter discusses the application of evolutionary multi-objective optimization (EMO) to classification rule mining. In the field of classification rule mining, classifiers are designed through the following two phases: rule discovery and rule selection. In the rule discovery phase, a large number of classification rules are extracted from training data. This phase is based on two rule evaluation criteria: support and confidence. An association rule mining technique such as Apriori is usually used to extract classification rules satisfying pre-specified threshold values of the minimum support and confidence. In some studies, EMO algorithms were used to search for Pareto-optimal rules with respect to support and confidence. On the other hand, a small number of rules are selected from the extracted rules to design an accurate and compact classifier in the rule selection phase. A heuristic rule sorting criterion is usually used for rule selection. In some studies, EMO algorithms were used for multi-objective rule selection to maximize the accuracy of rule sets and minimize their complexity. In this chapter, first we explain the above-mentioned two phases in classification rule mining. Next we explain the search for Pareto-optimal rules and the search for Pareto-optimal rule sets. Then we explain evolutionary multi-objective rule selection as a post processing procedure in the second phase of classification rule mining. A number of Pareto-optimal rule sets are found from a large number of candidate rules, which are extracted from training data in the first phase. Finally we show experimental results on some data sets from the UCI machine learning repository. Through computational experiments, we demonstrate that evolutionary rule selection can drastically decrease the number of extracted rules without severely degrading their classification accuracy. We also examine the relation between Paretooptimal rules and Pareto- optimal rule sets. © 2008 Springer-Verlag Berlin Heidelberg.",,
"Pulkkinen P., Koivisto H.","Fuzzy classifier identification using decision tree and multiobjective evolutionary algorithms",2008,"International Journal of Approximate Reasoning",84,"10.1016/j.ijar.2007.10.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-42649122303&doi=10.1016%2fj.ijar.2007.10.004&partnerID=40&md5=fe75e8634007b47312165d5d71d75dc7","This paper presents a hybrid method for identification of Pareto-optimal fuzzy classifiers (FCs). In contrast to many existing methods, the initial population for multiobjective evolutionary algorithms (MOEAs) is neither created randomly nor a priori knowledge is required. Instead, it is created by the proposed two-step initialization method. First, a decision tree (DT) created by C4.5 algorithm is transformed into an FC. Therefore, relevant variables are selected and initial partition of input space is performed. Then, the rest of the population is created by randomly replacing some parameters of the initial FC, such that, the initial population is widely spread. That improves the convergence of MOEAs into the correct Pareto front. The initial population is optimized by NSGA-II algorithm and a set of Pareto-optimal FCs representing the trade-off between accuracy and interpretability is obtained. The method does not require any a priori knowledge of the number of fuzzy sets, distribution of fuzzy sets or the number of relevant variables. They are all determined by it. Performance of the obtained FCs is validated by six benchmark data sets from the literature. The obtained results are compared to a recently published paper [H. Ishibuchi, Y. Nojima, Analysis of interpretability-accuracy tradeoff of fuzzy systems by multiobjective fuzzy genetics-based machine learning, International Journal of Approximate Reasoning 44 (1) (2007) 4-31] and the benefits of our method are clearly shown. © 2007 Elsevier Inc. All rights reserved.","Decision trees (DTs); Fuzzy classifiers (FCs); Initialization; Multiobjective evolutionary algorithms (MOEAs)",
"Barton A.J., Valdés J.J.","Hybrid unsupervised/supervised virtual reality spaces for visualizing gastric and liver cancer databases: An evolutionary computation approach",2008,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-540-68123-6_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44649139855&doi=10.1007%2f978-3-540-68123-6_28&partnerID=40&md5=3bb9fa0f08382ec10b368a36098ea174","This paper expands a multi-objective optimization approach to the problem of computing virtual reality spaces for the visual representation of relational structures (e.g. databases), symbolic knowledge and others, in the context of visual data mining and knowledge discovery. Procedures based on evolutionary computation are discussed. In particular, the NSGA-II algorithm is used as a framework for an instance of this methodology; simultaneously minimizing Sammon's error for dissimilarity measures, and mean cross-validation error on a k-nn pattern classifier. The proposed approach is illustrated with two examples from cancer genomics data (e.g. gastric and liver cancer) by constructing virtual reality spaces resulting from multi-objective optimization. Selected solutions along the Pareto front approximation are used as nonlinearly transformed features for new spaces that compromise similarity structure preservation (from an unsupervised perspective) and class separability (from a supervised pattern recognition perspective), simultaneously. The possibility of spanning a range of solutions between these two important goals, is a benefit for the knowledge discovery and data understanding process. The quality of the set of discovered solutions is superior to the ones obtained separately, from the point of view of visual data mining. © 2008 Springer-Verlag Berlin Heidelberg.",,
"Mu X., Tang N., Gao W., Li L., Zhou Y.","A one-step network traffic prediction",2008,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",5,"10.1007/978-3-540-85984-0_74","https://www.scopus.com/inward/record.uri?eid=2-s2.0-53049106082&doi=10.1007%2f978-3-540-85984-0_74&partnerID=40&md5=e272e282dcc527193b35f4b728a14e91","In the information society today computer networks are an indispensable part of people's life. Network traffic prediction is important to network planning, performance evaluation and network management directly. A variety of machine learning models such as artificial neural networks (ANN) and support vector machine (SVM) have been applied in traffic prediction. In this paper, a novel network traffic one-step-ahead prediction technique is proposed based on a state-of-the-art learning model called minimax probability machine (MPM). The predictive performance is tested on traffic data of Ethernet, experimental results show that the predictions of MPM match the actual traffics accurately and the proposed methods can increases the computational efficiency. Furthermore, we compare the MPM-based prediction technique with the SVM-based techniques. The results show that the predictive performance of MPM is competitive with SVM. © 2008 Springer-Verlag Berlin Heidelberg.","Minimax Probability Machine; Network Traffic; Prediction; Support Vector Machine",
"Qian X., Zhang X., Jiao L., Ma W.","Unsupervised texture image segmentation using multiobjective evolutionary clustering ensemble algorithm",2008,"2008 IEEE Congress on Evolutionary Computation, CEC 2008",11,"10.1109/CEC.2008.4631279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-55749084335&doi=10.1109%2fCEC.2008.4631279&partnerID=40&md5=0f5322fe99b8d092fe22f4a8fc604b2a","Multiobjective evolutionary clustering approach has been successfully utilized in data clustering. In this paper, we propose a novel unsupervised machine learning algorithm namely multiobjective evolutionary clustering ensemble algorithm (MECEA) to perform the texture image segmentation, MECEA comprises two main phases. In the first phase, MECEA uses a multiobjective evolutionary clustering algorithm to optimize two complementary clustering objectives: one based on compactness in the same cluster, and the other based on connectedness of different clusters. The output of the first phase is a set of Pareto solutions, which correspond to different tradeoffs between two clustering objectives, and different numbers of clusters. In the second phase, we make use of the meta-clustering algorithm (MCLA) to combine all the Pareto solutions to get the final segmentation. The segmentation results are evaluated by comparing with three known algorithms: K-means, fuzzy K-means (FCM), and evolutionary clustering algorithm (ECA). It is shown that MECEA is an adaptive clustering algorithm, which outperforms the three algorithms in the experiments we carried out. © 2008 IEEE.",,
"Zhang D.","Machine learning and value-based software engineering: A research agenda",2008,"20th International Conference on Software Engineering and Knowledge Engineering, SEKE 2008",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886938932&partnerID=40&md5=3bc17f0556c2f57e447f430b871fd95b","Software engineering research and practice thus far are primarily conducted in a value-neutral setting where each artifact in software development such as requirement, use case, test case, and defect, is treated as equally important during a software system development process. There are a number of shortcomings of such value-neutral software engineering. Value-based software engineering is to integrate value considerations into the full range of existing and emerging software engineering principles and practices. Machine learning has been playing an increasingly important role in helping develop and maintain large and complex software systems. However, machine learning applications to software engineering have been largely confined to the value-neutral software engineering setting. In this paper, the general message to be conveyed is to apply machine learning methods and algorithms to value-based software engineering. The training data or the background knowledge or domain theory or heuristics or bias used by machine learning methods in generating target models or functions should be aligned with stakeholders' value propositions. An initial research agenda is proposed for machine learning in value-based software engineering.","Machine learning; Pareto modules; Stakeholder value propositions; Value-based software engineering",
"Kim S.-J., Boyd S.","A minimax theorem with applications to machine learning, signal processing, and finance",2008,"SIAM Journal on Optimization",42,"10.1137/060677586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69649090538&doi=10.1137%2f060677586&partnerID=40&md5=a6cbedb4c748b2ba5fed0a419ae65d05","This paper concerns a fractional function of the form xTa/ √xTBx, where B is positive definite. We consider the game of choosing x from a convex set, to maximize the function, and choosing (a, B) from a convex set, to minimize it. We prove the existence of a saddle point and describe an efficient method, based on convex optimization, for computing it. We describe applications in machine learning (robust Fisher linear discriminant analysis), signal processing (robust beamforming and robust matched filtering), and finance (robust portfolio selection). In these applications, x corresponds to some design variables to be chosen, and the pair (a, B) corresponds to the statistical model, which is uncertain. © 2008 Society for Industrial and Applied Mathematics.","Convex optimization; Minimax theorem; Robust optimization",
"Gomes E.R., Kowalczyk R.","Non-symmetric preferences in the IPA market with Reinforcement Learning",2008,"Proceedings - 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2008",,"10.1109/WIIAT.2008.77","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949185076&doi=10.1109%2fWIIAT.2008.77&partnerID=40&md5=5a70827de2f42104537b584cad6f3a14","Machine Learning has been proposed to support and optimize market-based resource allocation. In particular, Reinforcement Learning (RL) has been used to improve the allocation in terms of the utility received by resource requesting agents in the Iterative Price Adjustment (IPA) mechanism. In such an approach, utility functions describe the agents' preferences for resource attributes and are the basis for RL to learn demand functions that are optimized for the market. It has been shown that the reward functions based on the individual utility of the agents and the social welfare of the allocation can deliver similar social results when the market consists only of learning agents with symmetric preferences. In this paper we investigate the IPA market-based resource allocation with RL for the case of agents with non-symmetric preferences. We show through experimental investigation that the results observed above are also held in this case. In particular, we show that the individual-based reward function is able to approximate the solution to the fairest Pareto-Optimal allocation in situations where the social-based reward function fails. © 2008 IEEE.",,
"Kokshenev I., Braga A.P.","A multi-objective learning algorithm for RBF neural network",2008,"Proceedings - 10th Brazilian Symposium on Neural Networks, SBRN 2008",3,"10.1109/SBRN.2008.39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049220856&doi=10.1109%2fSBRN.2008.39&partnerID=40&md5=b848569c67c1ddeb3d41399e6e1fcee8","In this paper, the problem of multi-objective supervised learning is discussed within the non-evolutionary optimization framework. The proposed MOBJ learning algorithm performs the search of Pareto-optimal models determining weights, width, prototype vectors, and the quantity of basis functions of the RBF network. In combination with the Akaike information criterion, the algorithm provides high quality solutions. © 2008 IEEE.",,
"De Carvalho A.B., Pozo A., Vergilio S., Lenz A.","Predicting fault proneness of classes trough a multiobjective particle swarm optimization algorithm",2008,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",24,"10.1109/ICTAI.2008.76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57649221639&doi=10.1109%2fICTAI.2008.76&partnerID=40&md5=5e7c70a2357a87a315d670284dc038b3","Software testing is a fundamental software engineering activity for quality assurance that is also traditionally very expensive. To reduce efforts of testing strategies, some design metrics have been used to predict the fault-proneness of a software class or module. Recent works have explored the use of Machine Learning (ML) techniques for fault prediction. However most used ML techniques can not deal with unbalanced data and their results usually have a difficult interpretation. Because of this, this paper introduces a Multi-Objective Particle Swarm Optimization (MOPSO) algorithm for fault prediction. It allows the creation of classifiers composed by rules with specific properties by exploring Pareto dominance concepts. These rules are more intuitive and easier to understand because they can be interpreted independently one of each other. Furthermore, an experiment using the approach is presented and the results are compared to the other techniques explored in the area. ©2008 IEEE.",,
"Santana-Quintero L.V., Coello Coello C.A., Hernández-Díaz A.G., Velázquez J.M.O.","Surrogate-based multi-objective particle swarm optimization",2008,"2008 IEEE Swarm Intelligence Symposium, SIS 2008",10,"10.1109/SIS.2008.4668300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57649158486&doi=10.1109%2fSIS.2008.4668300&partnerID=40&md5=71b236858d921705ece7a79de225dc0d","This paper presents a new algorithm that approximates real function evaluations using supervised learning with a surrogate method called support vector machine (SVM). We perform a comparative study among different leader selection schemes in a Multi-Objective Particle Swarm Optimizer (MOPSO), in order to determine the most appropriate approach to be adopted for solving the sort of problems of our interest. The resulting hybrid presents a poor spread of solutions, which motivates the introduction of a second phase to our algorithm, in which an approach called rough sets is adopted in order to improve the spread of solutions along the Pareto front. Rough sets are used as a local search engine, which is able to generate solutions in the neighborhood of the nondominated solutions previously generated by the surrogate-based algorithm. The resulting approach is able to generate reasonably good approximations of the Pareto front of problems of up to 30 decision variables with only 2,000 fitness function evaluations. Our results are compared with respect to the NSGA-II, which is a multi-objective evolutionary algorithm representative of the state-of-the-art in the area. ©2008 IEEE.","Hybrid algorithms; Multi-objective optimization; PSO; Rough sets; Support vector machines; Surrogates",
"Maulik U., Mukhopadhyay A., Bandyopadhyay S.","Combining Pareto-optimal clusters using supervised learning for identifying co-expressed genes",2009,"BMC Bioinformatics",89,"10.1186/1471-2105-10-27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949240361&doi=10.1186%2f1471-2105-10-27&partnerID=40&md5=44dd059fecbce27835bc0d329ad5d323","Background: The landscape of biological and biomedical research is being changed rapidly with the invention of microarrays which enables simultaneous view on the transcription levels of a huge number of genes across different experimental conditions or time points. Using microarray data sets, clustering algorithms have been actively utilized in order to identify groups of co-expressed genes. This article poses the problem of fuzzy clustering in microarray data as a multiobjective optimization problem which simultaneously optimizes two internal fuzzy cluster validity indices to yield a set of Pareto-optimal clustering solutions. Each of these clustering solutions possesses some amount of information regarding the clustering structure of the input data. Motivated by this fact, a novel fuzzy majority voting approach is proposed to combine the clustering information from all the solutions in the resultant Pareto-optimal set. This approach first identifies the genes which are assigned to some particular cluster with high membership degree by most of the Pareto-optimal solutions. Using this set of genes as the training set, the remaining genes are classified by a supervised learning algorithm. In this work, we have used a Support Vector Machine (SVM) classifier for this purpose. Results: The performance of the proposed clustering technique has been demonstrated on five publicly available benchmark microarray data sets, viz., Yeast Sporulation, Yeast Cell Cycle, Arabidopsis Thaliana, Human Fibroblasts Serum and Rat Central Nervous System. Comparative studies of the use of different SVM kernels and several widely used microarray clustering techniques are reported. Moreover, statistical significance tests have been carried out to establish the statistical superiority of the proposed clustering approach. Finally, biological significance tests have been carried out using a web based gene annotation tool to show that the proposed method is able to produce biologically relevant clusters of co-expressed genes. Conclusion: The proposed clustering method has been shown to perform better than other well-known clustering algorithms in finding clusters of co-expressed genes efficiently. The clusters of genes produced by the proposed technique are also found to be biologically significant, i.e., consist of genes which belong to the same functional groups. This indicates that the proposed clustering method can be used efficiently to identify co-expressed genes in microarray gene expression data. © 2009 Maulik et al; licensee BioMed Central Ltd.",,
"Jin Y., Gruna R., Sendhoff B.","Pareto analysis of evolutionary and learning systems",2009,"Frontiers of Computer Science in China",5,"10.1007/s11704-009-0004-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62349092355&doi=10.1007%2fs11704-009-0004-8&partnerID=40&md5=23a485d36b22ce7da63294433e106507","This paper attempts to argue that most adaptive systems, such as evolutionary or learning systems, have inherently multiple objectives to deal with. Very often, there is no single solution that can optimize all the objectives. In this case, the concept of Pareto optimality is key to analyzing these systems. To support this argument, we first present an example that considers the robustness and evolvability trade-off in a redundant genetic representation for simulated evolution. It is well known that robustness is critical for biological evolution, since without a sufficient degree of mutational robustness, it is impossible for evolution to create new functionalities. On the other hand, the genetic representation should also provide the chance to find new phenotypes, i.e., the ability to innovate. This example shows quantitatively that a trade-off between robustness and innovation does exist in the studied redundant representation. Interesting results will also be given to show that new insights into learning problems can be gained when the concept of Pareto optimality is applied to machine learning. In the first example, a Pareto-based multi-objective approach is employed to alleviate catastrophic forgetting in neural network learning. We show that learning new information and memorizing learned knowledge are two conflicting objectives, and a major part of both information can be memorized when the multi-objective learning approach is adopted. In the second example, we demonstrate that a Pareto-based approach can address neural network regularizationmore elegantly. By analyzing the Pareto-optimal solutions, it is possible to identifying interesting solutions on the Pareto front. © 2009 Higher Education Press and Springer-Verlag GmbH.","Accuracy; Complexity; Evolution; Evolvability; Learning; Multi-objective optimization; Pareto analysis; Robustness",
"Frénay B., Saerens M.","QL2, a simple reinforcement learning scheme for two-player zero-sum Markov games",2009,"Neurocomputing",4,"10.1016/j.neucom.2008.12.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62249147593&doi=10.1016%2fj.neucom.2008.12.022&partnerID=40&md5=8a04ce20b197ccf38d23c64ca0ed8e45","Markov games is a framework which can be used to formalise n-agent reinforcement learning (RL). Littman (Markov games as a framework for multi-agent reinforcement learning, in: Proceedings of the 11th International Conference on Machine Learning (ICML-94), 1994.) uses this framework to model two-agent zero-sum problems and, within this context, proposes the minimax-Q algorithm. This paper reviews RL algorithms for two-player zero-sum Markov games and introduces a new, simple, fast, algorithm, called QL2. QL2 is compared to several standard algorithms (Q-learning, Minimax and minimax-Q) implemented with the Q ash library written in Python. The experiments show that QL2 converges empirically to optimal mixed policies, as minimax-Q, but uses a surprisingly simple and cheap updating rule. © 2009 Elsevier B.V. All rights reserved.","Markov games; Multi-agent; Q-Learning; Reinforcement learning; Two-player zero-sum games",
"Peng X., King I.","A biased minimax probability machine-based scheme for relevance feedback in image retrieval",2009,"Neurocomputing",10,"10.1016/j.neucom.2008.11.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-61849120803&doi=10.1016%2fj.neucom.2008.11.020&partnerID=40&md5=b4bb500631c00a4f2fa325b051d4db5a","In recent years, minimax probability machines (MPMs) have demonstrated excellent performance in a variety of pattern recognition problems. At the same time various machine learning methods have been applied on relevance feedback tasks in content-based image retrieval (CBIR). One of the problems in typical techniques for relevance feedback is that they treat the relevant feedback and irrelevant feedback equally. Since the negative instances largely outnumber the positive instances, the assumption that they are balanced is incorrect as the data are biased. In this paper we study how biased minimax probability machine (BMPM), a variation of MPM, can be applied for relevance feedback in image retrieval tasks. Different from previous methods, this model directly controls the accuracy of classification of the future data to construct biased classifiers. Hence, it provides a rigorous treatment on imbalanced dataset. Mathematical formulation and explanations are provided to demonstrate the advantages. Experiments are conducted to evaluate the performance of our proposed framework, in which encouraging and promising experimental results are obtained. Crown Copyright © 2008.","Biased minimax probability machine; Content-based image retrieval; Relevance feedback",
"Handley C.M., Hawe G.I., Kell D.B., Popelier P.L.A.","Optimal construction of a fast and accurate polarisable water potential based on multipole moments trained by machine learning",2009,"Physical Chemistry Chemical Physics",100,"10.1039/b905748j","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68949154402&doi=10.1039%2fb905748j&partnerID=40&md5=da9fa3bbf2b8dcdd2ee866bac26ed19a","To model liquid water correctly and to reproduce its structural, dynamic and thermodynamic properties warrants models that account accurately for electronic polarisation. We have previously demonstrated that polarisation can be represented by fluctuating multipole moments (derived by quantum chemical topology) predicted by multilayer perceptrons (MLPs) in response to the local structure of the cluster. Here we further develop this methodology of modeling polarisation enabling control of the balance between accuracy, in terms of errors in Coulomb energy and computing time. First, the predictive ability and speed of two additional machine learning methods, radial basis function neural networks (RBFNN) and Kriging, are assessed with respect to our previous MLP based polarisable water models, for water dimer, trimer, tetramer, pentamer and hexamer clusters. Compared to MLPs, we find that RBFNNs achieve a 14-26% decrease in median Coulomb energy error, with a factor 2.5-3 slowdown in speed, whilst Kriging achieves a 40-67% decrease in median energy error with a 6.5-8.5 factor slowdown in speed. Then, these compromises between accuracy and speed are improved upon through a simple multi-objective optimisation to identify Pareto-optimal combinations. Compared to the Kriging results, combinations are found that are no less accurate (at the 90th energy error percentile), yet are 58% faster for the dimer, and 26% faster for the pentamer. © 2009 the Owner Societies.",,
"Qasem S.N., Shamsuddin S.M.H.","Radial basis function network based on multi-objective particle swarm optimization",2009,"2009 6th International Symposium on Mechatronics and its Applications, ISMA 2009",12,"10.1109/ISMA.2009.5164833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449644583&doi=10.1109%2fISMA.2009.5164833&partnerID=40&md5=5f1f6ec5d5dfcc6dfc4560540b20c3d3","The problem of unsupervised and supervised learning is discussed within the context of multi-objective optimization. In this paper, an evolutionary multi-objective selection method of RBF Networks structure is discussed. The candidates of RBF Network structure are encoded into the particles in PSO. Then, they evolve toward Pareto-optimal front defined by several objective functions concerning with model accuracy and model complexity. This study suggests an approach of RBF Network training through simultaneous optimization of architectures and weights with PSO-based multi-objective algorithm. Our goal is to determine whether Multi-objective PSO can train RBF Networks, and the performance is validated on accuracy and complexity. The experiments are conducted on benchmark datasets obtained from the UCI machine learning repository. The results show that our proposed method provides an effective means for training RBF Networks that is competitive with other evolutionary computational-based methods. © 2009 IEEE.",,
"Lafferty J., Wasserman L.","Statistical analysis of semi-supervised regression",2009,"Advances in Neural Information Processing Systems 20 - Proceedings of the 2007 Conference",49,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858784195&partnerID=40&md5=e6908c727990743e058a34d2d8b2ac5e","Semi-supervised methods use unlabeled data in addition to labeled data to construct predictors. While existing semi-supervised methods have shown some promising empirical performance, their development has been based largely based on heuristics. In this paper we study semi-supervised learning from the viewpoint of minimax theory. Our first result shows that some common methods based on regularization using graph Laplacians do not lead to faster minimax rates of convergence. Thus, the estimators that use the unlabeled data do not have smaller risk than the estimators that use only labeled data. We then develop several new approaches that provably lead to improved performance. The statistical tools of minimax analysis are thus used to offer some new perspective on the problem of semi-supervised learning.",,
"Agarwal A., Bartlett P., Ravikumar P., Wainwright M.J.","Information-theoretic lower bounds on the oracle complexity of convex optimization",2009,"Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference",55,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053968588&partnerID=40&md5=dbb48f12b338b369ec4b558e053f8e7b","Despite a large literature on upper bounds on complexity of convex optimization, relatively less attention has been paid to the fundamental hardness of these problems. Given the extensive use of convex optimization in machine learning and statistics, gaining a understanding of these complexity-theoretic issues is important. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We improve upon known results and obtain tight minimax complexity estimates for various function classes. We also discuss implications of these results for the understanding the inherent complexity of large-scale learning and estimation problems.",,
"Jones L.K.","Local minimax learning of functions with best finite sample estimation error bounds: Applications to ridge and lasso regression, boosting, tree learning, kernel machines, and inverse problems",2009,"IEEE Transactions on Information Theory",9,"10.1109/TIT.2009.2027479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955634773&doi=10.1109%2fTIT.2009.2027479&partnerID=40&md5=33dd910a40d7ba6b3794ecaf62b9e9c0","Optimal local estimation is formulated in the minimax sense for inverse problems and nonlinear regression. This theory provides best mean squared finite sample error bounds for some popular statistical learning algorithms and also for several optimal improvements of other existing learning algorithms such as smoothing splines and kernel regularization. The bounds and improved algorithms are not based on asymptotics or Bayesian assumptions and are truly local for each query, not depending on cross validating estimates at other queries to optimize modeling parameters. Results are given for optimal local learning of approximately linear functions with side information (context) using real algebraic geometry. In particular, finite sample error bounds are given for ridge regression and for a local version of lasso regression. The new regression methods require only quadratic programming with linear or quadratic inequality constraints for implementation. Greedy additive expansions are then combined with local minimax learning via a change in metric. An optimal strategy is presented for fusing the local minimax estimators of a class of experts-providing optimal finite sample prediction error bounds from (random) forests. Local minimax learning is extended to kernel machines. Best local prediction error bounds for finite samples are given for Tikhonov regularization. The geometry of reproducing kernel Hilbert space is used to derive improved estimators with finite sample mean squared error (MSE) bounds for class membership probability in two class pattern classification problems. A purely local, cross validation free algorithm is proposed which uses Fisher information with these bounds to determine best local kernel shape in vector machine learning. Finally, a locally quadratic solution to the finite Fourier moments problem is presented. After reading the first three sections the reader may proceed directly to any of the subsequent applications sections. © 2009 IEEE.","Fusion; Inverse problem; Minimax; Reproducing kernel; Ridge regression",
"Fernández J.C., Hervás C., Martínez F.J., Cruz M.","Design of artificial neural networks using a memetic pareto evolutionary algorithm using as objectives entropy versus variation coefficient",2009,"ISDA 2009 - 9th International Conference on Intelligent Systems Design and Applications",,"10.1109/ISDA.2009.153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949498372&doi=10.1109%2fISDA.2009.153&partnerID=40&md5=572f6042c1391ba23894b6dc36594def","This paper proposes a multi-classification pattern algorithm using multilayer perceptron neural network models which try to boost two conflicting main objectives of a classifier, a high correct classification rate and a high classification rate for each class. To solve this machine learning problem, we consider a Memetic Pareto Evolutionary approach based on the 2SGA2 algorithm (MPE2SGA2), where we defined two objectives for determining the goodness of a classifier: the cross-entropy error function and the variation coefficient of its sensitivities, because both measures are continuous functions, making the convergence more robust. Once the Pareto front is built, we use an automatic selection methodology of individuals: the best model in accuracy (upper extreme in the Pareto front). This methodology is applied to solve six benchmark classification problems, obtaining promising results and achieving a high classification rate in the generalization set with an acceptable level of accuracy for each class. © 2009 IEEE.",,
"Qasem S.N., Shamsuddin S.M.Hj.","Improving generalization of radial basis function network with adaptive multi-objective particle swarm optimization",2009,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",5,"10.1109/ICSMC.2009.5346876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74849129598&doi=10.1109%2fICSMC.2009.5346876&partnerID=40&md5=d3cc2e57291aae8090f05ba0de292866","In this paper, an adaptive evolutionary multiobjective selection method of RBF Networks structure is discussed. The candidates of RBF Network structures are encoded into particles in Particle Swarm Optimization (PSO). These particles evolve toward Pareto-optimal front defined by several objective functions with model accuracy and complexity. The problem of unsupervised and supervised learning is discussed with Adaptive Multi-Objective PSO (AMOPSO). This study suggests an approach of RBF Network training through simultaneous optimization of architectures and weights with Adaptive PSO-based multi-objective algorithm. Our goal is to determine whether Adaptive Multi-objective PSO can train RBF Networks, and the performance is validated on accuracy and complexity. The experiments are conducted on two benchmark datasets obtained from the machine learning repository. The results show that our proposed method provides an effective means for training RBF Networks that is competitive with PSO-based multi-objective algorithm. ©2009 IEEE.","Adaptive multiobjective particle swarm optimization; Multi-objective particle swarm optimization; Radial basis function network",
"Ishibuchi H., Nakashima Y., Nojima Y.","Search ability of evolutionary multiobjective optimization algorithms for multiobjective fuzzy genetics-based machine learning",2009,"IEEE International Conference on Fuzzy Systems",9,"10.1109/FUZZY.2009.5277370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71249138212&doi=10.1109%2fFUZZY.2009.5277370&partnerID=40&md5=6fe8b8c30d59d2775d030f46400c8918","Recently evolutionary multiobjective optimization (EMO) algorithms have been actively used for the design of accurate and interpretable fuzzy rule-based systems. This research area is often referred to as multiobjective genetic fuzzy systems where EMO algorithms are used to search for a number of non-dominated fuzzy rule-based systems with respect to their accuracy and interpretability. The main advantage of the use of EMO algorithms for fuzzy system design over single-objective optimizers is that multiple alternative fuzzy rule-based systems with different accuracy-interpretability tradeoffs are obtained by their single run. The decision maker can choose a single fuzzy rule-based system according to their preference. There still exist several important issues to be discussed in this research area such as the definition of interpretability, the formulation of interpretability measures, the visualization of tradeoff relations, and the interpretability of the explanation of fuzzy reasoning results. In this paper, we discuss the ability of EMO algorithms as multiobjective optimizers to search for Pareto optimal or near Pareto optimal fuzzy rule-based systems. More specifically, we examine whether EMO algorithms can find non-dominated fuzzy rule-based systems that approximate the entire Pareto fronts of multiobjective fuzzy system design problems. ©2009 IEEE.",,
"Liu Y.-F., Tseng S.-C., Jang J.-S.R., Chen C.-H.A.","Coping imbalanced prosodic unit boundary detection with linguistically-motivated prosodic features",2010,"Proceedings of the 11th Annual Conference of the International Speech Communication Association, INTERSPEECH 2010",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959815052&partnerID=40&md5=a5abc46311acbefc8b53b7eaba668e1c","Continuous speech input for ASR processing is usually presegmented into speech stretches by pauses. In this paper, we propose that smaller, prosodically defined units can be identified by tackling the problem on imbalanced prosodic unit boundary detection using five machine learning techniques. A parsimonious set of linguistically motivated prosodic features has been proven to be useful to characterize prosodic boundary information. Furthermore, BMPM is prone to have true positive rate on the minority class, i.e. the defined prosodic units. As a whole, the decision tree classifier, C4.5, reaches a more stable performance than the other algorithms. © 2010 ISCA.","Biased minimax probability machine; Machine learning; Prosodic unit","International Speech Communication Association"
"Yang L., Wang L., Sun Y., Zhang R.","Simultaneous feature selection and classification via minimax probability machine",2010,"International Journal of Computational Intelligence Systems",19,"10.1080/18756891.2010.9727738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78851471041&doi=10.1080%2f18756891.2010.9727738&partnerID=40&md5=97838b56e26dea0a141654311f17ecbf","This paper presents a novel method for simultaneous feature selection and classification by incorporating a robust L1-norm into the objective function of Minimax Probability Machine (MPM). A fractional programming framework is derived by using a bound on the misclassification error involving the mean and covariance of the data. Furthermore, the problems are solved by the Quadratic Interpolation method. Experiments show that our methods can select fewer features to improve the generalization compared to MPM, which illustrates the effectiveness of the proposed algorithms. © 2010 Taylor & Francis Group, LLC.","Feature selection; Machine learning; Minimax probability machine; Probability of misclassification",
"Greene C.S., Himmelstein D.S., Moore J.H.","A model free method to generate human genetics datasets with complex gene-disease relationships",2010,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-642-12211-8_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952307541&doi=10.1007%2f978-3-642-12211-8_7&partnerID=40&md5=6bd5598df7acc9bc77cb8e17ea6ad8a5","A goal of human genetics is to discover genetic factors that influence individuals' susceptibility to common diseases. Most common diseases are thought to result from the joint failure of two or more interacting components instead of single component failures. This greatly complicates both the task of selecting informative genetic variations and the task of modeling interactions between them. We and others have previously developed algorithms to detect and model the relationships between these genetic factors and disease. Previously these methods have been evaluated with datasets simulated according to pre-defined genetic models. Here we develop and evaluate a model free evolution strategy to generate datasets which display a complex relationship between individual genotype and disease susceptibility. We show that this model free approach is capable of generating a diverse array of datasets with distinct gene-disease relationships for an arbitrary interaction order and sample size. We specifically generate six-hundred pareto fronts; one for each independent run of our algorithm. In each run the predictiveness of single genetic variation and pairs of genetic variations have been minimized, while the predictiveness of third, fourth, or fifth order combinations is maximized. This method and the resulting datasets will allow the capabilities of novel methods to be tested without pre-specified genetic models. This could improve our ability to evaluate which methods will succeed on human genetics problems where the model is not known in advance. We further make freely available to the community the entire pareto-optimal front of datasets from each run so that novel methods may be rigorously evaluated. These 56,600 datasets are available from http://discovery.dartmouth.edu/model-free-data/ . © 2010 Springer-Verlag Berlin Heidelberg.",,"Springer Verlag"
"Zhang M., Alhajj R.","Skyline queries with constraints: Integrating skyline and traditional query operators",2010,"Data and Knowledge Engineering",13,"10.1016/j.datak.2009.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-71649086670&doi=10.1016%2fj.datak.2009.10.001&partnerID=40&md5=fbd9386d634cddea654daa3d605ce2e2","Multi-objective optimization has been extensively studied in the machine learning literature. And recently the database community adapted the concept as skyline queries focusing mainly on retrieving optimal values from the full-space. In this paper, we consider sub-space skyline queries in a more general database environment, such that the skyline operator does not stand alone in users' queries. In particular, the skyline operator may commute with the selection operator which may express users' preferences or constraints on the skylines; we call this class skyline queries with constraints. Queries in this class are different from constrained skyline queries as described in the literature. We introduce an algorithm to answer sub-space skyline queries with constraints. We investigate the conditions under which the two classes of queries are equivalent; this allows for more efficient computation of skyline queries. Unlike the previous works, we do not design a new index specifically for handling the skylines. We try to make full use of the resources available in traditional relational databases for skyline computation. Further, we consider the case when the constraints are absent. We study the relationship between the skylines of different sub-spaces and record this information in a special data structure to help in pruning the search space. © 2009 Elsevier B.V. All rights reserved.","High dimensionality; Multi-objective optimization; Pareto optimality; Skyline",
"Fernández Caballero J.C., Martinez F.J., Hervas C., Gutierrez P.A.","Sensitivity versus accuracy in multiclass problems using memetic pareto evolutionary neural networks",2010,"IEEE Transactions on Neural Networks",131,"10.1109/TNN.2010.2041468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951937354&doi=10.1109%2fTNN.2010.2041468&partnerID=40&md5=1d9c4d0a943ad67464d913552e4804db","This paper proposes a multiclassification algorithm using multilayer perceptron neural network models. It tries to boost two conflicting main objectives of multiclassifiers: a high correct classification rate level and a high classification rate for each class. This last objective is not usually optimized in classification, but is considered here given the need to obtain high precision in each class in real problems. To solve this machine learning problem, we use a Pareto-based multiobjective optimization methodology based on a memetic evolutionary algorithm. We consider a memetic Pareto evolutionary approach based on the NSGA2 evolutionary algorithm (MPENSGA2). Once the Pareto front is built, two strategies or automatic individual selection are used: the best model in accuracy and the best model in sensitivity (extremes in the Pareto front). These methodologies are applied to solve 17 classification benchmark problems obtained from the University of California at Irvine (UCI) repository and one complex real classification problem. The models obtained show high accuracy and a high classification rate for each class. © 2010 IEEE.","Accuracy; Local search; Multiclassification; Multiobjective evolutionary algorithms; Neural networks; Sensitivity",
"de Carvalho A.B., Pozo A., Vergilio S.R.","A symbolic fault-prediction model based on multiobjective particle swarm optimization",2010,"Journal of Systems and Software",76,"10.1016/j.jss.2009.12.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77549086028&doi=10.1016%2fj.jss.2009.12.023&partnerID=40&md5=2f81c25ab5c036e0a932060bbb988a89","In the literature the fault-proneness of classes or methods has been used to devise strategies for reducing testing costs and efforts. In general, fault-proneness is predicted through a set of design metrics and, most recently, by using Machine Learning (ML) techniques. However, some ML techniques cannot deal with unbalanced data, characteristic very common of the fault datasets and, their produced results are not easily interpreted by most programmers and testers. Considering these facts, this paper introduces a novel fault-prediction approach based on Multiobjective Particle Swarm Optimization (MOPSO). Exploring Pareto dominance concepts, the approach generates a model composed by rules with specific properties. These rules can be used as an unordered classifier, and because of this, they are more intuitive and comprehensible. Two experiments were accomplished, considering, respectively, fault-proneness of classes and methods. The results show interesting relationships between the studied metrics and fault prediction. In addition to this, the performance of the introduced MOPSO approach is compared with other ML algorithms by using several measures including the area under the ROC curve, which is a relevant criterion to deal with unbalanced data. © 2010 Elsevier Inc. All rights reserved.","Fault prediction; Multiobjective; Particle swarm optimization; Rule learning algorithm",
"Guid M., Možina M., Sadikov A., Bratko I.","Deriving concepts and strategies from chess tablebases",2010,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-642-12993-3_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953767912&doi=10.1007%2f978-3-642-12993-3_18&partnerID=40&md5=e31a7402e1ffd486dddab7b980eb012b","Complete tablebases, indicating best moves for every position, exist for chess endgames. There is no doubt that tablebases contain a wealth of knowledge, however, mining for this knowledge, manually or automatically, proved as extremely difficult. Recently, we developed an approach that combines specialized minimax search with the argument-based machine learning (ABML) paradigm. In this paper, we put this approach to test in an attempt to elicit human-understandable knowledge from tablebases. Specifically, we semi-automatically synthesize knowledge from the KBNK tablebase for teaching the difficult king, bishop, and knight versus the lone king endgame. © 2010 Springer-Verlag Berlin Heidelberg.",,
"Hoste K., Georges A., Eeckhout L.","Automated just-in-time compiler tuning",2010,"Proceedings of the 2010 CGO - The 8th International Symposium on Code Generation and Optimization",16,"10.1145/1772954.1772965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954017994&doi=10.1145%2f1772954.1772965&partnerID=40&md5=e8c065e7d4f5eab47557b41b7badede3","Managed runtime systems, such as a Java virtual machine (JVM), are complex pieces of software with many interacting components. The Just-In-Time (JIT) compiler is at the core of the virtual machine, however, tuning the compiler for optimum performance is a challenging task. There are (i) many compiler optimizations and options, (ii) there may be multiple optimization levels (e.g., -O0, -O1, -O2), each with a specific optimization plan consisting of a collection of optimizations, (iii) the Adaptive Optimization System (AOS) that decides which method to optimize to which optimization level requires fine-tuning, and (iv) the effectiveness of the optimizations depends on the application as well as on the hardware platform. Current practice is to manually tune the JIT compiler which is both tedious and very time-consuming, and in addition may lead to suboptimal performance. This paper proposes automated tuning of the JIT compiler through multi-objective evolutionary search. The proposed framework (i) identifies optimization plans that are Pareto-optimal in terms of compilation time and code quality, (ii) assigns these plans to optimization levels, and (iii) fine-tunes the AOS accordingly. The key benefit of our framework is that it automates the entire exploration process, which enables tuning the JIT compiler for a given hardware platform and/or application at very low cost. By automatically tuning Jikes RVM using our framework for average performance across the DaCapo and SPECjvm98 benchmark suites, we achieve similar performance to the hand-tuned default Jikes RVM. When optimizing the JIT compiler for individual benchmarks, we achieve statistically significant speedups for most benchmarks, up to 40% for startup and up to 19% for steady-state performance. We also show that tuning the JIT compiler for a new hardware platform can yield significantly better performance compared to using a JIT compiler that was tuned for another platform. © 2010 ACM.","compiler tuning; evolutionary search; java virtual machine (JVM); just-in-time (JIT) compiler; machine learning",
"Qasem S.N., Shamsuddin S.M.","Generalization improvement of radial basis function network based on multi-objective particle swarm optimization",2010,"Journal of Artificial Intelligence",16,"10.3923/jai.2010.1.16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955737824&doi=10.3923%2fjai.2010.1.16&partnerID=40&md5=3618a9cbb53b6859357f6ddc99dfa93b","The problem of unsupervised and supervised learning of RBF networks is discussed with Multi-Objective Particle Swarm Optimization (MOPSO). This study presents an evolutionary multi-objective selection method of RBF networks structure. The candidates of RBF networks structures are encoded into particles in PSO. These particles evolve toward Pareto-optimal front defined by several objective functions with model accuracy and complexity. This study suggests an approach of RBF network training through simultaneous optimization of architectures and connections with PSO-based multi-objective algorithm. Present goal is to determine whether MOPSO can train RBF networks and the performance is validated on accuracy and complexity. The experiments are conducted on two benchmark datasets obtained from the machine learning repository. The results show that; the best results are obtained for our proposed method that has obtained 100 and 80.21 % classification accuracy from the experiments made on the data taken from breast cancer and diabetes diseases database, respectively. The results also show that our approach provides an effective means to solve multi-objective RBF networks and outperforms multi-objective genetic algorithm. © 2010 Asian Network for Scientific Information.","Elitist non-dominated sorting genetic algorithm; Hybrid learning; Multi-objective optimization; Multi-objective particle swarm optimization; Radial basis function network",
"Kramer O., Danielsiek H.","DBSCAN-based multi-objective niching to approximate equivalent pareto-subsets",2010,"Proceedings of the 12th Annual Genetic and Evolutionary Computation Conference, GECCO '10",16,"10.1145/1830483.1830575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955878423&doi=10.1145%2f1830483.1830575&partnerID=40&md5=8eab69b1673e789e426c51147d1c18cd","In systems optimization and machine learning multiple alternative solutions may exist in different parts of decision space for the same parts of the Pareto-front. The detection of equivalent Pareto-subsets may be desirablethis paper we introduce a niching method that approximates Paretooptimal solutions with diversity mechanisms in objective and decision space. For diversity in objective space we use rake selection, a selection method based on the distances to reference lines in objective space. For diversity in decision space we introduce a niching approach that uses the density-based clustering method DBSCAN. The clustering process assigns the population to niches while the multi-objective optimization process concentrates on each niche independently. We introduce an indicator for the adaptive control of clustering processes, and extend rake selection by the concept of adaptive corner points. The niching method is experimentally validated on parameterized test function with the help of the S-metric. Copyright 2010 ACM.","Hybrid evolutionary multiobjective algorithm; Hybrid metaheuristics; Local search; Memetic algorithms",
"Veeramachaneni K., Vladislavleva K., Burland M., Parcon J., O'Reilly U.-M.","Evolutionary optimization of flavors",2010,"Proceedings of the 12th Annual Genetic and Evolutionary Computation Conference, GECCO '10",9,"10.1145/1830483.1830713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955855946&doi=10.1145%2f1830483.1830713&partnerID=40&md5=0c53f973518877cea2b0df350eeb98ba","We have acquired panelist data that provides hedonic (liking) ratings for a set of 40 flavors each composed of the same 7 ingredients at different concentration levels. Our goal is to use this data to predict other flavors, composed of the same ingredients in new combinations, which the panelist will like. We describe how we first employ Pareto-Genetic Programming (GP) to generate a surrogate for the human panelist from the 40 observations. This surrogate, in fact an ensemble of GP symbolic regression models, can predict liking scores for flavors outside the observations and provide a confidence in the prediction. We then employ a multi-objective particle swarm optimization (MOPSO) to design a well and consistently liked flavor suite for a panelist. The MOPSO identifies flavors that are well liked (high liking score), and consistently-liked (of maximum confidence). Further, we generate flavors that are well and consistently liked by a cluster of panelists, by giving the MOPSO slightly different objectives. Copyright 2010 ACM.","Ensemble learning; Genetic programming; Particle swarm optimization; Sensory evaluation",
"Huh S., Fienberg S.E.","Discriminative topic modeling based on manifold learning",2010,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",17,"10.1145/1835804.1835888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956221584&doi=10.1145%2f1835804.1835888&partnerID=40&md5=170223919ce7dc08960e07e37cb06a4e","Topic modeling has been popularly used for data analysis in various domains including text documents. Previous topic models, such as probabilistic Latent Semantic Analysis (pLSA) and Latent Dirichlet Allocation (LDA), have shown impressive success in discovering low-rank hidden structures for modeling text documents. These models, however, do not take into account the manifold structure of data, which is generally informative for the non-linear dimensionality reduction mapping. More recent models, namely Laplacian PLSI (LapPLSI) and Locally-consistent Topic Model (LTM), have incorporated the local manifold structure into topic models and have shown the resulting benefits. But these approaches fall short of the full discriminating power of manifold learning as they only enhance the proximity between the low-rank representations of neighboring pairs without any consideration for non-neighboring pairs. In this paper, we propose Discriminative Topic Model (DTM) that separates non-neighboring pairs from each other in addition to bringing neighboring pairs closer together, thereby preserving the global manifold structure as well as improving the local consistency. We also present a novel model fitting algorithm based on the generalized EM and the concept of Pareto improvement. As a result, DTM achieves higher classification performance in a semi-supervised setting by effectively exposing the manifold structure of data. We provide empirical evidence on text corpora to demonstrate the success of DTM in terms of classification accuracy and robustness to parameters compared to state-of-the-art techniques. © 2010 ACM.","Dimensionality reduction; Document classification; Semi-supervised learning; Topic modeling",
"Kokshenev I., Padua Braga A.","An efficient multi-objective learning algorithm for RBF neural network",2010,"Neurocomputing",34,"10.1016/j.neucom.2010.06.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649974166&doi=10.1016%2fj.neucom.2010.06.022&partnerID=40&md5=59aa9e1ae6aa0df7dbcc91574f7b556e","Most of modern multi-objective machine learning methods are based on evolutionary optimization algorithms. They are known to be global convergent, however, usually deliver nondeterministic results. In this work we propose the deterministic global solution to a multi-objective problem of supervised learning with the methodology of nonlinear programming. As the result, the proposed multi-objective algorithm performs a global search of Pareto-optimal hypotheses in the space of RBF networks, determining their weights and basis functions. In combination with the Akaike and Bayesian information criteria, the algorithm demonstrates a high generalization efficiency on several synthetic and real-world benchmark problems. © 2010 Elsevier B.V.","Model selection; Multi-objective learning; Pareto-optimality; Radial-basis functions; Regularization",
"Sun X., Li L., Wang Z.","Using manifold learning and minimax probability machine for face recognition",2010,"Proceedings - 2010 2nd International Conference on Modeling, Simulation, and Visualization Methods, WMSVM 2010",2,"10.1109/WMSVM.2010.46","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957927420&doi=10.1109%2fWMSVM.2010.46&partnerID=40&md5=4598f47c0c81663d534c57daea70ecf2","Face recognition has become one of the most important research areas of pattern recognition and machine learning due to its potential applications in many fields. To effectively cope with this problem, a novel face recognition algorithm is proposed by using manifold learning and minimax probability machine. Comprehensive comparisons and extensive experiments show that the proposed algorithm achieves much higher recognition rates than the ordinary face recognition algorithms. © 2010 IEEE.","Face recognition; Manifold learning; Minimax probability machine; Pattern recognition",
"Reynolds A.P., Corne D.W., Chantler M.J.","Feature selection for multi-purpose predictive models: A many-objective task",2010,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",7,"10.1007/978-3-642-15844-5_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149262263&doi=10.1007%2f978-3-642-15844-5_39&partnerID=40&md5=753383a20e23827749939e7f69399bcb","The target of machine learning is a predictive model that performs well on unseen data. Often, such a model has multiple intended uses, related to different points in the tradeoff between (e.g.) sensitivity and specificity. Moreover, when feature selection is required, different feature subsets will suit different target performance characteristics. Given a feature selection task with such multiple distinct requirements, one is in fact faced with a very-many-objective optimization task, whose target is a Pareto surface of feature subsets, each specialized for (e.g.) a different sensitivity/specificity tradeoff profile. We argue that this view has many advantages. We motivate, develop and test such an approach. We show that it can be achieved successfully using a dominance-based multiobjective algorithm, despite an arbitrarily large number of objectives. © 2010 Springer-Verlag.",,
"Woodward J.R., Gindy N.","A hyper-heuristic multi-criteria decision support system for eco-efficient product life cycle",2010,"IET Conference Publications",1,"10.1049/cp.2010.0436","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149334429&doi=10.1049%2fcp.2010.0436&partnerID=40&md5=4a69de440434ebfd3f92ebd3c79a3053","Decision support is required when complex situations arise during product development which takes into account the whole product life cycle. This is especially true when impacted by the ill-defined consequences on the environment in an ever increasingly eco-conscious world. Analytical Hierarchy process (AHP) is one method of providing decision support, and is an instance of a decision support heuristic. Machine learning methods have proved themselves on many well defined problems with clearly defined objectives. In particular, we focus on the recently emerging field of hyper-heuristics which is a blend of human designed heuristics, with the extension of machine designed heuristics. In essence humans can operate at the higher concept or abstract level, while machine heuristics can operate at a lower level. There are a number of issues within the proposed framework, including visualizing a multi-dimensional surface of designs along the Pareto front, as well as dealing with different types of data during the decision making process. It is proposed that Hyper-heuristics, supplemented with other methodologies to deal with vague or missing data, offer a framework in which to begin to address several of the complex compromises that arise during product development.","analytical hierarchal process; decision support system; genetic programming; Hyper-heuristics",
"Zhou H., Cheng Q.","Sufficient conditions for generating group level sparsity in a robust minimax framework",2010,"Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010, NIPS 2010",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860622721&partnerID=40&md5=5219a78ca6425830c234bd3a5897d07b","Regularization technique has become a principled tool for statistics and machine learning research and practice. However, in most situations, these regularization terms are not well interpreted, especially on how they are related to the loss function and data. In this paper, we propose a robust minimax framework to interpret the relationship between data and regularization terms for a large class of loss functions. We show that various regularization terms are essentially corresponding to different distortions to the original data matrix. This minimax framework includes ridge regression, lasso, elastic net, fused lasso, group lasso, local coordinate coding, multiple kernel learning, etc., as special cases. Within this minimax framework, we further give mathematically exact definition for a novel representation called sparse grouping representation (SGR), and prove a set of sufficient conditions for generating such group level sparsity. Under these sufficient conditions, a large set of consistent regularization terms can be designed. This SGR is essentially different from group lasso in the way of using class or group information, and it outperforms group lasso when there appears group label noise. We also provide some generalization bounds in a classification setting.",,
"Chan Y.-H., Chiang T.-C., Fu L.-C.","A two-phase evolutionary algorithm for multiobjective mining of classification rules",2010,"2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010",17,"10.1109/CEC.2010.5586523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959480959&doi=10.1109%2fCEC.2010.5586523&partnerID=40&md5=7393f143c6568db69ee27830a7f9c8f6","Classification rule mining, addressed a lot in machine learning and statistics communities, is an important task to extract knowledge from data. Most existing approaches do not particularly deal with data instances matched by more than one rule, which results in restricted performance. We present a two-phase multiobjective evolutionary algorithm which first aims at searching decent rules and then takes the rule interaction into account to produce the final rule sets. The algorithm incorporates the concept of Pareto dominance to deal with trade-off relations in both phases. Through computational experiments, the proposed algorithm shows competitive to the state-of-the-art. We also study the effect of a niching mechanism. © 2010 IEEE.",,
"Ethridge J., Ditzler G., Polikar R.","Optimal ν-SVM parameter estimation using multi objective evolutionary algorithms",2010,"2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010",6,"10.1109/CEC.2010.5586029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959471489&doi=10.1109%2fCEC.2010.5586029&partnerID=40&md5=28417d6ec56b222f8c572e8965f5d162","Using a machine learning algorithm for a given application often requires tuning design parameters of the classifier to obtain optimal classification performance without overfitting. In this contribution, we present an evolutionary algorithm based approach for multi-objective optimization of the sensitivity and specificity of a ν-SVM. The ν-SVM is often preferred over the standard C-SVM due to smaller dynamic range of the ν parameter compared to the unlimited dynamic range of the C parameter. Instead of looking for a single optimization result, we look for a set of optimal solutions that lie along the Pareto optimality front. The traditional advantage of using the Pareto optimality is of course the flexibility to choose any of the solutions that lies on the Pareto optimality front. However, we show that simply maximizing sensitivity and specificity over the Pareto front leads to parameters that appear to be mathematically optimal yet still cause overfitting. We propose a multiple objective optimization approach with three objective functions to find additional parameter values that do not cause overfitting. © 2010 IEEE.","ν-SVM; evolutionary algorithms; multi-objective optimization",
"Tang L., Lei Y.-K., Zhu L., Huang D.-S.","Dimensionality reduction based on minimax risk criterion for face recognition",2010,"Proceedings of the International Joint Conference on Neural Networks",3,"10.1109/IJCNN.2010.5596520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959427931&doi=10.1109%2fIJCNN.2010.5596520&partnerID=40&md5=1b76dac48b652edcce7b6c6aff8824e7","In the field of pattern recognition and machine learning, many problems are involved in the tasks of dimensionality reduction and then classification. In this paper, we develop an efficient dimensionality reduction method named MiniRisk Supervised Discrimiant Projection (MRSDP), which extracts effective low-dimensional features for classification purpose. The proposed method utilizes discriminant information to guide the procedure of extracting intrinsic low-dimensional features and provides a linear projection matrix. Since MRSDP is based on minimax risk criterion, it can minimize the maximal probability of misclassification in the common borders of different classes of data by contracting within-class scatter and maximizing between-class scatter. The advantage of our method is borne out by comparison with other widely used methods. In the experiments on Yale face database and ORL face database, our method achieves constantly superior performance than those competing methods. © 2010 IEEE.",,
"Raginsky M.","Divergence-based characterization of fundamental limitations of adaptive dynamical systems",2010,"2010 48th Annual Allerton Conference on Communication, Control, and Computing, Allerton 2010",5,"10.1109/ALLERTON.2010.5706895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952397424&doi=10.1109%2fALLERTON.2010.5706895&partnerID=40&md5=ce11e10a95298a24b8a1832f07c3df4f","Adaptive dynamical systems arise in a multitude of contexts, e.g., optimization, control, communications, signal processing, and machine learning. A precise characterization of their fundamental limitations is therefore of paramount importance. In this paper, we consider the general problem of adaptively controlling and/or identifying a stochastic dynamical system, where our a priori knowledge allows us to place the system in a subset of a metric space (the uncertainty set). We present an information-theoretic meta-theorem that captures the trade-off between the metric complexity (or richness) of the uncertainty set, the amount of information acquired online in the process of controlling and observing the system, and the residual uncertainty remaining after the observations have been collected. Following the approach of Zames, we quantify a priori information by the Kolmogorov (metric) entropy of the uncertainty set, while the information acquired online is expressed as a sum of information divergences. The general theory is used to derive new minimax lower bounds on the metric identification error, as well as to give a simple derivation of the minimum time needed to stabilize an uncertain stochastic linear system. ©2010 IEEE.",,
"Giusti R., Batista G.E.A.P.A.","Discovering knowledge rules with multi-objective evolutionary computing",2010,"Proceedings - 9th International Conference on Machine Learning and Applications, ICMLA 2010",,"10.1109/ICMLA.2010.25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952381057&doi=10.1109%2fICMLA.2010.25&partnerID=40&md5=4941256bce65a0828dadfb0b6e8ccb2d","Most Machine Learning systems target into inducing classifiers with optimal coverage and precision measures. Although this constitutes a good approach for prediction, it might not provide good results when the user is more interested in description. In this case, the induced models should present other properties such as novelty, interestingness and so forth. In this paper we present a research work based in Multi-Objective Evolutionary Computing to construct individual knowledge rules targeting arbitrary user-defined criteria via objective quality measures such as precision, support, novelty etc. This paper also presents a comparison among multi-objective and ranking composition techniques. It is shown that multi-objective-based methods attain better results than ranking-based methods, both in terms of solution dominance and diversity of solutions in the Pareto front. © 2010 IEEE.","Evolutionary computing; Knowledge discovery in databases; Multi-objective machine learning",
"Karthik Kannan A.S., Thanapal P.","A hybrid evolutionary approach for optimal fuzzy classifier design",2010,"2010 IEEE International Conference on Communication Control and Computing Technologies, ICCCCT 2010",2,"10.1109/ICCCCT.2010.5670725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751499993&doi=10.1109%2fICCCCT.2010.5670725&partnerID=40&md5=e1a9aa535f7b576fd6abbfd38fb3af36","One of the important issues in the design of fuzzy classifier is the formation of fuzzy if-then rules and the membership functions. This paper presents a Niched Pareto Genetic Algorithm (NPGA) approach to obtain the optimal rule-set and the membership function. To develop the fuzzy system the rule set and the membership functions are encoded into the chromosome and evolved simultaneously using NPGA. The performance of the proposed approach is demonstrated through development of fuzzy classifier for Iris data available in the UCI machine learning repository. From the simulation study, it is found that that NPGA produces a fuzzy classifier which has minimum number of rules and high classification accuracy compared with the existing methods. ©2010 IEEE.","Fuzzy classifier; If-then-rules; Membership function; Niched Pareto genetic algorithm",
"Coelho A.L.V., Fernandes E., Faceli K.","Inducing multi-objective clustering ensembles with genetic programming",2010,"Neurocomputing",14,"10.1016/j.neucom.2010.09.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649462741&doi=10.1016%2fj.neucom.2010.09.014&partnerID=40&md5=f8edb03bfa57567528d16bfc89d0671d","The recent years have witnessed a growing interest in two advanced strategies to cope with the data clustering problem, namely, clustering ensembles and multi-objective clustering. In this paper, we present a genetic programming based approach that can be considered as a hybrid of these strategies, thereby allowing that different hierarchical clustering ensembles be simultaneously evolved taking into account complementary validity indices. Results of computational experiments conducted with artificial and real datasets indicate that, in most of the cases, at least one of the Pareto optimal partitions returned by the proposed approach compares favorably or go in par with the consensual partitions yielded by two well-known clustering ensemble methods in terms of clustering quality, as gauged by the corrected Rand index. © 2010 Elsevier B.V.","Cluster analysis; Ensembles; Genetic programming; Multi-objective optimization",
"White C.M., Khudanpur S.P., Wolfe P.J.","Likelihood-Based semi-Supervised model selection with applications to speech processing",2010,"IEEE Journal on Selected Topics in Signal Processing",,"10.1109/JSTSP.2010.2076050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649309025&doi=10.1109%2fJSTSP.2010.2076050&partnerID=40&md5=e01dd9d35a732aa27368a4c2b90a11dd","In conventional supervised pattern recognition tasks, model selection is typically accomplished by minimizing the classification error rate on a set of so-called development data, subject to ground-truth labeling by human experts or some other means. In the context of speech processing systems and other large-scale practical applications, however, such labeled development data are typically costly and difficult to obtain. This paper investigates an alternative semi-supervised framework for likelihood-based model selection that leverages unlabeled data by using trained classifiers representing each model to automatically generate putative labels. The errors that result from this automatic labeling are shown to be amenable to results from robust statistics, which in turn provide for minimax-optimal censored likelihood ratio tests that recover the nonparametric sign test as a limiting case. This approach is then validated experimentally using a state-of-the-art automatic speech recognition system to select between candidate word pronunciations using unlabeled speech data that only potentially contain instances of the words under test. Results provide supporting evidence for the utility of this approach, and suggest that it may also find use in other applications of machine learning. © 2010 IEEE.","Likelihood ratio tests; pronunciation modeling; robust statistics; semi-supervised learning; sign test; speech recognition; spoken term detection",
"Jones L.K., Zou F., Kheifets A., Rybnikov K., Berry D., Tan A.C.","Confident Predictability: Identifying reliable gene expression patterns for individualized tumor classification using a local minimax kernel algorithm",2011,"BMC Medical Genomics",2,"10.1186/1755-8794-4-10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751649980&doi=10.1186%2f1755-8794-4-10&partnerID=40&md5=8b55de392a5a688dde58c35b14e8f44b","Abstract. Background: Molecular classification of tumors can be achieved by global gene expression profiling. Most machine learning classification algorithms furnish global error rates for the entire population. A few algorithms provide an estimate of probability of malignancy for each queried patient but the degree of accuracy of these estimates is unknown. On the other hand local minimax learning provides such probability estimates with best finite sample bounds on expected mean squared error on an individual basis for each queried patient. This allows a significant percentage of the patients to be identified as confidently predictable, a condition that ensures that the machine learning algorithm possesses an error rate below the tolerable level when applied to the confidently predictable patients. Results: We devise a new learning method that implements: (i) feature selection using the k-TSP algorithm and (ii) classifier construction by local minimax kernel learning. We test our method on three publicly available gene expression datasets and achieve significantly lower error rate for a substantial identifiable subset of patients. Our final classifiers are simple to interpret and they can make prediction on an individual basis with an individualized confidence level. Conclusions: Patients that were predicted confidently by the classifiers as cancer can receive immediate and appropriate treatment whilst patients that were predicted confidently as healthy will be spared from unnecessary treatment. We believe that our method can be a useful tool to translate the gene expression signatures into clinical practice for personalized medicine. © 2011 Jones et al; licensee BioMed Central Ltd.",,
"McIntyre A.R., Heywood M.I.","Classification as clustering: A pareto cooperative-competitive GP approach",2011,"Evolutionary Computation",12,"10.1162/EVCO_a_00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951561922&doi=10.1162%2fEVCO_a_00016&partnerID=40&md5=0dc002e843b63fc234c0b51358279d7a","Intuitively population based algorithms such as genetic programming provide a natural environment for supporting solutions that learn to decompose the overall task between multiple individuals, or a team. This work presents a framework for evolving teams without recourse to prespecifying the number of cooperating individuals. To do so, each individual evolves a mapping to a distribution of outcomes that, following clustering, establishes the parameterization of a (Gaussian) local membership function. This gives individuals the opportunity to represent subsets of tasks, where the overall task is that of classification under the supervised learning domain. Thus, rather than each team member representing an entire class, individuals are free to identify unique subsets of the overall classification task. The framework is supported by techniques from evolutionary multiobjective optimization (EMO) and Pareto competitive coevolution. EMOestablishes the basis for encouraging individuals to provide accurate yet nonoverlaping behaviors; whereas competitive coevolution provides the mechanism for scaling to potentially large unbalanced datasets. Benchmarking is performed against recent examples of nonlinear SVM classifiers over 12 UCI datasets with between 150 and 200,000 training instances. Solutions from the proposed coevolutionary multiobjective GP framework appear to provide a good balance between classification performance and model complexity, especially as the dataset instance count increases. © 2011 by the Massachusetts Institute of Technology.","Classification; Coevolution; Genetic programming; Pareto multi-objective optimization; Problem decomposition",
"Saha I., Maulik U., Bandyopadhyay S., Plewczynski D.","Unsupervised and supervised learning approaches together for microarray analysis",2011,"Fundamenta Informaticae",6,"10.3233/FI-2011-376","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951637220&doi=10.3233%2fFI-2011-376&partnerID=40&md5=de9ffbe2657cb40b94f775104fbee712","In this article, a novel concept is introduced by using both unsupervised and supervised learning. For unsupervised learning, the problem of fuzzy clustering in microarray data as a multiobjective optimization is used, which simultaneously optimizes two internal fuzzy cluster validity indices to yield a set of Pareto-optimal clustering solutions. In this regards, a new multiobjective differential evolution based fuzzy clustering technique has been proposed. Subsequently, for supervised learning, a fuzzy majority voting scheme along with support vector machine is used to integrate the clustering information from all the solutions in the resultant Pareto-optimal set. The performances of the proposed clustering techniques have been demonstrated on five publicly available benchmark microarray data sets. A detail comparison has been carried out with multiobjective genetic algorithm based fuzzy clustering, multiobjective differential evolution based fuzzy clustering, single objective versions of differential evolution and genetic algorithm based fuzzy clustering as well as well known fuzzy c-means algorithm. While using support vector machine, comparative studies of the use of four different kernel functions are also reported. Statistical significance test has been done to establish the statistical superiority of the proposed multiobjective clustering approach. Finally, biological significance test has been carried out using a web based gene annotation tool to show that the proposed integrated technique is able to produce biologically relevant clusters of coexpressed genes.","Fuzzy clustering; improved differential evolution; multiobjective optimization; Pareto-optimal; support vector machine",
"Oztekin A.","A decision support system for usability evaluation of web-based information systems",2011,"Expert Systems with Applications",29,"10.1016/j.eswa.2010.07.151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049530599&doi=10.1016%2fj.eswa.2010.07.151&partnerID=40&md5=430eb2066359ea564865cbc5d730099b","In this study, a decision support system (DSS) for usability assessment and design of web-based information systems (WIS) is proposed. It employs three machine learning methods (support vector machines, neural networks, and decision trees) and a statistical technique (multiple linear regression) to reveal the underlying relationships between the overall WIS usability and its determinative factors. A sensitivity analysis on the predictive models is performed and a new metric, criticality index, is devised to identify the importance ranking of the determinative factors. Checklist items with the highest and the lowest contribution to the usability performance of the WIS are specified by means of the criticality index. The most important usability problems for the WIS are determined with the help of a pseudo-Pareto analysis. A case study through a student information system at Fatih University is carried out to validate the proposed DSS. The proposed DSS can be used to decide which usability problems to focus on so as to improve the usability and quality of WIS. © 2010 Elsevier Ltd. All rights reserved.","Criticality index; Machine learning; Sensitivity analysis; Usability engineering; Web-based information system",
"Cartlidge J., Ait-Boudaoud D.","Autonomous virulence adaptation improves coevolutionary optimization",2011,"IEEE Transactions on Evolutionary Computation",9,"10.1109/TEVC.2010.2073471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953289033&doi=10.1109%2fTEVC.2010.2073471&partnerID=40&md5=162b01f8cf22e096174a8fa2bc092a3f","A novel approach for the autonomous virulence adaptation (AVA) of competing populations in a coevolutionary optimization framework is presented. Previous work has demonstrated that setting an appropriate virulence, v, of populations accelerates coevolutionary optimization by avoiding detrimental periods of disengagement. However, since the likelihood of disengagement varies both between systems and over time, choosing the ideal value of v is problematic. The AVA technique presented here uses a machine learning approach to continuously tune v as system engagement varies. In a simple, abstract domain, AVA is shown to successfully adapt to the most productive values of v. Further experiments, in more complex domains of sorting networks and maze navigation, demonstrate AVA's efficiency over reduced virulence and the layered Pareto coevolutionary archive. © 2006 IEEE.","Autonomous virulence adaptation; coevolution; disengagement; genetic algorithms; machine learning; maze navigation; optimization methods; reduced virulence; sorting networks",
"Darnstädt M., Simon H.U.","Smart PAC-learners",2011,"Theoretical Computer Science",5,"10.1016/j.tcs.2010.12.053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952619803&doi=10.1016%2fj.tcs.2010.12.053&partnerID=40&md5=18ec2296b7dd8fdcd96ae84729b4c5ad","The PAC-learning model is distribution-independent in the sense that the learner must reach a learning goal with a limited number of labeled random examples without any prior knowledge of the underlying domain distribution. In order to achieve this, one needs generalization error bounds that are valid uniformly for every domain distribution. These bounds are (almost) tight in the sense that there is a domain distribution which does not admit a generalization error being significantly smaller than the general bound. Note however that this leaves open the possibility to achieve the learning goal faster if the underlying distribution is ""simple"". Informally speaking, we say a PAC-learner L is ""smart"" if, for a ""vast majority"" of domain distributions D, L does not require significantly more examples to reach the ""learning goal"" than the best learner whose strategy is specialized to D. In this paper, focusing on sample complexity and ignoring computational issues, we show that smart learners do exist. This implies (at least from an information-theoretical perspective) that full prior knowledge of the domain distribution (or access to a huge collection of unlabeled examples) does (for a vast majority of domain distributions) not significantly reduce the number of labeled examples required to achieve the learning goal. © 2010 Elsevier B.V. All rights reserved.","Learning under a fixed distribution; Machine learning; Minimax theorem; PAC-learning; Semi-supervised learning; Smart PAC-learner; Value of unlabeled data",
"Kraus J.M., Müssel C., Palm G., Kestler H.A.","Multi-objective selection for collecting cluster alternatives",2011,"Computational Statistics",13,"10.1007/s00180-011-0244-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955468355&doi=10.1007%2fs00180-011-0244-6&partnerID=40&md5=973575a9f4dc0c93a7ca64c823111763","Grouping objects into different categories is a basic means of cognition. In the fields of machine learning and statistics, this subject is addressed by cluster analysis. Yet, it is still controversially discussed how to assess the reliability and quality of clusterings. In particular, it is hard to determine the optimal number of clusters inherent in the underlying data. Running different cluster algorithms and cluster validation methods usually yields different optimal clusterings. In fact, several clusterings with different numbers of clusters are plausible in many situations, as different methods are specialized on diverse structural properties. To account for the possibility of multiple plausible clusterings, we employ a multi-objective approach for collecting cluster alternatives (MOCCA) from a combination of cluster algorithms and validation measures. In an application to artificial data as well as microarray data sets, we demonstrate that exploring a Pareto set of optimal partitions rather than a single solution can identify alternative solutions that are overlooked by conventional clustering strategies. Competitive solutions are hereby ranked following an impartial criterion, while the ultimate judgement is left to the investigator. © 2011 Springer-Verlag.","Cluster analysis; Cluster number estimation; Cluster validation; Multi-objective optimization",
"Bhowan U., Johnston M., Zhang M.","Evolving ensembles in Multi-objective Genetic Programming for classification with unbalanced data",2011,"Genetic and Evolutionary Computation Conference, GECCO'11",25,"10.1145/2001576.2001756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859002798&doi=10.1145%2f2001576.2001756&partnerID=40&md5=3889e6e7dada51f161ecb28754d59ac7","Machine learning algorithms can suffer a performance bias when data sets are unbalanced. This paper proposes a Multi-objective Genetic Programming approach using negative correlation learning to evolve accurate and diverse ensembles of non-dominated solutions where members vote on class membership. We also compare two popular Pareto-based fitness schemes on the classification tasks. We show that the evolved ensembles achieve high accuracy on both classes using six unbalanced binary data sets, and that this performance is usually better than many of its individual members. Copyright 2011 ACM.","Class imbalance; Classification; Evolutionary multi-objective optimisation; Genetic programming",
"Freire Da Silva V., Reali Costa A.H.","A geometric approach to find nondominated policies to imprecise reward MDPs",2011,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-642-23780-5_38","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052411945&doi=10.1007%2f978-3-642-23780-5_38&partnerID=40&md5=1002735be010a2ed4122a8f2ab8bd66b","Markov Decision Processes (MDPs) provide a mathematical framework for modelling decision-making of agents acting in stochastic environments, in which transitions probabilities model the environment dynamics and a reward function evaluates the agent's behaviour. Lately, however, special attention has been brought to the difficulty of modelling precisely the reward function, which has motivated research on MDP with imprecisely specified reward. Some of these works exploit the use of nondominated policies, which are optimal policies for some instantiation of the imprecise reward function. An algorithm that calculates nondominated policies is πWitness, and nondominated policies are used to take decision under the minimax regret evaluation. An interesting matter would be defining a small subset of nondominated policies so that the minimax regret can be calculated faster, but accurately. We modified πWitness to do so. We also present the πHull algorithm to calculate nondominated policies adopting a geometric approach. Under the assumption that reward functions are linearly defined on a set of features, we show empirically that πHull can be faster than our modified version of πWitness. © 2011 Springer-Verlag.","Imprecise Reward MDP; Minimax Regret; Preference Elicitation",
"Cesa-Bianchi N.","Ensembles and multiple classifiers: A game-theoretic view",2011,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-642-21557-5_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052991199&doi=10.1007%2f978-3-642-21557-5_2&partnerID=40&md5=ccfc1343ab0a61a3e89b6250d7e81833","The study of multiple classifier systems is a fundamental topic in modern machine learning. However, early work on aggregation of predictors can be traced back to the Fifties, in the area of game theory. At that time, the pioneering work of James Hannan [11] and David Blackwell [2] laid down the foundations of repeated game theory. In a nutshell, a repeated game is the game-theoretic interpretation of learning. In games played once, lacking any information about the opponent, the best a player can do is to play the minimax strategy (the best strategy against the worst possible opponent). In repeated games, by examining the history of past opponent moves, the player acquires information about the opponent's behavior and can adapt to it, in order to achieve a better payoff than that guaranteed by the minimax strategy. © 2011 Springer-Verlag.",,
"Sidiroglou S., Misailovic S., Hoffmann H., Rinard M.","Managing performance vs. accuracy trade-offs with loop perforation",2011,"SIGSOFT/FSE 2011 - Proceedings of the 19th ACM SIGSOFT Symposium on Foundations of Software Engineering",314,"10.1145/2025113.2025133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053213080&doi=10.1145%2f2025113.2025133&partnerID=40&md5=3ead3d6c78ebeaff0b96e6ae5f7afcd6","Many modern computations (such as video and audio encoders, Monte Carlo simulations, and machine learning algorithms) are designed to trade off accuracy in return for increased performance. To date, such computations typically use ad-hoc, domain-specific techniques developed specifically for the computation at hand. Loop perforation provides a general technique to trade accuracy for performance by transforming loops to execute a subset of their iterations. A criticality testing phase filters out critical loops (whose perforation produces unacceptable behavior) to identify tunable loops (whose perforation produces more efficient and still acceptably accurate computations). A perforation space exploration algorithm perforates combinations of tunable loops to find Pareto-optimal perforation policies. Our results indicate that, for a range of applications, this approach typically delivers performance increases of over a factor of two (and up to a factor of seven) while changing the result that the application produces by less than 10%. © 2011 ACM.","Loop perforation; Profiling; Quality of service",
"Liitiäinen E., Corona F., Lendasse A.","On the curse of dimensionality in supervised learning of smooth regression functions",2011,"Neural Processing Letters",4,"10.1007/s11063-011-9188-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053568910&doi=10.1007%2fs11063-011-9188-7&partnerID=40&md5=ea0f5a8a3596ff0051000a413a55bb65","In this paper, the effect of dimensionality on the supervised learning of infinitely differentiable regression functions is analyzed. By invoking the Van Trees lower bound, we prove lower bounds on the generalization error with respect to the number of samples and the dimensionality of the input space both in a linear and non-linear context. It is shown that in non-linear problems without prior knowledge, the curse of dimensionality is a serious problem. At the same time, we speculate counter-intuitively that sometimes supervised learning becomes plausible in the asymptotic limit of infinite dimensionality. © 2011 Springer Science+Business Media, LLC.","Analytic function; High dimensional; Minimax; Nonparametric regression; Supervised learning; Van Trees",
"Gao C., Wang N., Yu Q., Zhang Z.","A feasible nonconvex relaxation approach to feature selection",2011,"Proceedings of the National Conference on Artificial Intelligence",48,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-80055039401&partnerID=40&md5=0ac9523fb3563ff4381066647780c0c8","Variable selection problems are typically addressed under a penalized optimization framework. Nonconvex penalties such as the minimax concave plus (MCP) and smoothly clipped absolute deviation (SCAD), have been demonstrated to have the properties of sparsity practically and theoretically. In this paper we propose a new nonconvex penalty that we call exponential-type penalty. The exponential-type penalty is characterized by a positive parameter, which establishes a connection with the ℓ0 and ℓ1 penalties. We apply this new penalty to sparse supervised learning problems. To solve to resulting optimization problem, we resort to a reweighted ℓ1 minimization method. Moreover, we devise an efficient method for the adaptive update of the tuning parameter. Our experimental results are encouraging. They show that the exponential-type penalty is competitive with MCP and SCAD. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.",,
"Jaśkowski W., Krawiec K.","Formal analysis, hardness, and algorithms for extracting internal structure of test-based problems",2011,"Evolutionary Computation",16,"10.1162/EVCO_a_00046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80055077684&doi=10.1162%2fEVCO_a_00046&partnerID=40&md5=edd5cf02e728cf0a1486bd28af6ba85f","Problems in which some elementary entities interact with each other are common in computational intelligence. This scenario, typical for coevolving artificial life agents, learning strategies for games, and machine learning from examples, can be formalized as a test-based problem and conveniently embedded in the common conceptual framework of coevolution. In test-based problems, candidate solutions are evaluated on a number of test cases (agents, opponents, examples). It has been recently shown that every test of such problem can be regarded as a separate objective, and the whole problem as multi-objective optimization. Research on reducing the number of such objectives while preserving the relations between candidate solutions and tests led to the notions of underlying objectives and internal problem structure, which can be formalized as a coordinate system that spatially arranges candidate solutions and tests. The coordinate system that spans the minimal number of axes determines the so-called dimension of a problem and, being an inherent property of every problem, is of particular interest. In this study, we investigate in-depth the formalism of a coordinate system and its properties, relate them to properties of partially ordered sets, and design an exact algorithm for finding a minimal coordinate system. We also prove that this problem is NP-hard and come up with a heuristic which is superior to the best algorithm proposed so far. Finally, we apply the algorithms to three abstract problems and demonstrate that the dimension of the problem is typically much lower than the number of tests, and for some problems converges to the intrinsic parameter of the problem-its a priori dimension.© 2011 by the Massachusetts Institute of Technology.","Co-optimization; Coevolution; Games; Interactive domains; Internal problem structure; NP-hardness; Pareto coevolution; Test-based problem; Underlying objectives",
"Cherry K., Chen J.","An intelligent othello player combining machine learning and game specific heuristics",2011,"Proceedings of the 2011 International Conference on Artificial Intelligence, ICAI 2011",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866069102&partnerID=40&md5=b00d45ab6155639e3a0171eb326e0be6","In this paper we present an intelligent Othello game player that combines game-specific heuristics with machine learning techniques for move selection. Five game specific heuristics have been proposed; some of which can be generalized to fit other games. For machine learning techniques, the normal Minimax algorithm along with a custom variation is used as a base. Genetic algorithms and neural networks are applied to learn the static evaluation function. The game specific techniques (or a subset of) are to be executed first and if no move is found, Minimax is performed. All techniques, and several subsets of them, have been tested against three deterministic agents, one non-deterministic agent, and three human players of varying skill levels. The results show that the combined Othello player performs better in general. We present the study results on the basis of performance (percentage of games won), speed, predictability of opponent, and usage situation.","Expected min; Genetic algorithm; Influence map; Minimax; Neural network; Othello",
"Liu Y., Li D., Hu Y.","Machine learning in adversarial game using flight chess",2011,"Proceedings - 3rd International Conference on Multimedia Information Networking and Security, MINES 2011",,"10.1109/MINES.2011.124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862912828&doi=10.1109%2fMINES.2011.124&partnerID=40&md5=a90534381203c832331600e9dcd9f95b","Game playing is a perfect domain of the study of machine learning for its simplicity that allows the researchers to focus on the learning problems themselves and ignore marginal factors. Many learning techniques derived from games have been applied successfully in other learning problems. In this paper, we introduce a Minimax Recurrence Learning algorithm to reinforce the intelligence of a game agent and a supervised learning technique to train the agent. It proves that our intelligent flight chess agent defeat human players in the flight chess game with high probability. Theory deduction proves that combination of the reinforcement learning and supervised learning techniques used in our agent can learn the essential knowledge in an adversarial game. The infrastructure and the algorithm of our agent can be extended in other learning problems also. © 2011 IEEE.","feature characterization; machine learning; reinforcement learning; supervised learning",
"Balakrishnan S., Xu M., Krishnamurthy A., Singh A.","Noise thresholds for spectral clustering",2011,"Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011",45,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860641664&partnerID=40&md5=5cbcc9879f5a7951f6d79a3b51953be5","Although spectral clustering has enjoyed considerable empirical success in machine learning, its theoretical properties are not yet fully developed. We analyze the performance of a spectral algorithm for hierarchical clustering and show that on a class of hierarchically structured similarity matrices, this algorithm can tolerate noise that grows with the number of data points while still perfectly recovering the hierarchical clusters with high probability. We additionally improve upon previous results for k-way spectral clustering to derive conditions under which spectral clustering makes no mistakes. Further, using minimax analysis, we derive tight upper and lower bounds for the clustering problem and compare the performance of spectral clustering to these information theoretic limits. We also present experiments on simulated and real world data illustrating our results.",,
"Ishibuchi H., Nakashima Y., Nojima Y.","Performance evaluation of evolutionary multiobjective optimization algorithms for multiobjective fuzzy genetics-based machine learning",2011,"Soft Computing",34,"10.1007/s00500-010-0669-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155126069&doi=10.1007%2fs00500-010-0669-9&partnerID=40&md5=150bc22e31f24dc2f6a271e05ab4121e","Recently, evolutionary multiobjective optimization (EMO) algorithms have been utilized for the design of accurate and interpretable fuzzy rule-based systems. This research area is often referred to as multiobjective genetic fuzzy systems (MoGFS), where EMO algorithms are used to search for non-dominated fuzzy rule-based systems with respect to their accuracy and interpretability. In this paper, we examine the ability of EMO algorithms to efficiently search for Pareto optimal or near Pareto optimal fuzzy rule-based systems for classification problems. We use NSGA-II (elitist non-dominated sorting genetic algorithm), its variants, and MOEA/D (multiobjective evolutionary algorithm based on decomposition) in our multiobjective fuzzy genetics-based machine learning (MoFGBML) algorithm. Classification performance of obtained fuzzy rule-based systems by each EMO algorithm is evaluated for training data and test data under various settings of the available computation load and the granularity of fuzzy partitions. Experimental results in this paper suggest that reported classification performance of MoGFS in the literature can be further improved using more computation load, more efficient EMO algorithms, and/or more antecedent fuzzy sets from finer fuzzy partitions. © 2010 Springer-Verlag.","Evolutionary multiobjective optimization; Fuzzy rule-based classification; Genetic algorithms; Genetics-based machine learning; Multiobjective machine learning",
"Zuluaga M., Bonilla E., Topham N.","Predicting best design trade-offs: A case study in processor customization",2012,"Proceedings -Design, Automation and Test in Europe, DATE",7,"10.1109/date.2012.6176647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862059721&doi=10.1109%2fdate.2012.6176647&partnerID=40&md5=4459d1138345057d5c3f45e81bb37824","Given the high level description of a task, many different hardware modules may be generated while meeting its behavioral requirements. The characteristics of the generated hardware can be tailored to favor energy efficiency, performance, accuracy or die area. The inherent trade-offs between such metrics need to be explored in order to choose a solution that meets design and cost expectations. We address the generic problem of automatically deriving a hardware implementation from a high-level task description. In this paper we present a novel technique that exploits previously explored implementation design spaces in order to find optimal trade-offs for new high-level descriptions. This technique is generalizable to a range of high-level synthesis problems in which trade-offs can be exposed by changing the parameters of the hardware generation tool. Our strategy, based upon machine learning techniques, models the impact of the parameterization of the tool on the target objectives, given the characteristics of the input. Thus, a predictor is able to suggest a subset of parameters that are likely to lead to optimal hardware implementations. The proposed method is evaluated on a resource sharing problem which is typical in high level synthesis, where the trade-offs between area and performance need to be explored. In this case study, we show that the technique can reduce by two orders of magnitude the number of design points that need to be explored in order to find the Pareto optimal solutions. © 2012 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Huh S., Fienberg S.E.","Discriminative topic modeling based on manifold learning",2012,"ACM Transactions on Knowledge Discovery from Data",23,"10.1145/2086737.2086740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857717020&doi=10.1145%2f2086737.2086740&partnerID=40&md5=ad932bc2dc6f36214f030e5a1b4fdffd","Topic modeling has become a popular method used for data analysis in various domains including text documents. Previous topic model approaches, such as probabilistic Latent Semantic Analysis (pLSA) and Latent Dirichlet Allocation (LDA), have shown impressive success in discovering low-rank hidden structures for modeling text documents. These approaches, however do not take into account the manifold structure of the data, which is generally informative for nonlinear dimensionality reduction mapping. More recent topic model approaches, Laplacian PLSI (LapPLSI) and Locally-consistent Topic Model (LTM), have incorporated the local manifold structure into topic models and have shown resulting benefits. But they fall short of achieving full discriminating power of manifold learning as they only enhance the proximity between the low-rank representations of neighboring pairs without any consideration for non-neighboring pairs. In this article, we propose a new approach, Discriminative Topic Model (DTM), which separates non-neighboring pairs from each other in addition to bringing neighboring pairs closer together, thereby preserving the global manifold structure as well as improving local consistency. We also present a novel model-fitting algorithm based on the generalized EM algorithm and the concept of Pareto improvement. We empirically demonstrate the success of DTM in terms of unsupervised clustering and semisupervised classification accuracies on text corpora and robustness to parameters compared to state-of-the-art techniques. © 2012 ACM.","Dimensionality reduction; Document clustering and classification; Semisupervised learning; Topic modeling",
"Yoshiyama K., Sakurai A.","Manifold-regularized minimax probability machine",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-642-28258-4_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857411643&doi=10.1007%2f978-3-642-28258-4_5&partnerID=40&md5=eafbeec8c66d922220d8c763a38ba92f","In this paper we propose Manifold-Regularized Minimax Probability Machine, called MRMPM. We show that Minimax Probability Machine can properly be extended to semi-supervised version in the manifold regularization framework and that its kernelized version is obtained for non-linear case. Our experiments show that the proposed methods achieve results competitive to existing learning methods, such as Laplacian Support Vector Machine and Laplacian Regularized Least Square for publicly available datasets from UCI machine learning repository. © 2012 Springer-Verlag.",,
"Tian J., Li M., Chen F., Kou J.","Coevolutionary learning of neural network ensemble for complex classification tasks",2012,"Pattern Recognition",30,"10.1016/j.patcog.2011.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-83655163794&doi=10.1016%2fj.patcog.2011.09.012&partnerID=40&md5=0f2f75983fbd9330072630ace268914b","Ensemble approaches to classification have attracted a great deal of interest recently. This paper presents a novel method for designing the neural network ensemble using coevolutionary algorithm. The bootstrap resampling procedure is employed to obtain different training subsets that are used to estimate different component networks of the ensemble. Then the cooperative coevolutionary algorithm is developed to optimize the ensemble model via the divide-and-cooperative mechanism. All component networks are coevolved in parallel in the scheme of interacting co-adapted subpopulations. The fitness of an individual from a particular subpopulation is assessed by associating it with the representatives from other subpopulations. In order to promote the cooperation of all component networks, the proposed method considers both the accuracy and the diversity among the component networks that are evaluated using the multi-objective Pareto optimality measure. A hybrid output-combination method is designed to determine the final ensemble output. Experimental results illustrate that the proposed method is able to obtain neural network ensemble models with better classification accuracy in comparison with currently popular ensemble algorithms. © 2011 Elsevier Ltd All rights reserved.","Classification; Coevolutionary algorithm; Ensemble learning; Neural network",
"Li C., Singh V.P., Mishra A.K.","Simulation of the entire range of daily precipitation using a hybrid probability distribution",2012,"Water Resources Research",53,"10.1029/2011WR011446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859184993&doi=10.1029%2f2011WR011446&partnerID=40&md5=37776e9a3bd90c84b5a069a5e9c4bf0c","Underestimation of extreme values is a widely acknowledged issue in daily precipitation simulation. Nonparametric precipitation generators have inherent limitations in representing extremes. Parametric generators can realistically model the full spectrum of precipitation amount through compound distributions. Nevertheless, fitting these distributions suffers from numerical instability, supervised learning, and computational demand. This study presents an easy-to-implement hybrid probability distribution to model the full spectrum of precipitation amount. The basic idea for the hybrid distribution lies in synthesizing low to moderate precipitation by an exponential distribution and extreme precipitation by a generalized Pareto distribution. By forcing the two distributions to be continuous at the junction point, the threshold of the generalized Pareto distribution can be implicitly learned in an unsupervised manner. Monte Carlo simulation shows that the hybrid distribution is capable of modeling heavy tailed data. Performance of the distribution is further evaluated using 49 daily precipitation records across Texas. Results show that the model is able to capture both the bulk and the tail of daily precipitation amount. The maximum goodness-of-fit and penalized maximum likelihood methods are found to be reliable complements to the maximum likelihood method, in that generally they can provide adequate goodness-of-fit. The proposed distribution can be incorporated into precipitation generators and downscaling models in order to realistically simulate the entire range of precipitation without losing extreme values. Copyright 2012 by the American Geophysical Union.",,
"Zuluaga M., Krause A., Milder P., Püschel M.","Smart design space sampling to predict pareto-optimal solutions",2012,"ACM SIGPLAN Notices",15,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866340251&partnerID=40&md5=74eca3d9685067e3b4aff73dc07d1c99","Many high-level synthesis tools offer degrees of freedom in mapping high-level specifications to Register-Transfer Level descriptions. These choices do not affect the functional behavior but span a design space of different cost-performance tradeoffs. In this paper we present a novel machine learning-based approach that efficiently determines the Pareto-optimal designs while only sampling and synthesizing a fraction of the design space. The approach combines three key components: (1) A regression model based on Gaussian processes to predict area and throughput based on synthesis training data. (2) A ""smart"" sampling strategy, GP-PUCB, to iteratively refine the model by carefully selecting the next design to synthesize to maximize progress. (3) A stopping criterion based on assessing the accuracy of the model without access to complete synthesis data. We demonstrate the effectiveness of our approach using IP generators for discrete Fourier transforms and sorting networks. However, our algorithm is not specific to this application and can be applied to a wide range of Pareto front prediction problems. Copyright © 2012 ACM.","Area and performance estimation; High-level synthesis; Machine learning; Pareto optimality",
"Agarwal A., Bartlett P.L., Ravikumar P., Wainwright M.J.","Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization",2012,"IEEE Transactions on Information Theory",100,"10.1109/TIT.2011.2182178","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860244324&doi=10.1109%2fTIT.2011.2182178&partnerID=40&md5=6b1b49c5670aaf8e93f00d82caaca52f","Relative to the large literature on upper bounds on complexity of convex optimization, lesser attention has been paid to the fundamental hardness of these problems. Given the extensive use of convex optimization in machine learning and statistics, gaining an understanding of these complexity-theoretic issues is important. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We introduce a new notion of discrepancy between functions, and use it to reduce problems of stochastic convex optimization to statistical parameter estimation, which can be lower bounded using information-theoretic methods. Using this approach, we improve upon known results and obtain tight minimax complexity estimates for various function classes. © 2011 IEEE.","Computational learning theory; convex optimization; Fano's inequality; information-based complexity; minimax analysis; oracle complexity",
"Dutta D., Dutta P., Sil J.","Clustering by multi objective genetic algorithm",2012,"2012 1st International Conference on Recent Advances in Information Technology, RAIT-2012",13,"10.1109/RAIT.2012.6194619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862109101&doi=10.1109%2fRAIT.2012.6194619&partnerID=40&md5=b01e5b7d93719d3220c2aa8a8d5562f3","The aim of the paper is to study a real coded multi objective genetic algorithm based K-clustering, where K represents the number of clusters, may be known or unknown. If the value of K is known, it is called K-clustering algorithm. The searching power of Genetic Algorithm (GA) is exploited to get for proper clusters and centers of clusters in the feature space to optimize simultaneously intra-cluster distance (Homogeneity) (H) and inter-cluster distances (Separation) (S). Maximization of 1/H and S are the twin objectives of Multi Objective Genetic Algorithm (MOGA) achieved by measuring H and S using Euclidean distance metric, suitable for continuous features (attributes). We have selected 10 data sets from the UCI machine learning repository containing continuous features only to validate the proposed algorithms. All-important steps of algorithms are shown here. At the end, classification accuracies obtained by best chromosomes are shown. © 2012 IEEE.","Clustering; homogeneity and separation; Pareto optimal front; real coded multi objective genetic algorithm",
"Stalph P.O., Rubinsztajn J., Sigaud O., Butz M.V.","Function approximation with LWPR and XCSF: A comparative study",2012,"Evolutionary Intelligence",7,"10.1007/s12065-012-0082-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861636511&doi=10.1007%2fs12065-012-0082-7&partnerID=40&md5=35a1e9c8976bf465a328b71664668040","Function approximation, also called regression, is an important tool in numerical mathematics and engineering. The most challenging approximation problems arise, when the function class is unknown and the surface has to be approximated online from incoming samples. One way to achieve good approximations of complex non-linear functions is to cluster the input space into small patches, apply linear models in each niche, and recombine these models via a weighted sum. While it is rather simple to optimally fit a linear model to given data, it is fairly complex to find a reasonable structuring of the input space in order to exploit linearities in the underlying function. We compare two non-parametric regression algorithms that are able to approximate multi-dimensional, non-linear functions online. The XCSF Learning Classifier System is a modified version of XCS, which is a genetics-based machine learning algorithm. Locally Weighted Projection Regression is a statistics-based machine learning technique that is mainly used for function approximation tasks in robotics. For both algorithms the relevant, conflicting performance criteria are accuracy and population size, that is, the number of local models. We explore the trade-off between those criteria on three benchmark problems by means of intense grid search for Pareto optimal solutions. Detailed learning behavior is investigated using selected Pareto optimal parameters. The illustration of final input space clusterings sheds light on the structuring capabilities. A discussion of advantages and drawbacks completes this comparative study. © 2012 Springer-Verlag.","LWPR; Machine learning; Non-parametric regression; XCSF",
"Zafra A., Ventura S.","Multi-objective approach based on grammar-guided genetic programming for solving multiple instance problems",2012,"Soft Computing",3,"10.1007/s00500-011-0794-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861007399&doi=10.1007%2fs00500-011-0794-0&partnerID=40&md5=57a16c6c3cf84d86913aa1862e45bf18","Multiple instance learning (MIL) is considered a generalization of traditional supervised learning which deals with uncertainty in the information. Together with the fact that, as in any other learning framework, the classifier performance evaluation maintains a trade-off relationship between different conflicting objectives, this makes the classification task less straightforward. This paper introduces a multi-objective proposal that works in a MIL scenario to obtain well-distributed Pareto solutions to multi-instance problems. The algorithm developed, Multi-Objective Grammar Guided Genetic Programming for Multiple Instances (MOG3P-MI), is based on grammar-guided genetic programming, which is a robust tool for classification. Thus, this proposal combines the advantages of the grammar-guided genetic programming with benefits provided by multi-objective approaches. First, a study of multi-objective optimization for MIL is carried out. To do this, three different extensions of MOG3P-MI are designed and implemented and their performance is compared. This study allows us on the one hand, to check the performance of multi-objective techniques in this learning paradigm and on the other hand, to determine the most appropriate evolutionary process for MOG3P-MI. Then, MOG3P-MI is compared with some of the most significant proposals developed throughout the years in MIL. Computational experiments show that MOG3P-MI often obtains consistently better results than the other algorithms, achieving the most accurate models. Moreover, the classifiers obtained are very comprehensible. © 2011 Springer-Verlag.","Evolutionary rule learning; Grammar guided genetic programming; Multiple instance learning; Multiple objective learning",
"Ali A., Meilǎ M.","Experiments with Kemeny ranking: What works when?",2012,"Mathematical Social Sciences",93,"10.1016/j.mathsocsci.2011.08.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861777150&doi=10.1016%2fj.mathsocsci.2011.08.008&partnerID=40&md5=54b0be4936f6737a0f330d559dba06da","This paper performs a comparison of several methods for Kemeny rank aggregation (104 algorithms and combinations thereof in total) originating in social choice theory, machine learning, and theoretical computer science, with the goal of establishing the best trade-offs between search time and performance. We find that, for this theoretically NP-hard task, in practice the problems span three regimes: strong consensus, weak consensus, and no consensus. We make specific recommendations for each, and propose a computationally fast test to distinguish between the regimes.In spite of the great variety of algorithms, there are few classes that are consistently Pareto optimal. In the most interesting regime, the integer program exact formulation, local search algorithms and the approximate version of a theoretically exact branch and bound algorithm arise as strong contenders. © 2011 Elsevier B.V.",,
"Zuluaga M., Krause A., Milder P., Püschel M.","""Smart"" design space sampling to predict pare-to-optimal solutions",2012,"Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)",11,"10.1145/2248418.2248436","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864153273&doi=10.1145%2f2248418.2248436&partnerID=40&md5=d04b2a5f5b4c098d2ff58def2e6f02f5","Many high-level synthesis tools offer degrees of freedom in mapping high-level specifications to Register-Transfer Level descriptions. These choices do not affect the functional behavior but span a design space of different cost-performance tradeoffs. In this paper we present a novel machine learning-based approach that efficiently determines the Pareto-optimal designs while only sampling and synthesizing a fraction of the design space. The approach combines three key components: (1) A regression model based on Gaussian processes to predict area and throughput based on synthesis training data. (2) A ""smart"" sampling strategy, GP-PUCB, to iteratively refine the model by carefully selecting the next design to synthesize to maximize progress. (3) A stopping criterion based on assessing the accuracy of the model without access to complete synthesis data. We demonstrate the effectiveness of our approach using IP generators for discrete Fourier transforms and sorting networks. However, our algorithm is not specific to this application and can be applied to a wide range of Pareto front prediction problems. Copyright © 2012 ACM.","Area and performance estimation; High-level synthesis; Machine learning; Pareto optimality",
"Phan D.H., Suzuki J., Hayashi I.","Leveraging indicator-based ensemble selection in evolutionary multiobjective optimization algorithms",2012,"GECCO'12 - Proceedings of the 14th International Conference on Genetic and Evolutionary Computation",9,"10.1145/2330163.2330234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864679467&doi=10.1145%2f2330163.2330234&partnerID=40&md5=6095eac42722b016bbb38309b111fa84","Various evolutionary multiobjective optimization algorithms (EMOAs) have replaced or augmented the notion of dominance with quality indicators and leveraged them in selection operators. Recent studies show that indicator-based EMOAs outperform traditional dominance-based EMOAs. This paper proposes and evaluates an ensemble learning method that constructs an ensemble of existing indicators with a novel boosting algorithm called Pdi-Boosting. The proposed method is carried out with a training problem in which Pareto-optimal solutions are known. It can work with a simple training problem, and an ensemble of indicators can effectively aid parent selection and environmental selection in order to solve harder problems. Experimental results show that the proposed method is efficient thanks to its dynamic adjustment of training data. An ensemble of indicators outperforms existing individual indicators in optimality, diversity and robustness. The proposed ensemble-based evolutionary algorithm outperforms a well-known dominance-based EMOA and existing indicator-based EMOAs. © 2012 ACM.","boosting; evolutionary multiobjective optimization algorithms; indicator-based ensemble selection; quality indicators",
"Bonissone P.P.","Lazy meta-learning: Creating customized model ensembles on demand",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",12,"10.1007/978-3-642-30687-7_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864973312&doi=10.1007%2f978-3-642-30687-7_1&partnerID=40&md5=1d9209315898e10c8417a53ddf9e515f","In the not so distant future, we expect analytic models to become a commodity. We envision having access to a large number of data-driven models, obtained by a combination of crowdsourcing, crowdservicing, cloud-based evolutionary algorithms, outsourcing, in-house development, and legacy models. In this new context, the critical question will be model ensemble selection and fusion, rather than model generation. We address this issue by proposing customized model ensembles on demand, inspired by Lazy Learning. In our approach, referred to as Lazy Meta-Learning, for a given query we find the most relevant models from a DB of models, using their meta-information. After retrieving the relevant models, we select a subset of models with highly uncorrelated errors. With these models we create an ensemble and use their meta-information for dynamic bias compensation and relevance weighting. The output is a weighted interpolation or extrapolation of the outputs of the models ensemble. Furthermore, the confidence interval around the output is reduced as we increase the number of uncorrelated models in the ensemble. We have successfully tested this approach in a power plant management application. © 2012 Springer-Verlag.","coal-fired power plant management; computational intelligence; ensemble; entropy; fusion; lazy learning; Machine learning; meta-learning; neural networks; Pareto set",
"Costa M.A., Braga A.P., de Menezes B.R.","Convergence analysis of sliding mode trajectories in multi-objective neural networks learning",2012,"Neural Networks",8,"10.1016/j.neunet.2012.04.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863880041&doi=10.1016%2fj.neunet.2012.04.006&partnerID=40&md5=a3745b94673063ae99b9709420aac380","The Pareto-optimality concept is used in this paper in order to represent a constrained set of solutions that are able to trade-off the two main objective functions involved in neural networks supervised learning: data-set error and network complexity. The neural network is described as a dynamic system having error and complexity as its state variables and learning is presented as a process of controlling a learning trajectory in the resulting state space. In order to control the trajectories, sliding mode dynamics is imposed to the network. It is shown that arbitrary learning trajectories can be achieved by maintaining the sliding mode gains within their convergence intervals. Formal proofs of convergence conditions are therefore presented. The concept of trajectory learning presented in this paper goes further beyond the selection of a final state in the Pareto set, since it can be reached through different trajectories and states in the trajectory can be assessed individually against an additional objective function. © 2012 Elsevier Ltd.","Multi-objective learning; Neural networks; Sliding mode",
"Thill M., Koch P., Konen W.","Reinforcement learning with n-tuples on the game connect-4",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",15,"10.1007/978-3-642-32937-1_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866370625&doi=10.1007%2f978-3-642-32937-1_19&partnerID=40&md5=975fca71539e3fa62c3d4a884241bd94","Learning complex game functions is still a difficult task. We apply temporal difference learning (TDL), a well-known variant of the reinforcement learning approach, in combination with n-tuple networks to the game Connect-4. Our agent is trained just by self-play. It is able, for the first time, to consistently beat the optimal-playing Minimax agent (in game situations where a win is possible). The n-tuple network induces a mighty feature space: It is not necessary to design certain features, but the agent learns to select the right ones. We believe that the n-tuple network is an important ingredient for the overall success and identify several aspects that are relevant for achieving high-quality results. The architecture is sufficiently general to be applied to similar reinforcement learning tasks as well. © 2012 Springer-Verlag.","board games; feature generation; Machine learning; n-tuple systems; reinforcement learning; self-play; TDL",
"Takeda A., Mitsugi H., Kanamori T.","A unified robust classification model",2012,"Proceedings of the 29th International Conference on Machine Learning, ICML 2012",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867129653&partnerID=40&md5=563d32ee4c7880b34867851219ce6756","A wide variety of machine learning algorithms such as support vector machine (SVM), minimax probability machine (MPM), and Fisher discriminant analysis (FDA), exist for binary classification. The purpose of this paper is to provide a unified classification model that includes the above models through a robust optimization approach. This unified model has several benefits. One is that the extensions and improvements intended for SVM become applicable to MPM and FDA, and vice versa. Another benefit is to provide theoretical results to above learning methods at once by dealing with the unified model. We give a statistical interpretation of the unified classification model and propose a non-convex optimization algorithm that can be applied to non-convex variants of existing learning methods. Copyright 2012 by the author(s)/owner(s).",,
"Torres L.C.B., Castro C.L., Braga A.P.","A computational geometry approach for pareto-optimal selection of neural networks",2012,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-642-33266-1_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867671055&doi=10.1007%2f978-3-642-33266-1_13&partnerID=40&md5=ffdfee7ef980a7a371559b76abc38400","This paper presents a Pareto-optimal selection strategy for multiobjective learning that is based on the geometry of the separation margin between classes. The Gabriel Graph, a method borrowed from Computational Geometry, is constructed in order to obtain margin patterns and class borders. From border edges, a target separator is obtained in order to obtain a large margin classifier. The selected model from the generated Pareto-set is the one that is closer to the target separator. The method presents robustness in both synthetic and real benchmark datasets. It is efficient for Pareto-Optimal selection of neural networks and no claim is made that the obtained solution is equivalent to a maximum margin separator. © 2012 Springer-Verlag.","classification; decision-making; gabriel graph; multiobjective machine learning",
"Guo C., Ryoo H.S.","Compact MILP models for optimal and Pareto-optimal LAD patterns",2012,"Discrete Applied Mathematics",21,"10.1016/j.dam.2012.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865084222&doi=10.1016%2fj.dam.2012.05.006&partnerID=40&md5=c1330b6a07966f56df7deb49233faab9","This paper develops MILP models for various optimal and Pareto-optimal LAD patterns that involve at most 2n 01 decision variables, where n is the number of support features for the data under analysis, which usually is small. Noting that the previous MILP pattern generation models are defined in 2n+m 01 variables, where m is the number of observations in the dataset with m≫n in general, the new models are expected to generate useful LAD patterns more efficiently. With experiments on six well-studied machine learning datasets, we first demonstrate the efficiency of the new MILP models and next use them to show different utilities of strong prime patterns and strong spanned patterns in enhancing the overall classification accuracy of a LAD decision theory. © 2012 Elsevier B.V. All rights reserved.","LAD; Maximum prime pattern; Maximum spanned pattern; MILP; Strong prime pattern; Strong spanned pattern",
"Galvan E., Malak R.","A genetic algorithm approach for technology characterization",2012,"Proceedings of the ASME Design Engineering Technical Conference",6,"10.1115/DETC2012-70465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884598673&doi=10.1115%2fDETC2012-70465&partnerID=40&md5=21c6e43f8ac7418784f9660933aa0a13","It is important for engineers to understand the capabilities and limitations of the technologies they consider for use in their systems. Several researchers have investigated approaches for modeling the capabilities of a technology with the aim of supporting the design process. In these works, the information about the physical form is typically abstracted away. However, the efficient generation of an accurate model of technical capabilities remains a challenge. Pareto frontier based methods are often used but yield results that are of limited use for subsequent decision making and analysis. Models based on parameterized Pareto frontiers-Termed Technology Characterization Models (TCMs)-Are much more reusable and composable. However, there exists no efficient technique for modeling the parameterized Pareto frontier. The contribution of this paper is a new algorithm for modeling the parameterized Pareto frontier to be used as a model of the characteristics of a technology. The proposed algorithm uses fundamental concepts from multiobjective genetic optimization and machine learning to generate a model of the technology frontier. © 2012 by ASME.",,
"Litao Z., Tiejun W., Xi J., Jin J.","The machine learning classifier based on Multi-Objective Genetic Algorithm",2012,"Proceedings - 2012 7th International Conference on Computing and Convergence Technology (ICCIT, ICEI and ICACT), ICCCT 2012",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881167866&partnerID=40&md5=4c8828077c9c21a447365929928c2913","This paper presents a machine learning classifier algorithm based on MOGA (Multi-Objective Genetic Algorithm), which applies the information entropy theory to optimize the MOGA and then can be used to discretize the continuous attributes. According to the practical problems, the fitness vector can be constructed by judging multi-objective functions to find the Pareto optimal solutions. Combining the classic set theories with the two relationships, i.e. coverage and contradictory, between chromosomes, more reasonable selection rules can be worked out to delete the redundant chromosomes and get more efficient classification rules. The new algorithm was applied to Iris and Wine dataset from UCI. By comparison, the algorithm in this paper has higher classification accuracy than KNN, C4.5 and NaiveBayes. © 2012 AICIT.","Delete Rule; Discrete; Learning Classifier; MOGA; Multi-Objective; Pareto Optimization",
"Dutta D., Dutta P., Sil J.","Simultaneous feature selection and clustering for categorical features using multi objective genetic algorithm",2012,"Proceedings of the 2012 12th International Conference on Hybrid Intelligent Systems, HIS 2012",7,"10.1109/HIS.2012.6421332","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874183876&doi=10.1109%2fHIS.2012.6421332&partnerID=40&md5=87ac07da52c260bf99c298f74451c0a0","Clustering is unsupervised learning where ideally class levels and number of clusters (K) are not known. K-clustering can be categorized as semi-supervised learning where K is known. Here we have considered K-Clustering with simultaneous feature selection. Feature subset selection helps to identify relevant features for clustering, increase understandability, better scalability and improve accuracy. Here we have used two measures, intra-cluster distance (Homogeneity, H) and inter-cluster distances (Separation, S) for clustering. Measures are using mod distance per feature suitable for categorical features (attributes). Rather than combining H and S to frame the problem as single objective optimization problem, we use multi objective genetic algorithm (MOGA) to find out diverse solutions near to Pareto optimal front in the two-dimensional objective space. Each evolved solution represents a set of cluster modes (CMs) build by selected feature subset. Here, K-modes is hybridized with MOGA. We have used hybridized GA to combine global searching powers of GA with local searching powers of K-modes. Considering context sensitivity, we have used a special crossover operator called 'pairwise crossover' and 'substitution'. The main contribution of this paper is simultaneous dimensionality reduction and optimization of objectives using MOGA. Results on 3 benchmark data sets from UCI Machine Learning Repository containing categorical features shows the superiority of the algorithm. © 2012 IEEE.",,
"Utkin L.V., Zhuk Y.A., Selikhovkin I.A.","A classification model based on incomplete information on features in the form of their average values",2012,"Scientific and Technical Information Processing",3,"10.3103/S0147688212060068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872961895&doi=10.3103%2fS0147688212060068&partnerID=40&md5=5bef54958621657f59b8bfebfb2b5d42","This paper presents a model of classification under incomplete information in the form of mathematical expectations of features; it is based on the minimax (minimin) strategy of decision making. The discriminant function is calculated by maximization (minimization) of the risk functional as a measure of misclassification, by a set of distributions of probabilities with bounds determined by information on features, and minimization by the set of parameters. The algorithm is reduced to solution of the parametric problem of linear programming. © 2012 Allerton Press, Inc.","classification; linear programming; machine learning; mathematical expectation; minimax strategy; risk functional; the loss function",
"Alamaniotis M., Ikonomopoulos A., Tsoukalas L.H.","Optimal assembly of support vector regressors with application to system monitoring",2012,"International Journal on Artificial Intelligence Tools",6,"10.1142/S0218213012500340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872190390&doi=10.1142%2fS0218213012500340&partnerID=40&md5=17342f8ba60eb58fc74ef6c527790c1d","Power plants are high complexity systems running risks of low frequency but high consequence. The field of machine learning appears to offer the necessary tools for developing automated instrument surveillance systems supporting decision-making in critical systems such as power stations. A novel prediction method is presented with the aim to enhance system safety and performance by making an ahead-of-time prediction of the status of fundamental system components and subsequent detection of abnormalities. The utilization of a linear assembly of support vector regressors employing unique kernels is proposed in a hybrid computational scheme that encompasses the formulation of a multi-objective optimization problem addressed with an evolutionary algorithm that employs Pareto theory to identify an optimal solution. The approach is tested on the ahead of time prediction of the crack length in power plant turbine blades utilizing historical data. The results obtained highlight the efficiency of the proposed methodology since better performance over the standalone support vector regressors is observed. © 2012 World Scientific Publishing Company.","multi-objective optimization; parameter monitoring; Pareto optimal; SVR",
"Van Moffaert K., Drugan M.M., Nowé A.","Scalarized multi-objective reinforcement learning: Novel design techniques",2013,"Belgian/Netherlands Artificial Intelligence Conference",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072668093&partnerID=40&md5=362adbe0fe603f924f5cb5cac90037b7","In multi-objective problems, it is key to find compromising solutions that balance different objectives. The linear scalarization function is often utilized to translate the multi-objective nature of a problem into a standard, single-objective problem. Generally, it is noted that such as linear combination can only find solutions in convex areas of the Pareto front, therefore making the method inapplicable in situations where the shape of the front is not known beforehand. We propose a non-linear scalarization function, called the Chebyshev scalarization function in multi-objective reinforcement learning. We show that the Chebyshev scalarization method overcomes the flaws of the linear scalarization function and is able to discover all Pareto optimal solutions in non-convex environments. © 2013 University of Groningen. All rights reserved.",,"University of Groningen"
"Dutta D., Dutta P., Sil J.","Categorical feature reduction using multi objective genetic Algorithm in cluster analysis",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/978-3-642-45318-2_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892713608&doi=10.1007%2f978-3-642-45318-2_7&partnerID=40&md5=70ff4a45dc55f45274819ea969b5503c","In the paper, real coded multi objective genetic algorithm based K-clustering method has been studied, K represents the number of clusters. In K-clustering algorithm value of K is known. The searching power of Genetic Algorithm (GA) is exploited to search for suitable clusters and centers of clusters so that intra-cluster distance (Homogeneity, H) and inter-cluster distances (Separation, S) are simultaneously optimized. It is achieved by measuring H and S using Mod distance per feature metric, suitable for categorical features (attributes). We have selected 3 benchmark data sets from UCI Machine Learning Repository containing categorical features only. The paper proposes two versions of MOGA based K-clustering algorithm. In proposed MOGA (H, S), all features are taking part in building chromosomes and calculation of H and S values. In MOGA-Feature-Selection (H, S), selected features take part to build chromosomes, relevant for clusters. Here, K-modes is hybridized with GA. We have used hybridized GA to combine global searching capabilities of GA with local searching capabilities of K-modes. Considering context sensitivity, we have used a special crossover operator called ""pairwise crossover"" and ""substitution"". The main contribution of this paper is simultaneous dimensionality reduction and optimization of objectives using MOGA. © 2013 Springer-Verlag Berlin Heidelberg.","Clustering; dimensionality reduction; homogeneity and separation; Pareto optimal front; real coded multi objective genetic algorithm","Springer Verlag"
"Zhao J., Ding Y., Xu G., Hu L., Dong Y., Fu X.","A location selection policy of live virtual machine migration for power saving and load balancing",2013,"The Scientific World Journal",19,"10.1155/2013/492615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890092998&doi=10.1155%2f2013%2f492615&partnerID=40&md5=2ccad30867d407c216530190ae047e54","Green cloud data center has become a research hotspot of virtualized cloud computing architecture. And load balancing has also been one of the most important goals in cloud data centers. Since live virtual machine (VM) migration technology is widely used and studied in cloud computing, we have focused on location selection (migration policy) of live VM migration for power saving and load balancing. We propose a novel approach MOGA-LS, which is a heuristic and self-adaptive multiobjective optimization algorithm based on the improved genetic algorithm (GA). This paper has presented the specific design and implementation of MOGA-LS such as the design of the genetic operators, fitness values, and elitism. We have introduced the Pareto dominance theory and the simulated annealing (SA) idea into MOGA-LS and have presented the specific process to get the final solution, and thus, the whole approach achieves a long-term efficient optimization for power saving and load balancing. The experimental results demonstrate that MOGA-LS evidently reduces the total incremental power consumption and better protects the performance of VM migration and achieves the balancing of system load compared with the existing research. It makes the result of live VM migration more high-effective and meaningful. © 2013 Jia Zhao et al.",,"Hindawi Publishing Corporation"
"Lourenço N., Martins R., Barros M., Horta N.","Analog circuit design based on robust POFs using an enhanced MOEA with SVM models",2013,"Lecture Notes in Electrical Engineering",8,"10.1007/978-3-642-36329-0_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884550184&doi=10.1007%2f978-3-642-36329-0_7&partnerID=40&md5=14d477c5f6520e88c4ab710b0f0acb3e","In this chapter, a multi-objective design methodology for automatic analog integrated circuits (IC) synthesis, which enhances the robustness of the solution by varying technological and environmental parameters, is presented. The automatic analog IC sizing tool GENOM-POF was implemented and used to demonstrate the methodology, and to verify the effect of corner cases on the Pareto optimal front (POF). To enhance the efficiency of the tool, a supervised learning strategy, which is based on Support Vector Machines (SVM), is used to create feasibility models that efficiently prune the design search space during the optimization process, thus, reducing the overall number of required evaluations. The GPOF-SVM optimization kernel consists of a modified version of the multi-objective evolutionary algorithm (MOEA), NSGA-II, and uses HSPICE® as the evaluation engine. The usage of standard inputs and outputs eases the integration with other design automation tools, either at system level or at physical level, which is the case of LAYGEN, an in-house layout generation tool. Finally, the approach was validated using benchmark examples, which consist of circuits tested with similar tools, particularly, the former GENOM tool and other tools from literature. © Springer-Verlag Berlin Heidelberg 2013.",,"Springer Verlag"
"Utkin L.V., Zhuk Y.A.","Robust novelty detection in the framework of a contamination neighbourhood",2013,"International Journal of Intelligent Information and Database Systems",5,"10.1504/IJIIDS.2013.053830","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877766783&doi=10.1504%2fIJIIDS.2013.053830&partnerID=40&md5=942e4b23260408e58a09b166cbd550db","A novelty detection robust model is studied in the paper. It is based on contaminated (robust) models which produce a set of probability distributions of data points instead of the empirical distribution. The minimax and minimin strategies are used to construct optimal separating functions. An algorithm for computing the optimal parameters of the novelty detection model is reduced to a finite number of standard SVM tasks with weighted data points. Experimental results with synthetic and some real data illustrate the proposed novelty detection robust model. Copyright © 2013 Inderscience Enterprises Ltd.","Classification; Machine learning; Minimax strategy; Novelty detection; Quadratic programming; Support vector machine; SVM","Inderscience Publishers"
"Sinha A., Saxena D.K., Deb K., Tiwari A.","Using objective reduction and interactive procedure to handle many-objective optimization problems",2013,"Applied Soft Computing Journal",29,"10.1016/j.asoc.2012.08.030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869389860&doi=10.1016%2fj.asoc.2012.08.030&partnerID=40&md5=8fd265dd2dd4126d6485f074719e7a96","A number of practical optimization problems are posed as many-objective (more than three objectives) problems. Most of the existing evolutionary multi-objective optimization algorithms, which target the entire Pareto-front are not equipped to handle many-objective problems. Though there have been copious efforts to overcome the challenges posed by such problems, there does not exist a generic procedure to effectively handle them. This paper presents a simplify and solve framework for handling many-objective optimization problems. In that, a given problem is simplified by identification and elimination of the redundant objectives, before interactively engaging the decision maker to converge to the most preferred solution on the Pareto-optimal front. The merit of performing objective reduction before interacting with the decision maker is two fold. Firstly, the revelation that certain objectives are redundant, significantly reduces the complexity of the optimization problem, implying lower computational cost and higher search efficiency. Secondly, it is well known that human beings are not efficient in handling several factors (objectives in the current context) at a time. Hence, simplifying the problem a priori addresses the fundamental issue of cognitive overload for the decision maker, which may help avoid inconsistent preferences during the different stages of interactive engagement. The implementation of the proposed framework is first demonstrated on a three-objective problem, followed by its application on two real-world engineering problems. © 2012 Elsevier B.V. All rights reserved.","Evolutionary algorithms; Evolutionary multi- and many-objective optimization; Interactive optimization; Machine learning; Multi-criteria decision making",
"Horata P., Chiewchanwattana S., Sunat K.","Robust extreme learning machine",2013,"Neurocomputing",128,"10.1016/j.neucom.2011.12.045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870248640&doi=10.1016%2fj.neucom.2011.12.045&partnerID=40&md5=9c8b36f1092bc68679493201db21601d","The output weights computing of extreme learning machine (ELM) encounters two problems, the computational and outlier robustness problems. The computational problem occurs when the hidden layer output matrix is a not full column rank matrix or an ill-conditioned matrix because of randomly generated input weights and biases. An existing solution to this problem is Singular Value Decomposition (SVD) method. However, the training speed is still affected by the large complexity of SVD when computing the Moore-Penrose (MP) pseudo inverse. The outlier robustness problem may occur when the training data set contaminated with outliers then the accuracy rate of ELM is extremely affected. This paper proposes the Extended Complete Orthogonal Decomposition (ECOD) method to solve the computational problem in ELM weights computing via ECODLS algorithm. And the paper also proposes the other three algorithms, i.e. the iteratively reweighted least squares (IRWLS-ELM), ELM based on the multivariate least-trimmed squares (MLTS-ELM), and ELM based on the one-step reweighted MLTS (RMLTS-ELM) to solve the outlier robustness problem. However, they also encounter the computational problem. Therefore, the ECOD via ECODLS algorithm is also used successfully in the three proposed algorithms. The experiments of regression problems were conducted on both toy and real-world data sets. The outlier types are one-sided and two-sided outliers. Each experiment was randomly contaminated with outliers, of one type only, with 10%, 20%, 30%, 40%, and 50% of the total training data size. Meta-metrics evaluation was used to measure the outlier robustness of the proposed algorithms compared to the existing algorithms, i.e. the minimax probability machine regression (MPMR) and the ordinary ELM. The experimental results showed that ECOD can effectively replace SVD. The ECOD is robust to the not full column rank or the ill-conditional problem. The speed of the ELM training using ECOD is also faster than the ordinary training algorithm. Moreover, the meta-metrics measure showed that the proposed algorithms are less affected by the increasing number of outliers than the existing algorithms. © 2012 Elsevier B.V.","Extended Complete Orthogonal Decomposition; Extreme learning machine; Iteratively reweighted least squares; Meta-metrics evaluation; Minimax probability machine regression; Moore-Penrose pseudo inverse; Multivariate least-trimmed squares; Outlier; Robustness; Singular Value Decomposition",
"Mozaffari A., Gorji-Bandpy M., Samadian P., Rastgar R., Rezania Kolaei A.","Comprehensive preference optimization of an irreversible thermal engine using pareto based mutable smart bee algorithm and generalized regression neural network",2013,"Swarm and Evolutionary Computation",19,"10.1016/j.swevo.2012.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875210352&doi=10.1016%2fj.swevo.2012.11.004&partnerID=40&md5=6d9c1d6a63f85dc07bf68d865405e4b8","Optimizing and controlling of complex engineering systems is a phenomenon that has attracted an incremental interest of numerous scientists. Until now, a variety of intelligent optimizing and controlling techniques such as neural networks, fuzzy logic, game theory, support vector machines and stochastic algorithms were proposed to facilitate controlling of the engineering systems. In this study, an extended version of mutable smart bee algorithm (MSBA) called Pareto based mutable smart bee (PBMSB) is inspired to cope with multi-objective problems. Besides, a set of benchmark problems and four well-known Pareto based optimizing algorithms i.e. multi-objective bee algorithm (MOBA), multi-objective particle swarm optimization (MOPSO) algorithm, non-dominated sorting genetic algorithm (NSGA-II), and strength Pareto evolutionary algorithm (SPEA 2) are utilized to confirm the acceptable performance of the proposed method. In order to find the maximum exploration potentials, these techniques are equipped with an external archive. These archives aid the methods to record all of the non-dominated solutions. Eventually, the proposed method and generalized regression neural network (GRNN) are simultaneously used to optimize the major parameters of an irreversible thermal engine. In order to direct the PBMSB to explore deliberate spaces within the solution domain, a reference point obtained from finite time thermodynamic (FTT) approach, is utilized in the optimization. The outcome results show the acceptable performance of the proposed method to optimize complex real-life engineering systems. © 2012 Elsevier B.V. All rights reserved.","Comprehensive preference optimization; Generalized regression neural network; Irreversible thermal engine; Machine learning; Multiobjective optimization; Mutable smart bee algorithm",
"Valencia C., Yuan M.","Radial basis function regularization for linear inverse problems with random noise",2013,"Journal of Multivariate Analysis",2,"10.1016/j.jmva.2012.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871775986&doi=10.1016%2fj.jmva.2012.09.007&partnerID=40&md5=c93e1c726ab7884e29ccab8b8de8b397","In this paper, we study the statistical properties of the method of regularization with radial basis functions in the context of linear inverse problems. Radial basis function regularization is widely used in machine learning because of its demonstrated effectiveness in numerous applications and computational advantages. From a statistical viewpoint, one of the main advantages of radial basis function regularization in general and Gaussian radial basis function regularization in particular is their ability to adapt to varying degrees of smoothness in a direct problem. We show here that similar approaches for inverse problems not only share such adaptivity to the smoothness of the signal but also can accommodate different degrees of ill-posedness. These results render further theoretical support to the superior performance observed empirically for radial basis function regularization. © 2012 Elsevier Inc.","Inverse problem; Minimax rate of convergence; Primary; Radial basis function; Regularization",
"Bandaru S., Deb K.","A dimensionally-aware genetic programming architecture for automated innovization",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",10,"10.1007/978-3-642-37140-0_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875501275&doi=10.1007%2f978-3-642-37140-0_39&partnerID=40&md5=8bdb48b645c552994b828b832ccfe362","Automated innovization is an unsupervised machine learning technique for extracting useful design knowledge from Pareto-optimal solutions in the form of mathematical relationships of a certain structure. These relationships are known as design principles. Past studies have shown the applicability of automated innovization on a number of engineering design optimization problems using a multiplicative form for the design principles. In this paper, we generalize the structure of the obtained principles using a tree-based genetic programming framework. While the underlying innovization algorithm remains the same, evolving multiple trees, each representing a different design principle, is a challenging task. We also propose a method for introducing dimensionality information in the search process to produce design principles that are not just empirical in nature, but also meaningful to the user. The procedure is illustrated for three engineering design problems. © 2013 Springer-Verlag.","automated innovization; design principles; dimensional awareness; genetic programming; multi-objective optimization",
"Niyogi P.","Manifold regularization and semi-supervised learning: Some theoretical analyses",2013,"Journal of Machine Learning Research",49,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878920314&partnerID=40&md5=f1c77487da3bbae507d8aa9cdc3c7bdd","Manifold regularization (Belkin et al., 2006) is a geometrically motivated framework for machine learning within which several semi-supervised algorithms have been constructed. Here we try to provide some theoretical understanding of this approach. Our main result is to expose the natural structure of a class of problems on which manifold regularization methods are helpful. We show that for such problems, no supervised learner can learn effectively. On the other hand, a manifold based learner (that knows the manifold or learns it from unlabeled examples) can learn with relatively few labeled examples. Our analysis follows a minimax style with an emphasis on finite sample results (in terms of n: the number of labeled examples). These results allow us to properly interpret manifold regularization and related spectral and geometric algorithms in terms of their potential use in semi-supervised learning. © 2013 Partha Niyogi.","Graph Laplacian; Manifold regularization; Minimax rates; Semi-supervised learning",
"Cruz-Ramírez M., Hervás-Martínez C., Fernández J.C., Briceño J., de la Mata M.","Predicting patient survival after liver transplantation using evolutionary multi-objective artificial neural networks",2013,"Artificial Intelligence in Medicine",38,"10.1016/j.artmed.2013.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876956168&doi=10.1016%2fj.artmed.2013.02.004&partnerID=40&md5=356ce3321532d76245ac4decc4f86a0b","Objective: The optimal allocation of organs in liver transplantation is a problem that can be resolved using machine-learning techniques. Classical methods of allocation included the assignment of an organ to the first patient on the waiting list without taking into account the characteristics of the donor and/or recipient. In this study, characteristics of the donor, recipient and transplant organ were used to determine graft survival. We utilised a dataset of liver transplants collected by eleven Spanish hospitals that provides data on the survival of patients three months after their operations. Methods and material: To address the problem of organ allocation, the memetic Pareto evolutionary non-dominated sorting genetic algorithm 2 (MPENSGA2 algorithm), a multi-objective evolutionary algorithm, was used to train radial basis function neural networks, where accuracy was the measure used to evaluate model performance, along with the minimum sensitivity measurement. The neural network models obtained from the Pareto fronts were used to develop a rule-based system. This system will help medical experts allocate organs. Results: The models obtained with the MPENSGA2 algorithm generally yielded competitive results for all performance metrics considered in this work, namely the correct classification rate (C), minimum sensitivity (MS), area under the receiver operating characteristic curve (AUC), root mean squared error (RMSE) and Cohen's kappa (Kappa). In general, the multi-objective evolutionary algorithm demonstrated a better performance than the mono-objective algorithm, especially with regard to the MS extreme of the Pareto front, which yielded the best values of MS (48.98) and AUC (0.5659).The rule-based system efficiently complements the current allocation system (model for end-stage liver disease, MELD) based on the principles of efficiency and equity. This complementary effect occurred in 55% of the cases used in the simulation. The proposed rule-based system minimises the prediction probability error produced by two sets of models (one of them formed by models guided by one of the objectives (entropy) and the other composed of models guided by the other objective (MS)), such that it maximises the probability of success in liver transplants, with success based on graft survival three months post-transplant. Conclusion: The proposed rule-based system is objective, because it does not involve medical experts (the expert's decision may be biased by several factors, such as his/her state of mind or familiarity with the patient). This system is a useful tool that aids medical experts in the allocation of organs; however, the final allocation decision must be made by an expert. © 2013 Elsevier B.V.","Liver transplantation; Making decisions rule-based; Multi-objective evolutionary algorithm; Organ allocations; Radial basis function neural networks",
"Rizoiu M.-A., Velcin J., Lallich S.","Unsupervised feature construction for improving data representation and semantics",2013,"Journal of Intelligent Information Systems",3,"10.1007/s10844-013-0235-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878020277&doi=10.1007%2fs10844-013-0235-x&partnerID=40&md5=847b8e2ee58db3b0d007266bc669adac","Attribute-based format is the main data representation format used by machine learning algorithms. When the attributes do not properly describe the initial data, performance starts to degrade. Some algorithms address this problem by internally changing the representation space, but the newly constructed features rarely have any meaning. We seek to construct, in an unsupervised way, new attributes that are more appropriate for describing a given dataset and, at the same time, comprehensible for a human user. We propose two algorithms that construct the new attributes as conjunctions of the initial primitive attributes or their negations. The generated feature sets have reduced correlations between features and succeed in catching some of the hidden relations between individuals in a dataset. For example, a feature like sky \wedge \neg building \wedge panorama would be true for non-urban images and is more informative than simple features expressing the presence or the absence of an object. The notion of Pareto optimality is used to evaluate feature sets and to obtain a balance between total correlation and the complexity of the resulted feature set. Statistical hypothesis testing is employed in order to automatically determine the values of the parameters used for constructing a data-dependent feature set. We experimentally show that our approaches achieve the construction of informative feature sets for multiple datasets. © 2013 Springer Science+Business Media New York.","Algorithms for data and knowledge management; Clustering; Data mining; Feature evaluation; Heuristic methods; Nonparametric statistics; Pattern analysis; Representations; Unsupervised feature construction",
"Bhowan U., Johnston M., Zhang M., Yao X.","Evolving diverse ensembles using genetic programming for classification with unbalanced data",2013,"IEEE Transactions on Evolutionary Computation",143,"10.1109/TEVC.2012.2199119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878394942&doi=10.1109%2fTEVC.2012.2199119&partnerID=40&md5=5903a18bc423ee3322147d6c206bfd20","In classification, machine learning algorithms can suffer a performance bias when data sets are unbalanced. Data sets are unbalanced when at least one class is represented by only a small number of training examples (called the minority class), while the other class(es) make up the majority. In this scenario, classifiers can have good accuracy on the majority class, but very poor accuracy on the minority class(es). This paper proposes a multiobjective genetic programming (MOGP) approach to evolving accurate and diverse ensembles of genetic program classifiers with good performance on both the minority and majority of classes. The evolved ensembles comprise of nondominated solutions in the population where individual members vote on class membership. This paper evaluates the effectiveness of two popular Pareto-based fitness strategies in the MOGP algorithm (SPEA2 and NSGAII), and investigates techniques to encourage diversity between solutions in the evolved ensembles. Experimental results on six (binary) class imbalance problems show that the evolved ensembles outperform their individual members, as well as single-predictor methods such as canonical GP, naive Bayes, and support vector machines, on highly unbalanced tasks. This highlights the importance of developing an effective fitness evaluation strategy in the underlying MOGP algorithm to evolve good ensemble members. © 1997-2012 IEEE.","class imbalance learning; Classification; genetic programming (GP); multiobjective machine learning (ML)",
"Zhang C., Ravindran A.","A statistical machine learning based modeling and exploration framework for run-time cross-stack energy optimization",2013,"ISPASS 2013 - IEEE International Symposium on Performance Analysis of Systems and Software",,"10.1109/ISPASS.2013.6557161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881416262&doi=10.1109%2fISPASS.2013.6557161&partnerID=40&md5=633f17d7c2116ec0f5d3cd80ccb065d1","As the complexity of many-core processors grow, meeting performance, energy, temperature, reliability, and noise requirements under dynamically changing operating conditions requires run-time optimization of all parts of the computing stack - architecture, system software, and applications. Unfortunately, the combination of design parameters for the entire computing stack results in an operating space of millions of points that must be explored and evaluated at run-time. In this paper, we present a statistical machine learning (SML) based modeling framework that can be used to rapidly explore such vast operating spaces. We construct a multivariate adaptive regression spline (MARS) based model that uses a number of architecture and application parameters as predictor variables to predict performance and power. We then use a Pareto-front exploring evolutionary algorithm to determine operating points for optimal power and performance. The operating points constituting the Pareto front are stored in look-up tables for run-time use. The proposed framework is applied to an x264 video encoding application executing on a quad core processor. The microarchitectural predictor variables include core and cache parameters. The application predictor variables include the video resolution, and visual quality determined by the choice of the motion estimation algorithm. The model outputs the average frames per second (FPS) and the average power consumption. The MARS model has an R2 of 0.9657 and 0.9467 respectively for FPS and power. For a video frame resolution of 480×320, and FPS of 20, a power saving of 55% can be obtained by jointly tuning the microarchitectural parameters and the visual quality. © 2013 IEEE.","cross stack; energy; modeling; optimization; run-time",
"Bhowan U., Johnston M., Zhang M.","Comparing ensemble learning approaches in genetic programming for classification with unbalanced data",2013,"GECCO 2013 - Proceedings of the 2013 Genetic and Evolutionary Computation Conference Companion",1,"10.1145/2464576.2464643","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882443302&doi=10.1145%2f2464576.2464643&partnerID=40&md5=1e8c8784705547ba5fe65da9d58951d8","This paper compares three approaches to evolving ensembles in Genetic Programming (GP) for binary classification with unbalanced data. The first uses bagging with sampling, while the other two use Pareto-based multi-objective GP (MOGP) for the trade-off between the two (unequal) classes. In MOGP, two ways are compared to build the ensembles: using the evolved Pareto front alone, and using the whole evolved population of dominated and non-dominated individuals alike. Experiments on several benchmark (binary) unbalanced tasks find that smaller, more diverse ensembles chosen during ensemble selection perform best due to better generalisation, particularly when the combined knowledge of the whole evolved MOGP population forms the ensemble.","Clasfisification; Class imbalance; Genetic programming; Multi-objective optimisation",
"Rahimi S., McIntyre A.R., Heywood M.I., Zincir-Heywood N.","Label free change detection on streaming data with cooperative multi-objective genetic programming",2013,"GECCO 2013 - Proceedings of the 2013 Genetic and Evolutionary Computation Conference Companion",2,"10.1145/2464576.2464652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882374977&doi=10.1145%2f2464576.2464652&partnerID=40&md5=48e51b61c4a2f276f55dfe19f79451f5","Classification under streaming data conditions requires that the machine learning (ML) approach operate interactively with the stream content. Thus, given some initial ML clas- sification capability, it is not possible to assume that stream content will be stationary. It is therefore necessary to first detect when the stream content changes. Only after detect- ing a change, can classifier retraining be triggered. Current methods for change detection tend to assume an entropy fil- ter approach, where class labels are necessary. In practice, labeling the stream would be extremely expensive. This work proposes an approach in which the behaviour of GP individuals is used to detect change without the use of la- bels. Only after detecting a change is label information re- quested. Benchmarking under a computer network traffic analysis scenario demonstrates that the proposed approach performs at least as well as the filter method, while retaining the advantage of requiring no labels.","Coevolution; Dynamic environments; Genetic programming; Pareto archiving; Streaming data",
"Xu B., Chen H., Zhu W., Zhu X.","Multi-objective cost-sensitive attribute reduction",2013,"Proceedings of the 2013 Joint IFSA World Congress and NAFIPS Annual Meeting, IFSA/NAFIPS 2013",4,"10.1109/IFSA-NAFIPS.2013.6608602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886534468&doi=10.1109%2fIFSA-NAFIPS.2013.6608602&partnerID=40&md5=7d3e3204177cc06132dc5739914b06f5","Cost-sensitive learning is both hot and difficult in data mining and machine learning applications. Some research considers only one type of cost. Others convert two or more types of cost into the same unit, and then deal with a single-objective optimization problem. However, in many cases different types of cost cannot be converted. In this paper, we define and tackle multi-objective attribute reduct problem with multiple types of test cost. First, we compute all reducts of a decision system. Then, we separately calculate the money cost and time cost of these reducts and compare them according to the two kinds of test cost. Finally, the worse ones are removed. The remaining reducts form a Pareto optimal solution set. We tested our algorithm with three representative cost distributions on four UCI datasets. Experimental results indicate that a Pareto optimal solution set is usually very small compared with the size of all reducts. Hence our approach is effective in filtering out worse solutions and helping users in scheme selection. © 2013 IEEE.","attribute reduction; Cost-sensitive learning; money cost; rough sets; time cost",
"Zhang R., Huang K.","One-side probability machine: Learning imbalanced classifiers locally and globally",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-642-42042-9_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893415762&doi=10.1007%2f978-3-642-42042-9_18&partnerID=40&md5=7c81fba277d433f2116648bdb73d5731","Imbalanced learning is a challenged task in machine learning, where the data associated with one class are far fewer than those associated with the other class. In this paper, we propose a novel model called One-Side Probability Machine (OSPM) able to learn from imbalanced data rigorously and accurately. In particular, OSPM can lead to a rigorous treatment on biased or imbalanced classification tasks, which is significantly different from previous approaches. Importantly, the proposed OSPM exploits the reliable global information from one side only, i.e., the majority class , while engaging the robust local learning [2] from the other side, i.e., the minority class. Such setting proves much effective than other models such as Biased Minimax Probability Machine (BMPM). To our best knowledge, OSPM presents the first model capable of learning from imbalanced data both locally and globally. Our proposed model has also established close connections with various famous models such as BMPM and Support Vector Machine. One appealing feature is that the optimization problem involved can be cast as a convex second order conic programming problem with a global optimum guaranteed. A series of experiments on three data sets demonstrate the advantages of our proposed method against four competitive approaches. © Springer-Verlag 2013.",,
"Rohban M.H., Ishwar P., Orten B., Karl W.C., Saligrama V.","An impossibility result for high dimensional supervised learning",2013,"2013 IEEE Information Theory Workshop, ITW 2013",1,"10.1109/ITW.2013.6691252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893306821&doi=10.1109%2fITW.2013.6691252&partnerID=40&md5=a08c9df62becba063ca53bad20125425","We study high-dimensional asymptotic performance limits of binary supervised classification problems where the class conditional densities are Gaussian with unknown means and covariances and the number of signal dimensions scales faster than the number of labeled training samples. We show that the Bayes error, namely the minimum attainable error probability with complete distributional knowledge and equally likely classes, can be arbitrarily close to zero and yet the limiting minimax error probability of every supervised learning algorithm is no better than a random coin toss. In contrast to related studies where the classification difficulty (Bayes error) is made to vanish, we hold it constant when taking high-dimensional limits. In contrast to VC-dimension based minimax lower bounds that consider the worst case error probability over all distributions that have a fixed Bayes error, our worst case is over the family of Gaussian distributions with constant Bayes error. We also show that a nontrivial asymptotic minimax error probability can only be attained for parametric subsets of zero measure (in a suitable measure space). These results expose the fundamental importance of prior knowledge and suggest that unless we impose strong structural constraints, such as sparsity, on the parametric space, supervised learning may be ineffective in high dimensional small sample settings. © 2013 IEEE.",,
"Kumar M., Samui P., Naithani A.K.","Determination of uniaxial compressive strength and modulus of elasticity of travertine using machine learning techniques",2013,"International Journal of Advances in Soft Computing and its Applications",15,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893033808&partnerID=40&md5=6f9f743c72a62cf8bda9277167a7d009","This article adopts machine learning techniques Relevance Vector Machine (RVM), Gaussian Process Regression (GPR) and Minimax Probability Machine Regression (MPMR)} for determination of Uniaxial Compressive Strength (UCS) and the Modulus of Elasticity (E) of Travertine samples. Point load index (Is(50)), porosity (n), P-wave velocity (Vp), and Schmidt hammer rebound number (Rn) have been taken as inputs of the RVM, GPR and MPMR model. The outputs of RVM, MPMR and GPR are UCS and E. The developed RVM gives equations for prediction UCS and E. The performance of GPR, MPMR and RVM has been compared with the Artificial Neural Network (ANN) models. The simulation results show that the proposed methods give encouraging performance for prediction of UCS and E of Travertine samples.","Artificial neural network; Gaussian process regression; Minimax probability machine regression; Modulus of Elasticity; Relevance vector machine; Travertine samples; Uniaxial compressive strength",
"Oztekin A., Delen D., Turkyilmaz A., Zaim S.","A machine learning-based usability evaluation method for eLearning systems",2013,"Decision Support Systems",80,"10.1016/j.dss.2013.05.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889088422&doi=10.1016%2fj.dss.2013.05.003&partnerID=40&md5=30ea410f887097da31d196862a2bbb72","The research presented in this paper proposes a new machine learning-based evaluation method for assessing the usability of eLearning systems. Three machine learning methods (support vector machines, neural networks and decision trees) along with multiple linear regression are used to develop prediction models in order to discover the underlying relationship between the overall eLearning system usability and its predictor factors. A subsequent sensitivity analysis is conducted to determine the rank-order importance of the predictors. Using both sensitivity values along with the usability scores, a metric (called severity index) is devised. By applying a Pareto-like analysis, the severity index values are ranked and the most important usability characteristics are identified. The case study results show that the proposed methodology enhances the determination of eLearning system problems by identifying the most pertinent usability factors. The proposed method could provide an invaluable guidance to the usability experts as to what measures should be improved in order to maximize the system usability for a targeted group of end-users of an eLearning system. © 2013 Elsevier B.V.","eLearning (web-based learning/distance learning); Information fusion; Machine learning; Sensitivity analysis; Severity index; Usability engineering",
"Chen S., Amid D., Shir O.M., Limonad L., Boaz D., Anaby-Tavor A., Schreck T.","Self-organizing maps for multi-objective Pareto Frontiers",2013,"IEEE Pacific Visualization Symposium",22,"10.1109/PacificVis.2013.6596140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889069849&doi=10.1109%2fPacificVis.2013.6596140&partnerID=40&md5=491582939b5eb936498f5820466c85d4","Decision makers often need to take into account multiple conflicting objectives when selecting a solution for their problem. This can result in a potentially large number of candidate solutions to be considered. Visualizing a Pareto Frontier, the optimal set of solutions to a multi-objective problem, is considered a difficult task when the problem at hand spans more than three objective functions. We introduce a novel visual-interactive approach to facilitate coping with multi-objective problems. We propose a characterization of the Pareto Frontier data and the tasks decision makers face as they reach their decisions. Following a comprehensive analysis of the design alternatives, we show how a semantically-enhanced Self-Organizing Map, can be utilized to meet the identified tasks. We argue that our newly proposed design provides both consistent orientation of the 2D mapping as well as an appropriate visual representation of individual solutions. We then demonstrate its applicability with two real-world multi-objective case studies. We conclude with a preliminary empirical evaluation and a qualitative usefulness assessment. © 2013 IEEE.","[Computing Methodologies]: Machine Learning - Machine Learning Approaches Neural Networks; [Human-Centered Computing]: Visualization - Visualization Design and Evaluation Methods; [Information Systems]: Information Systems Applications - Decision Support Systems",
"Liau Y.S., Tan K.C., Hu J., Qiu X., Gee S.B.","Machine learning enhanced multi-objective evolutionary algorithm based on decomposition",2013,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",6,"10.1007/978-3-642-41278-3_67","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890877172&doi=10.1007%2f978-3-642-41278-3_67&partnerID=40&md5=bbf4ca7d8f80a59856c289bc99466967","We address the problem of expensive multi-objective optimization using a machine learning assisted model of evolutionary computation. Specifically, we formulate a meta-objective function tailored to the framework of MOEA/D, which can be solved by means of supervised regression learning using the Support Vector Machine (SVM) algorithm. The learned model constitutes the knowledge which can be then utilized to guide the evolution process within MOEA/D so as to reach better regions in the search space more quickly. Simulation results on a variety of benchmark problems show that the machine-learning enhanced MOEA/D is able to obtain better estimation of Pareto fronts when the allowed computational budget, measured in terms of number of objective function evaluation, is scarce. © 2013 Springer-Verlag.","Evolutionary multi-objective optimization; expensive optimization; support vector machine; surrogate modelling",
"Tsybakov A.B.","Aggregation and minimax optimality in high-dimensional estimation",2014,"Proceeding of the International Congress of Mathematicans, ICM 2014",12,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087097347&partnerID=40&md5=2c46673fdb2cb1067d76780872f6a2f8","Aggregation is a popular technique in statistics and machine learning. Given a collection of estimators, the problem of linear, convex or model selection type aggregation consists in constructing a new estimator, called the aggregate, which is nearly as good as the best among them (or nearly as good as their best linear or convex combination), with respect to a given risk criterion. When the underlying model is sparse, which means that it is well approximated by a linear combination of a small number of functions in the dictionary, the aggregation techniques turn out to be very useful in taking advantage of sparsity. On the other hand, aggregation is a general way of constructing adaptive nonparametric estimators, which is more powerful than the classical methods since it allows one to combine estimators of different nature. Aggregates are usually constructed by mixing the initial estimators or functions of the dictionary with data-dependent weights that can be defined is several possible ways. An important example is given by aggregates with exponential weights. They satisfy sharp oracle inequalities that allow one to treat in a unified way three different problems: Adaptive nonparametric estimation, aggregation and sparse estimation. © 2014 by Seoul ICM 2014 Organizing Committee. All rights reserved.","Aggregation; Exponential weights; High-dimensional model; Minimax estimation; Oracle inequality; Sparsity","KYUNG MOON SA Co. Ltd."
"Geyer-Schulz A., Ovelgönne M.","The randomized greedy modularity clustering algorithm and the core groups graph clustering scheme",2014,"Studies in Classification, Data Analysis, and Knowledge Organization",6,"10.1007/978-3-319-01264-3_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946577469&doi=10.1007%2f978-3-319-01264-3_2&partnerID=40&md5=b658cdccee75658a3c9887a1537d11c3","The modularity measure of Newman and Girvan is a popular formal cluster criterium for graph clustering. Although the modularity maximization problem has been shown to be NP-hard, a large number of heuristic modularity maximization algorithms have been developed. In the 10th DIMACS Implementation Challenge of the Center for Discrete Mathematics & Theoretical Computer Science (DIMACS) for graph clustering our core groups graph clustering scheme combined with a randomized greedy modularity clustering algorithm won both modularity optimization challenges: the Modularity (highest modularity) and the Pareto Challenge (tradeoff between modularity and performance). The core groups graph clustering scheme is an ensemble learning clustering method which combines the local solutions of several base algorithms to form a good start solution for the final algorithm. The randomized greedy modularity algorithm is a nondeterministic agglomerative hierarchical clustering approach which finds locally optimal solutions. In this contribution we analyze the similarity of the randomized greedy modularity algorithm with incomplete solvers for the satisfiability problem and we establish an analogy between the cluster core group heuristic used in core groups graph clustering and a sampling of restart points on the Morse graph of a continuous optimization problem with the same local optima. © Springer International Publishing Switzerland 2014.",,"Kluwer Academic Publishers"
"Liu A., Ziebart B.D.","Robust classification under sample selection bias",2014,"Advances in Neural Information Processing Systems",47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937896443&partnerID=40&md5=8f0f028dd680d9c851302d207e9241a8","In many important machine learning applications, the source distribution used to estimate a probabilistic classifier differs from the target distribution on which the classifier will be used to make predictions. Due to its asymptotic properties, sample reweighted empirical loss minimization is a commonly employed technique to deal with this difference. However, given finite amounts of labeled source data, this technique suffers from significant estimation errors in settings with large sample selection bias. We develop a framework for learning a robust bias-aware (RBA) probabilistic classifier that adapts to different sample selection biases using a minimax estimation formulation. Our approach requires only accurate estimates of statistics under the source distribution and is otherwise as robust as possible to unknown properties of the conditional label distribution, except when explicit generalization assumptions are incorporated. We demonstrate the behavior and effectiveness of our approach on binary classification tasks.",,"Neural information processing systems foundation"
"Piltaver R., Luštrek M., Zupančič J., Džeroski S., Gams M.","Multi-objective learning of hybrid classifiers",2014,"Frontiers in Artificial Intelligence and Applications",3,"10.3233/978-1-61499-419-0-717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923196985&doi=10.3233%2f978-1-61499-419-0-717&partnerID=40&md5=8c9554027100a3a6fadcbbfa04fe146d","We propose a multi-objective machine learning approach guaranteed to find the Pareto optimal set of hybrid classification models consisting of comprehensible and incomprehensible submodels. The algorithm run-times are below 1 s for typical applications despite the exponential worst-case time complexity. The user chooses the model with the best comprehensibility-accuracy trade-off from the Pareto front which enables a well informed decision or repeats finding new Pareto fronts with modified seeds. For a classification trees as the comprehensible seed, the hybrids include single black-box model, invoked in hybrid leaves. The comprehensibility of such hybrid classifiers is measured with the proportion of examples classified by the regular leaves. We propose one simple and one computationally efficient algorithm for finding the Pareto optimal hybrid trees, starting from an initial classification tree and a black-box classifier. We evaluate the proposed algorithms empirically, comparing them to the baseline solution set, showing that they often provide valuable improvements. Furthermore, we show that the efficient algorithm outperforms the NSGA-II algorithm in terms of quality of the result set and efficiency (for this optimisation problem). Finally we show that the algorithm returns hybrid classifiers that reflect the expert's knowledge on activity recognition problem well. © 2014 The Authors and IOS Press.",,"IOS Press"
"Tawfeek M.A., El-Sisi A.B., Keshk A.E., Torkey F.A.","Virtual machine placement based on ant colony optimization for minimizing resource wastage",2014,"Communications in Computer and Information Science",31,"10.1007/978-3-319-13461-1_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916239187&doi=10.1007%2f978-3-319-13461-1_16&partnerID=40&md5=e971ed63c919fdddf66d4dfbb4d76da6","Cloud computing is concept of computing technology in which user uses remote server for maintain their data and application. Resources in cloud computing are demand driven utilized in forms of virtual machines to facilitate the execution of complicated tasks. Virtual machine placement is the process of mapping virtual machines to physical machines. This is an active research topic and different strategies have been adopted in literature for this problem. In this paper, the problem of virtual machine placement is formulated as a multiobjective optimization problem aiming to simultaneously optimize total processing resource wastage and total memory resource wastage. After that ant colony optimization algorithm is proposed for solving the formulated problem. The main goal of the proposed algorithm is to search the solution space more efficiently and obtain a set of non-dominated solutions called the Pareto set. The proposed algorithm has been compared with the well-known algorithms for virtual machine placement problem existing in the literature. The comparison results elucidate that the proposed algorithm is more efficient and significantly outperforms the compared methods on the basis of CPU resource wastage and memory resource wastage. © Springer International Publishing Switzerland 2014.","Ant colony optimization; Cloud computing; Virtual machine placement","Springer Verlag"
"Lattimore T., Hutter M.","Bayesian reinforcement learning with exploration",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/978-3-319-11662-4_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910077608&doi=10.1007%2f978-3-319-11662-4_13&partnerID=40&md5=da9634018122eae72ee2fac5317ba948","We consider a general reinforcement learning problem and show that carefully combining the Bayesian optimal policy and an exploring policy leads to minimax sample-complexity bounds in a very general class of (history-based) environments. We also prove lower bounds and show that the new algorithm displays adaptive behaviour when the environment is easier than worst-case. © Springer International Publishing Switzerland 2014.",,"Springer Verlag"
"Liu J., Min F., Zhao H., Zhu W.","Feature selection with positive region constraint for test-cost-sensitive data",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-662-44680-5_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907363809&doi=10.1007%2f978-3-662-44680-5_2&partnerID=40&md5=ad6a97b8b73c6b279be07a3ffb149782","In many data mining and machine learning applications, data are not free, and there is a test cost for each data item. Due to economic, technological and legal reasons, it is neither possible nor necessary to obtain a classifier with 100 % accuracy. In this paper, we consider such a situation and propose a new constraint satisfaction problem to address it. With this in mind, one has to minimize the test cost to keep the accuracy of the classification under a budget. The constraint is expressed by the positive region, whereas the object is to minimizing the total test cost. The new problem is essentially a dual of the test cost constraint attribute reduction problem, which has been addressed recently. We propose a heuristic algorithm based on the information gain, the test cost, and a user specified parameter to deal with the new problem. The algorithm is tested on four University of California - Irvine datasets with various test cost settings. Experimental results indicate that the algorithm finds optimal feature subset in most cases, the rational setting of is different among datasets, and the algorithm is especially stable when the test cost is subject to the Pareto distribution. © 2014 Springer-Verlag.","Cost-sensitive learning; Feature selection; Positive region; Test cost","Springer Verlag"
"Huang G., Song S., Xu Z., Weinberger K.","Transductive minimax probability machine",2014,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/978-3-662-44848-9_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907012517&doi=10.1007%2f978-3-662-44848-9_37&partnerID=40&md5=83ad27efc69058b03a564235fc4fa87b","The Minimax Probability Machine (MPM) is an elegant machine learning algorithm for inductive learning. It learns a classifier that minimizes an upper bound on its own generalization error. In this paper, we extend its celebrated inductive formulation to an equally elegant transductive learning algorithm. In the transductive setting, the label assignment of a test set is already optimized during training. This optimization problem is an intractable mixed-integer programming. Thus, we provide an efficient label-switching approach to solve it approximately. The resulting method scales naturally to large data sets and is very efficient to run. In comparison with nine competitive algorithms on eleven data sets, we show that the proposed Transductive MPM (TMPM) almost outperforms all the other algorithms in both accuracy and speed. © 2014 Springer-Verlag.","minimax probability machine; semi-supervised learning; transductive learning","Springer Verlag"
"Neto H.C., Julia R.M.S., Caexeta G.S., Barcelos A.R.A.","LS-VisionDraughts: Improving the performance of an agent for checkers by integrating computational intelligence, reinforcement learning and a powerful search method",2014,"Applied Intelligence",11,"10.1007/s10489-014-0536-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906783226&doi=10.1007%2fs10489-014-0536-y&partnerID=40&md5=55ad24fc4ea3e108b3645983f8519923","This paper presents LS-VisionDraughts: an efficient unsupervised evolutionary learning system for Checkers whose contribution is to automate the process of selecting an appropriate representation for the board states - by means of Evolutionary Computation - keeping a deep look-ahead (search depth) at the moment of choosing an adequate move. It corresponds to a player Multi Layer Perceptron Neural Network whose weights are updated through an evaluation function that is automatically adjusted by means of the Temporal Difference methods. A Genetic Algorithm automatically chooses a concise and efficient set of functions, which describe various scenarios associated with Checkers - called features - to represent the board states in the input layer of the Neural Network. It means that each individual of the Genetic Algorithm is a candidate set of features that is associated to a distinct Multi Layer Perceptron Neural Network. The output layer of the Neural Network is a real number (prediction) that indicates to which extent the input state is favorable to provide a better agent performance. In LS-VisionDraughts, a particular version of the search algorithm Alpha-Beta, called fail-soft Alpha-Beta, combined with Table Transposition, Iterative Deepening and ordered tree, uses this prediction value to choose the best move corresponding to the current board state. The best individual is chosen by means of numerous tournaments involving these selfsame Neural Networks. The architecture of LS-VisionDraught is inspired on the agent NeuroDraughts. However, the former system enhances the performance of the latter by automating the selection of the features through Evolutionary Computation and by replacing its Minimax search algorithm with the improved search strategy resumed above. This procedure allows for a 95 % reduction in the search runtime. Further, it remarkably increases the search tree depth. The results obtained from evaluative tournaments confirm the advances of LS-VisionDraughts compared to its opponents. It is however important to point out that LS-VisionDraughts learns practically without human supervision, contrary to the current automatic world champion Chinook, which has been built in a strongly supervised manner. © 2014 Springer Science+Business Media New York.","Artificial intelligence; Artificial neural network; Evolutionary computation; Game theory; Genetic algorithms; Machine learning; Reinforcement learning; Temporal differences","Kluwer Academic Publishers"
"Ghosh D.","An asymptotically minimax kernel machine",2014,"Statistics and Probability Letters",,"10.1016/j.spl.2014.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906702560&doi=10.1016%2fj.spl.2014.08.005&partnerID=40&md5=22ff8b5209fa169d67027f6c31221601","Recently, a class of machine learning-inspired procedures, termed kernel machine methods, has been extensively developed in the statistical literature. In this note, we construct a so-called 'adaptively minimax' kernel machine. Such a construction highlights the limits on the interpretability of such kernel machines. © 2014.","Data mining; Decision theory; Hard-thresholding; Nonparametric regression; Support vector machines","Elsevier"
"Guan P., Raginsky M., Willett R.","From minimax value to low-regret algorithms for online Markov decision processes",2014,"Proceedings of the American Control Conference",4,"10.1109/ACC.2014.6858844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905715161&doi=10.1109%2fACC.2014.6858844&partnerID=40&md5=ba0aec0dc5ddef07ca735a00846789e8","The standard Markov Decision Process (MDP) framework assumes a stationary (or at least predictable) environment. Online learning algorithms can deal with non-stationary or unpredictable environments, but there is no notion of a state that might be changing throughout the learning process as a function of past actions. In recent years, there has been a growing interest in combining the above two frameworks and considering an MDP setting, where the cost function is allowed to change arbitrarily after each time step. However, most of the work in this area has been algorithmic: given a problem, one would design an algorithm from scratch and analyze its performance on a case-by-case basis. Moreover, the presence of the state and the assumption of an arbitrarily varying environment complicate both the theoretical analysis and the development of computationally efficient methods. This paper builds on recent results of Rakhlin et al. to give a general framework for deriving algorithms in an MDP setting with arbitrarily changing costs. This framework leads to a unifying view of existing methods and provides a general procedure for constructing new ones. © 2014 American Automatic Control Council.","Machine learning; Markov processes","Institute of Electrical and Electronics Engineers Inc."
"Fathi A., Mozaffari A.","Vector optimization of laser solid freeform fabrication system using a hierarchical mutable smart bee-fuzzy inference system and hybrid NSGA-II/self-organizing map",2014,"Journal of Intelligent Manufacturing",37,"10.1007/s10845-012-0718-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904402984&doi=10.1007%2fs10845-012-0718-6&partnerID=40&md5=42626ba47f310502c283a2ae8345ae2b","The purpose of current investigation is to develop a robust intelligent framework to achieve efficient and reliable operating process parameters for laser solid freeform fabrication (LSFF) process as a recent and ongoing topic of investigation. Firstly, based on mutable smart bee algorithm (MSBA) and fuzzy inference system (FIS) two models are developed to identify the clad hight (deposited layer thickness) and the melt pool depth as functions of scanning speed, laser power and mass powder. Using the obtained model, the well-known multiobjective evolutionary algorithm called non-dominated sorting genetic algorithm (NSGA-II) is used for multi-criterion optimization of LSFF process. According to the available reported information and also the author's experiments, it is observed that the obtained Pareto front is not justifiable since it fails to cover the entire Pareto hyper-volume due to the lack of intensified exploration. To tackle this deficiency, authors execute a post optimization process through utilizing a competitive unsupervised machine learning approach known as self-organizing map (SOM) with cubic spatial topology. Achieved results indicate that this grid based network is capable of enhancing the intensification of Pareto solutions since its synaptic weights successfully imitate the characteristics of non-dominated solutions (optimal values of mass powder, laser power and scanning speed). For extracting the corresponding objective functions of these non-dominated synaptic weights, MSBA-FIS is used again to map the operating parameters to objective functions space. After the termination of abovementioned procedures, a valuable archive, containing a set of non-dominated solutions, is obtained which lets the authors to make a deliberate engineering trade-off. Simulation experiments reveal that the proposed intelligent framework is highly capable to cope with complex engineering systems. Besides, it is observed that MSBA is more efficient in evolving the structure of hierarchical fuzzy inference system in comparison with classic hierarchical GA-FIS model. This rises from the simple structure of MSBA that turns it into a fast and robust algorithm for handling constraint distributed systems (i.e. hierarchical FIS in current investigation). The obtained results also indicate that the introduced intelligent framework is applicable for optimal design of complex engineering systems where there exists no analytical formulation that describes the phenomenon as well as information of optimal operating parameters. © 2012 Springer Science+Business Media New York.","Intelligent post optimization; Laser solid freeform fabrication (LSFF); Mutable smart bee algorithm (MSBA); Supervised hierarchical fuzzy training; Vector optimization","Kluwer Academic Publishers"
"Nepal K., Li Y., Bahar R.I., Reda S.","ABACUS: A technique for automated behavioral synthesis of approximate computing circuits",2014,"Proceedings -Design, Automation and Test in Europe, DATE",127,"10.7873/DATE2014.374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903831997&doi=10.7873%2fDATE2014.374&partnerID=40&md5=3afcf562f68f907c23031dedda3330ff","Many classes of applications, especially in the domains of signal and image processing, computer graphics, computer vision, and machine learning, are inherently tolerant to inaccuracies in their underlying computations. This tolerance can be exploited to design approximate circuits that perform within acceptable accuracies but have much lower power consumption and smaller area footprints (and often better run times) than their exact counterparts. In this paper, we propose a new class of automated synthesis methods for generating approximate circuits directly from behavioral-level descriptions. In contrast to previous methods that operate at the Boolean level or use custom modifications, our automated behavioral synthesis method enables a wider range of possible approximations and can operate on arbitrary designs. Our method first creates an abstract synthesis tree (AST) from the input behavioral description, and then applies variant operators to the AST using an iterative stochastic greedy approach to identify the optimal inexact designs in an efficient way. Our method is able to identify the optimal designs that represent the Pareto frontier trade-off between accuracy and power consumption. Our methodology is developed into a tool we call ABACUS, which we integrate with a standard ASIC experimental flow based on industrial tools. We validate our methods on three realistic Verilog-based benchmarks from three different domains - signal processing, computer vision and machine learning. Our tool automatically discovers optimal designs, providing area and power savings of up to 50% while maintaining good accuracy. © 2014 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Wang L., Liang Y.Q., Tian Q.J., Yang J., Song C., Wu Z.","A community detection method based on multi-objective optimization method",2014,"Applied Mechanics and Materials",3,"10.4028/www.scientific.net/AMM.571-572.177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903461372&doi=10.4028%2fwww.scientific.net%2fAMM.571-572.177&partnerID=40&md5=55584421e8520788b5d701ccce728fce","Community detection in complex network has been an active research area in data mining and machine learning. This paper proposed a community detection method based on multi-objective evolutionary algorithm, named CDMOEA, which tries to find the Pareto front by maximize two objectives, community score and community fitness. Fast and Elitist Multi-objective Genetic Algorithm is used to attained a set of optimal solutions, and then use Modularity function to choose the best one from them. The locus based adjacency representation is used to realize genetic representation, which ensures the effective connections of the nodes in the network during the process of population Initialization and other genetic operator. Uniform crossover is introduced to ensure population's diversity. We compared it with some popular community detection algorithms in computer generated network and real world networks. Experiment results show that it is more efficient in community detection. © (2014) Trans Tech Publications, Switzerland.","Community detection; Complex network; Modularity; Multi-objective evolutionary algorithm; Pareto front","Trans Tech Publications Ltd"
"Takeda A., Kanamori T.","Using financial risk measures for analyzing generalization performance of machine learning models",2014,"Neural Networks",13,"10.1016/j.neunet.2014.05.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901984498&doi=10.1016%2fj.neunet.2014.05.006&partnerID=40&md5=aef125380e5cd18436d89195d26234f5","We propose a unified machine learning model (UMLM) for two-class classification, regression and outlier (or novelty) detection via a robust optimization approach. The model embraces various machine learning models such as support vector machine-based and minimax probability machine-based classification and regression models. The unified framework makes it possible to compare and contrast existing learning models and to explain their differences and similarities.In this paper, after relating existing learning models to UMLM, we show some theoretical properties for UMLM. Concretely, we show an interpretation of UMLM as minimizing a well-known financial risk measure (worst-case value-at risk (VaR) or conditional VaR), derive generalization bounds for UMLM using such a risk measure, and prove that solving problems of UMLM leads to estimators with the minimized generalization bounds. Those theoretical properties are applicable to related existing learning models. © 2014 Elsevier Ltd.","Financial risk measure; Generalization performance; Minimax probability machine; Support vector machine","Elsevier Ltd"
"Utkin L.V.","A framework for imprecise robust one-class classification models",2014,"International Journal of Machine Learning and Cybernetics",25,"10.1007/s13042-012-0140-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901302959&doi=10.1007%2fs13042-012-0140-6&partnerID=40&md5=933a577ef0e1d33f0d3a8d8ba65f7dcf","A framework for constructing robust one-class classification models is proposed in the paper. It is based on Walley's imprecise extensions of contaminated models which produce a set of probability distributions of data points instead of a single empirical distribution. The minimax and minimin strategies are used to choose an optimal probability distribution from the set and to construct optimal separating functions. It is shown that an algorithm for computing optimal parameters is determined by extreme points of the probability set and is reduced to a finite number of standard SVM tasks with weighted data points. Important special cases of the models, including pari-mutuel, constant odd-ratio, contaminated models and Kolmogorov-Smirnov bounds are studied. Experimental results with synthetic and real data illustrate the proposed models. © 2012 Springer-Verlag Berlin Heidelberg.","Classification; Machine learning; Minimax strategy; Novelty detection; Quadratic programming; Support vector machine","Springer Verlag"
"Utkin L.V., Zhuk Y.A.","Robust boosting classification models with local sets of probability distributions",2014,"Knowledge-Based Systems",11,"10.1016/j.knosys.2014.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897414918&doi=10.1016%2fj.knosys.2014.02.007&partnerID=40&md5=29c961570c7c8262f05a32a55208a08c","Robust classification models based on the ensemble methodology are proposed in the paper. The main feature of the models is that the precise vector of weights assigned for examples in the training set at each iteration of boosting is replaced by a local convex set of weight vectors. The minimax strategy is used for building weak classifiers at each iteration. The local sets of weights are constructed by means of imprecise statistical models. The proposed models are called RILBoost (Robust Imprecise Local Boost). Numerical experiments with real data show that the proposed models outperform the standard AdaBoost algorithm for several well-known data sets. © 2014 Elsevier B.V. All rights reserved.","Boosting; Classification; Imprecise model; Machine learning; Robust","Elsevier"
"Jiménez F., Sánchez G., Juárez J.M.","Multi-objective evolutionary algorithms for fuzzy classification in survival prediction",2014,"Artificial Intelligence in Medicine",39,"10.1016/j.artmed.2013.12.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897096881&doi=10.1016%2fj.artmed.2013.12.006&partnerID=40&md5=76f64b90ac40326bb7dd33a3a01c7ad9","Objective: This paper presents a novel rule-based fuzzy classification methodology for survival/mortality prediction in severe burnt patients. Due to the ethical aspects involved in this medical scenario, physicians tend not to accept a computer-based evaluation unless they understand why and how such a recommendation is given. Therefore, any fuzzy classifier model must be both accurate and interpretable. Methods and materials: The proposed methodology is a three-step process: (1) multi-objective constrained optimization of a patient's data set, using Pareto-based elitist multi-objective evolutionary algorithms to maximize accuracy and minimize the complexity (number of rules) of classifiers, subject to interpretability constraints; this step produces a set of alternative (Pareto) classifiers; (2) linguistic labeling, which assigns a linguistic label to each fuzzy set of the classifiers; this step is essential to the interpretability of the classifiers; (3) decision making, whereby a classifier is chosen, if it is satisfactory, according to the preferences of the decision maker. If no classifier is satisfactory for the decision maker, the process starts again in step (1) with a different input parameter set. Results: The performance of three multi-objective evolutionary algorithms, niched pre-selection multi-objective algorithm, elitist Pareto-based multi-objective evolutionary algorithm for diversity reinforcement (ENORA) and the non-dominated sorting genetic algorithm (NSGA-II), was tested using a patient's data set from an intensive care burn unit and a standard machine learning data set from an standard machine learning repository. The results are compared using the hypervolume multi-objective metric. Besides, the results have been compared with other non-evolutionary techniques and validated with a multi-objective cross-validation technique. Our proposal improves the classification rate obtained by other non-evolutionary techniques (decision trees, artificial neural networks, Naive Bayes, and case-based reasoning) obtaining with ENORA a classification rate of 0.9298, specificity of 0.9385, and sensitivity of 0.9364, with 14.2 interpretable fuzzy rules on average. Conclusions: Our proposal improves the accuracy and interpretability of the classifiers, compared with other non-evolutionary techniques. We also conclude that ENORA outperforms niched pre-selection and NSGA-II algorithms. Moreover, given that our multi-objective evolutionary methodology is non-combinational based on real parameter optimization, the time cost is significantly reduced compared with other evolutionary approaches existing in literature based on combinational optimization. © 2014 Elsevier B.V.","Fuzzy classification; Intensive care burns unit; Multi-objective evolutionary computation; Severity scores","Elsevier"
"Bianchi R.A.C., Martins M.F., Ribeiro C.H.C., Costa A.H.R.","Heuristically-accelerated multiagent reinforcement learning",2014,"IEEE Transactions on Cybernetics",48,"10.1109/TCYB.2013.2253094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893355297&doi=10.1109%2fTCYB.2013.2253094&partnerID=40&md5=e14d645b7569ee457a6a90fd9d4de9e5","This paper presents a novel class of algorithms, called Heuristically-Accelerated Multiagent Reinforcement Learning (HAMRL), which allows the use of heuristics to speed up well-known multiagent reinforcement learning (RL) algorithms such as the Minimax-Q. Such HAMRL algorithms are characterized by a heuristic function, which suggests the selection of particular actions over others. This function represents an initial action selection policy, which can be handcrafted, extracted from previous experience in distinct domains, or learnt from observation. To validate the proposal, a thorough theoretical analysis proving the convergence of four algorithms from the HAMRL class (HAMMQ, HAMQ}(λ, HAMQS, and HAMS) is presented. In addition, a comprehensive systematical evaluation was conducted in two distinct adversarial domains. The results show that even the most straightforward heuristics can produce virtually optimal action selection policies in much fewer episodes, significantly improving the performance of the HAMRL over vanilla RL algorithms. © 2013 IEEE.","Artificial intelligence; heuristic algorithms; machine learning; multiagent systems",
"Yoshiyama K., Sakurai A.","Laplacian minimax probability machine",2014,"Pattern Recognition Letters",12,"10.1016/j.patrec.2013.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891628135&doi=10.1016%2fj.patrec.2013.01.004&partnerID=40&md5=0d53ba4ad0a6b2390bb2aa95a75c05d3","In this paper, we propose a Laplacian minimax probability machine, which is a semi-supervised version of minimax probability machine based on the manifold regularization framework. We also show that the proposed method can be kernelized on the basis of a theorem similar to the representer theorem for non-linear cases. Experiments confirm that the proposed methods achieve competitive results, as compared to existing graph-based learning methods such as the Laplacian support vector machine and the Laplacian regularized least square, for publicly available datasets from the UCI machine learning repository. © 2013 Elsevier Ltd. All rights reserved.","Laplacian RLS; Laplacian SVM; Manifold regularization; Minimax probability machine; Semi-supervised learning",
"Campigotto P., Passerini A., Battiti R.","Active learning of pareto fronts",2014,"IEEE Transactions on Neural Networks and Learning Systems",26,"10.1109/TNNLS.2013.2275918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897673026&doi=10.1109%2fTNNLS.2013.2275918&partnerID=40&md5=67c2f0b6665544e420ee5206f47d541b","This paper introduces the active learning of Pareto fronts (ALP) algorithm, a novel approach to recover the Pareto front of a multiobjective optimization problem. ALP casts the identification of the Pareto front into a supervised machine learning task. This approach enables an analytical model of the Pareto front to be built. The computational effort in generating the supervised information is reduced by an active learning strategy. In particular, the model is learned from a set of informative training objective vectors. The training objective vectors are approximated Pareto-optimal vectors obtained by solving different scalarized problem instances. The experimental results show that ALP achieves an accurate Pareto front approximation with a lower computational effort than state-of-the-art estimation of distribution algorithms and widely known genetic techniques. © 2012 IEEE.","Active learning; Gaussian process regression; multiobjective optimization; uncertainty sampling",
"Yan Z., Wang J.","Robust model predictive control of nonlinear systems with unmodeled dynamics and bounded uncertainties based on neural networks",2014,"IEEE Transactions on Neural Networks and Learning Systems",112,"10.1109/TNNLS.2013.2275948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897626373&doi=10.1109%2fTNNLS.2013.2275948&partnerID=40&md5=166fd71ef2de5fb5bd820ea37e7c351d","This paper presents a neural network approach to robust model predictive control (MPC) for constrained discrete-time nonlinear systems with unmodeled dynamics affected by bounded uncertainties. The exact nonlinear model of underlying process is not precisely known, but a partially known nominal model is available. This partially known nonlinear model is first decomposed to an affine term plus an unknown high-order term via Jacobian linearization. The linearization residue combined with unmodeled dynamics is then modeled using an extreme learning machine via supervised learning. The minimax methodology is exploited to deal with bounded uncertainties. The minimax optimization problem is reformulated as a convex minimization problem and is iteratively solved by a two-layer recurrent neural network. The proposed neurodynamic approach to nonlinear MPC improves the computational efficiency and sheds a light for real-time implementability of MPC technology. Simulation results are provided to substantiate the effectiveness and characteristics of the proposed approach. © 2013 IEEE.","Extreme learning machine (ELM); real-time optimization; recurrent neural networks (RNNs); robust model predictive control (MPC); unmodeled dynamics",
"Rosin C.D.","Game playing",2014,"Wiley Interdisciplinary Reviews: Cognitive Science",1,"10.1002/wcs.1278","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893789564&doi=10.1002%2fwcs.1278&partnerID=40&md5=1c384e46954678988a15d856c08d8ee1","Game playing has been a core domain of artificial intelligence research since the beginnings of the field. Game playing provides clearly defined arenas within which computational approaches can be readily compared to human expertise through head-to-head competition and other benchmarks. Game playing research has identified several simple core algorithms that provide successful foundations, with development focused on the challenges of defeating human experts in specific games. Key developments include minimax search in chess, machine learning from self-play in backgammon, and Monte Carlo tree search in Go. These approaches have generalized successfully to additional games. While computers have surpassed human expertise in a wide variety of games, open challenges remain and research focuses on identifying and developing new successful algorithmic foundations. © 2014 John Wiley & Sons, Ltd.",,
"Xu B., Min F., Zhu W., Chen H.","A genetic algorithm to multi-objective cost-sensitive attribute reduction",2014,"Journal of Computational Information Systems",5,"10.12733/jcis9968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901854600&doi=10.12733%2fjcis9968&partnerID=40&md5=71e795e5fc44795d8408d1657fb2a5fd","Cost-sensitive learning is both hot and difficult in data mining and machine learning applications. Recently, some algorithms have been designed for the minimal test cost attribute reduction problem. They deal with either money cost or time cost, therefore they are single-objective. In this paper, we propose a genetic algorithm to the multi-objective attribute reduction problem involving multiple types of test cost, and define three metrics to evaluate the performance of our algorithm. In the algorithm, the fitness function is constructed based on positive region, the selected multiple types of test cost, a given set of weighting parameters and a user-specified non-positive exponent λ. We adopt the cross generational elitist selection strategy which can ensure better individuals maintained from one generation to the next. With different parameter settings, a number of reducts are produced and worse ones are filtered out. Then the remaining reducts form a Pareto optimal solution set. We test our algorithm with three representative cost distributions on four UCI datasets. Experimental results indicate that our algorithm performs well. © 2014 Binary Information Press.","Attribute reduction; Cost-sensitive learning; Genetic algorithm; Rough sets","Binary Information Press"
"Kim K.-H., Choi S.","Label propagation through minimax paths for scalable semi-supervised learning",2014,"Pattern Recognition Letters",13,"10.1016/j.patrec.2014.02.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897560409&doi=10.1016%2fj.patrec.2014.02.020&partnerID=40&md5=9f8531355c1cf98a4865cd98b46cf8c6","Semi-supervised learning (SSL) is attractive for labeling a large amount of data. Motivated from cluster assumption, we present a path-based SSL framework for efficient large-scale SSL, propagating labels through only a few important paths between labeled nodes and unlabeled nodes. From the framework, minimax paths emerge as a minimal set of important paths in a graph, leading us to a novel algorithm, minimax label propagation. With an appropriate stopping criterion, learning time is (1) linear with respect to the number of nodes in a graph and (2) independent of the number of classes. Experimental results show the superiority of our method over existing SSL methods, especially on large-scale data with many classes. © 2014 Elsevier B.V. All rights reserved.","Label propagation; Minimax path; Semi-supervised learning","Elsevier"
"Bandaru S., Ng A.H.C., Deb K.","On the performance of classification algorithms for learning Pareto-dominance relations",2014,"Proceedings of the 2014 IEEE Congress on Evolutionary Computation, CEC 2014",26,"10.1109/CEC.2014.6900641","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908584346&doi=10.1109%2fCEC.2014.6900641&partnerID=40&md5=ecbf5c309b37b6a8451d479d85bad541","Multi-objective evolutionary algorithms (MOEAs) are often criticized for their high-computational costs. This becomes especially relevant in simulation-based optimization where the objectives lack a closed form and are expensive to evaluate. Over the years, meta-modeling or surrogate modeling techniques have been used to build inexpensive approximations of the objective functions which reduce the overall number of function evaluations (simulations). Some recent studies however, have pointed out that accurate models of the objective functions may not be required at all since evolutionary algorithms only rely on the relative ranking of candidate solutions. Extending this notion to MOEAs, algorithms which can 'learn' Pareto-dominance relations can be used to compare candidate solutions under multiple objectives. With this goal in mind, in this paper, we study the performance of ten different off-the-shelf classification algorithms for learning Pareto-dominance relations in the ZDT test suite of benchmark problems. We consider prediction accuracy and training time as performance measures with respect to dimensionality and skewness of the training data. Being a preliminary study, this paper does not include results of integrating the classifiers into the search process of MOEAs. © 2014 IEEE.","Classification algorithms; Machine learning; Meta-modeling; Multi-objective optimization; Pareto-dominance","Institute of Electrical and Electronics Engineers Inc."
"Zhang B., Shafi K., Abbass H.","Online knowledge-based evolutionary multi-objective optimization",2014,"Proceedings of the 2014 IEEE Congress on Evolutionary Computation, CEC 2014",2,"10.1109/CEC.2014.6900610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908573195&doi=10.1109%2fCEC.2014.6900610&partnerID=40&md5=8f814ce5783b23fb3171fd2e7765da6f","Knowledge extraction from a multi-objective optimization process has important implications including a better understanding of the optimization process and the relationship between decision variables. The extant approaches, in this respect, rely on processing the post-optimization Pareto sets for automatic rule discovery using statistical or machine learning methods. However such approaches fall short of providing any information during the progress of the optimization process, which can be critical for decision analysis especially if the problem is dynamic. In this paper, we present a multi-objective optimization framework that uses a knowledge-based representation to search for patterns of Pareto optimal design variables instead of conventional point form solution search. The framework facilitates the online discovery of knowledge during the optimization process in the form of interpretable rules. The core contributing idea of our research is that we apply multi-objective evolutionary process on a population of bounding hypervolumes, or rules, instead of evolving individual point-based solutions. The framework is generic in a sense that any existing multi-objective optimization algorithm can be adapted to evaluate the rule quality based on the sampled solutions from the bounded space. An instantiation of the framework using hyperrectangular representation and non-dominated sorting based rule evaluation is presented in this paper. Experimental results on a specifically designed test function as well as some standard test functions are presented to demonstrate the working and convergence properties of our algorithm. © 2014 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Utkin L.V., Zhuk Y.A.","Imprecise prior knowledge incorporating into one-class classification",2014,"Knowledge and Information Systems",8,"10.1007/s10115-013-0661-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908134516&doi=10.1007%2fs10115-013-0661-7&partnerID=40&md5=3fccd920b98bb573c5aca9a2003e1161","An extension of Campbell and Bennett’s novelty detection or one-class classification model incorporating prior knowledge is studied in the paper. The proposed extension relaxes the strong assumption of the empirical probability distribution over elements of a training set and deals with a set of probability distributions produced by prior knowledge about training data. The classification problem is solved by considering extreme points of the probability distribution set or by means of the conjugate duality technique. Special cases of prior knowledge are considered in detail, including the imprecise linear-vacuous mixture model and interval-valued moments of feature values. Numerical experiments show that the proposed models outperform Campbell and Bennett’s model for many real and synthetic data. © 2013, Springer-Verlag London.","Extreme points; Imprecise statistical model; Linear programming; Machine learning; Minimax strategy; Novelty detection; One-class classification","Springer London"
"You D., Benitez-Quiroz C.F., Martinez A.M.","Multiobjective optimization for model selection in kernel methods in regression",2014,"IEEE Transactions on Neural Networks and Learning Systems",12,"10.1109/TNNLS.2013.2297686","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907814221&doi=10.1109%2fTNNLS.2013.2297686&partnerID=40&md5=b59d43fd75518d04d9431c379abeaafe","Regression plays a major role in many scientific and engineering problems. The goal of regression is to learn the unknown underlying function from a set of sample vectors with known outcomes. In recent years, kernel methods in regression have facilitated the estimation of nonlinear functions. However, two major (interconnected) problems remain open. The first problem is given by the bias-versus-variance tradeoff. If the model used to estimate the underlying function is too flexible (i.e., high model complexity), the variance will be very large. If the model is fixed (i.e., low complexity), the bias will be large. The second problem is to define an approach for selecting the appropriate parameters of the kernel function. To address these two problems, this paper derives a new smoothing kernel criterion, which measures the roughness of the estimated function as a measure of model complexity. Then, we use multiobjective optimization to derive a criterion for selecting the parameters of that kernel. The goal of this criterion is to find a tradeoff between the bias and the variance of the learned function. That is, the goal is to increase the model fit while keeping the model complexity in check. We provide extensive experimental evaluations using a variety of problems in machine learning, pattern recognition, and computer vision. The results demonstrate that the proposed approach yields smaller estimation errors as compared with methods in the state of the art. © 2012 IEEE.","Kernel methods; kernel optimization; optimization; Pareto optimality; regression","Institute of Electrical and Electronics Engineers Inc."
"Duchi J.C., Jordan M.I., Wainwright M.J.","Privacy aware learning",2014,"Journal of the ACM",58,"10.1145/2666468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919772168&doi=10.1145%2f2666468&partnerID=40&md5=c5dbee07008776456e84798bbb887998","We study statistical risk minimization problems under a privacy model in which the data is kept confidential even from the learner. In this local privacy framework, we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures. As a consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility, as measured by convergence rate, of any statistical estimator or learning procedure. © 2014 ACM.","Differential privacy; Lower bounds; Machine learning; Minimax convergence rates; Saddle points","Association for Computing Machinery"
"Miranda P.B.C., Prudêncio R.B.C., de Carvalho A.P.L.F., Soares C.","A hybrid meta-learning architecture for multi-objective optimization of SVM parameters",2014,"Neurocomputing",29,"10.1016/j.neucom.2014.06.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904806561&doi=10.1016%2fj.neucom.2014.06.026&partnerID=40&md5=c235ff72980f7c7ba0a8f9a6589631f3","Support Vector Machines (SVMs) have achieved a considerable attention due to their theoretical foundations and good empirical performance when compared to other learning algorithms in different applications. However, the SVM performance strongly depends on the adequate calibration of its parameters. In this work we proposed a hybrid multi-objective architecture which combines meta-learning (ML) with multi-objective particle swarm optimization algorithms for the SVM parameter selection problem. Given an input problem, the proposed architecture uses a ML technique to suggest an initial Pareto front of SVM configurations based on previous similar learning problems; the suggested Pareto front is then refined by a multi-objective optimization algorithm. In this combination, solutions provided by ML are possibly located in good regions in the search space. Hence, using a reduced number of successful candidates, the search process would converge faster and be less expensive. In the performed experiments, the proposed solution was compared to traditional multi-objective algorithms with random initialization, obtaining Pareto fronts with higher quality on a set of 100 classification problems. © 2014 Elsevier B.V.","Meta-learning; Multi-objective optimization; Parameter selection; Particles swarm optimization; Support vector machines","Elsevier"
"Bhowan U., Johnston M., Zhang M., Yao X.","Reusing genetic programming for ensemble selection in classification of unbalanced data",2014,"IEEE Transactions on Evolutionary Computation",58,"10.1109/TEVC.2013.2293393","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914103027&doi=10.1109%2fTEVC.2013.2293393&partnerID=40&md5=73027528f149b61314b54dba80ccc8c3","Classification algorithms can suffer from performance degradation when the class distribution is unbalanced. This paper develops a two-step approach to evolving ensembles using genetic programming (GP) for unbalanced data. The first step uses multiobjective (MO) GP to evolve a Pareto-approximated front of GP classifiers to form the ensemble by trading-off the minority and the majority class against each other during learning. The MO component alleviates the reliance on sampling to artificially rebalance the data. The second step, which is the focus this paper, proposes a novel ensemble selection approach using GP to automatically find/choose the best individuals for the ensemble. This new GP approach combines multiple Pareto-approximated front members into a single composite genetic program solution to represent the (optimized) ensemble. This ensemble representation has two main advantages/novelties over traditional genetic algorithm (GA) approaches. First, by limiting the depth of the composite solution trees, we use selection pressure during evolution to find small highly-cooperative groups of individuals for the ensemble. This means that ensemble sizes are not fixed a priori (as in GA), but vary depending on the strength of the base learners. Second, we compare different function set operators in the composite solution trees to explore new ways to aggregate the member outputs and thus, control how the ensemble computes its output. We show that the proposed GP approach evolves smaller more diverse ensembles compared to an established ensemble selection algorithm, while still performing as well as, or better than the established approach. The evolved GP ensembles also perform well compared to other bagging and boosting approaches, particularly on tasks with high levels of class imbalance. © 1997-2012 IEEE.","Classification; ensemble machine learning; genetic programming; unbalanced data","Institute of Electrical and Electronics Engineers Inc."
"Duro J.A., Kumar Saxena D., Deb K., Zhang Q.","Machine learning based decision support for many-objective optimization problems",2014,"Neurocomputing",16,"10.1016/j.neucom.2014.06.076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906951087&doi=10.1016%2fj.neucom.2014.06.076&partnerID=40&md5=27eef04e5bf6701ad77b294d809d4d40","Multiple Criteria Decision-Making (MCDM) based Multi-objective Evolutionary Algorithms (MOEAs) are increasingly becoming popular for dealing with optimization problems with more than three objectives, commonly termed as many-objective optimization problems (MaOPs). These algorithms elicit preferences from a single or multiple Decision Makers (DMs), a priori or interactively, to guide the search towards the solutions most preferred by the DM(s), as against the whole Pareto-optimal Front (POF). Despite its promise for dealing with MaOPs, the utility of this approach is impaired by the lack of- objectivity; repeatability; consistency; and coherence in DM's preferences. This paper proposes a machine learning based framework to counter the above limitations. Towards it, the preference-structure of the different objectives embedded in the problem model is learnt in terms of: a smallest set of conflicting objectives which can generate the same POF as the original problem; the smallest objective sets corresponding to pre-specified errors; and the objective sets of pre-specified sizes that correspond to minimum error. While the focus is on demonstrating how the proposed framework could serve as a decision support for the DM, its performance is also studied vis-à-vis an alternative approach (based on dominance relation preservation), for a wide range of test problems and a real-world problem. The results mark a new direction for MCDM based MOEAs for MaOPs. © 2014 Elsevier B.V.","Evolutionary many-objective optimization; Kernels and multiple criteria decision-making; Maximum variance unfolding; Principal component analysis","Elsevier"
"Li K., Kwong S.","A general framework for evolutionary multiobjective optimization via manifold learning",2014,"Neurocomputing",24,"10.1016/j.neucom.2014.03.070","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906949014&doi=10.1016%2fj.neucom.2014.03.070&partnerID=40&md5=d32083ef3d37a1bb82cf65a59930755a","Under certain mild condition, the Pareto-optimal set (PS) of a continuous multiobjective optimization problem, with m objectives, is a piece-wise continuous (m-1)-dimensional manifold. This regularity property is important, yet has been unfortunately ignored in many evolutionary multiobjective optimization (EMO) studies. The first work that explicitly takes advantages of this regularity property in EMO is the regularity model-based multiobjective estimation of distribution algorithm (RM-MEDA). However, its performance largely depends on its model parameter, which is problem dependent. Manifold learning, also known as nonlinear dimensionality reduction, is able to discover the geometric property of a low-dimensional manifold embedded in the high-dimensional ambient space. This paper presents a general framework that applies advanced manifold learning techniques in EMO. At each generation, we first use a principal curve algorithm to obtain an approximation of the PS manifold. Then, the Laplacian eigenmaps algorithm is employed to find the low-dimensional representation of this PS approximation. Afterwards, we identify the neighborhood relationship in this low-dimensional representation, which is also applicable for the original high-dimensional data. Based on the neighborhood relationship, we can interpolate new candidate solutions that obey the geometric property of the PS manifold. Empirical results validate the effectiveness of our proposal. © 2014 Elsevier B.V.","Evolutionary computation; Laplacian eigenmaps; Manifold learning; Multiobjective optimization; Principal curve; Regularity","Elsevier"
"Ma X., Liu F., Qi Y., Gong M., Yin M., Li L., Jiao L., Wu J.","MOEA/D with opposition-based learning for multiobjective optimization problem",2014,"Neurocomputing",57,"10.1016/j.neucom.2014.04.068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906947832&doi=10.1016%2fj.neucom.2014.04.068&partnerID=40&md5=53f98d19802ec25da8d04508d5ef8feb","Multiobjective evolutionary algorithm based on decomposition (MOEA/D) has attracted a great deal of attention and has obtained enormous success in the field of evolutionary multiobjective optimization. It converts a multiobjective optimization problem (MOP) into a set of scalar optimization subproblems and then uses the evolutionary algorithm (EA) to optimize these subproblems simultaneously. However, there is a great deal of randomness in MOEA/D. Researchers in the field of evolutionary algorithm, reinforcement learning and neural network have reported that the simultaneous consideration of randomness and opposition has an advantage over pure randomness. A new scheme, called opposition-based learning (OBL), has been proposed in the machine learning field. In this paper, OBL has been integrated into the framework of MOEA/D to accelerate its convergence speed. Hence, our proposed approach is called opposition-based learning MOEA/D (MOEA/D-OBL). Compared with MOEA/D, MOEA/D-OBL uses an opposition-based initial population and opposition-based learning strategy to generate offspring during the evolutionary process. It is compared with its parent algorithm MOEA/D on four representative kinds of MOPs and many-objective optimization problems. Experimental results indicate that MOEA/D-OBL outperforms or performs similar to MOEA/D. Moreover, the parameter sensitivity of generalization opposite point and the probable to use OBL is experimentally investigated. © 2014 Elsevier B.V.","Decomposition; Evolutionary algorithm; Multi-objective optimization; Opposition-based learning","Elsevier"
"Mahdavi M., Zhang L., Jin R.","Lower and upper bounds on the generalization of stochastic exponentially concave optimization",2015,"Journal of Machine Learning Research",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984698465&partnerID=40&md5=f9ee8e15b18af940312db38915ff00a5","In this paper we derive high probability lower and upper bounds on the excess risk of stochastic optimization of exponentially concave loss functions. Exponentially concave loss functions encompass several fundamental problems in machine learning such as squared loss in linear regression, logistic loss in classification, and negative logarithm loss in portfolio management. We demonstrate an O(d log T/T ) upper bound on the excess risk of stochastic online Newton step algorithm, and an O(d/T ) lower bound on the excess risk of any stochastic optimization method for squared loss, indicating that the obtained upper bound is optimal up to a logarithmic factor. The analysis of upper bound is based on recent advances in concentration inequalities for bounding self-normalized martingales, which is interesting by its own right, and the proof technique used to achieve the lower bound is a probabilistic method and relies on an information-theoretic minimax analysis. © 2015 M. Mahdavi, L. Zhang & R. Jin.","Excess Risk; Exponentially Concave Losses; Stochastic Optimization","Microtome Publishing"
"Sopov E., Ivanov I.","Self-configuring ensemble of neural network classifiers for emotion recognition in the intelligent human-machine interaction",2015,"Proceedings - 2015 IEEE Symposium Series on Computational Intelligence, SSCI 2015",1,"10.1109/SSCI.2015.252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964921921&doi=10.1109%2fSSCI.2015.252&partnerID=40&md5=44c50e2a7a4e4096f19c77da136a1993","Reducing the dimensionality of datasets and configuring learning algorithms for solving particular practical tasks are the main problems in machine learning. In this work we propose multi-objective optimization approach to feature selection and base learners hyper-parameter optimization. The effectiveness of the proposed multi-objective approach is compared to the single-objective approach. We have chosen emotion recognition problem by audio-visual data as a benchmark for comparing the two mentioned approaches. We have chosen neural network as a base learning algorithm for testing the proposed approach to parameter optimization. As a result of multi-objective optimization applied to parameter configuration we get the Pareto set of neural networks with optimal parameter values. In order to get the single output, the Pareto optimal neural networks were combined into an ensemble. We have examined several ensemble model fusion techniques including voting, average class probabilities and meta-classification. According to results, multi-objective optimization approach to feature selection provides an average 2.8% better emotion classification rate on the given datasets than single-objective approach. Multi-objective approach is 5.4% more effective compared to principal components analysis, and 13.9% more effective compared to not using any dimensionality reduction at all. Multi-objective approach applied to neural networks parameter optimization provided on average 7.1% better classification rate than single-objective approach. The results suggest that the proposed multi-objective optimization approach is more effective at solving considered emotion recognition problem. © 2015 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Behpour S., Ziebart B.D.","A minimax robust approach for learning to assist users with pointing tasks",2015,"AAAI Workshop - Technical Report",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964599981&partnerID=40&md5=b219ea78e8a6b44127683c71d8797c78","Learning to provide appropriate assistance to people in different situations is an extremely important, but insufficiently investigated machine learning task. Applications include human-robot and human-computer interactions settings (Lieberman 2009; Goodrich and Schultz 2007) to max-imizing the benefits of assistive technologies (Hoey et al. 2005). Three key challenges must be overcome to appropriately address this task: Complexity: The space of possible assistive policies can be very large, making many existing methods (e.g., from reinforcement learning) too data inefficient to be practical. Noise and misspecification: observed human behavior is often noisy and parametric formulations that reduce complexity will typically suffer from model misspecification, leading to unboundedly sub-optimal assistance. Biasedness: data available for learning a model is biased by previously provided assistive actions, violating the typical assumptions of supervised learning. © Copyright 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"AI Access Foundation"
"Gilan S.S., Dilkina B.","Sustainable building design: A challenge at the intersection of machine learning and design optimization",2015,"AAAI Workshop - Technical Report",11,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964570149&partnerID=40&md5=128a4f595a085cfebd4055d6239638af","Residential and commercial buildings are responsible for about 40% of primary energy consumption in the United States, hence improving their energy efficiency could have important sustainability benefits. The design of a building has tremendous effect on its energy profile, and recently there has been an increased interest in developing optimization methods that support the design of high performance buildings. Previous approaches are either based on simulation optimization or on training an accurate predictive model that is queried during the optimization. We propose a method that more tightly integrates the machine learning and optimization components, by employing active learning during optimization. In particular, we use a Gaussian Process (GP) model for the prediction and active learning and multi- objective genetic algorithm NSGA-II for the optimization. We develop a comprehensive and publicly available benchmark for building design optimization. We evaluate 5 machine learning approaches on our dataset, and show that the GP model is competitive, in addition to being well-suited for the active learning setting. We compare our optimization approach against the 2-stage approach and simulation optimization. Our results show that our approach produces solutions at the Pareto frontier compared to the other two approaches, while using only a fraction of the simulations and time. © Copyright 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"AI Access Foundation"
"Benavoli A., de Campos C.P.","Statistical tests for joint analysis of performance measures",2015,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-319-28379-1_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955318574&doi=10.1007%2f978-3-319-28379-1_6&partnerID=40&md5=5d9cc7e4f272f845e15285178304686e","Recently there has been an increasing interest in the development of new methods using Pareto optimality to deal with multiobjective criteria (for example, accuracy and architectural complexity). Once one has learned a model based on their devised method, the problem is then how to compare it with the state of art. In machine learning, algorithms are typically evaluated by comparing their performance on different data sets by means of statistical tests. Unfortunately, the standard tests used for this purpose are not able to jointly consider performance measures. The aim of this paper is to resolve this issue by developing statistical procedures that are able to account for multiple competing measures at the same time. In particular, we develop two tests: a frequentist procedure based on the generalized likelihood-ratio test and a Bayesian procedure based on a multinomial-Dirichlet conjugate model. We further extend them by discovering conditional independences among measures to reduce the number of parameter of such models, as usually the number of studied cases is very reduced in such comparisons. Real data from a comparison among general purpose classifiers is used to show a practical application of our tests. © Springer International Publishing Switzerland 2015.",,"Springer Verlag"
"Panagopoulos A.A., Alam M., Rogers A., Jennings N.R.","Adaheat: A general adaptive intelligent agent for domestic heating control",2015,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945218365&partnerID=40&md5=12e769e6e0a623397849a455aaf27d9b","Improving the energy efficiency of domestic heating systems can lead to a major reduction in energy consumption and the corresponding CO2 emissions. To this end, intelligent domestic heating agents (IDHAs) aim to operate domestic heating systems more efficiently with minimum user input. In this work, we propose a new general IDHA that balances heating cost and thermal discomfort in an infinite horizon optimization manner, learns an adaptive thermal model of the system under control on-line and plans a heating schedule that fully exploits the probabilistic occupancy estimates. Importantly, our agent adapts to the user preferences in balancing heating cost and thermal discomfort, as it relies on a single parametrization variable that is learned on-line, and is able to consider a wide range of heating systems typically employed in domestic settings. The backbone of our IDHA is an adaptive model predictive control approach along with a new general planning algorithm that utilizes dynamic programming. We present a thorough evaluation of our approach, and show its effectiveness in terms of Pareto efficiency and usability criteria against state-of-the-art IDHAs. By so doing, we also conduct a comprehensive characterization of existing IDHAs to provide significant insights about their performance in different operational settings. Copyright © 2015, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","Control; Energy savings; Machine learning","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)"
"Nguyen T.H., Tambe M.","A unifying methodology for confronting uncertainties in security games: Advances and algorithms (doctoral consortium)",2015,"Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944688595&partnerID=40&md5=c711a8bc5123b37ff3bbbca909a88e9d","Given the real-world applications of Stackelberg security games (SSGs), addressing uncertainties in these games is a major challenge. Two competitive approaches have been pursued by previous work on addressing uncertainties in SSGs, namely: (1) applying robust optimization techniques without requiring a prior distribution; and (2) using probabilistic models to capture uncertainties. In general, the decision of which approach to use is based on the availability of data. While the first approach suits data-sparse domains, the second approach works better for data-rich domains. My thesis will focus on addressing uncertainties in SSGs following these two leading approaches. In particular, with regards to robust methods, I attempt to develop new maximin/minimax regret-based robust algorithms for computing a defender's optimal strategy given uncertainties. I also aim to contribute to probabilistic modeling techniques by developing a new computational model of human decision making to capture the adversary's bounded rationality. Copyright © 2015, International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.","Behavioral Model; Computational Game Theory; Machine Learning; Robust Optimization; Security Games; Uncertainty","International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)"
"Breaban M.E., Iftene A.","Dynamic objective sampling in many-objective optimization",2015,"Procedia Computer Science",4,"10.1016/j.procs.2015.08.117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941038617&doi=10.1016%2fj.procs.2015.08.117&partnerID=40&md5=a0d31c1b320f186c800e0a6e5cf288bc","Given the poor convergence of multi-objective evolutionary algorithms (MOEAs) demonstrated in several studies that address many-objective optimization, we propose a simple objective sampling scheme that can be incorporated in any MOEA in order to enhance its convergence towards the Pareto front. An unsupervised clustering algorithm is applied in the space of objectives at various moments during the search process performed by the MOEA, and only representative objectives are used to guide the optimizer towards the Pareto front during next iterations. The effectiveness of the approach is experimentally demonstrated in the context of the NSGA-II optimizer. The redundant objectives are eliminated during search when the number of clusters (representative objectives) is automatically selected by an unsupervised standard procedure, popular in the field of unsupervised machine learning. Furthermore, if after eliminating all the redundant objectives the number of conflicting objectives is still high, continuing to eliminate objectives by imposing a lower number of clusters speeds-up the convergence towards the Pareto front. © 2015 The Authors. Published by Elsevier B.V.","Clustering; Many-objective optimization; Rank correlation; Unsupervised objective selection","Elsevier B.V."
"Sudusinghe K., Jiao Y., Salem H.B., Van Der Schaar M., Bhattacharyya S.S.","Multiobjective design optimization in the Lightweight Dataflow for DDDAS Environment (LiD4E)",2015,"Procedia Computer Science",3,"10.1016/j.procs.2015.05.364","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939212317&doi=10.1016%2fj.procs.2015.05.364&partnerID=40&md5=842eab8d22417cd5fe6fd338c0f779d0","In this paper, we introduce new methods for multiobjective, system-level optimization that have been incorporated into the Lightweight Dataflow for Dynamic Data Driven Application Systems (DDDAS) Environment (LiD4E). LiD4E is a design tool for optimized implementation of dynamic, data-driven stream mining systems using high-level dataflow models of computation. More specifically, we develop in this paper new methods for integrated modeling and optimization of real-time stream mining constraints, multidimensional stream mining performance (precision and recall), and energy efficiency. Using a design methodology centered on data-driven control of and coordination between alternative dataflow subsystems for stream mining (classification modes), we develop systematic methods for exploring complex, multidimensional design spaces associated with dynamic stream mining systems, and deriving sets of Pareto-optimal system configurations that can be switched among based on data characteristics and operating constraints. © The Authors. Published by Elsevier B.V.","Dataflow; DDDAS; Machine learning; Model-based design; Stream mining","Elsevier B.V."
"Galvan E., Malak R.J.","P3GA: An algorithm for technology characterization",2015,"Journal of Mechanical Design, Transactions of the ASME",19,"10.1115/1.4028101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928785543&doi=10.1115%2f1.4028101&partnerID=40&md5=0a7fe9f3b71540c1887b24c44df38934","It is important for engineers to understand the capabilities and limitations of the technologies they consider for use in their systems. However, communicating this information can be a challenge. Mathematical characterizations of technical capabilities are of interest as a means to reduce ambiguity in communication and to increase opportunities to utilize design automation methods. The parameterized Pareto frontier (PPF) was introduced in prior work as a mathematical basis for modeling technical capabilities. One advantage of PPFs is that, in many cases, engineers can model a system by composing frontiers of its components. This allows for rapid technology evaluation and design space exploration. However, finding the PPF can be difficult. The contribution of this article is a new algorithm for approximating the PPF, called predictive parameterized Pareto genetic algorithm (P3GA). The proposed algorithm uses concepts and methods from multi-objective genetic optimization and machine learning to generate a discrete approximation of the PPF. If needed, designers can generate a continuous approximation of the frontier by generalizing beyond these data. The algorithm is explained, its performance is analyzed on numerical test problems, and its use is demonstrated on an engineering example. The results of the investigation indicate that P3GA may be effective in practice. Copyright VC 2015 by ASME.",,"American Society of Mechanical Engineers (ASME)"
"Dozono H.","Visualization and classification of DNA sequence by using pareto learning self organizing maps for short sequences",2015,"Proceedings of the 7th International Conference on Bioinformatics and Computational Biology, BICOB 2015",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925875424&partnerID=40&md5=ba93654734ea6c40ca547d4cb6e96718","Next-generation sequencing techniques produce an enormous amount of sequence data. Analyzing these sequences requires an efficient method that can handle large amounts of data. Self-organizing maps (SOMs), which use the frequencies of N-tuples and correlation coefficients of nucleotide, can categorize sets of DNA sequences with unsupervised learning. And Pareto learning SOM can classify the DNA sequences with supervised learning. In this study, the effect of the short fragments, which will be given directly as the sequencing results of NGS are examined using Pareto learning SOM, and the novel method which uses the correlation coefficients of tuples and integration of correlation coefficient and frequencies are proposed. Copyright ISCA, BICOB 2015.","Meta-genome; Self-Organizing Map; Sequence Analysis","The International Society for Computers and Their Applications (ISCA)"
"Boryczka U., Kozak J.","Enhancing the effectiveness of Ant Colony Decision Tree algorithms by co-learning",2015,"Applied Soft Computing",26,"10.1016/j.asoc.2014.12.036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922726367&doi=10.1016%2fj.asoc.2014.12.036&partnerID=40&md5=a3713acd5928eb7d91903bb2bf962b8b","Data mining and visualization techniques for high-dimensional data provide helpful information to substantially augment decision-making. Optimization techniques provide a way to efficiently search for these solutions. ACO applied to data mining tasks - a decision tree construction - is one of these methods and the focus of this paper. The Ant Colony Decision Tree (ACDT) approach generates solutions efficiently and effectively but scales poorly to large problems. This article merges the methods that have been developed for better construction of decision trees by ants. The ACDT approach is tested in the context of the bi-criteria evaluation function by focusing on two problems: the size of the decision trees and the accuracy of classification obtained during ACDT performance. This approach is tested in co-learning mechanism, it means agents-ants can interact during the construction decision trees via pheromone values. This cooperation is a chance of getting better results. The proposed methodology of analysis of ACDT is tested in a number of well-known benchmark data sets from the UCI Machine Learning Repository. The empirical results clearly show that the ACDT algorithm creates good solutions which are located in the Pareto front. The software that implements the ACDT algorithm used to generate the results of this study can be downloaded freely from http://www.acdtalgorithm.com. © 2015 Elsevier B.V. All rights reserved.","Ant Colony Decision Trees; Ant Colony Optimization; Ant-Miner; Decision trees; Pareto front; Quality of decision trees","Elsevier Ltd"
"Truong D.T., Battiti R.","A flexible cluster-oriented alternative clustering algorithm for choosing from the Pareto front of solutions",2015,"Machine Learning",4,"10.1007/s10994-013-5350-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920708105&doi=10.1007%2fs10994-013-5350-y&partnerID=40&md5=edf08c01c6c0589202532318cbd3d5c4","Supervised alternative clustering is the problem of finding a set of clusterings which are of high quality and different from a given negative clustering. The task is therefore a clear multi-objective optimization problem. Optimizing two conflicting objectives at the same time requires dealing with trade-offs. Most approaches in the literature optimize these objectives sequentially (one objective after another one) or indirectly (by some heuristic combination of the objectives). Solving a multi-objective optimization problem in these ways can result in solutions which are dominated, and not Pareto-optimal. We develop a direct algorithm, called COGNAC, which fully acknowledges the multiple objectives, optimizes them directly and simultaneously, and produces solutions approximating the Pareto front. COGNAC performs the recombination operator at the cluster level instead of at the object level, as in the traditional genetic algorithms. It can accept arbitrary clustering quality and dissimilarity objectives and provides solutions dominating those obtained by other state-of-the-art algorithms. Based on COGNAC, we propose another algorithm called SGAC for the sequential generation of alternative clusterings where each newly found alternative clustering is guaranteed to be different from all previous ones. The experimental results on widely used benchmarks demonstrate the advantages of our approach. © 2013, The Author(s).","Alternative clustering; Cluster-oriented recombination; Genetic algorithms; Multi-objective optimization","Kluwer Academic Publishers"
"Xydis S., Palermo G., Zaccaria V., Silvano C.","SPIRIT: Spectral-aware pareto iterative refinement optimization for supervised high-level synthesis",2015,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",30,"10.1109/TCAD.2014.2363392","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919832879&doi=10.1109%2fTCAD.2014.2363392&partnerID=40&md5=81dc115015476e38362ce200085dd940","Supervised high-level synthesis (HLS) is a new class of design problems where exploration strategies play the role of supervisor for tuning an HLS engine. The complexity of the problem is increased due to the large set of tunable parameters exposed by the 'new wave' of HLS tools that include not only architectural alternatives but also compiler transformations. In this paper, we developed a novel exploration approach, called spectral-aware Pareto iterative refinement, that exploits response surface models (RSMs) and spectral analysis for predicting the quality of the design points without resorting to costly architectural synthesis procedures. We show that the target solution space can be accurately modeled through RSMs, thus enabling a speedup of the overall exploration without compromising the quality of results. Furthermore, we introduce the usage of spectral techniques to find high variance regions of the design space that require analysis for improving the RSMs prediction accuracy. © 2014 IEEE.","design space exploration; high level synthesis; machine learning; spectral analysis; system level design","Institute of Electrical and Electronics Engineers Inc."
"Li C., Georgiopoulos M., Anagnostopoulos G.C.","Pareto-path multitask multiple kernel learning",2015,"IEEE Transactions on Neural Networks and Learning Systems",12,"10.1109/TNNLS.2014.2309939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919617362&doi=10.1109%2fTNNLS.2014.2309939&partnerID=40&md5=4241cba7544cd845c1b432b8071af57e","A traditional and intuitively appealing Multitask Multiple Kernel Learning (MT-MKL) method is to optimize the sum (thus, the average) of objective functions with (partially) shared kernel function, which allows information sharing among the tasks. We point out that the obtained solution corresponds to a single point on the Pareto Front (PF) of a multiobjective optimization problem, which considers the concurrent optimization of all task objectives involved in the Multitask Learning (MTL) problem. Motivated by this last observation and arguing that the former approach is heuristic, we propose a novel support vector machine MT-MKL framework that considers an implicitly defined set of conic combinations of task objectives. We show that solving our framework produces solutions along a path on the aforementioned PF and that it subsumes the optimization of the average of objective functions as a special case. Using the algorithms we derived, we demonstrate through a series of experimental results that the framework is capable of achieving a better classification performance, when compared with other similar MTL approaches. © 2014 IEEE.","Machine learning; optimization methods; pattern recognition; supervised learning; support vector machines (SVM).","Institute of Electrical and Electronics Engineers Inc."
"Cheng S., Chen M.-Y., Fleming P.J.","Improved multi-objective particle swarm optimization with preference strategy for optimal DG integration into the distribution system",2015,"Neurocomputing",38,"10.1016/j.neucom.2012.08.074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908052496&doi=10.1016%2fj.neucom.2012.08.074&partnerID=40&md5=2061d3fdd57a0d1f4db962b012ab43e5","Considering the different requirements for decision and state variables in engineering optimizations, an improved multi-objective particle swarm optimization with preference strategy (IMPSO-PS) is presented and applied to the optimal integration of distributed generation (DG) into the distribution system. Preference factors are introduced to quantify the degree of preference for certain attributes in the constraint-space. In addition to the application of a popular non-dominated sorting technique for identifying Pareto solutions, the performance of IMPSO-PS is strengthened via the inclusion of a dynamic selection of the global bests, a novel circular non-dominated selection of particles from one iteration to the next and a special mutation operation. The proposed algorithm has been successfully applied to benchmark functions and to the multi-objective optimal integration of DG into an IEEE 33-bus system. This real-world application aims to satisfy some special preferences and determine the optimal locations and capacities of DG units to minimize the total active power loss of the system and decrease cost caused by power generation and pollutant emissions. The results show that the proposed approach can provide a wider range of Pareto solutions of high quality, while satisfying special preference demands. © 2014 Elsevier B.V.","Circular non-dominated selection; Distributed generation (DG); Multi-objective particle swarm optimization; NSGA-II; Optimal allocation; Preference strategy","Elsevier"
"Al-Jubouri B., Gabrys B.","Multicriteria approaches for predictive model generation: A comparative experimental study",2015,"IEEE SSCI 2014 - 2014 IEEE Symposium Series on Computational Intelligence - MCDM 2014: 2014 IEEE Symposium on Computational Intelligence in Multi-Criteria Decision-Making, Proceedings",3,"10.1109/MCDM.2014.7007189","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922571989&doi=10.1109%2fMCDM.2014.7007189&partnerID=40&md5=a928829ba70ccf0fb4a0571e21105635","This study investigates the evaluation of machine learning models based on multiple criteria. The criteria included are: predictive model accuracy, model complexity, and algorithmic complexity (related to the learning/adaptation algorithm and prediction delivery) captured by monitoring the execution time. Furthermore, it compares the models generated from optimising the criteria using two approaches. The first approach is a scalarized multi objective optimisation, where the models are generated from optimising a single cost function that combines the criteria. On the other hand the second approach uses a Pareto-based multi objective optimisation to trade-off the three criteria and to generate a set of non-dominated models. This study shows that defining universal measures for the three criteria is not always feasible. Furthermore, it was shown that, the models generated from Pareto-based multi objective optimisation approach can be more accurate and more diverse than the models generated from scalarized multi objective optimisation approach. © 2014 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Rakhlin A., Sridharan K., Tewari A.","Online learning via sequential complexities",2015,"Journal of Machine Learning Research",24,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930672598&partnerID=40&md5=874896a473b090fcb40f0f49801a6b64","We consider the problem of sequential prediction and provide tools to study the minimax value of the associated game. Classical statistical learning theory provides several useful complexity measures to study learning with i.i.d. data. Our proposed sequential complexities can be seen as extensions of these measures to the sequential setting. The developed theory is shown to yield precise learning guarantees for the problem of sequential prediction. In particular, we show necessary and sufficient conditions for online learnability in the setting of supervised learning. Several examples show the utility of our framework: we can establish learnability without having to exhibit an explicit online learning algorithm. ©2015 Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari.","Online learning; Regret minimization; Sequential complexities","Microtome Publishing"
"Utkin L.V., Zhuk Y.A.","Robust classifiers using imprecise probability models and importance of classes",2015,"International Journal on Artificial Intelligence Tools",,"10.1142/S0218213015500086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928548325&doi=10.1142%2fS0218213015500086&partnerID=40&md5=c549317894630d36d6be39ff030739af","A framework for constructing robust classification models is proposed in the paper. An assumption about importance of one of the classes in comparison with other classes is incorporated into the models. It often takes place in the real application, for example, in reliability, in medical diagnostic, etc. A main idea underlying the models is to consider a set of probability distributions on training examples produced by the imprecise probability models such as linear-vacuous mixture and constant odd-ratio contaminated models. Extreme points of the sets of probability distributions are a main tool for constructing the robust classifiers. It is shown that algorithms for computing optimal classification parameters are reduced to a finite number of weighted support vector machines with weights determined by the extreme points. Experimental results with synthetic and real data illustrate the proposed models. © 2015 World Scientific Publishing Company.","classification; extreme points; imprecise probability model; Machine learning; minimax strategy; quadratic programming; support vector machine","World Scientific"
"Yang T., Mahdavi M., Jin R., Zhu S.","An efficient primal dual prox method for non-smooth optimization",2015,"Machine Learning",12,"10.1007/s10994-014-5436-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922337974&doi=10.1007%2fs10994-014-5436-1&partnerID=40&md5=704683425955db3b1dbc1a40ffb788a1","We study the non-smooth optimization problems in machine learning, where both the loss function and the regularizer are non-smooth functions. Previous studies on efficient empirical loss minimization assume either a smooth loss function or a strongly convex regularizer, making them unsuitable for non-smooth optimization. We develop a simple yet efficient method for a family of non-smooth optimization problems where the dual form of the loss function is bilinear in primal and dual variables. We cast a non-smooth optimization problem into a minimax optimization problem, and develop a primal dual prox method that solves the minimax optimization problem at a rate of O(1/T) assuming that the proximal step can be efficiently solved, significantly faster than a standard subgradient descent method that has an (Formula Presented) convergence rate. Our empirical studies verify the efficiency of the proposed method for various non-smooth optimization problems that arise ubiquitously in machine learning by comparing it to the state-of-the-art first order methods. © 2014, The Author(s).","Convergence rate; Efficiency; Non-smooth optimization; Primal dual method; Sparsity","Kluwer Academic Publishers"
"Mishra N., Zhang H., Lafferty J.D., Hoffmann H.","A probabilistic graphical model-based approach for minimizing energy under performance constraints",2015,"International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS",27,"10.1145/2694344.2694373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939133793&doi=10.1145%2f2694344.2694373&partnerID=40&md5=2fc7ab83bd33eeb425c72db9f33d016d","In many deployments, computer systems are underutilized - meaning that applications have performance requirements that demand less than full system capacity. Ideally, we would take advantage of this under-utilization by allocating system resources so that the performance requirements are met and energy is minimized. This optimization problem is complicated by the fact that the performance and power consumption of various system configurations are often application - or even input - dependent. Thus, practically, minimizing energy for a performance constraint requires fast, accurate estimations of application-dependent performance and power tradeoffs. This paper investigates machine learning techniques that enable energy savings by learning Pareto-optimal power and performance tradeoffs. Specifically, we propose LEO, a probabilistic graphical model-based learning system that provides accurate online estimates of an application's power and performance as a function of system configuration. We compare LEO to (1) offline learning, (2) online learning, (3) a heuristic approach, and (4) the true optimal solution. We find that LEO produces the most accurate estimates and near optimal energy savings. Copyright © 2015 ACM.","Adaptation; Dynamic systems; Energy minimization; Probabilistic graphical models; Statistics","Association for Computing Machinery"
"Mishra N., Zhang H., Lafferty J.D., Hoffmann H.","A probabilistic graphical model-based approach for minimizing energy under performance constraints",2015,"ACM SIGPLAN Notices",34,"10.1145/2694344.2694373","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951203877&doi=10.1145%2f2694344.2694373&partnerID=40&md5=558db653b92f8a618484085a7b07989b","In many deployments, computer systems are underutilized-meaning that applications have performance requirements that demand less than full system capacity. Ideally, we would take advantage of this under-utilization by allocating system resources so that the performance requirements are met and energy is minimized. This optimization problem is complicated by the fact that the performance and power consumption of various system configurations are often application-or even input-dependent. Thus, practically, minimizing energy for a performance constraint requires fast, accurate estimations of application-dependent performance and power tradeoffs. This paper investigates machine learning techniques that enable energy savings by learning Pareto-optimal power and performance tradeoffs. Specifically, we propose LEO, a probabilistic graphical model-based learning system that provides accurate online estimates of an application's power and performance as a function of system configuration. We compare LEO to (1) offline learning, (2) online learning, (3) a heuristic approach, and (4) the true optimal solution. We find that LEO produces the most accurate estimates and near optimal energy savings. Copyright © 2015 ACM.","Adaptation; Dynamic systems; Energy minimization; Probabilistic graphical models; Statistics","Association for Computing Machinery"
"Wang P., Emmerich M., Li R., Tang K., Bäck T., Yao X.","Convex Hull-Based Multiobjective Genetic Programming for Maximizing Receiver Operating Characteristic Performance",2015,"IEEE Transactions on Evolutionary Computation",32,"10.1109/TEVC.2014.2305671","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926459721&doi=10.1109%2fTEVC.2014.2305671&partnerID=40&md5=5b6d2257a2c237bde44c2951586d96d8","The receiver operating characteristic (ROC) is commonly used to analyze the performance of classifiers in data mining. An important topic in ROC analysis is the ROC convex hull (ROCCH), which is the least convex majorant (LCM) of the empirical ROC curve and covers potential optima for a given set of classifiers. ROCCH maximization problems have been taken as multiobjective optimization problem (MOPs) in some previous work. However, the special characteristics of ROCCH maximization problem makes it different from traditional MOPs. In this paper, the difference will be discussed in detail and a new convex hull-based multiobjective genetic programming (CH-MOGP) is proposed to solve ROCCH maximization problems. Specifically, convex hull-based without redundancy sorting (CWR-sorting) is introduced, which is an indicator-based selection scheme that aims to maximize the area under the convex hull. A novel selection procedure is also proposed based on the proposed sorting scheme. It is hypothesized that by using a tailored indicator-based selection, CH-MOGP becomes more efficient for ROC convex hull approximation than algorithms that compute all Pareto optimal points. Empirical studies are conducted to compare CH-MOGP to both existing machine learning approaches and multiobjective genetic programming (MOGP) methods with classical selection schemes. Experimental results show that CH-MOGP outperforms the other approaches significantly. © 1997-2012 IEEE.","Classification; evolutionary multiobjective algorithm; genetic programming; memetic algorithm; receiver operating characteristic (ROC) convex hull","Institute of Electrical and Electronics Engineers Inc."
"Liu K., Tovar A., Nutwell E., Detwiler D.","Thin-Walled Compliant Mechanism Component Design Assisted by Machine Learning and Multiple Surrogates",2015,"SAE Technical Papers",8,"10.4271/2015-01-1369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938357218&doi=10.4271%2f2015-01-1369&partnerID=40&md5=59cb0f223e64d4ff7789160544459905","This work introduces a new design algorithm to optimize progressively folding thin-walled structures and in order to improve automotive crashworthiness. The proposed design algorithm is composed of three stages: conceptual thickness distribution, design parameterization, and multi-objective design optimization. The conceptual thickness distribution stage generates an innovative design using a novel one-iteration compliant mechanism approach that triggers progressive folding even on irregular structures under oblique impact. The design parameterization stage optimally segments the conceptual design into a reduced number of clusters using a machine learning K-means algorithm. Finally, the multi-objective design optimization stage finds non-dominated designs of maximum specific energy absorption and minimum peak crushing force. The proposed optimization problem is addressed by a multi-objective genetic algorithm on sequentially updated surrogate models, which are optimally selected from a set of 24 surrogates. The effectiveness of the design algorithm is demonstrated on an S-rail thin-walled structure. The best compromised Pareto design increases specific energy absorption and decreases peak crushing force in the order of 8% and 12%, respectively. Copyright © 2015 SAE International.",,"SAE International"
"Qian C., Yu Y., Zhou Z.-H.","Pareto ensemble pruning",2015,"Proceedings of the National Conference on Artificial Intelligence",67,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949912487&partnerID=40&md5=387c4b57afd8bf78b2eb2b3d95c729af","Ensemble learning is among the state-of-the-art learning techniques, which trains and combines many base learners. Ensemble pruning removes some of the base learners of an ensemble, and has been shown to be able to further improve the generalization performance. However, the two goals of ensemble pruning, i.e., maximizing the generalization performance and minimizing the number of base learners, can conflict when being pushed to the limit. Most previous ensemble pruning approaches solve objectives that mix the two goals. In this paper, motivated by the recent theoretical advance of evolutionary optimization, we investigate solving the two goals explicitly in a bi-objective formulation and propose the PEP (Pareto Ensemble Pruning) approach. We disclose that PEP does not only achieve significantly better performance than the state-of-the-art approaches, and also gains theoretical support. Copyright © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"AI Access Foundation"
"Prakash J., Singh P.K.","An effective multiobjective approach for hard partitional clustering",2015,"Memetic Computing",17,"10.1007/s12293-014-0147-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939992553&doi=10.1007%2fs12293-014-0147-5&partnerID=40&md5=b4b0d74e507a75884ce2d3799c6b2512","Clustering is an unsupervised classification method in the field of data mining. Many population based evolutionary and swarm intelligence optimization methods are proposed to optimize clustering solutions globally based on a single selected objective function which lead to produce a single best solution. In this sense, optimized solution is biased towards a single objective, hence it is not equally well to the data set having clusters of different geometrical properties. Thus, clustering having multiple objectives should be naturally optimized through multiobjective optimization methods for capturing different properties of the data set. To achieve this clustering goal, many multiobjective population based optimization methods, e.g., multiobjective genetic algorithm, mutiobjective particle swarm optimization (MOPSO), are proposed to obtain diverse tradeoff solutions in the pareto-front. As single directional diversity mechanism in particle swarm optimization converges prematurely to local optima, this paper presents a two-stage diversity mechanism in MOPSO to improve its exploratory capabilities by incorporating crossover operator of the genetic algorithm. External archive is used to store non-dominated solutions, which is further utilized to find one best solution having highest F-measure value at the end of the run. Two conceptually orthogonal internal measures SSE and connectedness are used to estimate the clustering quality. Results demonstrate effectiveness of the proposed method over its competitors MOPSO, non-dominated sorting genetic algorithm, and multiobjective artificial bee colony on seven real data sets from UCI machine learning repository. © 2015, Springer-Verlag Berlin Heidelberg.","Data clustering; Evolutionary and swarm intelligence; Multiobjective optimization; Mutiobjective particle swarm optimization","Springer Verlag"
"Gromski P.S., Xu Y., Hollywood K.A., Turner M.L., Goodacre R.","The influence of scaling metabolomics data on model classification accuracy",2015,"Metabolomics",52,"10.1007/s11306-014-0738-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939138183&doi=10.1007%2fs11306-014-0738-7&partnerID=40&md5=8c38779aaa2c4641e4721166b39510e0","Correctly measured classification accuracy is an important aspect not only to classify pre-designated classes such as disease versus control properly, but also to ensure that the biological question can be answered competently. We recognised that there has been minimal investigation of pre-treatment methods and its influence on classification accuracy within the metabolomics literature. The standard approach to pre-treatment prior to classification modelling often incorporates the use of methods such as autoscaling, which positions all variables on a comparable scale thus allowing one to achieve separation of two or more groups (target classes). This is often undertaken without any prior investigation into the influence of the pre-treatment method on the data and supervised learning techniques employed. Whilst this is useful for deriving essential information such as predictive ability or visual interpretation in many cases, as shown in this study the standard approach is not always the most suitable option available. Here, a study has been conducted to investigate the influence of six pre-treatment methods—autoscaling, range, level, Pareto and vast scaling, as well as no scaling—on four classification models, including: principal components-discriminant function analysis (PC-DFA), support vector machines (SVM), random forests (RF) and k-nearest neighbours (kNN)—using three publically available metabolomics data sets. We have demonstrated that undertaking different pre-treatment methods can greatly affect the interpretation of the statistical modelling outputs. The results have shown that data pre-treatment is context dependent and that there was no single superior method for all the data sets used. Whilst we did find that vast scaling produced the most robust models in terms of classification rate for PC-DFA of both NMR spectroscopy data sets, in general we conclude that both vast scaling and autoscaling produced similar and superior results in comparison to the other four pre-treatment methods on both NMR and GC–MS data sets. It is therefore our recommendation that vast scaling is the primary pre-treatment method to use as this method appears to be more stable and robust across all the different classifiers that were conducted in this study. © 2014, Springer Science+Business Media New York.","Chemometrics; Classification accuracy; Metabolomics; Pre-treatment; Scaling","Springer New York LLC"
"Bandaru S., Aslam T., Ng A.H.C., Deb K.","Generalized higher-level automated innovization with application to inventory management",2015,"European Journal of Operational Research",11,"10.1016/j.ejor.2014.11.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923494070&doi=10.1016%2fj.ejor.2014.11.015&partnerID=40&md5=f05fc33db8c0b5d2b27579a0bbace877","This paper generalizes the automated innovization framework using genetic programming in the context of higher-level innovization. Automated innovization is an unsupervised machine learning technique that can automatically extract significant mathematical relationships from Pareto-optimal solution sets. These resulting relationships describe the conditions for Pareto-optimality for the multi-objective problem under consideration and can be used by scientists and practitioners as thumb rules to understand the problem better and to innovate new problem solving techniques; hence the name innovization (innovation through optimization). Higher-level innovization involves performing automated innovization on multiple Pareto-optimal solution sets obtained by varying one or more problem parameters. The automated innovization framework was recently updated using genetic programming. We extend this generalization to perform higher-level automated innovization and demonstrate the methodology on a standard two-bar bi-objective truss design problem. The procedure is then applied to a classic case of inventory management with multi-objective optimization performed at both system and process levels. The applicability of automated innovization to this area should motivate its use in other avenues of operational research. © 2014 Elsevier B.V. All rights reserved.","Automated innovization; Genetic programming; Higher-level innovization; Inventory management; Knowledge discovery","Elsevier B.V."
"Ishibashi R., Nascimento C.L., Jr.","MoGFT-I: A Multi-objective Optimization approach for the Cart and Pole control problem",2015,"9th Annual IEEE International Systems Conference, SysCon 2015 - Proceedings",1,"10.1109/SYSCON.2015.7116758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941272105&doi=10.1109%2fSYSCON.2015.7116758&partnerID=40&md5=2b9cae43ed8c8987e21bc52aa21f21fb","In this article a set of well-known computational intelligence techniques such as Decision Trees, Fuzzy Logic, and Multi-objective Optimization Genetic Algorithm are combined to generate a novel hybrid method which is called MoGFT-I: Multi-objective Genetic Fuzzy Rule Based System supported by a Decision Tree with Improved Interpretability. The output of the proposed supervised learning method is a set of Mamdani-type fuzzy systems which are optimized and distributed along a Pareto curve by considering two conflicting attributes: accuracy and interpretability. The MoGFT-I method is then applied to the Cart and Pole control problem such that a set of feedback controller are designed to control this unstable nonlinear dynamical system. © 2015 IEEE.","Fuzzy Controller; Genetic Fuzzy Rule Based System; Interpretability; Knowledge Extraction; Multi-objective Optimization; Pareto-optimal front","Institute of Electrical and Electronics Engineers Inc."
"Yan Y., Giagkiozis I., Fleming P.J.","Improved sampling of decision space for pareto estimation",2015,"GECCO 2015 - Proceedings of the 2015 Genetic and Evolutionary Computation Conference",1,"10.1145/2739480.2754713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963670569&doi=10.1145%2f2739480.2754713&partnerID=40&md5=4ffd1786ab393fbc2f9655dcc90bae49","Pareto Estimation (PE) is a novel method for increasing the density of Pareto optimal solutions across the entire Pareto Front or in a specific region of interest. PE identifies the inverse mapping of Pareto optimal solutions, namely, from objective space to decision space. This identification can be performed using a number of modeling techniques, however, for the sake of simplicity in this work we use a radial basis neural network. In any modeling method, the quality of the resulting model depends heavily on the training samples used. The original version of PE uses the resulting set of Pareto optimal solutions from any multi-objective optimization algorithm and then utilizes this set to identify the aforementioned mapping. However, we argue that this selection may not always be the best possible and propose an alternative scheme to improve the resulting set of Pareto optimal solutions in order to produce higher quality samples for the identification scheme in PE. The proposed approach is integrated with MAEA-gD, and the resulting solutions are used with PE. The results show that the proposed method shows promise, in that there is measurable improvement in the quality of the estimated PE in terms of the coverage and density. © 2015 ACM.","Local search; Machine learning; Metaheuristics; Neural networks; Surrogate model/fitness approximation","Association for Computing Machinery, Inc"
"Zhang T., Georgiopoulos M., Anagnostopoulos G.C.","SPRINT multi-objective model racing",2015,"GECCO 2015 - Proceedings of the 2015 Genetic and Evolutionary Computation Conference",12,"10.1145/2739480.2754791","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963655358&doi=10.1145%2f2739480.2754791&partnerID=40&md5=fef8d44e817d4386d84e10f0165186c7","Multi-objective model selection, which is an important aspect of Machine Learning, refers to the problem of identifying a set of Pareto optimal models from a given ensemble of models. This paper proposes SPRINT-Race, a multiobjective racing algorithm based on the Sequential Probability Ratio Test with an Indifference Zone. In SPRINT-Race, a non-parametric ternary-decision sequential analogue of the sign test is adopted to identify pair-wise dominance and non-dominance relationship. In addition, a Bonferroni approach is employed to control the overall probability of any erroneous decisions. In the fixed confidence setting, SPRINT-Race tries to minimize the computational effort needed to achieve a predefined confidence about the quality of the returned models. The efficiency of SPRINT-Race is analyzed on artificially-constructed multi-objective model selection problems with known ground-truth. Moreover, SPRINT-Race is applied to identifying the Pareto optimal parameter settings of Ant Colony Optimization algorithms in the context of solving Traveling Salesman Problems. The experimental results confirm the advantages of SPRINT-Race for multi-objective model selection. © 2015 Copyright held by the owner/author(s).","Model selection; Multi-objective optimization; Racing algorithm; Sequential Probability Ratio Test","Association for Computing Machinery, Inc"
"Tax N., Bockting S., Hiemstra D.","A cross-benchmark comparison of 87 learning to rank methods",2015,"Information Processing and Management",47,"10.1016/j.ipm.2015.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939800634&doi=10.1016%2fj.ipm.2015.07.002&partnerID=40&md5=250c5664f0dc370a24cf767483392b90","Learning to rank is an increasingly important scientific field that comprises the use of machine learning for the ranking task. New learning to rank methods are generally evaluated on benchmark test collections. However, comparison of learning to rank methods based on evaluation results is hindered by the absence of a standard set of evaluation benchmark collections. In this paper we propose a way to compare learning to rank methods based on a sparse set of evaluation results on a set of benchmark datasets. Our comparison methodology consists of two components: (1) Normalized Winning Number, which gives insight in the ranking accuracy of the learning to rank method, and (2) Ideal Winning Number, which gives insight in the degree of certainty concerning its ranking accuracy. Evaluation results of 87 learning to rank methods on 20 well-known benchmark datasets are collected through a structured literature search. ListNet, SmoothRank, FenchelRank, FSMRank, LRUF and LARF are Pareto optimal learning to rank methods in the Normalized Winning Number and Ideal Winning Number dimensions, listed in increasing order of Normalized Winning Number and decreasing order of Ideal Winning Number. © 2015 Elsevier Ltd. All rights reserved.","Evaluation metric; Information retrieval; Learning to rank","Elsevier Ltd"
"Ma H., Su S., Simon D., Fei M.","Ensemble multi-objective biogeography-based optimization with application to automated warehouse scheduling",2015,"Engineering Applications of Artificial Intelligence",52,"10.1016/j.engappai.2015.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940030290&doi=10.1016%2fj.engappai.2015.05.009&partnerID=40&md5=d1c25e01bc2c0d9eb9c27bba407c221c","This paper proposes an ensemble multi-objective biogeography-based optimization (EMBBO) algorithm, which is inspired by ensemble learning, to solve the automated warehouse scheduling problem. First, a real-world automated warehouse scheduling problem is formulated as a constrained multi-objective optimization problem. Then EMBBO is formulated as a combination of several multi-objective biogeography-based optimization (MBBO) algorithms, including vector evaluated biogeography-based optimization (VEBBO), non-dominated sorting biogeography-based optimization (NSBBO), and niched Pareto biogeography-based optimization (NPBBO). Performance is tested on a set of 10 unconstrained multi-objective benchmark functions and 10 constrained multi-objective benchmark functions from the 2009 Congress on Evolutionary Computation (CEC), and compared with single constituent MBBO and CEC competition algorithms. Results show that EMBBO is better than its constituent algorithms, and among the best CEC competition algorithms, for the benchmark functions studied in this paper. Finally, EMBBO is successfully applied to the automated warehouse scheduling problem, and the results show that EMBBO is a competitive algorithm for automated warehouse scheduling. © 2015 Elsevier Ltd.","Automated warehousing; Multi-objective optimization; Performance analysis; Simulation; Travel time analysis","Elsevier Ltd"
"Utkin L.V., Chekh A.I.","A new robust model of one-class classification by interval-valued training data using the triangular kernel",2015,"Neural Networks",10,"10.1016/j.neunet.2015.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936131635&doi=10.1016%2fj.neunet.2015.05.004&partnerID=40&md5=84574953f7cee91bb368c6de2f670d8c","A robust one-class classification model as an extension of Campbell and Bennett's (C-B) novelty detection model on the case of interval-valued training data is proposed in the paper. It is shown that the dual optimization problem to a linear program in the C-B model has a nice property allowing to represent it as a set of simple linear programs. It is proposed also to replace the Gaussian kernel in the obtained linear support vector machines by the well-known triangular kernel which can be regarded as an approximation of the Gaussian kernel. This replacement allows us to get a finite set of simple linear optimization problems for dealing with interval-valued data. Numerical experiments with synthetic and real data illustrate performance of the proposed model. © 2015 Elsevier Ltd.","Extreme points; Interval-valued data; Kernel; Linear programming; Minimax strategy; Novelty detection; One-class classification; Support vector machine","Elsevier Ltd"
"Rabbi M., Aung M.H., Zhang M., Choudhury T.","MyBehavior: Automatic personalized health feedback from user behaviors and preferences using smartphones",2015,"UbiComp 2015 - Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing",118,"10.1145/2750858.2805840","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960916058&doi=10.1145%2f2750858.2805840&partnerID=40&md5=a4d90014b971171dd9c58398724baf22","Mobile sensing systems have made significant advances in tracking human behavior. However, the development of personalized mobile health feedback systems is still in its infancy. This paper introduces MyBehavior, a smartphone application that takes a novel approach to generate deeply personalized health feedback. It combines state-of-The-Art behavior tracking with algorithms that are used in recommendation systems. MyBehavior automatically learns a user's physical activity and dietary behavior and strategically suggests changes to those behaviors for a healthier lifestyle. The system uses a sequential decision making algorithm, Multiarmed Bandit, to generate suggestions that maximize calorie loss and are easy for the user to adopt. In addition, the system takes into account user's preferences to encourage adoption using the pareto-frontier algorithm. In a 14-week study, results show statistically significant increases in physical activity and decreases in food calorie when using MyBehavior compared to a control condition. Copyright © 2015 ACM.","Health Feedback; Machine learning; Mobile Health; Mobile Phone Sensing","Association for Computing Machinery, Inc"
"Samui P., Kim D., Hariharan R.","Determination of seismic liquefaction potential of soil based on strain energy concept",2015,"Environmental Earth Sciences",6,"10.1007/s12665-015-4567-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941178329&doi=10.1007%2fs12665-015-4567-4&partnerID=40&md5=c429c4b66d8f91d12b8b1adc2d0b0112","In the present study, minimax probability machine regression (MPMR) and extreme learning machine (ELM) have been adopted for prediction of seismic liquefaction of soil based on strain energy. Initial effective mean confining pressure (σ′mean), initial relative density after consolidation (Dr), percentage of fines content (FC), coefficient of uniformity (Cu), and mean grain size (D50) have been taken as inputs of MPMR and ELM models. MPMR and ELM have been used as regression techniques. The performances of MPMR and ELM have been compared with the artificial neural network. A sensitivity analysis has been carried out to determine the effect of each input. The experimental results demonstrate that proposed methods are robust models for determination seismic liquefaction potential of soil based on strain energy. © 2015, Springer-Verlag Berlin Heidelberg.","Extreme learning machine; Liquefaction; Minimax probability machine regression; Strain energy","Springer Verlag"
"Outin E., Dartois J.-E., Barais O., Pazat J.-L.","Enhancing Cloud Energy Models for Optimizing Datacenters Efficiency",2015,"Proceedings - 2015 International Conference on Cloud and Autonomic Computing, ICCAC 2015",9,"10.1109/ICCAC.2015.10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962070970&doi=10.1109%2fICCAC.2015.10&partnerID=40&md5=89145700c43c6d46b7eadab977f470aa","Due to high electricity consumption in the Cloud datacenters, providers aim at maximizing energy efficiency through VM consolidation, accurate resource allocation or adjusting VM usage. More generally, the provider attempts to optimize resource utilization. However, while minimizing expenses, the Cloud operator still needs to conform to SLA constraints negotiated with customers (such as latency, downtime, affinity, placement, response time or duplication). Consequently, optimizing a Cloud configuration is a multi-objective problem. As a nontrivial multi-objective optimization problem, there does not exist a single solution that simultaneously optimizes each objective. There exists a (possibly infinite) number of Pareto optimal solutions. Evolutionary algorithms are popular approaches for generating Pareto optimal solutions to a multi-objective optimization problem. Most of these solutions use a fitness function to assess the quality of the candidates. However, regarding the energy consumption estimation, the fitness function can be approximative and lead to some imprecisions compared to the real observed data. This paper presents a system that uses a genetic algorithm to optimize Cloud energy consumption and machine learning techniques to improve the fitness function regarding a real distributed cluster of server. We have carried out experiments on the OpenStack platform to validate our solution. This experimentation shows that the machine learning produces an accurate energy model, predicting precise values for the simulation. © 2015 IEEE.","Cloud computing; energy efficiency; model","Institute of Electrical and Electronics Engineers Inc."
"Sikdar U.K., Ekbal A., Saha S.","MODE: multiobjective differential evolution for feature selection and classifier ensemble",2015,"Soft Computing",23,"10.1007/s00500-014-1565-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947080353&doi=10.1007%2fs00500-014-1565-5&partnerID=40&md5=53ced3ec2144c9b0a6b4a8f1bcee2c63","In this paper, we propose a multiobjective differential evolution (MODE)-based feature selection and ensemble learning approaches for entity extraction in biomedical texts. The first step of the algorithm concerns with the problem of automatic feature selection in a machine learning framework, namely conditional random field. The final Pareto optimal front which is obtained as an output of the feature selection module contains a set of solutions, each of which represents a particular feature representation. In the second step of our algorithm, we combine a subset of these classifiers using a MODE-based ensemble technique. Our experiments on three benchmark datasets namely GENIA, GENETAG and AIMed show the F-measure values of 76.75, 94.15 and 91.91 %, respectively. Comparisons with the existing systems show that our proposed algorithm achieves the performance levels which are at par with the state of the art. These results also exhibit that our method is general in nature and because of this it performs well across the several domain of datasets. The key contribution of this work is the development of MODE-based generalized feature selection and ensemble learning techniques with the aim of extracting entities from the biomedical texts of several domains. © 2015, Springer-Verlag Berlin Heidelberg.",,"Springer Verlag"
"Mousavi R., Eftekhari M.","A new ensemble learning methodology based on hybridization of classifier ensemble selection approaches",2015,"Applied Soft Computing Journal",43,"10.1016/j.asoc.2015.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942420474&doi=10.1016%2fj.asoc.2015.09.009&partnerID=40&md5=f169826489409fdb9c6c3f0f4c784a83","Ensemble learning is a system that improves the performance and robustness of the classification problems. How to combine the outputs of base classifiers is one of the fundamental challenges in ensemble learning systems. In this paper, an optimized Static Ensemble Selection (SES) approach is first proposed on the basis of NSGA-II multi-objective genetic algorithm (called SES-NSGAII), which selects the best classifiers along with their combiner, by simultaneous optimization of error and diversity objectives. In the second phase, the Dynamic Ensemble Selection-Performance (DES-P) is improved by utilizing the first proposed method. The second proposed method is a hybrid methodology that exploits the abilities of both SES and DES approaches and is named Improved DES-P (IDES-P). Accordingly, combining static and dynamic ensemble strategies as well as utilizing NSGA-II are the main contributions of this research. Findings of the present study confirm that the proposed methods outperform the other ensemble approaches over 14 datasets in terms of classification accuracy. Furthermore, the experimental results are described from the view point of Pareto front with the aim of illustrating the relationship between diversity and the over-fitting problem. © 2015 Elsevier B.V. All rights reserved.","Classifier combination; Classifier diversity; Dynamic ensemble selection; Ensemble learning system; Multi-objective optimization; Static ensemble selection","Elsevier Ltd"
"Edwards H., Storkey A.","Censoring representations with an adversary",2016,"4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings",78,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951030&partnerID=40&md5=5b4928ce909cceed161b854af7eefe9f","In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from separate training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model. © ICLR 2016: San Juan, Puerto Rico. All Rights Reserved.",,"International Conference on Learning Representations, ICLR"
"Yi X., Wang Z., Yang Z., Caramanis C., Liu H.","More supervision, less computation: Statistical-computational tradeoffs in weakly supervised learning",2016,"Advances in Neural Information Processing Systems",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019231342&partnerID=40&md5=51aa247eb27640df0b743ca82d3a4bd9","We consider the weakly supervised binary classification problem where the labels are randomly flipped with probability 1 - α. Although there exist numerous algorithms for this problem, it remains theoretically unexplored how the statistical accuracies and computational efficiency of these algorithms depend on the degree of supervision, which is quantified by α. In this paper, we characterize the effect of α by establishing the information-theoretic and computational boundaries, namely, the minimax-optimal statistical accuracy that can be achieved by all algorithms, and polynomial-time algorithms under an oracle computational model. For small α, our result shows a gap between these two boundaries, which represents the computational price of achieving the information-theoretic boundary due to the lack of supervision. Interestingly, we also show that this gap narrows as α increases. In other words, having more supervision, i.e., more correct labels, not only improves the optimal statistical accuracy as expected, but also enhances the computational efficiency for achieving such accuracy. © 2016 NIPS Foundation - All Rights Reserved.",,"Neural information processing systems foundation"
"Farnia F., Tse D.","A minimax approach to supervised learning",2016,"Advances in Neural Information Processing Systems",29,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019212301&partnerID=40&md5=9bae4acd76996964299db89aa9e6c4d7","Given a task of predicting Y from X, a loss function L, and a set of probability distributions Γ on [X, Y), what is the optimal decision rule minimizing the worst-case expected loss over r? In this paper, we address this question by introducing a generalization of the maximum entropy principle. Applying this principle to sets of distributions with marginal on X constrained to be the empirical marginal, we provide a minimax interpretation of the maximum likelihood problem over generalized linear models as well as some popular regularization schemes. For quadratic and logarithmic loss functions we revisit well-known linear and logistic regression models. Moreover, for the 0-1 loss we derive a classifier which we call the minimax SVM. The minimax SVM minimizes the worst-case expected 0-1 loss over the proposed Γ by solving a tractable optimization problem. We perform several numerical experiments to show the power of the minimax SVM in outperforming the SVM. © 2016 NIPS Foundation - All Rights Reserved.",,"Neural information processing systems foundation"
"Tolstikhin I., Sriperumbudur B.K., Schölkopf B.","Minimax estimation of maximum mean discrepancy with radial kernels",2016,"Advances in Neural Information Processing Systems",20,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019172607&partnerID=40&md5=e846a6e410602003ac3356c994abdb9c","Maximum Mean Discrepancy (MMD) is a distance on the space of probability measures which has found numerous applications in machine learning and nonpara-metric testing. This distance is based on the notion of embedding probabilities in a reproducing kernel Hilbert space. In this paper, we present the first known lower bounds for the estimation of MMD based on finite samples. Our lower bounds hold for any radial universal kernel on Rd and match the existing upper bounds up to constants that depend only on the properties of the kernel. Using these lower bounds, we establish the minimax rate optimality of the empirical estimator and its U-statistic variant, which are usually employed in applications. © 2016 NIPS Foundation - All Rights Reserved.",,"Neural information processing systems foundation"
"Chen S., Varma R., Singh A., Kovacevic J.","Signal recovery on graphs: Fundamental limits of sampling strategies",2016,"IEEE Transactions on Signal and Information Processing over Networks",70,"10.1109/TSIPN.2016.2614903","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017587018&doi=10.1109%2fTSIPN.2016.2614903&partnerID=40&md5=92c79faf3bfac240bfed8b2594860298","This paper builds theoretical foundations for the recovery of a newly proposed class of smooth graph signals, approximately bandlimited graph signals, under three sampling strategies: uniform sampling, experimentally designed sampling, and active sampling. We then state minimax lower bounds on the maximum risk for the approximately bandlimited class under these three sampling strategies and show that active sampling cannot fundamentally outperform experimentally designed sampling. We propose a recovery strategy to compare uniform sampling with experimentally designed sampling. As the proposed recovery strategy lends itself well to statistical analysis, we derive the exact mean square error for each sampling strategy. To study convergence rates, we introduce two types of graphs and find that 1) the proposed recovery strategy achieves the optimal rates; and 2) the experimentally designed sampling fundamentally outperforms uniform sampling for Type-2 class of graphs. To validate our proposed recovery strategy, we test it on five specific graphs: a ring graph with k nearest neighbors, an Erd's-Rényi graph, a random geometric graph, a small-world graph, and a power-law graph and find that experimental results match the proposed theory well. This paper also presents a comprehensive explanation for when and why sampling for semi-supervised learning with graphs works. © 2015 IEEE.","Active sampling; experimentally designed sampling; semi-supervised learning; signal processing on graphs; signal recovery","Institute of Electrical and Electronics Engineers Inc."
"Zeliff K., Bennette W., Ferguson S.","Multi-objective composite panel optimization using machine learning classifiers and genetic algorithms",2016,"Proceedings of the ASME Design Engineering Technical Conference",2,"10.1115/DETC2016-60125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008204119&doi=10.1115%2fDETC2016-60125&partnerID=40&md5=65162ad3b43ac68f5ac1760369c31f9f","Design spaces that consist of millions or billions of design combinations pose a challenge to current methods for identifying optimal solutions. Complex analyses can also lead to lengthy computation times that further challenge the effectiveness of an algorithm in terms of solution quality and run-time. This work explores combining the design space exploration approach of a Multi-Objective Genetic Algorithm with different instance-based, statistical, rule-based and ensemble classifiers to reduce the number of unnecessary function evaluations associated with poorly performing designs. Results indicate that introducing a classifier to identify child designs that are likely to push the Pareto frontier toward an optima reduce the number of function calculations by 75-85%, depending on the classifier implemented. © Copyright 2016 by ASME.",,"American Society of Mechanical Engineers (ASME)"
"Li Y.-F., Kwok J.T., Zhou Z.-H.","Towards safe semi-supervised learning for multivariate performance measures",2016,"30th AAAI Conference on Artificial Intelligence, AAAI 2016",24,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007211682&partnerID=40&md5=16ff34e655f8da6fb713c55fde523d4b","Semi-supervised learning (SSL) is an important research problem in machine learning. While it is usually expected that the use of unlabeled data can improve performance, in many cases SSL is outperformed by supervised learning using only labeled data. To this end, the construction of a performance-safe SSL method has become a key issue of SSL study. To alleviate this problem, we propose in this paper the UMVP (safe semi-sUpervised learning for Multi- Variate Performance measure) method, because of the need of various performance measures in practical tasks. The proposed method integrates multiple semi-supervised learners, and maximizes the worst-case performance gain to derive the final prediction. The overall problem is formulated as a maximin optimization. In oder to solve the resultant difficult maximin optimization, this paper shows that when the performance measure is the Top-k Precision, Fβ score or AUC, a minimax convex relaxation of the maximin optimization can be solved efficiently. Experimental results show that the proposed method can effectively improve the safeness of SSL under multiple multivariate performance measures. © Copyright 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"AAAI press"
"Trafalis T.B., Santosa B., Richman M.B.","Tornado detection with Kernel-based classifiers from WSR-88D radar data",2016,"Springer Proceedings in Mathematics and Statistics",2,"10.1007/978-3-319-43709-5_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006043192&doi=10.1007%2f978-3-319-43709-5_16&partnerID=40&md5=b619ea11308d5092f54c27843967dd69","Detection of tornadoes that provides warning times sufficient for evasive action prior to a tornado strike has been a well-established objective of weather forecasters. With modern technology, progress has been made on increasing the average lead time of such warnings, which translates into a number of lives saved. Recently, machine learning (e.g., kernel methods) has been added to the collection of techniques brought to bear on severe weather prediction. In this chapter, we seek to extend this innovation by introducing and applying two types of kernel-based methods, support vector machines and minimax probability machines to detect tornadoes, using attributes from radar derived velocity data. These two approaches utilize kernel methods to address nonlinearity of the data in the input space. The approaches are based on maximizing the margin between two different classes: tornado and no tornado. The use of the Weather Surveillance Radar 1988 Doppler, with continuous data streaming every 6min, presents a source for a dynamic data driven application system. The results are compared to those produced by neural networks (NN). Findings indicate that these kernel approaches are significantly more accurate than NN for the tornado detection problem. © Springer International Publishing Switzerland 2016.","Dynamic data driven application; Feedforward neural networks; Generalization error; Kernel methods; Tornado detection","Springer New York LLC"
"Kostuik K., Mu Y., El-Beltagy M., Naiem A.","Visualizing portfolio tradeoffs with perceptually accurate self-organizing maps",2016,"Proceedings - SPE Annual Technical Conference and Exhibition",,"10.2118/181632-ms","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994102555&doi=10.2118%2f181632-ms&partnerID=40&md5=953636d32357c79766c3604fa0fb68eb","Multi-objective optimization and unsupervised machine learning were used to visualize relationships between portfolio composition and business performance tradeoffs. A multiobjective global optimization algorithm reduced the exponentially large space of possible portfolio outcomes to a set of Pareto optimal tradeoff frontiers for various combinations of decision and outcome constraints. The high-dimensional decision space was then reduced with an unsupervised neural network to generate Kohonen self-organizing maps (SOMs) for each tradeoff frontier. The resulting decision SOMs were rendered with a perceptually accurate color map and interactively linked with the tradeoff frontiers to enable visual data mining. The interactive visualization revealed relationships between planning decisions and business outcomes in the complex and high-dimensional decision space. The interactive SOM automatically classifies similar strategies together and shows how neighboring strategies relate to each other. The analysis demonstrated that the proximity of portfolios on the tradeoff frontier does not imply similarity of underlying portfolio decisions, and that the mapping between decisions and outcomes becomes more complex with stricter constraints. Copyright 2016, Society of Petroleum Engineers.",,"Society of Petroleum Engineers (SPE)"
"Urbanowicz R.J., Olson R.S., Moore J.H.","Pareto inspired multi-objective rule fitness for noise-adaptive rule-based machine learning",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/978-3-319-45823-6_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988499856&doi=10.1007%2f978-3-319-45823-6_48&partnerID=40&md5=87134ee39e26b401558770ae4ca48ef5","Learning classifier systems (LCSs) are rule-based evolutionary algorithms uniquely suited to classification and data mining in complex, multi-factorial, and heterogeneous problems. The fitness of individual LCS rules is commonly based on accuracy, but this metric alone is not ideal for assessing global rule ‘value’ in noisy problem domains and thus impedes effective knowledge extraction. Multi-objective fitness functions are promising but rely on prior knowledge of how to weigh objective importance (typically unavailable in real world problems). The Pareto-front concept offers a multi-objective strategy that is agnostic to objective importance. We propose a Pareto-inspired multi-objective rule fitness (PIMORF) for LCS, and combine it with a complimentary rule-compaction approach (SRC). We implemented these strategies in ExSTraCS, a successful supervised LCS and evaluated performance over an array of complex simulated noisy and clean problems (i.e. genetic and multiplexer) that each concurrently model pure interaction effects and heterogeneity. While evaluation over multiple performance metrics yielded mixed results, this work represents an important first step towards efficiently learning complex problem spaces without the advantage of prior problem knowledge. Overall the results suggest that PIMORF paired with SRC improved rule set interpretability, particularly with regard to heterogeneous patterns. © Springer International Publishing AG 2016.","Classifier systems; Data mining; Fitness evaluation; Machine learning; Multi-objective optimization","Springer Verlag"
"Horn D., Schork K., Wagner T.","Multi-objective selection of algorithm portfolios: Experimental validation",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-319-45823-6_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988484726&doi=10.1007%2f978-3-319-45823-6_39&partnerID=40&md5=2d8db0f27efebed9cc40dbced4cc2719","The selection of algorithms to build portfolios represents a multi-objective problem. From a possibly large pool of algorithm candidates, a portfolio of limited size but good quality over a wide range of problems is desired. Possible applications can be found in the context of machine learning, where the accuracy and runtime of different learning techniques must be weighed. Each algorithm is represented by its Pareto front, which has been approximated in an a priori parameter tuning. Our approach for multi-objective selection of algorithm portfolios (MOSAP) is capable to trade-off the number of algorithm candidates and the respective quality of the portfolio. The quality of the portfolio is defined as the distance to the joint Pareto front of all algorithm candidates. By means of a decision tree, also the selection of the right algorithm is possible based on the characteristics of the problem. In this paper, we propose a validation framework to analyze the performance of our MOSAP approach. This framework is based on a parametrized generator of the algorithm candidate’s Pareto front shapes. We discuss how to sample a landscape of multiple Pareto fronts with predefined intersections. The validation is performed by calculating discrete approximations for different landscapes and assessing the effect of the landscape parameters on the MOSAP approach. © Springer International Publishing AG 2016.","Algorithm selection; Benchmarking; Multi-objective optimization; Performance assessment","Springer Verlag"
"Hayashi Y., Bologna G., Hashiguchi R.","Accuracies and number of rules extracted using the Re-RX algorithm family from a pareto-optimal perspective",2016,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988336194&partnerID=40&md5=6f19f636d6179bb742bcd1a8ec0a070e","The Recursive-Rule eXtraction (Re-RX) algorithm family includes the Re-RX algorithm, the Re-RX algorithm with both discrete and continuous attributes (Continuous Re-RX [1]), the Re-RX algorithm with J48graft [2], Re-RX with J48graft combined with Sampling Selection Techniques (Sampling Re-RX with J48graft [4]), and the Re-RX algorithm with a trained neural network (Sampling Re-RX [3]). In this study, we compare the performance of the Re-RX algorithm family with various previous algorithms. One issue that always remains important in rule extraction is Pareto optimality, or in other words, an ideally balanced trade-off. In rule extraction, the trade-off is between the classification accuracy and interpretability of extracted rules. Our goal is to obtain a wider viable region for the Pareto optimal curve that will enable improvements in both the accuracy and interpretability of extracted rules. We vividly demonstrate Pareto-optimal curves between the accuracies and number of rules obtained for German and Australian datasets by 10 runs of 10-fold cross validation of the Re-RX algorithm family and those obtained using other algorithms. The Re-RX algorithm family has proven effective for extracting concise and interpretable rules from medical [1, 2, 4] and financial [3] datasets. © Springer International Publishing Switzerland 2016.",,"Springer Verlag"
"Sebastiani R., Trentin P.","On the benefits of enhancing optimization modulo theories with sorting networks for maxsmt",2016,"CEUR Workshop Proceedings",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984824806&partnerID=40&md5=b492054cc0cdcae7f99c04db5f578aa0","Optimization Modulo Theories (OMT) is an extension of SMT, which combines SMT with optimization, finding models that make given objectives optimal. OMT has been extended to be incremental and to handle multiple objective functions either independently or with their linear, lexicographic, Pareto, min-max/max-min combinations. OMT applications can be found not only in the domains of Formal Verification, Automated Reasoning and Planning with Resources, but also Machine Learning and Requirement Engineering. (Partial weighted) MAXSMT-or, alternatively, OMT with Pseudo-Boolean objective functions- is a very-relevant subcase of OMT. Unfortunately, using general OMT algorithm for MAXSMT suffers from some intrinsic inefficiencies in some cases. In this paper we identify the sources of such inefficiencies and address them by enhancing general OMT by means of sorting networks. We implemented this idea on top of the OPTIMATHSAT OMT solver and evaluated them empirically on problems coming from Machine Learning and Requirement Engineering. The empirical results support the effectiveness of this idea.",,"CEUR-WS"
"Ogutcen O.F., Gormez Z., Tahir M.A., Seker H.","An aggregated cross-validation framework for computational discovery of disease-associative genes",2016,"IFMBE Proceedings",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968649092&partnerID=40&md5=f0aef69cf9980bd1e3646dfe1aab7cde","Numerous computational techniques have been applied to identify vital features of gene expression datasets that aim to increase efficiency of biomedical applications. Classification of samples is an important task to correctly recognize diseased people by identifying small but clinically meaningful genes. Conversely, it is a challenging issue for machine learning algorithms. In this paper, we apply a two-stage feature selection approach by using ensemble filter methods and Pareto Optimality. Although filter methods provide ranked lists of all features, they do not give any information about required (optimum) subset sizes of the features, namely, genes in this study. In order to address this issue, PO is incorporated with filter methods. The main aim of this study is therefore to develop a robust framework with PO, multiple feature selection methods and crossvalidated subsets of the samples, which is also applicable to not only similar datasets but also different feature selection methods. The robustness of the framework has been successfully demonstrated over three well-known microarray gene expression data sets. The framework has been shown to yield equal or higher predictive accuracy with comparatively smaller feature sizes. Furthermore, the cross-validation and data variation approaches are considered in the framework. Consequently, the framework reduces the over-fitting problem and is observed to have made the gene selection more stable on different conditions. © Springer International Publishing Switzerland 2016.","Ensemble feature selection; K-nearest neighbour classifier; Pareto optimality; Statistical feature selection","Springer Verlag"
"Mane S., Sonawani S., Sakhare S.","Hybrid multi-objective optimization approach for neural network classification using local search",2016,"Advances in Intelligent Systems and Computing",2,"10.1007/978-981-10-0419-3_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961219458&doi=10.1007%2f978-981-10-0419-3_21&partnerID=40&md5=69dc155896dc52a6e50da76ff4fab3c3","Classification is inherently multi-objective problem. It is one of the most important tasks of data mining to extract important patterns from large volume of data. Traditionally, either only one objective is considered or the multiple objectives are accumulated to one objective function. In the last decade, Pareto-based multi-objective optimization approach have gained increasing popularity due to the use of multi-objective optimization using evolutionary algorithms and population-based search methods. Multi-objective optimization approaches are more powerful than traditional single-objective methods as it addresses various topics of data mining such as classification, clustering, feature selection, ensemble learning, etc. This paper proposes improved approach of non-dominated sorting algorithm II (NSGA II) for classification using neural network model by augmenting with local search. It tries to enhance two conflicting objectives of classifier: Accuracy and mean squared error. NSGA II is improved by augmenting backpropagation as a local search method to deal with the disadvantage of genetic algorithm, i.e. slow convergence to best solutions. By using backpropagation we are able to speed up the convergence. This approach is applied in various classification problems obtained from UCI repository. The neural network modes obtained shows high accuracy and low mean squared error. © Springer Science+Business Media Singapore 2016.","Classificationm; Local search; Multi-objective optimization; Neural network; NSGA II; Pareto optimality","Springer Verlag"
"Basterrech S., Ohnishi K., Koppen M.","Neural Signature of Efficiency Relations",2016,"Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015",,"10.1109/SMC.2015.365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964507182&doi=10.1109%2fSMC.2015.365&partnerID=40&md5=f60968f7a4483a0c9813af73c49d5999","In last years-especially due to the development of telecommunications-fairness modelling has received a strong attention. This article presents an approach for categorizing unknown relations according to their closeness to known relations. We consider as reference relations, the well-known: Pareto dominance, Leximin and Proportional fairness relation. We simulate each relation generating a learning dataset that is used for learning Neural Networks. The learning performance evaluation is based in several metrics, which are used as a signature of each relation. Besides, we develop a new function that gives an estimation about the closeness between relations. This concept permits us to categorise a new dataset (generated by an unknown relation) according its closeness with the Pareto dominance, Leximin and Proportional fairness relations know relations. Our experimental results are coherent with the alpha fairness concept. © 2015 IEEE.","Fairness; Maxmin Fairness; Neural Networks; Priority Fairness; Supervised Learning","Institute of Electrical and Electronics Engineers Inc."
"Shrivastava N.A., Lohia K., Panigrahi B.K.","A multiobjective framework for wind speed prediction interval forecasts",2016,"Renewable Energy",53,"10.1016/j.renene.2015.08.038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940704970&doi=10.1016%2fj.renene.2015.08.038&partnerID=40&md5=79c6be5d6ff7ffd7575b7dcef0481d9e","Wind energy is rapidly emerging as a potential and viable replacement for fossil fuels owing to its clean way of power production. However, integration of this abundantly available renewable energy into the power system is constrained by its intermittent nature and unpredictability. Efforts to improve the prediction accuracy of wind speed is therefore imperative for its successful integration into the grid. The uncertainty associated with the prediction is also an important information needed by the system operators for reliable and economic operations. This paper presents the implementation of a multi-objective differential evolution (MODE) algorithm for generation of prediction intervals (PIs) for capturing the uncertainty related to forecasts. Support vector machine (SVM) is used as the machine learning technique and its parameters are tuned such that multiple contradictory objectives are satisfied to generate Pareto-optimal solutions. Several case studies are performed for data from wind farms located in the eastern region of United States. The obtained results prove the successful implementation of the methodology and generation of high quality PIs. © 2015 Elsevier Ltd.","Differential evolution; Multi-objective; Prediction interval; Renewable energy; Support vector machines; Wind speed","Elsevier Ltd"
"Mehdiyev N., Krumeich J., Werth D., Loos P.","Determination of event patterns for complex event processing using fuzzy unordered rule induction algorithm with multi-objective evolutionary feature subset selection",2016,"Proceedings of the Annual Hawaii International Conference on System Sciences",10,"10.1109/HICSS.2016.216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975465966&doi=10.1109%2fHICSS.2016.216&partnerID=40&md5=6d08468aced7dbf1d0f20eeb03474574","Complex Event Processing (CEP) is an emerging technology to process streaming data and to generate response actions in real time. CEP systems treat all sensor data as primitive events and attempt to detect semantically high level events and related actions by matching them using event patterns. These event patterns are the rules which combine primitive events according to temporal, logical, or spatial correlations among them. Although event patterns (decision rules) can be provided by experts in simplistic scenarios, the huge amount of sensor data makes this unfeasible. The main purpose of the underlying paper is replacing manual identification of event patterns. Considering the uncertainty related to the sensor data, Fuzzy Unordered Rule Induction Algorithm (FURIA) was implemented to identify event patterns after selecting the relevant feature subset using Elitist Pareto-based Multi-Objective Evolutionary Algorithm for Diversity Reinforcement (ENORA). The results were compared to the alternative machine learning approaches. © 2016 IEEE.",,"IEEE Computer Society"
"Tatar K., Macret M., Pasquier P.","Automatic Synthesizer Preset Generation with PresetGen",2016,"Journal of New Music Research",9,"10.1080/09298215.2016.1175481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965062862&doi=10.1080%2f09298215.2016.1175481&partnerID=40&md5=64b20c6e96491dd280a76101560fb78d","We refer the task of finding preset(s) (i.e. set(s) of synthesizer parameters) that approximates a target sound best, as the preset generation problem. PresetGen addresses this problem regarding the real world synthesizer, OP-1. The OP-1 consists of several synthesis blocks, and it is not fully deterministic. We propose and evaluate a solution to preset generation using a multi-objective Non-dominated Sorting-Genetic-Algorithm-II. PresetGen handles the full problem complexity and returns a small set of presets that approximate the target sound best by covering the Pareto front of this multi-objective optimization problem. Moreover, we present an empirical evaluation experiment that compares the performance of three human sound designers to that of PresetGen. The results show that PresetGen is human-competitive. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","audio analysis; instruments; machine learning; sound synthesis","Taylor and Francis Ltd."
"Meng P., Althoff A., Gautier Q., Kastner R.","Adaptive Threshold Non-Pareto Elimination: Re-thinking machine learning for system level design space exploration on FPGAs",2016,"Proceedings of the 2016 Design, Automation and Test in Europe Conference and Exhibition, DATE 2016",32,"10.3850/9783981537079_0350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973606577&doi=10.3850%2f9783981537079_0350&partnerID=40&md5=36661b5232f442edcd27d25b05001cb3","One major bottleneck of the system level OpenCL-to-FPGA design tools is their extremely time consuming synthesis process (including place and route). The design space for a typical OpenCL application contains thousands of possible designs even when considering a small number of design space parameters. It costs months of compute time to synthesize all these possible designs into end-to-end FPGA implementations. Thus, the brute force design space exploration (DSE) is impractical for these design tools. Machine learning is one solution that identifies the valuable Pareto designs by sampling only a small portion of the entire design space. However, most of the existing machine learning frameworks focus on improving the design objective regression accuracy, which is not necessarily suitable for the FPGA DSE task. To address this issue, we propose a novel strategy - Adaptive Threshold Non-Pareto Elimination (ATNE). Instead of focusing on regression accuracy improvement, ATNE focuses on understanding and estimating the inaccuracy. ATNE provides a Pareto identification threshold that adapts to the estimated inaccuracy of the regressor. This adaptive threshold results in a more efficient DSE. For the same prediction quality, ATNE reduces the synthesis complexity by 1.6 - 2.89× (hundreds of synthesis hours) against the other state of the art frameworks for FPGA DSE. In addition, ATNE is capable of identifying the Pareto designs for certain difficult design spaces which the other existing frameworks are incapable of exploring effectively. © 2016 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Persello C., Bruzzone L.","Kernel-Based Domain-Invariant Feature Selection in Hyperspectral Images for Transfer Learning",2016,"IEEE Transactions on Geoscience and Remote Sensing",81,"10.1109/TGRS.2015.2503885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951310856&doi=10.1109%2fTGRS.2015.2503885&partnerID=40&md5=151e5db47eb8879082347a58d2c2382f","This paper presents a kernel-based feature selection method for the classification of hyperspectral images. The proposed method aims at selecting a subset of the original features that are both 1) relevant (discriminant) for the considered classification problem, i.e., preserve the functional relationship between input and output variables, and 2) invariant (stable) across different domains, i.e., minimize the data-set shift between the source and the target domains. Domains can be associated with hyperspectral images collected either on different geographical areas or on the same area at different times. We propose a novel measure of data-set shift for evaluating the domain stability, which computes the distance of the conditional distributions between the source and target domains in a reproducing kernel Hilbert space. Such a measure is defined on the basis of the kernel embeddings of the conditional distributions resulting in a nonparametric approach that does not require estimating the distribution of the classes. The adopted search strategy is based on a multiobjective optimization algorithm, which optimizes the two terms of the criterion function for the estimation of the Pareto-optimal solutions. This results in an effective approach of performing feature selection in a transfer learning setting. The experimental results obtained on two hyperspectral images show the effectiveness of the proposed method in selecting features with high generalization capabilities. © 1980-2012 IEEE.","Domain adaptation; feature selection; hyperspectral images; image classification; kernel methods; remote sensing; support vector machines (SVMs); transfer learning","Institute of Electrical and Electronics Engineers Inc."
"Ponce de León P.J., Iñesta J.M., Calvo-Zaragoza J., Rizo D.","Data-based melody generation through multi-objective evolutionary computation",2016,"Journal of Mathematics and Music",7,"10.1080/17459737.2016.1188171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980348010&doi=10.1080%2f17459737.2016.1188171&partnerID=40&md5=65d1270e29d629d3ffbc706ac3c0abfb","Genetic-based composition algorithms are able to explore an immense space of possibilities, but the main difficulty has always been the implementation of the selection process. In this work, sets of melodies are utilized for training a machine learning approach to compute fitness, based on different metrics. The fitness of a candidate is provided by combining the metrics, but their values can range through different orders of magnitude and evolve in different ways, which makes it hard to combine these criteria. In order to solve this problem, a multi-objective fitness approach is proposed, in which the best individuals are those in the Pareto front of the multi-dimensional fitness space. Melodic trees are also proposed as a data structure for chromosomic representation of melodies and genetic operators are adapted to them. Some experiments have been carried out using a graphical interface prototype that allows one to explore the creative capabilities of the proposed system. An Online Supplement is provided and can be accessed at http://dx.doi.org/10.1080/17459737.2016.1188171, where the reader can find some technical details, information about the data used, generated melodies, and additional information about the developed prototype and its performance. © 2016 Informa UK Limited, trading as Taylor & Francis Group.","composition; evolutionary algorithms; machine learning; melody; multi-objective optimization; tree representation","Taylor and Francis Ltd."
"Pham N.K., Kumar A., Aung K.M.M.","Machine learning approach to generate Pareto front for list-scheduling algorithms",2016,"Proceedings of the 19th International Workshop on Software and Compilers for Embedded Systems, SCOPES 2016",3,"10.1145/2906363.2906380","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974573817&doi=10.1145%2f2906363.2906380&partnerID=40&md5=b5054bebebb7de9cca07e8b03c87290c","List Scheduling is one of the most widely used techniques for scheduling due to its simplicity and efficiency. In traditional list-based schedulers, a cost/priority function is used to compute the priority of tasks/jobs and put them in an ordered list. The cost function has been becoming more and more complex to cover increasing number of constraints in the system design. However, most of the existing list-based schedulers implement a static priority function that usually provides only one schedule for each task graph input. Therefore, they may not be able to satisfy the desire of system designers, who want to examine the trade-off between a number of design requirements (performance, power, energy, reliability ...). To address this problem, we propose a framework to utilize the Genetic Algorithm (GA) for exploring the design space and obtaining Pareto-optimal design points. Furthermore, multiple regression techniques are used to build predictive models for the Pareto fronts to limit the execution time of GA. The models are built using training task graph datasets and applied on incoming task graphs. The Pareto fronts for incoming task graphs are produced in time 2 orders of magnitude faster than the traditional GA, with only 4% degradation in the quality. © 2016 ACM.","Design space exploration; List-scheduling; Machine learning","Association for Computing Machinery, Inc"
"Zhu F., Honeine P.","Biobjective Nonnegative Matrix Factorization: Linear Versus Kernel-Based Models",2016,"IEEE Transactions on Geoscience and Remote Sensing",27,"10.1109/TGRS.2016.2535298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979492975&doi=10.1109%2fTGRS.2016.2535298&partnerID=40&md5=7422e943e999c9e908a341aa37361361","Nonnegative matrix factorization (NMF) is a powerful class of feature extraction techniques that has been successfully applied in many fields, particularly in signal and image processing. Current NMF techniques have been limited to a single-objective optimization problem, in either its linear or nonlinear kernel-based formulation. In this paper, we propose to revisit the NMF as a multiobjective problem, particularly a biobjective one, where the objective functions defined in both input and feature spaces are taken into account. By taking the advantage of the sum-weighted method from the literature of multiobjective optimization, the proposed biobjective NMF determines a set of nondominated, Pareto optimal, solutions. Moreover, the corresponding Pareto front is approximated and studied. Experimental results on unmixing synthetic and real hyperspectral images confirm the efficiency of the proposed biobjective NMF compared with the state-of-the-art methods. © 2016 IEEE.","Hyperspectral image; kernel machines; nonnegative matrix factorization (NMF); Pareto optimal; unmixing problem","Institute of Electrical and Electronics Engineers Inc."
"Gaur A., Deb K.","Adaptive use of innovization principles for a faster convergence of evolutionary multi-objective optimization algorithms",2016,"GECCO 2016 Companion - Proceedings of the 2016 Genetic and Evolutionary Computation Conference",8,"10.1145/2908961.2909019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986265061&doi=10.1145%2f2908961.2909019&partnerID=40&md5=89850b19a949a8c199a488dd708a7d4d","""Innovization"" is a task of learning common principles that exist among some or all of the Pareto-optimal solutions of a multi-objective optimization problem. Except a few earlier studies, most innovization related studies were performed on the final non-dominated solutions found by an EMO algorithm. Since the innovization principles are properties of good and near-optimal solutions, an early identification of them can help improve the evolving population to converge quicker to the Pareto-optimal set. This paper advocates the discovery of innovized principles through machine learning methods during an evolutionary multi-objective optimization run and then using these principles to repair the population adaptively to achieve a faster convergence. Implementing this idea with linear regression as the learning tool and applying it in a test problem with power-law rules existing among Pareto-optimal solutions yields encouraging results. The results show not only an improvement in convergence rate but also in the diversity of non-dominated solutions. © 2016 Copyright held by the owner/author(s).","Convergence; Innovization; Multi-objective optimization","Association for Computing Machinery, Inc"
"Olson R.S., Bartley N., Urbanowicz R.J., Moore J.H.","Evaluation of a tree-based pipeline optimization tool for automating data science",2016,"GECCO 2016 - Proceedings of the 2016 Genetic and Evolutionary Computation Conference",208,"10.1145/2908812.2908918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985906105&doi=10.1145%2f2908812.2908918&partnerID=40&md5=f6347a9207730d0977aa657fee8613cb","As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning - pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.","Data science; Genetic programming; Hyperparameter optimization; Machine learning; Pareto optimization; Pipeline optimization; Python","Association for Computing Machinery, Inc"
"Utkin L.V., Popov S.G., Zhuk Y.A.","Robust transfer learning in multi-robot systems by using sparse autoencoder",2016,"Proceedings of the 19th International Conference on Soft Computing and Measurements, SCM 2016",2,"10.1109/SCM.2016.7519735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992079483&doi=10.1109%2fSCM.2016.7519735&partnerID=40&md5=08f08f6f338f99d8e46d36e49efad377","Robust algorithms for transfer learning in multirobot systems based on elements of the deep learning are proposed in the paper. The algorithms are based on using the sparse autoencoder. The main ideas underlying the algorithms are to extend the set of set-valued observations by training examples having uncertain weights and to apply the robust minimax strategy in order to find an optimal autoencoder for dealing with set-valued observations. An interesting scheme for transfer learning is considered for which source learning set is reconstructed by means of the sparse autoencoder trained on the target learning set. © 2016 IEEE.","deep learning; extreme points; minimax strategy; multi-robot system; sparse autoencoder; transfer learning","Institute of Electrical and Electronics Engineers Inc."
"Pal M., Bandyopadhyay S.","Many-objective feature selection for motor imagery EEG signals using differential evolution and support vector machine",2016,"International Conference on Microelectronics, Computing and Communication, MicroCom 2016",17,"10.1109/MicroCom.2016.7522574","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983479641&doi=10.1109%2fMicroCom.2016.7522574&partnerID=40&md5=bdbd2d998b8fcae85e565f28bad7272c","Processing of the movement related task under planning by artificial means provides a means to those people whose natural modality of performing the task is bottlenecked by physical disability or neuro-motor disorders. Electroencephalography (EEG) based Brain-Computer Interfacing (BCI) systems can be defined to be a non-muscular pathway to operate rehabilitative devices using motor imagery signals captured from the motor activation areas in the brain. Supervised learning can help in prediction of motor imagery actions by processing raw EEG signals. However, dimension of the feature space plays a crucial role in this process. Large dimensional features not only increase the computational complexity but also the presence of redundant features causes reduction in classification accuracy. In this work, we intend to select the relevant features from the feature vector obtained by Power Spectrum Density estimation of the left/right motor imagery signals. BCI Competition 2008-Graz dataset B has been used as the source of raw EEG data. To achieve this goal, we have used single-objective as well as many-objective version of Differential Evolution which optimizes the classifier's performance in terms of five metrics obtained from the Confusion Matrix. Support Vector Machine is used for fitness evaluation of the chosen feature subset as well as for classification of mental states. This work demonstrates the superiority of many-objective Differential Evolution in improving the accuracy due to reduction in feature dimension from an average of 60.56% to 82.60% while processing time of a test EEG sample reduces from 6.1 milliseconds to 5.6 milliseconds. The results obtained in this work are validated using Friedman Test. © 2016 IEEE.","Brain-Computer Interfacing; Differential Evolution; Electroencephalography; Many-Objective Optimization; Pareto-Optimality; Power Spectral Density; Support Vector Machine","Institute of Electrical and Electronics Engineers Inc."
"Ekbal A., Saha S.","Simultaneous feature and parameter selection using multiobjective optimization: application to named entity recognition",2016,"International Journal of Machine Learning and Cybernetics",13,"10.1007/s13042-014-0268-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978149951&doi=10.1007%2fs13042-014-0268-7&partnerID=40&md5=e0eed93f95038bf1ac3bb6f2671a503c","In this paper, we propose an efficient algorithm based on the concept of multiobjective optimization (MOO) for performing feature selection and parameter optimization of any machine learning technique. Feature and parameter combinations have significant effect to the accuracy of the classifier. We perform feature selection and parameter optimization for four different classifiers, namely conditional random field, support vector machine, memory based learner and maximum entropy. The proposed algorithms are evaluated for solving the problems of named entity recognition, an important component in many text processing applications. Currently we experiment with four different languages, namely Bengali, Hindi, Telugu and English. At first the proposed MOO based technique is used to determine the appropriate features and parameters. For each of the classifiers, the algorithm produces a set of solutions on the final Pareto optimal front. Each solution represents a classifier with a particular feature and parameter combination. All these solutions are thereafter combined using a MOO based classifier ensemble technique. Evaluation results show that the proposed approach attains the F-measure (harmonic mean of recall and precision) values of 90.48, 90.44, 78.71 and 88.68 % for Bengali, Hindi, Telugu and English, respectively. We also show that for all the experimental settings the proposed feature and parameter optimization technique performs reasonably better than the baseline systems, developed with random feature subsets. Comparisons with the existing works also show the efficacy of our proposed algorithm. © 2014, Springer-Verlag Berlin Heidelberg.","Feature selection; Machine learning; Multiobjective optimization; Named entity recognition (NER); Parameter selection","Springer Verlag"
"Zhang T., Georgiopoulos M., Anagnostopoulos G.C.","Multi-Objective Model Selection via Racing",2016,"IEEE Transactions on Cybernetics",6,"10.1109/TCYB.2015.2456187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939168171&doi=10.1109%2fTCYB.2015.2456187&partnerID=40&md5=87882f8b89f133e2e1e26a575404fe22","Model selection is a core aspect in machine learning and is, occasionally, multi-objective in nature. For instance, hyper-parameter selection in a multi-task learning context is of multi-objective nature, since all the tasks' objectives must be optimized simultaneously. In this paper, a novel multi-objective racing algorithm (RA), namely S-Race, is put forward. Given an ensemble of models, our task is to reliably identify Pareto optimal models evaluated against multiple objectives, while minimizing the total computational cost. As a RA, S-Race attempts to eliminate non-promising models with confidence as early as possible, so as to concentrate computational resources on promising ones. Simultaneously, it addresses the problem of multi-objective model selection (MOMS) in the sense of Pareto optimality. In S-Race, the nonparametric sign test is utilized for pair-wise dominance relationship identification. Moreover, a discrete Holm's step-down procedure is adopted to control the family-wise error rate of the set of hypotheses made simultaneously. The significance level assigned to each family is adjusted adaptively during the race. In order to illustrate its merits, S-Race is applied on three MOMS problems: 1) selecting support vector machines for classification; 2) tuning the parameters of artificial bee colony algorithms for numerical optimization; and 3) constructing optimal hybrid recommendation systems for movie recommendation. The experimental results confirm that S-Race is an efficient and effective MOMS algorithm compared to a brute-force approach. © 2015 IEEE.","Discrete Holm's step-down procedure; model selection; multi-objective optimization; racing algorithm (RA); sign test (ST)","Institute of Electrical and Electronics Engineers Inc."
"Szabó Z., Sriperumbudur B.K., Póczos B., Gretton A.","Learning theory for distribution regression",2016,"Journal of Machine Learning Research",42,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995467512&partnerID=40&md5=9976eaec5ea252b7ad4f1d22d7460915","We focus on the distribution regression problem: regressing to vector-valued outputs from probability measures. Many important machine learning and statistical tasks fit into this framework, including multi-instance learning and point estimation problems without analytical solution (such as hyperparameter or entropy estimation). Despite the large number of available heuristics in the literature, the inherent two-stage sampled nature of the problem makes the theoretical analysis quite challenging, since in practice only samples from sampled distributions are observable, and the estimates have to rely on similarities computed between sets of points. To the best of our knowledge, the only existing technique with consistency guarantees for distribution regression requires kernel density estimation as an intermediate step (which often performs poorly in practice), and the domain of the distributions to be compact Euclidean. In this paper, we study a simple, analytically computable, ridge regression-based alternative to distribution regression, where we embed the distributions to a reproducing kernel Hilbert space, and learn the regressor from the embeddings to the outputs. Our main contribution is to prove that this scheme is consistent in the two-stage sampled setup under mild conditions (on separable topological domains enriched with kernels): we present an exact computational-statistical efficiency trade-off analysis showing that our estimator is able to match the one-stage sampled minimax op- timal rate (Caponnetto and De Vito, 2007; Steinwart et al., 2009). This result answers a 17-year-old open question, establishing the consistency of the classical set kernel (Haussler, 1999; Gartner et al., 2002) in regression. We also cover consistency for more recent kernels on distributions, including those due to Christmann and Steinwart (2010). © 2016 Zoltán Szab, Bharath K. Sriperumbudur, Barnabás Póczos, and Arthur Gretton.","Kernel Ridge regression; Mean embedding; Minimax optimality; Multi-instance learning; Two-stage sampled distribution regression","Microtome Publishing"
"Samadi S., Soltanian-Zadeh H., Jutten C.","Integrated Analysis of EEG and fMRI Using Sparsity of Spatial Maps",2016,"Brain Topography",3,"10.1007/s10548-016-0506-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979656538&doi=10.1007%2fs10548-016-0506-2&partnerID=40&md5=fa2bfef53653303f216138a820c11203","Integration of electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) is an open problem, which has motivated many researches. The most important challenge in EEG-fMRI integration is the unknown relationship between these two modalities. In this paper, we extract the same features (spatial map of neural activity) from both modality. Therefore, the proposed integration method does not need any assumption about the relationship of EEG and fMRI. We present a source localization method from scalp EEG signal using jointly fMRI analysis results as prior spatial information and source separation for providing temporal courses of sources of interest. The performance of the proposed method is evaluated quantitatively along with multiple sparse priors method and sparse Bayesian learning with the fMRI results as prior information. Localization bias and source distribution index are used to measure the performance of different localization approaches with or without a variety of fMRI-EEG mismatches on simulated realistic data. The method is also applied to experimental data of face perception of 16 subjects. Simulation results show that the proposed method is significantly stable against the noise with low localization bias. Although the existence of an extra region in the fMRI data enlarges localization bias, the proposed method outperforms the other methods. Conversely, a missed region in the fMRI data does not affect the localization bias of the common sources in the EEG-fMRI data. Results on experimental data are congruent with previous studies and produce clusters in the fusiform and occipital face areas (FFA and OFA, respectively). Moreover, it shows high stability in source localization against variations in different subjects. © 2016, Springer Science+Business Media New York.","Elastic net; Integration analysis; Pareto optimization; Referenced-based signal processing; Weighted sparse decomposition","Springer New York LLC"
"Liu J.-W., Cui L.-P., Luo X.-L.","MCR SVM classifier with group sparsity",2016,"Optik",8,"10.1016/j.ijleo.2016.03.060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968813647&doi=10.1016%2fj.ijleo.2016.03.060&partnerID=40&md5=5fae5b958df97d7d6291da0a00a30136","Classification and dimensionality reduction of high-dimensional data are two important topics in bioinformatics, data mining and machine learning. We propose a novel sparse minimax concave ridge support vector machine (MCR SVM) classifier that simultaneously performs classification and dimensionality reduction. The MCR SVM classifier proposed in this study combines the advantages of the unbiasedness of the estimators of the SCAD SVM and the ability of feature group selection of HHSVM to overcome the disadvantages. We also provide a theoretical justification for the group sparsity of the selected features. The experiments on artificial highly correlated data and high-dimensional real-world data with a small sample size show that the MCR SVM classifier is a attractive technique of classification and dimensionality reduction and its performance is better than the other sparse SVMs. © 2016 Elsevier GmbH.","Feature selection; Group feature selection; MCR penalty; MCR SVM; Sparsity","Elsevier GmbH"
"Saha S., Mitra S., Yadav R.K.","A multiobjective based automatic framework for classifying cancer-microRNA biomarkers",2016,"Gene Reports",4,"10.1016/j.genrep.2016.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965146322&doi=10.1016%2fj.genrep.2016.04.001&partnerID=40&md5=10a8d2a93c41e1851108c4ca0a95cbf1","Short endogenous RNA aka miRNAs play significant roles in biological processes like RNA silencing and regulation of gene expressions. Several studies have revealed that there might be possible links between oncogenesis and some miRNA expression profiles since profiles of some specific miRNAs are expressed differently in case of normal and tumor tissues. In this paper, a technique based on multiobjective optimization for automatic selection of classifier, its parameters and feature combinations is used for classifying the miRNAs. The proposed approach is divided into two stages. In the first stage, a multiobjective framework in combination with four different classifiers namely Random Tree (RT), Random Forest (RF), Sequential Minimal Optimization (SMO), and Logistic Regression is used. The multiobjective based framework is capable of automatically determining the appropriate classifier, its different parameter combinations and feature combinations for any classification problem. The proposed approach is very generic and can be solved using any multiobjective evolutionary approach. But in the current study the search capability of popular NSGA-II is used. A new encoding strategy is proposed in the current paper to represent all the relevant information (classifier type, parameter combination, feature combination) in the form of a chromosome. Several different mutation operators are developed to accelerate the search process. In the second stage, the best solutions obtained from the first stage are combined using two different approaches: frequency-based approach and a simple ensemble-based approach. The performance of the proposed method has been demonstrated on several real life miRNA and mRNA datasets. Biological relevance of the obtained biomarkers has been reported. Results are compared with several state-of-the-art approaches. © 2016 Published by Elsevier Inc.","MicroRNA markers; Multiobjective optimization; Pareto optimal front; Supervised classification","Elsevier Inc"
"Polson N.G., Scott J.G.","Mixtures, envelopes and hierarchical duality",2016,"Journal of the Royal Statistical Society. Series B: Statistical Methodology",7,"10.1111/rssb.12130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949845414&doi=10.1111%2frssb.12130&partnerID=40&md5=066d8e6961334d848b0763a7d3f6f26e","We develop a connection between mixture and envelope representations of objective functions that arise frequently in statistics. We refer to this connection by using the term ‘hierarchical duality’. Our results suggest an interesting and previously underexploited relationship between marginalization and profiling, or equivalently between the Fenchel–Moreau theorem for convex functions and the Bernstein–Widder theorem for Laplace transforms. We give several different sets of conditions under which such a duality result obtains. We then extend existing work on envelope representations in several ways, including novel generalizations to variance–mean models and to multivariate Gaussian location models. This turns out to provide an elegant missing data interpretation of the proximal gradient method, which is a widely used algorithm in machine learning. We show several statistical applications in which the framework proposed leads to easily implemented algorithms, including a robust version of the fused lasso, non-linear quantile regression via trend filtering and the binomial fused double-Pareto model. Code for the examples is available on GitHub at https://github.com/jgscott/hierduals. © 2015 Royal Statistical Society","Bayesian inference; Convex duality; Envelopes; Gaussian mixtures; Maximum a posteriori estimation; Penalized likelihood; Variational methods","Blackwell Publishing Ltd"
"Wiśniewska M., Grudowski P.","High-quality academic teachers in business school. The case of The University of Gdańsk, Poland",2016,"Total Quality Management and Business Excellence",3,"10.1080/14783363.2015.1064766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936966560&doi=10.1080%2f14783363.2015.1064766&partnerID=40&md5=0db7256a03085c4e979fe572a2f1f6ea","The Bologna process, the increasing number of higher education institutions, the mass education and the demographic problems make the quality of education and quality of the academic teachers a subject of wide public debate and concern. The aim of the paper is to identify the most preferred characteristics of a teacher working at a business school. The research problem was: What should a high-quality business school academic teacher be like? During the research, a six-stage qualitative survey design was proposed, and a letter questionnaire was applied as a free writing instrument and sent to second-year bachelor students of the Faculty of Management at The University of Gdańsk, Poland. To identify the most preferred characteristics, a content analysis and Pareto analysis were used. As a result, 32 characteristics were proposed and grouped into 5 categories, namely tangibles (T), reliability (Rel), responsiveness (Res), assurance (A) and empathy (E). Based on this, several proposals and recommendations for the future were specified. The results obtained help not only to understand the needs of students, but also to prepare the most desired teaching environment in which deep learning outcomes are made possible for future managers in the context of modern economy. © 2015 Taylor & Francis.","academic teacher; business school; management education; quality","Routledge"
"Parisi S., Pirotta M., Restelli M.","Multi-objective reinforcement learning through continuous pareto manifold approximation",2016,"Journal of Artificial Intelligence Research",15,"10.1613/jair.4961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995701639&doi=10.1613%2fjair.4961&partnerID=40&md5=932c61a5996f300ac532db5835aea8ce","Many real-world control applications, from economics to robotics, are characterized by the presence of multiple conicting objectives. In these problems, the standard concept of optimality is replaced by Pareto{optimality and the goal is to find the Pareto frontier, a set of solutions representing different compromises among the objectives. Despite recent advances in multi{objective optimization, achieving an accurate representation of the Pareto frontier is still an important challenge. In this paper, we propose a reinforcement learning policy gradient approach to learn a continuous approximation of the Pareto frontier in multi{objective Markov Decision Problems (MOMDPs). Differently from previous policy gradient algorithms, where n optimization routines are executed to have n solutions, our approach performs a single gradient ascent run, generating at each step an improved continuous approximation of the Pareto frontier. The idea is to optimize the parameters of a function defining a manifold in the policy parameters space, so that the corresponding image in the objectives space gets as close as possible to the true Pareto frontier. Besides deriving how to compute and estimate such gradient, we will also discuss the non{trivial issue of defining a metric to assess the quality of the candidate Pareto frontiers. Finally, the properties of the proposed approach are empirically evaluated on two problems, a linear-quadratic Gaussian regulator and a water reservoir control task. © 2016 AI Access Foundation. All rights reserved.",,"AI Access Foundation"
"Fang Y., Liu Z.-H., Min F.","Multi-objective cost-sensitive attribute reduction on data with error ranges",2016,"International Journal of Machine Learning and Cybernetics",10,"10.1007/s13042-014-0296-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988378413&doi=10.1007%2fs13042-014-0296-3&partnerID=40&md5=8c81287f48147c528c168b8dbe0c3bf3","In current supervised machine learning research spectrum, there are several attribute reduction methodologies to acquire reducts with low test cost. They can deal with symbolic data, or numeric data with error ranges. In many cases, they consider the situation with only one type of cost; therefore the problem is single-objective. This paper addresses the attribute reduction problem on data with multi-type-costs and error ranges. First, we define the multi-objective attribute reduction problem where multi-type-costs are involved. Second, we propose three metrics to evaluate the quality of a reduct set. Third, we design a backtrack algorithm to compute the Pareto optimal set, and a heuristic algorithm to find a sub-optimal reduct set. Finally, we compare these algorithms on seven UCI (University of California-Irvine) datasets. Experimental results indicate that our heuristic algorithm has good capability of tackling the proposed problem. © 2014, Springer-Verlag Berlin Heidelberg.","Attribute reduction; Cost-sensitive learning; Error range; Test cost","Springer Verlag"
"Zerenner T., Venema V., Friederichs P., Simmer C.","Downscaling near-surface atmospheric fields with multi-objective Genetic Programming",2016,"Environmental Modelling and Software",11,"10.1016/j.envsoft.2016.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978164282&doi=10.1016%2fj.envsoft.2016.06.009&partnerID=40&md5=8d2547b74823f430017593dc8bb4c0c1","We present a new Genetic Programming based method to derive downscaling rules (i.e., functions or short programs) generating realistic high-resolution fields of atmospheric state variables near the surface given coarser-scale atmospheric information and high-resolution information on land surface properties. Such downscaling rules can be applied in coupled subsurface-land surface-atmosphere simulations or to generate high-resolution atmospheric input data for offline applications of land surface and subsurface models. Multiple features of the high-resolution fields, such as the spatial distribution of subgrid-scale variance, serve as objectives. The downscaling rules take an interpretable form and contain on average about 5 mathematical operations. The method is applied to downscale 10 m-temperature fields from 2.8 km to 400 m grid resolution. A large part of the spatial variability is reproduced, also in stable nighttime situations, which generate very heterogeneous near-surface temperature fields in regions with distinct topography. © 2016 The Authors","Coupled modeling; Disaggregation; Evolutionary computation; Machine learning; Pareto optimality; Statistical downscaling","Elsevier Ltd"
"Kantarcioglu M., Xi B.","Adversarial data mining: Big data meets cyber security",2016,"Proceedings of the ACM Conference on Computer and Communications Security",4,"10.1145/2976749.2976753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995436703&doi=10.1145%2f2976749.2976753&partnerID=40&md5=15d2cf43411c8bd84466d91014543206","As more and more cyber security incident data ranging from systems logs to vulnerability scan results are collected, manually analyzing these collected data to detect important cyber security events become impossible. Hence, data mining techniques are becoming an essential tool for real-world cyber security applications. For example, a report from Gartner [4] claims that ""Information security is becoming a big data analytics problem, where massive amounts of data will be correlated, analyzed and mined for meaningful patterns"". Of course, data mining/analytics is a means to an end where the ultimate goal is to provide cyber security analysts with prioritized actionable insights derived from big data. This raises the question, can we directly apply existing techniques to cyber security applications? One of the most important differences between data mining for cyber security and many other data mining applications is the existence of malicious adversaries that continuously adapt their behavior to hide their actions and to make the data mining models ineffective. Unfortunately, traditional data mining techniques are insufficient to handle such adversarial problems directly. The adversaries adapt to the data miner's reactions, and data mining algorithms constructed based on a training dataset degrades quickly. To address these concerns, over the last couple of years new and novel data mining techniques which is more resilient to such adversarial behavior are being developed in machine learning and data mining community. We believe that lessons learned as a part of this research direction would be beneficial for cyber security researchers who are increasingly applying machine learning and data mining techniques in practice. To give an overview of recent developments in adversarial data mining, in this three hour long tutorial, we introduce the foundations, the techniques, and the applications of adversarial data mining to cyber security applications. We first introduce various approaches proposed in the past to defend against active adversaries, such as a minimax approach to minimize the worst case error through a zero-sum game. We then discuss a game theoretic framework to model the sequential actions of the adversary and the data miner, while both parties try to maximize their utilities. We also introduce a modified support vector machine method and a relevance vector machine method to defend against active adversaries. Intrusion detection and malware detection are two important application areas for adversarial data mining models that will be discussed in details during the tutorial. Finally, we discuss some practical guidelines on how to use adversarial data mining ideas in generic cyber security applications and how to leverage existing big data management tools for building data mining algorithms for cyber security. © 2016 Copyright held by the owner/author(s).","Adversarial data mining; Big data analytics for cyber security","Association for Computing Machinery"
"Pham N.K., Kumar A., Singh A.K., Khin M.M.A.","Leakage aware resource management approach with machine learning optimization framework for partially reconfigurable architectures",2016,"Microprocessors and Microsystems",4,"10.1016/j.micpro.2016.09.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999266385&doi=10.1016%2fj.micpro.2016.09.012&partnerID=40&md5=ca6d5fbe810e659ffcf076bba85ea942","Shrinking size of transistors has enabled us to integrate more and more logic elements into FPGA chips leading to higher computing power. However, it also brings a serious concern to the leakage power dissipation of the FPGA devices. One of the major reasons for leakage power dissipation in FPGA is the utilization of prefetching technique to minimize the reconfiguration overhead (delay) in Partially Reconfigurable (PR) FPGAs. This technique creates delays between the reconfiguration and execution parts of a task, which may lead up to 38% leakage power of FPGA since the SRAM-cells containing reconfiguration information cannot be powered down. In this work, a resource management approach (RMA) containing scheduling, placement and post-placement stages has been proposed to address the aforementioned issue. In scheduling stage, a leakage-aware priority function is derived to cope with the leakage power. The placement stage uses a cost function that allows designers to determine the desired trade-off between performance and leakage-saving. The post-placement stage employs a heuristic approach to close the gaps between reconfiguration and execution of tasks, hence further reduce leakage waste. To further examine the trade-off between performance (schedule length) and leakage waste, we propose a framework to utilize the Genetic Algorithm (GA) for exploring the design space and obtaining Pareto optimal design points. Addressing the time-consuming limitation of GA, we apply Regression technique and Clustering algorithm to build predictive models for the Pareto fronts using a training task graph dataset. Experiments show that our approach can achieve large leakage savings for both synthetic and real-life applications with acceptable extended deadline. Furthermore, different variants of the proposed approach can reduce leakage power by 40–65% when compared to a performance-driven approach and by 15–43% when compared to state-of-the-art works. It's also proven that our Machine Learning Optimization framework can estimate the Pareto front for new coming task graphs 10x faster than well-established GA approach with only 10% degradation in quality. © 2016 Elsevier B.V.","Design space exploration; Machine learning; Mapping; Resource management; Scheduling","Elsevier B.V."
"Kartal H., Oztekin A., Gunasekaran A., Cebi F.","An integrated decision analytic framework of machine learning with multi-criteria decision making for multi-attribute inventory classification",2016,"Computers and Industrial Engineering",50,"10.1016/j.cie.2016.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977512343&doi=10.1016%2fj.cie.2016.06.004&partnerID=40&md5=aaf39f8e49645c2246b2d9e5342c5db7","The purpose of this study is to develop a hybrid methodology that integrates machine learning algorithms with multi-criteria decision making (MCDM) techniques to effectively conduct multi-attribute inventory analysis. In the proposed methodology, first, ABC analyses using three different MCDM methods (i.e. simple-additive weighting, analytical hierarchy process, and VIKOR) are employed to determine the appropriate class for each of the inventory items. Following this, naïve Bayes, Bayesian network, artificial neural network (ANN), and support vector machine (SVM) algorithms are implemented to predict classes of initially determined stock items. Finally, the detailed prediction performance metrics of algorithms for each method are determined. The comprehensive case study executed at a large-scale automotive company revealed that the best classification accuracy is achieved by SVMs. The results also revealed that Bayesian networks, SVMs and ANNs are all capable of successfully dealing with the unbalanced data problems associated with Pareto distribution, and each of these algorithms performed well against all examined measures, thus validating the fact that machine learning algorithms are highly applicable to inventory classification problems. Therefore, this study presents uniqueness in that it is the first and foremost of its kind to effectively combine MCDM methods with machine learning algorithms in multi-attribute inventory classification and is practically applicable in various inventory settings. Furthermore, this study also provides a comprehensive chronological overview of the existing literature of machine learning methods within inventory classification problems. © 2016 Elsevier Ltd","ABC analysis; Business analytics; Data mining; Multi-attribute inventory classification","Elsevier Ltd"
"Zhao J., Basto Fernandes V., Jiao L., Yevseyeva I., Maulana A., Li R., Bäck T., Tang K., Emmerich M.T.M.","Multiobjective optimization of classifiers by means of 3D convex-hull-based evolutionary algorithms",2016,"Information Sciences",19,"10.1016/j.ins.2016.05.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974802649&doi=10.1016%2fj.ins.2016.05.026&partnerID=40&md5=3da7a9a26e3f1ed2bf0ccafd1fb073ba","The receiver operating characteristic (ROC) and detection error tradeoff (DET) curves are frequently used in the machine learning community to analyze the performance of binary classifiers. Recently, the convex-hull-based multiobjective genetic programming algorithm was proposed and successfully applied to maximize the convex hull area for binary classification problems by minimizing false positive rate and maximizing true positive rate at the same time using indicator-based evolutionary algorithms. The area under the ROC curve was used for the performance assessment and to guide the search. Here we extend this research and propose two major advancements: Firstly we formulate the algorithm in detection error tradeoff space, minimizing false positives and false negatives, with the advantage that misclassification cost tradeoff can be assessed directly. Secondly, we add complexity as an objective function, which gives rise to a 3D objective space (as opposed to a 2D previous ROC space). A domain specific performance indicator for 3D Pareto front approximations, the volume above DET surface, is introduced, and used to guide the indicator-based evolutionary algorithm to find optimal approximation sets. We assess the performance of the new algorithm on designed theoretical problems with different geometries of Pareto fronts and DET surfaces, and two application-oriented benchmarks: (1) Designing spam filters with low numbers of false rejects, false accepts, and low computational cost using rule ensembles, and (2) finding sparse neural networks for binary classification of test data from the UCI machine learning benchmark. The results show a high performance of the new algorithm as compared to conventional methods for multicriteria optimization. © 2016 Elsevier Inc.","Anti-spam filters; Classification; Convex hull; Evolutionary multiobjective optimization; Parsimony; ROC analysis","Elsevier Inc."
"Moradi B., Mirzaei A.","A New Automated Design Method Based on Machine Learning for CMOS Analog Circuits",2016,"International Journal of Electronics",9,"10.1080/00207217.2016.1138538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959049899&doi=10.1080%2f00207217.2016.1138538&partnerID=40&md5=10cbc40aa7c2375692b618a9f7d98390","A new simulation based automated CMOS analog circuit design method which applies a multi-objective non-Darwinian-type evolutionary algorithm based on Learnable Evolution Model (LEM) is proposed in this article. The multi-objective property of this automated design of CMOS analog circuits is governed by a modified Strength Pareto Evolutionary Algorithm (SPEA) incorporated in the LEM algorithm presented here. LEM includes a machine learning method such as the decision trees that makes a distinction between high- and low-fitness areas in the design space. The learning process can detect the right directions of the evolution and lead to high steps in the evolution of the individuals. The learning phase shortens the evolution process and makes remarkable reduction in the number of individual evaluations. The expert designer’s knowledge on circuit is applied in the design process in order to reduce the design space as well as the design time. The circuit evaluation is made by HSPICE simulator. In order to improve the design accuracy, bsim3v3 CMOS transistor model is adopted in this proposed design method. This proposed design method is tested on three different operational amplifier circuits. The performance of this proposed design method is verified by comparing it with the evolutionary strategy algorithm and other similar methods. © 2016 Taylor & Francis.","automated design; CMOS analogue circuits; Learnable Evolution Model; multi-objective; operational amplifier","Taylor and Francis Ltd."
"Smithson S.C., Yang G., Gross W.J., Meyer B.H.","Neural networks designing neural networks: Multi-objective hyper-parameter optimization",2016,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",33,"10.1145/2966986.2967058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001090466&doi=10.1145%2f2966986.2967058&partnerID=40&md5=767c6d4a744bd4905982a74c7dcf6c1d","Artificial neural networks have gone through a recent rise in popularity, achieving state-of-the-art results in various fields, including image classification, speech recognition, and automated control. Both the performance and computational complexity of such models are heavily dependant on the design of characteristic hyper-parameters (e.g., number of hidden layers, nodes per layer, or choice of activation functions), which have traditionally been optimized manually. With machine learning penetrating low-power mobile and embedded areas, the need to optimize not only for performance (accuracy), but also for implementation complexity, becomes paramount. In this work, we present a multi-objective design space exploration method that reduces the number of solution networks trained and evaluated through response surface modelling. Given spaces which can easily exceed 1020 solutions, manually designing a near-optimal architecture is unlikely as opportunities to reduce network complexity, while maintaining performance, may be overlooked. This problem is exacerbated by the fact that hyper-parameters which perform well on specific datasets may yield sub-par results on others, and must therefore be designed on a per-application basis. In our work, machine learning is leveraged by training an artificial neural network to predict the performance of future candidate networks. The method is evaluated on the MNIST and CIFAR-10 image datasets, optimizing for both recognition accuracy and computational complexity. Experimental results demonstrate that the proposed method can closely approximate the Pareto-optimal front, while only exploring a small fraction of the design space. © 2016 ACM.",,"Institute of Electrical and Electronics Engineers Inc."
"Cococcioni M., Lazzerini B., Pistolesi F.","A semi-supervised learning-aided evolutionary approach to occupational safety improvement",2016,"2016 IEEE Congress on Evolutionary Computation, CEC 2016",9,"10.1109/CEC.2016.7744257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008263020&doi=10.1109%2fCEC.2016.7744257&partnerID=40&md5=6f8dda4e5004bd4c9469c49dc8c0ecf0","Worldwide, four people die every minute as a consequence of illnesses and accidents at work. This considerable number makes occupational safety an important research area aimed at obtaining safer and safer workplaces. This paper presents a semi-supervised learning-aided evolutionary approach to improve occupational safety by classifying workers depending on their own risk perception for the task assigned. More in detail, a semi-supervised learning phase is carried out to initialize a good population of a non-dominated sorting genetic algorithm (NSGA-II). Each chromosome of the population represents a pair of classifiers: one determines a worker's risk perception with respect to a task, the other determines the level of caution of the same worker for the same task. Learning from constraints reinforces the initial training performance. The best Pareto-optimal solution to the problem is selected by means of the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). The proposed framework was tested on real-world data gathered through a website purposely developed. Results showed a good performance of the obtained classifiers, thus validating the effectiveness of the proposed approach in supporting the decision-maker in critical job assignment problems, where risks are a serious threat to the workers' health. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"He H., Tiwari A., Mehnen J., Watson T., Maple C., Jin Y., Gabrys B.","Incremental information gain analysis of input attribute impact on RBF-kernel SVM spam detection",2016,"2016 IEEE Congress on Evolutionary Computation, CEC 2016",12,"10.1109/CEC.2016.7743901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008253503&doi=10.1109%2fCEC.2016.7743901&partnerID=40&md5=c3616a4f54d441b2ce14922fa1f26a63","The massive increase of spam is posing a very serious threat to email and SMS, which have become an important means of communication. Not only do spams annoy users, but they also become a security threat. Machine learning techniques have been widely used for spam detection. Email spams can be detected through detecting senders' behaviour, the contents of an email, subject and source address, etc, while SMS spam detection usually is based on the tokens or features of messages due to short content. However, a comprehensive analysis of email/SMS content may provide cures for users to aware of email/SMS spams. We cannot completely depend on automatic tools to identify all spams. In this paper, we propose an analysis approach based on information entropy and incremental learning to see how various features affect the performance of an RBF-based SVM spam detector, so that to increase our awareness of a spam by sensing the features of a spam. The experiments were carried out on the spambase and SMSSpemCollection databases in UCI machine learning repository. The results show that some features have significant impacts on spam detection, of which users should be aware, and there exists a feature space that achieves Pareto efficiency in True Positive Rate and True Negative Rate. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Zhang B., Shafi K., Abbass H.A.","Hybrid knowledge-based evolutionary many-objective optimization",2016,"2016 IEEE Congress on Evolutionary Computation, CEC 2016",1,"10.1109/CEC.2016.7743899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008248229&doi=10.1109%2fCEC.2016.7743899&partnerID=40&md5=dc65ddd97fa47cb402ed64ab28b08a78","Knowledge-based optimization is a recent direction in evolutionary optimization research which aims at understanding the optimization process, discovering relationships between decision variables and performance parameters, and using discovered knowledge to improve the optimization process, using machine learning techniques. A novel evolutionary optimization framework that incorporates a knowledge-based representation to search for Pareto optimal patterns in decision space was proposed earlier. This paper extends this framework to problems with four and more objectives, commonly referred to as many-objective optimization problems, using a hybridization approach with NSGA3. Experimental results on standard test functions are presented to demonstrate the advantages of the proposed hybrid algorithm in both objective and decision spaces. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Zhou Y., Ming A.","Semi-Supervised Multiple Instance Learning and its application in visual tracking",2016,"2016 8th International Conference on Wireless Communications and Signal Processing, WCSP 2016",1,"10.1109/WCSP.2016.7752532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006742055&doi=10.1109%2fWCSP.2016.7752532&partnerID=40&md5=347df6fb4d8c986e70be5f1cc3444244","In this paper, a novel Semi-Supervised Multiple Instance Learning (Semi-MIL) approach is presented. Compared with conventional approaches, we utilize a kind of 'bag of instances' representation in the semi-supervised learning process, which provides an effective way to use the unlabeled data in multiple instance learning problem. We formulate the problem with a graph model based on the Minimax kernel. In addition, the Semi-MIL algorithm is readily applied for visual tracking, which can resolve the ambiguities during the tracking process. The presented approach is validated on several benchmark videos for visual tracking and MUSKs dataset for classification, the competitive experimental results demonstrate the effectiveness of our approach. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Chan W.-T.J., Du Y., Kahng A.B., Nath S., Samadi K.","BEOL stack-aware routability prediction from placement using data mining techniques",2016,"Proceedings of the 34th IEEE International Conference on Computer Design, ICCD 2016",28,"10.1109/ICCD.2016.7753259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006757548&doi=10.1109%2fICCD.2016.7753259&partnerID=40&md5=f298f4ea7826227b4d82464fae54e467","In advanced technology nodes, physical design engineers must estimate whether a standard-cell placement is routable (before invoking the router) in order to maintain acceptable design turnaround time. Modern SoC designs consume multiple compute servers, memory, tool licenses and other resources for several days to complete routing. When the design is unroutable, resources are wasted, which increases the design cost. In this work, we develop machine learning-based models that predict whether a placement solution is routable without conducting trial or early global routing. We also use our models to accurately predict iso-performance Pareto frontiers of utilization, aspect ratio and number of layers in the back-end-of-line (BEOL) stack. Furthermore, using data mining and machine learning techniques, we develop new methodologies to generate training examples given very few placements. We conduct validation experiments in three foundry technologies (28nm FDSOI, 28nm LP and 45nm GS), and demonstrate accuracy ≥ 85.9% in predicting routability of a placement. Our predictions of Pareto frontiers in the three technologies are pessimistic by at most 2% with respect to the maximum achievable utilization for a given design in a given BEOL stack. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Lee E.Y., Fulan B.M., Wong G.C.L., Ferguson A.L.","Mapping membrane activity in undiscovered peptide sequence space using machine learning",2016,"Proceedings of the National Academy of Sciences of the United States of America",82,"10.1073/pnas.1609893113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998865440&doi=10.1073%2fpnas.1609893113&partnerID=40&md5=a68a926465dc3acc8d75657497c72d83","There are some ∼1,100 known antimicrobial peptides (AMPs), which permeabilize microbial membranes but have diverse sequences. Here, we develop a support vector machine (SVM)-based classifier to investigate α-helical AMPs and the interrelated nature of their functional commonality and sequence homology. SVM is used to search the undiscovered peptide sequence space and identify Pareto-optimal candidates that simultaneously maximize the distance σ from the SVM hyperplane (thus maximize its ""antimicrobialness"") and its α-helicity, but minimize mutational distance to known AMPs. By calibrating SVM machine learning results with killing assays and small-angle X-ray scattering (SAXS), we find that the SVM metric σ correlates not with a peptide's minimum inhibitory concentration (MIC), but rather its ability to generate negative Gaussian membrane curvature. This surprising result provides a topological basis for membrane activity common to AMPs. Moreover, we highlight an important distinction between the maximal recognizability of a sequence to a trained AMP classifier (its ability to generate membrane curvature) and its maximal antimicrobial efficacy. As mutational distances are increased from known AMPs, we find AMP-like sequences that are increasingly difficult for nature to discover via simple mutation. Using the sequence map as a discovery tool, we find a unexpectedly diverse taxonomy of sequences that are just as membrane-active as known AMPs, but with a broad range of primary functions distinct from AMP functions, including endogenous neuropeptides, viral fusion proteins, topogenic peptides, and amyloids. The SVM classifier is useful as a general detector of membrane activity in peptide sequences. © 2016, National Academy of Sciences. All rights reserved.","Antimicrobial peptides; Cell-penetrating peptides; Machine learning; Membrane curvature; Membrane permeation","National Academy of Sciences"
"Lippi M.","Statistical Relational Learning for Game Theory",2016,"IEEE Transactions on Computational Intelligence and AI in Games",3,"10.1109/TCIAIG.2015.2490279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027452107&doi=10.1109%2fTCIAIG.2015.2490279&partnerID=40&md5=f73a146098238158a91d97685dab3ab8","In this paper, we motivate the use of models and algorithms from the area of Statistical Relational Learning (SRL) as a framework for the description and the analysis of games. SRL combines the powerful formalism of first-order logic with the capability of probabilistic graphical models in handling uncertainty in data and representing dependencies between random variables: for this reason, SRL models can be effectively used to represent several categories of games, including games with partial information, graphical games and stochastic games. Inference algorithms can be used to approach the opponent modeling problem, as well as to find Nash equilibria or Pareto optimal solutions. Structure learning algorithms can be applied, in order to automatically extract probabilistic logic clauses describing the strategies of an opponent with a high-level, human-interpretable formalism. Experiments conducted using Markov logic networks, one of the most used SRL frameworks, show the potential of the approach. © 2015 IEEE.","Machine learning; probabilistic logic","Institute of Electrical and Electronics Engineers Inc."
"Chen X., Guntuboyina A., Zhang Y.","On bayes risk lower bounds",2016,"Journal of Machine Learning Research",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008311809&partnerID=40&md5=277e35133b76ec81f65b3f22915f2b24","This paper provides a general technique for lower bounding the Bayes risk of statistical estimation, applicable to arbitrary loss functions and arbitrary prior distributions. A lower bound on the Bayes risk not only serves as a lower bound on the minimax risk, but also characterizes the fundamental limit of any estimator given the prior knowledge. Our bounds are based on the notion of f-informativity (Csiszar, 1972), which is a function of the underlying class of probability measures and the prior. Application of our bounds requires upper bounds on the f-informativity, thus we derive new upper bounds on f-informativity which often lead to tight Bayes risk lower bounds. Our technique leads to generalizations of a variety of classical minimax bounds (e.g., generalized Fano's inequality). Our Bayes risk lower bounds can be directly applied to several concrete estimation problems, including Gaussian location models, generalized linear models, and principal component analysis for spiked covariance models. To further demonstrate the applications of our Bayes risk lower bounds to machine learning problems, we present two new theoretical results: (1) a precise characterization of the minimax risk of learning spherical Gaussian mixture models under the smoothed analysis framework, and (2) lower bounds for the Bayes risk under a natural prior for both the prediction and estimation errors for high-dimensional sparse linear regression under an improper learning setting. © 2016 Xi Chen, Adityanand Guntuboyina, and Yuchen Zhang.","Bayes risk; F-divergence; F-informativity; Fano's inequality; Minimax risk; Smoothed analysis","Microtome Publishing"
"Mannodi-Kanakkithodi A., Pilania G., Ramprasad R., Lookman T., Gubernatis J.E.","Multi-objective optimization techniques to design the Pareto front of organic dielectric polymers",2016,"Computational Materials Science",17,"10.1016/j.commatsci.2016.08.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985947261&doi=10.1016%2fj.commatsci.2016.08.018&partnerID=40&md5=df005960a8e104584cc1aa67afd74a0f","We present two Monte Carlo algorithms to find the Pareto front of the chemical space of a class of dielectric polymers that is most interesting with respect to optimizing both the bandgap and dielectric constant. Starting with a dataset generated from density functional theory calculations, we used machine learning to construct surrogate models for the bandgaps and dielectric constants of all physically meaningful 4-block polymers (that is, polymer systems with a 4-block repeat unit). We parameterized these machine learning models in such a way that the surrogates built for the 4-block polymers were readily extendable to polymers beyond a 4-block repeat unit. By using translational invariance, chemical intuition, and domain knowledge, we were able to enumerate all possible 4, 6, and 8 block polymers and benchmark our Monte Carlo sampling of the chemical space against the exact enumeration of the surrogate predictions. We obtained exact agreement for the fronts of 4-block polymers and at least a 90% agreement for those of 6 and 8-block polymers. We present fronts for 10-block polymer that are not possible to obtain by direct enumeration. We note that our Monte Carlo methods also return polymers close to the predicted front and a measure of the closeness. Both quantities are useful information for the design and discovery of new polymers. © 2016 Elsevier B.V.","Density functional theory; Materials informatics; Multi-objective optimization","Elsevier"
"Korba A., Clémençon S., Sibony E.","A learning theory of ranking aggregation",2017,"Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083936908&partnerID=40&md5=538bf5fc21ef6d31f7b237d50a93835e","Originally formulated in Social Choice theory, Ranking Aggregation, also referred to as Consensus Ranking, has motivated the development of numerous statistical models since the middle of the 20th century. Recently, the analysis of ranking/preference data has been the subject of a renewed interest in machine-learning, boosted by modern applications such as meta-search engines, giving rise to the design of various scalable algorithmic approaches for approximately computing ranking medians, viewed as solutions of a discrete (generally NP-hard) minimization problem. This paper develops a statistical learning theory for ranking aggregation in a general probabilistic setting (avoiding any rigid ranking model assumptions), assessing the generalization ability of empirical ranking medians. Universal rate bounds are established and the situations where convergence occurs at an exponential rate are fully characterized. Minimax lower bounds are also proved, showing that the rate bounds we obtain are optimal. Copyright 2017 by the author(s).",,"PMLR"
"Horii H.","Multi-objective optimization of vehicle occupant restraint system by using evolutionary algorithm with response surface model",2017,"International Journal of Computational Methods and Experimental Measurements",3,"10.2495/CMEM-V5-N2-163-170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064227214&doi=10.2495%2fCMEM-V5-N2-163-170&partnerID=40&md5=7157311f31c228cb0763c074b2c7bf00","This research reports a vehicle occupant restraint system design by using evolutionary multi-objective optimization with response surface model. The vehicle occupant restraint systems are composed of restraint equipment, such as an airbag, a seat belt and a knee bolster. The optimization aims to improve the safety of the system by evaluating some indexes based on some safety regulations. Estimation models of the safety indexes are introduced for accelerating the optimization. The estimation models, which are called the response surface models, are constructed by using Gaussian Process, which is a kind of machine learning method. The Gaussian Process constructs the estimation model from sampling results, which are calculated by using multi-body dynamics simulation. Some helpful information for designing the restraint systems, such as trade-off information of safety performance and contribution of design variables for the safety performance, is obtained by analysing the Pareto optimal solutions. © 2017 WIT Press.","Evolutionary algorithm; Machine learning; Multi-objective optimization; Occupant safety","Wit Press"
"Li Y., Ding A.A., Dy J.","Rate optimal estimation for high dimensional spatial covariance matrices",2017,"Journal of Machine Learning Research",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055680374&partnerID=40&md5=c608d793b52f11989a58cd30c3fe312e","Spatial covariance matrix estimation is of great significance in many applications in climatology, econometrics and many other fields with complex data structures involving spatial dependencies. High dimensionality brings new challenges to this problem, and no theoretical optimal estimator has been proved for the spatial high-dimensional covariance matrix. Over the past decade, the method of regularization has been introduced to high-dimensional covariance estimation for various structured matrices, to achieve rate optimal estimators. In this paper, we aim to bridge the gap in these two research areas. We use a structure of block bandable covariance matrices to incorporate spatial dependence information, and study rate optimal estimation of this type of structured high dimensional covariance matrices. A double tapering estimator is proposed, and is shown to achieve the asymptotic minimax error bound. Numerical studies on both synthetic and real data are conducted showing the improvement of the double tapering estimator over the sample covariance matrix estimator. © 2017 Y. Li, A.A. Ding & J. Dy.","Covariance estimation; High-dimensional statistics","Microtome Publishing"
"Van Der Pas S., Ročková V.","Bayesian dyadic trees and histograms for regression",2017,"Advances in Neural Information Processing Systems",7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047012654&partnerID=40&md5=da0825e3d1d8f21916ae3db61c91045f","Many machine learning tools for regression are based on recursive partitioning of the covariate space into smaller regions, where the regression function can be estimated locally. Among these, regression trees and their ensembles have demonstrated impressive empirical performance. In this work, we shed light on the machinery behind Bayesian variants of these methods. In particular, we study Bayesian regression histograms, such as Bayesian dyadic trees, in the simple regression case with just one predictor. We focus on the reconstruction of regression surfaces that are piecewise constant, where the number of jumps is unknown. We show that with suitably designed priors, posterior distributions concentrate around the true step regression function at a near-minimax rate. These results do not require the knowledge of the true number of steps, nor the width of the true partitioning cells. Thus, Bayesian dyadic regression trees are fully adaptive and can recover the true piecewise regression function nearly as well as if we knew the exact number and location of jumps. Our results constitute the first step towards understanding why Bayesian trees and their ensembles have worked so well in practice. As an aside, we discuss prior distributions on balanced interval partitions and how they relate to an old problem in geometric probability. Namely, we relate the probability of covering the circumference of a circle with random arcs whose endpoints are confined to a grid, a new variant of the original problem. © 2017 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Quadrianto N., Sharmanska V.","Recycling privileged learning and distribution matching for fairness",2017,"Advances in Neural Information Processing Systems",17,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047012565&partnerID=40&md5=bad6f10378f375adea45d8d19502c1ab","Equipping machine learning models with ethical and legal constraints is a serious issue; without this, the future of machine learning is at risk. This paper takes a step forward in this direction and focuses on ensuring machine learning models deliver fair decisions. In legal scholarships, the notion of fairness itself is evolving and multi-faceted. We set an overarching goal to develop a unified machine learning framework that is able to handle any definitions of fairness, their combinations, and also new definitions that might be stipulated in the future. To achieve our goal, we recycle two well-established machine learning techniques, privileged learning and distribution matching, and harmonize them for satisfying multi-faceted fairness definitions. We consider protected characteristics such as race and gender as privileged information that is available at training but not at test time; this accelerates model training and delivers fairness through unawareness. Further, we cast demographic parity, equalized odds, and equality of opportunity as a classical two-sample problem of conditional distributions, which can be solved in a general form by using distance measures in Hilbert Space. We show several existing models are special cases of ours. Finally, we advocate returning the Pareto frontier of multi-objective minimization of error and unfairness in predictions. This will facilitate decision makers to select an operating point and to be accountable for it. © 2017 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Xie Q., Dai Z., Du Y., Hovy E., Neubig G.","Controllable invariance through adversarial feature learning",2017,"Advances in Neural Information Processing Systems",89,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047007669&partnerID=40&md5=b3d7dc05c60a02b71249b840c06abb4a","Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved performance. © 2017 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Chiş R., Vinţan L.","Developing automatic multi-objective optimization methods for complex actuators",2017,"Advances in Electrical and Computer Engineering",,"10.4316/AECE.2017.04011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035746256&doi=10.4316%2fAECE.2017.04011&partnerID=40&md5=718019cb0441d65b768316c510593934","This paper presents the analysis and multiobjective optimization of a magnetic actuator. By varying just 8 parameters of the magnetic actuator's model the design space grows to more than 6 million configurations. Much more, the 8 objectives that must be optimized are conflicting and generate a huge objectives space, too. To cope with this complexity, we use advanced heuristic methods for Automatic Design Space Exploration. FADSE tool is one Automatic Design Space Exploration framework including different state of the art multi-objective meta-heuristics for solving NP-hard problems, which we used for the analysis and optimization of the COMSOL and MATLAB model of the magnetic actuator. We show that using a state of the art genetic multi-objective algorithm, response surface modelling methods and some machine learning techniques, the timing complexity of the design space exploration can be reduced, while still taking into consideration objective constraints so that various Pareto optimal configurations can be found. Using our developed approach, we were able to decrease the simulation time by at least a factor of 10, compared to a run that does all the simulations, while keeping prediction errors to around 1%.","Actuators; Computer aided engineering; Machine learning; Pareto optimization; Response surface methodology","University of Suceava"
"Zeliff K., Bennette W., Ferguson S.","Benchmarking the peformance of a machine learning classifier enabled multiobjective genetic algorithm on six standard test functions",2017,"Proceedings of the ASME Design Engineering Technical Conference",3,"10.1115/DETC2017-68332","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034739173&doi=10.1115%2fDETC2017-68332&partnerID=40&md5=09a6b04c3123317c87288cdd3efd459f","Previous work tested a multi-objective genetic algorithm that was integrated with a machine learning classifier to reduce the number of objective function calls. Four machine learning classifiers and a baseline ""No Classifier"" option were evaluated. Using a machine learning classifier to create a hybrid multiobjective genetic algorithm reduced objective function calls by 75-85% depending on the classifier used. This work expands the analysis of algorithm performance by considering six standard benchmark problems from the literature. The problems are designed to test the ability of the algorithm to identify the Pareto frontier and maintain population diversity. Results indicate a tradeoff between the objectives of Pareto frontier identification and solution diversity. The ""No Classifier"" baseline multiobjective genetic algorithm produces the frontier with the closest proximity to the true frontier while a classifier option provides the greatest diversity when the number of generations is fixed. However, there is a significant reduction in computational expense as the number of objective function calls required is significantly reduced, highlighting the advantage of this hybrid approach. © Copyright 2017 ASME.",,"American Society of Mechanical Engineers (ASME)"
"Soma T., Yoshida Y.","Regret ratio minimization in multi-objective submodular function maximization",2017,"31st AAAI Conference on Artificial Intelligence, AAAI 2017",9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030475742&partnerID=40&md5=d4a810b21f5c90eca347debe5615750b","Submodular function maximization has numerous applications in machine learning and artificial intelligence. Many real applications require multiple submodular objective functions to be maximized, and which function is regarded as important by a user is not known in advance. In such cases, it is desirable to have a small family of representative solutions that would satisfy any user's preference. A traditional approach for solving such a problem is to enumerate the Pareto optimal solutions. However, owing to the massive number of Pareto optimal solutions (possibly exponentially many), it is difficult for a user to select a solution. In this paper, we propose two efficient methods for finding a small family of representative solutions, based on the notion of regret ratio. The first method outputs a family of fixed size with a non-trivial regret ratio. The second method enables us to choose the size of the output family, and in the biobjective case, it has a provable trade-off between the size and the regret ratio. Using real and synthetic data, we empirically demonstrate that our methods achieve a small regret ratio. Copyright © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"AAAI press"
"Hu Y., Gibson E., Vercauteren T., Ahmed H.U., Emberton M., Moore C.M., Noble J.A., Barratt D.C.","Intraoperative organ motion models with an ensemble of conditional generative adversarial networks",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",12,"10.1007/978-3-319-66185-8_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029548476&doi=10.1007%2f978-3-319-66185-8_42&partnerID=40&md5=ceb2210257c4f7ac2c723c4e9893c9fd","In this paper, we describe how a patient-specific, ultrasound-probe-induced prostate motion model can be directly generated from a single preoperative MR image. Our motion model allows for sampling from the conditional distribution of dense displacement fields, is encoded by a generative neural network conditioned on a medical image, and accepts random noise as additional input. The generative network is trained by a minimax optimisation with a second discriminative neural network, tasked to distinguish generated samples from training motion data. In this work, we propose that (1) jointly optimising a third conditioning neural network that pre-processes the input image, can effectively extract patient-specific features for conditioning; and (2) combining multiple generative models trained separately with heuristically pre-disjointed training data sets can adequately mitigate the problem of mode collapse. Trained with diagnostic T2-weighted MR images from 143 real patients and 73,216 3D dense displacement fields from finite element simulations of intraoperative prostate motion due to transrectal ultrasound probe pressure, the proposed models produced physically-plausible patient-specific motion of prostate glands. The ability to capture biomechanically simulated motion was evaluated using two errors representing generalisability and specificity of the model. The median values, calculated from a 10-fold cross-validation, were 2.8 ± 0.3 mm and 1.7 ± 0.1 mm, respectively. We conclude that the introduced approach demonstrates the feasibility of applying state-of-the-art machine learning algorithms to generate organ motion models from patient images, and shows significant promise for future research. © Springer International Publishing AG 2017.",,"Springer Verlag"
"Chabert M., Solnon C.","Constraint programming for multi-criteria conceptual clustering",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",7,"10.1007/978-3-319-66158-2_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028725683&doi=10.1007%2f978-3-319-66158-2_30&partnerID=40&md5=754d1b36d88332642255ac3ac60176dd","A conceptual clustering is a set of formal concepts (i.e., closed itemsets) that defines a partition of a set of transactions. Finding a conceptual clustering is an NP -complete problem for which Constraint Programming (CP) and Integer Linear Programming (ILP) approaches have been recently proposed. We introduce new CP models to solve this problem: a pure CP model that uses set constraints, and an hybrid model that uses a data mining tool to extract formal concepts in a preprocessing step and then uses CP to select a subset of formal concepts that defines a partition. We compare our new models with recent CP and ILP approaches on classical machine learning instances. We also introduce a new set of instances coming from a real application case, which aims at extracting setting concepts from an Enterprise Resource Planning (ERP) software. We consider two classic criteria to optimize, i.e., the frequency and the size. We show that these criteria lead to extreme solutions with either very few small formal concepts or many large formal concepts, and that compromise clusterings may be obtained by computing the Pareto front of non dominated clusterings. © Springer International Publishing AG 2017.",,"Springer Verlag"
"Zhang Y., Gong D.-W., Cheng J.","Multi-objective particle swarm optimization approach for cost-based feature selection in classification",2017,"IEEE/ACM Transactions on Computational Biology and Bioinformatics",231,"10.1109/TCBB.2015.2476796","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027417770&doi=10.1109%2fTCBB.2015.2476796&partnerID=40&md5=79016f4705f43f2bbf0172260bb53d4e","Feature selection is an important data-preprocessing technique in classification problems such as bioinformatics and signal processing. Generally, there are some situations where a user is interested in not only maximizing the classification performance but also minimizing the cost that may be associated with features. This kind of problem is called cost-based feature selection. However, most existing feature selection approaches treat this task as a single-objective optimization problem. This paper presents the first study of multi-objective particle swarm optimization (PSO) for cost-based feature selection problems. The task of this paper is to generate a Pareto front of nondominated solutions, that is, feature subsets, to meet different requirements of decision-makers in real-world applications. In order to enhance the search capability of the proposed algorithm, a probability-based encoding technology and an effective hybrid operator, together with the ideas of the crowding distance, the external archive, and the Pareto domination relationship, are applied to PSO. The proposed PSO-based multi-objective feature selection algorithm is compared with several multi-objective feature selection algorithms on five benchmark datasets. Experimental results show that the proposed algorithm can automatically evolve a set of nondominated solutions, and it is a highly competitive feature selection method for solving cost-based feature selection problems. © 2004-2012 IEEE.","Cost; Feature selection; Multi-objective; Particle swarm optimization","Institute of Electrical and Electronics Engineers Inc."
"Chiba K., Nakata M.","From Extraction to Generation of Design Information -Paradigm Shift in Data Mining via Evolutionary Learning Classifier System",2017,"Procedia Computer Science",,"10.1016/j.procs.2017.05.233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027351338&doi=10.1016%2fj.procs.2017.05.233&partnerID=40&md5=61c47c1890e6e64e96e3a8d43e05d2d2","This paper aims at generating as well as extracting design strategies for a real world problem using an evolutionary learning classifier system. Data mining for a design optimization result as a virtual database specifies design information and discovers latent design knowledge. It is essential for decision making in real world problems. Although we employed several methods from classic statistics to artificial intelligence to obtain design information from optimization results, we may not cognize anything beyond a prepared database. In this study, we have applied an evolutionary learning classifier system as a data mining technique to a real world engineering problem. Consequently, not only it extracted known design information but also it successfully generated design strategies not to extract from the database. The generated design rules do not physically become innovative knowledge because the prepared dataset include Pareto solutions owing to complete exploration to the edge of the feasible region in the optimization. However, this problem is independent of the method, our evolutionary learning classifier system is a useful method for incomplete datasets. © 2017 The Authors. Published by Elsevier B.V.","data mining; design information generation; evolutionary machine learning; knowledge discovery; learning classifier system; real-world application","Elsevier B.V."
"Zhang, Y., Gong, D.-W., Cheng, J.","Multi-Objective Particle Swarm Optimization Approach for Cost-Based Feature Selection in Classification",2017,"IEEE/ACM transactions on computational biology and bioinformatics",,"10.1109/TCBB.2015.2476796","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027032944&doi=10.1109%2fTCBB.2015.2476796&partnerID=40&md5=411cfb9fda333a5702d53d981b7ef1ef",[No abstract available],,
"Khazraee M., Gutierrez L.V., Magaki I., Taylor M.B.","Specializing a Planet's Computation: ASIC Clouds",2017,"IEEE Micro",6,"10.1109/MM.2017.49","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021180865&doi=10.1109%2fMM.2017.49&partnerID=40&md5=cb0d12bb819cfe4307cf9eae01548c1e","GPU- and FPGA-based clouds have been deployed to accelerate computationally intensive workloads. ASIC-based clouds are a natural evolution as cloud services expand across the planet. ASIC Clouds are purpose-built datacenters comprising large arrays of ASIC accelerators that optimize the total cost of ownership (TCO) of large, high-volume scale-out computations. On the surface, ASIC Clouds may seem improbable due to high nonrecurring engineering (NRE) costs and ASIC inflexibility, but large-scale ASIC Clouds have been deployed for the Bitcoin cryptocurrency system. This article distills lessons from these Bitcoin ASIC Clouds and applies them to other large-scale workloads, including YouTube-style video-transcoding and Deep Learning, showing superior TCO versus CPU and GPU. It derives Pareto-optimal ASIC Cloud servers based on accelerator properties, by jointly optimizing ASIC architecture, DRAM, motherboard, power delivery, cooling, and operating voltage. Finally, the authors examine the impact of ASIC NRE and when it makes sense to build an ASIC Cloud. © 1981-2012 IEEE.","accelerator; ASIC Cloud; datacenter; nonrecurring engineering; NRE; planet-scale computation; TCO; total cost of ownership","IEEE Computer Society"
"Charisopoulos V., Maragos P.","Morphological perceptrons: Geometry and training algorithms",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",17,"10.1007/978-3-319-57240-6_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019198381&doi=10.1007%2f978-3-319-57240-6_1&partnerID=40&md5=0861ede2551878d6cd138ef30bedb482","Neural networks have traditionally relied on mostly linear models, such as the multiply-accumulate architecture of a linear perceptron that remains the dominant paradigm of neuronal computation. However, from a biological standpoint, neuron activity may as well involve inherently nonlinear and competitive operations. Mathematical morphology and minimax algebra provide the necessary background in the study of neural networks made up from these kinds of nonlinear units. This paper deals with such a model, called the morphological perceptron. We study some of its geometrical properties and introduce a training algorithm for binary classification. We point out the relationship between morphological classifiers and the recent field of tropical geometry, which enables us to obtain a precise bound on the number of linear regions of the maxout unit, a popular choice for deep neural networks introduced recently. Finally, we present some relevant numerical results. © Springer International Publishing AG 2017.","Machine learning; Mathematical morphology; Neural networks; Optimization; Tropical geometry","Springer Verlag"
"Yi L., Xing-Chun D., Jian-Jun C., Xing Z., Yu-Ling S.","A method for entity resolution in high dimensional data using ensemble classifiers",2017,"Mathematical Problems in Engineering",3,"10.1155/2017/4953280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014284069&doi=10.1155%2f2017%2f4953280&partnerID=40&md5=241d3080089ae87fcd772aab528c71a5","In order to improve utilization rate of high dimensional data features, an ensemble learning method based on feature selection for entity resolution is developed. Entity resolution is regarded as a binary classification problem, an optimization model is designed to maximize each classifier's classification accuracy and dissimilarity between classifiers and minimize cardinality of features. A modified multiobjective ant colony optimization algorithm is employed to solve the model for each base classifier, two pheromone matrices are set up, weighted product method is applied to aggregate values of two pheromone matrices, and feature's Fisher discriminant rate of records' similarity vector is calculated as heuristic information. A solution which is called complementary subset is selected from Pareto archive according to the descending order of three objectives to train the given base classifier. After training all base classifiers, their classification outputs are aggregated by max-wins voting method to obtain the ensemble classifiers' final result. A simulation experiment is carried out on three classical datasets. The results show the effectiveness of our method, as well as a better performance compared with the other two methods. © 2017 Liu Yi et al.",,"Hindawi Publishing Corporation"
"Duro J.A., Saxena D.K.","Timing the decision support for real-world many-objective optimization problems",2017,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-319-54157-0_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014185794&doi=10.1007%2f978-3-319-54157-0_14&partnerID=40&md5=840ffe11cfeb1a932bfd4328e314c004","Lately, there is growing emphasis on improving the scalability of multi-objective evolutionary algorithms (MOEAs) so that manyobjective problems (characterized by more than three objectives) can be effectively dealt with. Alternatively, the utility of integrating decision maker’s (DM’s) preferences into the optimization process so as to target some most preferred solutions by the DM (instead of the whole Paretooptimal front), is also being increasingly recognized. The authors here, have earlier argued that despite the promises in the latter approach, its practical utility may be impaired by the lack of—objectivity, repeatability, consistency, and coherence in the DM’s preferences. To counter this, the authors have also earlier proposed a machine learning based decision support framework to reveal the preference-structure of objectives. Notably, the revealed preference-structure may be sensitive to the timing of application of this framework along an MOEA run. In this paper the authors counter this limitation, by integrating a termination criterion with an MOEA run, towards determining the appropriate timing for application of the machine learning based framework. Results based on three real-world many-objective problems considered in this paper, highlight the utility of the proposed integration towards an objective, repeatable, consistent, and coherent decision support for many-objective problems. © Springer International Publishing AG 2017.",,"Springer Verlag"
"Allmendinger R., Emmerich M.T.M., Hakanen J., Jin Y., Rigoni E.","Surrogate-assisted multicriteria optimization: Complexities, prospective solutions, and business case",2017,"Journal of Multi-Criteria Decision Analysis",45,"10.1002/mcda.1605","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014115915&doi=10.1002%2fmcda.1605&partnerID=40&md5=f8aa478d2a4a83909d5fae55920da943","Complexity in solving real-world multicriteria optimization problems often stems from the fact that complex, expensive, and/or time-consuming simulation tools or physical experiments are used to evaluate solutions to a problem. In such settings, it is common to use efficient computational models, often known as surrogates or metamodels, to approximate the outcome (objective or constraint function value) of a simulation or physical experiment. The presence of multiple objective functions poses an additional layer of complexity for surrogate-assisted optimization. For example, complexities may relate to the appropriate selection of metamodels for the individual objective functions, extensive training time of surrogate models, or the optimal use of many-core computers to approximate efficiently multiple objectives simultaneously. Thinking out of the box, complexity can also be shifted from approximating the individual objective functions to approximating the entire Pareto front. This leads to further complexities, namely, how to validate statistically and apply the techniques developed to real-world problems. In this paper, we discuss emerging complexity-related topics in surrogate-assisted multicriteria optimization that may not be prevalent in nonsurrogate-assisted single-objective optimization. These complexities are motivated using several real-world problems in which the authors were involved. We then discuss several promising future research directions and prospective solutions to tackle emerging complexities in surrogate-assisted multicriteria optimization. Finally, we provide insights from an industrial point of view into how surrogate-assisted multicriteria optimization techniques can be developed and applied within a collaborative business environment to tackle real-world problems. Copyright © 2017 John Wiley & Sons, Ltd.","evolutionary multicriteria optimization; expensive optimization problems; machine learning; metamodels; multiple criteria decision making; surrogates","John Wiley and Sons Ltd"
"de Campos C.P., Benavoli A.","Joint Analysis of Multiple Algorithms and Performance Measures",2017,"New Generation Computing",6,"10.1007/s00354-016-0005-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003972509&doi=10.1007%2fs00354-016-0005-8&partnerID=40&md5=ccbfdb499a7a1eee49d8e42367675bcf","There has been an increasing interest in the development of new methods using Pareto optimality to deal with multi-objective criteria (for example, accuracy and time complexity). Once one has developed an approach to a problem of interest, the problem is then how to compare it with the state of art. In machine learning, algorithms are typically evaluated by comparing their performance on different data sets by means of statistical tests. Standard tests used for this purpose are able to consider jointly neither performance measures nor multiple competitors at once. The aim of this paper is to resolve these issues by developing statistical procedures that are able to account for multiple competing measures at the same time and to compare multiple algorithms altogether. In particular, we develop two tests: a frequentist procedure based on the generalized likelihood ratio test and a Bayesian procedure based on a multinomial-Dirichlet conjugate model. We further extend them by discovering conditional independences among measures to reduce the number of parameters of such models, as usually the number of studied cases is very reduced in such comparisons. Data from a comparison among general purpose classifiers are used to show a practical application of our tests. © 2016, Ohmsha, Ltd. and Springer Japan.",,"Springer Tokyo"
"Malazgirt G.A., Yurdakul A.","Prenaut: Design space exploration for embedded symmetric multiprocessing with various on-chip architectures",2017,"Journal of Systems Architecture",4,"10.1016/j.sysarc.2016.07.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994322695&doi=10.1016%2fj.sysarc.2016.07.004&partnerID=40&md5=33152101a3cc0173da9457fde7a14d77","As embedded systems have evolved to appear in many different domains, symmetric multiprocessing (SMP) has been the design choice from low-end to high-end devices. In this paper we present Prenaut, a design space exploration method for finding the best on-chip SMP architectures given processor cores, Level 1, Level 2, and Level 3 caches. Unlike traditional design space exploration tools that are majorly concerned with optimizations in processor, memory and cache structures with a fixed on-chip architecture, Prenaut explores architectures that have not been considered in symmetric multiprocessing domain. These architectures consist of shared instruction caches between cores and heterogeneous cache topologies that feature bypassing a level in the cache hierarchy. The design idea behind Prenaut is to build a data oriented design space exploration method that exploits simulation data to its full extent rather than discarding it. Therefore, Prenaut uses simulation data and applies machine learning methods for estimating design parameters. This provides very rapid estimation of the Pareto set and guides designers through the overall system design process. The design space is pruned by topological clustering of design points which groups similar topologies and new simulation points are selected via an ordered look up table that prevents infeasible random jumps in the design space. For the selected benchmarks, Prenaut can estimate the Pareto set up to 147x faster and the clustering information can reduce the design space up to 82% in comparison with a state-of-the-art evolutionary algorithm. © 2016 Elsevier B.V.","Clustering; Design space exploration; Machine learning; Symmetric multiprocessing","Elsevier B.V."
"Steponavičė I., Hyndman R.J., Smith-Miles K., Villanova L.","Dynamic algorithm selection for pareto optimal set approximation",2017,"Journal of Global Optimization",2,"10.1007/s10898-016-0420-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975730982&doi=10.1007%2fs10898-016-0420-x&partnerID=40&md5=89904b0cc1f43aca44f4fc3d15119314","This paper presents a meta-algorithm for approximating the Pareto optimal set of costly black-box multiobjective optimization problems given a limited number of objective function evaluations. The key idea is to switch among different algorithms during the optimization search based on the predicted performance of each algorithm at the time. Algorithm performance is modeled using a machine learning technique based on the available information. The predicted best algorithm is then selected to run for a limited number of evaluations. The proposed approach is tested on several benchmark problems and the results are compared against those obtained using any one of the candidate algorithms alone. © 2016, Springer Science+Business Media New York.","Algorithm selection; Classification; Expensive black-box function; Features; Hypervolume metric; Machine learning; Multiobjective optimization","Springer New York LLC"
"Salimi A., Lowther D.A.","Feature selection for facilitation of evolutionary multi-objective design optimization: Application to IPM motor design problems",2017,"IEEE CEFC 2016 - 17th Biennial Conference on Electromagnetic Field Computation",,"10.1109/CEFC.2016.7816205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011971682&doi=10.1109%2fCEFC.2016.7816205&partnerID=40&md5=468a3b35730f15b262636e74a73b8dc9","This paper discusses the application of statistical analysis and machine learning techniques, more specifically Correlation Feature Selection (CFS), in multi-objective design optimization of problems where the computational cost (of optimization) is dominated by the cost of solution evaluations, e.g. electromagnetic shape design problems. Here, CFS is used in order to reduce the dimensionality of the design space. As demonstrated through an Internal Permanent Magnet (IPM) motor design problem, the reduction information can be useful in decreasing the cost of optimization as well as detecting the dependencies of different variables in the vicinity of the optima. © 2016 IEEE.","Design Optimization; Dimensionality Reduction; Feature Selection; Machine Learning; Pareto Optimization","Institute of Electrical and Electronics Engineers Inc."
"Sagawa M., Aguirre H., Daolio F., Liefooghe A., Derbel B., Verel S., Tanaka K.","Learning variable importance to guide recombination",2017,"2016 IEEE Symposium Series on Computational Intelligence, SSCI 2016",2,"10.1109/SSCI.2016.7850229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016062251&doi=10.1109%2fSSCI.2016.7850229&partnerID=40&md5=0100b8f1201f5496fcd2777c55762bfd","In evolutionary multi-objective optimization, variation operators are crucially important to produce improving solutions, hence leading the search towards the most promising regions of the solution space. In this paper, we propose to use a machine learning modeling technique, namely random forest, in order to estimate, at each iteration in the course of the search process, the importance of decision variables with respect to convergence to the Pareto front. Accordingly, we are able to propose an adaptive mechanism guiding the recombination step with the aim of stressing the convergence of the so-obtained offspring. By conducting an experimental analysis using some of the WFG and DTLZ benchmark test problems, we are able to elicit the behavior of the proposed approach, and to demonstrate the benefits of incorporating machine learning techniques in order to design new efficient adaptive variation mechanisms. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Shadura O., Carminati F.","Stochastic performance tuning of complex simulation applications using unsupervised machine learning",2017,"2016 IEEE Symposium Series on Computational Intelligence, SSCI 2016",2,"10.1109/SSCI.2016.7850200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016055364&doi=10.1109%2fSSCI.2016.7850200&partnerID=40&md5=90c70f4c5e5d26b96fbe509ca254dfa9","Machine learning for complex multi-objective problems (MOP) can substantially speedup the discovery of solutions belonging to Pareto landscapes and improve Pareto front accuracy. Studying convergence speedup of multi-objective search on well-known benchmarks is an important step in the development of algorithms to optimize complex problems such as High Energy Physics particle transport simulations. In this paper we will describe how we perform this optimization via a tuning based on genetic algorithms and machine learning for MOP. One of the approaches described is based on the introduction of a specific multivariate analysis operator that can be used in case of expensive fitness function evaluations, in order to speed-up the convergence of the 'black-box' optimization problem. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Horn D., Bischl B.","Multi-objective parameter configuration of machine learning algorithms using model-based optimization",2017,"2016 IEEE Symposium Series on Computational Intelligence, SSCI 2016",13,"10.1109/SSCI.2016.7850221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014166972&doi=10.1109%2fSSCI.2016.7850221&partnerID=40&md5=2ea15dd6a72f1ed3ecc72c76f9b92bd6","The performance of many machine learning algorithms heavily depends on the setting of their respective hyperparameters. Many different tuning approaches exist, from simple grid or random search approaches to evolutionary algorithms and Bayesian optimization. Often, these algorithms are used to optimize a single performance criterion. But in practical applications, a single criterion may not be sufficient to adequately characterize the behavior of the machine learning method under consideration and the Pareto front of multiple criteria has to be considered. We propose to use model-based multi-objective optimization to efficiently approximate such Pareto fronts. © 2016 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Das A., Das S.","Feature weighting and selection with a Pareto-optimal trade-off between relevancy and redundancy",2017,"Pattern Recognition Letters",25,"10.1016/j.patrec.2017.01.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009874233&doi=10.1016%2fj.patrec.2017.01.004&partnerID=40&md5=a3ce4e1782514501bcb4d1b87ac5eed5","Feature Selection (FS) is an important pre-processing step in machine learning and it reduces the number of features/variables used to describe each member of a dataset. Such reduction occurs by eliminating some of the non-discriminating and redundant features and selecting a subset of the existing features with higher discriminating power among various classes in the data. In this paper, we formulate the feature selection as a bi-objective optimization problem of some real-valued weights corresponding to each feature. A subset of the weighted features is thus selected as the best subset for subsequent classification of the data. Two information theoretic measures, known as ‘relevancy’ and ‘redundancy’ are chosen for designing the objective functions for a very competitive Multi-Objective Optimization (MOO) algorithm called ‘Multi-Objective Evolutionary Algorithm based on Decomposition (MOEA/D)’. We experimentally determine the best possible constraints on the weights to be optimized. We evaluate the proposed bi-objective feature selection and weighting framework on a set of 15 standard datasets by using the popular k-Nearest Neighbor (k-NN) classifier. As is evident from the experimental results, our method appears to be quite competitive to some of the state-of-the-art FS methods of current interest. We further demonstrate the effectiveness of our framework by changing the choices of the optimization scheme and the classifier to Non-dominated Sorting Genetic Algorithm (NSGA)-II and Support Vector Machines (SVMs) respectively. © 2017 Elsevier B.V.","Classification; Feature selection; Feature weighting; Information measure; Multi-objective optimization","Elsevier B.V."
"Ojha V.K., Abraham A., Snášel V.","Ensemble of heterogeneous flexible neural trees using multiobjective genetic programming",2017,"Applied Soft Computing Journal",20,"10.1016/j.asoc.2016.09.035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992080670&doi=10.1016%2fj.asoc.2016.09.035&partnerID=40&md5=c5e51b40fd0486d3de25085afa2ee589","Machine learning algorithms are inherently multiobjective in nature, where approximation error minimization and model's complexity simplification are two conflicting objectives. We proposed a multiobjective genetic programming (MOGP) for creating a heterogeneous flexible neural tree (HFNT), tree-like flexible feedforward neural network model. The functional heterogeneity in neural tree nodes was introduced to capture a better insight of data during learning because each input in a dataset possess different features. MOGP guided an initial HFNT population towards Pareto-optimal solutions, where the final population was used for making an ensemble system. A diversity index measure along with approximation error and complexity was introduced to maintain diversity among the candidates in the population. Hence, the ensemble was created by using accurate, structurally simple, and diverse candidates from MOGP final population. Differential evolution algorithm was applied to fine-tune the underlying parameters of the selected candidates. A comprehensive test over classification, regression, and time-series datasets proved the efficiency of the proposed algorithm over other available prediction methods. Moreover, the heterogeneous creation of HFNT proved to be efficient in making ensemble system from the final population. © 2016 Elsevier B.V.","Approximation; Ensemble; Feature selection; Flexible neural tree; Pareto-based multiobjectives","Elsevier Ltd"
"Chen W., Liu J., He S.","Prior knowledge guided active modules identification: An integrated multi-objective approach",2017,"BMC Systems Biology",9,"10.1186/s12918-017-0388-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015190137&doi=10.1186%2fs12918-017-0388-2&partnerID=40&md5=d39ba094679f0fbbfcc1018842392b6c","Background: Active module, defined as an area in biological network that shows striking changes in molecular activity or phenotypic signatures, is important to reveal dynamic and process-specific information that is correlated with cellular or disease states. Methods: A prior information guided active module identification approach is proposed to detect modules that are both active and enriched by prior knowledge. We formulate the active module identification problem as a multi-objective optimisation problem, which consists two conflicting objective functions of maximising the coverage of known biological pathways and the activity of the active module simultaneously. Network is constructed from protein-protein interaction database. A beta-uniform-mixture model is used to estimate the distribution of p-values and generate scores for activity measurement from microarray data. A multi-objective evolutionary algorithm is used to search for Pareto optimal solutions. We also incorporate a novel constraints based on algebraic connectivity to ensure the connectedness of the identified active modules. Results: Application of proposed algorithm on a small yeast molecular network shows that it can identify modules with high activities and with more cross-talk nodes between related functional groups. The Pareto solutions generated by the algorithm provides solutions with different trade-off between prior knowledge and novel information from data. The approach is then applied on microarray data from diclofenac-treated yeast cells to build network and identify modules to elucidate the molecular mechanisms of diclofenac toxicity and resistance. Gene ontology analysis is applied to the identified modules for biological interpretation. Conclusions: Integrating knowledge of functional groups into the identification of active module is an effective method and provides a flexible control of balance between pure data-driven method and prior information guidance. © 2017 The Author(s).","Active module identification; Multi-objective evolutionary algorithm; Prior knowlege","BioMed Central Ltd."
"Kpotufe S., Verma N.","Time-accuracy tradeoffs in kernel prediction: Controlling prediction quality",2017,"Journal of Machine Learning Research",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020692065&partnerID=40&md5=78fe53b772e63356ce4d8b072d100c14","Kernel regression or classification (also referred to as weighted -NN methods in Machine Learning) are appealing for their simplicity and therefore ubiquitous in data analysis. However, practical implementations of kernel regression or classification consist of quantizing or sub-sampling data for improving time efficiency, often at the cost of prediction quality. While such tradeoffs are necessary in practice, their statistical implications are generally not well understood, hence practical implementations come with few performance guarantees. In particular, it is unclear whether it is possible to maintain the statistical accuracy of kernel prediction—crucial in some applications—while improving prediction time. The present work provides guiding principles for combining kernel prediction with data-quantization so as to guarantee good tradeoffs between prediction time and accuracy, and in particular so as to approximately maintain the good accuracy of vanilla kernel prediction. Furthermore, our tradeoff guarantees are worked out explicitly in terms of a tuning parameter which acts as a knob that favors either time or accuracy depending on practical needs. On one end of the knob, prediction time is of the same order as that of single-nearest-neighbor prediction (which is statistically inconsistent) while maintaining consistency; on the other end of the knob, the prediction risk is nearly minimax-optimal (in terms of the original data size) while still reducing time complexity. The analysis thus reveals the interaction between the data-quantization approach and the kernel prediction method, and most importantly gives explicit control of the tradeoff to the practitioner rather than fixing the tradeoff in advance or leaving it opaque. The theoretical results are validated on data from a range of real-world application domains; in particular we demonstrate that the theoretical knob performs as expected. © 2017 Samory Kpotufe and Nakul Verma.",,"Microtome Publishing"
"de Medeiros T.H., Rocha H.P., Torres F.S., Takahashi R.H.C., Braga A.P.","Multi-objective Decision in Machine Learning",2017,"Journal of Control, Automation and Electrical Systems",5,"10.1007/s40313-016-0295-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014862668&doi=10.1007%2fs40313-016-0295-6&partnerID=40&md5=648804e246d696c63301d0787ee6819b","This work presents a novel approach for decision-making for multi-objective binary classification problems. The purpose of the decision process is to select within a set of Pareto-optimal solutions, one model that minimizes the structural risk (generalization error). This new approach utilizes a kind of prior knowledge that, if available, allows the selection of a model that better represents the problem in question. Prior knowledge about the imprecisions of the collected data enables the identification of the region of equivalent solutions within the set of Pareto-optimal solutions. Results for binary classification problems with sets of synthetic and real data indicate equal or better performance in terms of decision efficiency compared to similar approaches. © 2016, Brazilian Society for Automatics--SBA.","Classification; Decision-making; Machine learning; Multi-objective optimization","Springer New York LLC"
"Crabtree N.M., Moore J.H., Bowyer J.F., George N.I.","Multi-class computational evolution: Development, benchmark evaluation and application to RNA-Seq biomarker discovery",2017,"BioData Mining",6,"10.1186/s13040-017-0134-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018556153&doi=10.1186%2fs13040-017-0134-8&partnerID=40&md5=7ce87cc31a40ef70f57c40dea7597810","Background: A computational evolution system (CES) is a knowledge discovery engine that can identify subtle, synergistic relationships in large datasets. Pareto optimization allows CESs to balance accuracy with model complexity when evolving classifiers. Using Pareto optimization, a CES is able to identify a very small number of features while maintaining high classification accuracy. A CES can be designed for various types of data, and the user can exploit expert knowledge about the classification problem in order to improve discrimination between classes. These characteristics give CES an advantage over other classification and feature selection algorithms, particularly when the goal is to identify a small number of highly relevant, non-redundant biomarkers. Previously, CESs have been developed only for binary class datasets. In this study, we developed a multi-class CES. Results: The multi-class CES was compared to three common feature selection and classification algorithms: support vector machine (SVM), random k-nearest neighbor (RKNN), and random forest (RF). The algorithms were evaluated on three distinct multi-class RNA sequencing datasets. The comparison criteria were run-time, classification accuracy, number of selected features, and stability of selected feature set (as measured by the Tanimoto distance). The performance of each algorithm was data-dependent. CES performed best on the dataset with the smallest sample size, indicating that CES has a unique advantage since the accuracy of most classification methods suffer when sample size is small. Conclusion: The multi-class extension of CES increases the appeal of its application to complex, multi-class datasets in order to identify important biomarkers and features. © 2017 The Author(s).","Artificial intelligence; Biomarker discovery; Classification; Data mining; Evolutionary algorithm; Feature selection; Genetic programming; Machine learning; Multi-class","BioMed Central Ltd."
"Hamm J.","Enhancing utility and privacy with noisy minimax filters",2017,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",10,"10.1109/ICASSP.2017.7953386","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023752424&doi=10.1109%2fICASSP.2017.7953386&partnerID=40&md5=a76892ed2de86703d695276002139819","Preserving privacy of continuous and/or high-dimensional data such as images, videos and audios is challenging. Syntactic anonymization methods were proposed typically for discrete data types and can be unsuitable. Differential privacy, which provides a stricter type of privacy, has shown more success in sanitizing continuous data. However, both syntactic and differential privacy are susceptible to inference attacks, i.e., an adversary can accurately guess sensitive attributes from insensitive attributes. On the other hand, minimax filters were proposed previously to minimize the accuracy of inference while maximizing utility at the same time. The paper presents noisy minimax filter that combines minimax filter and differentially private mechanism, which can attain high average utility and protection against inference attacks and a formal worst-case privacy guarantee. The proposed algorithm is demonstrated with real databases of faces, voices, and motion data. © 2017 IEEE.","differential privacy; machine learning; minimax optimization; postprocessing; syntactic anonymity","Institute of Electrical and Electronics Engineers Inc."
"Chen Y., Yu Z., Li B.","Clockwork: Scheduling Cloud Requests in Mobile Applications",2017,"2017 14th Annual IEEE International Conference on Sensing, Communication, and Networking, SECON 2017",,"10.1109/SAHCN.2017.7964910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031685530&doi=10.1109%2fSAHCN.2017.7964910&partnerID=40&md5=de1e3cf212cbade4c6665a45f00d5cd1","It is essential for mobile application developers to manage backend resources to serve dynamic user requests from the frontend. For a typical mobile application, the rate at which the user requests arrive at the backend fluctuates dramatically. However, it is difficult or expensive to frequently adjust the capacity of the backend to meet the request demand. In this paper, we present Clockwork, a third-party cloud service, which smooths the demand profile by redistributing delay-tolerant requests and prioritizing delay-sensitive requests, so that sufficient capacity can be provided with reduced cost and wastage. To begin with, Clockwork plans the optimal backend capacity on a relatively long timescale based on future demand estimated by machine learning algorithms. We discuss pros and cons of various simple machine learning algorithms and advanced deep learning algorithms, in terms of their prediction accuracy and training time. Then, Clockwork schedules user requests on a shorter timescale through a fair and Pareto- optimal rate allocation. We implemented a fully-functional prototype of Clockwork on cloud servers and user mobile devices. The experimental results show that Clockwork can effectively help developers cut cost, as well as improve the backend utilization. © 2017 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Nardi L., Bodin B., Saeedi S., Vespa E., Davison A.J., Kelly P.H.J.","Algorithmic performance-accuracy trade-off in 3D vision applications using HyperMapper",2017,"Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2017",8,"10.1109/IPDPSW.2017.107","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028057616&doi=10.1109%2fIPDPSW.2017.107&partnerID=40&md5=014691b460b1235717626ba43466d69f","In this paper we investigate an emerging application, 3D scene understanding, likely to be significant in the mobile space in the near future. The goal of this exploration is to reduce execution time while meeting our quality of result objectives. In previous work, we showed for the first time that it is possible to map this application to power constrained embedded systems, highlighting that decision choices made at the algorithmic design-level have the most significant impact. As the algorithmic design space is too large to be exhaustively evaluated, we use a previously introduced multi-objective random forest active learning prediction framework dubbed HyperMapper, to find good algorithmic designs. We show that HyperMapper generalizes on a recent cutting edge 3D scene understanding algorithm and on a modern GPU-based computer architecture. HyperMapper is able to beat an expert human hand-tuning the algorithmic parameters of the class of computer vision applications taken under consideration in this paper automatically. In addition, we use crowd-sourcing using a 3D scene understanding Android app to show that the Pareto front obtained on an embedded system can be used to accelerate the same application on all the 83 smart-phones and tablets with speedups ranging from 2x to over 12x. © 2017 IEEE.","computer vision; crowd- sourcing; design space exploration; embedded systems; GPU; machine learning; SLAM","Institute of Electrical and Electronics Engineers Inc."
"Zutty J., Rohling G.","Solving test case based problems with fuzzy dominance",2017,"GECCO 2017 - Proceedings of the 2017 Genetic and Evolutionary Computation Conference",1,"10.1145/3071178.3071234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026386995&doi=10.1145%2f3071178.3071234&partnerID=40&md5=bf0841e7fb0bfec294f0eeb6daf44d40","Genetic algorithms and genetic programming lend themselves well to the field of machine learning, which involves solving test case based problems. However, most traditional multi-objective selection methods work with scalar objectives, such as minimizing false negative and false positive rates, that are computed from underlying test cases. In this paper, we propose a new fuzzy selection operator that takes into account the statistical nature of machine learning problems based on test cases. Rather than use a Pareto rank or strength computed from scalar objectives, such as with NSGA2 or SPEA2, we will compute a probability of Pareto optimality. This will be accomplished through covariance estimation and Markov chain Monte Carlo simulation in order to generate probabilistic objective scores for each individual. We then compute a probability that each individual will generate a Pareto optimal solution. This probability is directly used with a roulette wheel selection technique. Our method's performance is evaluated on the evolution of a feature selection vector for a binary classification on each of eight different activities. Fuzzy selection performance varies, outperforming both NSGA2 and SPEA2 in both speed (measured in generations) and solution quality (measured by area under the curve) in some cases, while underperforming in others. © 2017 ACM.","Genetic Algorithms; Machine Learning; Markov Chain Monte Carlo; Pareto Dominance","Association for Computing Machinery, Inc"
"Liskowski P., Krawiec K.","Discovery of search objectives in continuous domains",2017,"GECCO 2017 - Proceedings of the 2017 Genetic and Evolutionary Computation Conference",5,"10.1145/3071178.3071344","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026371934&doi=10.1145%2f3071178.3071344&partnerID=40&md5=2e8c2fe345ce9ecb0fe31d3f53b94ade","In genetic programming (GP), the outcomes of the evaluation phase can be represented as an interaction matrix, with rows corresponding to programs in a population and columns corresponding to tests that define a program synthesis task. Recent contributions on Discovery of Objectives via Clustering (DOC) and Discovery of Objectives by Factorization of interaction matrix (DOF) show that informative characterizations of programs can be automatically derived from interaction matrices in discrete domains and used as search objectives in multidimensional setting. In this paper, we propose analogous methods for continuous domains and compare them with conventional GP that uses tournament selection, Age-Fitness Pareto Optimization, and GP with epsilon-lexicase selection. Experiments show that the proposed methods are effective for symbolic regression, systematically producing better-fitting models than the two former baselines, and surpassing epsilon-lexicase selection on some problems. We also investigate the hybrids of the proposed approach with the baselines, concluding that hybridization of DOC with epsilon-lexicase leads to the best overall results. © 2017 ACM.","Genetic Programming; Machine Learning; Multiobjective optimization; Nonnegative Matrix Factorization","Association for Computing Machinery, Inc"
"Onan A., Korukoğlu S., Bulut H.","A hybrid ensemble pruning approach based on consensus clustering and multi-objective evolutionary algorithm for sentiment classification",2017,"Information Processing and Management",112,"10.1016/j.ipm.2017.02.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014936437&doi=10.1016%2fj.ipm.2017.02.008&partnerID=40&md5=a5a3391b10db6f40f3d5571b0537d780","Sentiment analysis is a critical task of extracting subjective information from online text documents. Ensemble learning can be employed to obtain more robust classification schemes. However, most approaches in the field incorporated feature engineering to build efficient sentiment classifiers. The purpose of our research is to establish an effective sentiment classification scheme by pursuing the paradigm of ensemble pruning. Ensemble pruning is a crucial method to build classifier ensembles with high predictive accuracy and efficiency. Previous studies employed exponential search, randomized search, sequential search, ranking based pruning and clustering based pruning. However, there are tradeoffs in selecting the ensemble pruning methods. In this regard, hybrid ensemble pruning schemes can be more promising. In this study, we propose a hybrid ensemble pruning scheme based on clustering and randomized search for text sentiment classification. Furthermore, a consensus clustering scheme is presented to deal with the instability of clustering results. The classifiers of the ensemble are initially clustered into groups according to their predictive characteristics. Then, two classifiers from each cluster are selected as candidate classifiers based on their pairwise diversity. The search space of candidate classifiers is explored by the elitist Pareto-based multi-objective evolutionary algorithm. For the evaluation task, the proposed scheme is tested on twelve balanced and unbalanced benchmark text classification tasks. In addition, the proposed approach is experimentally compared with three ensemble methods (AdaBoost, Bagging and Random Subspace) and three ensemble pruning algorithms (ensemble selection from libraries of models, Bagging ensemble selection and LibD3C algorithm). Results demonstrate that the consensus clustering and the elitist pareto-based multi-objective evolutionary algorithm can be effectively used in ensemble pruning. The experimental analysis with conventional ensemble methods and pruning algorithms indicates the validity and effectiveness of the proposed scheme. © 2017 Elsevier Ltd","Consensus clustering; Ensemble pruning; Multi-objective evolutionary algorithm; Sentiment classification","Elsevier Ltd"
"Mariani G., Anghel A., Jongerius R., Dittmann G.","Predicting Cloud Performance for HPC Applications: A User-Oriented Approach",2017,"Proceedings - 2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, CCGRID 2017",13,"10.1109/CCGRID.2017.11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027444992&doi=10.1109%2fCCGRID.2017.11&partnerID=40&md5=e1815e37517fd924bb133afa76715cb9","Cloud computing enables end users to execute high-performance computing applications by renting the required computing power. This pay-for-use approach enables small enterprises and startups to run HPC-related businesses with a significant saving in capital investment and a short time to market. When deploying an application in the cloud, the users may a) fail to understand the interactions of the application with the software layers implementing the cloud system, b) be unaware of some hardware details of the cloud system, and c) fail to understand how sharing part of the cloud system with other users might degrade application performance. These misunderstandings may lead the users to select suboptimal cloud configurations in terms of cost or performance. To aid the users in selecting the optimal cloud configuration for their applications, we suggest that the cloud provider generate a prediction model for the provided system. We propose applying machine-learning techniques to generate this prediction model. First, the cloud provider profiles a set of training applications by means of a hardware-independent profiler and then executes these applications on a set of training cloud configurations to collect actual performance values. The prediction model is trained to learn the dependencies of actual performance data on the application profile and cloud configuration parameters. The advantage of using a hardware-independent profiler is that the cloud users and the cloud provider can analyze applications on different machines and interface with the same prediction model. We validate the proposed methodology for a cloud system implemented with OpenStack. We apply the prediction model to the NAS parallel benchmarks. The resulting relative error is below 15% and the Pareto optimal cloud configurations finally found when maximizing application speed and minimizing execution cost on the prediction model are also at most 15% away from the actual optimal solutions. © 2017 IEEE.","Cloud; Design of experiments; High performance computing; Machine learning; Performance prediction; Random forest","Institute of Electrical and Electronics Engineers Inc."
"Zangari M., Pozo A., Santana R., Mendiburu A.","A decomposition-based binary ACO algorithm for the multiobjective UBQP",2017,"Neurocomputing",15,"10.1016/j.neucom.2016.09.122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012874274&doi=10.1016%2fj.neucom.2016.09.122&partnerID=40&md5=7a7ef628d00f7bd22793cb441c272d22","The multiobjective unconstrained binary quadratic programming (mUBQP) is a combinatorial optimization problem which is able to represent several multiobjective optimization problems (MOPs). The problem can be characterized by the number of variables, the number of objectives and the objective correlation strength. Multiobjective evolutionary algorithms (MOEAs) are known as an efficient technique for solving MOPs. Moreover, several recent studies have shown the effectiveness of the MOEA/D framework applied to different MOPs. Previously, we have presented a preliminary study on an algorithm based on MOEA/D framework and the bio-inspired metaheuristic called binary ant colony optimization (BACO). The metaheuristic uses a positive feedback mechanism according to the best solutions found so far to update a probabilistic model which maintains the learned information. This paper presents the improved MOEA/D-BACO framework for solving the mUBQP. The components (i) mutation-like effect, and (ii) diversity preserving method are incorporated into the framework to enhance its search ability avoiding the premature convergence of the model and consequently maintaining a more diverse population of solutions. Experimental studies were conducted on a set of mUBQP instances. The results have shown that the proposed MOEA/D-BACO has outperformed MOEA/D, which uses genetic operators, in most of the test instances. Moreover, the algorithm has produced competitive results in comparison to the best approximated Pareto fronts from the literature. © 2017 Elsevier B.V.","Binary Ant Colony Optimization; MOEA/D; mUBQP; Multiobjective optimization problems; Probabilistic modeling","Elsevier B.V."
"Klusowski J.M., Barron A.R.","Minimax lower bounds for ridge combinations including neural nets",2017,"IEEE International Symposium on Information Theory - Proceedings",4,"10.1109/ISIT.2017.8006754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034088357&doi=10.1109%2fISIT.2017.8006754&partnerID=40&md5=4bcf8ef461a263987023d482480809a2","Estimation of functions of d variables is considered using ridge combinations of the form Σmk=1 c1, kφ(Σdj=1c0, j, kxj-bk) where the activation function φ is a function with bounded value and derivative. These include single-hidden layer neural networks, polynomials, and sinusoidal models. From a sample of size n of possibly noisy values at random sites X B = [-1, 1]d, the minimax mean square error is examined for functions in the closure of the ℓ1 hull of ridge functions with activation φ. It is shown to be of order d/n to a fractional power (when d is of smaller order than n), and to be of order (log d)/n to a fractional power (when d is of larger order than n). Dependence on constraints v0 and v1 on the ℓ1 norms of inner parameter co and outer parameter c1, respectively, is also examined. Also, lower and upper bounds on the fractional power are given. The heart of the analysis is development of information-theoretic packing numbers for these classes of functions. © 2017 IEEE.","Constant weight codes; Generalization error; Greedy algorithms; High-dimensional data analysis; Learning theory; Machine learning; Metric entropy; Neural nets; Nonlinear regression; Nonparametric regression; Packing sets; Penalization; Polynomial nets; Sinusoidal nets","Institute of Electrical and Electronics Engineers Inc."
"Roy S., Ma Y., Miao J., Yu B.","A learning bridge from architectural synthesis to physical design for exploring power efficient high-performance adders",2017,"Proceedings of the International Symposium on Low Power Electronics and Design",6,"10.1109/ISLPED.2017.8009168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028586797&doi=10.1109%2fISLPED.2017.8009168&partnerID=40&md5=37ee6e28c81e8599b69ec443b57aee0e","In spite of maturity to the modern electronic design automation (EDA) tools, optimized designs at architectural stage may become sub-optimal after going through physical design flow. Adder design has been such a long studied fundamental problem in VLSI industry yet designers cannot achieve optimal solutions by running EDA tools on the set of available prefix adder architectures. In this paper, we enhance a state-of-the-art prefix adder synthesis algorithm to obtain a much wider solution space in architectural domain. On top of that, a machine learning based design space exploration methodology is applied to predict the Pareto frontier of the adders in physical domain, which is infeasible by exhaustively running EDA tools for innumerable architectural solutions. Experimental results demonstrate that our framework can achieve near-optimal delay vs. power/area Pareto frontier over a wide design space, bridging the gap between architectural and physical designs. © 2017 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Muller H., Bosse S., Pohl M., Turowski K.","Capacity planning as a service for enterprise standard software",2017,"Proceedings - 2017 IEEE 19th Conference on Business Informatics, CBI 2017",,"10.1109/CBI.2017.25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029455808&doi=10.1109%2fCBI.2017.25&partnerID=40&md5=7b4d29af54b4875cd4b39fe01182d8a6","Too often, capacity planning activities that are crucial to software performance are being pushed to late development phases where trivial measurement-based assessment techniques can be employed on enterprise applications that are nearing completion. This procedure is highly inefficient, time consuming, and may result in disproportionately high correction costs to meet existing service level agreements. However, enterprise applications nowadays excessively make use of standard software that is shipped by large software vendors to a wide range of customers. Therefore, an application similar to the one whose capacity is being planned may already be in production state and constantly produce log data as part of application performance monitoring facilities. In this paper, we demonstrate how potential capacity planning service providers can leverage the dissemination effects of standard software by applying machine learning techniques on measurement data from various running enterprise applications. Utilizing prediction models that were trained on a large scale of monitoring data enables cost-efficient measurement-based prediction techniques to be used in early design phases. Therefore, we integrate knowledge discovery activities into well-known capacity planning steps, which we adapt to the special characteristics of enterprise applications. We evaluate the feasibility of the modeled process using measurement data from more than 1,800 productively running enterprise applications in order to predict the response time of a widely used standard business transaction. Based on the trained model, we demonstrate how to simulate and analyze future workload scenarios. Using a Pareto approach, we were able to identify cost-effective design alternatives for a planned enterprise application. © 2017 IEEE.","Big data; Business transaction; Machine learning; Prediction model; Response time; Service design","Institute of Electrical and Electronics Engineers Inc."
"Nojima Y., Arahari K., Takemura S., Ishibuchi H.","Multiobjective fuzzy genetics-based machine learning based on MOEA/D with its modifications",2017,"IEEE International Conference on Fuzzy Systems",3,"10.1109/FUZZ-IEEE.2017.8015749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030173675&doi=10.1109%2fFUZZ-IEEE.2017.8015749&partnerID=40&md5=08e875dc3482ef7545aa2fcb1da90090","Various evolutionary multiobjective optimization (EMO) algorithms have been used in the field of evolutionary fuzzy systems (EFS), because EMO algorithms can easily handle multiple objective functions such as the accuracy maximization and complexity minimization for fuzzy system design. Most EMO algorithms used in EFS are Pareto dominance-based algorithms such as NSGA-II, SPEA2, and PAES. There are a few studies where other types of EMO algorithms are used in EFS. In this paper, we apply a multiobjective evolutionary algorithm based on decomposition called MOEA/D to EFS for fuzzy classifier design. MOEA/D is one of the most well-known decomposition-based EMO algorithms. The key idea is to divide a multiobjective optimization problem into a number of single-objective problems using a set of uniformly distributed weight vectors in a scalarizing function. We propose a new scalarizing function called an accuracy-oriented function (AOF) which is specialized for classifier design. We examine the effects of using AOF in MOEA/D on the search ability of our multiobjective fuzzy genetics-based machine learning (GBML). We also examine the synergy effect of MOEA/D with AOF and parallel distributed implementation of fuzzy GBML on the generalization ability. © 2017 IEEE.","Accuracy-oriented scalarizingfunction; Evolutionary fuzzy systems; Fuzzy classifier design; MOEA/D","Institute of Electrical and Electronics Engineers Inc."
"Lakshika E., Barlow M., Easton A.","Understanding the Interplay of Model Complexity and Fidelity in Multiagent Systems via an Evolutionary Framework",2017,"IEEE Transactions on Computational Intelligence and AI in Games",7,"10.1109/TCIAIG.2016.2560882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030109394&doi=10.1109%2fTCIAIG.2016.2560882&partnerID=40&md5=0a0ddcee7fb3f3435adc2b1570733b78","Modern video games come with highly realistic graphics enabling the players to interact with visually rich virtual worlds. Realistic (life-like) animation of nonplayer characters (NPCs) in such virtual worlds is particularly important to enhance the gaming experience. Multiagent systems are one effective approach to synthesize life-like behaviors and interactions by codifying simple rules into NPCs (each NPC as an autonomous agent). However, such behaviors generally come at the cost of increasing computational expense and complexity in terms of aspects such as number of rules and parameters. Therefore, the desire for high fidelity (highly realistic) behaviors is often in conflict with the drive for low complexity. Multiobjective evolutionary algorithms provide a sophisticated mechanism to optimize two or more conflicting objectives simultaneously. However, evolutionary computing techniques need an appropriate objective function to drive the exploration in the correct direction. Pairing of evolutionary techniques and multiagent systems is challenging in the classes of problems in which the fitness is evaluated based on human aesthetic judgment rather than on objective forms of measurements. In this study, we present a multiobjective evolutionary framework to evolve low complexity and high fidelity multiagent systems by utilizing a machine learning system trained by bootstrapping human aesthetic judgment. We have gathered empirical data in three problem areas - simulation of conversational group dynamics, sheepdog herding behaviors, and traffic dynamics, and show the effectiveness of our approach in deriving low complexity and high fidelity multiagent systems. Further, we have identified common properties of the Pareto-optimal frontiers in the three problem areas that can ultimately lead to an understanding of a relationship between simulation model complexity and behavior fidelity. This understanding will be useful in deciding which level of behavioral fidelity is required for the characters in video games based on the distance to the camera, importance to the scene, and available computational resources. © 2009-2012 IEEE.","Complexity; fidelity; level of detail artificial intelligence (LOD AI); multiagent systems; multiobjective optimization","Institute of Electrical and Electronics Engineers Inc."
"Fernández A., Carmona C.J., José Del Jesus M., Herrera F.","A pareto-based ensemble with feature and instance selection for learning from multi-class imbalanced datasets",2017,"International Journal of Neural Systems",36,"10.1142/S0129065717500289","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021173836&doi=10.1142%2fS0129065717500289&partnerID=40&md5=b5bafde200aa81e6d37dc5c9bfe1bb03","Imbalanced classification is related to those problems that have an uneven distribution among classes. In addition to the former, when instances are located into the overlapped areas, the correct modeling of the problem becomes harder. Current solutions for both issues are often focused on the binary case study, as multi-class datasets require an additional effort to be addressed. In this research, we overcome these problems by carrying out a combination between feature and instance selections. Feature selection will allow simplifying the overlapping areas easing the generation of rules to distinguish among the classes. Selection of instances from all classes will address the imbalance itself by finding the most appropriate class distribution for the learning task, as well as possibly removing noise and difficult borderline examples. For the sake of obtaining an optimal joint set of features and instances, we embedded the searching for both parameters in a Multi-Objective Evolutionary Algorithm, using the C4.5 decision tree as baseline classifier in this wrapper approach. The multi-objective scheme allows taking a double advantage: the search space becomes broader, and we may provide a set of different solutions in order to build an ensemble of classifiers. This proposal has been contrasted versus several state-of-the-art solutions on imbalanced classification showing excellent results in both binary and multi-class problems. © 2017 World Scientific Publishing Company.","ensembles; feature selection; Imbalanced classification; instance selection; multi-class; multi-objective evolutionary algorithms; overlapping","World Scientific Publishing Co. Pte Ltd"
"Che J., Yang Y., Li L., Bai X., Zhang S., Deng C.","Maximum relevance minimum common redundancy feature selection for nonlinear data",2017,"Information Sciences",72,"10.1016/j.ins.2017.05.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019245357&doi=10.1016%2fj.ins.2017.05.013&partnerID=40&md5=fca33751d597401bc87c6bc514a5fa30","In recent years, feature selection based on relevance redundancy trade-off criteria has become a very promising and popular approach in the field of machine learning. However, the existing algorithmic frameworks of mutual information feature selection have certain limitations for the common feature selection problems in practice. To overcome these limitations, the idea of a new framework is developed by introducing a novel maximum relevance and minimum common redundancy criterion and a minimax nonlinear optimization approach. In particular, a novel mutual information feature selection method based on the normalization of the maximum relevance and minimum common redundancy (N-MRMCR-MI) is presented, which produces a normalized value in the range [0, 1] and results in a regression problem. We perform extensive experimental comparisons over numerous state-of-art algorithms using different forecasts (Bayesian Additive Regression tree, treed Gaussian process, k-NN, and SVM) and different data sets (two simulated and five real datasets). The results show that the proposed algorithm outperforms the others in terms of feature selection and forecasting accuracy. © 2017 Elsevier Inc.","Feature selection; Maximal relevance; Minimal common redundancy; Mutual information; Normalization","Elsevier Inc."
"Mannion P., Devlin S., Mason K., Duggan J., Howley E.","Policy invariance under reward transformations for multi-objective reinforcement learning",2017,"Neurocomputing",14,"10.1016/j.neucom.2017.05.090","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023761455&doi=10.1016%2fj.neucom.2017.05.090&partnerID=40&md5=edcfc572092078ef87028bc4e12a2a0c","Reinforcement Learning (RL) is a powerful and well-studied Machine Learning paradigm, where an agent learns to improve its performance in an environment by maximising a reward signal. In multi-objective Reinforcement Learning (MORL) the reward signal is a vector, where each component represents the performance on a different objective. Reward shaping is a well-established family of techniques that have been successfully used to improve the performance and learning speed of RL agents in single-objective problems. The basic premise of reward shaping is to add an additional shaping reward to the reward naturally received from the environment, to incorporate domain knowledge and guide an agent's exploration. Potential-Based Reward Shaping (PBRS) is a specific form of reward shaping that offers additional guarantees. In this paper, we extend the theoretical guarantees of PBRS to MORL problems. Specifically, we provide theoretical proof that PBRS does not alter the true Pareto front in both single- and multi-agent MORL. We also contribute the first published empirical studies of the effect of PBRS in single- and multi-agent MORL problems. © 2017 Elsevier B.V.","Multi-agent systems; Multi-objective; Potential-based; Reinforcement learning; Reward shaping","Elsevier B.V."
"Ruiz-Montiel M., Mandow L., Pérez-de-la-Cruz J.-L.","A temporal difference method for multi-objective reinforcement learning",2017,"Neurocomputing",12,"10.1016/j.neucom.2016.10.100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021340135&doi=10.1016%2fj.neucom.2016.10.100&partnerID=40&md5=96bcf2bab2134268a18aa60ccef26f43","This work describes MPQ-learning, an algorithm that approximates the set of all deterministic non-dominated policies in multi-objective Markov decision problems, where rewards are vectors and each component stands for an objective to maximize. MPQ-learning generalizes directly the ideas of Q-learning to the multi-objective case. It can be applied to non-convex Pareto frontiers and finds both supported and unsupported solutions. We present the results of the application of MPQ-learning to some benchmark problems. The algorithm solves successfully these problems, so showing the feasibility of this approach. We also compare MPQ-learning to a standard linearization procedure that computes only supported solutions and show that in some cases MPQ-learning can be as effective as the scalarization method. © 2017 Elsevier B.V.","MOMDPs; Multi-objective optimization; Q-learning; Reinforcement learning","Elsevier B.V."
"Parisi S., Pirotta M., Peters J.","Manifold-based multi-objective policy search with sample reuse",2017,"Neurocomputing",14,"10.1016/j.neucom.2016.11.094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021240639&doi=10.1016%2fj.neucom.2016.11.094&partnerID=40&md5=31f45a6b2c49b0b8d138e921505cfd38","Many real-world applications are characterized by multiple conflicting objectives. In such problems optimality is replaced by Pareto optimality and the goal is to find the Pareto frontier, a set of solutions representing different compromises among the objectives. Despite recent advances in multi-objective optimization, achieving an accurate representation of the Pareto frontier is still an important challenge. Building on recent advances in reinforcement learning and multi-objective policy search, we present two novel manifold-based algorithms to solve multi-objective Markov decision processes. These algorithms combine episodic exploration strategies and importance sampling to efficiently learn a manifold in the policy parameter space such that its image in the objective space accurately approximates the Pareto frontier. We show that episode-based approaches and importance sampling can lead to significantly better results in the context of multi-objective reinforcement learning. Evaluated on three multi-objective problems, our algorithms outperform state-of-the-art methods both in terms of quality of the learned Pareto frontier and sample efficiency. © 2017 Elsevier B.V.","Black-box optimization; Importance sampling; Multi-objective; Policy search; Reinforcement learning","Elsevier B.V."
"Sagawa M., Aguirre H., Daolio F., Liefooghe A., Derbel B., Verel S., Tanaka K.","Learning Variable Importance to Guide Recombination on Many-Objective Optimization",2017,"Proceedings - 2017 6th IIAI International Congress on Advanced Applied Informatics, IIAI-AAI 2017",2,"10.1109/IIAI-AAI.2017.158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040615462&doi=10.1109%2fIIAI-AAI.2017.158&partnerID=40&md5=2a1b161e27e72029e23c7c0400176a86","There are numerous many-objective real-world problems in various application domains for which it is difficult or time-consuming to derive Pareto optimal solutions. In an evolutionary algorithm, variation operators such as recombination and mutation are extremely important to obtain an effective solution search. In this paper, we study a machine learning-enhanced recombination that incorporates an intelligent variable selection method. The method is based on the importance of variables with respect to convergence to the Pareto front. We verify the performance of the enhanced recombination on benchmark test problems with three or more objectives using the many-objective evolutionary algorithm AeSeH as a baseline algorithm. Results show that variable importance can enhance the performance of many-objective evolutionary algorithms. © 2017 IEEE.","Evolutionary algorithm; Machine learning; Many-objective optimization; Multi-objective optimization; Random forest; Variable importance","Institute of Electrical and Electronics Engineers Inc."
"Huang C., Kairouz P., Chen X., Sankar L., Rajagopal R.","Context-aware generative adversarial privacy",2017,"Entropy",50,"10.3390/e19120656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038374221&doi=10.3390%2fe19120656&partnerID=40&md5=6d78676f8cfb34923f9d74bcf14e43ee","Preserving the utility of published datasets while simultaneously providing provable privacy guarantees is a well-known challenge. On the one hand, context-free privacy solutions, such as differential privacy, provide strong privacy guarantees, but often lead to a significant reduction in utility. On the other hand, context-aware privacy solutions, such as information theoretic privacy, achieve an improved privacy-utility tradeoff, but assume that the data holder has access to dataset statistics. We circumvent these limitations by introducing a novel context-aware privacy framework called generative adversarial privacy (GAP). GAP leverages recent advancements in generative adversarial networks (GANs) to allow the data holder to learn privatization schemes from the dataset itself. Under GAP, learning the privacy mechanism is formulated as a constrained minimax game between two players: a privatizer that sanitizes the dataset in a way that limits the risk of inference attacks on the individuals' private variables, and an adversary that tries to infer the private variables from the sanitized dataset. To evaluate GAP's performance, we investigate two simple (yet canonical) statistical dataset models: (a) the binary data model; and (b) the binary Gaussian mixture model. For both models, we derive game-theoretically optimal minimax privacy mechanisms, and show that the privacy mechanisms learned from data (in a generative adversarial fashion) match the theoretically optimal ones. This demonstrates that our framework can be easily applied in practice, even in the absence of dataset statistics. © 2017 by the authors.","Adversarial network; Differential privacy; Error probability games; Generative adversarial networks; Generative adversarial privacy; Information theoretic privacy; Machine learning; Mutual information privacy; Privatizer network; Statistical data privacy","MDPI AG"
"Fang Y., Liu Z.-H., Min F.","A PSO algorithm for multi-objective cost-sensitive attribute reduction on numeric data with error ranges",2017,"Soft Computing",8,"10.1007/s00500-016-2260-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978173215&doi=10.1007%2fs00500-016-2260-5&partnerID=40&md5=ab1758405d86a43433f87ea35dfca991","Multi-objective cost-sensitive attribute reduction is an attractive problem in supervised machine learning. Most research has focused on single-objective minimal test cost reduction or dealt with symbolic data. In this paper, we propose a particle swarm optimization algorithm for the attribute reduction problem on numeric data with multiple costs and error ranges and use three metrics with which to evaluate the performance of the algorithm. The proposed algorithm benefits from a fitness function based on the positive region, the selected n types of the test cost, a set of constant weight values wik, and a designated non-positive exponent λ. We design a learning strategy by setting dominance principles, which ensures the preservation of Pareto-optimal solutions and the rejection of redundant solutions. With different parameter settings, our PSO algorithm searches for a sub-optimal reduct set. Finally, we test our algorithm on seven UCI (University of California, Irvine) datasets. Comparisons with alternative approaches including the λ-weighted method and exhaustive calculation method of reduction are analyzed. Experimental results indicate that our heuristic algorithm outperforms existing algorithms. © 2016, Springer-Verlag Berlin Heidelberg.","Attribute reduction; Cost-sensitive learning; Particle swarm optimization; Rough sets","Springer Verlag"
"Vatanpavar K., Faruque M.A.A.","ACQUA: Adaptive and cooperative quality-aware control for automotive cyber-physical systems",2017,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",5,"10.1109/ICCAD.2017.8203778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043528780&doi=10.1109%2fICCAD.2017.8203778&partnerID=40&md5=808f580ee2cdc0030d6a98680b487bee","Controllers in cyber-physical systems integrate a design-time behavioral model of the system under design to improve their own quality. In the state-of-the-art control designs, behavioral models of other interacting neighbor systems are also integrated to form a centralized behavioral model and to enable a system-level optimization and control. Although this ideal embedded control design may result in pareto-optimal solutions, it is not scalable to larger number of systems. Moreover, the behavior of the multi-domain physical systems may be too complex for a control designer to model and may dynamically change at run time. In this paper, we propose a novel Adaptive and Cooperative Quality-Aware (ACQUA) control design which addresses these challenges. In this control design, an ACQUA-based controller for the system under design will monitor the quality of the neighbor systems to dynamically learn their behavior. Therefore, it can quickly adapt its control to cooperate with other neighbor controllers for improving the quality of not only itself, but also other neighbor systems. We apply ACQUA to design a cooperative controller for automotive navigation system, motor control unit, and battery management system in an electric vehicle. We use this automotive example to analyze the performance of the design. We show that by using our ACQUA control, we can reach up to 86% improvements achievable by an ideal embedded control design such that energy consumption reduces by 18% and battery capacity loss decreases by 12% compared to the state-of-the-art on average. © 2017 IEEE.","Automotive; CPS; Electric Vehicle; Machine Learning; Model Predictive Control; Power Optimization; Regression Modeling","Institute of Electrical and Electronics Engineers Inc."
"Zhou T., Bilmes J.","Minimax curriculum learning: Machine teaching with desirable difficulties and scheduled diversity",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",11,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954063&partnerID=40&md5=f20076fbb7032d90fa1a112bd4f57043","We introduce and study minimax curriculum learning (MCL), a new method for adaptively selecting a sequence of training subsets for a succession of stages in machine learning. The subsets are encouraged to be small and diverse early on, and then larger, harder, and allowably more homogeneous in later stages. At each stage, model weights and training sets are chosen by solving a joint continuous-discrete minimax optimization, whose objective is composed of a continuous loss (reflecting training set hardness) and a discrete submodular promoter of diversity for the chosen subset. MCL repeatedly solves a sequence of such optimizations with a schedule of increasing training set size and decreasing pressure on diversity encouragement. We reduce MCL to the minimization of a surrogate function handled by submodular maximization and continuous gradient methods. We show that MCL achieves better performance and, with a clustering trick, uses fewer labeled samples for both shallow and deep models. Our method involves repeatedly solving constrained submodular maximization of an only slowly varying function on the same ground set. Therefore, we develop a heuristic method that utilizes the previous submodular maximization solution as a warm start for the current submodular maximization process to reduce computation while still yielding a guarantee. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"International Conference on Learning Representations, ICLR"
"Dhillon G.S., Azizzadenesheli K., Lipton Z.C., Bernstein J., Kossaifi J., Khanna A., Anandkumar A.","Stochastic activation pruning for robust adversarial defense",2018,"6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings",132,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953694&partnerID=40&md5=4a5023b7f24bce33b2f2c618e5d4e357","Neural networks are known to be vulnerable to adversarial examples. Carefully chosen perturbations to real images, while imperceptible to humans, induce misclassification and threaten the reliability of deep learning systems in the wild. To guard against adversarial examples, we take inspiration from game theory and cast the problem as a minimax zero-sum game between the adversary and the model. In general, for such games, the optimal strategy for both players requires a stochastic policy, also known as a mixed strategy. In this light, we propose Stochastic Activation Pruning (SAP), a mixed strategy for adversarial defense. SAP prunes a random subset of activations (preferentially pruning those with smaller magnitude) and scales up the survivors to compensate. We can apply SAP to pretrained networks, including adversarially trained models, without fine-tuning, providing robustness against adversarial examples. Experiments demonstrate that SAP confers robustness against attacks, increasing accuracy and preserving calibration. © Learning Representations, ICLR 2018 - Conference Track Proceedings.All right reserved.",,"International Conference on Learning Representations, ICLR"
"Imaizumi M., Maehara T., Yoshida Y.","Statistically efficient estimation for non-smooth probability densities",2018,"International Conference on Artificial Intelligence and Statistics, AISTATS 2018",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067783837&partnerID=40&md5=287cd71eef22c10de6e5789f83cfd870","We investigate statistical efficiency of estimators for non-smooth density functions. The density estimation problem appears in various situations, and it is intensively used in statistics and machine learning. The statistical efficiencies of estimators, i.e., their convergence rates, play a central role in advanced statistical analysis. Although estimators and their convergence rates for smooth density functions are well investigated in the literature, those for non-smooth density functions remain elusive despite their importance in application fields. In this paper, we propose new estimators for non-smooth density functions by employing the notion of Szemerédi partitions from graph theory. We derive convergence rates of the proposed estimators. One of them has the optimal convergence rate in minimax sense, and the other has slightly worse convergence rate but runs in polynomial time. Experimental results support the theoretical performance of our estimators. Copyright 2018 by the author(s).",,"PMLR"
"Polson N.G., Ročková V.","Posterior concentration for sparse deep learning",2018,"Advances in Neural Information Processing Systems",12,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064835370&partnerID=40&md5=822dc39051431e3f692bdb890af6d5f4","We introduce Spike-and-Slab Deep Learning (SS-DL), a fully Bayesian alternative to dropout for improving generalizability of deep ReLU networks. This new type of regularization enables provable recovery of smooth input-output maps with unknown levels of smoothness. Indeed, we show that the posterior distribution concentrates at the near minimax rate for α-Hölder smooth maps, performing as well as if we knew the smoothness level α ahead of time. Our result sheds light on architecture design for deep neural networks, namely the choice of depth, width and sparsity level. These network attributes typically depend on unknown smoothness in order to be optimal. We obviate this constraint with the fully Bayes construction. As an aside, we show that SS-DL does not overfit in the sense that the posterior concentrates on smaller networks with fewer (up to the optimal number of) nodes and links. Our results provide new theoretical justifications for deep ReLU networks from a Bayesian point of view. © 2018 Curran Associates Inc..All rights reserved.",,"Neural information processing systems foundation"
"Desai N., Critch A., Russell S.","Negotiable reinforcement learning for Pareto optimal sequential decision-making",2018,"Advances in Neural Information Processing Systems",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064819899&partnerID=40&md5=e207b2c9c55e709075a2f6e1498292b1","It is commonly believed that an agent making decisions on behalf of two or more principals who have different utility functions should adopt a Pareto optimal policy, i.e. a policy that cannot be improved upon for one principal without making sacrifices for another. Harsanyi's theorem shows that when the principals have a common prior on the outcome distributions of all policies, a Pareto optimal policy for the agent is one that maximizes a fixed, weighted linear combination of the principals' utilities. In this paper, we derive a more precise generalization for the sequential decision setting in the case of principals with different priors on the dynamics of the environment. We refer to this generalization as the Negotiable Reinforcement Learning (NRL) framework. In this more general case, the relative weight given to each principal's utility should evolve over time according to how well the agent's observations conform with that principal's prior. To gain insight into the dynamics of this new framework, we implement a simple NRL agent and empirically examine its behavior in a simple environment. © 2018 Curran Associates Inc..All rights reserved.",,"Neural information processing systems foundation"
"Singh S., Póczos B., Ma J.","Minimax reconstruction risk of convolutional sparse dictionary learning",2018,"International Conference on Artificial Intelligence and Statistics, AISTATS 2018",4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064805825&partnerID=40&md5=cc87b4c24bc5eb973a1bc166cc267930","Sparse dictionary learning (SDL) has become a popular method for learning parsimonious representations of data, a fundamental problem in machine learning and signal processing. While most work on SDL assumes a training dataset of independent and identically distributed (IID) samples, a variant known as convolutional sparse dictionary learning (CSDL) relaxes this assumption to allow dependent, non-stationary sequential data sources. Recent work has explored statistical properties of IID SDL; however, the statistical properties of CSDL remain largely unstudied. This paper identifies minimax rates of CSDL in terms of reconstruction risk, providing both lower and upper bounds in a variety of settings. Our results make minimal assumptions, allowing arbitrary dictionaries and showing that CSDL is robust to dependent noise. We compare our results to similar results for IID SDL and verify our theory with synthetic experiments. Copyright 2018 by the author(s).",,"PMLR"
"Sener O., Koltun V.","Multi-task learning as multi-objective optimization",2018,"Advances in Neural Information Processing Systems",186,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064738485&partnerID=40&md5=ec86fe63c0cb960009d86371ad33243c","In multi-task learning, multiple tasks are solved jointly, sharing inductive bias between them. Multi-task learning is inherently a multi-objective problem because different tasks may conflict, necessitating a trade-off. A common compromise is to optimize a proxy objective that minimizes a weighted linear combination of per-task losses. However, this workaround is only valid when the tasks do not compete, which is rarely the case. In this paper, we explicitly cast multi-task learning as multi-objective optimization, with the overall objective of finding a Pareto optimal solution. To this end, we use algorithms developed in the gradient-based multiobjective optimization literature. These algorithms are not directly applicable to large-scale learning problems since they scale poorly with the dimensionality of the gradients and the number of tasks. We therefore propose an upper bound for the multi-objective loss and show that it can be optimized efficiently. We further prove that optimizing this upper bound yields a Pareto optimal solution under realistic assumptions. We apply our method to a variety of multi-task deep learning problems including digit classification, scene understanding (joint semantic segmentation, instance segmentation, and depth estimation), and multi-label classification. Our method produces higher-performing models than recent multi-task learning formulations or per-task training. © 2018 Curran Associates Inc..All rights reserved.",,"Neural information processing systems foundation"
"Horii H.","Vehicle occupant restraint system design under uncertainty by using multi-objective robust design optimization",2018,"International Journal of Computational Methods and Experimental Measurements",1,"10.2495/CMEM-V6-N4-827-834","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064230175&doi=10.2495%2fCMEM-V6-N4-827-834&partnerID=40&md5=4a9111ca3ad25f2879c7f421964ad035","This research reports a vehicle occupant restraint system design that takes account of uncertainties of crash conditions and situations by using a multi-objective robust design optimization method called MORDO. The vehicle occupant restraint system is composed of restraint equipment, such as an airbag, a seatbelt and a knee bolster. The optimization aims to improve the safety performance of the system and its robustness simultaneously. The safety of the system is evaluated by some indexes based on some safety regulations, which are calculated by response surface model of an occupant at a crash. In addition, its robustness is evaluated by the mean value and the standard deviation of objective functions, which are calculated by using Monte Carlo simulation based on a certain probabilistic distribution in space of design variables around each design candidate. Some helpful information for designing the restraint systems, such as trade-off information of safety performance and its robustness, are provided by visualizing and analysing the Pareto optimal solutions. © 2018 WIT Press.","Evolutionary algorithm; Machine learning; Multi-objective optimization; Occupant safety; Robust optimization","Wit Press"
"Horn D., Demircioğlu A., Bischl B., Glasmachers T., Weihs C.","A comparative study on large scale kernelized support vector machines",2018,"Advances in Data Analysis and Classification",7,"10.1007/s11634-016-0265-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063628425&doi=10.1007%2fs11634-016-0265-7&partnerID=40&md5=384e0975dc21cd94f3fa64600ae75e17","Kernelized support vector machines (SVMs) belong to the most widely used classification methods. However, in contrast to linear SVMs, the computation time required to train such a machine becomes a bottleneck when facing large data sets. In order to mitigate this shortcoming of kernel SVMs,many approximate training algorithms were developed. While most of these methods claim to be much faster than the state-of-the-art solver LIBSVM, a thorough comparative study is missing.We aim to fill this gap.We choose several well-known approximate SVM solvers and compare their performance on a number of large benchmark data sets. Our focus is to analyze the trade-off between prediction error and runtime for different learning and accuracy parameter settings. This includes simple subsampling of the data, the poor-man’s approach to handling large scale problems. We employ model-based multi-objective optimization, which allows us to tune the parameters of learning machine and solver over the full range of accuracy/runtime trade-offs. We analyze (differences between) solvers by studying and comparing the Pareto fronts formed by the two objectives classification error and training time. Unsurprisingly, givenmore runtimemost solvers are able to find more accurate solutions, i.e., achieve a higher prediction accuracy. It turns out that LIBSVM with subsampling of the data is a strong baseline. Some solvers systematically outperform others, which allows us to give concrete recommendations of when to use which solver. © Springer-Verlag Berlin Heidelberg 2016.","Large scale; Machine learning; Multi-objective optimization; Nonlinear SVM; Parameter tuning; Supervised learning; Support vector machine","Springer Verlag"
"Yang J., Fan J., Weiz Z., Li G., Liu T., Du X.","Cost-effective data annotation using game-based crowdsourcing",2018,"Proceedings of the VLDB Endowment",19,"10.14778/3275536.3275541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062027921&doi=10.14778%2f3275536.3275541&partnerID=40&md5=095427281d2211e36d4f37b4f2364cb6","Large-scale data annotation is indispensable for many applications, such as machine learning and data integration. However, existing annotation solutions either incur expensive cost for large datasets or produce noisy results. This paper introduces a cost-effective annotation approach, and focuses on the labeling rule generation problem that aims to generate high-quality rules to largely reduce the labeling cost while preserving quality. To address the problem, we first generate candidate rules, and then devise a game-based crowdsourcing approach CrowdGame to select high-quality rules by considering coverage and precision. CrowdGame employs two groups of crowd workers: one group answers rule validation tasks (whether a rule is valid) to play a role of rule generator, while the other group answers tuple checking tasks (whether the annotated label of a data tuple is correct) to play a role of rule refuter. We let the two groups play a two-player game: rule generator identifies high-quality rules with large coverage and precision, while rule refuter tries to refute its opponent rule generator by checking some tuples that provide enough evidence to reject rules covering the tuples. This paper studies the challenges in CrowdGame. The first is to balance the trade-off between coverage and precision. We define the loss of a rule by considering the two factors. The second is rule precision estimation. We utilize Bayesian estimation to combine both rule validation and tuple checking tasks. The third is to select crowdsourcing tasks to fulfill the game-based framework for minimizing the loss.We introduce a minimax strategy and develop efficient task selection algorithms. We conduct experiments on entity matching and relation extraction, and the results show that our method outperforms state-of-the-art solutions. © 2018 VLDB Endowment 21508097/18/07.",,"Association for Computing Machinery"
"Lesinski G., Corns S.","Multi-objective evolutionary neural network to predict graduation success at the United States Military Academy",2018,"Procedia Computer Science",4,"10.1016/j.procs.2018.10.329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061986468&doi=10.1016%2fj.procs.2018.10.329&partnerID=40&md5=2d7e2899fd4858ab758ad1f453ddba87","This paper presents an evolutionary neural network approach to classify student graduation status based upon selected academic, demographic, and other indicators. A pareto-based, multi-objective evolutionary algorithm utilizing the Strength Pareto Evolutionary Algorithm (SPEA2) fitness evaluation scheme simultaneously evolves connection weights and identifies the neural network topology using network complexity and classification accuracy as objective functions. A combined vector-matrix representation scheme and differential evolution recombination operators are employed. The model is trained, tested, and validated using 5100 student samples with data compiled from admissions records and institutional research databases. The inputs to the evolutionary neural network model are used to classify students as: graduates, late graduates, or non-graduates. Results of the hybrid method show higher mean classification rates (88%) than the current methodology (80%) with a potential savings of $130M. Additionally, the proposed method is more efficient in that a less complex neural network topology is identified by the algorithm. © 2018 The Authors. Published by Elsevier B.V.","Enrollment management; Evolutionary Algorithms; Multi-objective Evolutionary Algorithms; Neural network; Student retention","Elsevier B.V."
"Tong H., Ng M.","Regularized semi-supervised least squares regression with dependent samples",2018,"Communications in Mathematical Sciences",,"10.4310/CMS.2018.v16.n5.a08","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059263251&doi=10.4310%2fCMS.2018.v16.n5.a08&partnerID=40&md5=99a4cee3aa457541dc4e63d183ad2bde","In this paper, we study regularized semi-supervised least squares regression with dependent samples. We analyze the regularized algorithm based on reproducing kernel Hilbert spaces, and show, with the use of unlabelled data that the regularized least squares algorithm can achieve the nearly minimax optimal learning rate with a logarithmic term for dependent samples. Our new results are better than existing results in the literature. © 2018 International Press.","Least squares regression; Non-iid sampling; Regularization; Semi-supervised learning","International Press of Boston, Inc."
"Zhao Y., Zhou C., Bellonio J.K.","New value metrics using unsupervised machine learning, lexical link analysis and game theory for discovering innovation from big data and crowd-sourcing",2018,"IC3K 2018 - Proceedings of the 10th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management",,"10.5220/0006959403270334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059022956&doi=10.5220%2f0006959403270334&partnerID=40&md5=8d24e6e65b49ef4dfbbd836695ebf9ce","We demonstrated a machine learning and artificial intelligence method, i.e., lexical link analysis (LLA) to discover innovative ideas from big data. LLA is an unsupervised machine learning paradigm that does not require manually labeled training data. New value metrics are defined based on LLA and game theory. In this paper, we show the value metrics generated from LLA in a use case of an internet game and crowd-sourcing. We show the results from LLA are validated and correlated with the ground truth. The LLA value metrics can be used to select high-value information for a wide range of applications. Copyright © 2018 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","Big data; Crowd-sourcing; Game theory; Lexical link analysis; Nash equilibrium; Pareto efficient; Pareto superior; Social welfare; Unsupervised learning","SciTePress"
"Hamm J., Noh Y.-K.","K-beam minimax: Efficient optimization for deep adversarial learning",2018,"35th International Conference on Machine Learning, ICML 2018",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057285498&partnerID=40&md5=dbd04c1eaee076e5f7edd4ecef1e6c62","Minimax optimization plays a key role in adversarial training of machine learning algorithms, such as learning generative models, domain adaptation, privacy preservation, and robust learning. In this paper, we demonstrate the failure of alternating gradient descent in minimax optimization problems due to the discontinuity of solutions of the inner maximization. To address this, we propose a new e-subgradient descent algorithm that addresses this problem by simultaneously tracking K candidate solutions. Practically, the algorithm can find solutions that previous saddle-point algorithms cannot find, with only a sublinear increase of complexity in K. We analyze the conditions under which the algorithm converges to the true solution in detail. A significant improvement in stability and convergence speed of the algorithm is observed in simple representative problems, GAN training, and domain-adaptation problems. © 2018 by authors.All right reserved.",,"International Machine Learning Society (IMLS)"
"Wang G., Hu Q., Cheng J., Hou Z.","Semi-supervised generative adversarial hashing for image retrieval",2018,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",10,"10.1007/978-3-030-01267-0_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055434845&doi=10.1007%2f978-3-030-01267-0_29&partnerID=40&md5=76b6a8cf2bdcca214370e40bf65d4259","With explosive growth of image and video data on the Internet, hashing technique has been extensively studied for large-scale visual search. Benefiting from the advance of deep learning, deep hashing methods have achieved promising performance. However, those deep hashing models are usually trained with supervised information, which is rare and expensive in practice, especially class labels. In this paper, inspired by the idea of generative models and the minimax two-player game, we propose a novel semi-supervised generative adversarial hashing (SSGAH) approach. Firstly, we unify a generative model, a discriminative model and a deep hashing model in a framework for making use of triplet-wise information and unlabeled data. Secondly, we design novel structure of the generative model and the discriminative model to learn the distribution of triplet-wise information in a semi-supervised way. In addition, we propose a semi-supervised ranking loss and an adversary ranking loss to learn binary codes which preserve semantic similarity for both labeled data and unlabeled data. Finally, by optimizing the whole model in an adversary training way, the learned binary codes can capture better semantic information of all data. Extensive empirical evaluations on two widely-used benchmark datasets show that our proposed approach significantly outperforms state-of-the-art hashing methods. © Springer Nature Switzerland AG 2018.","Deep learning; GANs; Hashing; Information retrieval","Springer Verlag"
"Gopinath K.G.S., Pal S., Tambe P.","Prediction of Weight Percentage Alumina and Pore Volume Fraction in Bio-Ceramics Using Gaussian Process Regression and Minimax Probability Machine Regression",2018,"Materials Today: Proceedings",2,"10.1016/j.matpr.2018.02.200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050124988&doi=10.1016%2fj.matpr.2018.02.200&partnerID=40&md5=fd3a62ba3a60358f126ce6e0acad4918","In Bio-ceramics, the alumina weight percentage and pore volume fraction play a vital role for its biocompatibility in human body. There are many experimental methods which are employed for achieving the required quality in it. In this work, for preparation of Al2O3/SiC ceramic cake, the amount of Silicon Carbide (SiC) is taken as input parameter. The weight percentage Alumina and pore volume fraction are taken as output parameters. Two machine learning models such as Gaussian Process Regression (GPR) and Minimax Probability Machine Regression (MPMR) are applied for predicting the above two output parameters. The performance of the above two models are compared. The Gaussian Process Regression outperforms the Minimax Probability Machine Regression marginally and the result of the Gaussian is encouraging for predicting the above two outputs. © 2017 Elsevier Ltd. All rights reserved.","Bio-ceramics; Gaussian Process Regression; Minimax Probability Machine Regression; Pore Volume fraction; Weight Percentage Alumina","Elsevier Ltd"
"Jafarzadeh S., Genç V.M.I.","Probabilistic dynamic security assessment of large power systems using machine learning algorithms",2018,"Turkish Journal of Electrical Engineering and Computer Sciences",9,"10.3906/elk-1709-247","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048219666&doi=10.3906%2felk-1709-247&partnerID=40&md5=6ae5bcd5532d245e31667701aa33367c","Due to extensive utilization of intermittent energy sources in recent years, deterministic approaches cannot provide an accurate security assessment for power systems under large uncertainties. Therefore, probabilistic approaches have become crucial for making decisions based on more reliable assessments. In this paper, a new method based on machine learning and proper sampling techniques is proposed to overcome the difficulties of the conventional Monte Carlo approaches used in power system security assessment. The main purpose of the proposed method is to accurately quantify the dynamic security related risk at a forecasted operating condition of a power system utilizing a large number of intermittent energy sources, e.g., wind, which greatly extends the uncertainties in its operation. This is achieved through the proposed method, which captures an accurate probability distribution of the system’s dynamic performance associated with both transient and small-signal angle stability. The accuracy of the fitted distribution is attained by adopting a generalized Pareto (GP) distribution for the left-tailed region that includes severe and rare cases using a multilayered perceptron neural network with the Relief feature selection technique, which speeds up the exceedance sample generation process required for the GP distribution. The Latin hypercube sampling technique, which samples the search space evenly, is proposed to create a dataset for training the neural network. To generate the Monte Carlo instances, the Gibbs sampling approach, which considers the correlation between random variables besides its simplicity, is utilized. © TUBITAK.","Feature selection; Neural networks; Power system security; Power system stability; Probabilistic security assessment","Turkiye Klinikleri Journal of Medical Sciences"
"Oruganti P.S., Ahmed Q., Jung D.","Effects of Thermal and Auxiliary Dynamics on a Fuel Cell Based Range Extender",2018,"SAE Technical Papers",1,"10.4271/2018-01-1311","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045458068&doi=10.4271%2f2018-01-1311&partnerID=40&md5=6548f62e4a7b4a32bba8d581fb747821","Batteries are useful in Fuel Cell Hybrid Electric Vehicles (FCHEV) to fulfill transient demands and for regenerative braking. Efficient energy management strategies paired with optimal powertrain design further improves the efficiency. In this paper, a new methodology to simultaneously size the propulsive elements and optimize the power-split strategy of a Range Extended Battery Electric Vehicle (REBEV), using a Polymer Electron Membrane Fuel Cell (PEMFC), is proposed and preliminary studies on the effects of the driving mission profile and the auxiliary power loads on the sizing and optimal performance of the powertrain design are carried out. Dynamic Programming is used to compute the optimal energy management strategy for a given driving mission profile, providing a global optimal solution. The component sizing problem is performed using a machine learning based, guided design space exploration to find the set of Pareto-optimal solutions that give the best trade-offs between the different objectives. The powertrain model includes the dynamic behavior of the fuel cell system compressor and a battery lumped parameter thermal model along with the quasi-static semi-empirical model of the fuel cell and a zero-order battery model. Initial results indicate an increase in the Pareto-optimal sizes with the inclusion of thermal management. © 2018 SAE International. All Rights Reserved.",,"SAE International"
"Akhter N., Shehu A.","From extraction of local structures of protein energy landscapes to improved decoy selection in template-free protein structure prediction",2018,"Molecules",26,"10.3390/molecules23010216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041008293&doi=10.3390%2fmolecules23010216&partnerID=40&md5=eff6b7ecb15103c5a38b3b31714495e6","Due to the essential role that the three-dimensional conformation of a protein plays in regulating interactions with molecular partners, wet and dry laboratories seek biologically-active conformations of a protein to decode its function. Computational approaches are gaining prominence due to the labor and cost demands of wet laboratory investigations. Template-free methods can now compute thousands of conformations known as decoys, but selecting native conformations from the generated decoys remains challenging. Repeatedly, research has shown that the protein energy functions whose minima are sought in the generation of decoys are unreliable indicators of nativeness. The prevalent approach ignores energy altogether and clusters decoys by conformational similarity. Complementary recent efforts design protein-specific scoring functions or train machine learning models on labeled decoys. In this paper, we show that an informative consideration of energy can be carried out under the energy landscape view. Specifically, we leverage local structures known as basins in the energy landscape probed by a template-free method. We propose and compare various strategies of basin-based decoy selection that we demonstrate are superior to clustering-based strategies. The presented results point to further directions of research for improving decoy selection, including the ability to properly consider the multiplicity of native conformations of proteins. © 2018 by the authors.","Basins; Conformational space; Decoy selection; Energy landscape; Pareto optimality; Template-free protein structure prediction","MDPI AG"
"Ferreiro-Cabello J., Fraile-Garcia E., Martinez de Pison Ascacibar E., Martinez de Pison Ascacibar F.J.","Metamodel-based design optimization of structural one-way slabs based on deep learning neural networks to reduce environmental impact",2018,"Engineering Structures",31,"10.1016/j.engstruct.2017.11.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033564283&doi=10.1016%2fj.engstruct.2017.11.005&partnerID=40&md5=f646fdf3ea4715a1977589192d97e61e","This article presents a methodology for the construction and use of metamodels with Deep Learning (DL) methods that are useful for making multi-criteria decisions in the design and optimization of one-way slabs. The main motivation behind this research has been to examine the possibilities of improving slab design by including this methodology in future tools, which is capable of calculating thousands of solutions in real time based on the designer's specifications. The process of creating these metamodels begins by developing a database of millions of combinations of slab designs. These combinations are calculated with a heuristic algorithm that provides the following results: rigidity, deflection, cost per square meter, CO2 emissions and embodied energy. Once a database including the entire universe of possible solutions has been created, a metamodel is developed that is capable of “condensing” the implicit knowledge contained in the database. This metamodel is included within a Decision Support System (DSS) that produces thousands of solutions for slabs that all comply with a range of specifications designated by the design plan. Furthermore, the methodology described herein proposes the use of Pareto-optimal solutions and graphic tools to help designers make multi-criteria decisions regarding the solutions that best fit their needs. A case study is presented to illustrate this proposal: optimizing slab design in two buildings according to technical, economic and sustainability criteria. The results indicate that the multi-criteria solutions obtained would entail a significant reduction in both emissions and embodied energy as compared to mono-criteria solutions, without significantly increasing costs. © 2017","Deep learning; Metamodel; Multicriteria optimization; One-way slab; Reinforced concrete; Structures","Elsevier Ltd"
"Bharsakade R.S., Kulkarni O.S., Afle A.S., Kulkarni M.S.","Analysis of and modeling for emergency medical services facility location for road accidents on highway",2018,"International Journal of Mechanical and Production Engineering Research and Development",,"10.24247/ijmperdfeb201866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041801080&doi=10.24247%2fijmperdfeb201866&partnerID=40&md5=390acdee0c2b16b161b0f41f6d1a89c8","This paper analyses the accident-prone regions along the 94.5km stretch of Mumbai-Pune express highway to determine optimal base locations for dispatching Emergency Medical Services (EMS). The study was driven by an increasing concern over the rise in accident fatalities on the expressway, and the alarming inadequacy of ambulance services. Our research aims to determine the optimal emergency medical service (EMS) facility locations to address the needs generated by accidents on expressways with heavy flowing traffic. Expressways present the unique problem of being isolated from hospitals and trauma centers located within cities, as well as practical constraints in turning vehicles around due to unidirectional heavy flow of traffic. We have used the mean shift algorithm of machine learning to determine clusters along with their centers. We further employed the minimax facility location model for rectilinear distances to determine a second base location within the primary clusters. The purpose of the secondary base locations is to supplement the primary EMS locations and distribute the load to ensure that the dispatched ambulances reach the accident spot in 8 minutes. The proposed model combines a traditional approach with a machine learning algorithm to produce faster output. © TJPRC Pvt. Ltd.","Accident-prone regions; Unidirectional heavy flow.& produce faster output","Transstellar Journal Publications and Research Consultancy Private Limited (TJPRC)"
"Zhang T., Georgiopoulos M., Anagnostopoulos G.C.","Pareto-Optimal Model Selection via SPRINT-Race",2018,"IEEE Transactions on Cybernetics",2,"10.1109/TCYB.2017.2647821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011653983&doi=10.1109%2fTCYB.2017.2647821&partnerID=40&md5=28e249d153532ecad183076e85a694e5","In machine learning, the notion of multi-objective model selection (MOMS) refers to the problem of identifying the set of Pareto-optimal models that optimize by compromising more than one predefined objectives simultaneously. This paper introduces SPRINT-Race, the first multi-objective racing algorithm in a fixed-confidence setting, which is based on the sequential probability ratio with indifference zone test. SPRINT-Race addresses the problem of MOMS with multiple stochastic optimization objectives in the proper Pareto-optimality sense. In SPRINT-Race, a pairwise dominance or non-dominance relationship is statistically inferred via a non-parametric, ternary-decision, dual-sequential probability ratio test. The overall probability of falsely eliminating any Pareto-optimal models or mistakenly returning any clearly dominated models is strictly controlled by a sequential Holm's step-down family-wise error rate control method. As a fixed-confidence model selection algorithm, the objective of SPRINT-Race is to minimize the computational effort required to achieve a prescribed confidence level about the quality of the returned models. The performance of SPRINT-Race is first examined via an artificially constructed MOMS problem with known ground truth. Subsequently, SPRINT-Race is applied on two real-world applications: 1) hybrid recommender system design and 2) multi-criteria stock selection. The experimental results verify that SPRINT-Race is an effective and efficient tool for such MOMS problems. © 2017 IEEE.","Model selection (MS); multi-objective optimization; racing algorithm; sequential probability ratio test (SPRT)","Institute of Electrical and Electronics Engineers Inc."
"Shang R., Zhang W., Li F., Jiao L., Stolkin R.","Multi-objective artificial immune algorithm for fuzzy clustering based on multiple kernels",2018,"2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings",3,"10.1109/SSCI.2017.8285279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046103864&doi=10.1109%2fSSCI.2017.8285279&partnerID=40&md5=8f46ff0b50b6651118e7359dec3e1c9c","This paper presents a multi-objective artificial immune algorithm for fUzzy clustering based on multiple kernels (MAFC). MAFC extends the classical Fuzzy C-Means (FCM) algorithm and overcomes its important limitations, such as limited adaptability, poor handling of non-linear relationships between data, and vulnerability to local optima convergence, which can lead to poor clustering quality. To compensate these limitations, MAFC unifies multi-kernel learning and multi-objective optimization in a joint clustering framework, which preserves the geometric information of the dataset. The multikernel method maps data from the feature space to kernel space by kernel functions. This approach is effective, not only for spherical clusters, but can also discover the non-linear relationships between data, and adds robustness to the particular choice of kernel functions. Additionally, the introduction of multi-objective optimization can optimize between-cluster separation and within-cluster compactness simultaneously via two different clustering validity criteria. These properties help the proposed algorithm to avoid becoming stuck at local optima. Furthermore, this paper utilizes an artificial immune algorithm to address the multi-objective clustering problem and acquire a Pareto optimal solution set. The solution set is obtained through the process of antibody population initialization, clone proliferation, non-uniform mutation and uniformity maintaining strategy, which avoids the problems of degradation and prematurity which can occur with conventional genetic algorithms. Finally, we choose the best solution, from the Pareto optimal solution set, using a semi-supervised method, to achieve the final clustering results. We compare our method against three state-of-the-art methods from the literature by performing experiments with both UCI datasets and face datasets. The results suggest that MAFC is significantly more efficient for clustering and has a wider scope of application. © 2017 IEEE.","artificial immune algorithm; fuzzy c-means (FCM); multi-objective optimization; multiple kernel learning","Institute of Electrical and Electronics Engineers Inc."
"Sabar N.R., Yi X., Song A.","A Bi-objective Hyper-Heuristic Support Vector Machines for Big Data Cyber-Security",2018,"IEEE Access",25,"10.1109/ACCESS.2018.2801792","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043389474&doi=10.1109%2fACCESS.2018.2801792&partnerID=40&md5=f00b6f1e16b149c7f0f9c4035999e55d","Cyber security in the context of big data is known to be a critical problem and presents a great challenge to the research community. Machine learning algorithms have been suggested as candidates for handling big data security problems. Among these algorithms, support vector machines (SVMs) have achieved remarkable success on various classification problems. However, to establish an effective SVM, the user needs to define the proper SVM configuration in advance, which is a challenging task that requires expert knowledge and a large amount of manual effort for trial and error. In this paper, we formulate the SVM configuration process as a bi-objective optimization problem in which accuracy and model complexity are considered as two conflicting objectives. We propose a novel hyper-heuristic framework for bi-objective optimization that is independent of the problem domain. This is the first time that a hyper-heuristic has been developed for this problem. The proposed hyper-heuristic framework consists of a high-level strategy and low-level heuristics. The high-level strategy uses the search performance to control the selection of which low-level heuristic should be used to generate a new SVM configuration. The low-level heuristics each use different rules to effectively explore the SVM configuration search space. To address bi-objective optimization, the proposed framework adaptively integrates the strengths of decomposition- and Pareto-based approaches to approximate the Pareto set of SVM configurations. The effectiveness of the proposed framework has been evaluated on two cyber security problems: Microsoft malware big data classification and anomaly intrusion detection. The obtained results demonstrate that the proposed framework is very effective, if not superior, compared with its counterparts and other algorithms. © 2013 IEEE.","big data; cyber security; Hyper-heuristics; optimisation","Institute of Electrical and Electronics Engineers Inc."
"Daavarani Asl Z., Derhami V., Yazdian-Dehkordi M.","A new approach on multi-agent Multi-Objective Reinforcement Learning based on agents' preferences",2018,"19th CSI International Symposium on Artificial Intelligence and Signal Processing, AISP 2017",4,"10.1109/AISP.2017.8324111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050994547&doi=10.1109%2fAISP.2017.8324111&partnerID=40&md5=65f8b1ea0693a281daf2d2d5b47f578f","Reinforcement Learning (RL) is a powerful machine learning paradigm for solving Markov Decision Process (MDP). Traditional RL algorithms aim to solve one-objective problems, but many real-world problems have more than one objective which conflict each other. In recent years, Multi-Objective Reinforcement Learning (MORL) algorithms, which employ a reward vector instead of a scalar reward signal, have been proposed to solve multi-objective problems. In MORL, because of conflicting objectives, there is no one optimal solution and a set of solutions named Pareto Front will be learned. In this paper, we proposed a new multi-agent method, which uses a shared Q-table for all agents to solve bi-objective problems. However, each agent selects actions based on its preference. These preferences are different with each other and the agents reach to Pareto Front solutions based on this preferences. The proposed method is simple in understanding and its computational cost is very low. Moreover, after finding the Pareto Front set, we can easily track the policy. Simulation results show that our proposed method outperforms the available methods in the term of learning speed. © 2017 IEEE.","multi-agent systems; multi-objective; Pareto Front; Reinforcement learning","Institute of Electrical and Electronics Engineers Inc."
"Dutta S., Samui P., Kim D.","Comparison of machine learning techniques to predict compressive strength of concrete",2018,"Computers and Concrete",35,"10.12989/cac.2018.21.4.463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049587528&doi=10.12989%2fcac.2018.21.4.463&partnerID=40&md5=00dd5a5f9482f226d3348b9e8620b7db","In the present study, soft computing i.e., machine learning techniques and regression models algorithms have earned much importance for the prediction of the various parameters in different fields of science and engineering. This paper depicts that how regression models can be implemented for the prediction of compressive strength of concrete. Three models are taken into consideration for this; they are Gaussian Process for Regression (GPR), Multi Adaptive Regression Spline (MARS) and Minimax Probability Machine Regression (MPMR). Contents of cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, fine aggregate and age in days have been taken as inputs and compressive strength as output for GPR, MARS and MPMR models. A comparatively large set of data including 1030 normalized previously published results which were obtained from experiments were utilized. Here, a comparison is made between the results obtained from all the above mentioned models and the model which provides the best fit is established. The experimental results manifest that proposed models are robust for determination of compressive strength of concrete. Copyright © 2018 Techno-Press, Ltd.","Compressive strength; Concrete; Gaussian Process for Regression (GPR); Minimax Probability Machine Regression (MPMR); Multi Adaptive Regression Spline (MARS)","Techno Press"
"Yu K., While L., Reynolds M., Wang X., Liang J.J., Zhao L., Wang Z.","Multiobjective optimization of ethylene cracking furnace system using self-adaptive multiobjective teaching-learning-based optimization",2018,"Energy",33,"10.1016/j.energy.2018.01.159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041748366&doi=10.1016%2fj.energy.2018.01.159&partnerID=40&md5=8426a500c0f6a5bbde0308df86ba501c","The ethylene cracking furnace system is crucial for an olefin plant. Multiple cracking furnaces are used to convert various hydrocarbon feedstocks to smaller hydrocarbon molecules, and the operational conditions of these furnaces significantly influence product yields and fuel consumption. This paper develops a multiobjective operational model for an industrial cracking furnace system that describes the operation of each furnace based on current feedstock allocations, and uses this model to optimize two important and conflicting objectives: maximization of key products yield, and minimization of the fuel consumed per unit ethylene. The model incorporates constraints related to material balance and the outlet temperature of transfer line exchanger. The self-adaptive multiobjective teaching-learning-based optimization algorithm is improved and used to solve the designed multiobjective optimization problem, obtaining a Pareto front with a diverse range of solutions. A real industrial case is investigated to illustrate the performance of the proposed model: the set of solutions returned offers a diverse range of options for possible implementation, including several solutions with both significant improvement in product yields and lower fuel consumption, compared with typical operational conditions. © 2018 Elsevier Ltd","Ethylene cracking furnace; Fuel consumption; Multiobjective optimization; Product yield; Teaching-learning-based optimization","Elsevier Ltd"
"Santoro G., Casu M.R., Peluso V., Calimera A., Alioto M.","Energy-performance design exploration of a low-power microprogrammed deep-learning accelerator",2018,"Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition,  DATE 2018",3,"10.23919/DATE.2018.8342185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048767258&doi=10.23919%2fDATE.2018.8342185&partnerID=40&md5=927bed8d5965e9bbf315e428cf2dc6a9","This paper presents the design space exploration of a novel microprogrammable accelerator in which PEs are connected with a Network-on-Chip and benefit from low-power features enabled through a practical implementation of a Dual-Vdd assignment scheme. An analytical model, fitted with postlayout data obtained with a 28nm FDSOI design kit, returns implementations with optimal energy-performance tradeoff by taking into consideration all the key design-space variables. The obtained Pareto analysis helps us infer optimization rules aimed at improving quality of design. © 2018 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Santoro G., Casu M.R., Peluso V., Calimera A., Alioto M.","Design-Space Exploration of Pareto-Optimal Architectures for Deep Learning with DVFS",2018,"Proceedings - IEEE International Symposium on Circuits and Systems",5,"10.1109/ISCAS.2018.8351685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057105973&doi=10.1109%2fISCAS.2018.8351685&partnerID=40&md5=f9f01347075e094279bc38b4a051051a","Specialized computing engines are required to accelerate the execution of Deep Learning (DL) algorithms in an energy-efficient way. To adapt the processing throughput of these accelerators to the workload requirements while saving power, Dynamic Voltage and Frequency Scaling (DVFS) seems the natural solution. However, DL workloads need to frequently access the off-chip memory, which tends to make the performance of these accelerators memory-bound rather than computation-bound, hence reducing the effectiveness of DVFS. In this work we use a performance-power analytical model fitted on a parametrized implementation of a DL accelerator in a 28-nm FDSOI technology to explore a large design space and to obtain the Pareto points that maximize the effectiveness of DVFS in the sub-space of throughput and energy efficiency. In our model we consider the impact on performance and power of the off-chip memory using real data of a commercial low-power DRAM. © 2018 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Acampora G., Herrera F., Tortora G., Vitiello A.","A multi-objective evolutionary approach to training set selection for support vector machine",2018,"Knowledge-Based Systems",26,"10.1016/j.knosys.2018.02.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042154632&doi=10.1016%2fj.knosys.2018.02.022&partnerID=40&md5=7bee772591607574ce4c5fbf2fd65f28","The Support Vector Machine (SVM) is one of the most powerful algorithms for machine learning and data mining in numerous and heterogenous application domains. However, in spite of its competitiveness, SVM suffers from scalability problems which drastically worsens its performance in terms of memory requirements and execution time. As a consequence, there is a strong emergence of approaches for supporting SVM in efficiently addressing the aforementioned problems without affecting its classification capabilities. In this scenario, methods for Training Set Selection (TSS) represent a suitable and consolidated pre-processing technique to compute a reduced but representative training dataset, and improve SVM's scalability without deprecating its classification accuracy. Recently, TSS has been formulated as an optimization problem characterized by two objectives (the classification accuracy and the reduction rate) and solved through the application of evolutionary algorithms. However, so far, all the evolutionary approaches for TSS have been based on a so-called multi-objective a priori technique, where multiple objectives are aggregated together into a single objective through a weighted combination. This paper proposes to apply, for the first time, a Pareto-based multi-objective optimization approach to the TSS problem in order to explicitly deal with both its objectives and offer a better trade-off between SVM's classification and reduction performance. The benefits of the proposed approach are validated by a set of experiments involving well-known datasets taken from the UCI Machine Learning Database Repository. As shown by statistical tests, the application of a Pareto-based multi-objective optimization approach improves on state-of-the-art TSS techniques and enhances SVM efficiency. © 2018 Elsevier B.V.","Multi-objective optimization; Support vector machine; Training set selection","Elsevier B.V."
"Thirumalaiselvi A., Verma M., Anandavalli N., Rajasankar J.","Response prediction of laced steel-concrete composite beams using machine learning algorithms",2018,"Structural Engineering and Mechanics",8,"10.12989/sem.2018.66.3.399","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049248423&doi=10.12989%2fsem.2018.66.3.399&partnerID=40&md5=60c3674a8775e380c2fc7f83a9833266","This paper demonstrates the potential application of machine learning algorithms for approximate prediction of the load and deflection capacities of the novel type of Laced Steel Concrete-Composite1 (LSCC) beams proposed by Anandavalli et al. (Engineering Structures 2012). Initially, global and local responses measured on LSCC beam specimen in an experiment are used to validate nonlinear FE model of the LSCC beams. The data for the machine learning algorithms is then generated using validated FE model for a range of values of the identified sensitive parameters. The performance of four well-known machine learning algorithms, viz., Support Vector Regression (SVR), Minimax Probability Machine Regression (MPMR), Relevance Vector Machine (RVM) and Multigene Genetic Programing (MGGP) for the approximate estimation of the load and deflection capacities are compared in terms of well-defined error indices. Through relative comparison of the estimated values, it is demonstrated that the algorithms explored in the present study provide a good alternative to expensive experimental testing and sophisticated numerical simulation of the response of LSCC beams. The load carrying and displacement capacity of the LSCC was predicted well by MGGP and MPMR, respectively. © 2018 Techno-Press, Ltd.","Composite structures; Displacement; Machine learning algorithms; Ultimate strength","Techno-Press"
"Kim S.H., Kim H.-J., Kim J.-Y.","GAN-Based One-Class Classification for Personalized Image Retrieval",2018,"Proceedings - 2018 IEEE International Conference on Big Data and Smart Computing, BigComp 2018",8,"10.1109/BigComp.2018.00147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048497878&doi=10.1109%2fBigComp.2018.00147&partnerID=40&md5=61589d4530de236ef583fca8907cccb6","One-class classification for a personalized image retrieval system is one of most important research issues in machine learning. However, the conventional one-class classification techniques can have an overfitting problem. Thus, in this paper, we propose a novel one-class classification technique using the framework of generative adversarial nets (GAN) for image data. First, the support model and one-class model are trained with only positive-class data by a minimax game. At the end of this learning process, the one-class model learns the features of positive-class data very well while reducing generation error. One of our important findings is that the negative-class data generated by the support model help the one-class model conceptually and experimentally reduce the generative error. Using CIFAR-10, we show that our proposed technique outperforms the conventional technique by ∼10% in terms of F1 measure. © 2018 IEEE.","convolutional neural network; deep learning; generative adversarial net; image retrieval; one class classification","Institute of Electrical and Electronics Engineers Inc."
"Krasopoulos C.T., Beniakar M.E., Kladas A.G.","Multicriteria PM motor design based on ANFIS evaluation of EV driving cycle efficiency",2018,"IEEE Transactions on Transportation Electrification",34,"10.1109/TTE.2018.2810707","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048212522&doi=10.1109%2fTTE.2018.2810707&partnerID=40&md5=1700a6090704ed9d52fdd054eac3f4de","This paper proposes a multicriteria design optimization methodology for permanent magnet (PM) motors used in electric vehicle (EV) applications. In the process, an adaptive-network-based fuzzy inference system (ANFIS) is utilized, coupled with a multiobjective optimization algorithm, as a surrogate model of the electric motor. This allows for the consideration of the full drive cycle and respective efficiency map for every motor design. The prediction error of the ANFIS is minimized by employing appropriate membership functions, initial training data, and an adaptive learning scheme via iterative training. The efficiency map is then implemented in a vehicle dynamic model to compute the total consumed energy over the driving cycle. The optimization profile accounts for total energy efficiency, torque density, and additionally considers complementary design criteria via an a posteriori selection procedure on the resulting Pareto set. The methodology developed is applied to optimize a surface PM motor with concentrated fractional slot winding, mounted on a light EV that competes in fuel economy races. The selected motor design has been validated through measurements on a prototype. © 2015 IEEE.","Adaptive-network-based fuzzy inference system (ANFIS); drive cycle; efficiency map; electric vehicle (EV); energy efficiency; machine learning; multicriteria design; multiobjective optimization; permanent magnet (PM) motor design; torque density","Institute of Electrical and Electronics Engineers Inc."
"Zheng Y.-J., Zhou X.-H., Sheng W.-G., Xue Y., Chen S.-Y.","Generative adversarial network based telecom fraud detection at the receiving bank",2018,"Neural Networks",44,"10.1016/j.neunet.2018.02.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044029801&doi=10.1016%2fj.neunet.2018.02.015&partnerID=40&md5=3e3e8f4f68985f925a502bbc4eb4c20d","Recently telecom fraud has become a serious problem especially in developing countries such as China. At present, it can be very difficult to coordinate different agencies to prevent fraud completely. In this paper we study how to detect large transfers that are sent from victims deceived by fraudsters at the receiving bank. We propose a new generative adversarial network (GAN) based model to calculate for each large transfer a probability that it is fraudulent, such that the bank can take appropriate measures to prevent potential fraudsters to take the money if the probability exceeds a threshold. The inference model uses a deep denoising autoencoder to effectively learn the complex probabilistic relationship among the input features, and employs adversarial training that establishes a minimax game between a discriminator and a generator to accurately discriminate between positive samples and negative samples in the data distribution. We show that the model outperforms a set of well-known classification methods in experiments, and its applications in two commercial banks have reduced losses of about 10 million RMB in twelve weeks and significantly improved their business reputation. © 2018 Elsevier Ltd","Deep learning; Denoising autoencoder; Fraud detection; Generative adversarial network (GAN); Intelligent data analysis","Elsevier Ltd"
"Benito-Garzón M., Fady B., Davi H., Vizcaíno-Palomar N., Fernández-Manjarrés J.","Trees on the move: using decision theory to compensate for climate change at the regional scale in forest social-ecological systems",2018,"Regional Environmental Change",5,"10.1007/s10113-018-1277-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040681611&doi=10.1007%2fs10113-018-1277-y&partnerID=40&md5=0ba745c805810c8330f15d80f2d4bf48","The adaptation of social-ecological systems such as managed forests depends largely on decisions taken by forest managers who must choose among a wide range of possible futures to spread risks. We used robust decision theory to guide management decisions on the translocation of tree populations to compensate for climate change. We calibrated machine learning correlational models using tree height data collected from five common garden tests in France where Abies alba provenances from 11 European countries are planted. Resulting models were used to simulate tree height in the planting sites under current and 2050 climates (regional concentration pathway scenarios (RCPs) 2.6, 4.5, 6.0 and 8.5). Our results suggest an overall increase in tree height by 2050, but with large variation among the predictions depending on the provenance and the RCPs. We applied maximin, maximax and minimax decision rules to address outcomes under five uncertain states of the world represented by the four RCPs and the present climate (baseline). The maximin rule indicated that for 2050, the best translocation option for maximising tree height would be the use of provenances from Northwest France into all target zones. The maximax and minimax regret rules pointed out the same result for all target zones except for the ‘Les Chauvets’ trial, where the East provenance was selected. Our results show that decision theory can help management by reducing the number of options if most decision rules converge. Interestingly, the commonly suggested recommendation of using multiple provenances to mitigate long-term maladaptation risks or from ‘pre-adapted’ populations from the south was not supported by our approach. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","Assisted migration; Decision theory; Forests; Phenotypic variation; Social-ecological systems; Uncertainty","Springer Verlag"
"Yasini S., Pelckmans K.","Worst-case prediction performance analysis of the Kalman filter",2018,"IEEE Transactions on Automatic Control",6,"10.1109/TAC.2017.2757908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030764624&doi=10.1109%2fTAC.2017.2757908&partnerID=40&md5=7fb095ea98cc3256bfd62a87983ea711","In this paper, we study the prediction performance of the Kalman filter (KF) in a worst case minimax setting as studied in online machine learning, information, and game theory. The aim is to predict the sequence of observations almost as well as the best reference predictor (comparator) sequence in a comparison class. We prove worst-case bounds on the cumulative squared prediction errors using a priori knowledge about the complexity of reference predictor sequence. In fact, the performance of the KF is derived as a function of the performance of the best reference predictor and the total amount of drift that occurs in the schedule of the best comparator. © 1963-2012 IEEE.","H∞ estimation; Kalman filter (KF); online machine learning; tracking worst-case bounds","Institute of Electrical and Electronics Engineers Inc."
"Ding Z., Guo Y., Zhang L., Fu Y.","One-shot face recognition via generative learning",2018,"Proceedings - 13th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2018",24,"10.1109/FG.2018.00011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049383771&doi=10.1109%2fFG.2018.00011&partnerID=40&md5=f9c51f7152c55b2549cb60aabd68d6d3","One-shot face recognition measures the ability to recognize persons with only seeing them once, which is a hallmark of human visual intelligence. It is challenging for existing machine learning approaches to mimic this way, since limited data cannot well represent the data variance. To this end, we propose to build a large-scale face recognizer, which is capable to fight off the data imbalance difficulty. To seek a more effective general classifier, we develop a novel generative model attempting to synthesize meaningful data for one-shot classes by adapting the data variances from other normal classes. Specifically, we formulate conditional generative adversarial networks and the general Softmax classifier into a unified framework. Such a two-player minimax optimization can guide the generation of more effective data, which benefit the classifier learning for one-shot classes. The experimental results on a large-scale face benchmark with 21K persons verify the effectiveness of our proposed algorithm in one-shot classification, as our generative model significantly improves the recognition coverage rate from 25:65% to 94:84% at the precision of 99% for the one-shot classes, while still keeps an overall Top-1 accuracy at 99:80% for the normal classes. © 2018 IEEE.","Face recognition; Generative model; One shot learning","Institute of Electrical and Electronics Engineers Inc."
"Niu X., Wang H., Hu S., Yang C., Wang Y.","Multi-objective online optimization of a marine diesel engine using NSGA-II coupled with enhancing trained support vector machine",2018,"Applied Thermal Engineering",36,"10.1016/j.applthermaleng.2018.03.080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044582569&doi=10.1016%2fj.applthermaleng.2018.03.080&partnerID=40&md5=2003054e619484d0e17e4130136ec9f1","The multi-objective optimization problems of diesel engines are always challenging for the engineers, especially with the application of new technologies that aim at improving the engine performance and emissions. This paper proposed a novel online optimization approach using NSGA-II coupled with a machine learning method (SVM). The proposed online optimization approach was conducted based on an engine physical model, which was calibrated and validated carefully using experimental data. In the optimization process, the engine physical model is used as a substitute of real engine to generate training data for the SVM and validate the accuracy of the optimization results; SVM, with fast computing speed, undertakes the massive calculating workloads of fitness evaluation on searching the Pareto optimal solutions. Moreover, this paper proposed an enhancing training method to guarantee the accuracy of SVM model. When applying on a marine diesel engine, the proposed online optimization approach has demonstrated its reliability and high efficiency. In addition, with fast computing speed, the well trained SVM model can develop the engine responses maps rapidly. Eventually, based on the Pareto-optimal solutions obtained by the proposed optimization approach, combining with the maps, the solving of multi-objective optimization problems will be significantly facilitated. © 2018 Elsevier Ltd","Marine diesel engine; Multi-objective optimization; NSGA-II; Pareto-optimal solution; SVM","Elsevier Ltd"
"Bharathi B., Kavitha S., Shashaank D.S., Priyanka S., Sriram V.","Speech recognition based chess system for visually challanged",2018,"2017 International Conference on Energy, Communication, Data Analytics and Soft Computing, ICECDS 2017",,"10.1109/ICECDS.2017.8389758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050151421&doi=10.1109%2fICECDS.2017.8389758&partnerID=40&md5=881c92909016fbf2f0a07a3ecbeda219","To overcome the obstacle of visual chess simulators, a system is proposed in which visually impaired individuals can practice by using only voice commands. In addition, this system will be powered using machine learning algorithms with the help of a publicly available repository of over five million games. This will make the user feel like he/she is playing against another human and not a machine. The existing chess systems use a variety of algorithms in order to choose its move. Most of these use tree traversals and the most common one is the min-max algorithm with alpha-beta pruning. Min-max algorithm finds the best move, and alpha-beta pruning prevents it from going into branches of the game tree that cannot yield a better result than previously traversed branches. Since the tree generated in a chess game is very deep and have a lot nodes, these algorithms examine the depth only to a certain amount. Generally, these algorithms are accompanied by an opening repository which bolsters the algorithm's efficiency. Since these algorithms are too strong for a visually impaired individual, a new approach is suggested to choose the computer's move. A publicly available repository of over five million chess games played by humans will be used to train the machine, initially. When the user makes his/her move, it will be converted into text and given as input to both the Minimax and the k-NN algorithms. The moves given as output by both these algorithms are compared using an evaluation function. The move with a higher score is chosen. The game continues till a decisive result is obtained. © 2017 IEEE.","Alpha-beta pruning; Hidden Markov Model; K-nearest neighbour; Minimax model; Speech Recognition","Institute of Electrical and Electronics Engineers Inc."
"Lokhmotov A., Vella F., Chunosov N., Fursin G.","Multi-objective autotuning of mobile nets across the full software/hardware stack",2018,"Proceedings of the 1st Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning, ReQuEST 2018 -  Co-located with ACM ASPLOS 2018",6,"10.1145/3229762.3229767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050640500&doi=10.1145%2f3229762.3229767&partnerID=40&md5=6d25482a63264f6f1e2ce6fa75a2af81","We present a customizable Collective Knowledge workflow to study the execution time vs. accuracy trade-offs for the MobileNets CNN family. We use this workflow to evaluate MobileNets on Arm Cortex CPUs using TensorFlow and Arm Mali GPUs using several versions of the Arm Compute Library. Our optimizations for the Arm Bifrost GPU architecture reduce the execution time by 2-3 times, while lying on a Pareto-optimal frontier. We also highlight the challenge of maintaining the accuracy when deploying CNN models across diverse platforms. We make all the workflow components (models, programs, scripts, etc.) publicly available to encourage further exploration by the community. © 2018 Copyright held by the owner/author(s).","Accuracy; Autotuning; Collective Knowledge; Crowdtuning; Customizable workflows; Live scoreboard; MobileNets; Performance; Reproducible experimentation; System co-design","Association for Computing Machinery, Inc"
"Gong J., Shen H., Zhang G., Liu X., Li S., Jin G., Maheshwari N., Fomenko E., Segal E.","Highly efficient 8-bit low precision inference of convolutional neural networks with intelcaffe",2018,"Proceedings of the 1st Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning, ReQuEST 2018 -  Co-located with ACM ASPLOS 2018",16,"10.1145/3229762.3229763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050615667&doi=10.1145%2f3229762.3229763&partnerID=40&md5=e520e32864b3752fe79e78b76e7f7a5f","High throughput and low latency inference of deep neural networks are critical for the deployment of deep learning applications. This paper presents the efficient inference techniques of IntelCaffe, the first Intel optimized deep learning framework that supports efficient 8-bit low precision inference and model optimization techniques of convolutional neural networks on Intel Xeon Scalable Processors. The 8-bit optimized model is automatically generated with a calibration process from FP32 model without the need of fine-tuning or retraining. We show that the inference throughput and latency with ResNet-50, Inception-v3 and SSD are improved by 1.38X-2.9X and 1.35X-3X respectively with neglectable accuracy loss from IntelCaffe FP32 baseline and by 56X-75X and 26X-37X from BVLC Caffe. All these techniques have been open-sourced on IntelCaffe GitHub1, and the artifact is provided to reproduce the result on Amazon AWS Cloud. © 2018 Association for Computing Machinery.","Convolutional Neural Network; Deep Learning; Intel Caffe; Model Optimization","Association for Computing Machinery, Inc"
"Zheng L., Chen T.","Optimizing deep learning workloads on ARM GPU with TVM",2018,"Proceedings of the 1st Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning, ReQuEST 2018 -  Co-located with ACM ASPLOS 2018",4,"10.1145/3229762.3229764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050614744&doi=10.1145%2f3229762.3229764&partnerID=40&md5=ac1752a490d23ffe47b661861ea67c2e","With the great success of deep learning, the demand for deploying deep neural networks to mobile devices is growing rapidly. However, current popular deep learning frameworks are often poorly optimized for mobile devices, especially mobile GPU. In this paper, we follow the pipeline proposed by TVM/NNVM, and optimize both kernel implementations and dataflow graph for ARM Mali GPU. Compared with vendor-provided ARM Compute Library, our kernel implementations and end-to-end pipeline are 1.7x faster on VGG16 and 2.2x faster on mobilenet. © 2018 Copyright held by the owner/author(s).","ARM GPU; Deep Learning; GPU Kernel; TVM","Association for Computing Machinery, Inc"
"Hadidi R., Cao J., Woodward M., Ryoo M.S., Kim H.","Real-time image recognition using collaborative IoT devices",2018,"Proceedings of the 1st Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning, ReQuEST 2018 -  Co-located with ACM ASPLOS 2018",9,"10.1145/3229762.3229765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050592607&doi=10.1145%2f3229762.3229765&partnerID=40&md5=ac5323ce29d672ee2102f42dc93a675f","Internet of things (IoT) devices capture and create various forms of sensor data such as images and videos. However, such resource-constrained devices lack the capability to efficiently process data in a timely and real-time manner. Therefore, IoT systems strongly rely on a powerful server (either local or on the cloud) to extract useful information from data. In addition, during communication with servers, unprocessed, sensitive, and private data is transmitted throughout the Internet, a serious vulnerability. What if we were able to harvest the aggregated computational power of already existing IoT devices in our system to locally process this data? In this artifact, we utilize Musical Chair [3], which enables efficient, localized, and dynamic real-time recognition by harvesting the aggregated computational power of these resource-constrained IoT devices. We apply Musical chair to two well-known image recognition models, AlexNet and VGG16, and implement them on a network of Raspberry PIs (up to 11). We compare inference per second and energy per inference of our systems with Tegra TX2, an embedded low-power platform with a six-core CPU and a GPU. We demonstrate that the collaboration of IoT devices, enabled by Musical Chair, achieves similar real-time performance without the extra costs of maintaining a server. © 2018 Association for Computing Machinery.",,"Association for Computing Machinery, Inc"
"van Rooyen B., Williamson R.C.","A theory of learning with corrupted labels",2018,"Journal of Machine Learning Research",9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053693546&partnerID=40&md5=7288b67fc107d4e6635b25eadf71f452","It is usual in machine learning theory to assume that the training and testing sets comprise of draws from the same distribution. This is rarely, if ever, true and one must admit the presence of corruption. There are many different types of corruption that can arise and as of yet there is no general means to compare the relative ease of learning in these settings. Such results are necessary if we are to make informed economic decisions regarding the acquisition of data. Here we begin to develop an abstract framework for tackling these problems. We present a generic method for learning from a fixed, known, reconstructible corruption, along with an analyses of its statistical properties. We demonstrate the utility of our framework via concrete novel results in solving supervised learning problems wherein the labels are corrupted, such as learning with noisy labels, semi-supervised learning and learning with partial labels. ©2018 Brendan van Rooyen, Robert C. Williamson.","Data processing; Decision theory; Generalized supervision; Minimax bounds; Noise; Supervised learning","Microtome Publishing"
"Pavlidis G.","Apollo - A Hybrid Recommender for Museums and Cultural Tourism",2018,"9th International Conference on Intelligent Systems 2018: Theory, Research and Innovation in Applications, IS 2018 - Proceedings",4,"10.1109/IS.2018.8710494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065994472&doi=10.1109%2fIS.2018.8710494&partnerID=40&md5=26c88ace571ab18f3cba6478356e86a7","This paper introduces Apollo, a novel hybrid recommender for free-roaming or guided museum visits and cultural tourism. The recommender is based on a new conceptualisation of a visit and the adoption of a minimax (or 'conservative') approach towards user satisfaction modelling. The approach is based on the integration of temporal, spatial and content dynamics captured during a visit and contribute to an estimate of the user satisfaction and a development of an optimal route as a sequence of points of interest. Apollo follows a minimax approach by targeting the minimisation of the highest possible user dissatisfaction or disengagement, rather than looking for a maximisation of the user satisfaction. A considerable effort has been dedicated to the creation of realistic simulation data for items (the exhibits), users (the visitors), and a small amount of ratings of the items by some of the users with specific characteristics selected to represent a realistic scenario. Extensive visit simulations have been conducted and results show a considerable decrease of the probable user dissatisfaction in relation to a baseline recommender. © 2018 IEEE.","Artificial intelligence; Cultural heritage; Electronic guide; Machine learning; Recommendation; Recommender; Recommender system","Institute of Electrical and Electronics Engineers Inc."
"Chugh T., Allmendinger R., Ojalehto V., Miettinen K.","Surrogate-assisted evolutionary biobjective optimization for objectives with non-uniform latencies",2018,"GECCO 2018 - Proceedings of the 2018 Genetic and Evolutionary Computation Conference",7,"10.1145/3205455.3205514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050641440&doi=10.1145%2f3205455.3205514&partnerID=40&md5=4a21f3188812065637daaafd4bc258f2","We consider multiobjective optimization problems where objective functions have different (or heterogeneous) evaluation times or latencies. This is of great relevance for (computationally) expensive multiobjective optimization as there is no reason to assume that all objective functions should take an equal amount of time to be evaluated (particularly when objectives are evaluated separately). To cope with such problems, we propose a variation of the Kriging-assisted reference vector guided evolutionary algorithm (K-RVEA) called heterogeneous K-RVEA (short HK-RVEA). This algorithm is a merger of two main concepts designed to account for different latencies: A single-objective evolutionary algorithm for selecting training data to train surrogates and K-RVEA's approach for updating the surrogates. HK-RVEA is validated on a set of biobjective benchmark problems varying in terms of latencies and correlations between the objectives. The results are also compared to those obtained by previously proposed strategies for such problems, which were embedded in a non-surrogate-assisted evolutionary algorithm. Our experimental study shows that, under certain conditions, such as short latencies between the two objectives, HK-RVEA can outperform the existing strategies as well as an optimizer operating in an environment without latencies. © 2018 Association for Computing Machinery.","Bayesian optimization; Expensive optimization; Heterogeneous objectives; Machine learning; Metamodelling; Multiobjective optimization; Pareto optimality","Association for Computing Machinery, Inc"
"Garciarena U., Santana R., Mendiburu A.","Evolved GANs for generating Pareto set approximations",2018,"GECCO 2018 - Proceedings of the 2018 Genetic and Evolutionary Computation Conference",17,"10.1145/3205455.3205550","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050615587&doi=10.1145%2f3205455.3205550&partnerID=40&md5=19f177223fa2c136e00a7783ea2c24d0","In machine learning, generative models are used to create data samples that mimic the characteristics of the training data. Generative adversarial networks (GANs) are neural-network based generator models that have shown their capacity to produce realistic samples in different domains. In this paper we propose a neuro-evolutionary approach for evolving deep GAN architectures together with the loss function and generator-discriminator synchronization parameters. We also propose the problem of Pareto set (PS) approximation as a suitable benchmark to evaluate the quality of neural-network based generators in terms of the accuracy of the solutions they generate. The covering of the Pareto front (PF) by the generated solutions is used as an indicator of the mode-collapsing behavior of GANs. We show that it is possible to evolve GANs that generate good PS approximations. Our method scales to up to 784 variables and that it is capable to create architecture transferable across dimensions and functions. © 2018 Association for Computing Machinery.","Generative adversarial network; Machine learning; Neuroevolution","Association for Computing Machinery, Inc"
"Mücke N., Blanchard G.","Parallelizing spectrally regularized kernel algorithms",2018,"Journal of Machine Learning Research",21,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053358900&partnerID=40&md5=eea8f886c27c04a27992ec3a8451efea","We consider a distributed learning approach in supervised learning for a large class of spectral regularization methods in an reproducing kernel Hilbert space (RKHS) framework. The data set of size n is partitioned into m = O(n α), α < 1 2 , disjoint subsamples. On each subsample, some spectral regularization method (belonging to a large class, including in particular Kernel Ridge Regression, L2-boosting and spectral cut-off) is applied. The regression function f is then estimated via simple averaging, leading to a substantial reduction in computation time. We show that minimax optimal rates of convergence are preserved if m grows sufficiently slowly (corresponding to an upper bound for α) as n → ∞, depending on the smoothness assumptions on f and the intrinsic dimensionality. In spirit, the analysis relies on a classical bias/stochastic error analysis. © 2018 Nicole Mücke and Gilles Blanchard.","Distributed Learning; Minimax Optimality; Spectral Regularization","Microtome Publishing"
"Turgut M.S., Turgut O.E.","Ensemble Shuffled Population Algorithm for multi-objective thermal design optimization of a plate frame heat exchanger operated with Al2O3/water nanofluid",2018,"Applied Soft Computing Journal",4,"10.1016/j.asoc.2018.04.057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046712825&doi=10.1016%2fj.asoc.2018.04.057&partnerID=40&md5=0312e9a568a089496867de6e53817959","This study proposes a brand new optimization algorithm entitled Ensemble Shuffled Population Algorithm for solving multidimensional optimization problems. The proposed algorithm adopts the perturbation equations of the Crow Search and Differential Search algorithms with useful modifications on them and aims to maintain a reasonable balance between the intensification and diversification phases of the algorithm. A batch of 22 benchmark problems consisting of unimodal and multimodal unconstrained optimization test functions are applied using this algorithm to assess its performance on multi dimensional problems. Statistical results obtained from the proposed Ensemble Shuffled Population Algorithm are compared to those found by eleven well known metaheuristic optimizers. The comparison results show that the Ensemble Shuffled Population Algorithm outperforms the compared optimizers with regards to solution accuracy and convergence speed. After that, the proposed algorithm is applied on a multi objective optimization of a plate frame heat exchanger operated with Al2O3 nanofluid. The optimization results show that utilizing nanoparticles instead of base fluid not only increases the overall heat transfer coefficient rates but also entails a huge decline in total cost values. A Pareto frontier is constructed for these two conflicting objectives to select the final optimum solution from the set of non-dominated solutions by virtue of three famous decision making methods of LINMAP, TOPSIS, and Shannon's entropy theory. Then, sensitivity analysis is performed to observe the variational effects of the design variables on the optimization objectives. © 2018 Elsevier B.V.","Ensemble learning; Nanofluids; Plate frame heat exchanger; Stochastic optimization","Elsevier Ltd"
"Jiang M., Huang Z., Qiu L., Huang W., Yen G.G.","Transfer Learning-Based Dynamic Multiobjective Optimization Algorithms",2018,"IEEE Transactions on Evolutionary Computation",112,"10.1109/TEVC.2017.2771451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033677778&doi=10.1109%2fTEVC.2017.2771451&partnerID=40&md5=fd116b59b177b960674d7c8402ac16b1","One of the major distinguishing features of the dynamic multiobjective optimization problems (DMOPs) is that optimization objectives will change over time, thus tracking the varying Pareto-optimal front becomes a challenge. One of the promising solutions is reusing 'experiences' to construct a prediction model via statistical machine learning approaches. However, most existing methods neglect the nonindependent and identically distributed nature of data to construct the prediction model. In this paper, we propose an algorithmic framework, called transfer learning-based dynamic multiobjective evolutionary algorithm (EA), which integrates transfer learning and population-based EAs to solve the DMOPs. This approach exploits the transfer learning technique as a tool to generate an effective initial population pool via reusing past experience to speed up the evolutionary process, and at the same time any population-based multiobjective algorithms can benefit from this integration without any extensive modifications. To verify this idea, we incorporate the proposed approach into the development of three well-known EAs, nondominated sorting genetic algorithm II, multiobjective particle swarm optimization, and the regularity model-based multiobjective estimation of distribution algorithm. We employ 12 benchmark functions to test these algorithms as well as compare them with some chosen state-of-the-art designs. The experimental results confirm the effectiveness of the proposed design for DMOPs. © 1997-2012 IEEE.","Dimensionality reduction; domain adaption; dynamic multiobjective optimization; evolutionary algorithm (EA); transfer learning","Institute of Electrical and Electronics Engineers Inc."
"Li C.T., Wu X., Ozgur A., El Gamal A.","Minimax Learning for Remote Prediction",2018,"IEEE International Symposium on Information Theory - Proceedings",5,"10.1109/ISIT.2018.8437318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052446182&doi=10.1109%2fISIT.2018.8437318&partnerID=40&md5=226e7e484255c1b274718bcd201a41e7","The classical problem of supervised learning is to infer an accurate predictor of a target variable Y from a measured variable X by using a finite number of labeled training samples. Motivated by the increasingly distributed nature of data and decision making, in this paper we consider a variation of this classical problem in which the prediction is performed remotely based on a rate-constrained description M of X. Upon receiving M, the remote node computes an estimate Y of Y. We follow the recent minimax approach to study this learning problem and show that it corresponds to a one-shot minimax noisy source coding problem. We then establish information theoretic bounds on the risk-rate Lagrangian cost and a general method to design a near-optimal descriptor-estimator pair, which can be viewed as a rate-constrained analog to the maximum conditional entropy principle used in the classical minimax learning problem. Our results show that a naive estimate-compress scheme for rate-constrained prediction is not in general optimal. © 2018 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Rezaei M., Shirazi M.A., Karimi B.","Amulti-objective SCOR-based decision alignment for supply chain performance management",2018,"Scientia Iranica",3,"10.24200/sci.2017.4463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055776694&doi=10.24200%2fsci.2017.4463&partnerID=40&md5=7d5ecc078e321c329295fa541109a685","A dynamic integrated solution to three main problems through integrating all metrics using SCOR is proposed in this research. This dynamic solution comprises strategic decisions in high level, operational decisions in low level, and alignment of these two decision levels. In this regard, a human intelligence-based process for high-level decisions and machine-intelligence based Decision Support Systems (DSSs) for low-level decisions are proposed using a novel approach. The presented operational model considers important supply chain features thoroughly, such as different echelons, several suppliers, several manufacturers, and several products, during multiple periods. A multi-objective mathematical programming model is then developed to yield the operational decisions with Pareto efficient performance values and solved using a well-known meta-heuristic algorithm, i.e., NSGAII, the parameters of which are tuned using Taguchi method. Afterwards, an intermediate machine-intelligence module is used to determine the best operational solution based on the strategic idea of the decision maker. The efficiency of the proposed framework is shown through numerical example and then, a sensitivity analysis is conducted for the obtained results so as to show the impact of the strategic scenario planning on the performance of the considered supply chain. © 2018 Sharif University of Technology. All rights reserved.","Decision alignment; Multi-objective; NSGAII; Performance management; SCOR model; Supply chain","Sharif University of Technology"
"Mitsunari K., Yu J., Onoye T., Hashimoto M.","Hardware architecture for high-speed object detection using decision tree ensemble",2018,"IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences",3,"10.1587/transfun.E101.A.1298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053846877&doi=10.1587%2ftransfun.E101.A.1298&partnerID=40&md5=a57f365adcbcca43fb54734a09c1e00b","Visual object detection on embedded systems involves a multi-objective optimization problem in the presence of trade-offs between power consumption, processing performance, and detection accuracy. For a new Pareto solution with high processing performance and low power consumption, this paper proposes a hardware architecture for decision tree ensemble using multiple channels of features. For efficient detection, the proposed architecture utilizes the dimensionality of feature channels in addition to parallelism in image space and adopts task scheduling to attain random memory access without conflict. Evaluation results show that an FPGA implementation of the proposed architecture with an aggregated channel features pedestrian detector can process 229 million samples per second at 100MHz operation frequency while it requires a relatively small amount of resources. Consequently, the proposed architecture achieves 350 fps processing performance for 1080P Full HD images and outperforms conventional object detection hardware architectures developed for embedded systems. © 2018 The Institute of Electronics, Information and Communication Engineers.","Decision tree ensemble; Embedded systems; Machine learning; Object detection; Task scheduling","Institute of Electronics, Information and Communication, Engineers, IEICE"
"Yamanishi K., Fukushima S.","Model Change Detection With the MDL Principle",2018,"IEEE Transactions on Information Theory",9,"10.1109/TIT.2018.2852747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049466201&doi=10.1109%2fTIT.2018.2852747&partnerID=40&md5=53cb6a50fdf00f327f05f5ec55b9d711","We are concerned with the issue of detecting model changes in probability distributions. We specifically consider the strategies based on the minimum description length (MDL) principle. We theoretically analyze their basic performance from the two aspects: data compression and hypothesis testing. From the view of data compression, we derive a new bound on the minimax regret for model changes. Here, the mini-max regret is defined as the minimum of the worst-case code-length relative to the least normalized maximum likelihood code-length over all model changes. From the view of hypothesis testing, we reduce the model change detection into a simple hypothesis testing problem. We thereby derive upper bounds on error probabilities for the MDL-based model change test. The error probabilities are valid for finite sample size and are related to the information-theoretic complexity as well as the discrepancy measure of the hypotheses to be tested. © 2018 IEEE.","change detection; hypothesis testing; machine learning; MDL principle","Institute of Electrical and Electronics Engineers Inc."
"Safari M.J.S., Danandeh Mehr A.","Multigene genetic programming for sediment transport modeling in sewers for conditions of non-deposition with a bed deposit",2018,"International Journal of Sediment Research",35,"10.1016/j.ijsrc.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046723844&doi=10.1016%2fj.ijsrc.2018.04.007&partnerID=40&md5=3662166786e49faaf76551058b9f64a6","It is known that construction of large sewers based on consideration of flow with non-deposition without a bed deposit is not economical. Sewer design based on consideration of flow with non-deposition with a bed deposit reduces channel bed slope and construction cost in which the presence of a small depth of sediment deposition on the bed increases the sediment transport capacity of the flow. This paper suggests a new Pareto-optimal model developed by the multigene genetic programming (MGGP) technique to estimate particle Froude number (Frp) in large sewers with conditions of sediment deposition on the bed. To this end, four data sets including wide ranges of sediment size and concentration, deposit thickness, and pipe size are used. On the basis of different statistical performance indices, the efficiency of the proposed Pareto-optimal MGGP model is compared to those of the best MGGP model developed in the current study as well as the conventional regression models available in the literature. The results indicate the higher efficiency of the MGGP-based models for Frp estimation in the case of no additional deposition onto a bed with a sediment deposit. Inasmuch as the Pareto-optimal MGGP model utilizes a lower number of input parameters to yield comparatively higher performance than the conventional regression models, it can be used as a parsimonious model for self-cleansing design of large sewers in practice. © 2018 International Research and Training Centre on Erosion and Sedimentation/the World Association for Sedimentation and Erosion Research","Bed deposition; Bed load; Multigene genetic programming; Non-deposition; Sediment transport; Sewer","Elsevier B.V."
"Awan D.A., Cavalcante R.L.G., Stanczak S.","A Robust Machine Learning Method for Cell-Load Approximation in Wireless Networks",2018,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",5,"10.1109/ICASSP.2018.8462320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054257519&doi=10.1109%2fICASSP.2018.8462320&partnerID=40&md5=8a2f864a92901a150a7ddf7c61191415","We propose a learning algorithm for cell-load approximation in wireless networks. The proposed algorithm is robust in the sense that it is designed to cope with the uncertainty arising from a small number of training samples. This scenario is highly relevant in wireless networks where training has to be performed on short time scales because of a fast time-varying communication environment. The first part of this work studies the set of feasible rates and shows that this set is compact. We then prove that the mapping relating a feasible rate vector to the unique fixed point of the non-linear cell-load mapping is monotone and uniformly continuous. Utilizing these properties, we apply an approximation framework that achieves the best worst-case performance. Furthermore, the approximation preserves the monotonicity and continuity properties. Simulations show that the proposed method exhibits better robustness and accuracy for small training sets in comparison with standard approximation techniques for multivariate data. © 2018 IEEE.","5G; Data interpolation; Machine learning; Minimax approximation; Multivariate scattered data","Institute of Electrical and Electronics Engineers Inc."
"Nascimento Z., Sadok D.","MODC: A pareto-optimal optimization approach for network traffic classification based on the divide and conquer strategy",2018,"Information (Switzerland)",3,"10.3390/info9090233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053610139&doi=10.3390%2finfo9090233&partnerID=40&md5=2713e9850da77e8a92fe7b10cbe0b0e9","Network traffic classification aims to identify categories of traffic or applications of network packets or flows. It is an area that continues to gain attention by researchers due to the necessity of understanding the composition of network traffics, which changes over time, to ensure the network Quality of Service (QoS). Among the different methods of network traffic classification, the payload-based one (DPI) is the most accurate, but presents some drawbacks, such as the inability of classifying encrypted data, the concerns regarding the users' privacy, the high computational costs, and ambiguity when multiple signatures might match. For that reason, machine learning methods have been proposed to overcome these issues. This work proposes a Multi-Objective Divide and Conquer (MODC) model for network traffic classification, by combining, into a hybrid model, supervised and unsupervised machine learning algorithms, based on the divide and conquer strategy. Additionally, it is a flexible model since it allows network administrators to choose between a set of parameters (pareto-optimal solutions), led by a multi-objective optimization process, by prioritizing flow or byte accuracies. Our method achieved 94.14% of average flow accuracy for the analyzed dataset, outperforming the six DPI-based tools investigated, including two commercial ones, and other machine learning-based methods. © 2018 by the authors.","Extreme learning machine; Growing hierarchical self-organizing map; Hybrid model; Machine learning; Multi-objective genetic algorithm; Network traffic classification","MDPI AG"
"Luck L., Moser A.","Combining machine learning and multi criteria decision analysis modeling regulatory, economic and social influences on wind turbine allocation",2018,"International Conference on the European Energy Market, EEM",2,"10.1109/EEM.2018.8470016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055536881&doi=10.1109%2fEEM.2018.8470016&partnerID=40&md5=dd67c5bcf11b648584ae16a61be6c70d","Knowledge about the future allocation of wind turbines is relevant for assessments of energy markets or necessary grid expansions. In Germany, political decisions drive the allocation together with investment decisions, social rejections, land use planning, regional development and ecological aspects. Taking all influences into account, a standardized multi-criteria optimization problem combining economic suitability, residential burden and site suitability calculates the regional distribution of wind turbines as input for further assessments. By considering the political framework as boundary conditions for the optimization and detailed geographic area suitability factors using a machine learning approach as input parameters, it is possible to assess effects of regulatory restrictions on regional developments. We use a backtesting for validation and weighting of the objectives. Sensitivities of changing regulatory frameworks modeled as different boundary conditions show effects of changing political decisions. © 2018 IEEE.","Distributed Power Generation; Machine Learning; Pareto Optimization; Power System Planning; Wind Energy Integration","IEEE Computer Society"
"Tahmassebi A., Gandomi A.H., Meyer-Baese A.","A Pareto Front Based Evolutionary Model for Airfoil Self-Noise Prediction",2018,"2018 IEEE Congress on Evolutionary Computation, CEC 2018 - Proceedings",3,"10.1109/CEC.2018.8477987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056273338&doi=10.1109%2fCEC.2018.8477987&partnerID=40&md5=eab642e71ace26ce55604b0651184867","According to NASA's report on the technologies that could reduce external aircraft noise by 10 dB, a challenge equally as important as finding approaches on airframe noise reduction is the demand to bring up strategies by which airframe noise can be predicted both accurately and rapidly. One of the components of the overall airframe noise is the self-noise of the airfoil itself. In this paper, an evolutionary symbolic implementation for airfoil self-noise prediction was proposed. Multi-objective genetic programming as a subset of evolutionary computation along with adaptive regression by mixing algorithm was used to create an executable fused model. The developed model was tested on the airfoil self-noise database and the performance of the developed model was compared to the previous works and benchmark machine learning algorithms. The reasonable results suggest that the proposed model can be applied to noise generation by low-Mach-number turbulent flows in aerospace, automobile, underwater, and wind turbine acoustic communities. © 2018 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Neto Verri F.A., Tinós R., Zhao L.","Feature Learning in Feature-Sample Networks Using Multi-Objective Optimization",2018,"2018 IEEE Congress on Evolutionary Computation, CEC 2018 - Proceedings",,"10.1109/CEC.2018.8477891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056264449&doi=10.1109%2fCEC.2018.8477891&partnerID=40&md5=55ae53238794fe88a9cff17eab862319","Data and knowledge representation are fundamental concepts in machine learning. The quality of the representation impacts the performance of a learning model directly. Feature learning transforms or enhances raw data to structures that are effectively exploited by those methods. In recent years, several works have been using complex networks for data representation and analysis. However, no feature learning method has been proposed to enhance such category of representation. Here, we present an unsupervised feature learning mechanism that works on datasets with binary features. First, the dataset is mapped into a feature-sample network. Then, a multi-objective optimization process selects a set of new vertices to produce an enhanced version of the network. The new features depend on a nonlinear function of a combination of preexisting features. Effectively, the process projects the input data into a higher-dimensional space. To solve the optimization problem, we design two metaheuristics based on the lexicographic genetic algorithm and the improved strength Pareto evolutionary algorithm (SPEA2). We show that the enhanced network contains more useful information and can be exploited to improve the performance of machine learning methods. The advantages and disadvantages of each optimization strategy are discussed. © 2018 IEEE.","complex networks; Feature learning; genetic algorithm; multiobjective optimization","Institute of Electrical and Electronics Engineers Inc."
"Alves Ribeiro V.H., Reynoso-Meza G.","Multi-objective Support Vector Machines Ensemble Generation for Water Quality Monitoring",2018,"2018 IEEE Congress on Evolutionary Computation, CEC 2018 - Proceedings",4,"10.1109/CEC.2018.8477745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056253826&doi=10.1109%2fCEC.2018.8477745&partnerID=40&md5=3154f668c7c3eebb8c538ebf510a37dd","Real-world classification problems generally deal with imbalanced data, where one class represents the majority of the data set. The present work deals with event detection on a drinking-water quality time series, where the presence of a quality event is the minority class. In order to solve such problems, supervised learning algorithms are recommended. Researchers have also used multi-objective optimization (MOO) in order to generate diverse models to build ensembles of classifiers. Although MOO has been used for ensemble member generation, there is a lack on it's application for member selection, which is usually done by selecting a specific subset from the resulting models, or by using meta-algorithms, such as boosting. The proposed work comprises the application of MOO design in the whole process of ensemble generation. To do so, one multi-objective problem (MOP) is defined for the creation of a set of non-dominated solutions with Pareto-optimal support vector machines (SVM). After that, a second MOP is defined for the selection of such SVMs as members of an ensemble. Such methodology is compared to other member selection methods, such as: The single best classifier, an ensemble composed of the full set of non-dominated solutions, and the selection of a specific subset from the Pareto front. Results show that the proposed method is suitable for the creation of ensembles, achieving the highest classification scores. © 2018 IEEE.","ensemble methods; genetic algorithms; machine learning; supervised learning; support vector machines","Institute of Electrical and Electronics Engineers Inc."
"Mariani G., Anghel A., Jongerius R., Dittmann G.","Predicting cloud performance for HPC applications before deployment",2018,"Future Generation Computer Systems",8,"10.1016/j.future.2017.10.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034856193&doi=10.1016%2fj.future.2017.10.048&partnerID=40&md5=024751ae81c224e24df6de4b5bd3198a","To reduce the capital investment required to acquire and maintain a high performance computing cluster, today many HPC users are moving to cloud. When deploying an application in the cloud, the users may (a) fail to understand the interactions of the application with the software layers implementing the cloud system, (b) be unaware of some hardware details of the cloud system, and (c) fail to understand how sharing part of the cloud system with other users might degrade application performance. These misunderstandings may lead the users to select suboptimal cloud configurations in terms of cost or performance. In this work we propose a machine-learning methodology to support the user in the selection of the best cloud configuration to run the target workload before deploying it in the cloud. This enables the user to decide if and what to buy before facing the cost of porting and analyzing the application in the cloud. We couple a cloud-performance-prediction model (CP) on the cloud-provider side with a hardware-independent profile-prediction model (PP) on the user-side. PP captures the application-specific scaling behavior. The user profiles the target application while processing small datasets on small machines she (or he) owns, and applies machine learning to generate PP to predict the profiles for larger datasets to be processed in the cloud. CP is generated by the cloud provider to learn the relationships between the hardware-independent profile and cloud performance starting from the observations gathered by executing a set of training applications on a set of training cloud configurations. Since the profile data in use is hardware-independent the user and the provider can generate the prediction models independently possibly on heterogeneous machines. We apply the prediction models to Fortran-MPI benchmarks. The resulting relative error is below 12% for CP and 30% for PP. The optimal Pareto front of cloud configurations finally found when maximizing performance and minimizing execution cost on the prediction models is at most 25% away from the actual optimal solutions. © 2017 Elsevier B.V.","Cloud computing; Performance prediction; Random forest","Elsevier B.V."
"Song H., Qin A.K., Salim F.D.","Evolutionary Multi-objective Ensemble Learning for Multivariate Electricity Consumption Prediction",2018,"Proceedings of the International Joint Conference on Neural Networks",5,"10.1109/IJCNN.2018.8489261","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056556521&doi=10.1109%2fIJCNN.2018.8489261&partnerID=40&md5=cf738e50f1889344b1a3b88be12e6235","Energy consumption prediction typically corresponds to a multivariate time series prediction task where different channels in the multivariate time series represent energy consumption data and various auxiliary data related to energy consumption such as environmental factors. It is non-trivial to resolve this task, which requires finding the most appropriate prediction model and the most useful features (extracted from the raw data) to be used by the model. This work proposes an evolutionary multi-objective ensemble learning (EMOEL) technique which uses extreme learning machines (ELMs) as base predictors due to its highly recognized efficacy. EMOEL employs evolutionary multi-objective optimization to search for the optimal parameters of the model as well as the optimal features fed into the model subjected to two conflicting criteria, i.e., accuracy and diversity. It leads to a Pareto front composed of non-dominated optimal solutions where each solution depicts the number of hidden neurons in the ELM, the selected channels in the multivariate time series, the selected feature extraction methods and the selected time windows applied to the selected channels. The optimal solutions in the Pareto front stand for different end-to-end prediction models which may lead to different prediction results. To boost ultimate prediction accuracy, the models with respect to these optimal solutions are linearly combined with combination coefficients being optimized via an evolutionary algorithm. We evaluate the proposed method in comparison to some existing prediction techniques on an Australian University based dataset, which demonstrates the superiority of the proposed method. © 2018 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Jesus J., Canuto A., Araujo D.","Dynamic Feature Selection Based on Pareto Front Optimization",2018,"Proceedings of the International Joint Conference on Neural Networks",3,"10.1109/IJCNN.2018.8489680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056555735&doi=10.1109%2fIJCNN.2018.8489680&partnerID=40&md5=71c3945cab192a96830dee6db82b9c42","One of the main issues of machine learning algorithms is the curse of dimensionality. With the fast growing of complex data in real world scenarios, the feature selection becomes a mandatory preprocessing step in any application to reduce both the complexity of the data and the computing time. Based on that, several works have been produced in order to develop efficient methods to perform this task. Most feature selection methods select the best attributes based on some specific criteria. Additionally, recent studies have successfully constructed models to select features considering the particularities of the data, assuming that similar samples should be treated separately. Although some advance has been made, a bad choice of one single criteria to evaluate the importance of the attributes and the arbitrary choice of the number of features made by the user can lead to a poor analysis. In order to overcome some of these issues, this work brings an improvement of a dynamic feature selection algorithm (DFS) by using the idea of pareto front multi-objective optimization, which allow us to both consider distinct perspectives of the features relevance and automatically set the number of attributes to select. We tested our approach using 15 artificial and real world data and results have shown that when compared to the original DFS method, the performance of the proposed method is remarkable superior. In fact, the results are very promising since the proposed method also achieved better performance than well-established dimensionality reduction methods and when using the original datasets, showing that the reduction of noisy and/or redundant attributes can have a positive effect in the performance of a classification task. © 2018 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Li R., Jin Y.","A wind speed interval prediction system based on multi-objective optimization for machine learning method",2018,"Applied Energy",78,"10.1016/j.apenergy.2018.07.032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050268174&doi=10.1016%2fj.apenergy.2018.07.032&partnerID=40&md5=6a88c03f2e31c67ca1136ce972bef91a","Accurate forecast of wind speed is the first prerequisite to supply high quality power energy to customer in a secure and economic manner. However, traditional point forecast may not be sufficiently reliable and accurate for decision-makers to perform operational strategies purely when the uncertainty level increases. For the sake of quantifying the uncertainty associated with point predictions, it is necessary to conduct interval prediction to provide reliable and accurate wind speed information. In this work, a hybrid model framework based on combinatorial modules was proposed and successfully adopted to construct the prediction intervals of the future wind speed. Feature selection methods are developed to determine the most suitable modes of original time series and the optimal input form of the model, while the optimization forecasting module is applied to model the wind speed series based on the machine learning method and the multi-objective optimization algorithm, then the compromise solution of Pareto front is chosen by “Min-max” method. Finally, the proposed combined model was investigated via the hourly wind speed data from two different periods in Penglai, China. Besides, the study's experimental results indicated that the prediction intervals generated perform well and are satisfactory in both criterion functions of high coverage and small width through discussion among single-objective models and other multi-objective models (signal pre-processing method comparison included). © 2018 Elsevier Ltd","Feature selection; Least squares support vector machines; Multi-objective optimization; Prediction intervals; Wind speed forecasting","Elsevier Ltd"
"Khairullin E., Ustyuzhanin A.","Speeding up prediction performance of BDT-based models",2018,"Journal of Physics: Conference Series",,"10.1088/1742-6596/1085/4/042009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055788690&doi=10.1088%2f1742-6596%2f1085%2f4%2f042009&partnerID=40&md5=d9743784f11d4f94b8a60fc8135efba2","The outcome of a machine learning algorithm is a prediction model. Typically, these models are computationally expensive, where improving of the quality the prediction leads to a decrease in the inference speed. However it is not always tradeoff between quality and speed. In this paper we show it is possible to speed up the model by using additional memory without losing significat prediction quality for a novel boosted trees algorithm called CatBoost. The idea is to combine two approaches: training fewer trees and merging trees into a kind of hashmaps called DecisionTensors. The proposed method allows for pareto-optimal reduction of the computational complexity of the decision tree model with regard to the quality of the model. In the considered example the number of lookups was decreased from 5000 to only 6 (speedup factor of 1000) while AUC score of the model was reduced by less than 10-3. © Published under licence by IOP Publishing Ltd.",,"IOP Publishing Ltd"
"Tohuvavohu A.","Improving science yield for NASA Swift with automated planning technologies",2018,"Journal of Physics: Conference Series",1,"10.1088/1742-6596/1085/3/032010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055649627&doi=10.1088%2f1742-6596%2f1085%2f3%2f032010&partnerID=40&md5=cd5c6bd09a9586e523ae8dac46ce11e8","The Neil Gehrels Swift Observatory is a uniquely capable mission, with three on-board instruments and rapid slewing capabilities. It serves as a fast-response satellite observatory for everything from gravitational-wave counterpart searches to cometary science. Swift averages 125 different observations per day, and is consistently over-subscribed, responding to about one-hundred Target of Oportunity (ToO) requests per month from the general astrophysics community, as well as co-pointing and follow-up agreements with many other observatories. Since launch in 2004, the demands put on the spacecraft have grown consistently in terms of number and type of targets as well as schedule complexity. To facilitate this growth, various scheduling tools and helper technologies have been built by the Swift team to continue improving the scientific yield of the Swift mission. However, these tools have been used only to assist humans in exploring the local pareto surface and for fixing constraint violations. Because of the computational complexity of the scheduling task, no automation tool has been able to produce a plan of equal or higher quality than that produced by a well-trained human, given the necessary time constraints. In this proceeding we formalize the Swift Scheduling Problem as a dynamic fuzzy Constraint Satisfaction Problem (DF-CSP) and explore the global solution space. We detail here several approaches towards achieving the goal of surpassing human quality schedules using classical optimization and algorithmic techniques, as well as machine learning and recurrent neural network (RNN) methods. We then briefly discuss the increased scientific yield and benefit to the wider astrophysics community that would result from the further development and adoption of these technologies. © 2018 Institute of Physics Publishing. All rights reserved.",,"IOP Publishing Ltd"
"Zhao Y., Zhou C.C.","A game-theoretic lexical link analysis for discovering high-value information from big data",2018,"Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018",1,"10.1109/ASONAM.2018.8508317","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057346971&doi=10.1109%2fASONAM.2018.8508317&partnerID=40&md5=e0d417dbfde74ea94fd192e7e5b86826","We demonstrate a machine learning and artificial intelligence method, i.e., lexical link analysis (LLA) to discover high-value information from big data. In this paper, high-value information refers to the information that has the potential to grow its value over time. LLA is a unsupervised learning method that does not require manually labeled training data. New value metrics are defined based on a game-theoretic framework for LLA. In this paper, we show the value metrics generated from LLA in a use case of analyzing business news. We show the results from LLA are validated and correlated with the ground truth. We show that by using game theory, the high-value information selected by LLA reaches a Nash equilibrium by superpositioning popular and anomalous information, and at the same time generates high social welfare, therefore, contains higher intrinsic value. © 2018 IEEE.","big data; game theory; high-value; lexical link analysis; Nash equilibrium; Pareto efficient; Pareto superior; social welfare; unsupervised learning","Institute of Electrical and Electronics Engineers Inc."
"Zhao Y., Zhou C.C., Bellonio J.K.","Multilayer value metrics using lexical link analysis and game theory for discovering innovation from big data and crowd-sourcing",2018,"Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018",1,"10.1109/ASONAM.2018.8508498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057321364&doi=10.1109%2fASONAM.2018.8508498&partnerID=40&md5=ba8c960380c63fe1a6c8dbf99c5e93ac","We demonstrated a machine learning and artificial intelligence method, i.e., lexical link analysis (LLA) to discover different layers of semantic network that contribute to innovative ideas from big data. The LLA is an unsupervised machine learning paradigm that does not require manually labeled training data. Multilayer value metrics are defined based on game theory for LLA. We showed the following results: 1) the value metrics generated from LLA in a use case of an internet game and crowd-sourcing; 2) the results from LLA are validated and correlated with the ground truth; 3) the game-theoretic LLA can help an information provider to present the information in the most valuable way. The information presentation can solve a problem (e.g., a search request of innovation) that no other information providers can solve (i.e., expertise). In addition, it ties also to a broader context that the unique value can propagate through the consensus. Based on the game-theoretic LLA, an information provider should not always present expertise content or authoritative content but rather with a mixed strategy where each type of content is presented with certain probabilities for the best value overall. © 2018 IEEE.","big data; crowd-sourcing; game theory; lexical link analysis; Nash equilibrium; Pareto efficient; Pareto superior; social welfare; unsupervised learning","Institute of Electrical and Electronics Engineers Inc."
"Cagni E., Botti A., Wang Y., Iori M., Petit S.F., Heijmen B.J.M.","Pareto-optimal plans as ground truth for validation of a commercial system for knowledge-based DVH-prediction",2018,"Physica Medica",15,"10.1016/j.ejmp.2018.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056230847&doi=10.1016%2fj.ejmp.2018.11.002&partnerID=40&md5=3c4134fe1bcf40666e750a006ce2c210","Purpose: Treatment plans manually generated in clinical routine may suffer from variations and inconsistencies in quality. Using such plans for validating a DVH prediction algorithm might obscure its intrinsic prediction accuracy. In this study we used a recently published large database of Pareto-optimal prostate cancer plans to assess the prediction accuracy of a commercial knowledge-based DVH prediction algorithm, RapidPlan. The database plans were consistently generated with automated planning using an independent optimizer, and can be considered as aground truth of plan quality. Methods: Prediction models were generated using training sets with 20, 30, 45, 55 and 114 Pareto-optimal plans. Model-20 and Model-30 were built using 5 groups of randomly selected training patients. For 60 independent Pareto-optimal validation plans, predicted and database DVHs were compared. Results: For model-114, differences between predicted and database mean doses of more than ± 10% in rectum, anus and bladder, occurred for 23.3%, 55.0%, and 6.7% of the validation plans, respectively. For rectum V65Gy and V75Gy, differences outside the ±10% range were observed in 21.7% and 70.0% of validation plans, respectively. For 61.7% of validation plans, inaccuracies in predicted rectum DVHs resulted in a deviation in predicted NTCP for rectal bleeding outside ±10%. With smaller training sets the DVH prediction performance deteriorated, showing dependence on the selected training patients. Conclusion: Even when analysed with Pareto-optimal plans with highly consistent quality, clinically relevant deviations in DVH predictions were observed. Such deviations could potentially result in suboptimal plans for new patients. Further research on DVH prediction models is warranted. © 2018","Automated planning; Knowledge-based planning; Machine learning; Pareto-optimal plan; Prostate cancer; RapidPlan","Associazione Italiana di Fisica Medica"
"Menou E., Tancret F., Toda-Caraballo I., Ramstein G., Castany P., Bertrand E., Gautier N., Rivera Díaz-Del-Castillo P.E.J.","Computational design of light and strong high entropy alloys (HEA): Obtainment of an extremely high specific solid solution hardening",2018,"Scripta Materialia",22,"10.1016/j.scriptamat.2018.07.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050070217&doi=10.1016%2fj.scriptamat.2018.07.024&partnerID=40&md5=542cf082baf1d407f9a7274b86f8ca17","A multi-objective optimisation genetic algorithm combining solid solution hardening (SSH) and thermodynamic modelling (CALPHAD) with data mining is used to design high entropy alloys (HEAs). The approach searches for the best compromise between single-phase stability, SSH and density. Thousands of Pareto-optimal base-centred cubic (BCC) HEAs are designed. Al35Cr35Mn8Mo5Ti17 (at.%) is chosen for experimental validation. The alloy was cast and characterised. Its microstructure consists of large grains of a single disordered solid solution displaying a Vickers hardness of 6.45 GPa (658 HV) and a density below 5.5 g/cm3; uniquely combining exceptional hardness with medium density. © 2018 Acta Materialia Inc","Machine learning; Modeling; Phase diagram; Simulation; Thermodynamics","Acta Materialia Inc"
"Javed S., Zafar K.","Player profiling and quality assessment of dynamic car racing tracks using entertainment quantifier technique",2018,"Computational Intelligence",1,"10.1111/coin.12161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043282457&doi=10.1111%2fcoin.12161&partnerID=40&md5=bef394deeaab87d27f8504bc41bb3b1c","Interactive games have been an interesting area of research and have many challenges. With the advancement in technology, games have been revolutionizing at each step per the emerging and variant interests of players. Recently, machine learning techniques are used for the generation of game content based on player's experience. The dynamic content generation in computer games based on player's experience and feedback is still a challenging task. This requires measurement of entertainment factor achieved by a player during a game. In order to measure entertainment factor, we need to incorporate human-computer interaction by evolution of game content with respect to player's response. Optimization techniques can be used for the measurement of entertainment factor and for the generation of dynamic game content. The use of computational intelligence techniques in game development can lead to a new domain called “computational intelligence in games.” This research is focused on car racing game genre, and the paradigm selected for dynamicity is track generation of car racing game. It requires player profiling and classification of players. The optimization of track generation has been performed by using single and multiobjective genetic algorithm and particle swarm optimization. Initially, classification of player's rank based on data and theory-driven approaches has been performed. Moreover, 3 different techniques of defining ranges or boundaries of race parameters for player's rank classification are studied. The techniques are based on crisp values, neural network, and fuzzy inference process. Then, an entertainment quantifier technique is proposed for a player after playing a certain number of games based on dynamic content generation using multiobjective genetic algorithm using standard Pareto optimal front and an epsilon (ϵ) front. In conclusion, the method proposed for quantifying entertainment can be used to analyze and classify the trend in interests of a player according to which the game itself can dynamically generate. This will keep the interest of player intact and provides maximum entertainment experience per the interest of an individual. The proposed solution can easily be used in generation of any game content and can effectively be used in accurate measurement of entertaining factor of any game. © 2018 Wiley Periodicals, Inc.","computational intelligence; data-driven approach; genetic algorithm; measuring entertainment; Pareto optimal front; particle swarm optimization","Blackwell Publishing Inc."
"DeCanio S.J.","Games between humans and AIs",2018,"AI and Society",1,"10.1007/s00146-017-0732-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020109041&doi=10.1007%2fs00146-017-0732-5&partnerID=40&md5=bfa514733ca2fd785f348492c8c0df82","Various potential strategic interactions between a “strong” Artificial intelligence (AI) and humans are analyzed using simple 2 × 2 order games, drawing on the New Periodic Table of those games developed by Robinson and Goforth (The topology of the 2 × 2 games: a new periodic table. Routledge, London, 2005). Strong risk aversion on the part of the human player(s) leads to shutting down the AI research program, but alternative preference orderings by the human and the AI result in Nash equilibria with interesting properties. Some of the AI-Human games have multiple equilibria, and in other cases Pareto-improvement over the Nash equilibrium could be attained if the AI’s behavior towards humans could be guaranteed to be benign. The preferences of a superintelligent AI cannot be known in advance, but speculation is possible as to its ranking of alternative states of the world, and how it might assimilate the accumulated wisdom (and folly) of humanity. © 2017, Springer-Verlag London.","Artificial intelligence; Machine learning; Nash equilibrium; Order games","Springer London"
"Park S., Na J., Kim M., Lee J.M.","Multi-objective Bayesian optimization of chemical reactor design using computational fluid dynamics",2018,"Computers and Chemical Engineering",24,"10.1016/j.compchemeng.2018.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052942007&doi=10.1016%2fj.compchemeng.2018.08.005&partnerID=40&md5=62b4cd75d17865fc8837cb4260df56e7","This study presents a computational fluid dynamics (CFD) based optimal design tool for chemical reactors, in which multi-objective Bayesian optimization (MBO) is utilized to reduce the number of required CFD runs. Detailed methods used to automate the process by connecting CFD with MBO are also proposed. The developed optimizer was applied to minimize the power consumption and maximize the gas holdup in a gas-sparged stirred tank reactor, which has six design variables: the aspect ratio of the tank, the diameter and clearance of each of the two impellers, and the gas sparger. The saturated Pareto front is obtained after 100 iterations. The resulting Pareto front consists of many near-optimal designs with significantly enhanced performances compared to conventional reactors reported in the literature. We anticipate that this design approach can be applied to any process unit design problems that require a large number of CFD simulation runs. © 2018 Elsevier Ltd","Bayesian optimization; CFD-based optimization; Computational fluid dynamics; Machine learning; Multi-objective optimization; Reactor design","Elsevier Ltd"
"Schweidtmann A.M., Clayton A.D., Holmes N., Bradford E., Bourne R.A., Lapkin A.A.","Machine learning meets continuous flow chemistry: Automated optimization towards the Pareto front of multiple objectives",2018,"Chemical Engineering Journal",92,"10.1016/j.cej.2018.07.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049468283&doi=10.1016%2fj.cej.2018.07.031&partnerID=40&md5=8447e1da74ca85de13a0b1797b00daba","Automated development of chemical processes requires access to sophisticated algorithms for multi-objective optimization, since single-objective optimization fails to identify the trade-offs between conflicting performance criteria. Herein we report the implementation of a new multi-objective machine learning optimization algorithm for self-optimization, and demonstrate it in two exemplar chemical reactions performed in continuous flow. The algorithm successfully identified a set of optimal conditions corresponding to the trade-off curve (Pareto front) between environmental and economic objectives in both cases. Thus, it reveals the complete underlying trade-off and is not limited to one compromise as is the case in many other studies. The machine learning algorithm proved to be extremely data efficient, identifying the optimal conditions for the objectives in a lower number of experiments compared to single-objective optimizations. The complete underlying trade-off between multiple objectives is identified without arbitrary weighting factors, but via true multi-objective optimization. © 2018","Automated flow reactor; Environmental chemistry; Machine learning; Reaction engineering; Sustainable chemistry","Elsevier B.V."
"Younis M.C., Keedwell E., Savic D.","An Investigation of Pixel-Based and Object-Based Image Classification in Remote Sensing",2018,"ICOASE 2018 - International Conference on Advanced Science and Engineering",1,"10.1109/ICOASE.2018.8548845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060041922&doi=10.1109%2fICOASE.2018.8548845&partnerID=40&md5=a75f771c4c41fda1c16eba20336ba9b2","This research evaluates pixel-based and object-based image classification techniques for extracting three land-use categories (buildings, roads, and vegetation areas) from six satellite images. The performance of eight supervised machine learning classifiers with 5-fold cross validation are also compared. Experimental validation found that using 'Bagged Tree' for object-based classification algorithms provides maximum overall accuracy when tested on 10,000 objects produced by the SLIC segmentation method, and improves upon an existing RGB-based approach. Our aforementioned proposed approach takes about 12 times less total runtime than the pixel-based method, demonstrating the power of the combined approach. © 2018 IEEE.","image classification; image segmentation; machine learning; Pareto Analysis; remote sensing","Institute of Electrical and Electronics Engineers Inc."
"Thakur N., Mathew L.","SEMG Signal Classification Using Ensemble Learning Classification Approach and DWT",2018,"Proceedings of the 2018 International Conference on Current Trends towards Converging Technologies, ICCTCT 2018",3,"10.1109/ICCTCT.2018.8551098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059954408&doi=10.1109%2fICCTCT.2018.8551098&partnerID=40&md5=10e7380acba930c464ee7324788de286","Nowadays surface electromyography (sEMG) signals play a very authoritative role in facilitating a neuromuscular disordered person and disabled person to live a smooth life. This offline study mainly focuses on the denoising, feature extraction and classification of the sEMG signals with discrete wavelet packet transform (DWT) with ensemble support vector machine (SVM) classification approach. In this work DWT (db 2, 4 th level) is selected for denoising and TFD feature extraction to form feature vectors and soft thresholding method (minimax) was utilized and the threshold value was taken as 2.991. The classification accuracy is 98% is achieved at the better precision and speed of response for elbow movement. feature vectors and soft thresholding method (minimax) was utilized and the threshold value was taken as 2.991. The classification accuracy is 98% is achieved at the better precision and speed of response for elbow movement. © 2018 IEEE.","DWT- discrete Wavelet Transform; SEMG- Suface Electromyography Signal; SVM- Support Vector Machine; WGN- White Gaussian Noise","Institute of Electrical and Electronics Engineers Inc."
"Gopakumar A.M., Balachandran P.V., Xue D., Gubernatis J.E., Lookman T.","Multi-objective Optimization for Materials Discovery via Adaptive Design",2018,"Scientific Reports",57,"10.1038/s41598-018-21936-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042678609&doi=10.1038%2fs41598-018-21936-3&partnerID=40&md5=f01cf387cba71f609630ddf6e4f970e7","Guiding experiments to find materials with targeted properties is a crucial aspect of materials discovery and design, and typically multiple properties, which often compete, are involved. In the case of two properties, new compounds are sought that will provide improvement to existing data points lying on the Pareto front (PF) in as few experiments or calculations as possible. Here we address this problem by using the concept and methods of optimal learning to determine their suitability and performance on three materials data sets; an experimental data set of over 100 shape memory alloys, a data set of 223 M 2 AX phases obtained from density functional theory calculations, and a computational data set of 704 piezoelectric compounds. We show that the Maximin and Centroid design strategies, based on value of information criteria, are more efficient in determining points on the PF from the data than random selection, pure exploitation of the surrogate model prediction or pure exploration by maximum uncertainty from the learning model. Although the datasets varied in size and source, the Maximin algorithm showed superior performance across all the data sets, particularly when the accuracy of the machine learning model fits were not high, emphasizing that the design appears to be quite forgiving of relatively poor surrogate models. © 2018 The Author(s).",,"Nature Publishing Group"
"Yang Z., Chen W., Wang F., Xu B.","Generative adversarial training for neural machine translation",2018,"Neurocomputing",11,"10.1016/j.neucom.2018.09.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054082294&doi=10.1016%2fj.neucom.2018.09.006&partnerID=40&md5=8a4ebfe63a950578892bed18463dcbcc","Neural machine translation (NMT) is typically optimized to generate sentences which cover n-grams with ground target as much as possible. However, it is widely acknowledged that n-gram precisions, the manually designed approximate loss function, may mislead the model to generate suboptimal translations. To solve this problem, we train the NMT model to generate human-like translations directly by using the generative adversarial net, which has achieved great success in computer vision. In this paper, we build a conditional sequence generative adversarial net (CSGAN-NMT) which comprises of two adversarial sub models, a generative model (generator) which translates the source sentence into the target sentence as the traditional NMT models do and a discriminative model (discriminator) which discriminates the machine-translated target sentence from the human-translated one. The two sub models play a minimax game and achieve a win-win situation when reaching a Nash Equilibrium. As a variant of the single generator-discriminator model, the multi-CSGAN-NMT which contains multiple discriminators and generators, is also proposed. In the multi-CSGAN-NMT model, each generator is viewed as an agent which can interact with others and even transfer messages. Experiments show that the proposed CSGAN-NMT model obtains substantial improvements than the strong baseline and the improvement of the multi-CSGAN-NMT model is more remarkable. © 2018 Elsevier B.V.","Human-like translation; Multi generative adversarial net; Neural machine translation","Elsevier B.V."
"Turner J., Cano J., Radu V., Crowley E.J., O'Boyle M., Storkey A.","Characterising Across-Stack Optimisations for Deep Convolutional Neural Networks",2018,"2018 IEEE International Symposium on Workload Characterization, IISWC 2018",16,"10.1109/IISWC.2018.8573503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060300265&doi=10.1109%2fIISWC.2018.8573503&partnerID=40&md5=0b32a61ea505b726b11c139800f6ad9f","Convolutional Neural Networks (CNNs) are extremely computationally demanding, presenting a large barrier to their deployment on resource-constrained devices. Since such systems are where some of their most useful applications lie (e.g. obstacle detection for mobile robots, vision-based medical assistive technology), significant bodies of work from both machine learning and systems communities have attempted to provide optimisations that will make CNNs available to edge devices. In this paper we unify the two viewpoints in a Deep Learning Inference Stack and take an across-stack approach by implementing and evaluating the most common neural network compression techniques (weight pruning, channel pruning, and quantisation) and optimising their parallel execution with a range of programming approaches (OpenMP, OpenCL) and hardware architectures (CPU, GPU). We provide comprehensive Pareto curves to instruct trade-offs under constraints of accuracy, execution time, and memory space. © 2018 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Volpi R., Morerio P., Savarese S., Murino V.","Adversarial Feature Augmentation for Unsupervised Domain Adaptation",2018,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",104,"10.1109/CVPR.2018.00576","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055436233&doi=10.1109%2fCVPR.2018.00576&partnerID=40&md5=c16a0b4fb30b3977468101abf2a61473","Recent works showed that Generative Adversarial Networks (GANs) can be successfully applied in unsupervised domain adaptation, where, given a labeled source dataset and an unlabeled target dataset, the goal is to train powerful classifiers for the target samples. In particular, it was shown that a GAN objective function can be used to learn target features indistinguishable from the source ones. In this work, we extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation. While data augmentation in the image space is a well established technique in deep learning, feature augmentation has not yet received the same level of attention. We accomplish it by means of a feature generator trained by playing the GAN minimax game against source features. Results show that both enforcing domain-invariance and performing feature augmentation lead to superior or comparable performance to state-of-the-art results in several unsupervised domain adaptation benchmarks. © 2018 IEEE.",,"IEEE Computer Society"
"Rathnayake S., Ramapantulu L., Teo Y.M.","Cost-Time performance of scaling applications on the cloud",2018,"Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom",1,"10.1109/CloudCom2018.2018.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061119213&doi=10.1109%2fCloudCom2018.2018.00021&partnerID=40&md5=6f25752a2ef8309e1ec7efe01de23b20","Recent advancements in big data processing and machine learning, among others, increase the resource demand for running applications with larger problem sizes. Elastic cloud computing resources with pay-per-use pricing offers new opportunities where large application execution is constrained only by the cost budget. Given a cost budget and a time deadline, this paper introduces a measurement-driven analytical modeling approach to determine the largest Pareto-optimal problem size and its corresponding cloud configuration for execution. We evaluate our approach with a set of representative applications that exhibit a range of resource demand growth patterns on Amazon AWS cloud. We show the existence of cost-Time-size Pareto-frontier with multiple sweet spots meeting user constraints. To characterize the cost-performance of cloud resources, we use Performance Cost Ratio (PCR) metric. We extend Gustafson's fixed-Time scaling in the context of cloud, and, investigate fixed-cost-Time scaling of applications and show that using resources with higher PCR yields better cost-Time performance. We discuss a number of useful insights on the trade-off between the execution time and the largest Pareto-optimal problem size, and, show that time deadline could be tightened for a proportionately much smaller reduction of problem size. © 2018 IEEE.","Cloud; Cost-Time performance; Largest problem size; Pareto-optimal configuration; Scaling","IEEE Computer Society"
"Pavlidis G.","Towards a Hybrid Minimax Recommender for Free-Roaming Museum Visits",2019,"Springer Proceedings in Business and Economics",,"10.1007/978-3-030-12453-3_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126184010&doi=10.1007%2f978-3-030-12453-3_2&partnerID=40&md5=78355ba4fcb4e7db86d6594215ac2c0a","This paper presents a novel minimax hybrid recommender for free-roaming museum visits that is based on a new museum visit concept that was developed to capture the spatial, temporal and content-based dynamics during free-roaming museum visits. The complex hybrid recommender applies a minimax approach as it estimates an overall visitor dissatisfaction and aims its minimisation. As a result, it is able to develop optimal routes, as sequences of points of interest for each individual visitor. This hybrid recommender, still at its fine-tuning phase, has been tested in large scale simulations, using realistic data for visitors and exhibitions and has already shown to outperform the naive baseline recommender that relies on popularity. © 2019, Springer Nature Switzerland AG.","Artificial intelligence; Cultural heritage; Machine learning; Museum guide; Recommendation; Recommender","Springer Science and Business Media B.V."
"Saldanha C., Cranston G., Lee J., Sjoberg C.","Maximizing daylight and energy performance: Using pareto front analysis for multi-objective facade shading optimization",2019,"Thermal Performance of the Exterior Envelopes of Whole Buildings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103001761&partnerID=40&md5=cfba86ed35f3a2c132cbfb6a39a6b1b8","In building science, maximizing natural daylighting while minimizing solar heat gains is a multi-objective optimization problem. The Pareto efficiency method offers a solution for approaching this challenge. Our team applied the Pareto efficiency method to the Vitta Center medical facility in Guatemala, where summer solar radiation is a significant concern. The challenge was to provide the architect with several arrangements of façade shading element geometries to maximize daylight and access to exterior views, while minimizing solar radiative gain. In this paper, we describe the modeling process, including determining constraints and permissible ranges for parameters, and develop tools to compare outputs from different software programs. We approached this problem by combining established optimization tools including Pareto efficiency, genetic algorithms and machine learning. We performed a parametric analysis, varying the vertical fin shade spacing and depth and the slab overhang depth, to quantify the daylight autonomy and solar radiative gain for a typical office space on each elevation independently. We analyze the resulting data to develop a set of preferred solutions of shading element geometry having comparable performance but varied aesthetic. The architect will use the preferred solutions to inform the final design and arrangement of the shading elements. © 2019 ASHRAE.",,"American Society of Heating, Refrigerating and Air-Conditioning Engineers (ASHRAE)"
"Wang W., Zhou X., Chen F., Cao B.","Sequential Minimax Search for Multi-Layer Gene Grouping",2019,"IEEE Access",,"10.1109/ACCESS.2019.2924491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097342030&doi=10.1109%2fACCESS.2019.2924491&partnerID=40&md5=58bb03bffd52046775e6ab52b5a0c34e","Many areas of exploratory data analysis need to deal with high-dimensional data sets. Some real life data like human gene have an inherent structure of hierarchy, which embeds multi-layer feature groups. In this paper, we propose an algorithm to search for the number of feature groups in high-dimensional data by sequential minimax method and detect the hierarchical structure of high-dimensional data. Several proper numbers of feature grouping can be discovered. The feature grouping and group weights are investigated for each group number. After the comparison of feature groupings, the multi-layer structure of feature groups is detected. The latent feature group learning (LFGL) algorithm is proposed to evaluate the effectiveness of the number of feature groups and provide a method of subspace clustering. In the experiments on several gene data sets, the proposed algorithm outstands several representative algorithms. © 2013 IEEE.","evolutionary computing; feature grouping; gene grouping; high-dimensional data analysis; knowledge transfer; Machine learning","Institute of Electrical and Electronics Engineers Inc."
"Sanmartín E.F., Damrich S., Hamprecht F.A.","Probabilistic watershed: Sampling all spanning forests for seeded segmentation and semi-supervised learning",2019,"Advances in Neural Information Processing Systems",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090175190&partnerID=40&md5=2ac31d866346249e14327ea2c38527ff","The seeded Watershed algorithm / minimax semi-supervised learning on a graph computes a minimum spanning forest which connects every pixel / unlabeled node to a seed / labeled node. We propose instead to consider all possible spanning forests and calculate, for every node, the probability of sampling a forest connecting a certain seed with that node. We dub this approach ""Probabilistic Watershed"". Leo Grady (2006) already noted its equivalence to the Random Walker / Harmonic energy minimization. We here give a simpler proof of this equivalence and establish the computational feasibility of the Probabilistic Watershed with Kirchhoff's matrix tree theorem. Furthermore, we show a new connection between the Random Walker probabilities and the triangle inequality of the effective resistance. Finally, we derive a new and intuitive interpretation of the Power Watershed. © 2019 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Tu Z., Zhang J., Tao D.","Theoretical analysis of adversarial learning: A minimax approach",2019,"Advances in Neural Information Processing Systems",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090169991&partnerID=40&md5=22731e4fcb616a4f4bbe18f1af0394fc","In this paper, we propose a general theoretical method for analyzing the risk bound in the presence of adversaries. Specifically, we try to fit the adversarial learning problem into the minimax framework. We first show that the original adversarial learning problem can be transformed into a minimax statistical learning problem by introducing a transport map between distributions. Then, we prove a new risk bound for this minimax problem in terms of covering numbers under a weak version of Lipschitz condition. Our method can be applied to multi-class classification and popular loss functions including the hinge loss and ramp loss. As some illustrative examples, we derive the adversarial risk bounds for SVMs and deep neural networks, and our bounds have two data-dependent terms, which can be optimized for achieving adversarial robustness. © 2019 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Nguyen T.P.Q., Kuo R.J.","Automatic Fuzzy Clustering Using Non-Dominated Sorting Particle Swarm Optimization Algorithm for Categorical Data",2019,"IEEE Access",9,"10.1109/ACCESS.2019.2927593","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086073011&doi=10.1109%2fACCESS.2019.2927593&partnerID=40&md5=8184589968ef02eb0d408b050ac02726","Categorical data clustering has been attracted a lot of attention recently due to its necessary in the real-world applications. Many clustering methods have been proposed for categorical data. However, most of the existing algorithms require the predefined number of clusters which is usually unavailable in real-world problems. Only a few works focused on automatic clustering, but mainly handled for numerical data. This study develops a novel automatic fuzzy clustering using non-dominated sorting particle swarm optimization (AFC-NSPSO) algorithm for categorical data. The proposed AFC-NSPSO algorithm can automatically identify the optimal number of clusters and exploit the clustering result with the corresponding selected number of clusters. In addition, a new technique is investigated to identify the maximum number of clusters in a dataset based on the local density. To select a final solution in the first Pareto front, some internal validation indices are used. The performance of the proposed AFC-NSPSO on the real-world datasets collected from the UCI machine learning repository exhibits effectiveness compared with some other existing automatic categorical clustering algorithms. Besides, this study also applies the proposed algorithm to analyze a real-world case study with an unknown number of clusters. © 2013 IEEE.","Automatic clustering; categorical data; local density; NSPSO","Institute of Electrical and Electronics Engineers Inc."
"Xie Y., Chen M., Jiang H., Zhao T., Zha H.","On scalable and efficient computation of large scale optimal transport",2019,"Deep Generative Models for Highly Structured Data, DGS@ICLR 2019 Workshop",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954295&partnerID=40&md5=089ff5bdfa298024a9459c8629c400c4","Optimal Transport (OT) naturally arises in many machine learning applications, where we need to handle cross-modality data from multiple sources. Yet the heavy computational burden limits its wide-spread uses. To address the scalability issue, we propose an implicit generative learning-based framework called SPOT (Scalable Push-forward of Optimal Transport). Specifically, we approximate the optimal transport plan by a pushforward of a reference distribution, and cast the optimal transport problem into a minimax problem. We then can solve OT problems efficiently using primal dual stochastic gradient-type algorithms. We also show that we can recover the density of the optimal transport plan using neural ordinary differential equations. Numerical experiments on both synthetic and real datasets illustrate that SPOT is robust and has favorable convergence behavior. SPOT also allows us to efficiently sample from the optimal transport plan, which benefits downstream applications such as domain adaptation. © Deep Generative Models for Highly Structured Data, DGS@ICLR 2019 Workshop.All right reserved.",,"International Conference on Learning Representations, ICLR"
"Wang H., Yu C.-N.","A direct approach to robust deep learning using adversarial networks",2019,"7th International Conference on Learning Representations, ICLR 2019",15,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083954043&partnerID=40&md5=05dcc3461b7b8ed9d1e3f92457b3460b","Deep neural networks have been shown to perform well in many classical machine learning problems, especially in image classification tasks. However, researchers have found that neural networks can be easily fooled, and they are surprisingly sensitive to small perturbations imperceptible to humans. Carefully crafted input images (adversarial examples) can force a well-trained neural network to provide arbitrary outputs. Including adversarial examples during training is a popular defense mechanism against adversarial attacks. In this paper we propose a new defensive mechanism under the generative adversarial network (GAN) framework. We model the adversarial noise using a generative network, trained jointly with a classification discriminative network as a minimax game. We show empirically that our adversarial network approach works well against black box attacks, with performance on par with state-of-art methods such as ensemble adversarial training and adversarial training with projected gradient descent. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,"International Conference on Learning Representations, ICLR"
"Azizan N., Hassibi B.","Stochastic gradient/mirror descent: Mini-MAX optimality and implicit regularization",2019,"7th International Conference on Learning Representations, ICLR 2019",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083953395&partnerID=40&md5=f6a2192d13f8392f4df0f0665b645cc4","Stochastic descent methods (of the gradient and mirror varieties) have become increasingly popular in optimization. In fact, it is now widely recognized that the success of deep learning is not only due to the special deep architecture of the models, but also due to the behavior of the stochastic descent methods used, which play a key role in reaching “good” solutions that generalize well to unseen data. In an attempt to shed some light on why this is the case, we revisit some minimax properties of stochastic gradient descent (SGD) for the square loss of linear models-originally developed in the 1990's-and extend them to general stochastic mirror descent (SMD) algorithms for general loss functions and nonlinear models. In particular, we show that there is a fundamental identity which holds for SMD (and SGD) under very general conditions, and which implies the minimax optimality of SMD (and SGD) for sufficiently small step size, and for a general class of loss functions and general nonlinear models. We further show that this identity can be used to naturally establish other properties of SMD (and SGD), namely convergence and implicit regularization for over-parameterized linear models (in what is now being called the “interpolating regime”), some of which have been shown in certain cases in prior literature. We also argue how this identity can be used in the so-called “highly over-parameterized” nonlinear setting (where the number of parameters far exceeds the number of data points) to provide insights into why SMD (and SGD) may have similar convergence and implicit regularization properties for deep learning. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,"International Conference on Learning Representations, ICLR"
"Suzuki T.","Adaptivity of deep Relu network for learning in besov and mixed smooth besov spaces: Optimal rate and curse of dimensionality",2019,"7th International Conference on Learning Representations, ICLR 2019",20,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083952838&partnerID=40&md5=6645d095b9837eae63f6aae55ecbb628","Deep learning has shown high performances in various types of tasks from visual recognition to natural language processing, which indicates superior flexibility and adaptivity of deep learning. To understand this phenomenon theoretically, we develop a new approximation and estimation error analysis of deep learning with the ReLU activation for functions in a Besov space and its variant with mixed smoothness. The Besov space is a considerably general function space including the Hölder space and Sobolev space, and especially can capture spatial inhomogeneity of smoothness. Throughout the analysis in the Besov space, it is shown that deep learning can achieve the minimax optimal rate and outperform any non-adaptive (linear) estimator such as kernel ridge regression, which shows that deep learning has higher adaptivity to the spatial inhomogeneity of the target function than other estimators such as linear ones. In addition to this, it is shown that deep learning can avoid the curse of dimensionality if the target function is in a mixed smooth Besov space. We also show that the dependency of the convergence rate on the dimensionality is tight due to its minimax optimality. These results support high adaptivity of deep learning and its superior ability as a feature extractor. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,"International Conference on Learning Representations, ICLR"
"Havasi M., Peharz R., Hernández-Lobato J.M.","Minimal random code learning: Getting bits back from compressed model parameters",2019,"7th International Conference on Learning Representations, ICLR 2019",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083951207&partnerID=40&md5=ca97ed2156a04aa5d278e1b558d403d7","While deep neural networks are a highly successful model class, their large memory footprint puts considerable strain on energy consumption, communication bandwidth, and storage requirements. Consequently, model size reduction has become an utmost goal in deep learning. A typical approach is to train a set of deterministic weights, while applying certain techniques such as pruning and quantization, in order that the empirical weight distribution becomes amenable to Shannon-style coding schemes. However, as shown in this paper, relaxing weight determinism and using a full variational distribution over weights allows for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits-back argument, we encode the network weights using a random sample, requiring only a number of bits corresponding to the Kullback-Leibler divergence between the sampled variational distribution and the encoding distribution. By imposing a constraint on the Kullback-Leibler divergence, we are able to explicitly control the compression rate, while optimizing the expected loss on the training set. The employed encoding scheme can be shown to be close to the optimal information-theoretical lower bound, with respect to the employed variational family. Our method sets new state-of-the-art in neural network compression, as it strictly dominates previous approaches in a Pareto sense: On the benchmarks LeNet-5/MNIST and VGG-16/CIFAR-10, our approach yields the best test performance for a fixed memory budget, and vice versa, it achieves the highest compression rates for a fixed test performance. © 7th International Conference on Learning Representations, ICLR 2019. All Rights Reserved.",,"International Conference on Learning Representations, ICLR"
"Hu D., Jiang X., Wei X., Wang J.","State Representation Learning for Minimax Deep Deterministic Policy Gradient",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-29551-6_43","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081638540&doi=10.1007%2f978-3-030-29551-6_43&partnerID=40&md5=149febc396c9520ad4dd1a616be5918e","Recently, the reinforcement learning of multi-agent has been developed rapidly, especially the Minimax Deep Deterministic Policy Gradient (M3DDPG) algorithm which improves agent robustness and solves the problem that agents trained by deep reinforcement learning (DRL) are often vulnerable and sensitive to the training environment. However, agents in the real environment may not be able to perceive certain important characteristics of the environment because of their limited perceptual capabilities. So Agents often fail to achieve the desired results. In this paper, we propose a novel algorithm State Representation Learning for Minimax Deep Deterministic Policy Gradient (SRL_M3DDPG) that combines M3DDPG with the state representation learning neural network model to extract the important characteristics of raw data. And we optimize the actor and critic network by using the neural network model of state representation learning. Then the actor and critic network learn from the state representation model instead of the raw observations. Simulation experiments show that the algorithm improves the final result. © Springer Nature Switzerland AG 2019.","M3DDPG; SRL_M3DDPG; State representation learning","Springer"
"Aijazi A.N., Glicksman L.R.","Application of surrogate modeling to multi-objective optimization for residential retrofit design",2019,"Simulation Series",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081619978&partnerID=40&md5=0f0d9daaf5a4a62b95759c965bee7665","This project combines surrogate modeling, a supervised machine learning technique, to bypass whole building energy simulations to enable multi-objective design optimization. We applied this method to identify Pareto optimal retrofit designs that are energy and cost effective for three residential apartments in Lisbon, Portugal. As part of our validation of this approach, we compared the surrogate model error for these Pareto optimal designs to the error in the rest of the design space when compared to a detailed energy simulation. Surrogate model error is higher towards the minimum and maximum energy consumption within the Pareto optimal designs compared to the rest of the design space. We also find that in the Pareto optimal set some design variable values are near their minimum or maximum value, which could be driving higher surrogate model error. We propose that future research should retrain the surrogate model after identifying design variable values of interest from an initial optimization run. © 2019 Society for Modeling & Simulation International (SCS).",,"The Society for Modeling and Simulation International"
"Li S., Wu Y., Cui X., Dong H., Fang F., Russell S.","Robust multi-agent reinforcement learning via minimax deep deterministic policy gradient",2019,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",63,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081618581&partnerID=40&md5=715aec1d7bb5a39316d783a4681c7f39","Despite the recent advances of deep reinforcement learning (DRL), agents trained by DRL tend to be brittle and sensitive to the training environment, especially in the multi-agent scenarios. In the multi-agent setting, a DRL agent's policy can easily get stuck in a poor local optima w.r.t. its training partners - the learned policy may be only locally optimal to other agents' current policies. In this paper, we focus on the problem of training robust DRL agents with continuous actions in the multi-agent learning setting so that the trained agents can still generalize when its opponents' policies alter. To tackle this problem, we proposed a new algorithm, MiniMax Multi-agent Deep Deterministic Policy Gradient (M3DDPG) with the following contributions: (1) we introduce a minimax extension of the popular multi-agent deep deterministic policy gradient algorithm (MADDPG), for robust policy learning; (2) since the continuous action space leads to computational intractability in our minimax learning objective, we propose Multi-Agent Adversarial Learning (MAAL) to efficiently solve our proposed formulation. We empirically evaluate our M3DDPG algorithm in four mixed cooperative and competitive multi-agent environments and the agents trained by our method significantly outperforms existing baselines. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org).",,"AAAI Press"
"Mohanty R., Mahamaya M., Das S.K., Mohanty M.","Liquefaction susceptibility of soil using multi objective feature selection",2019,"Earthquake Geotechnical Engineering for Protection and Development of Environment and Constructions- Proceedings of the 7th International Conference on Earthquake Geotechnical Engineering, 2019",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081173186&partnerID=40&md5=cc8e2c18d3770e39e2ee9b03b4633dff","In this paper, the prediction model for liquefaction susceptibility of soil based on shear wave velocity (Vs) is presented using a novel artificial intelligence method, multiobjective feature selection (MOFS) algorithm. In this proposed MOFS, extreme learning machine (ELM) acts as the learning algorithm and non-dominated sorting genetic algorithm (NSGA II) performs the feature subset selection, minimizes the errors and presents the Pareto optimal set of the developed model. The developed model could be effectively deployed to select the liquefied and non-liquefied cases with equal efficiency for an imbalanced data with majority (69.83%) of data belonging to the liquefied case. The corresponding important inputs/features also could be identified for the developed model. It was also observed that cyclic stress ratio (CSR) and Vs are the two most important input parameters for the prediction of liquefaction susceptibility followed by moment magnitude of the earthquake. © 2019 Associazione Geotecnica Italiana, Rome, Italy.",,"CRC Press/Balkema"
"Banerjee K., Georganas E., Kalamkar D.D., Ziv B., Segal E., Anderson C., Heinecke A.","Optimizing deep learning RNN topologies on intel architecture",2019,"Supercomputing Frontiers and Innovations",5,"10.14529/js?190304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079788754&doi=10.14529%2fjs%3f190304&partnerID=40&md5=a5efb4ae69907709de7f2b0145ca13b1","Recurrent neural network (RNN) models have been found to be well suited for processing temporal data. In this work, we present an optimized implementation of vanilla RNN cell and its two popular variants: LSTM and GRU for Intel Xeon architecture. Typical implementations of these RNN cells employ one or two large matrix multiplication (GEMM) calls and then apply the element-wise operations (sigmoid/tanh) onto the GEMM results. While this approach is easy to implement by exploiting vendor-optimized GEMM library calls, the data reuse relies on how GEMMs are parallelized and is sub-optimal for GEMM sizes stemming from small minibatch. Also, the element-wise operations are exposed as a bandwidth-bound kernel after the GEMM which is typically a compute-bound kernel. To address this discrepancy, we implemented a parallel blocked matrix GEMM in order to (a) achieve load balance, (b) maximize weight matrix reuse, (c) fuse the element-wise operations after partial GEMM blocks are computed and while they are hot in cache. Additionally, we bring the time step loop in our cell to further increase the weight reuse and amortize the overhead to transform the weights into blocked layout. The results show that our implementation is generally faster than Intel MKL-DNN library implementations, e.g. for RNN, forward pass is up to ~3x faster whereas the backward/weight update pass is up to ~5x faster. Furthermore, we investigate high-performance implementations of sigmoid and tanh activation functions that achieve various levels of accuracy. These implementations rely on minimax polynomial approximations, rational polynomials, Taylor expansions and exponential approximation techniques. Our vectorized implementations can be flexibly integrated into deep learning computations with different accuracy requirements without compromising performance; in fact, these are able to outperform vectorized and reduced accuracy vendor-optimized (Intel SVML) libraries by 1.6-2.6 x while speep up over GNU libm is close to two orders of magnitude. All our experiments are conducted on Intel's latest CascadeLake architecture. © The Authors 2019.","Bandwidth-bound kernel; Compute-bound kernel; Gemm; Intel xeon; Lstm","South Ural State University, Publishing Center"
"Thrampoulidis E., Mavromatidis G., Lucchi A., Orehounig K.","Could machine learning be used to approximate optimal building retrofit solutions with the use of easily accessible building data?",2019,"ECOS 2019 - Proceedings of the 32nd International Conference on Efficiency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079676613&partnerID=40&md5=cd86d396f4a779ccc284e610e18fa9d4","Building retrofit is of greatest importance to reduce the environmental footprint of the building stock. It typically refers to two types of interventions: the first pertaining to interventions on the building envelope, for instance by enhancing the thermal insulation of a building’s walls, and the second to energy system replacements. The latter includes not only the installation of a more efficient heating system, with the necessary capacity to meet the building's heat demands, but also the integration of renewable energy technologies and energy storage. Thus, there is a huge array of retrofit measure combinations to select from with different economic and environmental impacts. Even though there are tools and methodologies to handle the complex problem of deriving optimal retrofit solutions, they typically require increased level of expertise and highly heterogeneous building data, which are usually not available or challenging to obtain. As a result, building owners can find themselves in a quandary about how to further proceed with retrofitting their buildings. In this paper, we answer the question whether a machine-learning algorithm could be used as a surrogate model that can: (a) mimic the functionality of the retrofit process, and (b) derive near-optimal solutions with the use of building features that can be easily extracted, such as the building's ground floor area or age. To answer this question an artificial neural network-based model is trained with data collected from the case study of the city of Zurich. Results show that the proposed approach can approximate very well some dimensions of the building retrofit, such as the retrofit costs (R2 ≅ 0.971) and the energy system selection (f1 score ≅ 0.894), while for others, such as the electricity storage capacity (R2 ≅ 0.505), there is still room for improvement. Such surrogate retrofit models can be more easily shared with building owners, and can contribute towards accelerating the adoption of retrofit measures. © ECOS 2019 - Proceedings of the 32nd International Conference on Efficiency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems. All rights reserved.","Machine learning; Multi-objective optimization; Pareto-optimal; Renewables integration; Retrofit","Institute of Thermal Technology"
"Kalita H., Thangavelautham J.","Automated multidisciplinary design and control of hopping robots for exploration of extreme environments on the Moon and Mars",2019,"Proceedings of the International Astronautical Congress, IAC",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079196425&partnerID=40&md5=1d3b2872bd04f3556e3287e43a2235c9","The next frontier in solar system exploration will be missions targeting extreme and rugged environments such as caves, canyons, cliffs and crater rims of the Moon, Mars and icy moons. These environments are time capsules into early formation of the solar system and will provide vital clues of how our early solar system gave way to the current planets and moons. These sites will also provide vital clues to the past and present habitability of these environments. Current landers and rovers are unable to access these areas of high interest due to limitations in precision landing techniques, need for large and sophisticated science instruments and a mission assurance and operations culture where risks are minimized at all costs. Our past work has shown the advantages of using multiple spherical hopping robots called SphereX for exploring these extreme environments. Our previous work was based on performing exploration with a human-designed baseline design of a SphereX robot. However, the design of SphereX is a complex task that involves a large number of design variables and multiple engineering disciplines. In this work we propose to use Automated Multidisciplinary Design and Control Optimization (AMDCO) techniques to find near optimal design solutions in terms of mass, volume, power, and control for SphereX for different mission scenarios. The implementation of AMDCO for SphereX design is a complex process because of complexity of modelling and implementation, discontinuities in the design space, and wide range of time scales and exploration objectives. Moreover, the design of SphereX will depend on target environment (e.g. gravity, temperature, radiation and surface properties), coordination complexity with increased number of robots, expected distance of exploration and expected mission time length. We address these issues by using machine learning in the form of Genetic Algorithms integrated with gradient-based optimization techniques to search through the design space and find pareto optimal solutions for a given mission task. Using this technology, it is now possible to perform end to end automated preliminary design of planetary robots for surface exploration. Copyright © 2019 by the International Astronautical Federation (IAF). All rights reserved.","Automated design; Genetic algorithms; Multidisciplinary optimization","International Astronautical Federation, IAF"
"Dyankov D., Riccio S.D., Di Fatta G., Nicosia G.","Multi-task Learning by Pareto Optimality",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-030-37599-7_50","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078442708&doi=10.1007%2f978-3-030-37599-7_50&partnerID=40&md5=47c6b72d28ee07d05b2cb85ca1c5c62c","Deep Neural Networks (DNNs) are often criticized because they lack the ability to learn more than one task at a time: Multitask Learning is an emerging research area whose aim is to overcome this issue. In this work, we introduce the Pareto Multitask Learning framework as a tool that can show how effectively a DNN is learning a shared representation common to a set of tasks. We also experimentally show that it is possible to extend the optimization process so that a single DNN simultaneously learns how to master two or more Atari games: using a single weight parameter vector, our network is able to obtain sub-optimal results for up to four games. © Springer Nature Switzerland AG 2019.","Atari 2600 Games; Deep artificial neural networks; Deep neuroevolution; Evolution Strategy; Hypervolume; Kullback-Leibler Divergence; Multitask learning; Neural and evolutionary computing","Springer"
"Li Z., Ton J.-F., Oglic D., Sejdinovic D.","Towards a unified analysis of random fourier features",2019,"36th International Conference on Machine Learning, ICML 2019",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078336197&partnerID=40&md5=22941015b1fd39aae0150f39c5841cb3","Random Fourier features is a widely used, simple, and effective technique for scaling up kernel methods. The existing theoretical analysis of the approach, however, remains focused on specific learning tasks and typically gives pessimistic bounds which are at odds with the empirical results. We tackle these problems and provide the first unified risk analysis of learning with random Fourier features using the squared error and Lipschitz continuous loss functions. In our bounds, the trade-off between the computational cost and the expected risk convergence rate is problem specific and expressed in terms of the regularization parameter and the number of effective degrees of freedom. We study both the standard random Fourier features method for which we improve the existing bounds on the number of features required to guarantee the corresponding minimax risk convergence rate of kernel ridge regression, as well as a data-dependent modification which samples features proportional to ridge leverage scores and further reduces the required number of features. As ridge leverage scores are expensive to compute, we devise a simple approximation scheme which provably reduces the computational cost without loss of statistical efficiency. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Xie Y., Chen M., Jiang H., Zhao T., Zha H.","On scalable and efficient computation of large scale optimal transport",2019,"36th International Conference on Machine Learning, ICML 2019",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078310493&partnerID=40&md5=89c9280c03560b9126422aefba0246b6","Optimal Transport (OT) naturally arises in many machine learning applications, yet the heavy computational burden limits its wide-spread uses. To address the scalability issue, we propose an implicit generative learning-based framework called SPOT (Scalable Push-forward of Optimal Transport). Specifically, we approximate the optimal transport plan by a pushforward of a reference distribution, and cast the optimal transport problem into a minimax problem. We then can solve OT problems efficiently using primal dual stochastic gradient-type algorithms. We also show that we can recover the density of the optimal transport plan using neural ordinary differential equations. Numerical experiments on both synthetic and real datasets illustrate that SPOT is robust and has favorable convergence behavior. SPOT also allows us to efficiently sample from the optimal transport plan, which benefits downstream applications such as domain adaptation. Copyright © 2019 ASME",,"International Machine Learning Society (IMLS)"
"Oono K., Suzuki T.","Approximation and non-parametric estimation of ResNet-type convolutional neural networks",2019,"36th International Conference on Machine Learning, ICML 2019",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078234229&partnerID=40&md5=bf476ed3081f3436e50bf7b7a6394801","Convolutional neural networks (CNNs) have been shown to achieve optimal approximation and estimation error rates (in minimax sense) in several function classes. However, previous analyzed optimal CNNs are unrealistically wide and difficult to obtain via optimization due to sparse constraints in important function classes, including the Holder class. Wc show a RcsNct-typc CNN can attain the minimax optimal error rates in these classes in more plausible situations - it can be dense, and its width, channel size, and filter size are constant with respect to sample size. The key idea is that we can replicate the learning ability of Fully-connected neural networks (FNNs) by tailored CNNs, as long as the FNNs have block-sparse structures. Our theory is general in a sense that we can automatically translate any approximation rate achieved by block-sparse FNNs into that by CNNs. As an application, we derive approximation and estimation error rates of the aformentioned type of CNNs for the Barron and Holder classes with the same strategy. © 2019 International Machine Learning Society (IMLS).",,"International Machine Learning Society (IMLS)"
"Hendrickx J.M., Olshevsky A., Saligrama V.","Graph resistance and learning from pairwise comparisons",2019,"36th International Conference on Machine Learning, ICML 2019",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078219084&partnerID=40&md5=4a238092e28ec9ab3707ab5b42338258","We consider the problem of learning the qualities of a collection of items by performing noisy comparisons among them. Following the standard paradigm, we assume there is a fixed ""comparison graph"" and every neighboring pair of items in this graph is compared k times according to the Bradley-Terry-Luce model (where the probability than an item wins a comparison is proportional the item quality). We are interested in how the relative error in quality estimation scales with the comparison graph in the regime where k is large. We prove that, after a known transition period, the relevant graph-theoretic quantity is the square root of the resistance of the comparison graph. Specifically, we provide an algorithm that is minimax optimal. The algorithm has a relative error decay that scales with the square root of the graph resistance, and provide a matching lower bound (up to log factors). The performance guarantee of our algorithm, both in terms of the graph and the skewness of the item quality distribution, outperforms earlier results. Copyright 2019 by the author(s).",,"International Machine Learning Society (IMLS)"
"Jang J., Jiang H.","DBScan++: Towards fast and scalable density clustering",2019,"36th International Conference on Machine Learning, ICML 2019",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078181349&partnerID=40&md5=f46e8bc489ef933b67da796fb46e44b7","DBSCAN is a classical density-based clustering procedure with tremendous practical relevance. However, DBSCAN implicitly needs to compute the empirical density for each sample point, leading to a quadratic worst-case time complexity, which is too slow on large datasets. We propose DBSCAN++, a simple modification of DBSCAN which only requires computing the densities for a chosen subset of points. We show empirically that, compared to traditional DBSCAN, DBSCAN++ can provide not only competitive performance but also added robustness in the bandwidth hyperparameter while taking a fraction of the runtime. We also present statistical consistency guarantees showing the trade-off between computational cost and estimation rates. Surprisingly, up to a certain point, we can enjoy the same estimation rates while lowering computational cost, showing that DBSCAN++ is a sub-quadratic algorithm that attains minimax optimal rates for level-set estimation, a quality that may be of independent interest. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Cardoso A.R., Abernethy J., Wang H., Xu H.","Competing against equilibria in zero-sum games with evolving payoffs",2019,"36th International Conference on Machine Learning, ICML 2019",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078059771&partnerID=40&md5=1aac00b162c48346650982cf93668008","We study the problem of repeated play in a zerosum game in which the payoff matrix may change, in a possibly adversarial fashion, on each round; we call these Online Matrix Games. Finding the Nash Equilibrium (NE) of a two player zero-sum game is core to many problems in statistics, optimization, and economics, and for a fixed game matrix this can be easily reduced to solving a linear program. But when the payoff matrix evolves over time our goal is to find a sequential algorithm that can compete with, in a certain sense, the NE of the long-term-averaged payoff matrix. We design an algorithm with small NE regret-that is, we ensure that the long-term payoff of both players is close to minimax optimum in hindsight. Our algorithm achieves near-optimal dependence with respect to the number of rounds and depends poly-logarithmically on the number of available actions of the players. Additionally, we show that the naive reduction, where each player simply minimizes its own regret, fails to achieve the stated objective regardless of which algorithm is used. Lastly, we consider the so-called bandit setting, where the feedback is significantly limited, and we provide an algorithm with small NE regret using one-point estimates of each payoff matrix. © 2019 by the Author(S).",,"International Machine Learning Society (IMLS)"
"Dann C., Li L., Wei W., Brunskill E.","Policy certificates: Towards accountable reinforcement learning",2019,"36th International Conference on Machine Learning, ICML 2019",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078015455&partnerID=40&md5=963dd72729d92ae089858dc7b1fe9bda","The performance of a reinforcement learning algorithm can vary drastically during learning because of exploration. Existing algorithms provide little information about the quality of their current policy before executing it, and thus have limited use in high-stakes applications like healthcare. We address this lack of accountability by proposing that algorithms output policy certificates. These certificates bound the sub-optimality and return of the policy in the next episode, allowing humans to intervene when the certified quality is not satisfactory. We further introduce two new algorithms with certificates and present a new framework for theoretical analysis that guarantees the quality of their policies and certificates. For tabular MDPs, we show that computing certificates can even improve the sample-efficiency of optimism-based exploration. As a result, one of our algorithms is the first to achieve minimax-optimal PAC bounds up to lower-order terms, and this algorithm also matches (and in some settings slightly improves upon) existing minimax regret bounds. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Pacchiano A., Chatterji N.S., Bartlett P.L.","Online learning with kernel losses",2019,"36th International Conference on Machine Learning, ICML 2019",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078011083&partnerID=40&md5=5316cf7605083167f567d22011f8862b","We present a generalization of the adversarial linear bandits framework, where the underlying losses are kernel functions (with an associated reproducing kernel Hilbert space) rather than linear functions. We study a version of the exponential weights algorithm and bound its regret in this setting. Under conditions on the eigen-decay of the kernel we provide a sharp characterization of the regret for this algorithm. When we have polynomial eigen-decay (μj ≤ O(j-β)), we find that the regret is bounded by Rn ≤ O(nβ/2(β-1)). While under the assumption of exponential eigen-decay (μj ≤ O(e-βj)) we get an even tighter bound on the regret Rn ≤ Õ(n1/2). When the eigen-decay is polynomial we also show a non-matching minimax lower bound on the regret of Rn ≥ Ω(n(β+1)/2β) and a lower bound of Rn ≥ Ω(n1/2) when the decay in the eigenvalues is exponentially fast. We also study the full information setting when the underlying losses are kernel functions and present an adapted exponential weights algorithm and a conditional gradient descent algorithm. © 2019 by the Author(S).",,"International Machine Learning Society (IMLS)"
"Zhang Y., Liu T., Long M., Jordan M.I.","Bridging theory and algorithm for domain adaptation",2019,"36th International Conference on Machine Learning, ICML 2019",21,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077973636&partnerID=40&md5=2d27f85dd352c3427e83c16f2ef598f3","This paper addresses the problem of unsupervised domain adaption from theoretical and algorithmic perspectives. Existing domain adaptation theories naturally imply minimax optimization algorithms, which connect well with the domain adaptation methods based on adversarial learning. However, several disconnections still exist and form the gap between theory and algorithm. We extend previous theories (Mansour et al., 2009c; Ben-David et al., 2010) to multiclass classification in domain adaptation, where classifiers based on the scoring functions and margin loss are standard choices in algorithm design. We introduce Margin Disparity Discrepancy, a novel measurement with rigorous generalization bounds, tailored to the distribution comparison with the asymmetric margin loss, and to the minimax optimization for easier training. Our theory can be seamlessly transformed into an adversarial learning algorithm for domain adaptation, successfully bridging the gap between theory and algorithm. A series of empirical studies show that our algorithm achieves the state of the art accuracies on challenging domain adaptation tasks. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Vinayak R.K., Kong W., Valiant G., Kakade S.","Maximum likelihood estimation for learning populations of parameters",2019,"36th International Conference on Machine Learning, ICML 2019",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077971555&partnerID=40&md5=9d3592ac8bf1d2f5418ba06b56fc740d","Consider a setting with N independent individuals, each with an unknown parameter, pi ∊ [0,1] drawn from some unknown distribution P*. After observing the outcomes of t independent Bernoulli trials, i.e., Xi ~ Binomial(t,pi) per individual, our objective is to accurately estimate P*. This problem arises in numerous domains, including the social sciences, psychology, healthcare, and biology, where the size of the population under study is usually large while the number of observations per individual is often limited. Our main result shows that, in the regime where t &lt;&lt; N, the maximum likelihood estimator (MLE) is both statistically minimax optimal and efficiently computable. Precisely, for sufficiently large N, the MLE achieves the information theoretic optimal error bound of O(1/t) for t &lt; clog N, with regards to the earth mover's distance (between the estimated and true distributions). More generally, in an exponentially large interval of t beyond c log iV, the MLE achieves the minimax error bound of O(1/ t log N). In contrast, regardless of how large N is, the naive ""plug-in"" estimator for this problem only achieves the sub-optimal error of Θ(1/ t). © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Basu S., Gutstein S., Lance B., Shakkottai S.","Pareto optimal streaming unsupervised classification",2019,"36th International Conference on Machine Learning, ICML 2019",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077961354&partnerID=40&md5=c3d1554d09967c88e0bb358886fddee2","We study an online and streaming unsupervised classification system. Our setting consists of a collection of classifiers (with unknown confusion matrices) each of which can classify one sample per unit time, and which are accessed by a stream of unlabeled samples. Each sample is dispatched to one or more classifiers, and depending on the labels collected from these classifiers, may be sent to other classifiers to collect additional labels. The labels are continually aggregated. Once the aggregated label has high enough accuracy (pre-specified threshold for accuracy) or the sample is sent to all the classifiers, the now labeled sample is ejected from the system. For any given pre-specified accuracy threshold, the objective is to sustain the maximum possible sample arrival rate, such that the number of samples in memory does not grow unbounded. In this paper, we characterize the Pareto-optimal region of accuracy and arrival rate, and develop an algorithm that can operate at any point within this region. Our algorithm uses queueing-bascd routing and scheduling approaches combined with a novel online tensor decomposition method to learn the hidden parameters, to Pareto-optimality guarantees. We finally verify our theoretical results through simulations on two ensembles formed using AlexNet, VGG, and ResNet deep image classifiers. © 36th International Conference on Machine Learning, ICML 2019. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Rado O., Neagu D.","On Selection of Optimal Classifiers",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-030-34885-4_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076994695&doi=10.1007%2f978-3-030-34885-4_42&partnerID=40&md5=bec5a9b9e154120ac362113e6ee44429","The current advances of computational power and storage allow more models to be created and stored from significant data resources. This progress opens the opportunity to re-cycle and re-use such models in similar exercises. The evaluation of the machine learning algorithms and selection of an appropriate classifier from an existing collection of classifiers are still challenging tasks. In most cases, the decision of selecting the classifier is left to the user. When the selection is not performed accurately, the outcomes can have unexpected performance results. Classification algorithms aim to optimise some of the distinct objectives such as minimising misclassification error, maximising the accuracy, or maximising the model quality. The right choice for each of these objectives is critical to the quality of the classifier selected. This work aims to study the use of a multi-objective method that can be undertaken to find a set of suitable classifiers for a problem at hand. In this study, we applied seven classifiers on mental health data sets for classifier selection in terms of correctness and reliability. The experimental results suggest that this approach is useful in finding the best trade-off among the objectives of selecting a suitable classifier framework. © 2019, Springer Nature Switzerland AG.","Classification algorithms; Optimization; Pareto set","Springer"
"Li L., Zhai X.B., Chen B., Li C.","Multiple Tasks Assignment for Cooperating Homogeneous Unmanned Aerial Vehicles",2019,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST",,"10.1007/978-3-030-32388-2_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076159380&doi=10.1007%2f978-3-030-32388-2_18&partnerID=40&md5=dbaa86a651f9e6999086aa07a8bbada6","Using multiple unmanned aerial vehicles (UAVs) to perform some tasks cooperatively has received growing attention in recent years. Task assignment is a difficult problem in mission planning. Multiple tasks assignment problem for cooperating homogeneous UAVs is considered as a traditional combinatorial optimization problem. This paper addresses the problem of assigning multiple tasks to cooperative homogeneous UAVs, minimizing the total cost and balancing the cost of each UAV. We propose a centralized task assignment scheme which is based on minimum spanning tree. This scheme involves two phases. In the first phase, we use the Kruskal algorithm and the breadth first search algorithm to assign all tasks to UAVs and get a proper initial task assignment solution. The second phase involves the Pareto optimization improvement in the solution generated from the first phase. For a single UAV, we use the dynamic programming algorithm to calculate the total cost of completing all assigned tasks. The performance of the proposed scheme is compared to that of heuristic simulated annealing algorithm. The simulation results show that the proposed scheme can solve the homogeneous multi-UAV cooperative task assignment problem effectively. © 2019, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Minimum spanning tree; Pareto optimization; Task assignment; Unmanned aerial vehicle","Springer"
"Nguyen D., Barkousaraie A.S., Shen C., Jia X., Jiang S.","Generating Pareto Optimal Dose Distributions for Radiation Therapy Treatment Planning",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",12,"10.1007/978-3-030-32226-7_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075822994&doi=10.1007%2f978-3-030-32226-7_7&partnerID=40&md5=db7491c7ca8bda57531f0091fa2e8aa2","Radiotherapy treatment planning currently requires many trial-and-error iterations between the planner and treatment planning system, as well as between the planner and physician for discussion/consultation. The physician’s preferences for a particular patient cannot be easily quantified and precisely conveyed to the planner. In this study we present a real-time volumetric Pareto surface dose generation deep learning neural network that can be used after segmentation by the physician, adding a tangible and quantifiable endpoint to portray to the planner. From 70 prostate patients, we first generated 84,000 intensity modulated radiation therapy plans (1,200 plans per patient) sampling the Pareto surface, representing various tradeoffs between the planning target volume (PTV) and the organs-at-risk (OAR), including bladder, rectum, left femur, right femur, and body. We divided the data to 10 test patients and 60 training/validation patients. We then trained a hierarchically densely connected convolutional U-net (HD U-net), to take the PTV and avoidance map representing OARs masks and weights, and predict the optimized plan. The HD U-net is capable of accurately predicting the 3D Pareto optimal dose distributions, with average [mean, max] dose errors of [3.4%, 7.7%](PTV), [1.6%, 5.6%](bladder), [3.7%, 4.2%](rectum), [3.2%, 8.0%](left femur), [2.9%, 7.7%](right femur), and [0.04%, 5.4%](body) of the prescription dose. The PTV dose coverage prediction was also very similar, with errors of 1.3% (D98) and 2.0% (D99). Homogeneity was also similar, differing by 0.06 on average. The neural network can predict the dose within 1.7 s. Clinically, the optimization and dose calculation is much slower, taking 5–10 min. © 2019, Springer Nature Switzerland AG.","Deep learning; Dose distribution; Intensity modulation; Neural network; Pareto surface; Radiation therapy treatment planning; U-net","Springer Science and Business Media Deutschland GmbH"
"Briones A.M., Rumpfkeil M.P., Thomas N.R., Rankin B.A.","Effect of deterministic and continuous design space resolution on multiple-objective combustor optimization",2019,"Proceedings of the ASME Turbo Expo",3,"10.1115/1.4045284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075798423&doi=10.1115%2f1.4045284&partnerID=40&md5=08d50b69aa0b3633509dc5b59b5eb7c4","A supervised machine learning technique namely an Adaptive Multiple Objective (AMO) optimization algorithm is used to divide a continuous and deterministic design space into non-dominated Pareto frontier and dominated design points. The effect of the initial training data quantity, i.e., computational fluid dynamics (CFD) results, on the Pareto frontier and output parameter sensitivity is explored. The optimization study is performed on a subsonic small-scale cavity-stabilized combustor. A parametric geometry is created using CAD that is coupled with a meshing software. The latter automatically transfers meshes and boundary conditions to the solver, which is coupled with a post-processing tool. Steady, incompressible three-dimensional simulations are performed using a multiphase realizable k-ε Reynolds-averaged Navier-Stokes (RANS) approach with an adiabatic flamelet progress variable (FPV). Scalable wall functions are used for modeling turbulence near the wall. For each CFD simulation four levels of adaptive mesh refinement (AMR) are utilized on the original cut-cell grid. The mesh is refined where the flow exhibits large progress variable curvature. There are fifteen geometrical input parameters and three output parameters, viz., a pattern factor proxy (maximum exit temperature), a combustion efficiency proxy (averaged exit temperature), and total pressure loss (TPL). The Pareto frontier and the input-to-output parameter sensitivities are reported for each meta-model simulation. For the investigated design space, three times the number of input parameters plus one (48) yields an optimization independent of the initial sampling. This conclusion is drawn by comparing the Pareto frontiers and global sensitivities. However, the latter provides a better metric. The relative influence of the input parameters on the outputs is assessed by using both a Spearman’s order-rank correlation approach as well as an active subspace analysis. In general, non-dominated design points exhibit persistent geometrical features such as offset opposed cavity forward and aft driver jet alignment. Larger cavities necessitate larger chutes and smaller outer liner jet diameters, whereas smaller cavities require smaller chutes and larger outer liner jet diameters. The fuel injector radial location varies, but can be located either radially inward or outward with respect to the forward dilution jet radial locations. For these non-dominated designs there is substantial burning inside and outside of the cavity. The downstream dilution jets quench the upstream hot gases. Copyright © 2019 ASME.",,"American Society of Mechanical Engineers (ASME)"
"Ma J., Bai T., Nguyen D., Folkerts M., Jia X., Lu W., Zhou L., Jiang S.","Individualized 3D dose distribution prediction using deep learning",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-030-32486-5_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075662825&doi=10.1007%2f978-3-030-32486-5_14&partnerID=40&md5=139d8745a325395f39b9feb018f10a42","In cancer radiotherapy, inverse treatment planning is a multi-objective optimization problem. There exists a set of plans with various trade-offs on Pareto surface which are referred as Pareto optimal plans. Currently exploring such trade-offs, i.e., physician preference is a trial and error process and often time-consuming. Therefore, it is desirable to predict desired Pareto optimal plans in an efficient way before treatment planning. The predicted plans can be used as references for dosimetrists to rapidly achieve a clinically acceptable plan. Clinically the dose volume histogram (DVH) is a useful tool that can visually indicate the specific dose received by each certain volume percentage which is supposed to describe different trade-offs. Consequently, we have proposed a deep learning method based on patient’s anatomy and DVH information to predict the individualized 3D dose distribution. Qualitative measurements have showed analogous dose distributions and DVH curves compared to the true dose distribution. Quantitative measurements have demonstrated that our model can precisely predict the dose distribution with various trade-offs for different patients, with the largest mean and max dose differences between true dose and predicted dose for all critical structures no more than 1.7% of the prescription dose. © Springer Nature Switzerland AG 2019.","Deep learning; Dose prediction; Trade-offs; Treatment planning","Springer"
"Louppe G., Hermans J., Cranmer K.","Adversarial variational optimization of non-differentiable simulators",2019,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075063837&partnerID=40&md5=069dfaf34c95f8907fadd97da256ea09","Complex computer simulators are increasingly used across fields of science as generative models tying parameters of an underlying theory to experimental observations. Inference in this setup is often difficult, as simulators rarely admit a tractable density or likelihood function. We introduce Adversarial Variational Optimization (AVO), a likelihood-free inference algorithm for fitting a non-differentiable generative model incorporating ideas from generative adversarial networks, variational optimization and empirical Bayes. We adapt the training procedure of generative adversarial networks by replacing the differentiable generative network with a domain-specific simulator. We solve the resulting non-differentiable minimax problem by minimizing variational upper bounds of the two adversarial objectives. Effectively, the procedure results in learning a proposal distribution over simulator parameters, such that the JS divergence between the marginal distribution of the synthetic data and the empirical distribution of observed data is minimized. We evaluate and compare the method with simulators producing both discrete and continuous data. © 2019 for this paper by its authors.","Likelihood-free inference; Physics; Simulator-based inference","CEUR-WS"
"Wang K.","Adversarial machine learning with double oracle",2019,"IJCAI International Joint Conference on Artificial Intelligence",1,"10.24963/ijcai.2019/925","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074953898&doi=10.24963%2fijcai.2019%2f925&partnerID=40&md5=723aefc7933192a801c5dd5fb5ad655d","We aim to improve the general adversarial machine learning solution by introducing the double oracle idea from game theory, which is commonly used to solve a sequential zero-sum game, where the adversarial machine learning problem can be formulated as a zero-sum minimax problem between learner and attacker. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved.",,"International Joint Conferences on Artificial Intelligence"
"Méndez-Hernández B.M., Rodríguez-Bazan E.D., Martinez-Jimenez Y., Libin P., Nowé A.","A Multi-objective Reinforcement Learning Algorithm for JSSP",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",4,"10.1007/978-3-030-30487-4_44","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072864863&doi=10.1007%2f978-3-030-30487-4_44&partnerID=40&md5=06570ac6f383e881e1e4c2f1481ff23d","Scheduling is a decision making process that takes care of the allocation of resources to tasks over time. The Job Shop scheduling problem is one of the most complex scheduling scenarios and is commonly encountered in manufacturing industries. Most of the existing studies are based on optimizing one objective, but in real-world problems, multiple criteria often need to be optimized at once. We propose a Multi-Objective Multi-Agent Reinforcement Learning Algorithm that aims to obtain the non-dominated solutions set for Job Shop scheduling problems. The proposed algorithm is used to solve a set of benchmark problems optimizing makespan and tardiness. The performance of our algorithm is evaluated and compared to other algorithms from the literature using two measures for evaluating the Pareto front. We show that our algorithm is able to find a set of diverse and high quality non-dominated solutions, that significantly and consistently improves upon the results obtained by other state-of-the-art algorithms. © 2019, Springer Nature Switzerland AG.","Job Shop Scheduling Problems; Multi-agent; Multi-objective; Pareto front; Reinforcement Learning","Springer Verlag"
"Kontorovich A., Pinelis I.","Exact lower bounds for the agnostic probably-approximately-correct (PAC) machine learning model",2019,"Annals of Statistics",5,"10.1214/18-AOS1766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072229645&doi=10.1214%2f18-AOS1766&partnerID=40&md5=cfee13e74f6a484176d5045a43068edd","We provide an exact nonasymptotic lower bound on the minimax expected excess risk (EER) in the agnostic probably-approximately-correct (PAC) machine learning classification model and identify minimax learning algorithms as certain maximally symmetric and minimally randomized ""voting"" procedures. Based on this result, an exact asymptotic lower bound on the minimax EER is provided. This bound is of the simple form c∞/√ν as ν→∞, where c∞ = 0.16997 . . . is a universal constant, ν = m/d, m is the size of the training sample and d is the Vapnik-Chervonenkis dimension of the hypothesis class. It is shown that the differences between these asymptotic and nonasymptotic bounds, as well as the differences between these two bounds and the maximum EER of any learning algorithms that minimize the empirical risk, are asymptotically negligible, and all these differences are due to ties in the mentioned ""voting"" procedures. A few easy to compute nonasymptotic lower bounds on the minimax EER are also obtained, which are shown to be close to the exact asymptotic lower bound c∞/√ν even for rather small values of the ratio ν = m/d. As an application of these results, we substantially improve existing lower bounds on the tail probability of the excess risk. Among the tools used are Bayes estimation and apparently new identities and inequalities for binomial distributions. © Institute of Mathematical Statistics, 2019.","Bayes decision rules; Binomial distribution; Classification; Empirical estimators; Generalization error; Minimax decision rules; PAC learning theory","Institute of Mathematical Statistics"
"Ramakrishnan R., Jui S., Partovi Nia V.","Deep demosaicing for edge implementation",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-27202-9_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071464755&doi=10.1007%2f978-3-030-27202-9_25&partnerID=40&md5=c7709f9752dee1ca7df646ae58c9121a","Most digital cameras use sensors coated with a Color Filter Array (CFA) to capture channel components at every pixel location, resulting in a mosaic image that does not contain pixel values in all channels. Current research on reconstructing these missing channels, also known as demosaicing, introduces many artifacts, such as zipper effect and false color. Many deep learning demosaicing techniques outperform other classical techniques in reducing the impact of artifacts. However, most of these models tend to be over-parametrized. Consequently, edge implementation of the state-of-the-art deep learning-based demosaicing algorithms on low-end edge devices is a major challenge. We provide an exhaustive search of deep neural network architectures and obtain a Pareto front of Color Peak Signal to Noise Ratio (CPSNR) as the performance criterion versus the number of parameters as the model complexity that outperforms the state-of-the-art. Architectures on the Pareto front can then be used to choose the best architecture for a variety of resource constraints. Simple architecture search methods such as exhaustive search and grid search requires some conditions of the loss function to converge to the optimum. We clarify these conditions in a brief theoretical study. © Springer Nature Switzerland AG 2019.","Deep learning; Demosaicing; Edge computing; Network architecture search","Springer Verlag"
"Renard E., Absil P.-A., Gallivan K.A.","Minimax center to extract a common subspace from multiple datasets",2019,"ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071305891&partnerID=40&md5=7dacac71c2488c554ab7d310d01605b5","We address the problem of extracting common information from multiple datasets. More specifically, we look for a common subspace minimizing the maximal dissimilarity with all datasets and we propose an algorithm derived from the first order necessary conditions of optimality. On synthetic datasets the proposed method gives as good results as a Riemannian based approach, but also provides an evaluation on how far the iterate is from a critical point. © 2019 ESANN (i6doc.com). All rights reserved.",,"ESANN (i6doc.com)"
"Noori A., Bi Lynn O., Ahmad H., Badlishah Ahmad R., Amir A., Abd A., Ibrahim M.K.","Wireless sensor network deployment based on machine learning for prolonging network lifetime and PDR",2019,"Journal of Theoretical and Applied Information Technology",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070796969&partnerID=40&md5=283218d7194b8894dc7328001f9defe6","Sensor Deployment (SN) is one of the major challenges in wireless sensor network architecture. One of the most fundamental issues in wireless sensor deployment is to balance the objective to resolve network conflicts. This paper aims to find the Pareto front that maximizes the packet delivery ratio and minimizes sensor energy consumption for prolonging network lifetime. For this proposal, a hyper-heuristic framework for improving the performance of the metaheuristic (LMOJPSO) search optimization process by combining two different searching techniques was designed. The first optimization technique carried out its searches with the help of an extreme learning machine (ELM), whereas the second used a wireless sensor network simulator. In this paper, the proposed method is examined in given wireless sensor network test instances, and the evaluation of its performance is carried out using a WSN performance metric. The results indicate that the proposed model is superior to the non-dominated sorting genetic algorithm (NSGA-II). © 2005 – ongoing JATIT & LLS.","Hyper-heuristic; NSGA-II; Optimization; PSO; Wireless sensor network deployment","Little Lion Scientific"
"Khan M.S.R., Hussain Z., Ahmad I.","A comparison of quadratic regression and artificial neural networks for the estimation of quantiles at ungauged sites in regional frequency analysis",2019,"Applied Ecology and Environmental Research",4,"10.15666/aeer/1703_69376959","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069899111&doi=10.15666%2faeer%2f1703_69376959&partnerID=40&md5=b7e35fbe2c081822e346ffd56b2505f5","The study illustrates application of Regional Flood Frequency Analysis (RFFA) using Annual Maximum Peak Flows (AMPF) of eleven gauging sites of various streams of Khyber-Pakhtunkhwa, Pakistan. Assumptions associated to recorded data at various sites have been validated through various statistical tests. The discordancy measure indicates that there is no discordant site in the cluster of eleven sites. Heterogeneity measure based on l-moments confirms that the group of eleven sites is definitely homogeneous. Criterion of |Z - Dist| statistic and L-moment ratio diagram show that Generalized Pareto (GPA) distribution is the best fitted regional distribution of the study region. Regional flood quantiles for various return periods have been estimated using the quantile function of GPA distribution. Artificial Neural Networks (ANN) and Quadratic Regression (QR) model with robust estimation method have been used for the estimation of quantiles at ungauged sites. Model evaluation criteria’s (error comparison of predicted values) suggested that estimated quantiles through ANN are accurate relative to quadratic regression. Historical comparison shows that the quantiles estimated through index flood method and ANN are closely related to the highest recorded values of AMPF at each corresponding site for shorter as well as longer return periods. © 2019, ALÖKI Kft., Budapest, Hungary.","Analyzing extremes of floods; Khyber-Pakhtunkhwa; L-moments; Machine learning; Non-linear regression; Pakistan; Regional frequency analysis","Corvinus University of Budapest"
"Yamaguchi T., Nagahama S., Ichikawa Y., Takadama K.","Model-Based Multi-objective Reinforcement Learning with Unknown Weights",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-030-22649-7_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069692072&doi=10.1007%2f978-3-030-22649-7_25&partnerID=40&md5=a242f27031f347f917a96552b9489daf","This paper describes solving multi-objective reinforcement learning problems where there are multiple conflicting objectives with unknown weights. Reinforcement learning (RL) is a popular algorithm for automatically solving sequential decision problems and most of them are focused on single-objective settings to decide a single solution. In multi-objective reinforcement learning (MORL), the reward function emits a reward vector instead of a scalar reward. A scalarization function with a vector of n weights (weight vector) is a commonly used to decide a single solution. The simple scalarization function is linear scalarization such as weighted sum. The main problem of previous MORL methods is a huge learning cost required to collect all Pareto optimal policies. Hence, it is hard to learn the high dimensional Pareto optimal policies. To solve this, this paper proposes the novel model-based MORL method by reward occurrence probability (ROP) with unknown weights. There are two main features. The first feature is that the average reward of a policy is defined by inner product of the ROP vector and the weight vector. The second feature is that it learns ROP in each policy instead of Q-values. Pareto optimal deterministic policies directly form the vertices of a convex hull in the ROP vector space. Therefore, Pareto optimal policies are calculated independently with weights and just once. The experimental results show that our proposed method collected all optimal policies under four dimensional Pareto optimal policies, and it takes a small computation time though previous MORL methods learn at most two or three dimensions. © 2019, Springer Nature Switzerland AG.","Average reward; Model-based; Multi-objective reinforcement learning; Reward occurrence probability; Reward vector","Springer Verlag"
"Rodriguez-Ibanez M., Munoz-Romero S., Soguero-Ruiz C., Gimeno-Blanes F.-J., Rojo-Alvarez J.L.","Towards Organization Management Using Exploratory Screening and Big Data Tests: A Case Study of the Spanish Red Cross",2019,"IEEE Access",5,"10.1109/ACCESS.2019.2923533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069048843&doi=10.1109%2fACCESS.2019.2923533&partnerID=40&md5=fecab60d842c8f601a4e1d4bbb3f7f1e","With the emergence of information and communication technologies, a large amount of data has turned available for the organizations, which creates expectations on their value and content for management purposes. However, the exploratory analysis of available organizational data based on emerging Big Data technologies are still developing in terms of operative tools for solid and interpretable data description. In this work, we addressed the exploratory analysis of organization databases at early stages where little quantitative information is available about their efficiency. Categorical and metric single-variable tests are proposed and formalized in order to provide a mass criterion to identify regions in forms with clusters of significant variables. Bootstrap resampling techniques are used to provide nonparametric criteria in order to establish easy-to-use statistical tests, so that single-variable tests are represented each on a visual and quantitative statistical plot, whereas all the variables in a given form are jointly visualized in the so-called chromosome plots. More detailed profile plots offer deep comparison knowledge for categorical variables across the organization physical and functional structures, while histogram plots for numerical variables incorporate the statistical significance of the variables under study for preselected Pareto groups. Performance grouping is addressed by identifying two or three groups according to some representative empirical distribution of some convenient grouping feature. The method is applied to perform a Big-Data exploratory analysis on the follow-up forms of Spanish Red Cross, based on the number of interventions and on a by-record basis. Results showed that a simple one-variable blind-knowledge exploratory Big-Data analysis, as the one developed in this paper, offers unbiased comparative graphical and numerical information that characterize organizational dynamics in terms of applied resources, available capacities, and productivity. In particular, the graphical and numerical outputs of the present analysis proved to be a valid tool to isolate the underlying overloaded or under-performing resources in complex organizations. As a consequence, the proposed method allows a systematic and principled way for efficiency analysis in complex organizations, which combined with organizational internal knowledge could leverage and validate efficient decision-making. © 2013 IEEE.","Big Data; machine learning; organization efficiency; organization management; prediction model","Institute of Electrical and Electronics Engineers Inc."
"He W., Wang G., Hu J., Li C., Guo B., Li F.","Simultaneous Human Health Monitoring and Time-Frequency Sparse Representation Using EEG and ECG Signals",2019,"IEEE Access",9,"10.1109/ACCESS.2019.2921568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068829878&doi=10.1109%2fACCESS.2019.2921568&partnerID=40&md5=57941ad9ab015dc087ee055a013e02c5","In the field of human health monitoring, intelligent diagnostic methods have drawn much attention recently to tackle the health problems and challenges faced by patients. In this paper, an efficient and flexible diagnostic method is proposed, which enables the simultaneous use of a machine learning method and sparsity-based representation technique. Specifically, the proposed method is based on a convolutional neural network (CNN) and generalized minimax-concave (GMC) method. First, measured potential signals, for instance, electroencephalogram (EEG) and electrocardiogram (ECG) signals are directly inputted into the designed network based on CNN for health conditions classification. The designed network adopts small convolution kernels to enhance the performance of feature extraction. In the training process, small batch samples are applied to improve the generalization of the model. Meanwhile, the 'Dropout' strategy is applied to overcome the overfitting problem in fully connected layers. Then, for a record of the interested EEG or ECG signal, the sparse representation of useful time-frequency features can be estimated via the GMC method. Case studies of seizure detection and arrhythmia signal analysis are adopted to verify the performance of the proposed method. The experimental results demonstrate that the proposed method can effectively identify different health conditions and maximally enhance the sparsity of time-frequency features. © 2013 IEEE.","convolutional neural network; deep learning; Feature extraction; health monitoring; sparse representation","Institute of Electrical and Electronics Engineers Inc."
"Hu R., Zhou S., Liu Y., Tang Z.","Margin-Based Pareto Ensemble Pruning: An Ensemble Pruning Algorithm That Learns to Search Optimized Ensembles",2019,"Computational Intelligence and Neuroscience",10,"10.1155/2019/7560872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067799451&doi=10.1155%2f2019%2f7560872&partnerID=40&md5=7677029b2bea1229e66fe0352ea795dd","The ensemble pruning system is an effective machine learning framework that combines several learners as experts to classify a test set. Generally, ensemble pruning systems aim to define a region of competence based on the validation set to select the most competent ensembles from the ensemble pool with respect to the test set. However, the size of the ensemble pool is usually fixed, and the performance of an ensemble pool heavily depends on the definition of the region of competence. In this paper, a dynamic pruning framework called margin-based Pareto ensemble pruning is proposed for ensemble pruning systems. The framework explores the optimized ensemble pool size during the overproduction stage and finetunes the experts during the pruning stage. The Pareto optimization algorithm is used to explore the size of the overproduction ensemble pool that can result in better performance. Considering the information entropy of the learners in the indecision region, the marginal criterion for each learner in the ensemble pool is calculated using margin criterion pruning, which prunes the experts with respect to the test set. The effectiveness of the proposed method for classification tasks is assessed using datasets. The results show that margin-based Pareto ensemble pruning can achieve smaller ensemble sizes and better classification performance in most datasets when compared with state-of-the-art models. © 2019 Ruihan Hu et al.",,"Hindawi Limited"
"Tolle I., Lee J., Salvador D., Saville B., Yong P.-B., Marcuccilli G.","Defect learning with predictive sampling for process improvement",2019,"Proceedings of SPIE - The International Society for Optical Engineering",,"10.1117/12.2523963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067652476&doi=10.1117%2f12.2523963&partnerID=40&md5=b438aa10e3a4c6c299c93d4a767942cc","As technology nodes advance, the need for higher sensitivity optical inspection to identify critical defects has become extremely important for technology development. However, more sensitive optical inspection can induce more nuisance and hence more SEM non-visual (SNV) defects during review sampling. High SNV in the defect Pareto hinders the ability to get a true picture of the actual distribution of defect types on a wafer, and defect-of-interest (DOI) types that are crucial for process diagnostics can be missed. The culprit of this problem is the method of review sampling. Traditional review sampling consists of two parts: binning and defect selection. Binning is defined as a set of rules and conditions determined by human experience and judgment to categorize different DOI types. Then, defects are selected from each bin and reviewed by SEM. Due to the nature of high SNV from optical inspection, the random selection of defects will end up with high SNV in the defect Pareto. A defect Pareto with high SNV provides little value to yield learning. Because SEM review plus classification is limited by time and economic budget, improving the ability to predict whether a defect is DOI or SNV before SEM review is valuable. This paper introduces a machine learning based method suitable for high volume manufacturing that can increase the probability of finding DOIs during review sampling by integrating all available data sources, such as historical defect attributes from optical inspection, context information of the inspection recipe, design hotspots and metrology measurements. In addition to review sampling, this paper also illustrates other applications based on machine learning defect prediction, such as virtual process window discovery, and predicted defect types for trend monitoring. A predictive analytics platform was employed to allow defect type prediction based upon multiple inputs. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Machine learning; Predictive analytics platform; Process window qualification; SEM sample optimization","SPIE"
"Kim J., Rinaldo A., Wasserman L.","Minimax rates for estimating the dimension of a manifold",2019,"Journal of Computational Geometry",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066615422&partnerID=40&md5=7cac2295eef9995d7d3f111bedde0f25","Many algorithms in machine learning and computational geometry require, as input, the intrinsic dimension of the manifold that supports the probability distribution of the data. This parameter is rarely known and therefore has to be estimated. We characterize the statistical difficulty of this problem by deriving upper and lower bounds on the minimax rate for estimating the dimension. First, we consider the problem of testing the hypothesis that the support of the data-generating probability distribution is a well-behaved manifold of intrinsic dimension d1 versus the alternative that it is of dimension d2, with d1 &lt; d2. With an i.i.d. sample of size n, we provide an upper bound on the probability of choosing the wrong dimension of O(n−(d2/d1 −1−ɛ)n), where ɛ is an arbitrarily small positive number. The proof is based on bounding the length of the traveling salesman path through the data points. We also demonstrate a lower bound of Ω( n−(2d2−2d1 +ɛ)n), by applying Le Cam’s lemma with a specific set of d1-dimensional probability distributions. We then extend these results to get minimax rates for estimating the dimension of well-behaved manifolds. We obtain an upper bound of order O (n−( 1−ɛ)n)m−1 and a lower bound of order Ω(n−(2+ɛ)n), where m is the embedding dimension. © 2019, Macodrum library, Carleton University. All rights reserved.",,"Macodrum library, Carleton University"
"Zhong J., Li J., Gao J., Chen R.","Digital recognition of street view house numbers based on DCGAN",2019,"ACM International Conference Proceeding Series",,"10.1145/3313950.3313963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065778560&doi=10.1145%2f3313950.3313963&partnerID=40&md5=8c5de7a16d719528e8d9870ba43cd74a","Deep learning algorithms have surpassed human resolution in applications such as face recognition and object classification. However, it can only produce very blurred, lack of details of the image. Generative Adversarial Network is a game training of minimax antagonism between generator G and discriminator D, and ultimately achieves Nash equilibrium. We use deep convolutional GAN that recognizes sequence numbers and without split characters. First we use convolution network to extract character features. Second we construct a convolution neural network to recognize digits of natural scene house number. DCGAN is used to improve the resolution of the number of fuzzy houses, so as to extract more abundant data features in data set training. It can better recognize the numbers in the natural street. © 2019 Association for Computing Machinery.","Deep convolutional generative adversarial networks; Image processing; Machine learning; Street view house numbers","Association for Computing Machinery"
"Tawhid M.A., Ali A.F.","Multidirectional harmony search algorithm for solving integer programming and minimax problems",2019,"International Journal of Bio-Inspired Computation",5,"10.1504/ijbic.2019.099179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065766915&doi=10.1504%2fijbic.2019.099179&partnerID=40&md5=2c4376e24332b9bc789183d1f5414535","Integer programming and minimax problems are essential tools in solving various problems that arise in data mining and machine learning such as multi-class data classification and feature selection problems. In this paper, we propose a new hybrid harmony search algorithm by combining the harmony search algorithm with the multidirectional search method in order to solve the integer programming and minimax problems. The proposed algorithm is called multidirectional harmony search algorithm (MDHSA). MDHSA starts the search by applying the standard harmony search for numbers of iteration then the best-obtained solution is passing to the multidirectional search method as an intensification process in order to accelerate the search and overcome the slow convergence of the standard harmony search algorithm. The proposed algorithm is balancing between the global exploration of the harmony search algorithm and the deep exploitation of the multidirectional search method. MDHSA algorithm is tested on seven integer programming problems and 15 minimax problems and compared against 12 algorithms for solving integer programming problems and 11 algorithms for solving minimax problems. The experiments results show the efficiency of the proposed algorithm and its ability to solve integer programming and minimax problems in reasonable time. Copyright © 2019 Inderscience Enterprises Ltd.","Direct search algorithm; Evolutionary computation; Global optimisation; Harmony search algorithm; Integer programming problems; Minimax problems; Multidirectional search","Inderscience Enterprises Ltd."
"Shirangi M.G., Oruganti Y., Wilson T., Furlong E., Winter E., Martin J., Yancy R.","Prescriptive analytics for completion optimization in unconventional resources",2019,"SPE Western Regional Meeting Proceedings",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064404363&partnerID=40&md5=586ebdc3f428a279bf0c5e5f3f762e18","In this work, we present and apply a comprehensive prescriptive analytics framework for well completion optimization in unconventional resources. The methodology involves 1) data processing, ingestion into databases, and data cleansing 2) application of AutoML for generating an accurate machine learning model, and 3) numerical optimization of decision parameters for minimizing an economic objective. Input parameters to the machine learning model include system parameters (such as well location and trajectory, existence and type of artificial lift) and decision parameters (such as number of stages, amount of stimulation material). The AutoML process automatically searches among various machine-learning algorithms (e.g., neural networks, random forest), to find the best algorithm and the best associated hyper-parameters. In the third step, a multi-objective optimization process is implemented to simultaneously optimize the 12-month oil producton (Qoil) and the completion cost divided by Qoil. The methodology is applied to a real case in the Permian Basin, in collaboration with Diamondback Energy. The results demonstrate that the two objectives are conflicting. The construction of the Pareto front, which shows a set of optimal solutions, provides a visual trade-off for decision makers and enables them to select a strategy that minimizes the cost, but does not sacrifice too much of the 12-month oil production. © 2019, Society of Petroleum Engineers",,"Society of Petroleum Engineers (SPE)"
"Gergel V., Grishagin V., Israfilov R.","Adaptive dimensionality reduction in multiobjective optimization with multiextremal criteria",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",2,"10.1007/978-3-030-13709-0_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063586554&doi=10.1007%2f978-3-030-13709-0_11&partnerID=40&md5=a5bd04200d076dce54cf33d6cbe54937","The paper is devoted to consideration of multicriterial optimization (MCO) problems subject to multiextremality of criteria. Application of convolution techniques for finding partial Pareto-optimal solutions generates under this assumption the multiextremal problems of scalar optimization. For solving these problems it is necessary to use efficient global optimization algorithms. As such the methods the nested schemes of dimensionality reduction in combination with univariate characteristical optimization algorithms are considered. A general description of the scheme is given and its modification accelerating the search is presented. Efficiency of the proposed approach is demonstrated on the base of representative computational experiment on a test class of bi-criterial MCO problems with essentially multiextremal criteria. © Springer Nature Switzerland AG 2019.","Dimensionality reduction; Global search algorithms; Multicriterial optimization; Multiextremal criteria","Springer Verlag"
"Feliot P., Bect J., Vazquez E.","User preferences in bayesian multi-objective optimization: The expected weighted hypervolume improvement criterion",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",3,"10.1007/978-3-030-13709-0_45","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063567557&doi=10.1007%2f978-3-030-13709-0_45&partnerID=40&md5=c5bbaee77b1d98450324e7a0e5d348d1","In this article, we present a framework for taking into account user preferences in multi-objective Bayesian optimization in the case where the objectives are expensive-to-evaluate black-box functions. A novel expected improvement criterion to be used within Bayesian optimization algorithms is introduced. This criterion, which we call the expected weighted hypervolume improvement (EWHI) criterion, is a generalization of the popular expected hypervolume improvement to the case where the hypervolume of the dominated region is defined using a user-defined absolutely continuous measure instead of the Lebesgue measure. The EWHI criterion takes the form of an integral for which no closed form expression exists in the general case. To deal with its computation, we propose an importance sampling approximation method. A sampling density that is optimal for the computation of the EWHI for a predefined set of points is crafted and a sequential Monte-Carlo (SMC) approach is used to obtain a sample approximately distributed from this density. The ability of the criterion to produce optimization strategies oriented by user preferences is demonstrated on a simple bi-objective test problem in the cases of a preference for one objective and of a preference for certain regions of the Pareto front. © Springer Nature Switzerland AG 2019.","Bayesian optimization; Importance sampling; Multi-objective optimization; Sequential monte-carlo; User preferences","Springer Verlag"
"Mazumdar A., Chugh T., Miettinen K., López-Ibáñez M.","On dealing with uncertainties from kriging models in offline data-driven evolutionary multiobjective optimization",2019,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",8,"10.1007/978-3-030-12598-1_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063027062&doi=10.1007%2f978-3-030-12598-1_37&partnerID=40&md5=ea5d2cef7768278d2f012fad851c4b01","Many works on surrogate-assisted evolutionary multiobjective optimization have been devoted to problems where function evaluations are time-consuming (e.g., based on simulations). In many real-life optimization problems, mathematical or simulation models are not always available and, instead, we only have data from experiments, measurements or sensors. In such cases, optimization is to be performed on surrogate models built on the data available. The main challenge there is to fit an accurate surrogate model and to obtain meaningful solutions. We apply Kriging as a surrogate model and utilize corresponding uncertainty information in different ways during the optimization process. We discuss experimental results obtained on benchmark multiobjective optimization problems with different sampling techniques and numbers of objectives. The results show the effect of different ways of utilizing uncertainty information on the quality of solutions. © Springer Nature Switzerland AG 2019.","Gaussian process; Machine learning; Metamodelling; Pareto optimality; Surrogate","Springer Verlag"
"Nepal K., Hashemi S., Tann H., Bahar R.I., Reda S.","Automated high-level generation of low-power approximate computing circuits",2019,"IEEE Transactions on Emerging Topics in Computing",25,"10.1109/TETC.2016.2598283","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062732445&doi=10.1109%2fTETC.2016.2598283&partnerID=40&md5=cef46378b68e4791a67e0d94e630b792","Numerous application domains (e.g., signal and image processing, computer graphics, computer vision, and machine learning) are inherently error tolerant, which can be exploited to produce approximate ASIC implementations with low power consumption at the expense of negligible or small reductions in application quality. A major challenge is the need for approximate and high-level design generation tools that can automatically work on arbitrary designs. In this article, we provide an expanded and improved treatment of our ABACUS methodology, which aims to automatically generate approximate designs directly from their behavioral register-transfer level (RTL) descriptions, enabling a wider range of possible approximations. ABACUS starts by creating an abstract syntax tree (AST) from the input behavioral RTL description of a circuit, and then applies variant operators to the AST to create acceptable approximate designs. The devised variant operators include data type simplifications, arithmetic operation approximations, arithmetic expressions transformations, variable-to-constant substitutions, and loop transformations. A design space exploration technique is devised to explore the space of possible variant approximate designs and to identify the designs along the Pareto frontier that represents the trade-off between accuracy and power consumption. In addition, ABACUS prioritizes generating approximate designs that, when synthesized, lead to circuits with simplified critical paths, which are exploited to realize complementary power savings through standard voltage scaling. We integrate ABACUS with a standard ASIC design flow, and evaluate it on four realistic benchmarks from three different domains - machine learning, signal processing, and computer vision. Our tool automatically generates many approximate design variants with large power savings, while maintaining good accuracy. We demonstrate the scalability of ABACUS by parallelizing the flow and use of recent standard synthesis tools. Compared to our previous efforts, the new ABACUS tool provides up to 20.5× speed-up in runtime, while able to generate approximate circuits that lead to additional power savings reaching up to 40 percent. © 2013 IEEE.","Approximate computing; critical path optimization; design space exploration; low area circuits; low power circuits; voltage scaling","IEEE Computer Society"
"Künzel S.R., Sekhon J.S., Bickel P.J., Yu B.","Metalearners for estimating heterogeneous treatment effects using machine learning",2019,"Proceedings of the National Academy of Sciences of the United States of America",85,"10.1073/pnas.1804597116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062674310&doi=10.1073%2fpnas.1804597116&partnerID=40&md5=73b2da5343c6199f9d390d2bffdafcbb","There is growing interest in estimating and analyzing heterogeneous treatment effects in experimental and observational studies. We describe a number of metaalgorithms that can take advantage of any supervised learning or regression method in machine learning and statistics to estimate the conditional average treatment effect (CATE) function. Metaalgorithms build on base algorithms—such as random forests (RFs), Bayesian additive regression trees (BARTs), or neural networks—to estimate the CATE, a function that the base algorithms are not designed to estimate directly. We introduce a metaalgorithm, the X-learner, that is provably efficient when the number of units in one treatment group is much larger than in the other and can exploit structural properties of the CATE function. For example, if the CATE function is linear and the response functions in treatment and control are Lipschitz-continuous, the X-learner can still achieve the parametric rate under regularity conditions. We then introduce versions of the X-learner that use RF and BART as base learners. In extensive simulation studies, the X-learner performs favorably, although none of the metalearners is uniformly the best. In two persuasion field experiments from political science, we demonstrate how our X-learner can be used to target treatment regimes and to shed light on underlying mechanisms. A software package is provided that implements our methods. © 2019 National Academy of Sciences. All Rights Reserved.","conditional average treatment effect; heterogeneous treatment effects; minimax optimality; Observational studies; randomized controlled trials","National Academy of Sciences"
"Abdikenov B., Iklassov Z., Sharipov A., Hussain S., Jamwal P.K.","Analytics of Heterogeneous Breast Cancer Data Using Neuroevolution",2019,"IEEE Access",13,"10.1109/ACCESS.2019.2897078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062209129&doi=10.1109%2fACCESS.2019.2897078&partnerID=40&md5=e9c58bbcb3d47a51b16670074e45fcec","Breast cancer prognostic modeling is difficult since it is governed by many diverse factors. Given the low median survival and large scale breast cancer data, which comes from high throughput technology, the accurate and reliable prognosis of breast cancer is becoming increasingly difficult. While accurate and timely prognosis may save many patients from going through painful and expensive treatments, it may also help oncologists in managing the disease more efficiently and effectively. Data analytics augmented by machine-learning algorithms have been proposed in past for breast cancer prognosis; and however, most of these could not perform well owing to the heterogeneous nature of available data and model interpretability related issues. A robust prognostic modeling approach is proposed here whereby a Pareto optimal set of deep neural networks (DNNs) exhibiting equally good performance metrics is obtained. The set of DNNs is initialized and their hyperparameters are optimized using the evolutionary algorithm, NSGAIII. The final DNN model is selected from the Pareto optimal set of many DNNs using a fuzzy inferencing approach. Contrary to using DNNs as the black box, the proposed scheme allows understanding how various performance metrics (such as accuracy, sensitivity, F1, and so on) change with changes in hyper-parameters. This enhanced interpretability can be further used to improve or modify the behavior of DNNs. The heterogeneous breast cancer database requires preprocessing for better interpretation of categorical variables in order to improve prognosis from classifiers. Furthermore, we propose to use a neural network-based entity-embedding method for categorical features with high cardinality. This approach can provide a vector representation of categorical features in multidimensional space with enhanced interpretability. It is shown with evidence that DNNs optimized using evolutionary algorithms exhibit improved performance over other classifiers mentioned in this paper. © 2013 IEEE.","Breast cancer prognostic modelling; deep learning networks; entity embedding; evolutionary algorithms; fuzzy inferencing","Institute of Electrical and Electronics Engineers Inc."
"Masampally V., Pareek A., Nadimpalli N.K.V., Runkana V.","Multi-objective optimization of a mineral processing plant via machine learning and genetic algorithms",2019,"IMPC 2018 - 29th International Mineral Processing Congress",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059434852&partnerID=40&md5=d32077eca833e4225bc9b6ca45374cb0","Recovery and grade of the ore produced are two important metrics, which define the profitability of a mineral processing plant. Achieving high grade and high recovery at the same time in a mineral processing plant is difficult due to conflicting nature of the two objectives. To explore the operability limits of the plant operations and find the set of operating conditions that can help achieve the best possible recovery and grade, there is a need to solve a multi-objective optimization (MOO) problem. Past research focused on building a plant-wide simulation model or on optimization of individual units or a part of a mineral processing plant like grinding circuit, crushing circuit, etc. However, it is necessary to consider optimization of the complete plant in order to optimize the plant performance. Here, we have formulated the mineral processing plant performance optimization as a MOO problem. We have applied machine-learning algorithms such as random forest to build models to predict the recovery and grade of the ore. non-dominated sorting-based multi-objective evolutionary algorithm called NSGA-II (Non-dominated Sorting Genetic Algorithm II) was employed to solve the MOO problem. Since the number of parameters that influence recovery and grade are quite large, we have applied machine-learning algorithms for feature selection or identification of key process variables. Pareto optimal conditions were determined for manipulated variables like grinding mill throughput, speed ratio at SAG mill, speed of centrifugal pump, water addition at different locations etc. The results obtained are useful in identifying the operability of a mineral processing plant to achieve the optimum grade and recovery for a given feed grade and the processing circuit. © IMPC 2018 - 29th International Mineral Processing Congress. All rights reserved.","Genetic algorithm; Machine learning; Mineral processing; Modeling; Multi-objective optimization","Canadian Institute of Mining, Metallurgy and Petroleum"
"Senhaji K., Ramchoun H., Ettaouil M.","Multilayer Perceptron: NSGA II for a New Multi-objective Learning Method for Training and Model Complexity",2019,"Advances in Intelligent Systems and Computing",1,"10.1007/978-3-319-91337-7_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047323459&doi=10.1007%2f978-3-319-91337-7_15&partnerID=40&md5=f08b29068ecd7896e8517da85409a098","The multi-layer perceptron has proved its efficiencies in several fields as pattern and voice recognition. Unfortunately, the classical training for MLP suffers from a poor generalization. In this respect, we have proposed a new multi-objective training model with constraints, satisfies two objectives. The first one is the learning objective: minimizing the perceptron error and the second is the complexity objective: optimizing number of weights and neurons. The proposed model will provide a balance between the multi-layer perceptron learning and the complexity to get a good generalization. Our model has been solved using an evolutionary approach called the Non-Dominated Sorting Genetic Algorithm (NSGA II). This approach has led to a good representation of the Pareto set for the MLP network, from which an improved generalization performance model is selected. © 2019, Springer International Publishing AG, part of Springer Nature.","Multi-objective training; Multilayer perceptron; Non-dominated Sorting Genetic Algorithm II (NSGA II); Non-linear optimization; Pareto front; Supervised learning","Springer Verlag"
"Kovalerchuk B., Grishin V.","Adjustable general line coordinates for visual knowledge discovery in n-D data",2019,"Information Visualization",10,"10.1177/1473871617715860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041025100&doi=10.1177%2f1473871617715860&partnerID=40&md5=f919ebcdba4ad916d1e3893de03bddb7","Preserving all multidimensional data in two-dimensional visualization is a long-standing problem in Visual Analytics, Machine Learning/Data Mining, and Multiobjective Pareto Optimization. While Parallel and Radial (Star) coordinates preserve all n-D data in two dimensions, they are not sufficient to address visualization challenges of all possible datasets such as occlusion. More such methods are needed. Recently, the concepts of lossless General Line Coordinates that generalize Parallel, Radial, Cartesian, and other coordinates were proposed with initial exploration and application of several subclasses of General Line Coordinates such as Collocated Paired Coordinates and Star Collocated Paired Coordinates. This article explores and enhances benefits of General Line Coordinates. It shows the ways to increase expressiveness of General Line Coordinates including decreasing occlusion and simplifying visual pattern while preserving all n-D data in two dimensions by adjusting General Line Coordinates for given n-D datasets. The adjustments include relocating, rescaling, and other transformations of General Line Coordinates. One of the major sources of benefits of General Line Coordinates relative to Parallel Coordinates is twice less number of point and lines in visual representation of each n-D points. This article demonstrates the benefits of different General Line Coordinates for real data visual analysis such as health monitoring and benchmark Iris data classification compared with results from Parallel Coordinates, Radvis, and Support Vector Machine. The experimental part of the article presents the results of the experiment with about 70 participants on efficiency of visual pattern discovery using Star Collocated Paired Coordinates, Parallel, and Radial Coordinates. It shows advantages of visual discovery of n-D patterns using General Line Coordinates subclass Star Collocated Paired Coordinates with n = 160 dimensions. © The Author(s) 2017.","adjustable coordinates; clutter reduction; general line coordinates; knowledge discovery; lossless visual representation; machine learning; Multidimensional data visualization; parallel coordinates; reversible visual representation; visual data mining","SAGE Publications Ltd"
"Dehghanpour K., Nehrir H.","An Agent-Based Hierarchical Bargaining Framework for Power Management of Multiple Cooperative Microgrids",2019,"IEEE Transactions on Smart Grid",49,"10.1109/TSG.2017.2746014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028522967&doi=10.1109%2fTSG.2017.2746014&partnerID=40&md5=d2c01b021fd246ef9925f95695373f65","In this paper, we propose an agent-based hierarchical power management model in a power distribution system composed of several microgrids (MGs). At the lower level of the model, multiple MGs bargain with each other to cooperatively obtain a fair, and Pareto-optimal solution to their power management problem, employing the concept of Nash bargaining solution and using a distributed optimization framework. At the highest level of the model, a distribution system power supplier, e.g., a utility company, interacts with both the cluster of the MGs and the wholesale market. The goal of the utility company is to facilitate power exchange between the regional distribution network consisting of multiple MGs and the wholesale market to achieve its own private goals. The power exchange is controlled through dynamic energy pricing at the distribution level, at the day-ahead and real-time stages. To implement energy pricing at the utility company level, an iterative machine learning mechanism is employed, where the utility company develops a price-sensitivity model of the aggregate response of the MGs to the retail price signal through a learning process. This learned model is then used to perform optimal energy pricing. To verify its applicability, the proposed decision model is tested on a system with multiple MGs, with each MG having different load/generation data. © 2010-2012 IEEE.","agent-based modeling; bargaining games; distributed optimization; Microgrids; power management","Institute of Electrical and Electronics Engineers Inc."
"Deng Z., Liu M.","An Integrated Generation-Compensation optimization Strategy for Enhanced Short-Term Voltage Security of Large-Scale Power Systems Using Multi-Objective Reinforcement Learning Method",2019,"2018 International Conference on Power System Technology, POWERCON 2018 - Proceedings",2,"10.1109/POWERCON.2018.8601814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061752440&doi=10.1109%2fPOWERCON.2018.8601814&partnerID=40&md5=2cca68af361031502acdad18f722540d","High penetrations of industrial loads have placed significant pressures on short-term voltage security. This paper proposes an integrated generation-compensation optimization strategy, which coordinates the generators and the switchable capacitor banks to enhance short-term voltage security as a multi-objective dynamic optimization (MODO) model. This model is established containing dynamics, power flow balances, and security constraints to minimize the voltage deviation and the cost of control strategy. The differential-algebra equations are converted into algebra equations using the Radau collocation method. Furthermore, a novel multi-objective reinforcement learning (MORL) method is utilized to mitigate the computational burdens and to obtain Pareto optimal solutions by filtering the dominated solutions. Compared with conventional MORL methods, the proposed MORL method divides the full feasible region into several small independent regions to reduce and eliminate the searching for Pareto optimal solutions. Meanwhile, the state functions of MORL are redefined, and the state sensitivities are introduced to judge whether the trial and learning accumulate sufficient knowledge. Moreover, the Pareto optimal solutions are further improved by introducing several possible solutions. Finally, the tradeoff solution is obtained based on Fuzzy decision-making strategy. The effectiveness and efficiency of the MORL method are verified by numerical simulations on a provincial 748-bus power system. © 2018 IEEE.","Multi-objective dynamic optimization; multi-objective reinforcement learning; Pareto optimal solution; Radau collocation method; short-term voltage security","Institute of Electrical and Electronics Engineers Inc."
"Bilal M., Ullah M., Ullah H.","Chemometric data analysis with autoencoder neural network",2019,"IS and T International Symposium on Electronic Imaging Science and Technology",3,"10.2352/ISSN.2470-1173.2019.1.VDA-679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080046996&doi=10.2352%2fISSN.2470-1173.2019.1.VDA-679&partnerID=40&md5=427fa216ba7f69708564d33c6dbbbb22","We propose novel deep learning based chemometric data analysis technique. We trained L2 regularized sparse autoencoder end-to-end for reducing the size of the feature vector to handle the classic problem of the curse of dimensionality in chemometric data analysis. We introduce a novel technique of automatic selection of nodes inside the hidden layer of an autoencoder through Pareto optimization. Moreover, Gaussian process regressor is applied on the reduced size feature vector for the regression. We evaluated our technique on orange juice and wine dataset and results are compared against 3 state-of-the-art methods. Quantitative results are shown on Normalized Mean Square Error (NMSE) and the results show considerable improvement in the state-of-the-art. © 2019 Society for Imaging Science and Technology. All rights reserved.","Chemometric data; Gaussian process regressor; Pareto optimization; Sparse autoencoder","Society for Imaging Science and Technology"
"Wangsom P., Bouvry P., Lavangnananda K.","Extreme Solutions NSGA-III (E-NSGA-III) for Scientific Workflow Scheduling on Cloud",2019,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",5,"10.1109/ICMLA.2018.00184","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062237230&doi=10.1109%2fICMLA.2018.00184&partnerID=40&md5=8ca28132b75d7f6f30c0937302a93efd","The execution of scientific workflows on dynamic environments such as cloud computing has become multi-objective scheduling in order to satisfy user demands from several perspectives. Among these objectives, Cost and Makespan are probably the most common. This research also includes Data Movement as an additional objective as it has significant effect to network utilization and energy consumption in network equipment in cloud data center. This paper proposes a multi-objective scheduling, Extreme Nondominated Sorting Genetic Algorithm (E-NSGA-III). It is an extension of the Nondominated Sorting Genetic Algorithm (NSGA-III). E-NSGA-III utilizes extreme solutions in the population generation module in order improve quality of solutions. Five well-known scientific workflows are selected as testbeds. Hypervolume and the Pareto front are chosen as the performance metrics. E-NSGA-III is evaluated by comparing its performance against the two previous versions (NSGA-II and NSGA-III). The comparison reveals that E-NSGA-III yields the best performance among them in multi-objective scheduling of the five scientific workflows. © 2018 IEEE.","Cloud Computing; Cost; Data Movement; Extreme Nondominated Sorting Genetic Algorithm (E-NSGA-III); Makespan; Multi-objective Scheduling; NSGA-II; NSGA-III; Scientific Workflow","Institute of Electrical and Electronics Engineers Inc."
"Pulkkinen P., Tiwari N., Kumar A., Jones C.","A Multi-objective Rule Optimizer with an Application to Risk Management",2019,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",2,"10.1109/ICMLA.2018.00018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062223514&doi=10.1109%2fICMLA.2018.00018&partnerID=40&md5=d955bba484e859fe8783295ddf70aa58","Managing risk is important to any E-commerce merchant. Various machine learning (ML) models combined with a rule set as the decision layer is a common practice to manage the risks. Unlike the ML models that can be automatically refreshed periodically based on new risk patterns, rules are generally static and rely on manual updates. To tackle that, this paper presents a data-driven and automated rule optimization method that generates multiple Pareto-optimal rule sets representing different trade-offs between business objectives. This enables business owners to make informed decisions when choosing between optimized rule sets for changing business needs and risks. Furthermore, manual work in rule management is greatly reduced. For scalability this method leverages Apache Spark and runs either on a single host or in a distributed environment in the cloud. This allows us to perform the optimization in a distributed fashion using millions of transactions, hundreds of variables and hundreds of rules during the training. The proposed method is general but we used it for optimizing real-world E-commerce (Amazon) risk rule sets. It could also be used in other fields such as finance and medicine. © 2018 IEEE.","Big data; Cloud computing; Machine learning; Multi-objective optimization; Risk management; Spark","Institute of Electrical and Electronics Engineers Inc."
"Badiei Khuzani M.","Distributed Primal-Dual Proximal Method for Regularized Empirical Risk Minimization",2019,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",,"10.1109/ICMLA.2018.00152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062221095&doi=10.1109%2fICMLA.2018.00152&partnerID=40&md5=1effd2eb0cd605b3f39e0d862575c428","Most high-dimensional estimation and classification methods propose to minimize a loss function (empirical risk) that is the sum of losses associated with each observed data point. We consider the special case of binary classification problems, where the loss is a function of the inner product of the feature vectors and a weight vector. For this special class of classification tasks, the empirical risk minimization problem can be recast as a minimax optimization which has a unique saddle point when the losses are smooth functions. We propose a distributed proximal primal-dual method to solve the minimax problem. We also analyze the convergence of the proposed primal-dual method and show its convergence to the unique saddle point. To prove the convergence results, we present a novel analysis of the consensus terms that takes into account the non-Euclidean geometry of the parameter space. We also numerically verify the convergence of the proposed algorithm for the logistic regression on the Erdös-Réyni random graphs and lattices. © 2018 IEEE.","Distributed Optimization; Empirical Risk; Primal-Dual Method","Institute of Electrical and Electronics Engineers Inc."
"Zhang J., Xu Z., Xu W., Zhu F., Lyu X., Fu M.","Bi-objective dispatch of multi-energy virtual power plant: Deep-learning-based prediction and particle swarm optimization",2019,"Applied Sciences (Switzerland)",14,"10.3390/app9020292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059983404&doi=10.3390%2fapp9020292&partnerID=40&md5=460ccca70f1af6a6d06f7e5c431e2949","This paper addresses the coordinative operation problem of multi-energy virtual power plant (ME-VPP) in the context of energy internet. A bi-objective dispatch model is established to optimize the performance of ME-VPP in terms of economic cost (EC) and power quality (PQ). Various realistic factors are considered, which include environmental governance, transmission ratings, output limits, etc. Long short-term memory (LSTM), a deep learning method, is applied to the promotion of the accuracy of wind prediction. An improved multi-objective particle swarm optimization (MOPSO) is utilized as the solving algorithm. A practical case study is performed on Hongfeng Eco-town in Southwestern China. Simulation results of three scenarios verify the advantages of bi-objective optimization over solely saving EC and enhancing PQ. The Pareto frontier also provides a visible and flexible way for decision-making of ME-VPP operator. Two strategies, ""improvisational"" and ""foresighted"", are compared by testing on the Institute of Electrical and Electronic Engineers (IEEE) 118-bus benchmark system. It is revealed that ""foresighted"" strategy, which incorporates LSTM prediction and bi-objective optimization over a 5-h receding horizon, takes 10 Pareto dominances in 24 h. © 2019 by the authors.","Bi-objective dispatch; Economic cost; Long short-term memory; Multi-energy virtual power plant; Multi-objective particle swarm optimization; Power quality","MDPI AG"
"Masuyama N., Tanigaki Y., Nojima Y., Ishibuchi H.","Multiobjective Evolutionary Data Mining for Performance Improvement of Evolutionary Multiobjective Optimization",2019,"Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018",,"10.1109/SMC.2018.00135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062219008&doi=10.1109%2fSMC.2018.00135&partnerID=40&md5=96e025b0af6d3b54d1901f3036531646","In recent years, evolutionary multiobjective optimization (EMO) algorithms have frequently been used for engineering problems with some conflicting objective functions to be simultaneously optimized. EMO algorithms can provide a number of Pareto optimal solutions to users. Two scenarios are considered in the practical use of EMO algorithms. One is that a decision maker selects a single solution from the obtained ones after the EMO process. The other is that a decision maker utilizes the solutions to analyze the relationship between design variables and objective functions of the corresponding problem. In this paper, we apply fuzzy genetics-based machine learning to the second scenario in order to generate if-then rule-based classifiers which represent the relationship between design variables and objective functions. We also utilize this method during the EMO process to pre-screen candidate offspring solutions. The classifier detects non-promising offspring solutions. Then, they are discarded before their fitness evaluation, so that the computation resource is used only for promising solutions. We apply this method to one engineering problem and examine its effect on the search performance of an EMO algorithm. © 2018 IEEE.","data mining; Evolutionary multiobjective optimization; multiobjective fuzzy genetics-based machine learning; pattern classification","Institute of Electrical and Electronics Engineers Inc."
"Sun X., Le T.N., Chowdhury M., Liu Z.","Fair allocation of heterogeneous and interchangeable resources",2019,"Performance Evaluation Review",1,"10.1145/3305218.3305227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061100776&doi=10.1145%2f3305218.3305227&partnerID=40&md5=2a2173d4e98f5b314e1dd3a58bbb9a5a","Motivated by the proliferation of heterogeneous processors such as multi-core CPUs, GPUs, TPUs, and other accelerators for machine learning, we formulate a novel multi-interchangeable resource allocation (MIRA) problem where some resources are interchangeable. The challenge is how to allocate interchangeable resources to users in a sharing system while maintaining desirable properties such as sharing incentive, Pareto efficiency, and envy-freeness. In this paper, we first show that existing algorithms, including the Dominant Resource Fairness used in production systems, fail to provide these properties for interchangeable resources. Then we characterize the tradeo between performance and strategyproofness, and design the Budget-based (BUD) algorithm, which preserves Pareto efficiency, sharing incentive and envy-freeness while providing better performance over currently used algorithms. © 2018 Copyright held by the owner/author(s).",,"Association for Computing Machinery"
"Muniraj D., Vamvoudakis K.G., Farhood M.","Enforcing Signal Temporal Logic Specifications in Multi-Agent Adversarial Environments: A Deep Q-Learning Approach",2019,"Proceedings of the IEEE Conference on Decision and Control",13,"10.1109/CDC.2018.8618746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062192491&doi=10.1109%2fCDC.2018.8618746&partnerID=40&md5=be630fa2f8b17f48b5983152023905d9","This work addresses the problem of learning optimal control policies for a multi-agent system in an adversarial environment. Specifically, we focus on multi-agent systems where the mission objectives are expressed as signal temporal logic (STL) specifications. The agents are classified as either defensive or adversarial. The defensive agents are maximizers, namely, they maximize an objective function that enforces the STL specification; the adversarial agents, on the other hand, are minimizers. The interaction among the agents is modeled as a finite-state team stochastic game with an unknown transition probability function. The synthesis objective is to determine optimal control policies for the defensive agents that implement the STL specification against the best responses of the adversarial agents. A multi-agent deep Q-learning algorithm, which is an extension of the minimax Q-learning algorithm, is then proposed to learn the optimal policies. The effectiveness of the proposed approach is illustrated through a simulation case study. © 2018 IEEE.","deep Q-learning; multi-agent system; signal temporal logic","Institute of Electrical and Electronics Engineers Inc."
"Motohashi H., Teraoka T., Aoki S., Ohwada H.","Regression Models and Ranking Method for p53 Inhibitor Candidates Using Machine Learning",2019,"Proceedings - 2018 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2018",2,"10.1109/BIBM.2018.8621142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062520329&doi=10.1109%2fBIBM.2018.8621142&partnerID=40&md5=d18e3d067b30ab0fed7bcddf6b07e6d6","Radiation therapy is one of the main treatments for cancer. However, it may cause various side effects owing to the apoptosis activity of the p53 protein in normal cells. Therefore, to avoid the side effects, it is important to protect normal cells against radiation by using p53 inhibitors. It is also expected that p53 inhibitors have low toxicity against patients' bodies. However, the design of p53 inhibitors is not easy because drug discovery requires enormous costs and long time. In this paper, we propose a new method for ranking candidate p53 inhibitors, considering both their radioprotective function and cytotoxicity. We use features of the two- and three-dimensional structures of the compounds, including fingerprints, some machine learning methods such as random forest and SVR (Support Vector Machine), and one method for ranking, i.e., the Pareto ranking method. Therefore, we present the regression models of the cytotoxicity and radioprotective functions of the candidates to determine their ranking. Our proposed methods yield useful rankings for drug discovery. © 2018 IEEE.","machine learning; p53; Pareto ranking; SVR","Institute of Electrical and Electronics Engineers Inc."
"Ma X., Xia L., Zhao Q.","Air-Combat Strategy Using Deep Q-Learning",2019,"Proceedings 2018 Chinese Automation Congress, CAC 2018",14,"10.1109/CAC.2018.8623434","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062791739&doi=10.1109%2fCAC.2018.8623434&partnerID=40&md5=1ef1af9cfb40e34cc3431eee2bec550d","Unmanned aircraft systems (UAS) are essential components in the future air-combat. Due to high dynamics and randomness of the aircrafts, traditional methods are difficult to solve the optimal control strategy. The characteristics of reinforcement learning (RL) match the difficulty of this problem. In this paper, we build an air-combat game environment and train the agent with deep Q-learning (DQN). Despite of increasing probability of loses slightly, our method performs much better than other algorithms in the simulations. Compared with the searching based methods, like Minimax and MCTS, the policy trained by DQN can take specific tactics with a long-term view of the game. Result shows that a large number of simulations and carefully designed features and reward are the essential points of DON. © 2018 IEEE.","air-combat; DQN; RL; UAS","Institute of Electrical and Electronics Engineers Inc."
"Chen P.P., Guitart A., Del Río A.F., Periáñez A.","Customer Lifetime Value in Video Games Using Deep Learning and Parametric Models",2019,"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018",15,"10.1109/BigData.2018.8622151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062630857&doi=10.1109%2fBigData.2018.8622151&partnerID=40&md5=2c41f56faedecafe34d70abd992c9d99","Nowadays, video game developers record every virtual action performed by their players. As each player can remain in the game for years, this results in an exceptionally rich dataset that can be used to understand and predict player behavior. In particular, this information may serve to identify the most valuable players and foresee the amount of money they will spend in in-app purchases during their lifetime. This is crucial in free-to-play games, where up to 50% of the revenue is generated by just around 2% of the players, the so-called whales.To address this challenge, we explore how deep neural networks can be used to predict customer lifetime value in video games, and compare their performance to parametric models such as Pareto/NBD. Our results suggest that convolutional neural network structures are the most efficient in predicting the economic value of individual players. They not only perform better in terms of accuracy, but also scale to big data and significantly reduce computational time, as they can work directly with raw sequential data and thus do not require any feature engineering process. This becomes important when datasets are very large, as is often the case with video game logs.Moreover, convolutional neural networks are particularly well suited to identify potential whales. Such an early identification is of paramount importance for business purposes, as it would allow developers to implement in-game actions aimed at retaining big spenders and maximizing their lifetime, which would ultimately translate into increased revenue. © 2018 IEEE.","behavioral data; big data; deep learning; lifetime value; user behavior; video games","Institute of Electrical and Electronics Engineers Inc."
"Garcia J., Korhonen T.","On runtime and classification performance of the discretize-optimize (DISCO) classification approach",2019,"Performance Evaluation Review",2,"10.1145/3308897.3308965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061559763&doi=10.1145%2f3308897.3308965&partnerID=40&md5=cfd5a6adf2935100647e8324012d961f","Using machine learning in high-speed networks for tasks such as flow classification typically requires either very resource efficient classification approaches, large amounts of computational resources, or specialized hardware. Here we provide a sketch of the discretize-optimize (DISCO) approach which can construct an extremely efficient classifier for low-dimensional problems by combining feature selection, efficient discretization, novel bin placement, and lookup. As feature selection and discretization parameters are crucial, appropriate combinatorial optimization is an important aspect of the approach. A performance evaluation is performed for a YouTube classification task using a cellular traffic data set. The initial evaluation results show that the DISCO approach can move the Pareto boundary in the classification performance versus runtime trade-off by up to an order of magnitude compared to runtime optimized random forest and decision tree classifiers. © is is held held by by author/owner(s). author/owner(s).","Classification; Machine learning; Runtime","Association for Computing Machinery"
"Noriega-Campero A., Garcia-Bulle B., Bakker M.A., Pentland A.S.","Active fairness in algorithmic decision making",2019,"AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society",16,"10.1145/3306618.3314277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070630156&doi=10.1145%2f3306618.3314277&partnerID=40&md5=e8911d3564144e327eaf5b7466b49fd3","Society increasingly relies on machine learning models for automated decision making. Yet, efficiency gains from automation have come paired with concern for algorithmic discrimination that can systematize inequality. Recent work has proposed optimal post-processing methods that randomize classification decisions for a fraction of individuals, in order to achieve fairness measures related to parity in errors and calibration. These methods, however, have raised concern due to the information inefficiency, intra-group unfairness, and Pareto sub-optimality they entail. The present work proposes an alternative active framework for fair classification, where, in deployment, a decision-maker adaptively acquires information according to the needs of different groups or individuals, towards balancing disparities in classification performance. We propose two such methods, where information collection is adapted to group- and individual-level needs respectively. We show on real-world datasets that these can achieve: 1) calibration and single error parity (e.g., equal opportunity); and 2) parity in both false positive and false negative rates (i.e., equal odds). Moreover, we show that by leveraging their additional degree of freedom, active approaches can substantially outperform randomization-based classifiers previously considered optimal, while avoiding limitations such as intra-group unfairness. © 2019 Copyright held by the owner/author(s).","Active feature acquisition; Adaptive inquiry; Algorithmic fairness","Association for Computing Machinery, Inc"
"Gupta R., Gulati N.","Survey of Transportation Problems",2019,"Proceedings of the International Conference on Machine Learning, Big Data, Cloud and Parallel Computing: Trends, Prespectives and Prospects, COMITCon 2019",1,"10.1109/COMITCon.2019.8862242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074144254&doi=10.1109%2fCOMITCon.2019.8862242&partnerID=40&md5=5838beecc1c21a5f9532269eea8efc66","This review paper considered the operational management on the transportation and distribution problem of various things. The main objective is to maximize profit along with minimum cost, time and distance. There is a limitless application of Transportation problem in practical life in the field of operational research. In this review paper we propose an effective improvement of algorithms in the solution procedure to get a prominent initial basic feasible solution for TPs. For obtaining the best solutions various algorithms are used such as NWCR, LCM, Vogel approximation Method, SS Method, Modified Distribution Method, BCM and MM method. The best optimal initial basic solution is obtained by these methods. Specially, TP deals with the advantages of both waterways and land transportation, waterways for transporting heavy goods or goods in bulk amount over long distances, land transportation for fetching and distributing over small to medium distances. To tackle the problem, a heuristic algorithm is chosen and tested experimentally. Final results show that the algorithm is very effective on a set of standard instances, quickly achieving most favorable solutions. © 2019 IEEE.","Heuristic; Lexicographic order; Pareto optima solution","Institute of Electrical and Electronics Engineers Inc."
"Han T., Liu C., Yang W., Jiang D.","A novel adversarial learning framework in deep convolutional neural network for intelligent diagnosis of mechanical faults",2019,"Knowledge-Based Systems",177,"10.1016/j.knosys.2018.12.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058561080&doi=10.1016%2fj.knosys.2018.12.019&partnerID=40&md5=7b4c8d9707bfdd4b3aa6edf3df42c06c","In recent years, deep learning has become an emerging research orientation in the field of intelligent monitoring and fault diagnosis for industry equipment. Generally, the success of supervised deep models is largely attributed to a mass of typically labeled data, while it is often limited in real diagnosis tasks. In addition, the diagnostic model trained with data from limited conditions may generalize poorly for conditions not observed during training. To tackle these challenges, adversarial learning is introduced as a regularization into the convolutional neural network (CNN), and a novel deep adversarial convolutional neural network (DACNN) is accordingly proposed in this paper. By adding an additional discriminative classifier, an adversarial learning framework can be developed to train the convolutional blocks with the split data subsets, leading to a minimax two-player game. This process contributes to making the feature representation robust, boosting the generalization ability of the trained model as well as avoiding overfitting with a small size of labeled samples. The comparison studies with respect to conventional deep models on two fault datasets demonstrate the applicability and superiority of proposed method. © 2018 Elsevier B.V.","Adversarial training; Deep convolutional neural network; Generative adversarial network; Intelligent fault diagnosis; Rotating machinery","Elsevier B.V."
"V. Utkin L.","An imprecise extension of SVM-based machine learning models",2019,"Neurocomputing",28,"10.1016/j.neucom.2018.11.053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057214304&doi=10.1016%2fj.neucom.2018.11.053&partnerID=40&md5=08e59f06b9516e26043d0b74d4f42c71","A general approach for incorporating imprecise prior knowledge and for robustifying the machine learning SVM-based models is proposed in the paper. The main idea underlying the approach is to use a double duality representation in the framework of the minimax strategy of decision making. This idea allows us to get simple extensions of SVMs including additional constraints for optimization variables (the Lagrange multipliers) formalizing the incorporated imprecise information. The approach is applied to regression, binary classification and one-class classification SVM-based problems. Moreover, it is adopted to set-valued or interval-valued training data. For every problem, numerical examples are provided which illustrate how imprecise information may improve the machine learning algorithm performance. © 2018 Elsevier B.V.","Classification; Duality; Imprecise model; Interval-valued data; Machine learning; Regression; Support vector machine","Elsevier B.V."
"Guariniello C., Mockus L., Raz A.K., Delaurentis D.A.","Towards Intelligent Architecting of Aerospace System-of-Systems",2019,"IEEE Aerospace Conference Proceedings",5,"10.1109/AERO.2019.8742173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068345083&doi=10.1109%2fAERO.2019.8742173&partnerID=40&md5=15b4248ad7156aba4a0e959e07a3f651","System-of-Systems (SoS) are composed of large scale independent and complex heterogeneous systems which collaborate to create capabilities not achievable by a single system, for example air transportation system, satellite constellations, and space exploration architectures. Much of the research effort in the field of SoS has focused on the analysis of these complex entities, while there are still major gaps in developing tools for automated synthesis and engineering of SoS that consider all the various aspects in this problem domain. The gap we address in this paper is a mapping of clusters of SoS architecture alternatives, segmented by performance along multiple metrics, to architectural features. Building upon our previous research where we used a SoS Analytic Work Bench in combination with Model-Based Systems Engineering artifacts to perform analysis of aerospace systems, we propose to build a process for intelligent architecting of aerospace SoS. This process discovers and employs pertinent features in a complex design space to effectively meet the user needs, elevating SoS engineering from retrospective architectural analysis to automated synthesis of new architectures. As a first step towards intelligent architecture of aerospace SoS, we propose to utilize Machine Learning techniques to automate the synthesis phase of SoS. Our hypothesis is that a set of holistic metrics of aerospace architectures (cost, performance, robustness, operational risk, average delay, etc.) can be used to characterize a measure of goodness of architectures, with good architectures on a Pareto front of the multi-dimensional space of holistic metrics of interest. Each architecture or cluster may be then mapped to a set of architectural features, with the goal of identifying which features belong to good architectures. Specifically, we propose to utilize non-parametric regression on a set of training architectures (for example, Neural Networks can deal with mixed real and integer variables) to associate each one with a pattern of features. This mapping will allow the automated process to predict what metrics will be expected from SoS architectures with specific features, and therefore to automatically synthesize architectures that exhibit desired characteristics of goodness. For example, for constellations of satellites, a group of good architecture might have medium cost, high resilience, medium robustness, and low risk, and the architectural features to be mapped to each group can include number of satellites, number of components, type of orbit, type of power system, etc. Since the environment constantly evolves, architectures must adapt, and stochastic optimization can be used to switch between architectures with minimal effort. In this work we illustrate the new version of our aerospace SoS analysis and synthesis framework, which includes Machine Learning techniques to support synthesis of SoS architectures. We demonstrate the application of this process on satellite constellations and discuss challenges of this approach and future steps. © 2019 IEEE.",,"IEEE Computer Society"
"Misra K., Schwartz E.M., Abernethy J.","Dynamic online pricing with incomplete information using multiarmed bandit experiments",2019,"Marketing Science",22,"10.1287/mksc.2018.1129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065958398&doi=10.1287%2fmksc.2018.1129&partnerID=40&md5=2ba95ac887854c14bb9b5530280d6c46","Pricing managers at online retailers face a unique challenge. They must decide on real-time prices for a large number of products with incomplete demand information. The manager runs price experiments to learn about each product’s demand curve and the profitmaximizing price. In practice, balanced field price experiments can create high opportunity costs, because a large number of customers are presented with suboptimal prices. In this paper, we propose an alternative dynamic price experimentation policy. The proposed approach extends multiarmed bandit (MAB) algorithms from statistical machine learning to include microeconomic choice theory. Our automated pricing policy solves this MAB problem using a scalable distribution-free algorithm. We prove analytically that our method is asymptotically optimal for any weakly downward sloping demand curve. In a series of MonteCarlo simulations,we showthat the proposed approach performs favorably compared with balanced field experiments and standard methods in dynamic pricing from computer science. In a calibrated simulation based on an existing pricing field experiment, we find that our algorithm can increase profits by 43% during the month of testing and 4% annually. © 2019 INFORMS.","A/b testing; Dynamic pricing; E-commerce; Field experiments; Machine learning; Minimax regret; Multiarmed bandits; Nonparametric econometrics; Online experiments; Partial identification","INFORMS Inst.for Operations Res.and the Management Sciences"
"del Rio-Chanona E.A., Wagner J.L., Ali H., Fiorelli F., Zhang D., Hellgardt K.","Deep learning-based surrogate modeling and optimization for microalgal biofuel production and photobioreactor design",2019,"AIChE Journal",36,"10.1002/aic.16473","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058642194&doi=10.1002%2faic.16473&partnerID=40&md5=e2c974caa75b5c2174fb20ac83edae4a","Identifying optimal photobioreactor configurations and process operating conditions is critical to industrialize microalgae-derived biorenewables. Traditionally, this was addressed by testing numerous design scenarios from integrated physical models coupling computational fluid dynamics and kinetic modeling. However, this approach presents computational intractability and numerical instabilities when simulating large-scale systems, causing time-intensive computing efforts and infeasibility in mathematical optimization. Therefore, we propose an innovative data-driven surrogate modeling framework, which considerably reduces computing time from months to days by exploiting state-of-the-art deep learning technology. The framework built upon a few simulated results from the physical model to learn the sophisticated hydrodynamic and biochemical kinetic mechanisms; then adopts a hybrid stochastic optimization algorithm to explore untested processes and find optimal solutions. Through verification, this framework was demonstrated to have comparable accuracy to the physical model. Moreover, multi-objective optimization was incorporated to generate a Pareto-frontier for decision-making, advancing its applications in complex biosystems modeling and optimization. © 2018 American Institute of Chemical Engineers AIChE J, 65: 915–923, 2019. © 2018 American Institute of Chemical Engineers","convolutional neural network; excreted biofuel; hybrid stochastic optimization; photobioreactor design; surrogate modeling","John Wiley and Sons Inc."
"Babutzka J., Bortz M., Dinges A., Foltin G., Hajnal D., Schultze H., Weiss H.","Machine Learning Supporting Experimental Design for Product Development in the Lab",2019,"Chemie-Ingenieur-Technik",8,"10.1002/cite.201800089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056416394&doi=10.1002%2fcite.201800089&partnerID=40&md5=c1632e587f1ae64a5032d3f88a54e0a0","An interactive decision support framework is presented that assists lab researchers in finding optimal product recipes. Within this framework, an approach for sequential experimental design for black box models in a multicriteria optimization context is introduced. An additional criterion involving the prediction error to design new experiments is used with the goal to get a reliable estimate of the Pareto frontier within a few experimental iterations. The resulting decision support approach accompanies the chemist through the whole workflow and supports the user via interactive, graphical elements. © 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim","Machine learning; Model selection; Multiobjective optimizations; Parameter estimation; Prediction error methods; Sequential experimental design","Wiley-VCH Verlag"
"Jiang P., Li R., Li H.","Multi-objective algorithm for the design of prediction intervals for wind power forecasting model",2019,"Applied Mathematical Modelling",70,"10.1016/j.apm.2018.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055484803&doi=10.1016%2fj.apm.2018.10.019&partnerID=40&md5=e491e4c1855f52aff1247267561b91b1","A composite forecasting framework is designed and implemented successfully to estimate the prediction intervals of wind speed time series simultaneously through machine learning method embedding a newly proposed optimization method (multi-objective salp swarm algorithm). In this study, data pre-process strategy based on feature extraction is served for reducing the fluctuations of wind power generation and select appropriate input forms of wind speed datasets for the sake of improving the overall performance. Besides, fuzzy set theory selection technique is used to determine the best compromise solutions from Pareto front set deriving from the optimization phase. To test the effectiveness of the proposed composite forecasting framework, several case studies based on different time-scale wind speed datasets are conducted. The corresponding results present that the proposed framework significantly outperforms other benchmark methods, and it can provide very satisfactory results in both goals between high coverage and small width. © 2018 Elsevier Inc.","Best compromise solution; Fuzzy set theory; Interval forecasting; Least square support vector machine; Multi-objective salp swarm algorithm","Elsevier Inc."
"Moradi B.","Multi-objective mobile robot path planning problem through learnable evolution model",2019,"Journal of Experimental and Theoretical Artificial Intelligence",6,"10.1080/0952813X.2018.1549107","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057587802&doi=10.1080%2f0952813X.2018.1549107&partnerID=40&md5=5a00aac003acbbaea3862a730fcc2925","A new multi-objective non-Darwinian-type evolutionary computation approach based on learnable evolution model (LEM) is proposed for solving the robot path planning problem. The multi-objective property of this approach is governed by a robust strength Pareto evolutionary algorithm (SPEA) incorporated in the LEM algorithm presented here. Learnable evolution model includes a machine learning method, like the decision trees, that can detect the right directions of the evolution and leads to large improvements in the fitness of the individuals. Several new refiner operators are proposed to improve the objectives of the individuals in the evolutionary process. These objectives are: the path length, the path safety and the path smoothness. A modified integer coding path representation scheme is proposed where the edge-fixing and top-row fixing procedures are performed implicitly. This proposed robot path planning problem solving approach is assessed on eight realistic scenarios in order to verify the performance thereof. Computer simulations reveal that this proposed approach exhibits much higher hypervolume and set coverage in comparison with other similar approaches. The experimental results confirm that the proposed approach performs in the workspaces with a dense set of obstacles in a significant manner. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","learnable evolution model; multi-objective optimisation; path planning; Robotics; strength Pareto evolutionary algorithm","Taylor and Francis Ltd."
"Ahmad A., Shatabda S.","EPAI-NC: Enhanced prediction of adenosine to inosine RNA editing sites using nucleotide compositions",2019,"Analytical Biochemistry",5,"10.1016/j.ab.2019.01.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060336242&doi=10.1016%2fj.ab.2019.01.002&partnerID=40&md5=676cd716ad734e13b9d64d6b6ff8fc50","RNA editing process like Adenosine to Intosine (A-to-I) often influences basic functions like splicing stability and most importantly the translation. Thus knowledge about editing sites is of great importance in molecular biology. With the growth of known editing sites, machine learning or data centric approaches are now being applied to solve this problem of prediction of RNA editing sites. In this paper, we propose EPAI-NC, a novel method for prediction of RNA editing sites. We have used l-mer composition and n-gapped l-mer composition as features and used Pearson Correlation Coefficient to select features according to Pareto Principle. Locally deep support vector machines were used to train the classification model of EPAI-NC. EPAI-NC significantly enhances the prediction accuracy compared to the previous state-of-the-art methods when tested on standard benchmark and independent dataset. © 2019 Elsevier Inc.","Classification; Feature selection; Machine learning; Nucleotide compositions; RNA editing sites; Web application","Academic Press Inc."
"Shi B., Yuan H., Shi R.","Pricing cloud resource based on multi-agent reinforcement learning in the competing environment",2019,"Proceedings - 16th IEEE International Symposium on Parallel and Distributed Processing with Applications, 17th IEEE International Conference on Ubiquitous Computing and Communications, 8th IEEE International Conference on Big Data and Cloud Computing, 11th IEEE International Conference on Social Computing and Networking and 8th IEEE International Conference on Sustainable Computing and Communications, ISPA/IUCC/BDCloud/SocialCom/SustainCom 2018",,"10.1109/BDCloud.2018.00076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063897254&doi=10.1109%2fBDCloud.2018.00076&partnerID=40&md5=0050d8415ba4a76bdb4c572ca4d6250a","Multiple cloud providers compete against each other in order to attract cloud users and make profits in the cloud market. In doing so, each provider needs to charge fees to users in a proper way. In this paper, we analyze how a cloud provider sets price effectively when competing against other cloud providers. The price set by the cloud provider is affected by its opponent's price, and as well as the prices set in the last round. Specifically, we model this problem as a Markov game by considering two cloud providers competing against each other. We then adopt two different solution concepts in game theory, minimax and Nash equilibrium, to solve this problem. Specifically, we use two different multi-agent reinforcement learning algorithms, minimax-Q and Nash-Q, which correspond to those two solution concepts respectively, to design the pricing policies. Furthermore, we improve the Nash-Q learning algorithm by taking into account the probability of each Nash equilibrium happening. Based on this, we run extensive experiments to analyze the effectiveness of minimax-Q and Nash-Q based pricing policies in terms of making long-term profits. We find that the pricing policy based on Nash-Q learning algorithm with selecting Nash equilibrium according to the probability can beat other Nash-Q based pricing polices with selecting Nash equilibrium according to the maximal payoff. However, in the further experimental analysis, we find that minimax-Q based pricing policies can beat all Nash-Q based pricing policies. This is because the minimax solution concept is more suitable in this competing environment. Our experimental results provide useful insights on designing practical pricing policies for competing cloud providers. © 2018 IEEE.","Competing Cloud Providers; Minimax-Q Learning; Nash-Q Learning; Pricing Policy","Institute of Electrical and Electronics Engineers Inc."
"Vaz A.F., Izbicki R., Stern R.B.","Quantification under prior probability shift: The ratio estimator and its extensions",2019,"Journal of Machine Learning Research",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072409593&partnerID=40&md5=5cfa4a8a65768bf0ad00ff50a9a8635e","The quantification problem consists of determining the prevalence of a given label in a target population. However, one often has access to the labels in a sample from the training population but not in the target population. A common assumption in this situation is that of prior probability shift, that is, once the labels are known, the distribution of the features is the same in the training and target populations. In this paper, we derive a new lower bound for the risk of the quantification problem under the prior shift assumption. Complementing this lower bound, we present a new approximately minimax class of estimators, ratio estimators, which generalize several previous proposals in the literature. Using a weaker version of the prior shift assumption, which can be tested, we show that ratio estimators can be used to build confidence intervals for the quantification problem. We also extend the ratio estimator so that it can: (i) incorporate labels from the target population, when they are available and (ii) estimate how the prevalence of positive labels varies according to a function of certain covariates. © 2019 Afonso Fernandes Vaz, Rafael Izbicki and Rafael Bassi Stern.","Data set shift; Domain shift; Prior probability shift; Quantification; Semisupervised learning","Microtome Publishing"
"Demirer R.M., Demirer O.","Early prediction of sepsis from clinical data using artificial intelligence",2019,"2019 Scientific Meeting on Electrical-Electronics and Biomedical Engineering and Computer Science, EBBT 2019",2,"10.1109/EBBT.2019.8741834","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068586194&doi=10.1109%2fEBBT.2019.8741834&partnerID=40&md5=c9b21beb8216c88ac8cb7670272c1c65","Sepsis is a major cause of death in the world. World Health Organization estimates 30 million people developing sepsis and 6 million people die from sepsis each year; an estimated 4.2 million newborns and children are affected. The mortality rate is highest in septic shock in poor and developing countries. Early prediction of sepsis is critical for improving sepsis outcomes. The late prediction of sepsis in non-sepsis patients is a challenging problem. The aim of this study is to develop an artificial intelligence-based early warning and therapeutic decision support system which reduces sepsis-associated hospital mortality. We propose two compatible Boolean switchable Partially Observable Markov Decision Processes (POMDP) under a general risk-sensitive optimization criterion with finite time horizon. It is based on Spectral analysis of unevenly sampled (missing) observations with Demographics, Vital Signs, and Laboratory values for the patient. The policy is a common mixture of sepsis and non-sepsis beliefs on own utility functions which favors to achieve Pareto Optimality from this high dimensional belief space. © 2019 IEEE.","Artificial Intelligence; Decision Support; Deep Learning; Lomb-Scargle Periyodogram; POMDP; Sepsis","Institute of Electrical and Electronics Engineers Inc."
"Kodmelwar M.K., Joshi S.D., Khanna V.","Software estimation using deep learning",2019,"International Journal of Innovative Technology and Exploring Engineering",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067012177&partnerID=40&md5=b416017731a7e263cf9cb3fdab12230e","For any effective project management, estimation stands as a key piece of project methodology. It plays a noteworthy part in project management to execute the orders required. The assessed parameter helps in sharing the resources requisite to finish the project deliverables effectively. The significant parameters that control the software projects are time, prerequisites, individuals, infrastructure/materials and cash, and dangers. This is one cause why making great appraisals of these elements like time and also resources required for a project stands exceptionally basic. The assessed parameter helps in sharing the resources requisite to finish the project deliverables effectively. The significant parameters that control the software projects are time, prerequisites, individuals, infrastructure/materials and cash, and dangers. This is one cause why making great appraisals of these elements like time and also resources required for a project stands exceptionally basic. If the estimation is lesser compared to required then the with the progress of project it lacks the cash & time as well. If over estimated then the chances of wastage of resources. Therefore it is required to estimate correctly to avoid problem in future. © BEIESP.","COCOMO; Differential Evolution (DE); MMRE; MRE; Pareto-Based Differential Evolution (PBDE)","Blue Eyes Intelligence Engineering and Sciences Publication"
"Muggleton S.H., Hocquette C.","Machine Discovery of Comprehensible Strategies for Simple Games Using Meta-interpretive Learning",2019,"New Generation Computing",2,"10.1007/s00354-019-00054-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065030104&doi=10.1007%2fs00354-019-00054-2&partnerID=40&md5=d40c517598f829ac81d0bf29d641f7f0","Recently, world-class human players have been outperformed in a number of complex two-person games (Go, Chess, Checkers) by Deep Reinforcement Learning systems. However, the data efficiency of the learning systems is unclear given that they appear to require far more training games to achieve such performance than any human player might experience in a lifetime. In addition, the resulting learned strategies are not in a form which can be communicated to human players. This contrasts to earlier research in Behavioural Cloning in which single-agent skills were machine learned in a symbolic language, facilitating their being taught to human beings. In this paper, we consider Machine Discovery of human-comprehensible strategies for simple two-person games (Noughts-and-Crosses and Hexapawn). One advantage of considering simple games is that there is a tractable approach to calculating minimax regret. We use these games to compare Cumulative Minimax Regret for variants of both standard and deep reinforcement learning against two variants of a new Meta-interpretive Learning system called MIGO. In our experiments, tested variants of both normal and deep reinforcement learning have consistently worse performance (higher cumulative minimax regret) than both variants of MIGO on Noughts-and-Crosses and Hexapawn. In addition, MIGO’s learned rules are relatively easy to comprehend, and are demonstrated to achieve significant transfer learning in both directions between Noughts-and-Crosses and Hexapawn. © 2019, The Author(s).","Games strategies; Inductive Logic Programming; Reinforcement learning","Springer Tokyo"
"Rawat S., Shen M.H.H.","Application of adversarial networks for 3d structural topology optimization",2019,"SAE Technical Papers",5,"10.4271/2019-01-0829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064620064&doi=10.4271%2f2019-01-0829&partnerID=40&md5=a8a249aa1f01d2a49510552889156a33","Topology optimization is a branch of structural optimization which solves an optimal material distribution problem. The resulting structural topology, for a given set of boundary conditions and constraints, has an optimal performance (e.g. minimum compliance). Conventional 3D topology optimization algorithms achieve quality optimized results; however, it is an extremely computationally intensive task which is, in general, impractical and computationally unachievable for real-world structural optimal design processes. Therefore, the current development of rapid topology optimization technology is experiencing a major drawback. To address the issues, a new approach is presented to utilize the powerful abilities of large deep learning models to replicate this design process for 3D structures. Adversarial models, primarily Wasserstein Generative Adversarial Networks (WGAN), are constructed which consist of 2 deep convolutional neural networks (CNN) namely, a discriminator and a generator. A minimax game is conducted between the generator and the discriminator as part of training where the discriminator maximizes the loss function whereas the generator tries to minimize the loss function of the model. Once trained, the generator from GAN can produce 3D structures in a computationally inexpensive process instantaneously. The corresponding input variables of the new generated structures are evaluated using a trained convolutional neural network. The dataset needed for training is generated using the traditional 3D topology optimization algorithms. Results from the GANs are validated by comparing these optimal structures against the 3D structures generated from the traditional algorithms with the same design settings. The potential issues and future extension of this work are discussed in detail in the article. As illustrated, introducing deep learning into the field of design will remarkably reduce the work time of an iterative design process. © 2019 SAE International. All Rights Reserved.",,"SAE International"
"Fleischhacker A., Lettner G., Schwabeneder D., Auer H.","Portfolio optimization of energy communities to meet reductions in costs and emissions",2019,"Energy",21,"10.1016/j.energy.2019.02.104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062146387&doi=10.1016%2fj.energy.2019.02.104&partnerID=40&md5=c391b93e35cc9411bd903b7d5abdfa0e","Cities are expected to grow further, and energy communities are one promising approach to promote distributed energy resources and implement energy efficiency measures. To understand the motivation of those communities, this work improves two existing open source models with a Pareto Optimization and two objectives: costs and carbon emissions. Clustering algorithms support the improvement of the models' scalability and performance. The methods developed in this work gives stakeholders the tool to calculate the capabilities and restrictions of the local energy system. The models are applied to a case study using data from an Austrian city, Linz. Four scenarios help to understand aspects of the energy community, such as the lock-in effect of existing infrastructure and future developments. The results show that it is possible to reduce both objectives, but the solutions for minimum costs and minimum carbon emissions are contrary to each other. This work quantifies the highest effect of emission reduction by the electrification of the system. It may be concluded, that a steady transformation of the local energy systems is necessary to reach economically sustainable goals. © 2019 Elsevier Ltd","Data clustering; Emission accounting; Energy community; Machine learning; Multi-energy; Open source model; Pareto optimization","Elsevier Ltd"
"Zhou Z., Dohopolski M., Chen L., Chen X., Jiang S., Sher D., Wang J.","Reliable lymph node metastasis prediction in head neck cancer through automated multi-objective model",2019,"2019 IEEE EMBS International Conference on Biomedical and Health Informatics, BHI 2019 - Proceedings",5,"10.1109/BHI.2019.8834658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073003164&doi=10.1109%2fBHI.2019.8834658&partnerID=40&md5=5599055395f687f699bdfdf2911f0a46","Lymph node metastasis (LNM) plays an important role for accurately diagnosing and treating the patients with head neck cancer. Positron emission tomography (PET) and computed tomography (CT) are two primary imaging modalities used for identifying LNM status. However, the uncertainty of LNM may exist especially for reactive or small nodes. Furthermore, identifying the LNM on PET or CT is greatly dependent on the physician's experience. Therefore, developing a reliable and automatic model is essential for accurately identifying LNM. Multi-objective models have shown promising predictive results by considering different objectives such as sensitivity and specificity. However, most multi-objective models need to choose an optimal model manually. In this work, we proposed an automated multi-objective learning model (AutoMO) for predicting LNM reliably. Instead of picking one optimal model, all the Pareto-optimal models with the calculated relative weights are used in AutoMO. Then the evidential reasoning (ER) approach is used for fusing the output probability for obtaining more reliable results than traditional fusion method. We built three models for PET, CT and PETCT and the results showed that PETCT outperformed two single modality based models. The comparative study demonstrated that AutoMO obtained better performance than current available multi-objective and deep learning methods, and more reliable results can be acquired when using ER fusion. © 2019 IEEE.","Automated multi-objective learning (AutoMO); Evidential reasoning; Head neck cancer; Lymph node metastasis; Multi-objective optimization","Institute of Electrical and Electronics Engineers Inc."
"Jamshidi P., Camara J., Schmerl B., Kaestner C., Garlan D.","Machine learning meets quantitative planning: Enabling self-adaptation in autonomous robots",2019,"ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems",21,"10.1109/SEAMS.2019.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071135281&doi=10.1109%2fSEAMS.2019.00015&partnerID=40&md5=0acd3a03b678c9f403a61351d3834e2c","Modern cyber-physical systems (e.g., robotics systems) are typically composed of physical and software components, the characteristics of which are likely to change over time. Assumptions about parts of the system made at design time may not hold at run time, especially when a system is deployed for long periods (e.g., over decades). Self-adaptation is designed to find reconfigurations of systems to handle such run-time inconsistencies. Planners can be used to find and enact optimal reconfigurations in such an evolving context. However, for systems that are highly configurable, such planning becomes intractable due to the size of the adaptation space. To overcome this challenge, in this paper we explore an approach that (a) uses machine learning to find Pareto-optimal configurations without needing to explore every configuration and (b) restricts the search space to such configurations to make planning tractable. We explore this in the context of robot missions that need to consider task timeliness and energy consumption. An independent evaluation shows that our approach results in high-quality adaptation plans in uncertain and adversarial environments. © 2019 IEEE.","artificial intelligence; Machine learning; quantitative planning; robotics systems; self-adaptive systems","IEEE Computer Society"
"Tang H., Sharma M., Cheng W.-T., Veda G., Gehringer D., Knowles M., D'Souza J., Sekar K., Bawaskar N., Pan Y.","Yield learning for complex FinFET defect mechanisms based on volume scan diagnosis results",2019,"ASMC (Advanced Semiconductor Manufacturing Conference) Proceedings",3,"10.1109/ASMC.2019.8791755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071050588&doi=10.1109%2fASMC.2019.8791755&partnerID=40&md5=dfae1ac482c02283dcb7d6159b267b1d","Device complexity is reaching all-time highs with the adoption of high aspect ratio FinFETs created using multi- patterning process technologies. Simultaneously, new product segments such as AI and automotive are being fabricated on such advanced processes. In this dynamic environment, new complex defect modes have challenged manufacturers to ramp and sustain quality and yield at advanced nodes. Process variability of the standard cell introduces new transistor-level defect modes. Meanwhile the cost of traditional failure analysis has continued to skyrocket. How will the industry reduce the defect-rate and ramp yield to meet these aggressive market demands? This article will detail a new breakthrough in the field of scan diagnosis using machine learning. For the first time, cell-internal defects are detected, diagnosed and now resolved with RCD (Root Cause Deconvolution). Experimental FA results will show how RCD is used to build an accurate defect pareto and pick targeted die for FA for faster and cheaper root cause identification. © 2019 IEEE.","Cell aware diagnosis; Root cause identification; Scan diagnosis; Volume diagnosis; Yield analysis","Institute of Electrical and Electronics Engineers Inc."
"Schuermyer C., Palosh S., Babighian P., Pan Y.","Application of Bayesian machine learning to create a low-cost silicon failure mechanism pareto",2019,"ASMC (Advanced Semiconductor Manufacturing Conference) Proceedings",2,"10.1109/ASMC.2019.8791833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070940351&doi=10.1109%2fASMC.2019.8791833&partnerID=40&md5=c923dc290edd04aa3bd3021b14324d16","The increasing challenges with relying on Physical Failure Analysis and inline inspection for ramping the yield are the reason that Volume Scan Diagnostics Analysis (VSDA) has become a mainstream methodology that supplements traditional yield learning. Because scan diagnostics are inherently noisy, the results often require expert knowledge to manually select the location that has the highest likelihood of being correct. In this paper, Failure Mechanism Analysis (FMA) applies the technique of Bayesian Machine Learning in a yield analysis system that can empirically estimate sources of yield loss using physical diagnostic information. © 2019 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Azizan N., Hassibi B.","A Characterization of Stochastic Mirror Descent Algorithms and Their Convergence Properties",2019,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",3,"10.1109/ICASSP.2019.8682271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069005800&doi=10.1109%2fICASSP.2019.8682271&partnerID=40&md5=2aa0de18e6ab7834d1238d5ac8852084","Stochastic mirror descent (SMD) algorithms have recently garnered a great deal of attention in optimization, signal processing, and machine learning. They are similar to stochastic gradient descent (SGD), in that they perform updates along the negative gradient of an instantaneous (or stochastically chosen) loss function. However, rather than update the parameter (or weight) vector directly, they update it in a »mirrored» domain whose transformation is given by the gradient of a strictly convex differentiable potential function. SMD was originally conceived to take advantage of the underlying geometry of the problem as a way to improve the convergence rate over SGD. In this paper, we study SMD, for linear models and convex loss functions, through the lens of H∞ estimation theory and come up with a minimax interpretation of the SMD algorithm which is the counterpart of the H∞-optimality of the SGD algorithm for linear models and quadratic loss. In doing so, we identify a fundamental conservation law that SMD satisfies and use it to study the convergence properties of the algorithm. For constant step size SMD, when the linear model is over-parameterized, we give a deterministic proof of convergence for SMD and show that from any initial point, it converges to the closest point in the space of all parameter vectors that interpolate the data, where closest is in the sense of the Bregman divergence of the potential function. This property is referred to as implicit regularization: with an appropriate choice of the potential function one can guarantee convergence to the minimizer of any desired convex regularizer. For vanishing step size SMD, and in the standard stochastic optimization setting, we give a direct and elementary proof of convergence for SMD to the »true» parameter vector which avoids ergodic averaging or appealing to stochastic differential equations. © 2019 IEEE.","convergence; implicit regularization; minimax optimality; mirror descent; Stochastic gradient descent","Institute of Electrical and Electronics Engineers Inc."
"Shetty P.P., Varsha C.M., Vadone V.D., Sarode S., Pradeep Kumar D.","Customers churn prediction with rfm model and building a recommendation system using semi-supervised learning in retail sector",2019,"International Journal of Recent Technology and Engineering",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067945184&partnerID=40&md5=1ee55e3fc14ba37319a76b240e9058ba","Customer churn or customer attrition occurs when certain customers are no longer loyal to a firm. In retail businesses, the event of churn is said to occur, if a customer's transactions terminates after a certain duration. High churn rates incur humungous losses for the businesses as it is observed that acquiring new buyers is costlier than retaining the current customer base. Hence, for calculating customer churn of companies, they should be able to monitor churn rates. These churn rates give an organization various factors to be considered to determine their customer retention success rates and identify strategies for improvement. Customer churn is predicted using Pareto/NBD model. Once the customers who are likely to churn are predicted, they need to be differentiated based on their previous purchasing history. Natural Language Processing is used to model product categorization. Semi-supervised learning does customer segmentation. This consists of assigning a score by RFM model and segmenting using k-means clustering. The prediction of clusters is then done using algorithms like logistic regression, SVM and SGD classifier. These methods are collectively used to build a suitable recommendation system, which is targeted to make the churn customers who were valuable to the company loyal again, thereby improving the business for retailers. © BEIESP.","NLP (Natural language processing); Pareto NBD(Pareto negative binomial distribution); RFM(Recency-Frequency-Monetary); SGD (Stochastic Gradient Descent); SVM (Support vector machine)","Blue Eyes Intelligence Engineering and Sciences Publication"
"Chugh T., Sindhya K., Hakanen J., Miettinen K.","A survey on handling computationally expensive multiobjective optimization problems with evolutionary algorithms",2019,"Soft Computing",88,"10.1007/s00500-017-2965-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037709518&doi=10.1007%2fs00500-017-2965-0&partnerID=40&md5=31333fb9fe26c74838d6540b750686ef","Evolutionary algorithms are widely used for solving multiobjective optimization problems but are often criticized because of a large number of function evaluations needed. Approximations, especially function approximations, also referred to as surrogates or metamodels are commonly used in the literature to reduce the computation time. This paper presents a survey of 45 different recent algorithms proposed in the literature between 2008 and 2016 to handle computationally expensive multiobjective optimization problems. Several algorithms are discussed based on what kind of an approximation such as problem, function or fitness approximation they use. Most emphasis is given to function approximation-based algorithms. We also compare these algorithms based on different criteria such as metamodeling technique and evolutionary algorithm used, type and dimensions of the problem solved, handling constraints, training time and the type of evolution control. Furthermore, we identify and discuss some promising elements and major issues among algorithms in the literature related to using an approximation and numerical settings used. In addition, we discuss selecting an algorithm to solve a given computationally expensive multiobjective optimization problem based on the dimensions in both objective and decision spaces and the computation budget available. © 2017, Springer-Verlag GmbH Germany, part of Springer Nature.","Computational cost; Machine learning; Metamodel; Multicriteria optimization; Pareto optimality; Response surface approximation; Surrogate","Springer Verlag"
"Lyubchenko A.A., Pacheco J.A., Casado S., Nuñez L.","An Effective Metaheuristic for Bi-objective Feature Selection in Two-Class Classification Problem",2019,"Journal of Physics: Conference Series",,"10.1088/1742-6596/1210/1/012086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065984658&doi=10.1088%2f1742-6596%2f1210%2f1%2f012086&partnerID=40&md5=00c9e4421f7c897ae5f004ab8e5e1244","Feature selection is known as a very useful technique in machine learning practice as it may result in the development of more straightforward models with better accuracy. Traditionally, feature selection is considered as a single-objective problem, however, it can be easily formulated in terms of two objectives. The solving of such problems requires the application of appropriate multi-objective optimization methods that do not always offer equally good solutions even under the same conditions. This paper focuses on the development of a metaheuristic optimization approach for bi-objective feature selection problem in two-class classification. We consider the solving of this problem in terms of minimization of both misclassification error and feature subset size. For solving the considered problem, an adaptation of the Multi-Objective Adaptive Memory Programming (MOAMP) metaheuristic based on the tabu search strategy is proposed. Our MOAMP adaption has been utilized to obtain the sets of most relevant features for two real classification problems with two classes. Finally, using popular Pareto front quality indicators, the obtained results have been compared with the sets of non-dominated solutions derived by the well-known NSGA2 algorithm. The conducted research allows concluding about the ability of the MOAMP adaptation to get a better efficient frontier for the same number of objective function calls. © 2019 IOP Publishing Ltd. All rights reserved.",,"Institute of Physics Publishing"
"Gruber A., Ben-Gal I.","A targeted Bayesian network learning for classification",2019,"Quality Technology and Quantitative Management",2,"10.1080/16843703.2017.1395109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032369681&doi=10.1080%2f16843703.2017.1395109&partnerID=40&md5=441fb3963db9f3069674be78dab598e9","A targeted Bayesian network learning (TBNL) method is proposed to account for a classification objective during the learning stage of the network model. The TBNL approximates the expected conditional probability distribution of the class variable. It effectively manages the trade-off between the classification accuracy and the model complexity by using a discriminative approach, constrained by information theory measurements. The proposed approach also provides a mechanism for maximizing the accuracy via a Pareto frontier over a complexity–accuracy plane, in cases of missing data in the data-sets. A comparative study over a set of classification problems shows the competitiveness of the TBNL mainly with respect to other graphical classifiers. © 2017, © 2017 International Chinese Association of Quantitative Management.","AI; Bayesian classifiers; complexity–accuracy trade-off; information theory; machine learning; target-oriented learning","Taylor and Francis Ltd."
"Duan Z., Liu H., Lv X., Ren Z., Junginger S.","Hybrid position forecasting method for mobile robot transportation in smart indoor environment",2019,"ACM International Conference Proceeding Series",,"10.1145/3335484.3335508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069782861&doi=10.1145%2f3335484.3335508&partnerID=40&md5=6f3ba96cff19dc9df77a2ea384273e3f","Indoor mobile robot position forecasting can improve safety and robustness of the robot navigation systems in indoor environment. In this paper, a novel hybrid computing framework for indoor mobile robot position forecasting is proposed, namely EWT-MOFEPSO-MRMRMI-ORELM. The proposed model consists of three parts, decomposition, feature selection and forecasting. The EWT (Empirical Wavelet Transform) algorithm is utilized to decompose raw series into several more predictable sublayers. For each sublayer, the MRMRMI (Maximum Relevancy Minimum Redundancy Maximum Interaction) model optimized by MOFEPSO (Multi-objective Feasibility Enhanced Particle Swarm Optimization) is applied to generate Pareto set of candidate feature set. The best feature set is selected as the one with minimum forecasting error in validation data. The selected best feature set is used as input of the ORELM (Outlier Robust Extreme Learning Machine) model to generate forecasting value. The ORELM can prevent adverse effect of outlier. Two experiments are carried out to verify the effectiveness of the proposed computing framework. The results indicate that (a) the proposed hybrid computing framework has excellent forecasting performance, (b) The EWT, MOFEPSO-MRMRMI can enhance performance of the ORELM significantly; and (c) the proposed forecasting method can guarantee the safety transportation of mobile robots in smart indoor environment. © 2019 Association for Computing Machinery.","Empirical wavelet transform; Indoor mobile robot navigation; Multi-objective optimization; Outlier robust extreme learning machine","Association for Computing Machinery"
"Jia Y., Zhang Q., Zhang W., Wang X.","CommunityGan: Community detection with generative adversarial nets",2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019",30,"10.1145/3308558.3313564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066881307&doi=10.1145%2f3308558.3313564&partnerID=40&md5=a824dde915cadf78860e1ada4c44c92e","Community detection refers to the task of discovering groups of vertices sharing similar properties or functions so as to understand the network data. With the recent development of deep learning, graph representation learning techniques are also utilized for community detection. However, the communities can only be inferred by applying clustering algorithms based on learned vertex embeddings. These general cluster algorithms like K-means and Gaussian Mixture Model cannot output much overlapped communities, which have been proved to be very common in many real-world networks. In this paper, we propose CommunityGAN, a novel community detection framework that jointly solves overlapping community detection and graph representation learning. First, unlike the embedding of conventional graph representation learning algorithms where the vector entry values have no specific meanings, the embedding of CommunityGAN indicates the membership strength of vertices to communities. Second, a specifically designed Generative Adversarial Net (GAN) is adopted to optimize such embedding. Through the minimax competition between the motif-level generator and discriminator, both of them can alternatively and iteratively boost their performance and finally output a better community structure. Extensive experiments on synthetic data and real-world tasks demonstrate that CommunityGAN achieves substantial community detection performance gains over the state-of-the-art methods. © 2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.","Community Detection; Generative Adversarial Nets; Graph Representation Learning","Association for Computing Machinery, Inc"
"Pantula P.D., Miriyala S.S., Mitra K.","A Chance Constrained Programming Based Multi-Criteria Decision Making under Uncertainty",2019,"2019 5th Indian Control Conference, ICC 2019 - Proceedings",,"10.1109/INDIANCC.2019.8715586","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066616167&doi=10.1109%2fINDIANCC.2019.8715586&partnerID=40&md5=51eb0cf36887eeceb859d232254f6c1b","Multi-criteria decision making under uncertainty is a common practice followed in industries and academia. Among several types of uncertainty handling techniques, Chance Constrained Programming (CCP) is considered as an efficient and tractable approach provided one has accessibility to distribution of the data for uncertain parameters. However, the assumption that the uncertain parameters must follow some well-behaved probability distribution is a myth for most of the practical applications. This paper proposes a methodology to amalgamate machine learning algorithms with CCP and thereby make it data-driven. A novel fuzzy clustering mechanism is implemented to transcript the uncertain space such that the exact regions of uncertainty are identified. Subsequently, density based boundary point detection and Delaunay triangulation based boundary construction enable intelligent Sobol based sampling in these regions for use in CCP. The Fuzzy clustering mechanism used in the proposed method transforms the existing fuzzy C-means technique such that the decision variables are significantly reduced. This enables evolutionary optimizers to obtain better approximations of the uncertain space by identifying the true clusters. A highly nonlinear real life model for continuous casting from steelmaking industries is considered as a case study for testing the efficiency of data based CCP along with a comprehensive comparison between conventional CCP approach using box uncertainty set and proposed methodology. As the resulting CCP problem is multi-objective in nature, the Pareto solutions are obtained by NSGA II. © 2019 IEEE.","Data Driven Chance Constrained Programming; Fuzzy Clustering; Multi-objective Optimization","Institute of Electrical and Electronics Engineers Inc."
"Chouikhi N., Ammar B., Hussain A., Alimi A.M.","Bi-level multi-objective evolution of a Multi-Layered Echo-State Network Autoencoder for data representations",2019,"Neurocomputing",11,"10.1016/j.neucom.2019.03.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063098629&doi=10.1016%2fj.neucom.2019.03.012&partnerID=40&md5=fd1d74ae4e22cc4e93f05af9c6e9cdf8","The Multi-Layered Echo-State Network (ML-ESN) is a recently developed, highly powerful type of recurrent neural network. It has succeeded in dealing with several non-linear benchmark problems. On account of its rich dynamics, ML-ESN is exploited in this paper, for the first time, as a recurrent Autoencoder (ML-ESNAE) to extract new features from original data representations. Further, the challenging and crucial task of optimally determining the ML-ESNAE architecture and training parameters is addressed, in order to extract more efficient features from the data. Traditionally, in a ML-ESN, the number of parameters (hidden neurons, sparsity rates, weights) are randomly chosen and manually altered to achieve a minimum learning error. On one hand, this random setting may not guarantee best generalization results. On the other, it can increase the network's complexity. In this paper, a novel bi-level evolutionary optimization approach is thus proposed for the ML-ESNAE, to deal with these challenges. The first level offers Pareto multi-objective architecture optimization, providing maximum learning accuracy while maintaining a reduced complexity target. Next, every Pareto optimal solution obtained from the first level undergoes a mono-objective weights optimization at the second level. Particle Swarm Optimization (PSO) is used as an evolutionary tool for both levels 1 and 2. An empirical study shows that the evolved ML-ESNAE produces a noticeable improvement in extracting new, more expressive data features from original ones. A number of application case studies, using a range of benchmark datasets, show that the extracted features produce excellent results in terms of classification accuracy. The effectiveness of the evolved ML-ESNAE is demonstrated for both noisy and noise-free data. In conclusion, the evolutionary ML-ESNAE is proposed as a new benchmark for the evolutionary AI and machine learning research community. © 2019 Elsevier B.V.","Architecture optimization; Autoencoder; Data representation; Multi-Layered Echo State Network; Multi-objective optimization; PSO; Weights optimization","Elsevier B.V."
"Wang W.L., Li W.K., Wang Z., Li L.","Opposition-based multi-objective whale optimization algorithm with global grid ranking",2019,"Neurocomputing",34,"10.1016/j.neucom.2019.02.054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062836634&doi=10.1016%2fj.neucom.2019.02.054&partnerID=40&md5=61a3ffabe6c905e7e97a3f0b5b47fb00","Nature-inspired computing has attracted a lot of research effort especially for addressing real-world multi-objective optimization problem (MOP). This paper proposes a new nature-inspired optimization algorithm which is named opposition-based multi-objective whale optimization algorithm with global grid ranking (MOWOA). The proposed approach utilizes several parts to enhance the performance in optimization. First, the efficient evolution process is inherited from the single objective whale optimization algorithm(WOA). Second, opposition-based learning(OBL) is applied into the algorithm. Meanwhile, a novel mechanism called global grid ranking(GGR) which is inspired by grid mechanism has been incorporated into the proposed algorithm. To show the significance of the proposed algorithm, MOWOA is tested on a diverse set of benchmark with a series of well-known evolutionary algorithms and the influence of each individual strategy is also verified through 14 benchmarks. Moreover, the new proposed algorithm is also applied to the simple data clustering problem and a real-world water optimization problem in China. The results demonstrate that MOWOA is not only an algorithm with well performance for bench-mark problems but also expected to have a more wide application in real-world engineering problems. © 2019 Elsevier B.V.","Engineering optimization; Evolutionary algorithms; Global grid ranking; Multi-objective optimization; Opposition-based learning","Elsevier B.V."
"Shi Y., Davaslioglu K., Sagduyu Y.E.","Generative adversarial network for wireless signal spoofing",2019,"WiseML 2019 - Proceedings of the 2019 ACM Workshop on Wireless Security and Machine Learning",30,"10.1145/3324921.3329695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066601953&doi=10.1145%2f3324921.3329695&partnerID=40&md5=ac4a7c10aa654cf59e29b5d10514f198","The paper presents a novel approach of spooing wireless signals by using a general adversarial network (GAN) to generate and transmit synthetic signals that cannot be reliably distinguished from intended signals. It is of paramount importance to authenticate wireless signals at the PHY layer before they proceed through the receiver chain. For that purpose, various waveform, channel, and radio hardware features that are inherent to original wireless signals need to be captured. In the meantime, adversaries become sophisticated with the cognitive radio capability to record, analyze, and manipulate signals before spooing. Building upon deep learning techniques, this paper introduces a spooing attack by an adversary pair of a transmitter and a receiver that assume the generator and discriminator roles in the GAN and play a minimax game to generate the best spooing signals that aim to fool the best trained defense mechanism. The output of this approach is two-fold. From the attacker point of view, a deep learning-based spooing mechanism is trained to potentially fool a defense mechanism such as RF ingerprinting. From the defender point of view, a deep learning-based defense mechanism is trained against potential spooing attacks when an adversary pair of a transmitter and a receiver cooperates. The probability that the spooing signal is misclassiied as the intended signal is measured for random signal, replay, and GAN-based spooing attacks. Results show that the GAN-based spooing attack provides a major increase in the success probability of wireless signal spooing even when a deep learning classiier is used as the defense. © 2019 Association for Computing Machinery.","Adversarial machine learning; Deep learning; General adversarial network (GAN); Spooing attack","Association for Computing Machinery, Inc"
"Jenni S., Favaro P.","On stabilizing generative adversarial training with noise",2019,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",7,"10.1109/CVPR.2019.01242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078797781&doi=10.1109%2fCVPR.2019.01242&partnerID=40&md5=57f7ef96e566e4582137a521cee8548e","We present a novel method and analysis to train generative adversarial networks (GAN) in a stable manner. As shown in recent analysis, training is often undermined by the probability distribution of the data being zero on neighborhoods of the data space. We notice that the distributions of real and generated data should match even when they undergo the same filtering. Therefore, to address the limited support problem we propose to train GANs by using different filtered versions of the real and generated data distributions. In this way, filtering does not prevent the exact matching of the data distribution, while helping training by extending the support of both distributions. As filtering we consider adding samples from an arbitrary distribution to the data, which corresponds to a convolution of the data distribution with the arbitrary one. We also propose to learn the generation of these samples so as to challenge the discriminator in the adversarial training. We show that our approach results in a stable and well-behaved training of even the original minimax GAN formulation. Moreover, our technique can be incorporated in most modern GAN formulations and leads to a consistent improvement on several common datasets. © 2019 IEEE.","Deep Learning; Image and Video Synthesis","IEEE Computer Society"
"Kim M., Sahu P., Gholami B., Pavlovic V.","Unsupervised visual domain adaptation: A deep max-margin gaussian process approach",2019,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",19,"10.1109/CVPR.2019.00451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078772248&doi=10.1109%2fCVPR.2019.00451&partnerID=40&md5=e12f15194bfba74a3f0026f176bfb2e5","For unsupervised domain adaptation, the target domain error can be provably reduced by having a shared input representation that makes the source and target domains indistinguishable from each other. Very recently it has been shown that it is not only critical to match the marginal input distributions, but also align the output class distributions. The latter can be achieved by minimizing the maximum discrepancy of predictors. In this paper, we take this principle further by proposing a more systematic and effective way to achieve hypothesis consistency using Gaussian processes (GP). The GP allows us to induce a hypothesis space of classifiers from the posterior distribution of the latent random functions, turning the learning into a large-margin posterior separation problem, significantly easier to solve than previous approaches based on adversarial minimax optimization. We formulate a learning objective that effectively influences the posterior to minimize the maximum discrepancy. This is shown to be equivalent to maximizing margins and minimizing uncertainty of the class predictions in the target domain. Empirical results demonstrate that our approach leads to state-to-the-art performance superior to existing methods on several challenging benchmarks for domain adaptation. © 2019 IEEE.","Categorization; Deep Learning; Recognition: Detection; Retrieval; Statistical Learning","IEEE Computer Society"
"Li Y., Vasconcelos N.","Repair: Removing representation bias by dataset resampling",2019,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",41,"10.1109/CVPR.2019.00980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077639114&doi=10.1109%2fCVPR.2019.00980&partnerID=40&md5=af61c0cd42a1f29e482c27e19317a154","Modern machine learning datasets can have biases for certain representations that are leveraged by algorithms to achieve high performance without learning to solve the underlying task. This problem is referred to as 'representation bias'. The question of how to reduce the representation biases of a dataset is investigated and a new dataset REPresentAtion bIas Removal (REPAIR) procedure is proposed. This formulates bias minimization as an optimization problem, seeking a weight distribution that penalizes examples easy for a classifier built on a given feature representation. Bias reduction is then equated to maximizing the ratio between the classification loss on the reweighted dataset and the uncertainty of the ground-truth class labels. This is a minimax problem that REPAIR solves by alternatingly updating classifier parameters and dataset resampling weights, using stochastic gradient descent. An experimental set-up is also introduced to measure the bias of any dataset for a given representation, and the impact of this bias on the performance of recognition models. Experiments with synthetic and action recognition data show that dataset REPAIR can significantly reduce representation bias, and lead to improved generalization of models trained on REPAIRed datasets. The tools used for characterizing representation bias, and the proposed dataset REPAIR algorithm, are available at https://github.com/JerryYLi/Dataset-REPAIR/. © 2019 IEEE.","Action Recognition; Datasets and Evaluation; Deep Learning; Representation Learning; Video Analytics","IEEE Computer Society"
"Liu X., Li S., Kong L., Xie W., Jia P., You J., Kumar B.V.K.","Feature-level frankenstein: Eliminating variations for discriminative recognition",2019,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",23,"10.1109/CVPR.2019.00073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077298323&doi=10.1109%2fCVPR.2019.00073&partnerID=40&md5=8828443a7567237bacdfd620122b2010","Recent successes of deep learning-based recognition rely on maintaining the content related to the main-task label. However, how to explicitly dispel the noisy signals for better generalization remains an open issue. We systematically summarize the detrimental factors as task-relevant/irrelevant semantic variations and unspecified latent variation. In this paper, we cast these problems as an adversarial minimax game in the latent space. Specifically, we propose equipping an end-to-end conditional adversarial network with the ability to decompose an input sample into three complementary parts. The discriminative representation inherits the desired invariance property guided by prior knowledge of the task, which is marginally independent to the task-relevant/irrelevant semantic and latent variations. Our proposed framework achieves top performance on a serial of tasks, including digits recognition, lighting, makeup, disguise-tolerant face recognition, and facial attributes recognition. © 2019 IEEE.","Biometrics; Categorization; Recognition: Detection; Retrieval","IEEE Computer Society"
"Li J., Jing M., Lu K., Ding Z., Zhu L., Huang Z.","Leveraging the invariant side of generative zero-shot learning",2019,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",93,"10.1109/CVPR.2019.00758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074866029&doi=10.1109%2fCVPR.2019.00758&partnerID=40&md5=325580ac63664b9ae77997937684e518","Conventional zero-shot learning (ZSL) methods generally learn an embedding, e.g., visual-semantic mapping, to handle the unseen visual samples via an indirect manner. In this paper, we take the advantage of generative adversarial networks (GANs) and propose a novel method, named leveraging invariant side GAN (LisGAN), which can directly generate the unseen features from random noises which are conditioned by the semantic descriptions. Specifically, we train a conditional Wasserstein GANs in which the generator synthesizes fake unseen features from noises and the discriminator distinguishes the fake from real via a minimax game. Considering that one semantic description can correspond to various synthesized visual samples, and the semantic description, figuratively, is the soul of the generated features, we introduce soul samples as the invariant side of generative zero-shot learning in this paper. A soul sample is the meta-representation of one class. It visualizes the most semantically-meaningful aspects of each sample in the same category. We regularize that each generated sample (the varying side of generative ZSL) should be close to at least one soul sample (the invariant side) which has the same class label with it. At the zero-shot recognition stage, we propose to use two classifiers, which are deployed in a cascade way, to achieve a coarse-to-fine result. Experiments on five popular benchmarks verify that our proposed approach can outperform state-of-the-art methods with significant improvements. © 2019 IEEE.","Categorization; Deep Learning; Image and Video Synthesis; Recognition: Detection; Retrieval","IEEE Computer Society"
"Pantula P.D., Mitra K.","An Evolutionary Machine Learning Approach Towards Less Conservative Robust Optimization",2019,"2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings",1,"10.1109/CEC.2019.8790094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071317930&doi=10.1109%2fCEC.2019.8790094&partnerID=40&md5=9dcf52a9342accffe0f3d3c3fff835c5","In the recent era, multi-criteria decision making under uncertainty is gaining importance due to its wide range of applicability. Among several types of uncertainty handling techniques, Robust Optimization (RO) is considered as an efficient and tractable approach provided one has accessibility to data in uncertain regions. However, solutions of RO may actually deviate from actual results in real scenarios, due to conservative sampling. This paper proposes a methodology to amalgamate unsupervised machine learning algorithms with RO which thereby makes it data-driven. A novel evolutionary fuzzy clustering mechanism is implemented to transcript the uncertain space such that the exact regions of uncertainty are identified. Subsequently, density based boundary point detection and Delaunay triangulation based boundary construction enables intelligent Sobol based sampling in these regions for use in RO. Results of two test cases with varying dimensions are presented along with a comprehensive comparison between conventional RO approach using box uncertainty set and proposed methodology. Considered case studies include highly nonlinear real life model for continuous casting from steelmaking industries, where a time expensive multi-objective optimization problem under uncertainty is formulated to resolve the conflict in productivity and energy consumption. Optimal Artificial Neural Network (ANN) surrogate assisted optimization under uncertainty for casting model is performed to obtain solutions in realistic time. The resulting RO problem being multi-objective in nature, the Pareto solutions are obtained by NSGA II. © 2019 IEEE.","ANN surrogate models; Data Driven Robust Optimization; Evolutionary Algorithms; Fuzzy Clustering; Multi objective Optimization","Institute of Electrical and Electronics Engineers Inc."
"Liu Y., Lu H., Cheng S., Shi Y.","An Adaptive Online Parameter Control Algorithm for Particle Swarm Optimization Based on Reinforcement Learning",2019,"2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings",10,"10.1109/CEC.2019.8790035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071308630&doi=10.1109%2fCEC.2019.8790035&partnerID=40&md5=00df3f119f9c80551e665312b60258dc","Parameter control is critical to the performance of any evolutionary algorithm (EA). In this paper, we propose a Q-Learning-based Particle Swarm Optimization (QLPSO) algorithm, which uses the Reinforcement Learning (RL) to train the parameters in Particle Swarm Optimization (PSO) algorithm. The core of the QLPSO algorithm is a three-dimensional Q table which consists of a state plane and an action axis. The state plane includes the state of the particles in both of the decision space and the objective space. The action axis controls the exploration and exploitation of particles by setting different parameters. The Q table can help particles to select actions according to their states. Besides, the Q table should be updated by reward function which is designed according to the performance change of particles and the number of iterations. The main difference between the QLPSO algorithms for single-objective and multi-objective optimization lies in the evaluation of the solution performance. In single-objective optimization, we only compare the fitness values of solutions, while in multi-objective optimization, we need to discuss the dominant relationship between solutions with the help of Pareto front. The performance of QLPSO is tested based on 6 single-objective and 5 multi-objective benchmark functions. The experiment results reveal the competitive performance of QLPSO compared with other algorithms. © 2019 IEEE.","optimization problem; parameter control; particle swarm optimization; reinforcement learning","Institute of Electrical and Electronics Engineers Inc."
"Alves Ribeiro V.H., Reynoso-Meza G.","A study of Pareto-based methods for ensemble pool generation and aggregation",2019,"2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings",2,"10.1109/CEC.2019.8790291","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071299256&doi=10.1109%2fCEC.2019.8790291&partnerID=40&md5=32c0294a67cfc6c4e8fc26d0be0d4ecd","In the field of machine learning, the application of ensemble methods is one of the most successful techniques in order to achieve a good performance in classification tasks. The combination of multiple classifiers is able to achieve better results than a single model, and much effort has been put into applying multi-objective optimisation for improving results with diverse ensemble generation and classifier aggregation. Most recently, dynamic classifier selection and weighting has acquired relevance in the field of multiple-classifier systems. However, to the authors knowledge, there has not yet been a comparison study of Pareto based techniques and dynamic ensemble methods. Thus, this paper proposes a comparison of two ensemble member generation techniques (Pareto-based diverse ensemble generation and bootstrap aggregating) and five aggregation methods (selection of the best classifier, majority voting with all members, majority voting with members selected with multi-objective optimisation, dynamic classifier selection and dynamic classifier weighting), performed on six binary classification benchmark data sets. Results indicate that the combination of bootstrap aggregating and majority voting with multi-objective ensemble member selection achieves the best performance. © 2019 IEEE.","Ensemble methods; multi-objective optimisation; supervised learning.","Institute of Electrical and Electronics Engineers Inc."
"Hu W., Jiang M., Gao X., Tan K.C., Cheung Y.-M.","Solving Dynamic Multi-objective Optimization Problems Using Incremental Support Vector Machine",2019,"2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings",7,"10.1109/CEC.2019.8790005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071288953&doi=10.1109%2fCEC.2019.8790005&partnerID=40&md5=4ed4422702d95643f1ce9cbadaca9a1a","The main feature of the Dynamic Multi-objective Optimization Problems (DMOPs) is that optimization objective functions will change with times or environments. One of the promising approaches for solving the DMOPs is reusing the obtained Pareto optimal set (POS) to train prediction models via machine learning approaches. In this paper, we train an Incremental Support Vector Machine (ISVM) classifier with the past POS, and then the solutions of the DMOP we want to solve at the next moment are filtered through the trained ISVM classifier. A high-quality initial population will be generated by the ISVM classifier, and a variety of different types of population-based dynamic multi-objective optimization algorithms can benefit from the population. To verify this idea, we incorporate the proposed approach into three evolutionary algorithms, the multi-objective particle swarm optimization(MOPSO), Nondominated Sorting Genetic Algorithm II (NSGA-II), and the Regularity Model-based multi-objective estimation of distribution algorithm(RE-MEDA). We employ experimentS to test these algorithms, and experimental results show the effectiveness. © 2019 IEEE.","Dynamic Multi-objective Optimization Problems; Incremental Support Vector Machine; Pareto Optimal Set","Institute of Electrical and Electronics Engineers Inc."
"Dutta P., Saha S.","A Weak Supervision Technique with a Generative Model for Improved Gene Clustering",2019,"2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings",4,"10.1109/CEC.2019.8790052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071288726&doi=10.1109%2fCEC.2019.8790052&partnerID=40&md5=caf3b92c867c98c08d99590d8e89638c","In the field of computational bioinformatics, for tasks such as medical diagnosis or disease gene classification, acquiring class labels is very much essential and costly. Now a days, labelling biomedical data became one of the crucial bottlenecks for developing supervised machine learning systems, as well as deep learning systems. On the contrary, weak supervision sources that generate diverse, semi-accurate or programmatically-generated labels are comparatively cheaper and less time consuming. In this paper, we have proposed a framework for integrating weak supervision sources with a generative model to estimate probabilistic class labels of the gene expression data. Here as the weak supervision source, a multi-objective optimization (MOO) based clustering technique is utilized. The non-dominated solutions of Pareto optimal front are viewed as the weak supervised labels. These weak supervised labels are fed to a generative model, which finally assigns probabilistic class labels to different genes. In this work, we have shown that our proposed generative model based clustering technique attains better Silhouette score (some quality measure of clustering) for three real-life NCBI gene expression data sets than other stateof-the-art methods, without using any labeled data. Finally, the superiority of the proposed method is validated by using a statistical and a biological significance test. © 2019 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Vaddireddy H., San O.","Equation discovery using fast function extraction: A deterministic symbolic regression approach",2019,"Fluids",3,"10.3390/fluids4020111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069767552&doi=10.3390%2ffluids4020111&partnerID=40&md5=901c4063ab436145da115780b76a01cc","Advances in machine learning (ML) coupled with increased computational power have enabled identification of patterns in data extracted from complex systems. ML algorithms are actively being sought in recovering physical models or mathematical equations from data. This is a highly valuable technique where models cannot be built using physical reasoning alone. In this paper, we investigate the application of fast function extraction (FFX), a fast, scalable, deterministic symbolic regression algorithm to recover partial differential equations (PDEs). FFX identifies active bases among a huge set of candidate basis functions and their corresponding coefficients from recorded snapshot data. This approach uses a sparsity-promoting technique from compressive sensing and sparse optimization called pathwise regularized learning to perform feature selection and parameter estimation. Furthermore, it recovers several models of varying complexity (number of basis terms). FFX finally filters out many identified models using non-dominated sorting and forms a Pareto front consisting of optimal models with respect to minimizing complexity and test accuracy. Numerical experiments are carried out to recover several ubiquitous PDEs such as wave and heat equations among linear PDEs and Burgers, Korteweg-de Vries (KdV), and Kawahara equations among higher-order nonlinear PDEs. Additional simulations are conducted on the same PDEs under noisy conditions to test the robustness of the proposed approach. c 2019 by the authors. © 2019 MDPI Multidisciplinary Digital Publishing Institute. All rights reserved.","Compressive sensing; Deterministic symbolic regression; Fast function extraction; Non-dominated sorting; Pathwise regularized learning","MDPI AG"
"Shi J., Song J., Song B., Lu W.F.","Multi-Objective Optimization Design through Machine Learning for Drop-on-Demand Bioprinting",2019,"Engineering",27,"10.1016/j.eng.2018.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064428937&doi=10.1016%2fj.eng.2018.12.009&partnerID=40&md5=72988a7d5174ac8502049d7192d554d3","Drop-on-demand (DOD) bioprinting has been widely used in tissue engineering due to its high-throughput efficiency and cost effectiveness. However, this type of bioprinting involves challenges such as satellite generation, too-large droplet generation, and too-low droplet speed. These challenges reduce the stability and precision of DOD printing, disorder cell arrays, and hence generate further structural errors. In this paper, a multi-objective optimization (MOO) design method for DOD printing parameters through fully connected neural networks (FCNNs) is proposed in order to solve these challenges. The MOO problem comprises two objective functions: to develop the satellite formation model with FCNNs; and to decrease droplet diameter and increase droplet speed. A hybrid multi-subgradient descent bundle method with an adaptive learning rate algorithm (HMSGDBA), which combines the multi-subgradient descent bundle (MSGDB) method with Adam algorithm, is introduced in order to search for the Pareto-optimal set for the MOO problem. The superiority of HMSGDBA is demonstrated through comparative studies with the MSGDB method. The experimental results show that a single droplet can be printed stably and the droplet speed can be increased from 0.88 to 2.08 m·s−1 after optimization with the proposed method. The proposed method can improve both printing precision and stability, and is useful in realizing precise cell arrays and complex biological functions. Furthermore, it can be used to obtain guidelines for the setup of cell-printing experimental platforms. © 2019 Chinese Academy of Engineering","Drop-on-demand printing; Fully connected neural networks; Gradient descent multi-objective optimization; Inkjet printing","Elsevier Ltd"
"Perera A.T.D., Wickramasinghe P.U., Nik V.M., Scartezzini J.-L.","Machine learning methods to assist energy system optimization",2019,"Applied Energy",26,"10.1016/j.apenergy.2019.03.202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063685843&doi=10.1016%2fj.apenergy.2019.03.202&partnerID=40&md5=f269114c2730389ba90e9e8e5273009f","This study evaluates the potential of supervised and transfer learning techniques to assist energy system optimization. A surrogate model is developed with the support of a supervised learning technique (by using artificial neural network) in order to bypass computationally intensive Actual Engineering Model (AEM). Eight different neural network architectures are considered in the process of developing the surrogate model. Subsequently, a hybrid optimization algorithm (HOA) is developed combining Surrogate and AEM in order to speed up the optimization process while maintaining the accuracy. Pareto optimization is conducted considering Net Present Value and Grid Integration level as the objective functions. Transfer learning is used to adapt the surrogate model (trained using supervised learning technique) for different scenarios where solar energy potential, wind speed and energy demand are notably different. Results reveal that the surrogate model can reach to Pareto solutions with a higher accuracy when grid interactions are above 10% (with reasonable differences in the decision space variables). HOA can reach to Pareto solutions (similar to the solutions obtained using AEM) around 17 times faster than AEM. The Surrogate Models developed using Transfer Learning (SMTL) shows a similar capability. SMTL combined with the optimization algorithm can predict Pareto fronts efficiently even when there are significant changes in the initial conditions. Therefore, STML can be used along with the HOA, which reduces the computational time required for energy system optimization by 84%. Such a significant reduction in computational time enables the approach to be used for energy system optimization at regional or national scale. © 2019 Elsevier Ltd","Distributed energy systems; Multi-objective optimization; Supervised learning; Transfer-learning","Elsevier Ltd"
"Tony Cai T., Ma J., Zhang L.","Chime: Clustering of high-dimensional Gaussian mixtures with EM algorithm and its optimality 1",2019,"Annals of Statistics",19,"10.1214/18-AOS1711","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063002117&doi=10.1214%2f18-AOS1711&partnerID=40&md5=a8beae6c3b2287afc0894e613ac05580","Unsupervised learning is an important problem in statistics and machine learning with a wide range of applications. In this paper, we study clustering of high-dimensional Gaussian mixtures and propose a procedure, called CHIME, that is based on the EM algorithm and a direct estimation method for the sparse discriminant vector. Both theoretical and numerical properties of CHIME are investigated. We establish the optimal rate of convergence for the excess misclustering error and show that CHIME is minimax rate optimal. In addition, the optimality of the proposed estimator of the discriminant vector is also established. Simulation studies show that CHIME outperforms the existing methods under a variety of settings. The proposed CHIME procedure is also illustrated in an analysis of a glioblastoma gene expression data set and shown to have superior performance. Clustering of Gaussian mixtures in the conventional low-dimensional setting is also considered. The technical tools developed for the high-dimensional setting are used to establish the optimality of the clustering procedure that is based on the classical EM algorithm. © Institute of Mathematical Statistics, 2019.","EM algorithm; Gaussian mixture model; High-dimensional data; Minimax optimality; Misclustering error; Unsupervised learning","Institute of Mathematical Statistics"
"Mrazek V., Hanif M.A., Vasicek Z., Sekanina L., Shafique M.","AutoAx: An automatic design space exploration and circuit building methodology utilizing libraries of approximate components",2019,"Proceedings - Design Automation Conference",22,"10.1145/3316781.3317781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067831196&doi=10.1145%2f3316781.3317781&partnerID=40&md5=72e56d6337bafe17e7bfd2636044a793","Approximate computing is an emerging paradigm for developing highly energy-efficient computing systems such as various accelerators. In the literature, many libraries of elementary approximate circuits have already been proposed to simplify the design process of approximate accelerators. Because these libraries contain from tens to thousands of approximate implementations for a single arithmetic operation it is intractable to find an optimal combination of approximate circuits in the library even for an application consisting of a few operations. An open problem is ""how to effectively combine circuits from these libraries to construct complex approximate accelerators"". This paper proposes a novel methodology for searching, selecting and combining the most suitable approximate circuits from a set of available libraries to generate an approximate accelerator for a given application. To enable fast design space generation and exploration, the methodology utilizes machine learning techniques to create computational models estimating the overall quality of processing and hardware cost without performing full synthesis at the accelerator level. Using the methodology, we construct hundreds of approximate accelerators (for a Sobel edge detector) showing different but relevant tradeoffs between the quality of processing and hardware cost and identify a corresponding Pareto-frontier. Furthermore, when searching for approximate implementations of a generic Gaussian filter consisting of 17 arithmetic operations, the proposed approach allows us to identify approximately 103 highly relevant implementations from 1023 possible solutions in a few hours, while the exhaustive search would take four months on a high-end processor. © 2019 Copyright held by the owner/author(s).",,"Institute of Electrical and Electronics Engineers Inc."
"Liu G., Primmer J., Zhang Z.","Rapid generation of high-quality RISC-V processors from functional instruction set specifications",2019,"Proceedings - Design Automation Conference",5,"10.1145/3316781.3317890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067827957&doi=10.1145%2f3316781.3317890&partnerID=40&md5=465df5cd27b9f63c3c1dec0ec5ac17db","The increasing popularity of compute acceleration for emerging domains such as artificial intelligence and computer vision has led to the growing need for domain-specific accelerators, often implemented as specialized processors that execute a set of domainoptimized instructions. The ability to rapidly explore (1) various possibilities of the customized instruction set, and (2) its corresponding micro-architectural features is critical to achieve the best quality-of-results (QoRs). However, this ability is frequently hindered by the manual design process at the register transfer level (RTL). Such an RTL-based methodology is often expensive and slow to react when the design specifications change at the instruction-set level and/or micro-architectural level. We address this deficiency in domain-specific processor design with ASSIST, a behavior-level synthesis framework for RISC-V processors. From an untimed functional instruction set description, ASSIST generates a spectrum of RISC-V processors implementing varying micro-architectural design choices, which enables effective tradeoffs between different QoR metrics. We demonstrate the automatic synthesis of more than 60 in-order processor implementations with varying pipeline structures from the RISC-V 32I instruction set, some of which dominate the manually optimized counterparts in the area-performance Pareto frontier. In addition, we propose an autotuning-based approach for optimizing the implementations under a given performance constraint and the technology target. We further present case studies of synthesizing various custom instruction extensions and customized instruction sets for cryptography and machine learning applications. © 2019 Association for Computing Machinery.",,"Institute of Electrical and Electronics Engineers Inc."
"Weiß L.","A simplified model for structural stiffness and crashworthiness optimisation of composite fuselages",2019,"Structural and Multidisciplinary Optimization",2,"10.1007/s00158-018-2166-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058446181&doi=10.1007%2fs00158-018-2166-1&partnerID=40&md5=dd2e8001cf52aaf96e87c440a4e0b498","In this paper, a multi-objective optimisation for the initial design of crashworthy composite structures is proposed. The focus is on the optimisation model with its minimisation of inhomogeneous deformation capability. It promotes homogeneous contribution of all crash elements, as a representative of structural crashworthiness. For the first time, homogeneous contribution has been identified as a metric for crashworthiness of composite structures and been transferred into a mathematical expression. The structural model uses discrete elements for very efficient computation in combination with the genetic algorithm NSGA-II. Clustering as a machine learning technique is applied to the Pareto set of solutions in order to identify representative structural solutions. The approach uses positioning of elements and the shape of the spring characteristic of these elements as variables. The method enables the simultaneous consideration of static and crash loads, which is demonstrated by a case study featuring a composite aircraft fuselage substructure. So far, static and crash loads have been only considered separately, but never at the same time. The novelty of this approach is in the combination of an appropriate simplified modelling technique and a new formulation of the optimisation model. The proposed optimisation is beneficial in improving the crashworthiness of composites, as optimisation of the geometry and material behaviour enables a non-linear response to be obtained in an otherwise brittle material. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","Composite structure; Crashworthiness; Multi-disciplinary; Multi-objective; NSGA-II; System response","Springer Verlag"
"Tang X., Liu C., Zhang X., Ma J., Jiao C., Jiao L.","Remote Sensing Image Retrieval Based on Semi-Supervised Deep Hashing Learning",2019,"International Geoscience and Remote Sensing Symposium (IGARSS)",,"10.1109/IGARSS.2019.8898676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077711488&doi=10.1109%2fIGARSS.2019.8898676&partnerID=40&md5=2d90d2d713d03da717f4433d2b5e8c06","As an useful solution of the approximate nearest neighbor (ANN) search, hashing attracts growing attention in the topic of large-scale image retrieval. In this paper, we propose a semi-supervised deep hashing method based on the adversarial autoencoder (AAE) network for remote sensing image retrieval (RSIR), and we name it SSHAAE. Here, we assume the RS images have been represented by the visual features, and the target of our SSHAAE is mapping those features into the binary codes. First, a hashing layer is adopted to replace the part of original latent layer in AAE. In addition, the classical reconstruction loss function is selected to generate the hash code. Second, two discriminators are added simultaneously to make sure the hash code is bit balanced and the generated label variable is one-hot. Third, we design the hash loss function to guarantee the obtained hash code is discriminative, similarity persevering, and low quantization error. The presented SSHAAE model can be trained by the minimax optimization. The encouraging experimental results counted on a high-resolution RS image archive demonstrate our SSHAAE model is effective to RSIR. © 2019 IEEE.","Hash learning; image retrieval; remote sensing; semi-supervised","Institute of Electrical and Electronics Engineers Inc."
"Draskovic D., Brzakovic M., Nikolic B.","A comparison of machine leaming methods using a two player board game",2019,"EUROCON 2019 - 18th International Conference on Smart Technologies",1,"10.1109/EUROCON.2019.8861927","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074207365&doi=10.1109%2fEUROCON.2019.8861927&partnerID=40&md5=e5f678da7afaecc12a5cca95863d627e","The board games are usually performed by game theory algorithms: minimax and minimax with alpha-beta pruning. Tic-tac-toe (X-O) is the best-known two-player board game. The game tic-tac-toe, based on machine learning algorithms, has been shown in this research. The neural network has been developed and trained to play the game utilizing three implemented agents: an agent based on deep Q-learning, an agent based on policy gradient method and a random agent. The agent can play the game perfectly in the 10-minute training interval, on an average graphics processing unit. © 2019 IEEE.","deep learning; machine learning; neural network; policy gradient method; Q-learning; reinforcement learning","Institute of Electrical and Electronics Engineers Inc."
"Fogel Y., Feder M.","Universal Learning of Individual Data",2019,"IEEE International Symposium on Information Theory - Proceedings",1,"10.1109/ISIT.2019.8849222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073170296&doi=10.1109%2fISIT.2019.8849222&partnerID=40&md5=03fe2be677513744d73e284d745bd6a3","Universal supervised learning of individual data is considered from an information theoretic point of view in the standard supervised 'batch' learning where prediction is done on a test sample once the entire training data is observed. In this individual setting the features and labels, both in the training and the test, are specific individual, deterministic quantities. Prediction loss is naturally measured by the log-loss. The presented results provide a minimax universal learning scheme, termed the Predictive Normalized Maximum Likelihood (pNML) that competes with a 'genie' (or reference) that knows the true test label. In addition, a pointwise learnability measure associated with the pNML, for the specific training and test, is provided. This measure may also indicate the performance of the commonly used Empirical Risk Minimizer (ERM) learner. © 2019 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Cai L., Barneche A.-M., Herbout A., Foo C.S., Lin J., Chandrasekhar V.R., Sabry Aly M.M.","TEA-DNN: the Quest for Time-Energy-Accuracy Co-optimized Deep Neural Networks",2019,"Proceedings of the International Symposium on Low Power Electronics and Design",6,"10.1109/ISLPED.2019.8824934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072658759&doi=10.1109%2fISLPED.2019.8824934&partnerID=40&md5=26e188a7c4ca80a76e8719c02cf255e5","Embedded deep learning platforms have witnessed two simultaneous improvements. First, the accuracy of convolutional neural networks (CNNs) has been significantly improved through the use of automated neural-architecture search (NAS) algorithms to determine CNN structure. Second, there has been increasing interest in developing hardware accelerators for CNNs that provide improved inference performance and energy consumption compared to GPUs. Such embedded deep learning platforms differ in the amount of compute resources and memory-access bandwidth, which would affect performance and energy consumption of CNNs. It is therefore critical to consider the available hardware resources in the network architecture search. To this end, we introduce TEA-DNN, a NAS algorithm targeting multi-objective optimization of execution time, energy consumption, and classification accuracy of CNN workloads on embedded architectures. TEA-DNN leverages energy and execution time measurements on embedded hardware when exploring the Pareto-optimal curves across accuracy, execution time, and energy consumption and does not require additional effort to model the underlying hardware. We apply TEA-DNN for image classification on actual embedded platforms (NVIDIA Jetson TX2 and Intel Movidius Neural Compute Stick). We highlight the Pareto-optimal operating points that emphasize the necessity to explicitly consider hardware characteristics in the search process. To the best of our knowledge, this is the most comprehensive study of Pareto-optimal models across a range of hardware platforms using actual measurements on hardware to obtain objective values. © 2019 IEEE.","hardware constraints; multi-objective optimization; Neural architecture search","Institute of Electrical and Electronics Engineers Inc."
"Lourenço N., Afacan E., Martins R., Passos F., Canelas A., Póvoa R., Horta N., Dundar G.","Using Polynomial Regression and Artificial Neural Networks for Reusable Analog IC Sizing",2019,"SMACD 2019 - 16th International Conference on Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design, Proceedings",11,"10.1109/SMACD.2019.8795282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071527328&doi=10.1109%2fSMACD.2019.8795282&partnerID=40&md5=07b7615f7bbb63b915e124a754acb8fc","In this paper, the use of machine learning techniques to repurpose already available Pareto optimal fronts of analog integrated circuit blocks for new contexts (loads, supply voltage, etc.) is explored. Data from previously sized circuits is used to train models that predict both circuit performance under the new context and the corresponding device sizes. A two-model chain is proposed, where, in the first layer, a multivariate polynomial regression estimates the performance tradeoffs. The output of this performance model is then used as input of an artificial neural network that predicts the device sizing that corresponds to that performance. Moreover, the models are trained with optimized sizing solutions, leading almost instantly to predicted solutions that are near optimal for the new context. The proposed methodology was integrated into a new framework and tested against a real circuit topology, with promising results. The model was able to predict wider and, in some cases, better, performance tradeoff, when compared to independent optimization runs for the same context, despite requiring 400 times fewer circuit simulations. © 2019 IEEE.","Analog IC Sizing; Artificial Neural Networks; Data Mining; Deep Learning; Retargeting","Institute of Electrical and Electronics Engineers Inc."
"Echtenbruck P., Emmerich M., Naujoks B.","A Multiobjective Approach to Classification in Drug Discovery",2019,"2019 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology, CIBCB 2019",3,"10.1109/CIBCB.2019.8791463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071423617&doi=10.1109%2fCIBCB.2019.8791463&partnerID=40&md5=2299101f8c232f843373f543d0b863a4","Classification based on machine learning algorithms is a widely used technique in contemporary in silico methods for drug discovery. However, typically the performance of the classification tool is evaluated based on a scalar performance score and essential information, such as the balance between false positive rates (FPRs)and false negative rates (FNRs)is not directly assessed. Moreover, there might be a large number of molecular features that are not relevant for the classification task and merely slow down the computations or add noise to the learning process. In this paper we adopt an approach that previously was used for the classification of text messages (spam/no-spam)to the classification of drug compounds (active/inactive). By considering the minimization of the classification costs (FPR, FNR)and the minimization of the number of features as separate optimization tasks, we demonstrate that it is possible to develop a more informative and versatile tool for drug discovery. We show, how to derive and evaluate 2-D and 3-D Pareto fronts for the classification of small compounds in active and non-active (similar studies could be conducted for toxic/non-toxic classification, and on other chemically relevant properties). We demonstrate the applicability of the method on a small data set for bio-activity prediction of ligands. © 2019 IEEE.","Bioactivity Prediction; Hyperparameter Tuning; In-Silico Drug Discovery; Machine Learning; Multiobjective Optimization","Institute of Electrical and Electronics Engineers Inc."
"Mizrachi E., Schwartz R., Spoerhase J., Uniyal S.","A tight approximation for submodular maximization with mixed packing and covering constraints",2019,"Leibniz International Proceedings in Informatics, LIPIcs",,"10.4230/LIPIcs.ICALP.2019.85","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069160728&doi=10.4230%2fLIPIcs.ICALP.2019.85&partnerID=40&md5=c354b2506c3fc9656f656383f55270cc","Motivated by applications in machine learning, such as subset selection and data summarization, we consider the problem of maximizing a monotone submodular function subject to mixed packing and covering constraints. We present a tight approximation algorithm that for any constant ε &gt; 0 achieves a guarantee of 1 − 1/e − ε while violating only the covering constraints by a multiplicative factor of 1 − ε. Our algorithm is based on a novel enumeration method, which unlike previously known enumeration techniques, can handle both packing and covering constraints. We extend the above main result by additionally handling a matroid independence constraint as well as finding (approximate) pareto set optimal solutions when multiple submodular objectives are present. Finally, we propose a novel and purely combinatorial dynamic programming approach. While this approach does not give tight bounds it yields deterministic and in some special cases also considerably faster algorithms. For example, for the well-studied special case of only packing constraints (Kulik et al. [Math. Oper. Res. '13] and Chekuri et al. [FOCS '10]), we are able to present the first deterministic non-trivial approximation algorithm. We believe our new combinatorial approach might be of independent interest. © Eyal Mizrachi, Roy Schwartz, Joachim Spoerhase, and Sumedha Uniyal; licensed under Creative Commons License CC-BY","Approximation algorithm; Covering; Packing; Submodular function","Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing"
"Venkatanareshbabu K., Nisheel S., Sakthivel R., Muralitharan K.","Novel elegant fuzzy genetic algorithms in classification problems",2019,"Soft Computing",1,"10.1007/s00500-018-3216-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046406347&doi=10.1007%2fs00500-018-3216-8&partnerID=40&md5=f3d9dff03f8f8045cf5ffde2a0d9dab3","In this paper, we propose three novel algorithms such as Novel genetic algorithm complex-valued backpropagation neural network (GA-CVBNN), Novel elegant fuzzy genetic algorithm (EFGA) and elegant fuzzy genetic algorithm-based complex-valued backpropagation neural network (EFGA-CVBNN) for classification of accuracy in datasets. In GA-CVBNN, classical Genetic Algorithm has been used for selecting appropriate initial weights for CVBNN. The EFGA is developed to resolve the drawback of classical GA by employing fuzzy logic to control parameters and selective pressure of GA. The EFGA uses a Min-Heap data structure and Pareto principle to improve the classical genetic algorithm. The EFGA-CVBNN resolves the drawbacks of classical CVBNN by employing EFGA at the time of initial weight selection. From the simulation result, the GA-CVBNN performs better than existing CVBNN and it is not efficient. To enhance the performance of GA-CVBNN, we have developed EFGA-CVBNN. Experimental results on various synthetic datasets and benchmark datasets taken from UCI machine learning repository shows that EFGA-CVBNN outperforms PSO-CVBNN in terms of classification accuracy and time. Statistical t test has been used to validate the obtained results. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","Classification; Complex number; Fuzzy logic; Genetic algorithm; Neural network; Optimization","Springer Verlag"
"Chugh T., Kratky T., Miettinen K., Jin Y., Makonen P.","Multiobjective shape design in a ventilation system with a preference-driven surrogate-assisted evolutionary algorithm",2019,"GECCO 2019 - Proceedings of the 2019 Genetic and Evolutionary Computation Conference",2,"10.1145/3321707.3321745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072314649&doi=10.1145%2f3321707.3321745&partnerID=40&md5=83e733ac7da38ba92f5f28acd5e2ed1d","We formulate and solve a real-world shape design optimization problem of an air intake ventilation system in a tractor cabin by using a preference-based surrogate-assisted evolutionary multiobjective optimization algorithm. We are motivated by practical applicability and focus on two main challenges faced by practitioners in industry: 1) meaningful formulation of the optimization problem reflecting the needs of a decision maker and 2) finding a desirable solution based on a decision maker's preferences when solving a problem with computationally expensive function evaluations. For the first challenge, we describe the procedure of modelling a component in the air intake ventilation system with commercial simulation tools. The problem to be solved involves time consuming computational fluid dynamics simulations. Therefore, for the second challenge, we extend a recently proposed Kriging-assisted evolutionary algorithm K-RVEA to incorporate a decision maker's preferences. Our numerical results indicate efficiency in using the computing resources available and the solutions obtained reflect the decision maker's preferences well. Actually, two of the solutions dominate the baseline design (the design provided by the decision maker before the optimization process). The decision maker was satisfied with the results and eventually selected one as the final solution. © 2019 Association for Computing Machinery.","Computational cost; Evolutionary multiobjective optimization; Machine learning; Metamodel; Multiple criteria decision making; Optimal shape design; Pareto optimality; Preference information","Association for Computing Machinery, Inc"
"Lu S., Dou Z., Xu J., Nie J.-Y., Wen J.-R.","PSGAN: A minimax game for personalized search with limited and noisy click data",2019,"SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval",22,"10.1145/3331184.3331218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073774150&doi=10.1145%2f3331184.3331218&partnerID=40&md5=df2fb34cbcf1e73f109257d6f9d9a8e4","Personalized search aims to adapt document ranking to user's personal interests. Traditionally, this is done by extracting click and topical features from historical data in order to construct a user profile. In recent years, deep learning has been successfully used in personalized search due to its ability of automatic feature learning. However, the small amount of noisy personal data poses challenges to deep learning models to learn the personalized classification boundary between relevant and irrelevant results. In this paper, we propose PSGAN, a Generative Adversarial Network (GAN) framework for personalized search. By means of adversarial training, we enforce the model to pay more attention to training data that are difficult to distinguish. We use the discriminator to evaluate personalized relevance of documents and use the generator to learn the distribution of relevant documents. Two alternative ways to construct the generator in the framework are tested: based on the current query or based on a set of generated queries. Experiments on data from a commercial search engine show that our models can yield significant improvements over state-of-the-art models. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Generative adversarial network; Personalized web search","Association for Computing Machinery, Inc"
"Dwivedi P.K., Tripathi S.P.","An improved fuzzy classification system for financial credit decision using multi-objective evolutionary optimization",2019,"International Journal of Engineering and Advanced Technology",,"10.35940/ijeat.F9136.088619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072078666&doi=10.35940%2fijeat.F9136.088619&partnerID=40&md5=35937bf94c9872e9e2c7fccd575fb975","In fuzzy classification system, accuracy has been gained at the cost of interpretability and vice versa. This situation is known as Interpretability-Accuracy Trade-off. To handle this trade-off between accuracy and interpretability the evolutionary algorithms (EAs) are often used to optimize the performance of the fuzzy classification system. From the last two decades, several multi-objective evolutionary systems have been designed and successfully implemented in several fields for finding multiple solutions at a single run. In Financial Decision making concerning Credit Allocation, Classification is a significant component to obtain credit scores and predict bankruptcy. A fuzzy classification system for the financial credit decision has been designed and find out the Accuracy and Interpretability parameters for applying various MOEAs to get the pareto optimal solution resulting in to improvement in the performance of the proposed system. The proposed model implemented on standard benchmark financial credit allocation datasets i.e., German Credit Approval system available from the UCI repository of machine learning databases (http://archive.ics.uci.edu/ml) and using the open source tool MOEA framework (http://www.moeaframework.org). The experimental analysis highlights that the NSGA-III works efficiently for financial credit approval system and improves the performance by making a balanced trade-off between accuracy and interpretability. © BEIESP.","Evolutionary algorithm; Fuzzy classifier; Fuzzy rules; I-A Trade-off; MOEA, etc; Multi-objective","Blue Eyes Intelligence Engineering and Sciences Publication"
"Tang K., Su Z., Zhang J., Cui L., Jiang W., Luo X., Sun X.","Bayesian rank penalization",2019,"Neural Networks",3,"10.1016/j.neunet.2019.04.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065774261&doi=10.1016%2fj.neunet.2019.04.018&partnerID=40&md5=6ca50af2ea62a158d24ba7898b3636f3","Rank minimization is a key component of many computer vision and machine learning methods, including robust principal component analysis (RPCA) and low-rank representations (LRR). However, usual methods rely on optimization to produce a point estimate without characterizing uncertainty in this estimate, and also face difficulties in tuning parameter choice. Both of these limitations are potentially overcome with Bayesian methods, but there is currently a lack of general purpose Bayesian approaches for rank penalization. We address this gap using a positive generalized double Pareto prior, illustrating the approach in RPCA and LRR. Posterior computation relies on hybrid Gibbs sampling and geodesic Monte Carlo algorithms. We assess performance in simulation examples, and benchmark data sets. © 2019 Elsevier Ltd","Bayesian model; Generalized double Pareto; Low-rank; LRR; RPCA","Elsevier Ltd"
"Ge H., Zhao M., Sun L., Wang Z., Tan G., Zhang Q., Philip Chen C.L.","A Many-Objective Evolutionary Algorithm with Two Interacting Processes: Cascade Clustering and Reference Point Incremental Learning",2019,"IEEE Transactions on Evolutionary Computation",20,"10.1109/TEVC.2018.2874465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054500071&doi=10.1109%2fTEVC.2018.2874465&partnerID=40&md5=57b9f603762b1792a2fd4e12acb05b16","Researches have shown difficulties in obtaining proximity while maintaining diversity for many-objective optimization problems. Complexities of the true Pareto front pose challenges for the reference vector-based algorithms for their insufficient adaptability to the diverse characteristics with no priori. This paper proposes a many-objective optimization algorithm with two interacting processes: cascade clustering and reference point incremental learning (CLIA). In the population selection process based on cascade clustering (CC), using the reference vectors provided by the process based on incremental learning, the nondominated and the dominated individuals are clustered and sorted with different manners in a cascade style and are selected by round-robin for better proximity and diversity. In the reference vector adaptation process based on reference point incremental learning, using the feedbacks from the process based on CC, proper distribution of reference points is gradually obtained by incremental learning. Experimental studies on several benchmark problems show that CLIA is competitive compared with the state-of-the-art algorithms and has impressive efficiency and versatility using only the interactions between the two processes without incurring extra evaluations. © 1997-2012 IEEE.","Clustering; incremental machine learning; interacting processes; many-objective optimization; reference vector","Institute of Electrical and Electronics Engineers Inc."
"Sun J., Zhang H., Zhou A., Zhang Q., Zhang K., Tu Z., Ye K.","Learning from a Stream of Nonstationary and Dependent Data in Multiobjective Evolutionary Optimization",2019,"IEEE Transactions on Evolutionary Computation",15,"10.1109/TEVC.2018.2865495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051671025&doi=10.1109%2fTEVC.2018.2865495&partnerID=40&md5=0da034b12e5117bd34c3dddc77f1399c","Combining machine learning techniques has shown great potentials in evolutionary optimization since the domain knowledge of an optimization problem, if well learned, can be a great help for creating high-quality solutions. However, existing learning-based multiobjective evolutionary algorithms (MOEAs) spend too much computational overhead on learning. To address this problem, we propose a learning-based MOEA where an online learning algorithm is embedded within the evolutionary search procedure. The online learning algorithm takes the stream of sequentially generated solutions along the evolution as its training data. It is noted that the stream of solutions are temporal, dependent, nonstationary, and nonstatic. These data characteristics make existing online learning algorithm not suitable for the evolution data. We hence modify an existing online agglomerative clustering algorithm to accommodate these characteristics. The modified online clustering algorithm is applied to adaptively discover the structure of the Pareto optimal set; and the learned structure is used to guide new solution creation. Experimental results have shown significant improvement over four state-of-the-art MOEAs on a variety of benchmark problems. © 1997-2012 IEEE.","Evolutionary algorithms (EAs); machine learning (ML); multiobjective optimization; online agglomerative clustering","Institute of Electrical and Electronics Engineers Inc."
"Saeed S., Ong H.C.","A bi-objective hybrid algorithm for the classification of imbalanced noisy and borderline data sets",2019,"Pattern Analysis and Applications",4,"10.1007/s10044-018-0693-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044191904&doi=10.1007%2fs10044-018-0693-4&partnerID=40&md5=9765557a8456b88032043b62a14f3094","Classification of imbalanced data sets is one of the significant problems of machine learning and data mining. Traditional classifiers usually produced suboptimal results for imbalanced data sets. This study proposed an idea of using a newly proposed bi-objective hybrid algorithm for the given classification task of binary imbalanced noisy and borderline data sets. The bi-objective hybrid algorithm was based on the hybridization of two metaheuristics, namely cuckoo search and covariance matrix adaptation evolution strategy. The validation of this proposed hybrid algorithm was confirmed in terms of the Pareto fronts. Thereafter, this algorithm was used in a methodology proposed for the classification task of the binary imbalanced data sets. The proposed methodology was based on an idea of estimating the probabilities from both classes (majority and minority) of a data set, using normal distribution. Optimization of parameters of the normal distribution was done with the help of the proposed algorithm. Different data sets (simulated, noisy borderline and real) were used. Four well-known classifiers with a preprocessing algorithm were cast-off for the comparison purpose. Performances of all classifiers were evaluated using three evaluation measures, sensitivity, G mean and F measure. A promising performance of proposed methodology was observed. © 2018, Springer-Verlag London Ltd., part of Springer Nature.","Bi-objective hybrid algorithm; Classification; Data mining; Imbalance data sets; Metaheuristics","Springer London"
"Fan K., Cosenza B., Juurlink B.","Predictable GPUs frequency scaling for energy and performance",2019,"ACM International Conference Proceeding Series",12,"10.1145/3337821.3337833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071140452&doi=10.1145%2f3337821.3337833&partnerID=40&md5=2b36145c0650171272a8a83457cd5157","Dynamic voltage and frequency scaling (DVFS) is an important solution to balance performance and energy consumption, and hardware vendors provide management libraries that allow the programmer to change both memory and core frequencies. The possibility to manually set these frequencies is a great opportunity for application tuning, which can focus on the best application-dependent setting. However, this task is not straightforward because of the large set of possible configurations and because of the multi-objective nature of the problem, which minimizes energy consumption and maximizes performance. This paper proposes a method to predict the best core and memory frequency configurations on GPUs for an input OpenCL kernel. Our modeling approach, based on machine learning, first predicts speedup and normalized energy over the default frequency configuration. Then, it combines the two models into a multi-objective one that predicts a Pareto-set of frequency configurations. The approach uses static code features, is built on a set of carefully designed micro-benchmarks, and can predict the best frequency settings of a new kernel without executing it. Test results show that our modeling approach is very accurate on predicting extrema points and Pareto set for ten out of twelve test benchmarks, and discover frequency configurations that dominate the default configuration in either energy or performance. © 2019 ACM.","Energy efficiency; Frequency scaling; GPUs; Modeling","Association for Computing Machinery"
"González Niño C., Kapur N., King M.-F., de Boer G., Blacker A.J., Bourne R., Thompson H.","Computational fluid dynamic enabled design optimisation of miniaturised continuous oscillatory baffled reactors in chemical processing",2019,"International Journal of Computational Fluid Dynamics",3,"10.1080/10618562.2019.1683169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074695371&doi=10.1080%2f10618562.2019.1683169&partnerID=40&md5=56a889973988fedf9b5fae70caed9556","The first CFD-enabled multi-objective design optimisation methodology for continuous oscillatory baffled reactors (COBRs), used for flow chemistry-based process development, is described, where performance is quantified in terms of two metrics: a mixing efficiency index and the variance of the residence time distribution. The effect of cross-validation approaches on the surrogate modelling of these performance metrics is examined in detail and the resultant surrogate models used to demonstrate the influence of key design variables. Pareto fronts of non-dominated solutions are presented to illustrate the available design compromises for COBR performance and it is shown that these can give a narrow Residence Time Distribution and good mixing within the final design. The novel feature of offset baffles within a channel, explored here for the first time, is identified as a key parameter in improving the performance of COBRs. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Continuous oscillatory baffled reactor; machine learning; multi-objective optimisation; surrogate modelling","Taylor and Francis Ltd."
"Liu Z., Wu C.T., Koishi M.","Transfer learning of deep material network for seamless structure–property predictions",2019,"Computational Mechanics",15,"10.1007/s00466-019-01704-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064242281&doi=10.1007%2fs00466-019-01704-4&partnerID=40&md5=123f5d7dabfeea3475c85d068434355d","Modern materials design requires reliable and consistent structure–property relationships. The paper addresses the need through transfer learning of deep material network (DMN). In the proposed learning strategy, we store the knowledge of a pre-trained network and reuse it to generate the initial structure for a new material via a naive approach. Significant improvements in the training accuracy and learning convergence are attained. Since all the databases share the same base network structure, their fitting parameters can be interpolated to seamlessly create intermediate databases. The new transferred models are shown to outperform the analytical micromechanics methods in predicting the volume fraction effects. We then apply the unified DMN databases to the design of failure properties, where the failure criteria are defined upon the distribution of microscale plastic strains. The Pareto frontier of toughness and ultimate tensile strength is extracted from a large-scale design space enabled by the efficiency of DMN extrapolation. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Failure analysis; Machine learning; Materials design; Micromechanics; Multiscale modeling; Nonlinear plasticity","Springer Verlag"
"Hu R., Huang Q., Chang S., Wang H., He J.","The MBPEP: a deep ensemble pruning algorithm providing high quality uncertainty prediction",2019,"Applied Intelligence",7,"10.1007/s10489-019-01421-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061740284&doi=10.1007%2fs10489-019-01421-8&partnerID=40&md5=d0945d4607d728766865e35ad8af64ce","Machine learning algorithms have been effectively applied into various real world tasks. However, it is difficult to provide high-quality machine learning solutions to accommodate an unknown distribution of input datasets; this difficulty is called the uncertainty prediction problems. In this paper, a margin-based Pareto deep ensemble pruning (MBPEP) model is proposed. It achieves the high-quality uncertainty estimation with a small value of the prediction interval width (MPIW) and a high confidence of prediction interval coverage probability (PICP) by using deep ensemble networks. In addition to these networks, unique loss functions are proposed, and these functions make the sub-learners available for standard gradient descent learning. Furthermore, the margin criterion fine-tuning-based Pareto pruning method is introduced to optimize the ensembles. Several experiments including predicting uncertainties of classification and regression are conducted to analyze the performance of MBPEP. The experimental results show that MBPEP achieves a small interval width and a low learning error with an optimal number of ensembles. For the real-world problems, MBPEP performs well on input datasets with unknown distributions datasets incomings and improves learning performance on a multi task problem when compared to that of each single model. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Ensemble pruning; Loss function; Margin criterion tuning; Uncertainty prediction","Springer New York LLC"
"Ragasa E.J., O'brien C.J., Hennig R.G., Foiles S.M., Phillpot S.R.","Multi-objective optimization of interatomic potentials with application to MgO",2019,"Modelling and Simulation in Materials Science and Engineering",5,"10.1088/1361-651X/ab28d9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072625760&doi=10.1088%2f1361-651X%2fab28d9&partnerID=40&md5=453c19ddf9587be92e4dfde7542bcd08","The parameterization of a functional form for an interatomic potential is treated as a problem in multi-objective optimization. An autonomous, machine-learning approach based on the identification of the Pareto hypersurface of errors in predicted properties allows the development of an ensemble of parameterizations with high materials fidelity and robustness. The efficacy of this approach is illustrated for the simple example of a Buckingham potential for MgO. This approach also provides a strong foundation for uncertainty quantification of potential parameterizations. © Not subject to copyright in the USA. Contribution of National Technology and Engineering Solutions of Sandia..","atomic-level simulation; interatomic potential; Pareto optimization; rational design","Institute of Physics Publishing"
"Chien J.-T., Lyu Y.-Y.","Partially adversarial learning and adaptation",2019,"European Signal Processing Conference",5,"10.23919/EUSIPCO.2019.8903147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075601778&doi=10.23919%2fEUSIPCO.2019.8903147&partnerID=40&md5=ef51d23fb39bfe613ac5160c5a953859","An image classification system for a specific target domain is usually trained with initialization from a source domain given with a large number of classes, particularly in an application of image recognition. The classes in target domain are usually seen as a subset in source domain. Partial domain adaptation aims to tackle this generalization issue where no labeled data are provided in target domain. This paper presents an adversarial learning for partial domain adaptation where a symmetric metric based on the Wasserstein distance is adopted in an adversarial learning objective. We build a Wasserstein partial transfer network where the Wasserstein adversarial objective is jointly optimized to partially transfer the relevance knowledge from source to target domains. The geometric property for optimal transport is assured to mitigate the gradient vanishing problem in adversarial training. The neural network components for feature extraction, relevance transfer, domain matching and task classification are jointly trained by solving a minimax optimization over multiple objectives. Experiments on image classification show the merits of the proposed partially adversarial domain adaptation over different tasks. © 2019,IEEE","Adversarial learning; Deep learning; Domain adaptation; Image classification; Partial transfer","European Signal Processing Conference, EUSIPCO"
"Reeve H.W.J., Kabán A.","Robust randomized optimization with k nearest neighbors",2019,"Analysis and Applications",1,"10.1142/S0219530519400086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071670836&doi=10.1142%2fS0219530519400086&partnerID=40&md5=977ca9028888c73dacee78793ae02f10","Modern applications of machine learning typically require the tuning of a multitude of hyperparameters. With this motivation in mind, we consider the problem of optimization given a set of noisy function evaluations. We focus on robust optimization in which the goal is to find a point in the input space such that the function remains high when perturbed by an adversary within a given radius. Here we identify the minimax optimal rate for this problem, which turns out to be of order (n-λ/(2λ+1)), where n is the sample size and λ quantifies the smoothness of the function for a broad class of problems, including situations where the metric space is unbounded. The optimal rate is achieved (up to logarithmic factors) by a conceptually simple algorithm based on k-nearest neighbor regression. © 2019 World Scientific Publishing Company.","metric spaces; non-parametric methods; Optimization for machine learning","World Scientific Publishing Co. Pte Ltd"
"Bonakdari H., Ebtehaj I., Samui P., Gharabaghi B.","Lake Water-Level fluctuations forecasting using Minimax Probability Machine Regression, Relevance Vector Machine, Gaussian Process Regression, and Extreme Learning Machine",2019,"Water Resources Management",18,"10.1007/s11269-019-02346-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071454516&doi=10.1007%2fs11269-019-02346-0&partnerID=40&md5=eb6dc70441ab265a7de72f2140808b50","Forecasting freshwater lake levels is vital information for water resource management, including water supply management, shoreline management, hydropower generation optimization, and flood management. This study presents a novel application of four advanced artificial intelligence models namely the Minimax Probability Machine Regression (MPMR), Relevance Vector Machine (RVM), Gaussian Process Regression (GPR) and Extreme Learning Machine (ELM) for forecasting lake level fluctuation in Lake Huron utilizing historical datasets. The MPMR is a probabilistic framework that employed Mercer Kernels to achieve nonlinear regression models. The GPR, which is a probabilistic technique used tractable Bayesian framework for generalization of multivariate distribution of input samples to vast dimensional space. The ELM is a capable algorithm-based model for the implementation of the single-layer feed-forward neural network. The RVM demonstrate depends on the specification of the Bayesian method on a linear model with proper preceding that results in demonstration of sparse. The recommended techniques were tested to evaluate the current lake water-level trend monthly from the historical datasets at four previous time steps. The Lake Huron levels from 1918 to 1993 was managed for the training phase, and the rest of data (from 1994 to 2013) was used for testing. Considering the monthly and annually previous time steps, six models were introduced and found that the best results are achieved for a model with (t-1, t-2, t-3, t-12) as input combinations. The results show that all models can forecast the lake levels precisely. The results of this research study exhibit that the MPMR model (R2 = 0.984; MAE = 0.035; RMSE = 0.044; ENS = 0.984; DRefined = 0.995; ELM = 0.874) found to be more precise in lake level forecasting. The MPMR can be utilized as a practical computational tool on current and future planning with sustainable management of water resource of Lake Michigan-Huron. © 2019, Springer Nature B.V.","Gaussian Process Regression (GPR); Lake level; Minimax Probability Machine Regression (MPMR); Relevance Vector Machine (RVM)","Springer Netherlands"
"Qin H., Guo X.","Semi-supervised learning with summary statistics",2019,"Analysis and Applications",1,"10.1142/S0219530519400037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070886223&doi=10.1142%2fS0219530519400037&partnerID=40&md5=db1580336c3f6b1cf4579ae72bfcdc93","Nowadays, the extensive collection and analyzing of data is stimulating widespread privacy concerns, and therefore is increasing tensions between the potential sources of data and researchers. A privacy-friendly learning framework can help to ease the tensions, and to free up more data for research. We propose a new algorithm, LESS (Learning with Empirical feature-based Summary statistics from Semi-supervised data), which uses only summary statistics instead of raw data for regression learning. The selection of empirical features serves as a trade-off between prediction precision and the protection of privacy. We show that LESS achieves the minimax optimal rate of convergence in terms of the size of the labeled sample. LESS extends naturally to the applications where data are separately held by different sources. Compared with the existing literature on distributed learning, LESS removes the restriction of minimum sample size on single data sources. © 2019 World Scientific Publishing Company.","Distributed learning; empirical features; privacy protection; semi-supervised learning; summary statistics","World Scientific Publishing Co. Pte Ltd"
"Li Z., Li S., Yue C., Shang Z., Qu B.","Differential evolution based on reinforcement learning with fitness ranking for solving multimodal multiobjective problems",2019,"Swarm and Evolutionary Computation",31,"10.1016/j.swevo.2019.06.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069057277&doi=10.1016%2fj.swevo.2019.06.010&partnerID=40&md5=d768d75c8b132a966d5364bc13d267b1","In multimodal multiobjective optimization problems (MMOOPs), there is more than one Pareto-optimal Set (PS) in the decision space corresponding to the same Pareto Front(PF). How to dynamically adjust the evolution direction of the population adaptively is a key problem, to ensure approaching the PF in the global sense with good convergence while finding out more PSs. In this paper, a novel Differential Evolution algorithm based on Reinforcement Learning with Fitness Ranking (DE-RLFR) is proposed. The DE-RLFR is based on the Q-learning framework, and each individual in the population is considered an agent. The fitness ranking values of each agent are used to encode hierarchical state variables. Three typical DE mutation operations are employed as optional actions for the agent. Based on the analysis of the distribution characteristics of the population in objective space, decision space and fitness-ranking space, we design a reward function of the 〉state, action〈 pairs to guide the population to move to the PF asymptotically. According to its reinforcement learning experience represented by the corresponding Q table value, each agent could adaptively select a mutation strategy to generate offspring individuals. The evaluation results on eleven MMOOP test functions show that DE-RLFR could quickly and effectively find multiple PSs in the decision space, and approach PF in the global sense. © 2019 Elsevier B.V.","Differential evolution; Fitness ranking; Multimodal multiobjective optimization problem; Q-learning; Reinforcement learning","Elsevier B.V."
"Sudharson D., Prabha D.","A novel machine learning approach for software reliability growth modelling with pareto distribution function",2019,"Soft Computing",8,"10.1007/s00500-019-04047-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065645365&doi=10.1007%2fs00500-019-04047-7&partnerID=40&md5=24fd2c7fba09aec25268c8aafdbb463e","Software reliability is the important quantifiable attribute in gaining reliability by assessing faults at the time of testing in the software products. Time-based software reliability models used to identify the defects in the product, and it is not suitable for dynamic situations. Instead of time, test effect is used in few explorations through effort function and it is not realistic for infinite testing time. Identifying number of defects is essential in software reliability models, and this research work presents a Pareto distribution (PD) to predict the fault distribution of software under homogenous and nonhomogeneous conditions along with artificial neural network (ANN). This methodology enables the parallel evolution of a product through NN models which exhibit estimated Pareto optimality with respect to multiple error measures. The proposed PD-ANN-based SRGM describes types of failure data and also improves the accuracy of parameter estimation more than existing growth models such as homogeneous poison process and two fuzzy time series-based software reliability models. Experimental evidence is presented for general application and the proposed framework by generating solutions for different product and developer indexes. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Artificial neural networks; Distribution parameter estimation; Pareto distribution; Software reliability","Springer Verlag"
"Sadeghi B., Yu R., Boddeti V.","On the global optima of kernelized adversarial representation learning",2019,"Proceedings of the IEEE International Conference on Computer Vision",10,"10.1109/ICCV.2019.00806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081939240&doi=10.1109%2fICCV.2019.00806&partnerID=40&md5=18e1da2f48de472857e31221568bd393","Adversarial representation learning is a promising paradigm for obtaining data representations that are invariant to certain sensitive attributes while retaining the information necessary for predicting target attributes. Existing approaches solve this problem through iterative adversarial minimax optimization and lack theoretical guarantees. In this paper, we first study the ''linear' form of this problem i.e., the setting where all the players are linear functions. We show that the resulting optimization problem is both non-convex and non-differentiable. We obtain an exact closed-form expression for its global optima through spectral learning and provide performance guarantees in terms of analytical bounds on the achievable utility and invariance. We then extend this solution and analysis to non-linear functions through kernel representation. Numerical experiments on UCI, Extended Yale B and CIFAR-100 datasets indicate that, (a) practically, our solution is ideal for ''imparting' provable invariance to any biased pre-trained data representation, and (b) the global optima of the ''kernel' form can provide a comparable trade-off between utility and invariance in comparison to iterative minimax optimization of existing deep neural network based approaches, but with provable guarantees. © 2019 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Gardner S., Golovidov O., Griffin J., Koch P., Thompson W., Wujek B., Xu Y.","Constrained multi-objective optimization for automated machine learning",2019,"Proceedings - 2019 IEEE International Conference on Data Science and Advanced Analytics, DSAA 2019",3,"10.1109/DSAA.2019.00051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079272269&doi=10.1109%2fDSAA.2019.00051&partnerID=40&md5=2884b1de41ab4389759244f483cb6619","Automated machine learning has gained a lot of attention recently. Building and selecting the right machine learning models is often a multi-objective optimization problem. General purpose machine learning software that simultaneously supports multiple objectives and constraints is scant, though the potential benefits are great. In this work, we present a framework called Autotune that effectively handles multiple objectives and constraints that arise in machine learning problems. Autotune is built on a suite of derivative-free optimization methods, and utilizes multi-level parallelism in a distributed computing environment for automatically training, scoring, and selecting good models. Incorporation of multiple objectives and constraints in the model exploration and selection process provides the flexibility needed to satisfy trade-offs necessary in practical machine learning applications. Experimental results from standard multi-objective optimization benchmark problems show that Autotune is very efficient in capturing Pareto fronts. These benchmark results also show how adding constraints can guide the search to more promising regions of the solution space, ultimately producing more desirable Pareto fronts. Results from two real-world case studies demonstrate the effectiveness of the constrained multi-objective optimization capability offered by Autotune. © 2019 IEEE.","Automated Machine Learning; Distributed Computing System; Multi-objective Optimization","Institute of Electrical and Electronics Engineers Inc."
"Nardi L., Koeplinger D., Olukotun K.","Practical design space exploration",2019,"Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS",11,"10.1109/MASCOTS.2019.00045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077791679&doi=10.1109%2fMASCOTS.2019.00045&partnerID=40&md5=72b1314175064b98e453008e1acf5a9b","Multi-objective optimization is a crucial matter in computer systems design space exploration because real-world applications often rely on a trade-off between several objectives. Derivatives are usually not available or impractical to compute and the feasibility of an experiment can not always be determined in advance. These problems are particularly difficult when the feasible region is relatively small, and it may be prohibitive to even find a feasible experiment, let alone an optimal one. We introduce a new methodology and corresponding software framework, HyperMapper 2.0, which handles multi-objective optimization, unknown feasibility constraints, and categorical/ordinal variables. This new methodology also supports injection of the user prior knowledge in the search when available. All of these features are common requirements in computer systems but rarely exposed in existing design space exploration systems. The proposed methodology follows a white-box model which is simple to understand and interpret (unlike, for example, neural networks) and can be used by the user to better understand the results of the automatic search. We apply and evaluate the new methodology to the automatic static tuning of hardware accelerators within the recently introduced Spatial programming language, with minimization of design run-time and compute logic under the constraint of the design fitting in a target field-programmable gate array chip. Our results show that HyperMapper 2.0 provides better Pareto fronts compared to state-of-the-art baselines, with better or competitive hypervolume indicator and with 8x improvement in sampling budget for most of the benchmarks explored. © 2019 IEEE.","Design space exploration; Hardware design; Machine learning driven optimization; Optimizing compilers; Pareto-optimal front; Performance modeling","IEEE Computer Society"
"Shayovitz S., Feder M.","Minimax Active Learning Via Minimal Model Capacity",2019,"IEEE International Workshop on Machine Learning for Signal Processing, MLSP",,"10.1109/MLSP.2019.8918907","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077696676&doi=10.1109%2fMLSP.2019.8918907&partnerID=40&md5=18fc9fc4dcbb5685ecd9b4c8f6626287","Active learning is a form of machine learning which combines supervised learning and feedback to minimize the training set size, subject to low generalization errors. Since direct optimization of the generalization error is difficult, many heuristics have been developed which lack a firm theoretical foundation. In this paper, a new information theoretic criterion is proposed based on a minimax log-loss regret formulation of the active learning problem. In the first part of this paper, a Redundancy Capacity theorem for active learning is derived along with an optimal learner. Building on this, a new active learning criterion is proposed which naturally induces an exploration - exploitation trade-off in feature selection. In the second part, the linear separator hypotheses class with additive label noise is considered and a low complexity algorithm is proposed which optimizes the active learning criterion from the first part. This greedy algorithm is based on the Posterior Matching scheme for communication with feedback and is shown that for BSC and BEC label noise, the proposed information theoretic criterion decays at an exponential rate. © 2019 IEEE.","Active Learning; Linear Separator; Posterior Matching","IEEE Computer Society"
"Mozaffari M., Yilmaz Y.","Online Anomaly Detection in Multivariate Settings",2019,"IEEE International Workshop on Machine Learning for Signal Processing, MLSP",8,"10.1109/MLSP.2019.8918893","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077692324&doi=10.1109%2fMLSP.2019.8918893&partnerID=40&md5=f6edf67ddb732deac0122ec31ea46ecc","This paper considers the real-time and nonparametric detection of anomalies in high-dimensional systems. The goal is to detect anomalies quickly and accurately such that the appropriate countermeasures could be taken before any possible harm is caused by the anomalous event. We propose a k NN-based sequential anomaly detection method in both semi-supervised and supervised settings. We prove that the proposed method is asymptotically optimum in the minimax sense under certain conditions in terms of minimizing the average detection delay for a given false alarm constraint. The proposed method is shown to be capable of multivariate anomaly detection and also scalable to high-dimensional datasets. We further propose an online learning scheme that combines the desirable properties of our semi-supervised and supervised methods. © 2019 IEEE.","anomaly detection; nonparametric methods; online learning","IEEE Computer Society"
"Jesus J., Canuto A., Araujo D.","Investigating the robustness and stability to noisy data of a dynamic feature selection method",2019,"Proceedings - 2019 Brazilian Conference on Intelligent Systems, BRACIS 2019",1,"10.1109/BRACIS.2019.00040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077034174&doi=10.1109%2fBRACIS.2019.00040&partnerID=40&md5=376121a43edac4631aadd80789747560","The curse of dimensionality is one of the major problems faced by machine learning researchers. If we consider the fast growing of complex data in real world scenarios, feature selection (FS) becomes a imperative step for many application domains to reduce both data complexity and computing time. Based on that, several studies have been developed in order to create efficient FS methods that performs this task. However, a bad selection of one single criterion to evaluate the attribute importance and the arbitrary choice of the number of features usually leads to a poor analysis. On the other hand, recent studies have successfully created models to select features considering the particularities of the data, known as dynamic feature selection. In this paper, we evaluate one of this successful methods, called pareto front based dynamic feature selection (PF-DFS), to test its stability and robustness in noisy data. We used 15 artificial and real world data with additional noise data. Results shown that the PF-DFS is more stable to noisy scenarios than existing feature selection methods. © 2019 IEEE.","Data analysis; Dynamic feature selection; Feature selection; Pareto front; Supervised learning","Institute of Electrical and Electronics Engineers Inc."
"Nguyen X.H., Thu Bui L., Tran C.T.","A pareto corner search evolutionary algorithm and principal component analysis for objective dimensionality reduction",2019,"Proceedings of 2019 11th International Conference on Knowledge and Systems Engineering, KSE 2019",2,"10.1109/KSE.2019.8919438","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077024788&doi=10.1109%2fKSE.2019.8919438&partnerID=40&md5=738eb999f330125bfb37622efb5beb72","Many-objective optimisation problems (MaOPs) cause serious difficulties for existing multi-objective evolutionary algorithms (MOEAs). One common way to alleviate these difficulties is to use objective dimensionality reduction. Most existing objective reduction methods are time-consuming because they require MOEAs to run numerous generations. Pareto corner search evolutionary algorithm (PCSEA) was proposed in [18] to speed up objective reduction methods by only seeking corner solutions instead of whole solutions. However, the PCSEA-based objective reduction method in [18] needs to predefine a threshold to select objectives which strongly depends on problems and is not straightforward to obtain. This paper proposes a new objective dimensionality reduction method by integrating PCSEA and principal component analysis (PCA). Thanks to combining advantages of PCSEA and PCA, the proposed method not only can be efficient to eliminate redundant objectives, but also not require to define any parameter in advanced. The experimental results also show that the proposed method can perform objective reduction more successfully than the PCSEA-based objective reduction method. The results further strengthen the links between evolutionary computation and machine learning to address optimization problems. © 2019 IEEE.","Evolutionary computation; Feature selection; Many-objective optimisation; Objective dimensionality reduction","Institute of Electrical and Electronics Engineers Inc."
"Jiang H., Zheng W., Luo L., Dong Y.","A two-stage minimax concave penalty based method in pruned AdaBoost ensemble",2019,"Applied Soft Computing Journal",9,"10.1016/j.asoc.2019.105674","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069908734&doi=10.1016%2fj.asoc.2019.105674&partnerID=40&md5=3eef1d98d0ac03e4687cc863b17bacd9","AdaBoost is a highly effective ensemble learning method that combines several weak learners to produce a strong committee with higher accuracy. However, similar to other ensemble methods, AdaBoost uses a large number of base learners to produce the final outcome while addressing high-dimensional data. Thus, it poses a critical challenge in the form of high memory-space consumption. Feature selection methods can significantly reduce dimensionality in regression and have been established to be applicable in ensemble pruning. By pruning the ensemble, it is possible to generate a simpler ensemble with fewer base learners but a higher accuracy. In this article, we propose the minimax concave penalty (MCP) function to prune an AdaBoost ensemble to simplify the model and improve its accuracy simultaneously. The MCP penalty function is compared with LASSO and SCAD in terms of performance in pruning the ensemble. Experiments performed on real datasets demonstrate that MCP-pruning outperforms the other two methods. It can reduce the ensemble size effectively, and generate marginally more accurate predictions than the unpruned AdaBoost model. © 2019 Elsevier B.V.","AdaBoost; Ensemble pruning; Feature selection; Minimax concave penalty","Elsevier Ltd"
"Grigorescu S.M., Trasnea B., Marina L., Vasilcoi A., Cocias T.","NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory Learning for Autonomous Vehicles",2019,"IEEE Robotics and Automation Letters",14,"10.1109/LRA.2019.2926224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069814784&doi=10.1109%2fLRA.2019.2926224&partnerID=40&md5=97fa67b6fc3789cf48479149be8b8e82","Autonomous vehicles are controlled today either based on sequences of decoupled perception-planning-action operations, either based on End2End or deep reinforcement learning (DRL) systems. Current deep learning solutions for autonomous driving are subject to several limitations (e.g., they estimate driving actions through a direct mapping of sensors to actuators, or require complex reward shaping methods). Although the cost function used for training can aggregate multiple weighted objectives, the gradient descent step is computed by the backpropagation algorithm using a single-objective loss. To address these issues, we introduce NeuroTrajectory, which is a multiobjective neuroevolutionary approach to local state trajectory learning for autonomous driving, where the desired state trajectory of the ego-vehicle is estimated over a finite prediction horizon by a perception-planning deep neural network. In comparison to DRL methods, which predict optimal actions for the upcoming sampling time, we estimate a sequence of optimal states that can be used for motion control. We propose an approach which uses genetic algorithms for training a population of deep neural networks, where each network individual is evaluated based on a multi-objective fitness vector, with the purpose of establishing a so-called Pareto front of optimal deep neural networks. The performance of an individual is given by a fitness vector composed of three elements. Each element describes the vehicle's travel path, lateral velocity and longitudinal speed, respectively. The same network structure can be trained on synthetic, as well as on real-world data sequences. We have benchmarked our system against a baseline Dynamic Window Approach (DWA), as well as against an End2End supervised learning method. © 2019 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Lopez J.F., Sotelo J.A.L., Leite D., Pena-Reyes C.","Applying one-class learning algorithms to predict phage-bacteria interactions",2019,"2019 IEEE Latin American Conference on Computational Intelligence, LA-CCI 2019",1,"10.1109/LA-CCI47412.2019.9037032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083092317&doi=10.1109%2fLA-CCI47412.2019.9037032&partnerID=40&md5=40c78531c961f0300e7152be49bc8b2c","The need to predict phage-bacteria interactions is a nowadays concern to overcome bacterial resistance issue; public genome databases contain highly imbalanced datasets which have hindered this task. Throughout this paper we will investigate, implement and evaluate One-Class Learning algorithms in order to predict phage-bacteria interactions using only positive samples. We will use the programming language Python aided by Scikit-Learn, Tensorflow and keras to develop the machine learning models and test them with real phage-bacteria interactions datasets. We trained the models using cross validation technique generating a gridsearch with all the datasets to find several combinations of hyperparameters available. Furthermore, we optimized those hyperparameters by using Pareto fronts based on seven different performance metrics, improving the efficiency of each algorithm for a given dataset. To refine each algorithm's performance separately we used the ensemble learning technique with an odd number of algorithms by simple voting. Finally, we managed to achieve an overall performance of 80% in predicting phage-bacteria interactions trained only with positive classes, this percentage in practice means that when a patient has an infection resistant to antibiotics, we have 80% of saving the life rather than maybe a 0% while finding the correct phage for the pathogenic host. © 2019 IEEE.","imbalanced datasets; One-Class Learning; optimization; phage-bacteria interaction","Institute of Electrical and Electronics Engineers Inc."
"Xu S., Schafer B.C.","Low power design of runtime reconfigurable FPGAs through contexts approximations",2019,"Proceedings - 2019 IEEE International Conference on Computer Design, ICCD 2019",,"10.1109/ICCD46524.2019.00078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081156781&doi=10.1109%2fICCD46524.2019.00078&partnerID=40&md5=8f952316e54edb8279936cf6249b9023","This paper presents a method to improve the performance and reduce the energy of applications mapped onto coarse-grain runtime reconfigurable arrays (CGRRAs) by substituting and merging different contexts by approximate predictive models. In CGRRAs applications are split into contexts. The CGRRA is then reconfigured every clock cycle by loading a new context onto the reconfigurable fabric. In this work, we propose to substitute contexts by approximate expressions using machine learning models of different complexities like linear regression (LR) and multi-layer perceptrons (MLPs) such that the CGRRA area and energy can be reduced albeit introducing different levels of errors at the output. Moreover, we propose a technique to merged these approximated contexts with other contexts leading to a set of Pareto-optimal configurations. Experimental results show that our proposed method works well and it can trade-off area, performance and energy with output error of several computationally intensive applications mapped onto a commercial CGRRA. © 2019 IEEE.","Approximate Computing; Coarse grain Runtime Reconfigurable Architecture; Hardware Accelerator; High level Synthesis; Machine Learning","Institute of Electrical and Electronics Engineers Inc."
"Nitanda A., Murata T., Suzuki T.","Sharp characterization of optimal minibatch size for stochastic finite sum convex optimization",2019,"Proceedings - IEEE International Conference on Data Mining, ICDM",,"10.1109/ICDM.2019.00059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078881697&doi=10.1109%2fICDM.2019.00059&partnerID=40&md5=5fad72f424acb4b90c34414a7838954b","The minibatching technique has been extensively adopted to facilitate stochastic first-order methods because of their computational efficiency in parallel computing for large-scale machine learning and data mining. However, the optimal minibatch size determination for accelerated stochastic gradient methods is not completely understood. Actually, there appears trade-off between the iteration complexity and the total computational complexity; that is, the number of iterations (minibatch queries) can be decreased by increasing the minibatch size, but too large minibatch size would result in an unnecessarily large total computational cost. In this study, we give a sharp characterization of the minimax optimal minibatch size to achieve the optimal iteration complexity by providing a reachable lower bound for minimizing finite sum of convex functions and, surprisingly, show that the optimal method with the minimax optimal minibatch size can achieve both of the optimal iteration complexity and the optimal total computational complexity simultaneously. Finally, this feature is verified experimentally. © 2019 IEEE.","Finite-sum problem; Optimal minibatch method","Institute of Electrical and Electronics Engineers Inc."
"Torun H.M., Yu H., Dasari N., Chekuri V.C.K., Singh A., Kim J., Lim S.K., Mukhopadhyay S., Swaminathan M.","A spectral convolutional net for co-optimization of integrated voltage regulators and embedded inductors",2019,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",8,"10.1109/ICCAD45719.2019.8942109","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077790427&doi=10.1109%2fICCAD45719.2019.8942109&partnerID=40&md5=c60a431916d32530ee319a27f3f7dc10","Integrated voltage regulators (IVR) with embedded inductors is an emerging technology that provides point-of-load voltage regulation to high-performance systems. Conventional two-step approaches to the design of IVRs can suffer from suboptimal design as the optimal inductor depends on the characteristics of the buck converter (BC). Furthermore, inductor-level trade-offs such as AC and DC resistance, inductance and area can not be determined independently from the BC. This co-dependency of the BC and the inductor creates a highly non-linear response surface, which raises the necessity of co-optimization, involving multiple time-consuming electromagnetics (EM) simulations. In this paper, we propose a machine learning based optimization methodology that eliminates EM simulations from the optimization loop to significantly reduce the optimization complexity. A novel technique named as Spectral Transposed Convolutional Neural Network (S-TCNN) is presented to derive an accurate predictive model of the inductor frequency response using a small amount of training data. The derived S-TCNN is then used along with a time-domain model of the BC to perform multi-objective optimization that approximates the Pareto front for 5 objectives, namely inductor area, BC settling time, voltage conversion efficiency, droop and ripple. The resulting methodology provides multiple Pareto optimal inductors in an efficient and fully automated fashion, thereby allows to rapidly determine the optimal trade-offs for possibly contradicting design objectives. We demonstrate the proposed framework on co-optimization of solenoidal inductor with magnetic core and BC that are integrated on silicon interposer. © 2019 IEEE.","Convolutional networks; Embedded inductors; Integrated voltage regulators; System-level optimization","Institute of Electrical and Electronics Engineers Inc."
"Hasan M.M., Lwin K., Imani M., Shabut A., Bittencourt L.F., Hossain M.A.","Dynamic multi-objective optimisation using deep reinforcement learning: benchmark, algorithm and an application to identify vulnerable zones based on water quality",2019,"Engineering Applications of Artificial Intelligence",9,"10.1016/j.engappai.2019.08.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071858165&doi=10.1016%2fj.engappai.2019.08.014&partnerID=40&md5=a9b52be6c4f3e7aae99fc40b37fb3526","Dynamic multi-objective optimisation problem (DMOP) has brought a great challenge to the reinforcement learning (RL) research area due to its dynamic nature such as objective functions, constraints and problem parameters that may change over time. This study aims to identify the lacking in the existing benchmarks for multi-objective optimisation for the dynamic environment in the RL settings. Hence, a dynamic multi-objective testbed has been created which is a modified version of the conventional deep-sea treasure (DST) hunt testbed. This modified testbed fulfils the changing aspects of the dynamic environment in terms of the characteristics where the changes occur based on time. To the authors’ knowledge, this is the first dynamic multi-objective testbed for RL research, especially for deep reinforcement learning. In addition to that, a generic algorithm is proposed to solve the multi-objective optimisation problem in a dynamic constrained environment that maintains equilibrium by mapping different objectives simultaneously to provide the most compromised solution that closed to the true Pareto front (PF). As a proof of concept, the developed algorithm has been implemented to build an expert system for a real-world scenario using Markov decision process to identify the vulnerable zones based on water quality resilience in São Paulo, Brazil. The outcome of the implementation reveals that the proposed parity-Q deep Q network (PQDQN) algorithm is an efficient way to optimise the decision in a dynamic environment. Moreover, the result shows PQDQN algorithm performs better compared to the other state-of-the-art solutions both in the simulated and the real-world scenario. © 2019 Elsevier Ltd","Artificial intelligence; Deep Q network; Dynamic environment; Meta-policy selection; Reinforcement learning; Water quality resilience","Elsevier Ltd"
"Shang R., Zhang W., Li F., Jiao L., Stolkin R.","Multi-objective artificial immune algorithm for fuzzy clustering based on multiple kernels",2019,"Swarm and Evolutionary Computation",14,"10.1016/j.swevo.2019.01.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069561105&doi=10.1016%2fj.swevo.2019.01.001&partnerID=40&md5=f773eebf8a47f07602bb5fd7cf40efd4","This paper presents a multi-objective artificial immune algorithm for fuzzy clustering based on multiple kernels (MAFC). MAFC extends the classical Fuzzy C-Means (FCM) algorithm and improves some of its important limitations, such as vulnerability to local optima convergence, which can lead to poor clustering quality. MAFC unifies multi-kernel learning and multi-objective optimization in a joint clustering framework, which preserves the geometric information of the dataset. The multi-kernel method maps data from the feature space to kernel space by using kernel functions. Additionally, the introduction of multi-objective optimization helps to optimize between-cluster separation and within-cluster compactness simultaneously via two different clustering validity criteria. These properties help the proposed algorithm to avoid becoming stuck at local optima. Furthermore, this paper utilizes an artificial immune algorithm to address the multi-objective clustering problem and acquire a Pareto optimal solution set. The solution set is obtained through the process of antibody population initialization, clone proliferation, non-uniform mutation and uniformity maintaining strategy, which avoids the problems of degradation and prematurity which can occur with conventional genetic algorithms. Finally, we choose the best solution from the Pareto optimal solution set. We use a semi-supervised method to achieve the final clustering results. We compare our method against state-of-the-art methods from the literature by performing experiments with both UCI datasets and face datasets. The results suggest that MAFC is significantly more efficient for clustering and has a wider scope of application. © 2019 Elsevier B.V.","Artificial immune algorithm; Fuzzy c-means (FCM); Multi-objective optimization; Multiple kernel learning","Elsevier B.V."
"Endrei M., Jin C., Dinh M.N., Abramson D., Poxon H., DeRose L., de Supinski B.R.","Statistical and machine learning models for optimizing energy in parallel applications",2019,"International Journal of High Performance Computing Applications",3,"10.1177/1094342019842915","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064910783&doi=10.1177%2f1094342019842915&partnerID=40&md5=938204bec83e7f0600691416cdac07f3","Rising power costs and constraints are driving a growing focus on the energy efficiency of high performance computing systems. The unique characteristics of a particular system and workload and their effect on performance and energy efficiency are typically difficult for application users to assess and to control. Settings for optimum performance and energy efficiency can also diverge, so we need to identify trade-off options that guide a suitable balance between energy use and performance. We present statistical and machine learning models that only require a small number of runs to make accurate Pareto-optimal trade-off predictions using parameters that users can control. We study model training and validation using several parallel kernels and more complex workloads, including Algebraic Multigrid (AMG), Large-scale Atomic Molecular Massively Parallel Simulator, and Livermore Unstructured Lagrangian Explicit Shock Hydrodynamics. We demonstrate that we can train the models using as few as 12 runs, with prediction error of less than 10%. Our AMG results identify trade-off options that provide up to 45% improvement in energy efficiency for around 10% performance loss. We reduce the sample measurement time required for AMG by 90%, from 13 h to 74 min. © The Author(s) 2019.","Energy efficiency; high performance computing; machine learning; performance; regression modeling","SAGE Publications Inc."
"Briones A.M., Rumpfkeil M.P., Thomas N.R., Rankin B.A.","Effect of deterministic and continuous design space resolution on multiple-objective combustor optimization",2019,"Journal of Engineering for Gas Turbines and Power",1,"10.1115/1.4045284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106986471&doi=10.1115%2f1.4045284&partnerID=40&md5=d0f29c3164c5a16b172cba5153a92132","Supervised machine learning is used to classify a continuous and deterministic design space into a nondominated Pareto frontier and dominated design points. The effect of the initial training data quantity on the Pareto frontier and output parameter sensitivity is explored. The study is performed with the optimization of a subsonic small-scale cavity-stabilized combustor. A 3D geometry is created and parameterized using computer aided design (CAD) that is combined with a software for meshing, which automatically transfers grids and boundary conditions to the solver and postprocessing tool. Steady, compressible three-dimensional simulations are conducted employing a multiphase Realizable k-ϵ Reynolds-averaged Navier-Stokes (RANS) physics with an adiabatic flamelet progress variable (FPV) model. The near-wall turbulence modeling is computed with scalable wall functions (SWFs). For each computational fluid dynamics (CFD) simulation, four levels of adaptive mesh refinement (AMR) are utilized on the original cut-cell grid. There are 15 geometrical input parameters and three output parameters, viz., a pattern factor proxy, a combustion efficiency proxy, and total pressure loss (TPL). Three times the number of input parameters plus one (48) is necessary to yield an optimization independent of the initial sampling. This conclusion is drawn by examining and comparing the Pareto frontiers and global sensitivities. However, the latter provides a better metric. The relative influence of the input parameters on the outputs is assessed by Spearman's order-rank correlation and an active subspace analysis. Some persistent geometric features for nondominated designs are also discussed. © 2019 American Society of Mechanical Engineers (ASME). All rights reserved.",,"American Society of Mechanical Engineers (ASME)"
"Liu W., Wu W., Wang Y., Fu Y., Lin Y.","Selective ensemble learning method for belief-rule-base classification system based on PAES",2019,"Big Data Mining and Analytics",5,"10.26599/BDMA.2019.9020008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081560596&doi=10.26599%2fBDMA.2019.9020008&partnerID=40&md5=9a31502fea7e3eb6e6b5125febf54828","Traditional Belief-Rule-Based (BRB) ensemble learning methods integrate all of the trained sub-BRB systems to obtain better results than a single belief-rule-based system. However, as the number of BRB systems participating in ensemble learning increases, a large amount of redundant sub-BRB systems are generated because of the diminishing difference between subsystems. This drastically decreases the prediction speed and increases the storage requirements for BRB systems. In order to solve these problems, this paper proposes BRBCS-PAES: a selective ensemble learning approach for BRB Classification Systems (BRBCS) based on Pareto- Archived Evolutionary Strategy (PAES) multi-objective optimization. This system employs the improved Bagging algorithm to train the base classifier. For the purpose of increasing the degree of difference in the integration of the base classifier, the training set is constructed by the repeated sampling of data. In the base classifier selection stage, the trained base classifier is binary coded, and the number of base classifiers participating in integration and generalization error of the base classifier is used as the objective function for multi-objective optimization. Finally, the elite retention strategy and the adaptive mesh algorithm are adopted to produce the PAES optimal solution set. Three experimental studies on classification problems are performed to verify the effectiveness of the proposed method. The comparison results demonstrate that the proposed method can effectively reduce the number of base classifiers participating in the integration and improve the accuracy of BRBCS. © 2020 The author(s).","Belief-rule-base; Classification; Pareto-archived evolutionary strategy; Selective ensemble","Tsinghua University Press"
"Pei Y.","Automatic Decision Making for Parameters in Kernel Method",2019,"2019 IEEE Symposium Series on Computational Intelligence, SSCI 2019",2,"10.1109/SSCI44817.2019.9002691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080919945&doi=10.1109%2fSSCI44817.2019.9002691&partnerID=40&md5=16a4ee5299b388db3aebc9d666e629dc","We propose to use the relationship between the parameter of kernel function and its decisional angle or distance metrics for selecting the optimal setting of the parameter of kernel functions in kernel method-based algorithms. Kernel method is established in the reproducing kernel Hilbert space, the angle and distance are two metrics in such space. We analyse and investigate the relationship between the parameter of kernel function and the metrics (distance or angle) in the reproducing kernel Hilbert space. We design a target function of optimization to model the relationship between these two variables, and found that (1) the landscape shapes of parameter and the metrics are the same in Gaussian kernel function because the norm of all the vectors are equal to one in reproducing kernel Hilbert space; (2) the landscape monotonicity of that are opposite in polynomial kernel function from that of Gaussian kernel. The monotonicity of designed target functions of optimization using Gaussian kernel and polynomial kernel is different as well. The distance metric and angle metric have different distribution characteristics for the decision of parameter setting in kernel function. It needs to balance these two metrics when selecting a proper parameter of the kernel function in kernel-based algorithms. We use evolutionary multi-objective optimization algorithms to obtain the Pareto solutions for optimal selection of the parameter in kernel functions. We found that evolutionary multi-objective optimization algorithms are useful tools to balance the distance metric and angle metric in the decision of parameter setting in kernel method-based algorithms. © 2019 IEEE.","decision making; evolutionary multi-objective optimization; kernel function; kernel method; machine learning; reproducing kernel Hilbert space","Institute of Electrical and Electronics Engineers Inc."
"Qiu Y., Ji W., Zhang C.","A hybrid machine learning and population knowledge mining method to minimize makespan and total tardiness of multi-variety products",2019,"Applied Sciences (Switzerland)",1,"10.3390/app9245286","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077353903&doi=10.3390%2fapp9245286&partnerID=40&md5=8bac725f3013780beb2ec0147f49f11a","Nowadays, the production model of many enterprises is multi-variety customized production, and the makespan and total tardiness are the main metrics for enterprises to make production plans. This requires us to develop a more effective production plan promptly with limited resources. Previous research focuses on dispatching rules and algorithms, but the application of the knowledge mining method for multi-variety products is limited. In this paper, a hybrid machine learning and population knowledge mining method to minimize makespan and total tardiness for multi-variety products is proposed. First, through offline machine learning and data mining, attributes of operations are selected to mine the initial population knowledge. Second, an addition-deletion sorting method (ADSM) is proposed to reprioritize operations and then form the rule-based initial population. Finally, the nondominated sorting genetic algorithm II (NSGA-II) hybrid with simulated annealing is used to obtain the Pareto solutions. To evaluate the effectiveness of the proposed method, three other types of initial populations were considered under different iterations and population sizes. The experimental results demonstrate that the new approach has a good performance in solving the multi-variety production planning problems, whether it is the function value or the performance metric of the acquired Pareto solutions. © 2019 by the authors.","Data mining; Initial population; Machine learning; Multi-variety; Production planning","MDPI AG"
"Murari A., Lungaroni M., Peluso E., Craciunescu T., Gelfusa M.","A Model Falsification Approach to Learning in Non-Stationary Environments for Experimental Design",2019,"Scientific Reports",2,"10.1038/s41598-019-54145-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075793142&doi=10.1038%2fs41598-019-54145-7&partnerID=40&md5=de5d666c9f53c07a8da35086fc7e2b1f","The application of data driven machine learning and advanced statistical tools to complex physics experiments, such as Magnetic Confinement Nuclear Fusion, can be problematic, due the varying conditions of the systems to be studied. In particular, new experiments have to be planned in unexplored regions of the operational space. As a consequence, care must be taken because the input quantities used to train and test the performance of the analysis tools are not necessarily sampled by the same probability distribution as in the final applications. The regressors and dependent variables cannot therefore be assumed to verify the i.i.d. (independent and identical distribution) hypothesis and learning has therefore to take place under non stationary conditions. In the present paper, a new data driven methodology is proposed to guide planning of experiments, to explore the operational space and to optimise performance. The approach is based on the falsification of existing models. The deployment of Symbolic Regression via Genetic Programming to the available data is used to identify a set of candidate models, using the method of the Pareto Frontier. The confidence intervals for the predictions of such models are then used to find the best region of the parameter space for their falsification, where the next set of experiments can be most profitably carried out. Extensive numerical tests and applications to the scaling laws in Tokamaks prove the viability of the proposed methodology. © 2019, The Author(s).",,"Nature Research"
"Dhulipati H., Ghosh E., Mukundan S., Korta P., Tjong J., Kar N.C.","Advanced design optimization technique for torque profile improvement in six-phase pmsm using supervised machine learning for direct-drive ev",2019,"IEEE Transactions on Energy Conversion",21,"10.1109/TEC.2019.2933619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075640604&doi=10.1109%2fTEC.2019.2933619&partnerID=40&md5=8b1251c827e8ddbb4222a6b3e8712982","Few of the challenges with development of a single on-board motor for direct-drive electric vehicles include high torque density and low torque ripple. Therefore, in this paper, a 36-slot, 34-pole consequent pole six-phase permanent magnet synchronous machine (PMSM) has been optimized to address the aforementioned challenges for direct-drive application. Existing literature on optimization processes that rely solely on finite element models are restricted to three-phase machines only and also take longer computation time. Therefore, this paper proposes a novel optimization approach based on supervised machine learning for six-phase PMSM. In this approach, a non-conventional extended dual dq-frame model that accounts for higher order space harmonics in inductances and flux linkages has been developed and used for accurate computation of average torque and torque ripple of six-phase PMSM. Using the performance characteristics obtained from the extended dual dq-frame model for a set of initial design candidates, support vector regression algorithm is employed for supervised machine learning and increasing solutions in the design space. Furthermore, pareto front is used for selecting optimal machine models with maximum torque density and reduced torque ripple. Multi-objective trade-offs and comparison of initial and optimized designs based on average torque, torque ripple, efficiency and cost are performed. © 1986-2012 IEEE.","Direct-drive; electric vehicle; frame model; machine learning; permanent magnet synchronous machine; support vector regression; time-step finite element analysis","Institute of Electrical and Electronics Engineers Inc."
"Zhou Y., Zhao X., Lin K.-P., Wang C.-H., Li L.","A Gaussian process mixture model-based hard-cut iterative learning algorithm for air quality prediction",2019,"Applied Soft Computing Journal",9,"10.1016/j.asoc.2019.105789","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072851469&doi=10.1016%2fj.asoc.2019.105789&partnerID=40&md5=84918090a81687bbe415fd5cb70b8118","Air quality is closely related to concentrations of gaseous pollutants, and the prediction of gaseous pollutant concentration plays a decisive role in regulating plant and vehicle emissions. Due to the non-linear and chaotic characteristics of the gas concentration series, traditional models may not easily capture the complex time series pattern. In this study, the Gaussian Process Mixture (GPM) model, which adopts hidden variables posterior hard-cut (HC) iterative learning algorithm, is first applied to the prediction of gaseous pollutant concentration in order to improve prediction performance. This algorithm adopts iterative learning and uses the maximizing a posteriori (MAP) estimation to achieve the optimal grouping of samples which effectively improves the expectation–maximization (EM) learning in GPM. The empirical results of the GPM model reveals improved prediction accuracy in gaseous pollutant concentration prediction, as compared with the kernel regression (K-R), minimax probability machine regression (MPMR), linear regression (L-R) and Gaussian Processes (GP) models. Furthermore, GPM with various learning algorithms, namely the HC algorithm, Leave-one-out Cross Validation (LOOCV), and variational algorithms, respectively, are also examined in this study. The results also show that the GPM with HC learning achieves superior performance compared with other learning algorithms. © 2019 Elsevier B.V.","Gaseous pollutant time series; Gaussian processes mixtures; Machine learning; Prediction","Elsevier Ltd"
"Ma Y., Roy S., Miao J., Chen J., Yu B.","Cross-Layer Optimization for High Speed Adders: A Pareto Driven Machine Learning Approach",2019,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",9,"10.1109/TCAD.2018.2878129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055711331&doi=10.1109%2fTCAD.2018.2878129&partnerID=40&md5=d823591f7a3e6e09fcca9801b785a456","In spite of maturity to the modern electronic design automation (EDA) tools, optimized designs at architectural stage may become suboptimal after going through physical design flow. Adder design has been such a long studied fundamental problem in very large-scale integration industry yet designers cannot achieve optimal solutions by running EDA tools on the set of available prefix adder architectures. In this paper, we enhance a state-of-the-art prefix adder synthesis algorithm to obtain a much wider solution space in architectural domain. On top of that, a machine learning-based design space exploration methodology is applied to predict the Pareto frontier of the adders in physical domain, which is infeasible by exhaustively running EDA tools for innumerable architectural solutions. Considering the high cost of obtaining the true values for learning, an active learning algorithm is proposed to select the representative data during learning process, which uses less labeled data while achieving better quality of Pareto frontier. Experimental results demonstrate that our framework can achieve Pareto frontier of high quality over a wide design space, bridging the gap between architectural and physical designs. Source code and data are available at https://github.com/yuzhe630/adder-DSE. © 1982-2012 IEEE.","Active learning; design space exploration; machine learning; Pareto optimality; prefix adder","Institute of Electrical and Electronics Engineers Inc."
"Long M., Cao Y., Cao Z., Wang J., Jordan M.I.","Transferable Representation Learning with Deep Adaptation Networks",2019,"IEEE Transactions on Pattern Analysis and Machine Intelligence",131,"10.1109/TPAMI.2018.2868685","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052886473&doi=10.1109%2fTPAMI.2018.2868685&partnerID=40&md5=bf26d1c262b426746810c02b5083dc63","Domain adaptation studies learning algorithms that generalize across source domains and target domains that exhibit different distributions. Recent studies reveal that deep neural networks can learn transferable features that generalize well to similar novel tasks. However, as deep features eventually transition from general to specific along the network, feature transferability drops significantly in higher task-specific layers with increasing domain discrepancy. To formally reduce the effects of this discrepancy and enhance feature transferability in task-specific layers, we develop a novel framework for deep adaptation networks that extends deep convolutional neural networks to domain adaptation problems. The framework embeds the deep features of all task-specific layers into reproducing kernel Hilbert spaces (RKHSs) and optimally matches different domain distributions. The deep features are made more transferable by exploiting low-density separation of target-unlabeled data in very deep architectures, while the domain discrepancy is further reduced via the use of multiple kernel learning that enhances the statistical power of kernel embedding matching. The overall framework is cast in a minimax game setting. Extensive empirical evidence shows that the proposed networks yield state-of-the-art results on standard visual domain-adaptation benchmarks. © 2018 IEEE.","convolutional neural network; deep learning; Domain adaptation; multiple kernel learning; two-sample test","IEEE Computer Society"
"Nguyen X.H., Bui L.T., Tran C.T.","Clustering method using Pareto Corner Search Evolutionary algorithm for objective reduction in many-objective optimization problems",2019,"ACM International Conference Proceeding Series",,"10.1145/3368926.3369720","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077822538&doi=10.1145%2f3368926.3369720&partnerID=40&md5=b1bf428127cb9d3a3918a65bef2a2396","Many-objective optimization problems (MaOPs) have been gained considerable attention for researcher, recently. MaOPs make a number of difficulties for multi-objective optimization evolutionary algorithms (MOEAs) when solving them. Although, there exist a number of many-objective optimization evolutionary algorithms (MaOEAs) for solving MaOPs, they still face difficulties when the number of objectives of MaOPs increases. One common method to reduce or alleviate these difficulties is to use objective dimensionality reduction (or objective reduction for briefly). Moreover, instead of searching the whole of objective space like existing MOEAs or MaOEAs, Pareto Corner Search Evolutionary (PCSEA) concentrates only on some places of objective space, so it decreases time consuming and then speeds up objective reduction. However, PCSEA-based objective reduction needs to specify a threshold to select or remove objectives, which is not straightforward to do. Based on the idea that more conflict two objectives are, more distant two objectives are; in this paper, we introduce a new objective reduction by integrating PCSEA and k-means, DBSCAN clustering algorithms for solving MaOPs which are assumed containing redundant objectives. The experimental results show that the introduced method can reducing redundant objectives better than PCSEA-based objective reduction. The results further strengthen the links between evolutionary computation and machine learning to address optimization problems. © 2019 Association for Computing Machinery.","Clustering; Many-objective optimization; Objective reduction","Association for Computing Machinery"
"Pantula P.D., Mitra K.","A data-driven approach towards finding closer estimates of optimal solutions under uncertainty for an energy efficient steel casting process",2019,"Energy",22,"10.1016/j.energy.2019.116253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074407315&doi=10.1016%2fj.energy.2019.116253&partnerID=40&md5=4921984018085b5d605dd7b72fd3a7a8","The process of steel casting involves several energy-intensive tasks such as heat transfer, solidification process, etc. Though the evolution of continuous casting of steel from the conventional ingot casting enabled a high amount of energy savings, operational parameter optimization considering various avenues of uncertainty is the key for next level of improvement in energy efficiency and process sustainability. To achieve this, a multi-objective optimization formulation under uncertainty has been proposed that can lead to simultaneous maximization of productivity and minimization of energy consumption. Among various uncertainty handling techniques, Chance Constrained Programming (CCP) is considered as an efficient approach. However, the requirement of uncertain parameters to follow some well-behaved probability distribution for having a closed form analytical solution in CCP is a bottleneck for most of the practical situations due to the unknown nature of uncertain data. This paper proposes a novel methodology called DDCCP (Data-Driven CCP), to amalgamate machine learning algorithms with CCP, thereby making the approach data-driven. A novel fuzzy clustering mechanism is implemented to transcript uncertain space such that the specific regions of uncertainty are identified accurately based on given uncertain data for more realistic sampling and thereby impacting the optimal solution accuracy. Implementing DDCCP on the casting model, ∼20–70% improvement in the objectives of energy calculations and 50–100% improvement in the metrics of Pareto optimal solutions are observed as compared to the existing box sampling approach showing efficacy of the proposed methodology. © 2019 Elsevier Ltd","Continuous casting; Data-driven chance constrained programming; Energy conservation; Fuzzy clustering; Multi-objective optimization; Uncertainty","Elsevier Ltd"
"Dutta D., Sil J., Dutta P.","Automatic clustering by multi-objective genetic algorithm with numeric and categorical features",2019,"Expert Systems with Applications",19,"10.1016/j.eswa.2019.06.056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068799031&doi=10.1016%2fj.eswa.2019.06.056&partnerID=40&md5=9ffa2c9d869f8fc2ed3680436b2c6da5","Many clustering algorithms categorized as K-clustering algorithm require the user to predict the number of clusters (K) to do clustering. Due to lack of domain knowledge an accurate value of K is difficult to predict. The problem becomes critical when the dimensionality of data points is large; clusters differ widely in shape, size, and density; and when clusters are overlapping in nature. Determining the suitable K is an optimization problem. Automatic clustering algorithms can discover the optimal K. This paper presents an automatic clustering algorithm which is superior to K-clustering algorithm as it can discover an optimal value of K. Iterative hill-climbing algorithms like K-Means work on a single solution and converge to a local optimum solution. Here, Genetic Algorithms (GAs) find out near global optimum solutions, i.e. optimal K as well as the optimal cluster centroids. Single-objective clustering algorithms are adequate for efficiently grouping linearly separable clusters. For non-linearly separable clusters they are not so good. So for grouping non-linearly separable clusters, we apply Multi-Objective Genetic Algorithm (MOGA) by minimizing the intra-cluster distance and maximizing inter-cluster distance. Many existing MOGA based clustering algorithms are suitable for either numeric or categorical features. This paper pioneered employing MOGA for automatic clustering with mixed types of features. Statistical testing on experimental results on real-life benchmark data sets from the University of California at Irvine (UCI) machine learning repository proves the superiority of the proposed algorithm. © 2019 Elsevier Ltd","Automatic clustering; Multi-Objective Genetic Algorithm (MOGA); Pareto approach; Statistical test","Elsevier Ltd"
"Kazmer D.O., Hutson L., Hazen D.","MACHINE LEARNING and MULTI-OBJECTIVE OPTIMIZATION of INDUSTRIAL EXTRUSION",2020,"Annual Technical Conference - ANTEC, Conference Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124576180&partnerID=40&md5=436bdb614cfe9705df78c4aa201f6516","A three-level multivariate control system is described that transforms a vector of machine inputs to a vector of virtual process states, and then these virtual process states to key performance objectives. The multivariate system is implemented on a 150 mm (6 inch) screw diameter producing approximately 500 kg/hr of polyvinyl chloride (PVC) film having a nominal width around 1 m (39 inch) and a nominal thickness of 0.38 mm (0.149 inch). Validation is performed with respect to modeling and optimization of three performance objectives including production rate, energy efficiency, and process capability. The results suggest significant gains with respect to the Pareto optimality (efficient frontier) of energy efficiency and process capability. © 2020 Society of Plastics Engineers. All rights reserved.",,"Society of Plastics Engineers"
"Zhang D., Li Y., Tian Z., Jiang Z.","Adaptive strategy optimization with multi-agent machine learning in the game of radar countermeasure",2020,"IET Conference Publications",,"10.1049/icp.2021.0527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117705883&doi=10.1049%2ficp.2021.0527&partnerID=40&md5=3ff8901b70bcae74657b78deefd84b93","Traditional radar countermeasure usually acts with some pre-defined strategies, ignoring the dynamic changes of both sides. In this paper, the scenario of radar countermeasure is represented as a two-player zero-sum dynamic game, where each player adaptively optimizes its own strategy. Specifically, according to game theory, two effective multi-agent machine learning methods, i.e. multi-stage minimax backward induction and deep counterfactual regret minimization are utilized to obtain the final strategies for both players. The experimental results demonstrate that the learned strategies for both players are more effective and reasonable than some simple strategies. © 2020 Institution of Engineering and Technology. All rights reserved.","Deep counterfactual regret minimization; Minimax algorithm; Radar countermeasure; Two-player zero-sum game","Institution of Engineering and Technology"
"Luiken N., Van Leeuwen T.","Relaxed regularization for linear inverse problems",2020,"SIAM Journal on Scientific Computing",,"10.1137/20M1348091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113300201&doi=10.1137%2f20M1348091&partnerID=40&md5=e25b6d6fe92a4a16652e9b0f851a64cd","We consider regularized least-squares problems of the form min {equation presented}. Recently, Zheng et al. [IEEE Access, 7 (2019), pp. 1404-1423], proposed an algorithm called Sparse Relaxed Regularized Regression (SR3) that employs a splitting strategy by introducing an auxiliary variable y and solves min {equation presented}. By minimizing out the variable x, we obtain an equivalent optimization problem min {equation presented}. In our work, we view the SR3 method as a way to approximately solve the regularized problem. We analyze the conditioning of the relaxed problem in general and give an expression for the SVD of Fκ as a function of κ. Furthermore, we relate the Pareto curve of the original problem to the relaxed problem, and we quantify the error incurred by relaxation in terms of κ. Finally, we propose an efficient iterative method for solving the relaxed problem with inexact inner iterations. Numerical examples illustrate the approach. Copyright © by SIAM.","Inverse problems; Machine learning; Optimization; Regularization; Sparsity; Total variation","Society for Industrial and Applied Mathematics Publications"
"Roth W., Pernkopf F., Schindler G., Fröning H.","On resource-efficient Bayesian network classifiers and deep neural networks",2020,"Proceedings - International Conference on Pattern Recognition",,"10.1109/ICPR48806.2021.9413156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110481572&doi=10.1109%2fICPR48806.2021.9413156&partnerID=40&md5=63672f1fac2cef4325de2508c536e4e3","We present two methods to reduce the complexity of Bayesian network (BN) classifiers. First, we introduce quantization-aware training using the straight-through gradient estimator to quantize the parameters of BNs to few bits. Second, we extend a recently proposed differentiable tree-augmented naïve Bayes (TAN) structure learning approach by also considering the model size. Both methods are motivated by recent developments in the deep learning community, and they provide effective means to trade off between model size and prediction accuracy, which is demonstrated in extensive experiments. Furthermore, we contrast quantized BN classifiers with quantized deep neural networks (DNNs) for small-scale scenarios which have hardly been investigated in the literature. We show Pareto optimal models with respect to model size, number of operations, and test error and find that both model classes are viable options. © 2020 IEEE",,"Institute of Electrical and Electronics Engineers Inc."
"Liu J.Z., Lin Z., Padhy S., Tran D., Bedrax-Weiss T., Lakshminarayanan B.","Simple and principled uncertainty estimation with deterministic deep learning via distance awareness",2020,"Advances in Neural Information Processing Systems",7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108445243&partnerID=40&md5=6612c05bedc70f9b3e6bd4842bdc5d2a","Bayesian neural networks and deep ensembles are principled approaches to estimate the predictive uncertainty of a deep learning model. However their practicality in real-time, industrial-scale applications are limited due to their heavy memory and inference cost. This motivates us to study principled approaches to high-quality uncertainty estimation that require only a single deep neural network (DNN). By formalizing the uncertainty quantification as a minimax learning problem, we first identify distance awareness, i.e., the model’s ability to properly quantify the distance of a testing example from the training data manifold, as a necessary condition for a DNN to achieve high-quality (i.e., minimax optimal) uncertainty estimation. We then propose Spectral-normalized Neural Gaussian Process (SNGP), a simple method that improves the distance-awareness ability of modern DNNs, by adding a weight normalization step during training and replacing the output layer with a Gaussian Process. On a suite of vision and language understanding tasks and on modern architectures (Wide-ResNet and BERT), SNGP is competitive with deep ensembles in prediction, calibration and out-of-domain detection, and outperforms the other single-model approaches. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Poli M., Massaroli S., Yamashita A., Asama H., Park J.","Hypersolvers: Toward fast continuous-depth models",2020,"Advances in Neural Information Processing Systems",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108441630&partnerID=40&md5=864208339c9748933956b3c5c9578790","The infinite–depth paradigm pioneered by Neural ODEs has launched a renaissance in the search for novel dynamical system–inspired deep learning primitives; however, their utilization in problems of non–trivial size has often proved impossible due to poor computational scalability. This work paves the way for scalable Neural ODEs with time–to–prediction comparable to traditional discrete networks. We introduce hypersolvers, neural networks designed to solve ODEs with low overhead and theoretical guarantees on accuracy. The synergistic combination of hypersolvers and Neural ODEs allows for cheap inference and unlocks a new frontier for practical application of continuous–depth models. Experimental evaluations on standard benchmarks, such as sampling for continuous normalizing flows, reveal consistent pareto efficiency over classical numerical methods. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Dong Y., Deng Z., Pang T., Zhu J., Su H.","Adversarial distributional training for robust deep learning",2020,"Advances in Neural Information Processing Systems",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108421019&partnerID=40&md5=4f7e60aade56665e1a2dd89609d5910d","Adversarial training (AT) is among the most effective techniques to improve model robustness by augmenting training data with adversarial examples. However, most existing AT methods adopt a specific attack to craft adversarial examples, leading to the unreliable robustness against other unseen attacks. Besides, a single attack algorithm could be insufficient to explore the space of perturbations. In this paper, we introduce adversarial distributional training (ADT), a novel framework for learning robust models. ADT is formulated as a minimax optimization problem, where the inner maximization aims to learn an adversarial distribution to characterize the potential adversarial examples around a natural one under an entropic regularizer, and the outer minimization aims to train robust models by minimizing the expected loss over the worst-case adversarial distributions. Through a theoretical analysis, we develop a general algorithm for solving ADT, and present three approaches for parameterizing the adversarial distributions, ranging from the typical Gaussian distributions to the flexible implicit ones. Empirical results on several benchmarks validate the effectiveness of ADT compared with the state-of-the-art AT methods. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"McRae A.D., Romberg J., Davenport M.A.","Sample complexity and effective dimension for regression on manifolds",2020,"Advances in Neural Information Processing Systems",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108411260&partnerID=40&md5=2ad0ad68697bc95d53f78096ca33b767","We consider the theory of regression on a manifold using reproducing kernel Hilbert space methods. Manifold models arise in a wide variety of modern machine learning problems, and our goal is to help understand the effectiveness of various implicit and explicit dimensionality-reduction methods that exploit manifold structure. Our first key contribution is to establish a novel nonasymptotic version of the Weyl law from differential geometry. From this we are able to show that certain spaces of smooth functions on a manifold are effectively finite-dimensional, with a complexity that scales according to the manifold dimension rather than any ambient data dimension. Finally, we show that given (potentially noisy) function values taken uniformly at random over a manifold, a kernel regression estimator (derived from the spectral decomposition of the manifold) yields minimax-optimal error bounds that are controlled by the effective dimension. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Mousavi Kalan S.M., Fabian Z., Avestimehr S., Soltanolkotabi M.","Minimax lower bounds for transfer learning with linear and one-hidden layer neural networks",2020,"Advances in Neural Information Processing Systems",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108406474&partnerID=40&md5=462e86816576abd31aae0a88ab7672c6","Transfer learning has emerged as a powerful technique for improving the performance of machine learning models on new domains where labeled training data may be scarce. In this approach a model trained for a source task, where plenty of labeled training data is available, is used as a starting point for training a model on a related target task with only few labeled training data. Despite recent empirical success of transfer learning approaches, the benefits and fundamental limits of transfer learning are poorly understood. In this paper we develop a statistical minimax framework to characterize the fundamental limits of transfer learning in the context of regression with linear and one-hidden layer neural network models. Specifically, we derive a lower-bound for the target generalization error achievable by any algorithm as a function of the number of labeled source and target data as well as appropriate notions of similarity between the source and target tasks. Our lowerbound provides new insights into the benefits and limitations of transfer learning. We further corroborate our theoretical finding with various experiments. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Gao W., Zhou Z.-H.","Towards convergence rate analysis of random forests for classification",2020,"Advances in Neural Information Processing Systems",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108064053&partnerID=40&md5=48ffd229eece159a78e32bda25c2e334","Random forests have been one of the successful ensemble algorithms in machine learning. The basic idea is to construct a large number of random trees individually and make prediction based on an average of their predictions. The great successes have attracted much attention on the consistency of random forests, mostly focusing on regression. This work takes one step towards convergence rates of random forests for classification. We present the first finite-sample rate O(n-1/(8d+2)) on the convergence of pure random forests for classification, which can be improved to be of O(n-1/(3.87d+2)) by considering the midpoint splitting mechanism. We introduce another variant of random forests, which follow Breiman’s original random forests but with different mechanisms on splitting dimensions and positions. We get a convergence rate O(n-1/(d+2)(ln n)1/(d+2)) for the variant of random forests, which reaches the minimax rate, except for a factor (ln n)1/(d+2), of the optimal plug-in classifier under the L-Lipschitz assumption. We achieve tighter convergence rate O(pln n/n) under proper assumptions over structural data. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Luo L., Ye H., Huang Z., Zhang T.","Stochastic recursive gradient descent ascent for stochastic nonconvex-strongly-concave minimax problems",2020,"Advances in Neural Information Processing Systems",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107922521&partnerID=40&md5=dd240c668800fbc75d3657ac18103dbe","We consider nonconvex-concave minimax optimization problems of the form minx maxy?Y f(x, y), where f is strongly-concave in y but possibly nonconvex in x and Y is a convex and compact set. We focus on the stochastic setting, where we can only access an unbiased stochastic gradient estimate of f at each iteration. This formulation includes many machine learning applications as special cases such as robust optimization and adversary training. We are interested in finding an O(e)-stationary point of the function F(·) = maxy?Y f(·, y). The most popular algorithm to solve this problem is stochastic gradient decent ascent, which requires O(?3e-4) stochastic gradient evaluations, where ? is the condition number. In this paper, we propose a novel method called Stochastic Recursive gradiEnt Descent Ascent (SREDA), which estimates gradients more efficiently using variance reduction. This method achieves the best known stochastic gradient complexity of O(?3e-3), and its dependency on e is optimal for this problem. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Lakkaraju H., Arsov N., Bastani O.","Robust and stable black box explanations",2020,"37th International Conference on Machine Learning, ICML 2020",5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105590715&partnerID=40&md5=5244971c55b1ed20acd6c3386c033d1a","As machine learning black boxes are increasingly being deployed in real-world applications, there has been a growing interest in developing post hoc explanations that summarize the behaviors of these black boxes. However, existing algo_rithms for generating such explanations have been shown to lack stability and robustness to distri_bution shifts. We propose a novel framework for generating robust and stable explanations of black box models based on adversarial training. Our framework optimizes a minimax objective that aims to construct the highest fidelity explanation with respect to the worst-case over a set of adver_sarial perturbations. We instantiate this algorithm for explanations in the form of linear models and decision sets by devising the required optimiza_tion procedures. To the best of our knowledge, this work makes the first attempt at generating post hoc explanations that are robust to a general class of adversarial perturbations that are of prac_tical interest. Experimental evaluation with real_world and synthetic datasets demonstrates that our approach substantially improves robustness of ex_planations without sacrificing their fidelity on the original data distribution. © International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Lin T., Jin C., Jordan M.I.","On gradient descent ascent for nonconvex-concave minimax problems",2020,"37th International Conference on Machine Learning, ICML 2020",13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105571322&partnerID=40&md5=0b1c27583809165783b70163d4f5854f","We consider nonconvex-concave minimax problems, minxmaxy2Y f(x,y) where f is nonconvex in x but concave in y and Y is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent (GDA) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, GDA with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale GDA for solving nonconvexconcave minimax problems, showing that the algorithm can find a stationary point of the function φ maxy2Y f( y) efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale GDA in this setting, shedding light on its superior practical performance in training generative adversarial networks (GANs) and other real applications. © International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Richards D., Rebeschini P., Rosasco L.","Decentralised learning with distributed gradient descent and random features",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105347264&partnerID=40&md5=3f07920650388f115757ee1589f275ec","We investigate the generalisation performance of Distributed Gradient Descent with Implicit Regularisation and Random Features in the homogenous setting where a network of agents are given data sampled independently from the same unknown distribution. Along with reducing the memory footprint, Random Features are particularly convenient in this setting as they provide a common parameterisation across agents that allows to overcome previous difficulties in implementing Decentralised Kernel Regression. Under standard source and capacity assumptions, we establish high probability bounds on the predictive performance for each agent as a function of the step size, number of iterations, inverse spectral gap of the communication matrix and number of Random Features. By tuning these parameters, we obtain statistical rates that are minimax optimal with respect to the total number of samples in the network. The algorithm provides a linear improvement over single machine Gradient Descent in memory cost and, when agents hold enough data with respect to the network size and inverse spectral gap, a linear speed-up in computational runtime for any network topology. We present simulations that show how the number of Random Features, iterations and samples impact predictive performance. Copyright © 2020 by the Authors. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Reeve H.W.J., Kabán A.","Optimistic bounds for multi-output prediction",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105334391&partnerID=40&md5=4f95a31e1c0b8e49b48effcbd74c5e27","We investigate the challenge of multi-output learning, where the goal is to learn a vector-valued function based on a supervised data set. This includes a range of important problems in Machine Learning including multi-target regression, multi-class classification and multi-label classification. We begin our analysis by introducing the self-bounding Lipschitz condition for multioutput loss functions, which interpolates continuously between a classical Lipschitz condition and a multi-dimensional analogue of a smoothness condition. We then show that the self-bounding Lipschitz condition gives rise to optimistic bounds for multi-output learning, which attain the minimax optimal rate up to logarithmic factors. The proof exploits local Rademacher complexity combined with a powerful minoration inequality due to Srebro, Sridharan and Tewari. As an application we derive a state-of-the-art generalisation bound for multi-class gradient boosting. Copyright © 2020 by the Authors. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Zhang J., Xu X., Han B., Niu G., Cui L., Sugiyama M., Kankanhalli M.","Attacks which do not kill training make adversarial learning stronger",2020,"37th International Conference on Machine Learning, ICML 2020",7,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105322490&partnerID=40&md5=6e99952b1c309b7719291c84f91bd689","Adversarial training based on the minimax formulation is necessary for obtaining adversarial robustness of trained models. However, it is conservative or even pessimistic so that it sometimes hurts the natural generalization. In this paper, we raise a fundamental question do we have to trade off natural generalization for adversarial robustness? We argue that adversarial training is to employ confident adversarial data for updating the current model. We propose a novel formulation of friendly adversarial training (FAT): rather than employing most adversarial data maximizing the loss, we search for least adversarial data (i.e., friendly adversarial data) minimizing the loss, among the adversarial data that are confidently misclassified. Our novel formulation is easy to implement by just stopping the most adversarial data searching algorithms such as PGD (projected gradient descent) early, which we call early-stopped PGD. Theoretically, FAT is justified by an upper bound of the adversarial risk. Empirically, early-stopped PGD allows us to answer the earlier question negatively adversarial robustness can indeed be achieved without compromising the natural generalization. © 2020 by the Authors All rights reserved.",,"International Machine Learning Society (IMLS)"
"Hendrickx J., Olshevsky A., Saligrama V.","Minimax rate for learning from pairwise comparisons in the btl model",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105314589&partnerID=40&md5=054df293ec4edc6eb967cef61eaea5fb","We consider the problem of learning the qualities w1, . . . , wn of a collection of items by performing noisy comparisons among them. A standard assumption is that there is a fixed ""comparison graph""and every neighboring pair of items is compared κ times. We will study the popular Bradley-Terry-Luce model, where the probability that item i wins a comparison against j equals wi/(wi + wj ). The goal is to understand how the expected error in estimating the vector w = (w1, . . . , wn) behaves in the regime when the number of comparisons κ is large. Our contribution is the determination of the minimax rate up to a constant factor. We show that this rate is achieved by a simple algorithm based on weighted least squares, with weights determined from the empirical outcomes of the comparisons. This algorithm can be implemented in nearly linear time in the total number of comparisons. © International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Siahkamari A., Gangrade A., Kulis B., Saligrama V.","Piecewise linear regression via a difference of convex functions",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105306893&partnerID=40&md5=c34895f95ac58c9762100bfe7b457589","We present a new piecewise linear regression methodology that utilizes fitting a difference of convex functions (DC functions) to the data. These are functions f that may be represented as the differenceØ 1 Ø 2 for a choice of convex functions Ø1; Ø 2. The method proceeds by estimating piecewise-liner convex functions, in a manner similar to max-affine regression, whose difference approximates the data. The choice of the function is regularised by a new seminorm over the class of DC functions that controls the `1 Lipschitz constant of the estimate. The resulting methodology can be efficiently implemented via Quadratic programming even in high dimensions, and is shown to have close to minimax statistical risk. We empirically validate the method, showing it to be practically implementable, and to have comparable performance to existing regression/classification methods on real-world datasets. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Rolf E., Simchowitz M., Dean S., Liu L.T., Björkegren D., Hardt M., Blumenstock J.","Balancing competing objectives with noisy data: Score-based classifiers for welfare-aware machine learning",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105260725&partnerID=40&md5=404e5a02f563368d9205527c3884d0d7","While real-world decisions involve many competing objectives, algorithmic decisions are often evaluated with a single objective function. In this paper, we study algorithmic policies which explicitly trade off between a private objective (such as profit) and a public objective (such as social welfare). We analyze a natural class of policies which trace an empirical Pareto frontier based on learned scores, and focus on how such decisions can be made in noisy or data-limited regimes. Our theoretical results characterize the optimal strategies in this class, bound the Pareto errors due to inaccuracies in the scores, and show an equivalence between optimal strategies and a rich class of fairness-constrained profit-maximizing policies. We then present empirical results in two different contexts - online content recommendation and sustainable abalone fisheries - to underscore the applicability of our approach to a wide range of practical decisions. Taken together, these results shed light on inherent trade-offs in using machine learning for decisions that impact social welfare. Copyright © 2020 by the Authors. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Golovin D., Zhang Q.R.","Random hypervolume scalarizations for provable multi-objective black box optimization",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105260697&partnerID=40&md5=819e012d6931c3f99d61dbbf182fc3fc","Single-objective black box optimization (also known as zeroth-order optimization) is the process of minimizing a scalar objective f(x), given evaluations at adaptively chosen inputs x. In this paper, we consider multi-objective optimization, where f(x) outputs a vector of possibly competing objectives and the goal is to converge to the Pareto frontier. Quantitatively, we wish to maximize the standard hypervolume indicator metric, which measures the dominated hypervolume of the entire set of chosen inputs. In this paper, we introduce a novel scalarization function, which we term the hypervolume scalarization, and show that drawing random scalarizations from an appropriately chosen distribution can be used to efficiently approximate the hypervolume indicator metric. We utilize this connection to show that Bayesian optimization with our scalarization via common acquisition functions, such as Thompson Sampling or Upper Confidence Bound, provably converges to the whole Pareto frontier by deriving tight hypervolume regret bounds on the order of eO ( p T). Furthermore, we highlight the general utility of our scalarization framework by showing that any provably convergent single-objective optimization process can be effortlessly converted to a multi-objective optimization process with provable convergence guarantees. © 2020 by the Authors All rights reserved.",,"International Machine Learning Society (IMLS)"
"Jin C., Netrapalli P., Jordan M.I.","What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?",2020,"37th International Conference on Machine Learning, ICML 2020",10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105229998&partnerID=40&md5=b58fdcd00a4663f5764e52a4bd38a452","Minimax optimization has found extensive applications in modern machine learning, in settings such as generative adversarial networks (GANs), adversarial training and multi-Agent reinforcement learning. As most of these applications involve continuous nonconvex-nonconcave formulations, a very basic question arises-""what is a proper definition of local optima?"" Most previous work answers this question using classical notions of equilibria from simultaneous games, where the min-player and the max-player act simultaneously. In contrast, most applications in machine learning, including GANs and adversarial training, correspond to sequential games, where the order of which player acts first is crucial (since minimax is in general not equal to maximin due to the nonconvex-nonconcave nature of the problems). The main contribution of this paper is to propose a proper mathematical definition of local optimality for this sequential setting-local minimax, as well as to present its properties and existence results. Finally, we establish a strong connection to a basic local search algorithm-gradient descent ascent (GDA): under mild conditions, all stable limit points of GDA are exactly local minimax points up to some degenerate points. © 2020 by the Authors.",,"International Machine Learning Society (IMLS)"
"Dan C., Wei Y., Ravikumar P.","Sharp statistical guarantees for adversarially robust Gaussian classification",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105223053&partnerID=40&md5=e8f595ff83150e612bd046b99e19978a","Adversarial robustness has become a fundamental requirement in modern machine learning applications. Yet, there has been surprisingly little statistical understanding so far. In this paper, we provide the first result of the optimal minimax guarantees for the excess risk for adversarially robust classification, under Gaussian mixture model proposed by (Schmidt et al., 2018). The results are stated in terms of the Adversarial Signal-to-Noise Ratio (AdvSNR), which generalizes a similar notion for standard linear classification to the adversarial setting. For the Gaussian mixtures with AdvSNR value of r, we establish an excess risk lower bound of order Θ(e−(8 1 +o(1))r2nd ) and design a computationally efficient estimator that achieves this optimal rate. Our results built upon minimal set of assumptions while cover a wide spectrum of adversarial perturbations including ℓp balls for any p ≥ 1. © 37th International Conference on Machine Learning, ICML 2020.",,"International Machine Learning Society (IMLS)"
"Liu X., Liu Q., Song S., Peng J., Liu X.","A chance-constrained generative framework for sequence optimization",2020,"37th International Conference on Machine Learning, ICML 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105208453&partnerID=40&md5=e87d958eeda1d371a3e55cdfccfd53b3","Deep generative modeling has achieved many successes for continuous data generation, such as producing realistic images and controlling their properties (e.g., styles). However, the development of generative modeling techniques for optimizing discrete data, such as sequences or strings, still lags behind largely due to the challenges in modeling complex and long-range constraints, including both syntax and semantics, in discrete structures. In this paper, we formulate the sequence optimization task as a chance-constrained optimization problem. The key idea is to enforce a high probability of generating valid sequences and also optimize the property of interest. We propose a novel minimax algorithm to simultaneously tighten a bound of the valid chance and optimize the expected property. Extensive experimental results in three domains demonstrate the superiority of our approach over the existing sequence optimization methods. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Makkuva A.V., Taghvaei A., Lee J.D., Oh S.","Optimal transport mapping via input convex neural networks",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105203547&partnerID=40&md5=39951f981e29df2472ac6f19d4d0110c","In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization. Numerical experiments confirm the accuracy of the learned transport map. Our approach can be readily used to train a deep generative model. When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model. Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity. As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks. Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous. This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Dong K., Li Y., Zhang Q., Zhou Y.","Multinomial logit bandit with low switching cost",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105172178&partnerID=40&md5=3bab6278e20999db8fa3f8fd3fc700cc","We study multinomial logit bandit with limited adaptivity, where the algorithms change their exploration actions as infrequently as possible when achieving almost optimal minimax regret. We propose two measures of adaptivity: The assortment switching cost and the more fine-grained item switching cost. We present an anytime algorithm (AT-DUCB) with O(N log T) assortment switches, almost matching the lower bound ?( N log T log log T ). In the fixed-horizon setting, our algorithm FH-DUCB incurs O(N log log T) assortment switches, matching the asymptotic lower bound. We also present the ESUCB algorithm with item switching cost O(N log2 T). © Author(s) 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Ma P., Du T., Matusik W.","Effcient continuous pareto exploration in multi-Task learning",2020,"37th International Conference on Machine Learning, ICML 2020",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105171457&partnerID=40&md5=ea509e14b2496a0b36ce0127d8f48d1a","Tasks in multi-Task learning often correlate, confict, or even compete with each other. As a result, a single solution that is optimal for all tasks rarely exists. Recent papers introduced the concept of Pareto optimality to this feld and directly cast multi-Task learning as multi-objective optimization problems, but solutions returned by existing methods are typically fnite, sparse, and discrete. We present a novel, effcient method that generates locally continuous Pareto sets and Pareto fronts, which opens up the possibility of continuous analysis of Pareto optimal solutions in machine learning problems. We scale up theoretical results in multi-objective optimization to modern machine learning problems by proposing a sample-based sparse linear system, for which standard Hessian-free solvers in machine learning can be applied. We compare our method to the stateof-the-Art algorithms and demonstrate its usage of analyzing local Pareto sets on various multitask classifcation and regression problems. The experimental results confrm that our algorithm reveals the primary directions in local Pareto sets for trade-off balancing, fnds more solutions with different trade-offs effciently, and scales well to tasks with millions of parameters. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Dan S., Bhattacharya B.B.","Goodness-of-fit tests for inhomogeneous random graphs",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105164541&partnerID=40&md5=f973f7014ec72601bb132a113202196b","Hypothesis testing of random networks is an emerging area of modern research, especially in the high-dimensional regime, where the number of samples is smaller or comparable to the size of the graph. In this paper we consider the goodness-of-fit testing problem for large inhomogeneous random (IER) graphs, where given a (known) reference symmetric matrix Q ∈ [0, 1]n×n and m independent samples from an IER graph given by an unknown symmetric matrix P ∈ [0, 1]n×n, the goal is to test the hypothesis P = Q versus ||P − Q|| ≥ ε, where ||· || is some specified norm on symmetric matrices. Building on recent related work on two-sample testing for IER graphs, we derive the optimal minimax sample complexities for the goodness-of-fit problem in various natural norms, such as the Frobenius norm and the operator norm. We also propose practical implementations of natural test statistics, using their asymptotic distributions and through the parametric bootstrap. We compare the performances of the different tests in simulations, and show that the proposed tests outperform the baseline tests across various natural random graphs models. © 37th International Conference on Machine Learning, ICML 2020.",,"International Machine Learning Society (IMLS)"
"Martinez N., Bertran M., Sapiro G.","Minimax pareto fairness: A multi objective perspective",2020,"37th International Conference on Machine Learning, ICML 2020",8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105164382&partnerID=40&md5=b1a8e3cbd669726bdc058fbd4295ab7a","In this work we formulate and formally characterize group fairness as a multi-objective optimization problem, where each sensitive group risk is a separate objective. We propose a fairness criterion where a classifier achieves minimax risk and is Pareto-efficient w.r.t. all groups, avoiding unnecessary harm, and can lead to the best zero-gap model if policy dictates so. We provide a simple optimization algorithm compatible with deep neural networks to satisfy these constraints. Since our method does not require test-Time access to sensitive attributes, it can be applied to reduce worst-case classification errors between outcomes in unbalanced classification problems. We test the proposed methodology on real case-studies of predicting income, ICU patient mortality, skin lesions classification, and assessing credit risk, demonstrating how our framework compares favorably to other approaches. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Bilodeau B., Foster D.J., Roy D.M.","Tight bounds on minimax regret under logarithmic loss via self-concordance",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105139642&partnerID=40&md5=e31ee17a0798182745e1faa932b122cc","We consider the classical problem of sequential probability assignment under logarithmic loss while competing against an arbitrary, potentially nonparametric class of experts. We obtain tight bounds on the minimax regret via a new approach that exploits the self-concordance property of the logarithmic loss. We show that for any expert class with (sequential) metric entropy O(γ-p) at scale γ, the minimax regret is O(n p p+1 ), and that this rate cannot be improved without additional assumptions on the expert class under consideration. As an application of our techniques, we resolve the minimax regret for nonparametric Lipschitz classes of experts. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Yang J., Kiyavash N., He N.","Global convergence and variance reduction for a class of nonconvex-nonconcave minimax problems",2020,"Advances in Neural Information Processing Systems",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104821606&partnerID=40&md5=8916b9daf749534c1de8c10bd1934c41","Nonconvex minimax problems appear frequently in emerging machine learning applications, such as generative adversarial networks and adversarial learning. Simple algorithms such as the gradient descent ascent (GDA) are the common practice for solving these nonconvex games and receive lots of empirical success. Yet, it is known that these vanilla GDA algorithms with constant stepsize can potentially diverge even in the convex-concave setting. In this work, we show that for a subclass of nonconvex-nonconcave objectives satisfying a so-called two-sided Polyak-Łojasiewicz inequality, the alternating gradient descent ascent (AGDA) algorithm converges globally at a linear rate and the stochastic AGDA achieves a sublinear rate. We further develop a variance reduced algorithm that attains a provably faster rate than AGDA when the problem has the finite-sum structure. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Xu D., Ruan C., Korpeoglu E., Kumar S., Achan K.","Adversarial counterfactual learning and evaluation for recommender system",2020,"Advances in Neural Information Processing Systems",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104405238&partnerID=40&md5=f1a92b0b65139a82ae1b8e7df8f04812","The feedback data of recommender systems are often subject to what was exposed to the users; however, most learning and evaluation methods do not account for the underlying exposure mechanism. We first show in theory that applying supervised learning to detect user preferences may end up with inconsistent results in the absence of exposure information. The counterfactual propensity-weighting approach from causal inference can account for the exposure mechanism; nevertheless, the partial-observation nature of the feedback data can cause identifiability issues. We propose a principled solution by introducing a minimax empirical risk formulation. We show that the relaxation of the dual problem can be converted to an adversarial game between two recommendation models, where the opponent of the candidate model characterizes the underlying exposure mechanism. We provide learning bounds and conduct extensive simulation studies to illustrate and justify the proposed approach over a broad range of recommendation settings, which shed insights on the various benefits of the proposed approach. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Xie G., Luo L., Lian Y., Zhang Z.","Lower complexity bounds for finite-sum convex-concave minimax optimization problems",2020,"37th International Conference on Machine Learning, ICML 2020",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104196572&partnerID=40&md5=a0112d4100f3efd9e2143cce0e800d98","This paper studies the lower bound complexity for minimax optimization problem whose objective function is the average of n individual smooth convex-concave functions. We consider the algorithm which has access to gradient and proximal oracle for each individual component. For the strongly-convex-strongly-concave case, we prove such an algorithm can not reach an ε-saddle point in fewer than Ω ((n + κ) log(1/ε)) iterations, where κ is the condition number of the objective function. This lower bound matches the upper bound of the existing proximal incremental first-order oracle algorithm in some specific case. We develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into n groups. This construction is friendly to the analysis of incremental gradient and proximal oracle and we also extend the analysis to general convex-concave cases. Copyright 2020 by the author(s).",,"International Machine Learning Society (IMLS)"
"Acharya J., Bonawitz K.A., Bonawitz@google.com, Kairouz P., Ramage D., Sun Z.","Context-Aware local differential privacy",2020,"37th International Conference on Machine Learning, ICML 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103272924&partnerID=40&md5=516620c2770a7ab3bb3feac5d5911e0e","Local differential privacy (LDP) is a strong notion of privacy that often leads to a significant drop in utility. The original definition of LDP assumes that all the elements in the data domain are equally sensitive. However, in many reallife applications, some elements are more sensitive than others. We propose a context-Aware framework for LDP that allows the privacy level to vary across the data domain, enabling system designers to place privacy constraints where they matter without paying the cost where they do not. For binary data domains, we provide a universally optimal privatization scheme and highlight its connections to Warner s randomized response and Mangat s improved response. Motivated by geo-location and web search applications, for k-Ary data domains, we consider two special cases of context-Aware LDP: blockstructured LDP and high-low LDP. We study minimax discrete distribution estimation under both cases and provide communication-efficient, sample-optimal schemes and information theoretic lower bounds. We show, using worst-case analyses and experiments on Gowalla s 3.6 million check-ins to 43,750 locations, that contextaware LDP achieves a far better accuracy under the same number of samples. © ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Woodworth B., Patel K.K., Stich S.U., Dai Z., Bullins B., Brendan McMahan H., Shamir O., Srebro N.","Is local SGD better than minibatch SGD?",2020,"37th International Conference on Machine Learning, ICML 2020",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103220530&partnerID=40&md5=c40ad9fec82b1138ea086ddac61003b5","We study local SGD (also known as parallel SGD and federated averaging), a natural and frequently used stochastic distributed optimization method. Its theoretical foundations are currently lacking and we highlight how all existing error guarantees in the convex setting are dominated by a simple baseline, minibatch SGD. (1) For quadratic objectives we prove that local SGD strictly dominates minibatch SGD and that accelerated local SGD is minimax optimal for quadratics; (2) For general convex objectives we provide the first guarantee that at least sometimes improves over minibatch SGD; (3) We show that indeed local SGD does not dominate minibatch SGD by presenting a lower bound on the performance of local SGD that is worse than the minibatch SGD guarantee. Copyright 2020 by the author(s).",,"International Machine Learning Society (IMLS)"
"Abdelrahman O., Keikhosrokiani P.","Assembly line anomaly detection and root cause analysis using machine learning",2020,"IEEE Access",6,"10.1109/ACCESS.2020.3029826","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102841434&doi=10.1109%2fACCESS.2020.3029826&partnerID=40&md5=49d5da8fec2ce61707a0e949d962bccf","Anomaly detection is becoming widely used in Manufacturing Industry to enhance product quality. At the same time, it plays a great role in several other domains due to the fact that anomaly may reveal rare but represent an important phenomenon. The objective of this paper is to detect anomalies and identify the possible variables that caused these anomalies on historical assembly data for two series of products. Multiple anomaly detection techniques were performed; HBOS, IForest, KNN, CBLOF, OCSVM, LOF, and ABOD. Moreover, we used AUROC and Rank Power as performance metrics, followed by Boosting ensemble learning method to ensure the best anomaly detectors robustness. The techniques that gave the highest performance are KNN, ABOD for both product series datasets with 0.95 and 0.99 AUROC respectively. Finally, we applied a statistical root cause analysis on the detected anomalies with the use of Pareto chart to visualize the frequency of the possible causes and its cumulative occurrence. The results showed that there are seven rejection causes for both product series, whereas the first three causes are responsible for 85% of the rejection rates. Besides, assembly machines engineers reported a significant reduction in the rejection rates in both assembly machines after tuning the specification limits of the rejection causes identified by this research results. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Anomaly detection; Assembly lines; Big data; Machine learning; Manufacturing industries; Root cause analysis; Unsupervised learning","Institute of Electrical and Electronics Engineers Inc."
"Gnansambandam A., Chan S.H.","One size fits all: Can we train one denoiser for all noise levels?",2020,"37th International Conference on Machine Learning, ICML 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102362959&partnerID=40&md5=53471c01b877fed4f487d72fe559c621","When training an estimator such as a neural network for tasks like image denoising, it is often preferred to train one estimator and apply it to all noise levels. The de facto training protocol to achieve this goal is to train the estimator with noisy samples whose noise levels are uniformly distributed across the range of interest. However, why should we allocate the samples uniformly? Can we have more training samples that are less noisy, and fewer samples that are more noisy? What is the optimal distribution? How do we obtain such a distribution? The goal of this paper is to address this training sample distribution problem from a minimax risk optimization perspective. We derive a dual ascent algorithm to determine the optimal sampling distribution of which the convergence is guaranteed as long as the set of admissible estimators is closed and convex. For estimators with non-convex admissible sets such as deep neural networks, our dual formulation converges to a solution of the convex relaxation. We discuss how the algorithm can be implemented in practice. We evaluate the algorithm on linear estimators and deep networks. Copyright 2020 by the author(s).",,"International Machine Learning Society (IMLS)"
"Farnia F., Ozdaglar A.","Do GANs always have Nash equilibria?",2020,"37th International Conference on Machine Learning, ICML 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102163408&partnerID=40&md5=93f996d232ef88d4e0906807794ebde8","Generative adversarial networks (GANs) represent a zero-sum game between two machine players, a generator and a discriminator, designed to learn the distribution of data. While GANs have achieved state-of-the-art performance in several benchmark learning tasks, GAN minimax optimization still poses great theoretical and empirical challenges. GANs trained using first-order optimization methods commonly fail to converge to a stable solution where the players cannot improve their objective, i.e., the Nash equilibrium of the underlying game. Such issues raise the question of the existence of Nash equilibria in GAN zero-sum games. In this work, we show through theoretical and numerical results that indeed GAN zero-sum games may have no Nash equilibria. To characterize an equilibrium notion applicable to GANs, we consider the equilibrium of a new zerosum game with an objective function given by a proximal operator applied to the original objective, a solution we call the proximal equilibrium. Unlike the Nash equilibrium, the proximal equilibrium captures the sequential nature of GANs, in which the generator moves first followed by the discriminator. We prove that the optimal generative model in Wasserstein GAN problems provides a proximal equilibrium. Inspired by these results, we propose a new approach, which we call proximal training, for solving GAN problems. We perform several numerical experiments indicating the existence of proximal equilibria in GANs. © Author(s) 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Galindez Olascoaga L.I., Meert W., Shah N., Verhelst M.","Dynamic Complexity Tuning for Hardware-Aware Probabilistic Circuits",2020,"Communications in Computer and Information Science",,"10.1007/978-3-030-66770-2_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101513036&doi=10.1007%2f978-3-030-66770-2_21&partnerID=40&md5=85e34b1207df18d386a282a8297f8c48","Probabilistic inference is a well suited approach to address the challenges of resource constrained embedded application scenarios. In particular, probabilistic models learned generatively are robust to missing data and are capable of encoding domain knowledge seamlessly. These traits have been leveraged to propose hardware-aware probabilistic learning and inference strategies that induce Pareto optimal accuracy versus resource consumption trade-offs. This paper proposes a model-complexity tuning strategy that relies on ensembles of probabilistic classifiers to identify the difficulty of the classification task on a given instance. It then dynamically switches to a higher or lower complexity setting accordingly. The strategy is evaluated on an embedded human activity recognition scenario and demonstrates a superior performance when compared to the Pareto-optimal trade-off obtained when the ensembles are deployed statically, especially in low cost regions of the trade-off space. This makes the strategy amenable to embedded computing scenarios, where one of the main constraints towards always-on functionality are the device’s strict resource constraints. © 2020, Springer Nature Switzerland AG.","Hardware-aware probabilistic models; Probabilistic circuits; Resource constrained embedded applications","Springer Science and Business Media Deutschland GmbH"
"Ferragina P., Lillo F., Vinciguerra G.","Why are learned indexes so effective?",2020,"37th International Conference on Machine Learning, ICML 2020",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101465807&partnerID=40&md5=3ee170f31456cfcad372334f1b83dd04","A recent trend in algorithm design consists of augmenting classic data structures with machine learning models, which are better suited to reveal and exploit patterns and trends in the input data so to achieve outstanding practical improvements in space occupancy and time efficiency. This is especially known in the context of indexing data structures where, despite few attempts in evaluating their asymptotic efficiency, theoretical results are yet missing in showing that learned indexes are provably better than classic indexes, such as B+-trees and their variants. In this paper, we present the first mathematically-grounded answer to this open problem. We obtain this result by discovering and exploiting a link between the original problem and a mean exit time problem over a proper stochastic process which, we show, is related to the space and time occupancy of those learned indexes. Our general result is then specialised to five well-known distributions: Uniform, Lognormal, Pareto, Exponential, and Gamma; and it is corroborated in precision and robustness by a large set of experiments. © Author(s) 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Wang H., Denton B.T.","Pareto-Weighted-Sum-Tuning: Learning-to-Rank for Pareto Optimization Problems",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-64580-9_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101315371&doi=10.1007%2f978-3-030-64580-9_39&partnerID=40&md5=52ef230e3f72049d6fbae5cefc323892","The weighted-sum method is a commonly used technique in Multi-objective optimization to represent different criteria considered in a decision-making and optimization problem. Weights are assigned to different criteria depending on the degree of importance. However, even if decision-makers have an intuitive sense of how important each criteria is, explicitly quantifying and hand-tuning these weights can be difficult. To address this problem, we propose the Pareto-Weighted-Sum-Tuning algorithm as an automated and systematic way of trading-off between different criteria in the weight-tuning process. Pareto-Weighted-Sum-Tuning is a configurable online-learning algorithm that uses sequential discrete choices by a decision-maker on sequential decisions, eliminating the need to score items or weights. We prove that utilizing our online-learning approach is computationally less expensive than batch-learning, where all the data is available in advance. Our experiments show that Pareto-Weighted-Sum-Tuning is able to achieve low relative error with different configurations. © 2020, Springer Nature Switzerland AG.","Information retrieval; Machine learning; Multi-objective optimization; Online learning","Springer Science and Business Media Deutschland GmbH"
"Zhao H., Chi J., Tian Y., Gordon G.J.","Trade-offs and guarantees of adversarial representation learning for information obfuscation",2020,"Advances in Neural Information Processing Systems",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101118156&partnerID=40&md5=afc43c4f4a851f1b9949081103fd3a57","Crowdsourced data used in machine learning services might carry sensitive information about attributes that users do not want to share. Various methods have been proposed to minimize the potential information leakage of sensitive attributes while maximizing the task accuracy. However, little is known about the theory behind these methods. In light of this gap, we develop a novel theoretical framework for attribute obfuscation. Under our framework, we propose a minimax optimization formulation to protect the given attribute and analyze its inference guarantees against worst-case adversaries. Meanwhile, it is clear that in general there is a tension between minimizing information leakage and maximizing task accuracy. To understand this, we prove an information-theoretic lower bound to precisely characterize the fundamental trade-off between accuracy and information leakage. We conduct experiments on two real-world datasets to corroborate the inference guarantees and validate this trade-off. Our results indicate that, among several alternatives, the adversarial learning approach achieves the best trade-off in terms of attribute obfuscation and accuracy maximization. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Suzuki S., Takeno S., Tamura T., Shitara K., Karasuyama M.","Multi-objective Bayesian Optimization using Pareto-frontier Entropy",2020,"37th International Conference on Machine Learning, ICML 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100494558&partnerID=40&md5=08ce4cecefa14cfb0025a717993e4862","This paper studies an entropy-based multi-objective Bayesian optimization (MBO). Exist-ing entropy-based MBO methods need compli-cated approximations to evaluate entropy or em-ploy over-simplification that ignores trade-off among objectives. We propose a novel entropy-based MBO called Pareto-frontier entropy search (PFES), which is based on the information gain of Pareto-frontier. We show that our entropy evaluation can be reduced to a closed form whose computation is quite simple while capturing the trade-off relation in Pareto-frontier. We further propose an extension for the ""decoupled"" set-ting, in which each objective function can be ob-served separately, and show that the PFES-based approach derives a natural extension of the origi-nal acquisition function which can also be evalu- A ted simply. Our numerical experiments show ef-fectiveness of PFES through several benchmark datasets, and real-word datasets from materials science. © 2020 37th International Conference on Machine Learning, ICML 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Dhouib S., Redko I., Kerdoncuff T., Emonet R., Sebban M.","A swiss army knife for minimax optimal transport",2020,"37th International Conference on Machine Learning, ICML 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100484086&partnerID=40&md5=2a199373e7d525249613915d4bbdc8c4","The Optimal transport (OT) problem and its associated Wasserstein distance have recently become a topic of great interest in the machine learning community. However, its underlying optimization problem is known to have two major restrictions: (i) it strongly depends on the choice of the cost function and (ii) its sample complexity scales exponentially with the dimension. In this paper, we propose a general formulation of a minimax OT problem that can tackle these limitations by jointly optimizing the cost matrix and the transport plan, allowing us to define a robust distance between distributions. We propose to use a cutting-set method to solve this general problem and show its links and advantages compared to other existing minimax OT approaches. Additionally, we use this method to define a notion of stability allowing us to select the ground metric robust to bounded perturbations. Finally, we provide an experimental study highlighting the efficiency of our approach. © Author(s) 2020. All rights reserved.",,"International Machine Learning Society (IMLS)"
"Lin Y., McPhee J., Azad N.L.","Anti-Jerk On-Ramp Merging Using Deep Reinforcement Learning",2020,"IEEE Intelligent Vehicles Symposium, Proceedings",3,"10.1109/IV47402.2020.9304647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099877418&doi=10.1109%2fIV47402.2020.9304647&partnerID=40&md5=c09071ab0f552e7dab36394195c3d0b0","Deep Reinforcement Learning (DRL) is used here for decentralized decision-making and longitudinal control for high-speed on-ramp merging. The DRL environment state includes the states of five vehicles: the merging vehicle, along with two preceding and two following vehicles when the merging vehicle is or is projected on the main road. The control action is the acceleration of the merging vehicle. Deep Deterministic Policy Gradient (DDPG) is the DRL algorithm for training to output continuous control actions. We investigated the relationship between collision avoidance for safety and jerk minimization for passenger comfort in the multi-objective reward function by obtaining the Pareto front. We found that, with a small jerk penalty in the multi-objective reward function, the vehicle jerk could be reduced by 73% compared with no jerk penalty while the collision rate was maintained at zero. Regardless of the jerk penalty, the merging vehicle exhibited decision-making strategies such as merging ahead or behind a main-road vehicle. © 2020 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Suzuki T.","Generalization bound of globally optimal non-convex neural network training: Transportation map estimation by infinite dimensional Langevin dynamics",2020,"Advances in Neural Information Processing Systems",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099864506&partnerID=40&md5=4fc1ffb4b790f77f0fc2b25f91d7916a","We introduce a new theoretical framework to analyze deep learning optimization with connection to its generalization error. Existing frameworks such as mean field theory and neural tangent kernel theory for neural network optimization analysis typically require taking limit of infinite width of the network to show its global convergence. This potentially makes it difficult to directly deal with finite width network; especially in the neural tangent kernel regime, we cannot reveal favorable properties of neural networks beyond kernel methods. To realize more natural analysis, we consider a completely different approach in which we formulate the parameter training as a transportation map estimation and show its global convergence via the theory of the infinite dimensional Langevin dynamics. This enables us to analyze narrow and wide networks in a unifying manner. Moreover, we give generalization gap and excess risk bounds for the solution obtained by the dynamics. The excess risk bound achieves the so-called fast learning rate. In particular, we show an exponential convergence for a classification problem and a minimax optimal rate for a regression problem. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Biedermann T.M., Reich M., Paschereit C.O.","Multi-objective modelling of leading edge serrations applied to low-pressure axial fans",2020,"Proceedings of the ASME Turbo Expo",,"10.1115/GT2020-14400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099793286&doi=10.1115%2fGT2020-14400&partnerID=40&md5=32a84fb136474caff9e146d50819b995","A novel modelling strategy is proposed which allows high-accuracy predictions of aerodynamic and aeroacoustic target values for a low-pressure axial fan, equipped with serrated leading edges. Inspired by machine learning processes, the sampling of the experimental space is realized by use of a Latin hypercube design plus a factorial design, providing highly diverse information on the analyzed system. The effects of four influencing parameters are tested, characterizing the inflow conditions as well as the serration geometry. A total of 65 target values in the time and frequency domains are defined and can be approximated with high accuracy by individual artificial neural networks. Furthermore, the validation of the model against fully independent test points within the experimental space yields a remarkable fit, even for the spectral distribution in 1/3rd-octave bands, proving the ability of the model to generalize. A meta-heuristic multi-objective optimization approach provides two-dimensional Pareto optimal solutions for selected pairs of target values. This is particularly important for reconciling opposing trends, such as the noise reduction capability and aerodynamic performance. The chosen optimization strategy also allows for a customized design of serrated leading edges, tailored to the specific operating conditions of the axial fan. © 2020 ASME","Aeroacoustic modelling; Artificial neural networks; Leading edge serrations; Low-pressure axial fans; Multi-objective optimization","American Society of Mechanical Engineers (ASME)"
"Hamer V., Dupont P.","Joint optimization of predictive performance and selection stability",2020,"ESANN 2020 - Proceedings, 28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098933105&partnerID=40&md5=a973495230406872f016dadd6fbc6b3f","Current feature selection methods, especially applied to high dimensional data, tend to suffer from instability since marginal modifica- tions in the data may result in largely distinct selected feature sets. Such instability strongly limits a sound interpretation of the selected variables by domain experts. We address this issue by optimizing jointly the pre- dictive accuracy and selection stability and by deriving Pareto-optimal trajectories. Our approach extends the Recursive Feature Elimination al- gorithm by enforcing the selection of some features based on a stable, univariate criterion. Experiments conducted on several high dimensional microarray datasets illustrate that large stability gains are obtained with no significant drop of accuracy. © ESANN 2020 - Proceedings, 28th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning.",,"ESANN (i6doc.com)"
"Tran-Dinh Q., Liu D., Nguyen L.M.","Hybrid variance-reduced SGD algorithms for minimax problems with nonconvex-linear function",2020,"Advances in Neural Information Processing Systems",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098747208&partnerID=40&md5=838e528427a9ff60f75c385672e49b09","We develop a novel and single-loop variance-reduced algorithm to solve a class of stochastic nonconvex-convex minimax problems involving a nonconvex-linear objective function, which has various applications in different fields such as machine learning and robust optimization. This problem class has several computational challenges due to its nonsmoothness, nonconvexity, nonlinearity, and non-separability of the objective functions. Our approach relies on a new combination of recent ideas, including smoothing and hybrid biased variance-reduced techniques. Our algorithm and its variants can achieve O(T-2/3)-convergence rate and the best known oracle complexity under standard assumptions, where T is the iteration counter. They have several computational advantages compared to existing methods such as simple to implement and less parameter tuning requirements. They can also work with both single sample or mini-batch on derivative estimators, and with constant or diminishing step-sizes. We demonstrate the benefits of our algorithms over existing methods through two numerical examples, including a nonsmooth and nonconvex-non-strongly concave minimax model. © 2020 Neural information processing systems foundation. All rights reserved.",,"Neural information processing systems foundation"
"Telnov V., Korovin Y.","Machine learning and text analysis in the tasks of knowledge graphs refinement and enrichment",2020,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098723055&partnerID=40&md5=8ade9f0b32d217eeb5b28dd50440ae57","Working prototypes of the scalable semantic web portals, which are deployed on cloud platforms and intended for use in universities educational activity, are discussed. The first project is related to teaching in the field of nuclear physics and nuclear power engineering. The second project is related to training in computer science and programming. The possibility of using the DLLearner software in conjunction with the Apache Jena Reasoners in order to refine the ontologies that are designed on the basis of the SROIQ(D) description logic is shown. A software agent for the context-sensitive searching for new knowledge in the WWW has been developed as a toolkit for ontologies enrichment. The binary Pareto relation and Levenshtein metrics are used in order to evaluate the measure of compliance of the found content concerning a specific domain. It allows the knowledge engineer to calculate the measure of the proximity of an arbitrary network resource about classes and objects of specific knowledge graphs. The suggested software solutions are based on cloud computing using DBaaS and PaaS service models to ensure the scalability of data warehouses and network services. Examples of applying the software and technologies under discuss are given. © 2020 CEUR-WS. All rights reserved.","Cloud Computing; Context-Sensitive Search; Education; Knowledge Database; Ontology Engineering; Semantic Annotation","CEUR-WS"
"Chérief-Abdellatif B.-E.","Convergence rates of variational inference in sparse deep learning",2020,"37th International Conference on Machine Learning, ICML 2020",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098108239&partnerID=40&md5=52d0ceb2fbe1c2c2c6c124f7158063b0","Variational inference is becoming more and more popular for approximating intractable posterior distributions in Bayesian statistics and machine learning. Meanwhile, a few recent works have provided theoretical justification and new insights on deep neural networks for estimating smooth functions in usual settings such as nonparametric regression. In this paper, we show that variational inference for sparse deep learning retains precisely the same generalization properties than exact Bayesian inference. In particular, we show that a wise choice of the neural network architecture leads to near-minimax rates of convergence for Hölder smooth functions. Additionally, we show that the model selection framework over the architecture of the network via ELBO maximization does not overfit and adaptively achieves the optimal rate of convergence. © 37th International Conference on Machine Learning, ICML 2020.",,"International Machine Learning Society (IMLS)"
"Petukhov A.","The concept of smart hydrocarbons and smart reservoirs in the development of oil and gas fields in karst-fractured carbonate reservoirs",2020,"Society of Petroleum Engineers - Abu Dhabi International Petroleum Exhibition and Conference 2020, ADIP 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097566301&partnerID=40&md5=e4c335f12b4b9164621bb207693c3cb0","Our studies undertaken at many oil and gas fields in different basins show that fractures separate reservoir rocks into differently-sized blocks that are complex self-similar fractal structures whose behavior is described by Pareto's common universal law. Based on this law, a fractal model of fractured reservoir was developed. It includes several hierarchical levels of matrix blocks and fractures, sometimes ten and more. In the proposed model, not only the sizes of the blocks are in the ratio of 1.618, and permeability of the fractures changes in the ratio of 1.618, which allows to reproduce the daily and cumulative oil and gas well production according to power law distribution and Pareto's law. According to the laws the article deals with one of the development paths which we proposed to call ""intensive"" [15]. Currently, this path of development is almost ignord by oil and gas companies, which, in order to increase the capitalization of their assets, are aimed at using modern digital technologies, using the capabilities of artificial intelligence, big data, neural networks and machine learning, etc. However, we believe that the path can make a significant economic and environmental contribution to the development of hard-to-recover resources in tight fractured carbonate reservoirs. The proposed development path is based on an understanding of the ""smart"" nature phenomenology and training of modern creative professionals in the base oil and gas universities. This development path allows to substantially reduce expenses while obtaining higher daily and cumulative production of hydrocarbons and preserving the natural potential of fractured reservoirs created by the nature itself. Today's specialists working on development of information technologies call this development path ""nature-like technologies"". However, considering natural fractured oil and gas reservoirs, we can talk about a purely natural phenomenon. © 2020, Society of Petroleum Engineers",,"Society of Petroleum Engineers"
"Shalit N., Fire M., Ben-Elia E.","Imputation of Missing Boarding Stop Information in Smart Card Data with Machine Learning Methods",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-62362-3_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097428137&doi=10.1007%2f978-3-030-62362-3_3&partnerID=40&md5=5384d3fddcfd11bc1073fa2bf51dab66","With the increase in population densities and environmental awareness, public transport has become an important aspect of urban life. Consequently, large quantities of transportation data are generated, and mining data from smart card use has become a standardized method to understand the travel habits of passengers. Increase in available data and computation power demands more sophisticated methods to analyze big data. Public transport datasets, however, often lack data integrity. Boarding stop information may be missing either due to imperfect acquirement processes or inadequate reporting. As a result, large quantities of observations and even complete sections of cities might be absent from the smart card database. We have developed a machine (supervised) learning method to impute missing boarding stops based on ordinal classification. In addition, we present a new metric, Pareto Accuracy, to evaluate algorithms where classes have an ordinal nature. Results are based on a case study in the city of Beer Sheva utilizing one month of data. We show that our proposed method significantly outperforms schedule-based imputation methods and can improve the accuracy and usefulness of large-scale transportation data. The implications for data imputation of smart card information is further discussed. © 2020, Springer Nature Switzerland AG.","Boarding stop imputation; Machine learning; Smart card","Springer Science and Business Media Deutschland GmbH"
"Dbouk H., Sanghvi H., Mehendale M., Shanbhag N.","DBQ: A Differentiable Branch Quantizer for Lightweight Deep Neural Networks",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-58583-9_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097421579&doi=10.1007%2f978-3-030-58583-9_6&partnerID=40&md5=7c4b7ed8ba6ee3d6bf5f8d2d500dbac3","Deep neural networks have achieved state-of-the art performance on various computer vision tasks. However, their deployment on resource-constrained devices has been hindered due to their high computational and storage complexity. While various complexity reduction techniques, such as lightweight network architecture design and parameter quantization, have been successful in reducing the cost of implementing these networks, these methods have often been considered orthogonal. In reality, existing quantization techniques fail to replicate their success on lightweight architectures such as MobileNet. To this end, we present a novel fully differentiable non-uniform quantizer that can be seamlessly mapped onto efficient ternary-based dot product engines. We conduct comprehensive experiments on CIFAR-10, ImageNet, and Visual Wake Words datasets. The proposed quantizer (DBQ) successfully tackles the daunting task of aggressively quantizing lightweight networks such as MobileNetV1, MobileNetV2, and ShuffleNetV2. DBQ achieves state-of-the art results with minimal training overhead and provides the best (pareto-optimal) accuracy-complexity trade-off. © 2020, Springer Nature Switzerland AG.","Deep learning; Low-complexity neural networks; Quantization","Springer Science and Business Media Deutschland GmbH"
"Xiong Y., Hsieh C.-J.","Improved Adversarial Training via Learned Optimizer",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-030-58598-3_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097374633&doi=10.1007%2f978-3-030-58598-3_6&partnerID=40&md5=77bac96944f7fcd1db7ddde0107fe0f2","Adversarial attack has recently become a tremendous threat to deep learning models. To improve the robustness of machine learning models, adversarial training, formulated as a minimax optimization problem, has been recognized as one of the most effective defense mechanisms. However, the non-convex and non-concave property poses a great challenge to the minimax training. In this paper, we empirically demonstrate that the commonly used PGD attack may not be optimal for inner maximization, and improved inner optimizer can lead to a more robust model. Then we leverage a learning-to-learn (L2L) framework to train an optimizer with recurrent neural networks, providing update directions and steps adaptively for the inner problem. By co-training optimizer’s parameters and model’s weights, the proposed framework consistently improves over PGD-based adversarial training and TRADES. © 2020, Springer Nature Switzerland AG.","Adversarial training; Learning to learn; Optimization","Springer Science and Business Media Deutschland GmbH"
"Daksha C.M., Yeon J., Chowdhury S.C., Gillespie J.W., JR.","Parametrization of reactive potential using genetic algorithm and machine learning techniques",2020,"Proceedings of the American Society for Composites - 35th Technical Conference, ASC 2020",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097271558&partnerID=40&md5=0e969ea54d9868f9839c39389a7cce98","Multi-scale modeling of composites spans many length scales ranging from atomistic to the continuum level. At the lower length scales, classical molecular dynamics (MD) provides insight into the failure mechanisms in the fiber, matrix, and the interphase region that forms during processing. MD requires selection of an accurate potential energy model to describe the system. Proper usage of the potential energy model requires parameter optimization of the model’s numerous parameters with respect to experimental geometric and energetic constraints. Parametrization of a potential model can be problematic due to its time-consuming and labor-intensive nature. The goal of this work is to develop a machine learning inspired evolutionary parametrization technique to decrease the time cost and diminish the human intervention required in the parametrization process. The evolutionary genetic algorithm is employed to optimize the parameters of the ReaxFF interatomic potential. Several augmentations are implemented using machine learning techniques. The utilization of an artificial neural network as a surrogate for the ReaxFF potential is considered. Changes to the genetic algorithm are incrementally benchmarked for accuracy and time cost with respect to a simple zinc-oxide model. Utilizing the artificial neural network significantly boosted performance, as measured by the final total error and the rate of decrease of total error with respect to time. The double-Pareto probability density-based crossover operator and a multiple standard deviation based Gaussian mutation scheme outperform their counterparts. The computational time cost to achieve the same level of accuracy relative to manual training is decreased from months to days. © ASC 2020.",,"DEStech Publications"
"Butler M., Fan Y., Faloutsos C.","FraudFox: Adaptable Fraud Detection in the Real World",2020,"Communications in Computer and Information Science",,"10.1007/978-3-030-59621-7_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096599750&doi=10.1007%2f978-3-030-59621-7_3&partnerID=40&md5=48dd649a2a399ad265c49739ece211c0","The proposed method (FraudFox) provides solutions to adversarial attacks in a resource constrained environment. We focus on questions like the following: How suspicious is ‘Smith’, trying to buy $500 shoes, on Monday 3am? How to merge the risk scores, from a handful of risk-assessment modules (‘oracles’) in an adversarial environment? More importantly, given historical data (orders, prices, and what-happened afterwards), and business goals/restrictions, which transactions, like the ‘Smith’ transaction above, which ones should we ‘pass’, versus send to human investigators? The business restrictions could be: ‘at most x investigations are feasible’, or ‘at most $y lost due to fraud’. These are the two research problems we focus on, in this work. One approach to address the first problem (‘oracle-weighting’), is by using Extended Kalman Filters with dynamic importance weights, to automatically and continuously update our weights for each ‘oracle’. For the second problem, we show how to derive an optimal decision surface, and how to compute the Pareto optimal set, to allow what-if questions. An important consideration is adaptation: Fraudsters will change their behavior, according to our past decisions; thus, we need to adapt accordingly. The resulting system, FraudFox, is scalable, adaptable to changing fraudster behavior, effective, and already in production at Amazon. FraudFox augments a fraud prevention sub-system and has led to significant performance gains. © 2020, Springer Nature Switzerland AG.","Adversarial learning; Ensemble modeling; Fraud detection; Kalman filters","Springer Science and Business Media Deutschland GmbH"
"Turnea M., Arotaritei D., Fuior R.","Intelligent algorithms with selection of hyperparameters for e-health applications powered by 5g wireless networks",2020,"eLearning and Software for Education Conference",,"10.12753/2066-026X-20-205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096537939&doi=10.12753%2f2066-026X-20-205&partnerID=40&md5=6e6064b904ebdd0266fa96935acd3068","Different from previous generations, the 5G networks has new capabilities due to servicebased architecture model and virtualization. The successful broadband networks must be able to handle the growth in the data traffic. The e-Health networks has additional issues as the continuous monitoring of patients suffering from chronic diseases (non-communicable diseases). The wearable devices used for monitoring are supposed to be used for balneo-physio-kinetotherapy (including the body gait index calculation) in the future and this will require and increasing traffic as users and data for 5G networks. Medical data and biomedical data are usually very large (especially for medical images) and the traffic can be critical in some situation when in order to take a decision due to alarms from generated by medical emergency when the data should be provided very fast to the physicians (hospitals, or clinics). An architecture for smart e-Health monitoring including the management of big database open the opportunity to use intelligent algorithm for complex problems, machine learning and artificial intelligence. The possibility to use of three algorithms in simulation and simulators for e-Health 5G wireless network is investigate in this paper. One of the key requirement is low energy consumption due to number of antenna elements at the access points and number of user terminals. The problem optimization address to a mix agglomeration: Dense urban area along with a set of dispersed locations in a rural area. The network planning is defined as optimization problem of configuration that depends on BS (Base Station) location and transmission power but as novelty, the constraints due to inclusion of rural area are also included in feasible solution. The constraints refer to two situations: The relief (that can be natural zone) or imposed black zone due external factors. Three algorithms are examined: Realcoded Genetic Algorithm for Variable Population - RCGAV), NSGA - II and Gossip, applied to modelling and optimization of power consumption in wireless access networks. Scenarios with simulation of the traffic between the client and the server are taken in to account using known models of distribution: Poisson, Pareto, and Weibull. © 2020, National Defence University-Carol I Printing House. All rights reserved.","Broadband Wireless; Data traffic; Intelligent Algorithms; Machine Learning; Optimization Algorithms","National Defence University - Carol I Printing House"
"Jiang H., Nie Z., Yeo R., Barati A., Levent F., Kara B.","Stressgan: A generative deep learning model for 2D stress distribution prediction",2020,"Proceedings of the ASME Design Engineering Technical Conference",3,"10.1115/DETC2020-22682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096340430&doi=10.1115%2fDETC2020-22682&partnerID=40&md5=14712bdad13e882917ba47255a578b4b","Using deep learning to analyze mechanical stress distributions has been gaining interest with the demand for fast stress analysis methods. Deep learning approaches have achieved excellent outcomes when utilized to speed up stress computation and learn the physics without prior knowledge of underlying equations. However, most studies restrict the variation of geometry or boundary conditions, making these methods difficult to be generalized to unseen configurations. We propose a conditional generative adversarial network (cGAN) model for predicting 2D von Mises stress distributions in solid structures. The cGAN learns to generate stress distributions conditioned by geometries, load, and boundary conditions through a two-player minimax game between two neural networks with no prior knowledge. By evaluating the generative network on two stress distribution datasets under multiple metrics, we demonstrate that our model can predict more accurate high-resolution stress distributions than a baseline convolutional neural network model, given various and complex cases of geometry, load and boundary conditions. Copyright © 2020 ASME.",,"American Society of Mechanical Engineers (ASME)"
"Valladares H., Tovar A.","A simple and effective methodology to perform multi-objective bayesian optimization: An application in the design of sandwich composite armors for blast mitigation",2020,"Proceedings of the ASME Design Engineering Technical Conference",2,"10.1115/DETC2020-22564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096338780&doi=10.1115%2fDETC2020-22564&partnerID=40&md5=805625f53926f1cb825155244774718f","Bayesian optimization is a versatile numerical method to solve global optimization problems of high complexity at a reduced computational cost. The efficiency of Bayesian optimization relies on two key elements: a surrogate model and an acquisition function. The surrogate model is generated on a Gaussian process statistical framework and provides probabilistic information of the prediction. The acquisition function, which guides the optimization, uses the surrogate probabilistic information to balance the exploration and the exploitation of the design space. In the case of multi-objective problems, current implementations use acquisition functions such as the multi-objective expected improvement (MEI). The evaluation of MEI requires a surrogate model for each objective function. In order to expand the Pareto front, such implementations perform a multi-variate integral over an intricate hypervolume, which require high computational cost. The objective of this work is to introduce an efficient multi-objective Bayesian optimization method that avoids the need for multi-variate integration. The proposed approach employs the working principle of multi-objective traditional methods, e.g., weighted sum and min-max methods, which transform the multi-objective problem into a single-objective problem through a functional mapping of the objective functions. Since only one surrogate is trained, this approach has a low computational cost. The effectiveness of the proposed approach is demonstrated with the solution of four problems: (1) an unconstrained version of the Binh and Korn test problem (convex Pareto front), (2) the Fonseca and Fleming test problem (non-convex Pareto front), (3) a three-objective test problem and (4) the design optimization of a sandwich composite armor for blast mitigation. The optimization algorithm is implemented in MATLAB and the finite element simulations are performed in the explicit, nonlinear finite element analysis code LS-DYNA. The results are comparable (or superior) to the results of the MEI acquisition function. © 2020 American Society of Mechanical Engineers (ASME). All rights reserved.","Bayesian Machine Learning; Bayesian Optimization; Blast Mitigation; Design Optimization; Multi-objective optimization; Response Surface Methodology; Sandwich Composites","American Society of Mechanical Engineers (ASME)"
"Zhang A.Y., Zhou H.H.","Theoretical and computational guarantees of mean field variational inference for community detection",2020,"Annals of Statistics",7,"10.1214/19-AOS1898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095489350&doi=10.1214%2f19-AOS1898&partnerID=40&md5=0b767941cbc3ca9f0c708567971e528d","The mean field variational Bayes method is becoming increasingly popular in statistics and machine learning. Its iterative coordinate ascent variational inference algorithm has been widely applied to large scale Bayesian inference. See Blei et al. (2017) for a recent comprehensive review. Despite the popularity of the mean field method, there exist remarkably little fundamental theoretical justifications. To the best of our knowledge, the iterative algorithm has never been investigated for any high-dimensional and complex model. In this paper, we study the mean field method for community detection under the stochastic block model. For an iterative batch coordinate ascent variational inference algorithm, we show that it has a linear convergence rate and converges to the minimax rate within log n iterations. This complements the results of Bickel et al. (2013) which studied the global minimum of the mean field variational Bayes and obtained asymptotic normal estimation of global model parameters. In addition, we obtain similar optimality results for Gibbs sampling and an iterative procedure to calculate maximum likelihood estimation, which can be of independent interest. © Institute of Mathematical Statistics, 2020","Bayesian; Community detection; Mean field; Stochastic block model; Variational inference","Institute of Mathematical Statistics"
"Xiong F., Zhou J., Lu J., Qian Y.","Nonconvex Nonseparable Sparse Nonnegative Matrix Factorization for Hyperspectral Unmixing",2020,"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",3,"10.1109/JSTARS.2020.3028104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094148444&doi=10.1109%2fJSTARS.2020.3028104&partnerID=40&md5=7f599c94021fb166b7634f39c635ac7d","Hyperspectral unmixing is an important step to learn the material categories and corresponding distributions in a scene. Over the past decade, nonnegative matrix factorization (NMF) has been utilized for this task, thanks to its good physical interpretation. The solution space of NMF is very huge due to its nonconvex objective function for both variables simultaneously. Many convex and nonconvex sparse regularizations are embedded into NMF to limit the number of trivial solutions. Unfortunately, they either produce biased sparse solutions or unbiased sparse solutions with the sacrifice of the convex objective function of NMF with respect to individual variable. In this article, we enhance NMF by introducing a generalized minimax concave (GMC) sparse regularization. The GMC regularization is nonconvex and nonseparable, enabling promotion of unbiased and sparser results while simultaneously preserving the convexity of NMF for each variable separately. Therefore, GMC-NMF better avoids being trapped into local minimals, and thereby produce physically meaningful and accurate results. Extensive experimental results on synthetic data and real-world data verify its utility when compared with several state-of-the-art approaches. © 2008-2012 IEEE.","Generalized minimax concave (GMC) regularization; hyperspectral unmixing; nonnegative matrix factorization (NMF); sparse representation","Institute of Electrical and Electronics Engineers Inc."
"Riccio S.D., Dyankov D., Jansen G., Di Fatta G., Nicosia G.","Pareto Multi-task Deep Learning",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-61616-8_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094142182&doi=10.1007%2f978-3-030-61616-8_11&partnerID=40&md5=5cb3ed3080bf054cc1595277fa67112c","Neuroevolution has been used to train Deep Neural Networks on reinforcement learning problems. A few attempts have been made to extend it to address either multi-task or multi-objective optimization problems. This research work presents the Multi-Task Multi-Objective Deep Neuroevolution method, a highly parallelizable algorithm that can be adopted for tackling both multi-task and multi-objective problems. In this method prior knowledge on the tasks is used to explicitly define multiple utility functions, which are optimized simultaneously. Experimental results on some Atari 2600 games, a challenging testbed for deep reinforcement learning algorithms, show that a single neural network with a single set of parameters can outperform previous state of the art techniques. In addition to the standard analysis, all results are also evaluated using the Hypervolume indicator and the Kullback-Leibler divergence to get better insights on the underlying training dynamics. The experimental results show that a neural network trained with the proposed evolution strategy can outperform networks individually trained respectively on each of the tasks. © 2020, Springer Nature Switzerland AG.","Atari 2600 games; Deep Neuroevolution; Evolution strategy; Hypervolume; Kullback-Leibler divergence; Multi-objective learning; Multi-task learning; Pareto front","Springer Science and Business Media Deutschland GmbH"
"Qi H., Mu X., Shi Y.","A task unloading strategy of IoT devices using deep reinforcement learning based on mobile cloud computing environment",2020,"Wireless Networks",1,"10.1007/s11276-020-02471-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092569952&doi=10.1007%2fs11276-020-02471-4&partnerID=40&md5=16bc46be879c2043e9237639f65588fb","Aiming at the task unloading mode in cloud computing environment, the task unloading problem for IoT devices is studied. Through theoretical analysis, we can know that in the task unloading problem, it is usually contradictory to improve the utilization of cloud resources and reduce the task delay. In order to solve this problem, a task unloading scheme for Internet of things devices using deep reinforcement learning algorithm is proposed. The deep reinforcement learning algorithm is used to model the task unloading problem. The return value with weight is introduced into the algorithm, and the utilization rate of cloud resources and the delay of unloading task are weighed by adjusting the return value of the weight. First of all, the improved k-means clustering algorithm with weighted density is used to cluster the physical machines. The physical machines of each cluster have similar bandwidth and task waiting time. Then, deep reinforcement learning is used to select the best physical machine cluster from the current unloading tasks. Finally, the improved PSO algorithm is used to select the optimal physical machine from the optimal cluster, and Pareto is used to improve the convergence speed. Experimental results show that compared with the traditional method, the proposed algorithm has a good performance, and can achieve the goal of increasing the utilization of physical machine resources and reducing task delay. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Convergence speed; Deep reinforcement learning; K-means clustering algorithm; Mobile cloud computing; Physical machine; Task unloading","Springer"
"Bhatia A.","Object detection in conditional GAN transferred sensor images",2020,"Proceedings of SPIE - The International Society for Optical Engineering",,"10.1117/12.2566885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092563637&doi=10.1117%2f12.2566885&partnerID=40&md5=955a0dfa6131fee0facd9dbe1ba84d6a","Object detection is a central theme for many Artificial Intelligence (AI) applications such as autonomous vehicles, surveillance etc. The algorithms providing this capability rely on training data being available in corresponding sensor mode. Having co-located data from multiple sensor modes enhances the detection confidence, but the availability of training data in desired sensor mode is not always readily available, which slows down progress. In this paper, we investigate the ability to translate images from one sensor mode to another, on a single fixed camera dataset, using conditional Generative Adversarial Network (cGAN). Specifically, images are transferred from Electro-Optical (EO) to Infra-Red (IR) images and vice-versa using cGAN models, which are generative models that learn the data distribution in a minimax game setting. To investigate the usability of such transferred images, we apply object detection algorithm on ground truth and transferred images and compare their performance. The results indicate that transferred images match closely to real images and object detection has good performance on transferred images, especially when the object size is large. © 2020 COPYRIGHT SPIE.","Conditional GAN; GAN; Image transfer; Object detection","SPIE"
"Inapakurthi R.K., Miriyala S.S., Mitra K.","Modelling of pollutants and particulate matter in air using auto-tuned deep recurrent networks",2020,"IFAC-PapersOnLine",,"10.1016/j.ifacol.2020.06.089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092501633&doi=10.1016%2fj.ifacol.2020.06.089&partnerID=40&md5=10bf5845ac7996babf14f49e57e7e90f","Atmospheric pollutants and Particulate Matter of size less than 10µm (PM10) are becoming dominant in the atmosphere due to human activities and natural calamities. To address their associated problems on human health, the interactions between pollutants and PM10 have to be envisaged. Machine learning techniques like Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) were successfully employed in establishing the interactions between various factors at play. However, these techniques are denounced for following a heuristic approach for determining network hyper-parameters. We propose a novel evolutionary multiobjective optimization algorithm which can optimally determine the hyper-parameters in deep recurrent neural networks. We test the algorithm to build optimal RNNs and LSTMs for modelling and forecasting the pollutants and PM10 data generated in northern Taiwan region during the year 2015. A state-of-the-art network training algorithm, Truncated Back Propagation Through Time was used in our study and single variable regression was done for CO, NOx, SO2, and PM10. Except for SO2 with RNN, model developed with the proposed algorithm gave high R2 values. LSTM was found to be superior than RNN in all the cases with R2 going as high as 0.9584 for PM10, while that attained by RNN is 0.93. © 2020, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.","Air quality monitoring; Auto tuning of deep neural networks; Hyper-parameter optimization; Machine learning; Pareto; Particulate matter","Elsevier B.V."
"Lötsch J., Ultsch A.","Random forests followed by computed abc analysis as a feature selection method for machine learning in biomedical data",2020,"Studies in Classification, Data Analysis, and Knowledge Organization",4,"10.1007/978-981-15-3311-2_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092125865&doi=10.1007%2f978-981-15-3311-2_5&partnerID=40&md5=fc9b354c6e9c91ab1b8aaaf1684efc33","Background: Data from biomedical measurements usually include many parameters (variables/features). To reduce efforts of data acquisition or to enhance comprehension, a feature selection method is proposed that combines the ranking of the relative importance of each parameter in random forests classifiers with an item categorization provided by computed ABC analysis. Data: The input data space, comprising an example subset of plasma concentrations of d = 23 different lipid markers of various classes, acquired in Parkinson patients and healthy subjects (n = 100 each). Methods: Random forest classifiers were constructed with various different scenarios of the number of trees and the number of features in each tree. The relative importance of each feature calculated by the classifier was submitted to computed ABC analysis, a categorization technique for skewed distributions to identify the most important feature subset “A,” i.e., a reduced-set containing the important few items. Results: Using different parameters for the algorithms, the classification performance of all reduced-set random forest classifiers was almost as good as that of a random forest classifier using the full set of d = 23 lipid markers; all reaching 95% or better classification accuracy. When including additional “nonsense” features consisting of concentration data permutated across the subject groups, these features were never found in the ABC set “A.” The obtained features sets provided better classifiers than those obtained using classical regression methods. Conclusions: Random forests plus computed ABC analysis provided a feature selection without the necessity to predefine the number of features. A substantial reduction of the number of features, following the “80/20 rule,” was obtained. The classifiers using the A-class performed better than with a regression-based feature selection and were (nearly) as good as using the complete feature set. The obtained small feature sets are also well suited for domain experts’ interpretation. © Springer Nature Singapore Pte Ltd 2020.","Feature selection; Item categorization techniques; Machine learning","Springer Science and Business Media Deutschland GmbH"
"Shao Y., Liu B., Wang S., Xiao P.","A novel test case prioritization method based on problems of numerical software code statement defect prediction [Nowatorska metoda priorytetyzacji przypadków testowych oparta na prognozowaniu błędów instrukcji kodu oprogramowania numerycznego]",2020,"Eksploatacja i Niezawodnosc",1,"10.17531/ein.2020.3.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092120318&doi=10.17531%2fein.2020.3.4&partnerID=40&md5=d1b99ddfcb2bfb8b0ee101eb712a80a1","Test case prioritization (TCP) has been considerably utilized to arrange the implementation order of test cases, which contributes to improve the efficiency and resource allocation of software regression testing. Traditional coverage-based TCP techniques, such as statement-level, method/function-level and class-level, only leverages program code coverage to prioritize test cases without considering the probable distribution of defects. However, software defect data tends to be imbalanced following Pareto principle. Instinctively, the more vulnerable the code covered by the test case is, the higher the priority it is. Besides, statement-level coverage is a more fine-grained method than function-level coverage or class-level coverage, which can more accurately formulate test strategies. Therefore, we present a test case prioritization approach based on statement software defect prediction to tame the limitations of current coverage-based techniques in this paper. Statement metrics in the source code are extracted and data pre-processing is implemented to train the defect predictor. And then the defect detection rate of test cases is calculated by combining the prioritization strategy and prediction results. Finally, the prioritization performance is evaluated in terms of average percentage faults detected in four open source datasets. We comprehensively compare the performance of the proposed method under different prioritization strategies and predictors. The experimental results show it is a promising technique to improve the prevailing coverage-based TCP methods by incorporating statement-level defect-proneness. Moreover, it is also concluded that the performance of the additional strategy is better than that of max and total, and the choice of the defect predictor affects the efficiency of the strategy. © 2020, Polish Academy of Sciences Branch Lublin. All rights reserved.","Code statement metrics; Machine learning; Software defect prediction; Software testing; Test case prioritization","Polish Academy of Sciences Branch Lublin"
"Jeyakumar J.V., Cherkasova L., Lajevardi S., Allan M., Zhao Y., Fry J., Srivastava M.","Combining Individual and Joint Networking Behavior for Intelligent IoT Analytics",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-59615-6_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092105212&doi=10.1007%2f978-3-030-59615-6_4&partnerID=40&md5=3c5f384d28debadb40524cb48a9d5311","The IoT vision of a trillion connected devices over the next decade requires reliable end-to-end connectivity and automated device management platforms. While we have seen successful efforts for maintaining small IoT testbeds, there are multiple challenges for the efficient management of large-scale device deployments. With Industrial IoT, incorporating millions of devices, traditional management methods do not scale well. In this work, we address these challenges by designing a set of novel machine learning techniques, which form a foundation of a new tool, IoTelligent, for IoT device management, using traffic characteristics obtained at the network level. The design of our tool is driven by the analysis of 1-year long networking data, collected from 350 companies with IoT deployments. The exploratory analysis of this data reveals that IoT environments follow the famous Pareto principle, such as: (i) 10% of the companies in the dataset contribute to 90% of the entire traffic; (ii) 7% of all the companies in the set own 90% of all the devices. We designed and evaluated CNN, LSTM, and Convolutional LSTM models for demand forecasting, with a conclusion of the Convolutional LSTM model being the best. However, maintaining and updating individual company models is expensive. In this work, we design a novel, scalable approach, where a general demand forecasting model is built using the combined data of all the companies with a normalization factor. Moreover, we introduce a novel technique for device management, based on autoencoders. They automatically extract relevant device features to identify device groups with similar behavior to flag anomalous devices. © 2020, Springer Nature Switzerland AG.","Deep learning; Device management; Forecasting","Springer Science and Business Media Deutschland GmbH"
"Kalita H., Thangavelautham J.","Multidisciplinary design and control optimization of a spherical robot for planetary exploration",2020,"AIAA Scitech 2020 Forum",,"10.2514/6.2020-0065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091791364&doi=10.2514%2f6.2020-0065&partnerID=40&md5=8d8ab306fe040a808994bfc9b8d2198c","Missions targeting extreme and rugged environments such as caves, canyons, cliffs and crater rims of the Moon, Mars and icy moons are the next frontiers in solar system exploration. Exploring these sites will help ascertain the range of conditions that can support life and identify planetary processes that are responsible for generating and sustaining habitable worlds. Current landers and rovers are unable to access these areas of high interest due to limitations in precision landing techniques, need for large and sophisticated science instruments and a mission assurance and operations culture where risks are minimized at all costs. This research proposes using multiple spherical robots called SphereX for exploring these extreme environments. The design of SphereX is a complex task that involves a large number of design variables and multiple engineering disciplines. The methodology developed in this work uses Automated Multidisciplinary Design and Control Optimization (AMDCO) techniques to find near optimal design solutions in terms of mass, volume, power and control for SphereX for different mission scenarios. The implementation of AMDCO for SphereX design is a complex process because of complexity of modelling and implementation, discontinuities in the design space, and wide range of time scales and exploration objectives. We address these issues by using machine learning in the form of Evolutionary Algorithms integrated with gradient-based optimization techniques to search through the design space and find pareto optimal solutions for a given mission task. The design space is searched using a GA multi-objective optimizer at the system (global) level to find the Pareto-optimal results while gradient-based techniques are used to search at the discipline (local) level. The modeled disciplines are mobility system, power system, thermal system, shielding, communication system, avionics and shell. Using this technology, it is now possible to perform end to end automated preliminary design of planetary robots for surface exploration. © 2020 American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.",,"American Institute of Aeronautics and Astronautics Inc, AIAA"
"Luo D., Wang X.","A large size image classification method based on semi-supervised learning",2020,"Recent Advances in Electrical and Electronic Engineering",,"10.2174/1874476105666190830110150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091590178&doi=10.2174%2f1874476105666190830110150&partnerID=40&md5=97f10708becded69053e70c2af10c073","Background: Semi-supervised learning in the machine learning community has received widespread attention. Semi-supervised learning can use a small number of tagged samples and a large number of untagged samples for efficient learning. Methods: In 2014, Kim proposed a new semi-supervised learning method: the minimax label propagation (MMLP) method. This method reduces time complexity to O (n), with a smaller computa-tion cost and stronger classification ability than traditional methods. However, classification results are not accurate in large-scale image classifications. Thus, in this paper, we propose a semi-supervised image classification method, which is an MMLP-based algorithm. The main idea is threefold: (1) Improving connectivity of image pixels by pixel sampling to reduce the image size, at the same time, reduce the diversity of image characteristics; (2) Using a recall feature to improve the MMLP algorithm; (3) through classification mapping, gaining the classification of the original data from the classification of the data reduction. Results: In the end, our algorithm also gains a minimax path from untagged samples to tagged samples. The experimental results proved that this algorithm is applicable to semi-supervised learning on small-size and that it can also gain better classification results for large-size image at the same time. Conclusion: In our paper, considering the connectivity of the neighboring matrix and the diversity of the characteristics, we used meanshift clustering algorithm, next we will use fuzzy energy clustering on our algorithm. We will study the function of these paths. © 2020 Bentham Science Publishers.","Classification mapping; Data reduction; Graph-based semi-supervised learning; MMLP algorithm; Neural network models; Recall feature","Bentham Science Publishers"
"Hedayat A.","Developing a futuristic multi-objective optimization of the fuel management problems for the nuclear research reactors [Entwicklung einer Mehrziel-Optimierung für Brennstoffmanagement-Aufgaben in Forschungsreaktoren]",2020,"Kerntechnik",2,"10.3139/124.190094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090942608&doi=10.3139%2f124.190094&partnerID=40&md5=9db129b81d7f0ef40c20d841baf5e8cf","In this paper, at the same time, two separate objectives and two safety and operational constraints are chosen to optimize fuel reloading pattern of a Material Testing Reactor (MTR), independently and coherently. This is one of the most difficult type of engineering problems as a constrained, non-continuous, combinatorial, and fully multi-objective optimization problem. Decision space is a non-continuous multimodal space restricted by both of the combinatorial and safety constraints. A smart software application and a robust hybrid algorithm have been developed to get Pareto optimal set with respect to both of the economy of irradiating utilizations and nuclear safety based on the heuristic soft computing. The hybrid algorithm is composed of a fast and elitist Multi-Objective Genetic Algorithm (MOGA) and a fast fitness function evaluating system based on the semi-deep learning cascade feed forward Artificial Neural Networks (ANNs). The smart software is used to produce database automatically required for the ANN training and test data. It can be also used to revise data accurately, impose further irradiating benefits or Operating Limits and Conditions (OLCs), and to advise the reactor supervisor on the most desire pattern based on the smart searches and filtering. The results are highly promising. For more details, optimization results dominate conventional operating core parameters, significantly. Also chosen OLCs are protected. Furthermore, this is very good practice to reach a fully developed practical application of the complex soft computing for the nuclear fuel management problems. © Carl Hanser Verlag, München.",,"Carl Hanser Verlag"
"Basset N., Dang T., Mambakam A., Jarabo J.I.R.","Learning Specifications for Labelled Patterns",2020,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-57628-8_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090175565&doi=10.1007%2f978-3-030-57628-8_5&partnerID=40&md5=e7dff99f41dd458b54519b95e776baee","In this work, we introduce a supervised learning framework for inferring temporal logic specifications from labelled patterns in signals, so that the formulae can then be used to correctly detect the same patterns in unlabelled samples. The input patterns that are fed to the training process are labelled by a Boolean signal that captures their occurrences. To express the patterns with quantitative features, we use parametric specifications that are increasing, which we call Increasing Parametric Pattern Predictor (IPPP). This means that augmenting the value of the parameters makes the predicted pattern true on a larger set. A particular class of parametric specification formalisms that we use is Parametric Signal Temporal Logic (PSTL). One of the main contributions of this paper is the definition of a new measure, called count, to assess the quality of the learned formula. This measure enables us to compare two Boolean signals and, hence, quantifies how much the labelling signal induced by the formula differs from the true labelling signal (e.g. given by an expert). Therefore, the count can measure the number of mismatches (either false positives or false negatives) up to some error tolerance. Our supervised learning framework can be expressed by a multicriteria optimization problem with two objective functions: the minimization of false positives and false negatives given by the parametric formula on a signal. We provide an algorithm to solve this multi-criteria optimization problem. Our approach is demonstrated on two case studies involving characterization and classification of labeled ECG (electrocardiogram) data. © 2020, Springer Nature Switzerland AG.","Monotonic specification learning; Pareto multi-criteria optimization; Signal pattern matching; Signal Temporal Logic","Springer"
"Said R., Bechikh S., Louati A., Aldaej A., Said L.B.","Solving Combinatorial Multi-Objective Bi-Level Optimization Problems Using Multiple Populations and Migration Schemes",2020,"IEEE Access",4,"10.1109/ACCESS.2020.3013568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090041042&doi=10.1109%2fACCESS.2020.3013568&partnerID=40&md5=af140ac79a0777931b91defb1d5f4753","Many decision making situations are characterized by a hierarchical structure where a lower-level (follower) optimization problem appears as a constraint of the upper-level (leader) one. Such kind of situations is usually modeled as a BLOP (Bi-Level Optimization Problem). The resolution of the latter usually has a heavy computational cost because the evaluation of a single upper-level solution requires finding its corresponding (near) optimal lower-level one. When several objectives are optimized in each level, the BLOP becomes a multi-objective task and more computationally costly as the optimum corresponds to a whole non-dominated solution set, called the PF (Pareto Front). Despite the considerable number of recent works in multi-objective evolutionary bi-level optimization, the number of methods that could be applied to the combinatorial (discrete) case is much reduced. Motivated by this observation, we propose in this paper an Indicator-Based version of our recently proposed Co-Evolutionary Migration-Based Algorithm (CEMBA), that we name IB-CEMBA, to solve combinatorial multi-objective BLOPs. The indicator-based search choice is justified by two arguments. On the one hand, it allows selecting the solution having the maximal marginal contribution in terms of the performance indicator from the lower-level PF. On the other hand, it encourages both convergence and diversity at the upper-level. The comparative experimental study reveals the outperformance of IB-CEMBA on a multi-objective bi-level production-distribution problem. From the effectiveness viewpoint, the upper-level hyper-volume values and inverted generational distance ones vary in the intervals [0.8500, 0.9710] and [0.0072, 0.2420], respectively. From the efficiency viewpoint, IB-CEMBA has a good reduction rate of the Number of Function Evaluations (NFEs), lying in the interval [30.13%, 54.09%]. To further show the versatility of our algorithm, we have developed a case study in machine learning, and more specifically we have addressed the bi-level multi-objective feature construction problem. © 2013 IEEE.","Combinatorial bi-level multi-objective optimization; computational cost; indicator-based evolutionary algorithms; migration schemes; population decomposition","Institute of Electrical and Electronics Engineers Inc."
"Swaroop K., Kakodkar N., Tripathy B.","Reliability-based design optimization of a door beam for fmvss214 requirements",2020,"Lecture Notes in Mechanical Engineering",,"10.1007/978-981-15-5432-2_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089705121&doi=10.1007%2f978-981-15-5432-2_13&partnerID=40&md5=1552b0b42470a16a7b41810448f4b225","Door beams are the principal components used in vehicle doors to satisfy FMVSS214 side impact load case and meet associated performance criteria. The beams are typically designed with multiple tailor rolled blanks (TRB) to minimize mass. This poses challenge to the designer to optimize the section sizes as well as thicknesses of different regions while meeting various performance requirements. One such requirement for the door beam is not to undergo buckling at places other than ram engagement location (called end buckling) in addition to other requirements such as adequate load resistance. Machine learning-based techniques can be used to effectively predict subjective performances like end buckling. Physical properties of the door beam such as thickness and material property can vary around the mean resulting in variations in performance. This calls for reliability-based design optimization (RBDO)—designs which would meet the required reliability in performance when the input variables undergo random variations. This piece of work combines the machine learning methods used to predict performance along with reliability analysis tools to develop a RBDO framework which can predict reliability of a design and can also come up with a design to meet required reliability figures. The framework developed is applied to a simplified door beam, and the results are presented. Different supervised machine learning models are investigated for predicting peak load, average load, mass and end buckling. These techniques are integrated with particle swarm optimization (PSO) technique to perform design optimization. A reliability analysis is done using a Monte Carlo Simulation within the PSO. The RBDO framework can develop a Pareto front of door beam mass as a function of reliability, which can help the designer to select a door beam to meet required performance with least mass. © Springer Nature Singapore Pte Ltd 2020.","Meta-heuristic optimization; RBDO; Supervised learning; Vehicle safety","Springer"
"Rajagopal A., Joshi G.P., Ramachandran A., Subhalakshmi R.T., Khari M., Jha S., Shankar K., You J.","A Deep Learning Model Based on Multi-Objective Particle Swarm Optimization for Scene Classification in Unmanned Aerial Vehicles",2020,"IEEE Access",25,"10.1109/ACCESS.2020.3011502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089340352&doi=10.1109%2fACCESS.2020.3011502&partnerID=40&md5=294294d0eb2a946393fffd4dceba027b","Recently, the increase in inexpensive and compact unmanned aerial vehicles (UAVs) and light-weight imaging sensors has led to an interest in using them in various remote sensing applications. The processes of collecting, calibrating, registering, and processing data from miniature UAVs and interpreting the data semantically are time-consuming. In UAV aerial imagery, learning effective image representations is central to the scene classification process. Earlier approaches to the scene classification process depended on feature coding methods with low-level hand-engineered features or unsupervised feature learning. These methods could produce mid-level image features with restricted representational abilities, which generally yielded mediocre results. The development of convolutional neural networks (CNNs) has made image classification more efficient. Due to the limited resources in UAVs, it is hard to fine-tune the hyperparameters and the trade-offs between classifier results and computation complexity. This paper introduces a new multi-objective optimization model for evolving state-of-the-art deep CNNs for scene classification, which generates the non-dominant solutions in an automated way at the Pareto front. We use a set of two benchmark datasets to test the performance of the scene classification model and make a detailed comparative study. The proposed method attains a very low computational time of 80 sec and maximum accuracy of 97.88% compared to all other methods. The proposed method is found to be appropriate for the effective scene classification of images captured by UAVs. © 2013 IEEE.","aerial images; convolutional neural networks; deep learning; internet of everything; machine learning; particle swarm optimization; smart environment; Unmanned aerial vehicle","Institute of Electrical and Electronics Engineers Inc."
"Vashishtha J., Puri V.H., Mukesh","Feature Selection Using PSO: A Multi Objective Approach",2020,"Communications in Computer and Information Science",,"10.1007/978-981-15-6318-8_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088207390&doi=10.1007%2f978-981-15-6318-8_10&partnerID=40&md5=513f17bb551214db856863eb2518e7e3","Feature selection is a pre-processing technique in which a subset or a small number of features, which are relevant and non-redundant, are selected for better classification performance. Multi-objective optimization is applied in the fields where finest decisions need to be taken in presence of trade-offs between two or more differing objectives. Therefore, feature selection is considered as a multi-objective problem with conflicting measures like classification error rate and feature reduction rate. The existing algorithms, Non-dominated Sorting based particle swarm optimization for Feature Selection (NSPSOFS) and Crowding Mutation Dominance based particle swarm optimization for Feature Selection (CMDPSOFS) are the two multi-objective PSO algorithms for feature selection. This work presents the enhanced form of NSPSOFS and CMDPSOFS. A novel selection mechanism for gbest is incorporated and hybrid mutation is also added to the algorithms in order to generate a better pareto optimal front of non-dominated solutions. The experimental results show that the proposed algorithm generates non-dominated solutions and produce better result than existing algorithms. © 2020, Springer Nature Singapore Pte Ltd.","Feature selection; Multi-objective optimization; PSO","Springer"
"Khayyam H., Jamali A., Bab-Hadiashar A., Esch T., Ramakrishna S., Jalili M., Naebe M.","A Novel Hybrid Machine Learning Algorithm for Limited and Big Data Modeling with Application in Industry 4.0",2020,"IEEE Access",7,"10.1109/ACCESS.2020.2999898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087414040&doi=10.1109%2fACCESS.2020.2999898&partnerID=40&md5=e7362e2adfe1e0c5018ca143c5442257","To meet the challenges of manufacturing smart products, the manufacturing plants have been radically changed to become smart factories underpinned by industry 4.0 technologies. The transformation is assisted by employment of machine learning techniques that can deal with modeling both big or limited data. This manuscript reviews these concepts and present a case study that demonstrates the use of a novel intelligent hybrid algorithms for Industry 4.0 applications with limited data. In particular, an intelligent algorithm is proposed for robust data modeling of nonlinear systems based on input-output data. In our approach, a novel hybrid data-driven combining the Group-Method of Data-Handling and Singular-Value Decomposition is adapted to find an offline deterministic model combined with Pareto multi-objective optimization to overcome the overfitting issue. An Unscented-Kalman-Filter is also incorporated to update the coefficient of the deterministic model and increase its robustness against data uncertainties. The effectiveness of the proposed method is examined on a set of real industrial measurements. © 2013 IEEE.","big data modeling; Industry 40; limited data modeling; multi-objective optimization","Institute of Electrical and Electronics Engineers Inc."
"Dickson A., Thomas C.","Improved PSO for optimizing the performance of intrusion detection systems",2020,"Journal of Intelligent and Fuzzy Systems",4,"10.3233/JIFS-179734","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086711518&doi=10.3233%2fJIFS-179734&partnerID=40&md5=0db2c4140e8722b70cf0db3698e322e9","Intrusion detection system is a second layer of defence in a secured network environment. When comes to an IoT platform, the role of IDS is very critical since it is highly vulnerable to security threats. For a trustworthy intrusion detection system in a network, it is necessary to improve the true positives with minimum false positives. Research reveals that the true positive and false positive are conflicting objectives that are to be simultaneously optimized and hence their trade-off always exists as a major challenge. This paper presents a method to solve the tradeoff among these conflicting objectives using multi-objective particle swarm optimization approach. We conducted empirical analysis of the system with multiple machine learning classifiers. Experimental results reveals that this technique with J48 classifier gives the highest gbest value 10.77 with minimum optimum value of false positive 0.02 and maximum true positive 0.995. Empirical evaluation shows an incredible improvement in Pareto set in the objective function space by attaining an optimum point. © 2020 - IOS Press and the authors. All rights reserved.","Intrusion detection system; multi-objective optimization; non-linear programming; pareto front; particle swarm optimization; receiver operating characteristics","IOS Press"
"Setiyoko A., Basaruddin T., Arymurthy A.M.","Minimax approach for semivariogram fitting in ordinary kriging",2020,"IEEE Access",3,"10.1109/ACCESS.2020.2991428","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084951222&doi=10.1109%2fACCESS.2020.2991428&partnerID=40&md5=bbe1c0c449940c9569787b1164798626","This research paper aims to analyze the minimax approach used in the semivariogram fitting process that forms one stage of the kriging operation performed for interpolation. The conventional method uses the weighted least squares fit for various theoretical functions such as stable, exponential, spherical. However, several recent approaches have been developed using machine learning regression techniques. This research employs the ordinary kriging technique where the proposed minimax approach is expected to increase the accuracy of the interpolation resulted by reducing the error of the final result. Kriging, which is based on the stochastic method, is widely used for spatial values and has been proven to be a better predicting process than deterministic methods. The novel approach to ordinary kriging discussed here, the minimax approach, is able to increase result accuracy based on the experiments performed. Minimax can predict the weights of the semivariogram values better than the weighted least-squares method and performs faster than machine learning approaches. © 2013 IEEE.","approximation methods; interpolation; Minimax techniques","Institute of Electrical and Electronics Engineers Inc."
"Wang J., Wang B., Liang J., Yu K., Yue C., Ren X.","Ensemble Learning via Multimodal Multiobjective Differential Evolution and Feature Selection",2020,"Communications in Computer and Information Science",,"10.1007/978-981-15-3425-6_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083967976&doi=10.1007%2f978-981-15-3425-6_34&partnerID=40&md5=d5945117a4d9101c0b075731da8629c0","Ensemble learning is an important element in machine learning. However, two essential tasks, including training base classifiers and finding a suitable ensemble balance for the diversity and accuracy of these base classifiers, are need to be achieved. In this paper, a novel ensemble method, which utilizes a multimodal multiobjective differential evolution (MMODE) algorithm to select feature subsets and optimize base classifiers parameters, is proposed. Moreover, three methods including minimum error ensemble, all Pareto sets ensemble, and error reduction ensemble are employed to construct ensemble classifiers for executing classification tasks. Experimental results on several benchmark classification databases evidence that the proposed algorithm is valid. © 2020, Springer Nature Singapore Pte Ltd.","Classifier parameter; Ensemble learning; Feature selection; Multimodal multiobjective optimization","Springer"
"Robinson J.C., Sherman K., Price D.W., Rathert J.","Inline Part Average Testing (I-PAT) for automotive die reliability",2020,"Proceedings of SPIE - The International Society for Optical Engineering",1,"10.1117/12.2551539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083762704&doi=10.1117%2f12.2551539&partnerID=40&md5=ca0a9849fded33ff54ce8d55c8b474aa","Semiconductor reliability in applications such as automotive is getting increased attention as design rules shrink to include 1Xnm, semiconductor content per vehicle continues to grow, applications become more critical and reliability requirements tighten. Current automotive requirements stipulate less than one defective part per million (DPPM). Approaches to address reliability include improving design, manufacturing and test. Process control in manufacturing is critical for reliability and includes continuous improvement for reducing process tool defectivity, excursion monitoring of process tools and product lines, golden or best performing tool methods [1], measurement system analysis (MSA) methods and screening. Inline defectivity is known to have an impact on both yield and reliability [2], and defects can impact reliability in one of two ways. Killer defects located in areas that are untested can result in so called Zero-Kilometer failures. In other cases, the same types of defects that cause yield loss can also cause latent reliability failures-the difference being size, location and density. Latent reliability defects become activated after test and can include defect types such as partial bridges, partial opens, and embedded particles. Current reliability engineering relies on outlier detection rules like parametric part average testing (P-PAT) [3], or geographic part average testing (G-PAT), both of which are derived from end-of-line screening data, which is based solely on electrical test data [4]. Inline Part Average Testing (I-PAT™) is enabled by multi-channel high-speed LED scanning inspection technology and offers an opportunity to apply fab data to reliability engineering. Defect inspection results are analyzed with machine learning (ML) to weigh the defectivity and create a die-level defectivity metric allowing the statistical identification of die which are a high reliability risk [5, 6]. Two case studies are described. The first case is a feasibility study based on historical fab defectivity data and includes a sample of ∼250,000 die, with eight inline defect inspections per wafer, including four front end of line (FEOL) and four back end of line (BEOL), on a high sensitivity broadband inspection system [7, 8]. Each defect is assigned a weight based on its impact to various ""ground truth"" indicators. The combined impact of all defects in a given die stacked across all inspections is aggregated into a die-level metric. Plotting the die-level I-PAT metrics for all the die as a Pareto chart allows outliers to be identified using accepted statistical methods [9]. I-PAT metrics can then be correlated to electrical wafer sort (EWS) yield or fallout rate, specific wafer-sort bins, EWS parametric test performance and post burn-in electrical test. Of key importance is that wafer test was not used to train the I-PAT model, and therefore this method is an independent validation of latent reliability. The second case study focuses on production screening feasibility with multi-channel high-speed LED scanning, and addresses overkill, or the over inking of potentially good die based on inline defectivity, which is a critical challenge that must be overcome for production implementation [10]. Using inspection enabled by high speed LED scanning technology, die screening is a critical component of a comprehensive automotive Zero Defect program. Applications include early detection of fab excursions, feedback for continuous improvement of inline defectivity, feedforward to optimize electrical test methods and screening of die containing possible latent reliability defects. The I-PAT methodology can be used to enhance standard end-of-line outlier detection rules such as P-PAT [3], which is based solely on parametric testing. © 2020 SPIE.","I-PAT; Inline Inspection; Part Average Testing (PAT); Reliability; Screening","SPIE"
"Tabak G., Fan M., Yang S., Hoyer S., Davis G.","Correcting nuisance variation using Wasserstein distance",2020,"PeerJ",2,"10.7717/peerj.8594","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083510953&doi=10.7717%2fpeerj.8594&partnerID=40&md5=24411b6bad33d28ce607b938da34b7d8","Profiling cellular phenotypes from microscopic imaging can provide meaningful biological information resulting from various factors affecting the cells. One motivating application is drug development: morphological cell features can be captured from images, from which similarities between different drug compounds applied at different doses can be quantified. The general approach is to find a function mapping the images to an embedding space of manageable dimensionality whose geometry captures relevant features of the input images. An important known issue for such methods is separating relevant biological signal from nuisance variation. For example, the embedding vectors tend to be more correlated for cells that were cultured and imaged during the same week than for those from different weeks, despite having identical drug compounds applied in both cases. In this case, the particular batch in which a set of experiments were conducted constitutes the domain of the data; an ideal set of image embeddings should contain only the relevant biological information (e.g., drug effects). We develop a general framework for adjusting the image embeddings in order to ""forget"" domain-specific information while preserving relevant biological information. To achieve this, we minimize a loss function based on distances between marginal distributions (such as the Wasserstein distance) of embeddings across domains for each replicated treatment. For the dataset we present results with, the only replicated treatment happens to be the negative control treatment, for which we do not expect any treatment-induced cell morphology changes. We find that for our transformed embeddings (i) the underlying geometric structure is not only preserved but the embeddings also carry improved biological signal; and (ii) less domain-specific information is present. Copyright © 2020 Tabak et al.","Batch effect; Cellular phenotyping; Domain adaptation; Embedding; Minimax; Optimal transport; Wasserstein distance","PeerJ Inc."
"Lin Z., Zhao J., Sinha S., Zhang W.","HL-Pow: A Learning-Based Power Modeling Framework for High-Level Synthesis",2020,"Proceedings of the Asia and South Pacific Design Automation Conference, ASP-DAC",4,"10.1109/ASP-DAC47756.2020.9045442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083038817&doi=10.1109%2fASP-DAC47756.2020.9045442&partnerID=40&md5=96edc805a101abfa33459ec487cb31ea","High-level synthesis (HLS) enables designers to customize hardware designs efficiently. However, it is still challenging to foresee the correlation between power consumption and HLS-based applications at an early design stage. To overcome this problem, we introduce HL-Pow, a power modeling framework for FPGA HLS based on state-of-the-art machine learning techniques. HL-Pow incorporates an automated feature construction flow to efficiently identify and extract features that exert a major influence on power consumption, simply based upon HLS results, and a modeling flow that can build an accurate and generic power model applicable to a variety of designs with HLS. By using HL-Pow, the power evaluation process for FPGA designs can be significantly expedited because the power inference of HL-Pow is established on HLS instead of the time-consuming register-transfer level (RTL) implementation flow. Experimental results demonstrate that HL-Pow can achieve accurate power modeling that is only 4.67% (24.02 mW) away from onboard power measurement. To further facilitate power-oriented optimizations, we describe a novel design space exploration (DSE) algorithm built on top of HL-Pow to trade off between latency and power consumption. This algorithm can reach a close approximation of the real Pareto frontier while only requiring running HLS flow for 20% of design points in the entire design space. © 2020 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Passos F., Roca E., Martins R., Lourenco N., Ahyoune S., Sieiro J., Castro-Lopez R., Horta N., Fernandez F.V.","Ready-to-fabricate RF circuit synthesis using a layout- And variability-aware optimization-based methodology",2020,"IEEE Access",3,"10.1109/ACCESS.2020.2980211","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082522707&doi=10.1109%2fACCESS.2020.2980211&partnerID=40&md5=c955e4085ffa48f43470c6ae1af75c20","In this paper, physical implementations and measurement results are presented for several Voltage Controlled Oscillators that were designed using a fully-automated, layout- and variability-aware optimization-based methodology. The methodology uses a highly accurate model, based on machine-learning techniques, to characterize inductors, and a multi-objective optimization algorithm to achieve a Pareto-optimal front containing optimal circuit designs offering different performance trade-offs. The final outcome of the proposed methodology is a set of design solutions (with their GDSII description available and ready-to-fabricate) that need no further designer intervention. Two key elements of the proposed methodology are the use of an optimization algorithm linked to an off-the-shelf simulator and an inductor model that yield EM-like accuracy but with much shorter evaluation times. Furthermore, the methodology guarantees the same high level of robustness against layout parasitics and variability that an expert designer would achieve with the verification tools at his/her disposal. The methodology is technology-independent and can be used for the design of radio frequency circuits. The results are validated with experimental measurements on a physical prototype. © 2013 IEEE.","electronic design automation and methodology; inductors; Integrated circuit synthesis; metamodeling; radio frequency; voltage-controlled oscillator","Institute of Electrical and Electronics Engineers Inc."
"Janet J.P., Ramesh S., Duan C., Kulik H.J.","Accurate Multiobjective Design in a Space of Millions of Transition Metal Complexes with Neural-Network-Driven Efficient Global Optimization",2020,"ACS Central Science",48,"10.1021/acscentsci.0c00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082040399&doi=10.1021%2facscentsci.0c00026&partnerID=40&md5=ae8eb966a6873ef5744b8ab6cc90bcaf","The accelerated discovery of materials for real world applications requires the achievement of multiple design objectives. The multidimensional nature of the search necessitates exploration of multimillion compound libraries over which even density functional theory (DFT) screening is intractable. Machine learning (e.g., artificial neural network, ANN, or Gaussian process, GP) models for this task are limited by training data availability and predictive uncertainty quantification (UQ). We overcome such limitations by using efficient global optimization (EGO) with the multidimensional expected improvement (EI) criterion. EGO balances exploitation of a trained model with acquisition of new DFT data at the Pareto front, the region of chemical space that contains the optimal trade-off between multiple design criteria. We demonstrate this approach for the simultaneous optimization of redox potential and solubility in candidate M(II)/M(III) redox couples for redox flow batteries from a space of 2.8 M transition metal complexes designed for stability in practical redox flow battery (RFB) applications. We show that a multitask ANN with latent-distance-based UQ surpasses the generalization performance of a GP in this space. With this approach, ANN prediction and EI scoring of the full space are achieved in minutes. Starting from ca. 100 representative points, EGO improves both properties by over 3 standard deviations in only five generations. Analysis of lookahead errors confirms rapid ANN model improvement during the EGO process, achieving suitable accuracy for predictive design in the space of transition metal complexes. The ANN-driven EI approach achieves at least 500-fold acceleration over random search, identifying a Pareto-optimal design in around 5 weeks instead of 50 years. © 2020 American Chemical Society.",,"American Chemical Society"
"Kang D., Oh J., Choi J., Yi Y., Ha S.","Scheduling of Deep Learning Applications onto Heterogeneous Processors in an Embedded Device",2020,"IEEE Access",4,"10.1109/ACCESS.2020.2977496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082023992&doi=10.1109%2fACCESS.2020.2977496&partnerID=40&md5=738d9850d4995a7dc00c00d983e3af4f","As the need for on-device machine learning is increasing recently, embedded devices tend to be equipped with heterogeneous processors that include a multi-core CPU, a GPU, and/or a DNN accelerator called a Neural Processing Unit (NPU). In the scheduling of multiple deep learning (DL) applications in such embedded devices, there are several technical challenges. First, a task can be mapped onto a single core or any number of available cores. So we need to consider various possible configurations of CPU cores. Second, embedded devices usually apply Dynamic Voltage and Frequency Scaling (DVFS) to reduce energy consumption at run-time. We need to consider the effect of DVFS in the profiling of task execution times. Third, to avoid overheat condition, it is recommended to limit the core utilization. Lastly, some cores will be shut-down at run-time if core utilization is not high enough, in case the hot-plugging option is turned on. In this paper, we propose a scheduling technique based on Genetic Algorithm to run DL applications on heterogeneous processors, considering all those issues. First, we aim to optimize the throughput of a single deep learning application. Next, we aim to find the Pareto optimal scheduling of multiple DL applications in terms of the response time of each DL application and overall energy consumption under the given throughput constraints of DL applications. The proposed technique is verified with real DL networks running on two embedded devices, Galaxy S9 and HiKey970. © 2013 IEEE.","Deep learning scheduling; genetic algorithm; heterogeneous processor; mobile device","Institute of Electrical and Electronics Engineers Inc."
"Li Y., Li H., Zhang J., Zhang S., Yin Y.","Burden Surface Decision Using MODE with TOPSIS in Blast Furnace Ironmkaing",2020,"IEEE Access",6,"10.1109/ACCESS.2020.2974882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080855381&doi=10.1109%2fACCESS.2020.2974882&partnerID=40&md5=f49bc61d8a697f0f7579f8037931864c","Burden surface distribution plays a key role in achieving an energy-efficient status of blast furnace (BF). However, actual adjustment of burden surface usually depends on the operator's experience when the production status changes. Meanwhile, due to the characteristics of high dimension, strong coupling, and distributed parameters, it is difficult to establish the accurate mechanism model for BF ironmaking process. Considering the aforementioned issues, this paper proposes an integrated multi-objective optimization framework for optimizing burden surface distribution based on the analysis of BF operation characteristics. Firstly, data-driven models are constructed for two objectives, i.e., gas utilization ratio (GUR) and coke ratio (CR), and two constraints using adaptive particle swarm optimization (APSO) based extreme learning machine (ELM), named APSO-ELM. Multi-objective optimization is subsequently carried out between GUR and CR using the multi-objective differential evolution algorithm (MODE) to generate the Pareto optimal solutions. Finally, TOPSIS is applied to select a best compromise solution among the Pareto optimal solutions for this optimization problem. Comprehensive experiments are presented to illustrate the performance of the proposed integrated multi-objective optimization framework. The experimental results demonstrate that the proposed framework can give a reasonable burden surface profile according to the production status changes to guarantee the BF operation more efficient and stable. © 2013 IEEE.","Blast furnace; burden surface optimization; extreme learning machine; MODE; multi-objective optimization; TOPSIS","Institute of Electrical and Electronics Engineers Inc."
"Hsu J.-Y., Wang Y.-F., Lin K.-C., Chen M.-Y., Hsu J.H.-Y.","Wind turbine fault diagnosis and predictive maintenance through statistical process control and machine learning",2020,"IEEE Access",31,"10.1109/ACCESS.2020.2968615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079779107&doi=10.1109%2fACCESS.2020.2968615&partnerID=40&md5=53f155c70fe11995a6f3220d0faa15b9","This study applies statistical process control and machine learning techniques to diagnose wind turbine faults and predict maintenance needs by analyzing 2.8 million sensor data collected from 31 wind turbines from 2015 to 2017 in Taiwan. Unlike previous studies that only relied on historical wind turbine data, this study analyzed the sensor data with practitioners' insight by incorporating maintenance check list items into the data mining processes. We used Pareto analyses, scatter plots, and the cause and effect diagram to cluster and classify the failure types of wind turbines. In addition, control charts were used to establish a monitoring mechanism to track whether operation data are deviated from the controls (i.e., standard deviations) as a mean to detect wind turbine abnormalities. While statistical process control was applied to fault diagnosis, machine learning algorithms were used to predict maintenance needs of wind turbines. First, the density-based spatial clustering of applications with noise algorithm was used to classify abnormal-state wind turbine data from normal-state data. Then, random forest and decision tree algorithms were employed to construct the predictive models for wind turbine anomalies and tested with K-fold cross-validation. The results indicate a high level of accuracy: 92.68% for the decision tree model, and 91.98% for the random forest model. The study demonstrates that, by data mining and modeling, the failures of wind turbines can be detected, and the maintenance needs of parts can be predicted. Model results may provide technicians early warnings, improve equipment efficient, and decrease system downtime of wind turbine operation. © 2013 IEEE.","Decision trees; fault diagnosis; machine learning; predictive maintenance; random forest; statistical process control; wind energy","Institute of Electrical and Electronics Engineers Inc."
"Pavani Priya C.H., Pravallika O., Venkat Krsihna U., Selvakumar R.","Optimized selection operation on non dominant sorting genetic algorithm-III in multiobject navigation system",2020,"International Journal of Scientific and Technology Research",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079468475&partnerID=40&md5=49437bbabf47af9e1834d5215276cbf2","In the contemporary era uses of Electrical Autonomous Vehicles (EAVs) are growing industry, parallel the automating them in the complex and uncertainty paths are most difficulty. In EAVs Multi object Navigation System (MNS) operation smoothly is more difficult, produces issues in the real world problems, namely multiple conflicting goals during the running condition MNV Elapse Time (ET), Energy Injection (EI), Path predictions. To improve and optimize several works are investigated in more than a decade, but there are two major areas were not able to improve namely Optimised Selection Operation (OSP), Simultaneous Search Dataset Decision (SSDD). In this work we have proposed an Optimized Selection Operation on Non-dominant Sorting Genetic Algorithm –III (NSGA-OSO). It solves the EAVs-MNS limitations. The Algorithm designed withthe concept of Machine Learning Reinforced (MLR) Genetic way of Searching and Sorting, NSGA-III parameterised based on the fundamental formulation of Pareto-Optimal for EAVs-MNS, we are improved the key functions in the systems which are Normalize Population Size(NPS), Crossover, Mutation, MOO with Scalable Fitness Dimension techniques correlated with DTLZ-1, DTLZ-2,finally No-Trade-Offs (NTo). Algorithm Programmed in Mat LAB 2018a platform and Python 3.7. The NSGA-OSO simulation outputs NPS 25, 50, 75, 100, 125, 150 respectively the Crossovers simulates 0.5 percentage, Mutation rates parameter setting various 0.5 in precisely to 0.25 mutation rate. Perform Scalarizing (PS) on the selections of single and Multi object depended on searching and sorting, similarly Scalable Fitness DTLZ s optimize the navigation process 12% during the Elapsed time 20ms to 50ms according the iterations, Efficient NSGA-OSO than existing NSGA-I, NSGA-II, MOEAs algorithms. All the parameter setting and operations are relatively better option for emerging Electrical Autonomous Vehicles. © 2020 IJSTR.","Electrical Autonomous Vehicle; Localizations and Navigation System; Machine Learning Reinforcement; Multiobjective Optimization; Non Dominant Sorting Genetic Algorithm; Optimized Selection","Amazedia Solutions"
"Ghosh T., Martinsen K.","Machine Learning Based Heuristic Technique for Multi-response Machining Process",2020,"Lecture Notes in Mechanical Engineering",,"10.1007/978-3-030-37566-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078462775&doi=10.1007%2f978-3-030-37566-9_3&partnerID=40&md5=aee66928727e4aa78d916579633b858e","Manufacturing process variables influence the quality of products substantially. It is unquestionably difficult to model the manufacturing processes that include a large number of variables and responses. Development of the multi-objective surrogate models for the manufacturing processes could be computationally and economically expensive. In this article, a generic multi-objective surrogate-coupled heuristic algorithm is employed that needs small amount of experimental data as input, and predicts precise responses with quick Pareto solutions. The proposed algorithm is verified with different cases collected from the literature based on the CNC turning, centerless cylindrical grinding, and micro milling machining and shown to produce some interesting results. © Springer Nature Switzerland AG 2020.","Heuristic algorithm; Manufacturing process optimization; Multi-objective optimization; Surrogate models","Springer"
"Duhan B., Dhankhar N.","Hybrid Approach of SVM and Feature Selection Based Optimization Algorithm for Big Data Security",2020,"Lecture Notes in Electrical Engineering",1,"10.1007/978-3-030-30577-2_62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075273737&doi=10.1007%2f978-3-030-30577-2_62&partnerID=40&md5=ac2174006ba09c677d5827b220410d17","As internet is growing at a fast rate due to which the cyber attacks have also increased. The type and rate of occurrence of these attacks is increasing rapidly. There are many traditional security solutions existing but these solutions do not perform well in case of Big Data. Securing Big Data from attacks needs a different approach rather than traditional solutions. In this paper spark tool is used. Spark tool has various advanced features like parallel processing of data. Its library provides some inbuilt machine learning algorithms. The dataset used is NSL KDDCUP which has size in MB’s. This dataset is best suited for Big Data as a test case. An approach is proposed for intrusion detection i.e., svm classifier is used and feature selection is done by using a new kind of approach named pareto fronts multi objective based genetic algorithm. © 2020, Springer Nature Switzerland AG.","Big data; Genetic algorithm; Intrusion Detection System; Pareto fronts; SVM","Springer"
"Kumar G.","An improved ensemble approach for effective intrusion detection",2020,"Journal of Supercomputing",8,"10.1007/s11227-019-03035-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074795656&doi=10.1007%2fs11227-019-03035-w&partnerID=40&md5=cdaf05cbef3c89e5a2139e80cabb160f","Nowadays, one critical challenge of cybersecurity administrators is the protection of online resources from network intrusions. Despite several academic and industry research initiatives, full protection of online resources from these network intrusions is not feasible. Therefore, several techniques have been developed that use network audit data for accurate detection of network intrusions effectively and efficiently and are used in network intrusion detection systems (NIDSs). But, most of NIDSs reported low detection accuracy with high false alarm rate and provide a single solution that lacks in classification trade-offs. In this paper, the authors present a hybrid approach of multi-objective genetic algorithm and neural networks for creating a set of ensemble solutions for detecting network intrusions effectively. The proposed approach works in two phases that initially creates a set of non-dominating solutions or Pareto optimal solutions of base techniques and then creates ensemble solutions. In the outcome of individual solutions or models in the ensemble are aggregated using most popular method of majority voting. The proposed hybrid approach is evaluated using benchmark datasets of NSL_KDD and ISCX-2012 datasets for intrusion detection. The evaluation results using benchmark datasets demonstrate that the proposed hybrid approach enables detecting network intrusions effectively as compared to conventional ensemble approaches, namely bagging and boosting. The resultant ensemble solutions are non-dominating and provide classification trade-offs for cybersecurity administrators. The results also show that the proposed hybrid approach detects both minority and majority intrusion types accurately. The proposed hybrid approach demonstrated a detection accuracy of 97% and 88% with FPR of 2.4% and 2% for ISCX-2012 and NSL_KDD datasets, respectively. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Genetic algorithm; Intrusion; Intrusion detection system; Machine learning; MOGA; Neural networks","Springer"
"Yin J., Tsai F.T.-C.","Bayesian set pair analysis and machine learning based ensemble surrogates for optimal multi-aquifer system remediation design",2020,"Journal of Hydrology",13,"10.1016/j.jhydrol.2019.124280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074137121&doi=10.1016%2fj.jhydrol.2019.124280&partnerID=40&md5=0f14dd205829b0db022ce0421d7d4645","Surrogate models are often adopted to substitute computationally intensive groundwater simulation models for aquifer management due to their high effectiveness and computing efficiency. However, solutions of using only one surrogate model are prone to large prediction uncertainty. This study compares individual surrogate models and an ensemble surrogate model in an optimal groundwater remediation design problem. Three machine learning based surrogate models (response surface regression model, artificial neural network and support vector machine) were developed to replace a high-fidelity solute transport model for predicting saltwater intrusion and assisting saltwater scavenging design. An optimal Latin hypercube design was employed to generate training and testing datasets. Set pair analysis was employed to construct a more reliable ensemble surrogate and to address prediction uncertainty arising from individual surrogate models. Bayesian set pair weights were derived by utilizing full information from both training and testing data and improved typical set pair weights. The individual and ensemble surrogate models were applied to the salinization remediation problem in the Baton Rouge area, southeast Louisiana. The optimal remediation design includes two conflicting objectives: minimizing total groundwater extraction from a horizontal scavenger well while maximizing chloride concentration difference to the MCL (maximum contamination level) at monitoring locations. NSGA-II (Non-dominated Sorting Genetic Algorithm II) was employed to solve the nonlinear optimization model and obtain Pareto-optimal pumping schedules. The optimal pumping schedules from ensemble surrogate models and individual surrogate models were verified by the solute transport model. The study found that Bayesian set pair analysis builds robust ensemble surrogates and accounts for model prediction uncertainty. The ensemble-surrogate-assisted optimization model provides stable and reliable solutions while considerably alleviating computational burden. © 2019 Elsevier B.V.","Bayesian set pair analysis; Bi-objective optimization; Ensemble surrogate; Machine learning; Saltwater scavenging; Uncertainty","Elsevier B.V."
"Zhou Z., Li S., Qin G., Folkert M., Jiang S., Wang J.","Multi-Objective-Based Radiomic Feature Selection for Lesion Malignancy Classification",2020,"IEEE Journal of Biomedical and Health Informatics",18,"10.1109/JBHI.2019.2902298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072975005&doi=10.1109%2fJBHI.2019.2902298&partnerID=40&md5=6dd50bf0300404755c4261bb4e488ef2","Objective: accurately classifying the malignancy of lesions detected in a screening scan is critical for reducing false positives. Radiomics holds great potential to differentiate malignant from benign tumors by extracting and analyzing a large number of quantitative image features. Since not all radiomic features contribute to an effective classifying model, selecting an optimal feature subset is critical. Methods: this work proposes a new multi-objective based feature selection (MO-FS) algorithm that considers sensitivity and specificity simultaneously as the objective functions during feature selection. For MO-FS, we developed a modified entropy-based termination criterion that stops the algorithm automatically rather than relying on a preset number of generations. We also designed a solution selection methodology for multi-objective learning that uses the evidential reasoning approach (SMOLER) to automatically select the optimal solution from the Pareto-optimal set. Furthermore, we developed an adaptive mutation operation to generate the mutation probability in MO-FS automatically. Results: we evaluated the MO-FS for classifying lung nodule malignancy in low-dose CT and breast lesion malignancy in digital breast tomosynthesis. Conclusion: the experimental results demonstrated that the feature set selected by MO-FS achieved better classification performance than features selected by other commonly used methods. Significance: the proposed method is general and more effective radiomic feature selection strategy. © 2013 IEEE.","evidential reasoning; feature selection; lesion malignancy classification; multi-objective evolutionary algorithm; Radiomics","Institute of Electrical and Electronics Engineers Inc."
"Sun X., Bommert A., Pfisterer F., Rähenfürher J., Lang M., Bischl B.","High dimensional restrictive federated model selection with multi-objective bayesian optimization over shifted distributions",2020,"Advances in Intelligent Systems and Computing",3,"10.1007/978-3-030-29516-5_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072829225&doi=10.1007%2f978-3-030-29516-5_48&partnerID=40&md5=4641abaf89bc5d793af12c22e2a62b37","A novel machine learning optimization process coined Restrictive Federated Model Selection (RFMS) is proposed under the scenario, for example, when data from healthcare units can not leave the site it is situated on and it is forbidden to carry out training algorithms on remote data sites due to either technical or privacy and trust concerns. To carry out a clinical research in this scenario, an analyst could train a machine learning model only on local data site, but it is still possible to execute a statistical query at a certain cost in the form of sending a machine learning model to some of the remote data sites and get the performance measures as feedback, maybe due to prediction being usually much cheaper. Compared to federated learning, which is optimizing the model parameters directly by carrying out training across all data sites, RFMS trains model parameters only on one local data site but optimizes hyper parameters across other data sites jointly since hyper-parameters play an important role in machine learning performance. The aim is to get a Pareto optimal model with respective to both local and remote unseen prediction losses, which could generalize well across data sites. In this work, we specifically consider high dimensional data with different distributions over data sites. As an initial investigation, Bayesian Optimization especially multi-objective Bayesian Optimization is used to guide an adaptive hyper-parameter optimization process to select models under the RFMS scenario. Empirical results shows that solely using the local data site to tune hyper-parameters generalizes poorly across data sites, compared to methods that utilize the local and remote performances. Furthermore, in terms of hypervolumes, multi-objective Bayesian Optimization algorithms show increased performance across multiple data sites among other candidates. © Springer Nature Switzerland AG 2020.","Differential privacy; Distribution shift; Federated learning; High dimensional data; Model selection; Multi-objective Bayesian Optimization","Springer Verlag"
"Doss K., Hanshew A.S., Mauro J.C.","Signatures of criticality in mining accidents and recurrent neural network forecasting model",2020,"Physica A: Statistical Mechanics and its Applications",3,"10.1016/j.physa.2019.122656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072288183&doi=10.1016%2fj.physa.2019.122656&partnerID=40&md5=812f383083557fa8bd20f1664ec2b656","We report signatures of criticality in mining accident data obtained from the Mine Accident, Injury and Illness Report form (MSHA Form 7000-1). This work builds on the hypothesis that workplace accident statistics follow self-organized criticality (Mauro et al., 2018). “1/f noise,” a distinct feature of critical systems, is extracted from this database and is used to forecast accident trends using a long short-term memory (LSTM) recurrent neural network (RNN). The algorithm used for extracting this noise is applicable to data available in any standard worker's compensation database. We also report a Pareto distribution in the number of accidents in relation to employee mine experience, implying a strong correlation between experience and susceptibility to accidents. © 2019 Elsevier B.V.","Machine learning; Mining safety; Self-organized criticality; Time-series forecasting","Elsevier B.V."
"Besser K.-L., Lin P.-H., Janda C.R., Jorswieck E.A.","Wiretap Code Design by Neural Network Autoencoders",2020,"IEEE Transactions on Information Forensics and Security",11,"10.1109/TIFS.2019.2945619","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068974900&doi=10.1109%2fTIFS.2019.2945619&partnerID=40&md5=81203dac496d9bbb7ffdd22492bd0bf6","In industrial machine type communications, an increasing number of wireless devices communicate under reliability, latency, and confidentiality constraints, simultaneously. From information theory, it is known that wiretap codes can asymptotically achieve reliability (vanishing block error rate (BLER) at the legitimate receiver Bob) while also achieving secrecy (vanishing information leakage (IL) to an eavesdropper Eve). However, under finite block length, there exists a tradeoff between the BLER at Bob and the IL at Eve. In this work, we propose a flexible wiretap code design for degraded Gaussian wiretap channels under finite block length, which can change the operating point on the Pareto boundary of the tradeoff between BLER and IL given specific code parameters. To attain this goal, we formulate a multi-objective programming problem, which takes the BLER at Bob and the IL at Eve into account. During training, we approximate the BLER by the mean square error and the IL by schemes based on Jensen's inequality and the Taylor expansion and then solve the optimization problem by neural network autoencoders. Simulation results show that the proposed scheme can find codes outperforming polar wiretap codes (PWC) with respect to both BLER and IL simultaneously. We show that the codes found by the autoencoders could be implemented with real modulation schemes with only small losses in performance. © 2005-2012 IEEE.","autoencoders; deep learning; Physical layer security; wiretap codes","Institute of Electrical and Electronics Engineers Inc."
"Hameed I.A.","Multi-objective Solution of Traveling Salesman Problem with Time",2020,"Advances in Intelligent Systems and Computing",5,"10.1007/978-3-030-14118-9_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064052694&doi=10.1007%2f978-3-030-14118-9_13&partnerID=40&md5=a4ad179bb5c2da701f77e589f6b72e80","The traveling salesman problem (TSP) is a challenging problem in combinatorial optimization. No general method of solution is known, and the problem is NP-hard. In this paper, we consider the multi-objective TSP which encompasses the optimization of two conflicting and competing objectives: here the dual minimization of the total travel distance and total travel time at various traffic flow conditions. It is well known that travellers can experience extra travel time during peak hours (i.e., congestion conditions) compared to free flow conditions (i.e., un-congested conditions), therefore and under some conditions, minimizing traveled time could conflict and compete with travel distance and vice versa. This problem has been studied in the form of a single objective problem, where either the two objectives have been combined in a single objective function or one of the objectives has been treated as a constraint. The purpose of this paper is to find a set of non-dominated solutions (i.e., the sequence of cities) using the notion of Pareto optimality where none of the objective functions can be improved in value without degrading one or more of the other objective values. The traveller then has the chance to choose a solution that fits his/her needs at each congestion level. In this paper, a multi-objective genetic algorithm (MOGA) for searching for efficient solutions is investigated. Here, an initial population composed of an approximation to the extreme supported efficient solutions is generated. A Pareto local search is then applied to all solutions of the initial population. The method is applied to a simulated problem and to a real-world problem where distances and real estimates of the travel duration for multiple origins and destinations for specific transport modes are obtained from Google Maps Platform using a Google Distance Matrix API. Results show that solving a TSP as a multi-objective optimization problem can provide more realistic solutions. The proposed approach can be used for recommending routes based on variable duration matrix and cost. © 2020, Springer Nature Switzerland AG.","Genetic algorithms; Optimization; TSP","Springer Verlag"
"Huang C., Sun X., Xiong J., Yao Y.","Boosting with structural sparsity: A differential inclusion approach",2020,"Applied and Computational Harmonic Analysis",1,"10.1016/j.acha.2017.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042334566&doi=10.1016%2fj.acha.2017.12.004&partnerID=40&md5=ff7d232fdde0bf01b3e6856b6297a793","Boosting as gradient descent algorithms is one popular method in machine learning. In this paper a novel Boosting-type algorithm is proposed based on restricted gradient descent with structural sparsity control whose underlying dynamics are governed by differential inclusions. In particular, we present an iterative regularization path with structural sparsity where the parameter is sparse under some linear transforms, based on variable splitting and the Linearized Bregman Iteration. Hence it is called Split LBI. Despite its simplicity, Split LBI outperforms the popular generalized Lasso in both theory and experiments. A theory of path consistency is presented that equipped with a proper early stopping, Split LBI may achieve model selection consistency under a family of Irrepresentable Conditions which can be weaker than the necessary and sufficient condition for generalized Lasso. Furthermore, some ℓ2 error bounds are also given at the minimax optimal rates. The utility and benefit of the algorithm are illustrated by several applications including image denoising, partial order ranking of sport teams, and world university grouping with crowdsourced ranking data. © 2018 Elsevier Inc.","Boosting; Consistency; Differential inclusions; Generalized Lasso; Linearized Bregman iteration; Model selection; Structural sparsity; Variable splitting","Academic Press Inc."
"He K., Zhong M., Du W.","Weighted incremental minimax probability machine-based method for quality prediction in gasoline blending process",2020,"Chemometrics and Intelligent Laboratory Systems",5,"10.1016/j.chemolab.2019.103909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076698676&doi=10.1016%2fj.chemolab.2019.103909&partnerID=40&md5=b910ce75c95081cc982f2b9a8ee5675c","Near-infrared (NIR) spectroscopy is frequently used to predict quality-relevant variables that are difficult to measure online. This technology can be applied by developing the NIR model in advance. Obtaining a high-accuracy NIR model is difficult using traditional modeling methods because process data inherently contain uncertainties and present strong non-Gaussian characteristics. Considering the difficulty in obtaining precise prediction results, biased estimation is important in producing qualified products when NIR spectroscopy is used in a feedback quality control system. The present work proposes a biased estimation model based on probabilistic representation to address the aforementioned issues. Additionally, a novel weighted incremental strategy with “just-in-time” learning is proposed to improve model adaptiveness. In this way, the NIR model could be established and maintained without imposing any distribution hypothesis on process data, and biased estimation could be obtained in the form of probability. The performance of the proposed method is demonstrated on an actual data set from a gasoline blending process. © 2019 Elsevier B.V.","Biased estimation; Gasoline blending; Minimax probability machine; Near-infrared spectroscopy; Non-Gaussian","Elsevier B.V."
"Deldjoo Y., Di Noia T., Merra F.A.","Adversarial machine learning in recommender systems (AML-RECSYS)",2020,"WSDM 2020 - Proceedings of the 13th International Conference on Web Search and Data Mining",13,"10.1145/3336191.3371877","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079522494&doi=10.1145%2f3336191.3371877&partnerID=40&md5=17f03bb0e9c7b4fb2552101737358aab","Recommender systems (RS) are an integral part of many online services aiming to provide an enhanced user-oriented experience. Machine learning (ML) models are nowadays broadly adopted in modern state-of-the-art approaches to recommendation, which are typically trained to maximize a user-centred utility (e.g., user satisfaction) or a business-oriented one (e.g., profitability or sales increase). They work under the main assumption that users’ historical feedback can serve as proper ground-truth for model training and evaluation. However, driven by the success in the ML community, recent advances show that state-of-the-art recommendation approaches such as matrix factorization (MF) models or the ones based on deep neural networks can be vulnerable to adversarial perturbations applied on the input data. These adversarial samples can impede the ability for training high-quality MF models and can put the driven success of these approaches at high risk. As a result, there is a new paradigm of secure training for RS that takes into account the presence of adversarial samples into the recommendation process. We present adversarial machine learning in Recommender Systems (AML-RecSys), which concerns the study of effective ML techniques in RS to fight against an adversarial component. AML-RecSys has been proposed in two main fashions within the RS literature: (i) adversarial regularization, which attempts to combat against adversarial perturbation added to input data or model parameters of a RS and, (ii) generative adversarial network (GAN)-based models, which adopt a generative process to train powerful ML models. We discuss a theoretical framework to unify the two above models, which is performed via a minimax game between an adversarial component and a discriminator. Furthermore, we explore various examples illustrating the successful application of AML to solve various RS tasks. Finally, we present a global taxonomy/overview of the academic literature based on several identified dimensions, namely (i) research goals and challenges, (ii) application domains and (iii) technical overview. © 2020 Copyright held by the owner/author(s).",,"Association for Computing Machinery, Inc"
"Hu L., Chen Y.","Fair classification and social welfare",2020,"FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency",12,"10.1145/3351095.3372857","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079693295&doi=10.1145%2f3351095.3372857&partnerID=40&md5=1dc842cc99dbee92c51f24e9bdbf3ab1","Now that machine learning algorithms lie at the center of many important resource allocation pipelines, computer scientists have been unwittingly cast as partial social planners. Given this state of affairs, important questions follow. How do leading notions of fairness as defined by computer scientists map onto longer-standing notions of social welfare? In this paper, we present a welfare-based analysis of fair classification regimes. Our main findings assess the welfare impact of fairness-constrained empirical risk minimization programs on the individuals and groups who are subject to their outputs. We fully characterize the ranges of ε perturbations to a fairness parameter ε in a fair Soft Margin SVM problem that yield better, worse, and neutral outcomes in utility for individuals and by extension, groups. Our method of analysis allows for fast and efficient computation of “fairness-to-welfare” solution paths, thereby allowing practitioners to easily assess whether and which fair learning procedures result in classification outcomes that make groups better-off. Our analyses show that applying stricter fairness criteria codified as parity constraints can worsen welfare outcomes for both groups. More generally, always preferring “more fair” classifiers does not abide by the Pareto Principle-a fundamental axiom of social choice theory and welfare economics. Recent work in machine learning has rallied around these notions of fairness as critical to ensuring that algorithmic systems do not have disparate negative impact on disadvantaged social groups. By showing that these constraints often fail to translate into improved outcomes for these groups, we cast doubt on their effectiveness as a means to ensure fairness and justice. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.",,"Association for Computing Machinery, Inc"
"Yin X., Niu Z., He Z., Li Z., Lee D.","An integrated computational intelligence technique based operating parameters optimization scheme for quality improvement oriented process-manufacturing system",2020,"Computers and Industrial Engineering",12,"10.1016/j.cie.2020.106284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077803876&doi=10.1016%2fj.cie.2020.106284&partnerID=40&md5=457244cf523cbc0609545d86074163de","The analysis and improvement of product quality for process industry is an increasing concern for academia and industry. As the outputs of a manufacturing system mainly depend on corresponding input conditions, so it is of high significance to develop an optimization scheme to actively and accurately determine operating parameters to obtain desired quality. However, the widely employed single-model modeling mode for whole production process neglects the natural characteristics within process manufacturing system such as multistage manufacturing and hysteresis. Additionally, the popular data-driven modeling techniques in current works, especially black-box machine learning models have been restricted to satisfying the requirements regarding excellent approximation capability and explicit mathematical expression simultaneously. To fill up above research gap, it is meaningful to develop a new data-driven optimization scheme in this work to effectively and accurately determine the optimum operating parameters considering the abovementioned characteristics and requirements. Firstly, two different connecting strategies are discussed to determine the more accurate and feasible quality propagation mode between adjacent stages. Then, two computational intelligence (CI) techniques, i.e., Multi-Gene Genetic Programming (MGGP) and Multi-objective Particle Swarm Optimization (MOPSO) algorithm are exploited to construct correlation model with explicit mathematical expression and derive the optimal operating parameters, respectively. Afterwards, the fuzzy Multi-criteria Decision Making (FMCDM) method is further proposed to select the optimal solution from the obtained Pareto solutions sets. The application of the proposed scheme in a coal preparation process indicates that the proposed scheme is promising and competitive on prediction accuracy and optimization efficiency over baseline methods, and can significantly improve the final product quality comparing with initial parameters setting. Moreover, the feasible quality specification for intermediate product can also be obtained by our proposed scheme which is beneficial for early detection of quality abnormality and timely parameters adjustment. © 2020","Computational intelligence; Multi-gene genetic programming (MGGP); Multistage manufacturing; Operating parameters optimization; Process industry; Quality improvement","Elsevier Ltd"
"Nguyen B.H., Xue B., Andreae P., Ishibuchi H., Zhang M.","Multiple Reference Points-Based Decomposition for Multiobjective Feature Selection in Classification: Static and Dynamic Mechanisms",2020,"IEEE Transactions on Evolutionary Computation",23,"10.1109/TEVC.2019.2913831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065443764&doi=10.1109%2fTEVC.2019.2913831&partnerID=40&md5=6a3281c8e65ed79badda99a61df3555c","Feature selection is an important task in machine learning that has two main objectives: 1) reducing dimensionality and 2) improving learning performance. Feature selection can be considered a multiobjective problem. However, it has its problematic characteristics, such as a highly discontinuous Pareto front, imbalance preferences, and partially conflicting objectives. These characteristics are not easy for existing evolutionary multiobjective optimization (EMO) algorithms. We propose a new decomposition approach with two mechanisms (static and dynamic) based on multiple reference points under the multiobjective evolutionary algorithm based on decomposition (MOEA/D) framework to address the above-mentioned difficulties of feature selection. The static mechanism alleviates the dependence of the decomposition on the Pareto front shape and the effect of the discontinuity. The dynamic one is able to detect regions in which the objectives are mostly conflicting, and allocates more computational resources to the detected regions. In comparison with other EMO algorithms on 12 different classification datasets, the proposed decomposition approach finds more diverse feature subsets with better performance in terms of hypervolume and inverted generational distance. The dynamic mechanism successfully identifies conflicting regions and further improves the approximation quality for the Pareto fronts. © 1997-2012 IEEE.","Classification; feature selection; multiobjective evolutionary algorithm based on decomposition (MOEA/D); multiobjective optimization; partially conflicting","Institute of Electrical and Electronics Engineers Inc."
"Zhu F., Lu J., Lin A., Zhang G.","A Pareto-smoothing method for causal inference using generalized Pareto distribution",2020,"Neurocomputing",1,"10.1016/j.neucom.2019.09.095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074525204&doi=10.1016%2fj.neucom.2019.09.095&partnerID=40&md5=8d1253b47f1ff6c0016969fabe18b24f","Causal inference aims to estimate the treatment effect of an intervention on the target outcome variable and has received great attention across fields ranging from economics and statistics to machine learning. Observational causal inference is challenging because the pre-treatment variables may influence both the treatment and the outcome, resulting in confounding bias. The classic inverse propensity weighting (IPW) estimator is theoretically able to eliminate the confounding bias. However, in observational studies, the propensity scores used in the IPW estimator must be estimated from finite observational data and may be subject to extreme values, leading to the problem of highly variable importance weights, which consequently makes the estimated causal effect unstable or even misleading. In this paper, by reframing the IPW estimator in the importance sampling framework, we propose a Pareto-smoothing method to tackle this problem. The generalized Pareto distribution (GPD) from extreme value theory is used to fit the upper tail of the estimated importance weights and to replace them using the order statistics of the fitted GPD. To validate the performance of the new method, we conducted extensive experiments on simulated and semi-simulated datasets. Compared with two existing methods for importance weight stabilization, i.e., weight truncation and self-normalization, the proposed method generally achieves better performance in settings with a small sample size and high-dimensional covariates. Its application on a real-world heath dataset indicates its utility in estimating causal effects for program evaluation. © 2019 Elsevier B.V.","Causal inference; Causality; Importance sampling; Machine learning; Treatment effect","Elsevier B.V."
"Guariniello C., Mockus L., Raz A.K., Delaurentis D.A.","Towards Intelligent Architecting of Aerospace System-of-Systems: Part II",2020,"IEEE Aerospace Conference Proceedings",,"10.1109/AERO47225.2020.9172585","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092599662&doi=10.1109%2fAERO47225.2020.9172585&partnerID=40&md5=ff348ef7c1784ace3f672948dff1bd89","System-of-Systems (SoS) are composed of large scale independent and complex heterogeneous systems which collaborate to create capabilities not achievable by a single system, for example air transportation system, satellite constellations, and space exploration architectures. To support architecting of aerospace SoS, in this work we present a methodology to accurately predict different aspects of performance for design/operation and SoS architecting, expanding previous work on intelligent architecting of aerospace SoS, by adding rigorous Uncertainty Quantification via Bayesian Neural Networks. A Bayesian Neural Network is a neural network with a-priori distribution on its weights. In addition to solving the overfit problem, which is common to traditional deep neural networks, Bayesian Neural Networks provide automated model pruning (or reduction of feature design space), that addresses a well-known dimensionality curse in the SoS domain. We enable SoS design/operation by using modeling and simulation, quantifying the uncertainty inherently present in SoS, and utilizing Artificial Intelligence and optimization techniques to design and operate the system so that its expected performance or behavior when the unexpected occurs (for example, a failure) still satisfies user requirements. Much of the research effort in the field of SoS has focused on the analysis of these complex entities, while there are still gaps in developing tools for automated synthesis and engineering of SoS that consider all the various aspects in this problem domain. In this expansion of the use of Artificial Intelligence towards automated design, these techniques are used not only to discover and employ features of interest in a complex design space, but also to assess how uncertainty can affect performance. This capability supports the automated design of robust architectures, that can effectively meet the user needs even in presence of uncertainty. The SoS design and evaluation methodology presented in this paper and demonstrated on a synthetic modular satellites problem starts from modeling and simulation, and design of experiments to explore the design space. The following step is deep learning, to develop a model which relates SoS architectural features with performance metrics. Uncertainty Quantification techniques are then applied to assess the performance metrics for different architectures. Once the most critical features that affect the SoS performance are identified, stochastic optimization of the SoS on a reduced design space can be performed to determine Pareto optimal features. The final step is determining if any additional design/operation measures need to be explored to further maximize the SoS performance. © 2020 IEEE.",,"IEEE Computer Society"
"Yin Z., Gross W., Meyer B.H.","Probabilistic Sequential Multi-Objective Optimization of Convolutional Neural Networks",2020,"Proceedings of the 2020 Design, Automation and Test in Europe Conference and Exhibition, DATE 2020",,"10.23919/DATE48585.2020.9116535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087397836&doi=10.23919%2fDATE48585.2020.9116535&partnerID=40&md5=c49864fa204137d9a66212cc6de399e6","With the advent of deeper, larger and more complex convolutional neural networks (CNN), manual design has become a daunting task, especially when hardware performance must be optimized. Sequential model-based optimization (SMBO) is an efficient method for hyperparameter optimization on highly parameterized machine learning (ML) algorithms, able to find good configurations with a limited number of evaluations by predicting the performance of candidates before evaluation. A case study on MNIST shows that SMBO regression model prediction error significantly impedes search performance in multi-objective optimization. To address this issue, we propose probabilistic SMBO, which selects candidates based on probabilistic estimation of their Pareto efficiency. With a formulation that incorporates error in accuracy prediction and uncertainty in latency measurement, probabilistic Pareto efficiency quantifies a candidate's quality in two ways: its likelihood of being Pareto optimal, and the expected number of current Pareto optimal solutions that it will dominate. We evaluate our proposed method on four image classification problems. Compared to a deterministic approach, probabilistic SMBO consistently generates Pareto optimal solutions that perform better, and that are competitive with state-of-the-art efficient CNN models, offering tremendous speedup in inference latency while maintaining comparable accuracy. © 2020 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Hamada M.A., Naizabayeva L.","Decision Support System with K-Means Clustering Algorithm for Detecting the Optimal Store Location Based on Social Network Events",2020,"2020 IEEE European Technology and Engineering Management Summit, E-TEMS 2020",2,"10.1109/E-TEMS46250.2020.9111758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086986707&doi=10.1109%2fE-TEMS46250.2020.9111758&partnerID=40&md5=773f79dba2feb7f035ace8cb7e19f5fc","Nowadays, the business market is more complicated and comprises many challenges; it became more competitive and surrounded by high-risk patterns. Seeking for new technologies and adopting innovation is becoming an important and crucial issue to eliminate the complexity of the decision-making process and failure probability. Decision support system (DSS) is a computerized system that encompasses mathematical and analytical models, knowledge base and a user interface to help managers for making better decisions. This research aims to develop a decision support system based on K-means clustering algorithm to detect the optimal store location through social network events. Also, this research explains how to extract data from one social network channel ""Instagram"" using the ""Octoparse API"" as a web data extraction tool. K-means algorithm identifies k-number of centroids, and allocates every data point to the nearest cluster. As a result, we analyzed 12754 posts started on the 1st of January 2019. Cleaned data are transformed using Minimax and K-means algorithms. As an output, we have got json format data file with centres which are placed on the map to provide a better understanding. The Result of this research is a visualized map pointed with places to define the optimal location of a specific store at the selected region. The practical value of this DSS tool is to help users to make a more valuable and accurate decision which lead to a decrease in the probability of ineffective business decision and minimize the business losses. © 2020 IEEE.","classification model; decision support system; K-means clustering algorithm; machine learning; optimal store location; social network events","Institute of Electrical and Electronics Engineers Inc."
"Zheng Y., Hao J.-Y., Zhang Z.-Z., Meng Z.-P., Hao X.-T.","Efficient Multiagent Policy Optimization Based on Weighted Estimators in Stochastic Cooperative Environments",2020,"Journal of Computer Science and Technology",6,"10.1007/s11390-020-9967-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085214844&doi=10.1007%2fs11390-020-9967-6&partnerID=40&md5=038d102553f9ecb6797e32cff88fd9db","Multiagent deep reinforcement learning (MA-DRL) has received increasingly wide attention. Most of the existing MA-DRL algorithms, however, are still inefficient when faced with the non-stationarity due to agents changing behavior consistently in stochastic environments. This paper extends the weighted double estimator to multiagent domains and proposes an MA-DRL framework, named Weighted Double Deep Q-Network (WDDQN). By leveraging the weighted double estimator and the deep neural network, WDDQN can not only reduce the bias effectively but also handle scenarios with raw visual inputs. To achieve efficient cooperation in multiagent domains, we introduce a lenient reward network and scheduled replay strategy. Empirical results show that WDDQN outperforms an existing DRL algorithm (double DQN) and an MA-DRL algorithm (lenient Q-learning) regarding the averaged reward and the convergence speed and is more likely to converge to the Pareto-optimal Nash equilibrium in stochastic cooperative environments. © 2020, Institute of Computing Technology, Chinese Academy of Sciences.","cooperative Markov game; deep reinforcement learning; lenient reinforcement learning; multiagent system; weighted double estimator","Springer"
"Yadav D.K., Mookherji S., Gomes J., Patil S.","Intelligent Navigation System for the Visually Impaired - A Deep Learning Approach",2020,"Proceedings of the 4th International Conference on Computing Methodologies and Communication, ICCMC 2020",1,"10.1109/ICCMC48092.2020.ICCMC-000121","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084672909&doi=10.1109%2fICCMC48092.2020.ICCMC-000121&partnerID=40&md5=57f499fb444bf3349cc8d64602ec159c","Visually impaired individuals have been gradually claiming a significant stake in the population demographics. The proposed autonomous device aims to provide a holistic solution by engineering a smart navigation system that relentlessly scans the environment, detects and classifies neighboring objects using a 4 layered Convolutional Neural Network (CNN) that has been trained on a data set containing 2513 permutations of various images of household objects that an individual may encounter in daily life. The CNN follows the 80-20 rule for testing and training the self-learning model enabling it to learn recursively from the error rate. The proposed system then calculates distances of neighboring objects from the user and provides adaptive solutions in real time to manoeuvre the user to safety by providing auditory input in a simplistic manner which considers 10-24 frames per second while drafting the kinematic response for the user. The device has achieved an unprecedented success rate of serving within a response time of less than 50 ms. The accuracy of the CNN algorithm being at 94.6%, also sets a distinguished benchmark as an object detection algorithm thereby contributing to the success in simulations of the proposed device in a constrained environment. © 2020 IEEE.","Convolutional Neural Networks; Deep Learning; Image Processing Algorithm; Image Scanning; Intelligent System; Internet of Things; Navigation System; Object Detection; Wireless Sensors","Institute of Electrical and Electronics Engineers Inc."
"Siade A.J., Cui T., Karelse R.N., Hampton C.","Reduced-Dimensional Gaussian Process Machine Learning for Groundwater Allocation Planning Using Swarm Theory",2020,"Water Resources Research",10,"10.1029/2019WR026061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083089900&doi=10.1029%2f2019WR026061&partnerID=40&md5=50ead325e006872287938d5d3acd8d05","Groundwater management and allocation planning involves a rigorous assessment of the performance of operational decisions such as extraction/injection rates on community and environmental objectives. Maximizing performance through numerical optimization can be essential for high-value resources and is often computationally infeasible due to long simulation model run times combined with nonconvex objectives and constraints. In order to mitigate these drawbacks, surrogate models can be used in place of complex models during the optimization process. There exist a number of machine learning techniques that can be used to develop a data-driven surrogate model. However, the curse of dimensionality, common to groundwater management, limits the use of these techniques due to the necessity for large training data sets. Even though it is now possible to handle large data sets, the generation of these data sets themselves remains computationally prohibitive as they require numerous simulations to produce accurate surrogates. In this study, we integrate a dimensionality reduction method using truncated singular value decomposition to reduce the number of decision variables, thereby reducing the size of the training data set needed. Correspondingly, we demonstrate a simple technique for acquiring an approximate minimax Latin Hypercube design from within the subspace. We also implement a novel technique for adaptive resampling through particle swarm optimization in order to maintain accuracy of the surrogate model throughout the optimization process. The resulting accurate surrogate model for the Perth regional aquifer system of Western Australia runs in a matter of seconds. Adopting this approach can produce timely solutions, making formal optimization tractable for practitioners. © 2020. American Geophysical Union. All Rights Reserved.","dimensionality reduction; Gaussian process regression; groundwater allocation planning; machine learning; particle swarm optimization","Blackwell Publishing Ltd"
"Asanuma J., Doi S., Igarashi H.","Transfer Learning through Deep Learning: Application to Topology Optimization of Electric Motor",2020,"IEEE Transactions on Magnetics",12,"10.1109/TMAG.2019.2956849","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081109387&doi=10.1109%2fTMAG.2019.2956849&partnerID=40&md5=ee772f2b38fb35d0f859f0c7a49228ec","This article proposes the use of transfer learning for the deep neural network to reduce the computing cost of the topology optimization of electric motors based on a genetic algorithm (GA). The average torque and torque ripple values are shown to be accurately inferred by the transfer learning with small learning data. The individuals on the Pareto front are only evaluated by the finite-element method, while others are fast evaluated only by convolutional neural networks (CNNs). The proposed method makes it possible to reduce the computing cost to less than 15% of the conventional topology optimization method. © 1965-2012 IEEE.","Deep learning; electric motor; regression; topology optimization; transfer learning","Institute of Electrical and Electronics Engineers Inc."
"Fang X., Cai Y., Cai Z., Jiang X., Chen Z.","Sparse feature learning of hyperspectral imagery via multiobjective-based extreme learning machine",2020,"Sensors (Switzerland)",5,"10.3390/s20051262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079873682&doi=10.3390%2fs20051262&partnerID=40&md5=69de0909249e3c9d2ef3a60a1c43e3e2","Hyperspectral image (HSI) consists of hundreds of narrow spectral band components with rich spectral and spatial information. Extreme Learning Machine (ELM) has been widely used for HSI analysis. However, the classical ELM is difficult to use for sparse feature leaning due to its randomly generated hidden layer. In this paper, we propose a novel unsupervised sparse feature learning approach, called Evolutionary Multiobjective-based ELM (EMO-ELM), and apply it to HSI feature extraction. Specifically, we represent the task of constructing the ELM Autoencoder (ELM-AE) as a multiobjective optimization problem that takes the sparsity of hidden layer outputs and the reconstruction error as two conflicting objectives. Then, we adopt an Evolutionary Multiobjective Optimization (EMO) method to solve the two objectives, simultaneously. To find the best solution from the Pareto solution set and construct the best trade-off feature extractor, a curvature-based method is proposed to focus on the knee area of the Pareto solutions. Benefited from the EMO, the proposed EMO-ELM is less prone to fall into a local minimum and has fewer trainable parameters than gradient-based AEs. Experiments on two real HSIs demonstrate that the features learned by EMO-ELM not only preserve better sparsity but also achieve superior separability than many existing feature learning methods. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Autoencoder; Evolutionary multiobjective optimization; Extreme learning machine autoencoder; Hyperspectral imagery; Sparse feature learning","MDPI AG"
"Shahane S., Aluru N., Ferreira P., Kapoor S.G., Vanka S.P.","Optimization of solidification in die casting using numerical simulations and machine learning",2020,"Journal of Manufacturing Processes",7,"10.1016/j.jmapro.2020.01.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078243202&doi=10.1016%2fj.jmapro.2020.01.016&partnerID=40&md5=7165706c26a1aa857d2fc95d401856ff","In this paper, we demonstrate the combination of machine learning and three dimensional numerical simulations for multi-objective optimization of low pressure die casting. The cooling of molten metal inside the mold is achieved typically by passing water through the cooling lines in the die. Depending on the cooling line location, coolant flow rate and die geometry, nonuniform temperatures are imposed on the molten metal at the mold wall. This boundary condition along with the initial molten metal temperature affect the product quality quantified in terms of micro-structure parameters and yield strength. A finite volume based numerical solver is used to determine the temperature-time history and correlate the inputs to outputs. The objective of this research is to develop and demonstrate a procedure to obtain the initial and wall temperatures so as to optimize the product quality. The non-dominated sorting genetic algorithm (NSGA-II) is used for multi-objective optimization in this work. The number of function evaluations required for NSGA-II can be of the order of millions and hence, the finite volume solver cannot be used directly for optimization. Therefore, a multilayer perceptron feed-forward neural network is first trained using the results from the numerical solution of the fluid flow and energy equations and is subsequently used as a surrogate model. As an assessment, simplified versions of the actual problem are designed to first verify results of the genetic algorithm. An innovative local sensitivity based approach is then used to rank the final Pareto optimal solutions and select a single best design. © 2020","Deep neural networks; Die casting; Multi-objective optimization","Elsevier Ltd"
"Nguyen D., McBeth R., Sadeghnejad Barkousaraie A., Bohara G., Shen C., Jia X., Jiang S.","Incorporating human and learned domain knowledge into training deep neural networks: A differentiable dose-volume histogram and adversarial inspired framework for generating Pareto optimal dose distributions in radiation therapy",2020,"Medical Physics",19,"10.1002/mp.13955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077884922&doi=10.1002%2fmp.13955&partnerID=40&md5=18d09fa8f58c29239d4a4df444b9dddc","Purpose: We propose a novel domain-specific loss, which is a differentiable loss function based on the dose-volume histogram (DVH), and combine it with an adversarial loss for the training of deep neural networks. In this study, we trained a neural network for generating Pareto optimal dose distributions, and evaluate the effects of the domain-specific loss on the model performance. Methods: In this study, three loss functions — mean squared error (MSE) loss, DVH loss, and adversarial (ADV) loss — were used to train and compare four instances of the neural network model: (a) MSE, (b) MSE + ADV, (c) MSE + DVH, and (d) MSE + DVH+ADV. The data for 70 prostate patients, including the planning target volume (PTV), and the organs at risk (OAR) were acquired as 96 × 96 × 24 dimension arrays at 5 mm3 voxel size. The dose influence arrays were calculated for 70 prostate patients, using a 7 equidistant coplanar beam setup. Using a scalarized multicriteria optimization for intensity-modulated radiation therapy, 1200 Pareto surface plans per patient were generated by pseudo-randomizing the PTV and OAR tradeoff weights. With 70 patients, the total number of plans generated was 84 000 plans. We divided the data into 54 training, 6 validation, and 10 testing patients. Each model was trained for a total of 100,000 iterations, with a batch size of 2. All models used the Adam optimizer, with a learning rate of 1 × 10−3. Results: Training for 100 000 iterations took 1.5 days (MSE), 3.5 days (MSE+ADV), 2.3 days (MSE+DVH), and 3.8 days (MSE+DVH+ADV). After training, the prediction time of each model is 0.052 s. Quantitatively, the MSE+DVH+ADV model had the lowest prediction error of 0.038 (conformation), 0.026 (homogeneity), 0.298 (R50), 1.65% (D95), 2.14% (D98), and 2.43% (D99). The MSE model had the worst prediction error of 0.134 (conformation), 0.041 (homogeneity), 0.520 (R50), 3.91% (D95), 4.33% (D98), and 4.60% (D99). For both the mean dose PTV error and the max dose PTV, Body, Bladder and rectum error, the MSE+DVH+ADV outperformed all other models. Regardless of model, all predictions have an average mean and max dose error &lt;2.8% and 4.2%, respectively. Conclusion: The MSE+DVH+ADV model performed the best in these categories, illustrating the importance of both human and learned domain knowledge. Expert human domain-specific knowledge can be the largest driver in the performance improvement, and adversarial learning can be used to further capture nuanced attributes in the data. The real-time prediction capabilities allow for a physician to quickly navigate the tradeoff space for a patient, and produce a dose distribution as a tangible endpoint for the dosimetrist to use for planning. This is expected to considerably reduce the treatment planning time, allowing for clinicians to focus their efforts on the difficult and demanding cases. © 2019 American Association of Physicists in Medicine","adversarial networks; deep learning; domain knowledge; dose volume histogram; intensity modulated radiation therapy; pareto optimality","John Wiley and Sons Ltd"
"Hayakawa S., Suzuki T.","On the minimax optimality and superiority of deep neural network learning over sparse parameter spaces",2020,"Neural Networks",5,"10.1016/j.neunet.2019.12.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077188477&doi=10.1016%2fj.neunet.2019.12.014&partnerID=40&md5=4dd4a53b3d2d9574ed0c4f1d197243ea","Deep learning has been applied to various tasks in the field of machine learning and has shown superiority to other common procedures such as kernel methods. To provide a better theoretical understanding of the reasons for its success, we discuss the performance of deep learning and other methods on a nonparametric regression problem with a Gaussian noise. Whereas existing theoretical studies of deep learning have been based mainly on mathematical theories of well-known function classes such as Hölder and Besov classes, we focus on function classes with discontinuity and sparsity, which are those naturally assumed in practice. To highlight the effectiveness of deep learning, we compare deep learning with a class of linear estimators representative of a class of shallow estimators. It is shown that the minimax risk of a linear estimator on the convex hull of a target function class does not differ from that of the original target function class. This results in the suboptimality of linear methods over a simple but non-convex function class, on which deep learning can attain nearly the minimax-optimal rate. In addition to this extreme case, we consider function classes with sparse wavelet coefficients. On these function classes, deep learning also attains the minimax rate up to log factors of the sample size, and linear methods are still suboptimal if the assumed sparsity is strong. We also point out that the parameter sharing of deep neural networks can remarkably reduce the complexity of the model in our setting. © 2019 The Author(s)","Deep learning; Linear estimator; Minimax optimality; Neural network; Nonparametric regression","Elsevier Ltd"
"You J., Ampomah W., Sun Q.","Development and application of a machine learning based multi-objective optimization workflow for CO2-EOR projects",2020,"Fuel",27,"10.1016/j.fuel.2019.116758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076238892&doi=10.1016%2fj.fuel.2019.116758&partnerID=40&md5=e1c80f653fb257d05bd6995edcfae1c5","Carbon dioxide-Enhanced Oil Recovery (CO2-EOR) is known as one of techniques for hydrocarbon production improvement as wells as an important candidate to reduce greenhouse gas emissions. Thus, an ideal development strategy for a CO2-EOR project would consider multiple objectives including to maximize oil recovery, CO2 storage volume and project economic outcomes. This work proposes a robust computational framework that couples artificial neural network (ANN) and multi-objective optimizers to optimize the aforementioned objectives in CO2-EOR processes simultaneously. Expert ANN systems are trained and employed as surrogate models of the high-fidelity compositional simulator in the optimization workflow. The robustness of the development optimization protocol is confirmed via a synthetic injection-pattern-base case study. Afterward a field implementation to Morrow-B formation to optimize the tertiary recovery stage of the field development is discussed. This work compares the optimum solution found using an aggregate objective function and the solution repository (Pareto front) generated by the multi-objective optimization process. The comparison indicates the existence of potential multi-solutions satisfying certain criteria in a CO2-EOR project designing, which cannot be found using traditional weighted sum method. The optimization results provide significant insight into the decision-making process of CO2-EOR project when multiple objective functions are considered. © 2019 Elsevier Ltd","Artificial neural network; Carbon dioxide sequestration; CO2-EOR; Multi-objective optimization","Elsevier Ltd"
"Martínez-García J.-A., Sancho-Gómez J.-L., Sánchez-Morales A., Figueiras-Vidal A.R.","Designing non-linear minimax and related discriminants by disjoint tangent configurations applied to RBF networks",2020,"Neurocomputing",,"10.1016/j.neucom.2019.12.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076849492&doi=10.1016%2fj.neucom.2019.12.016&partnerID=40&md5=609d9266ad45747096a8af4ccd3176b1","Non-linear classification machines seldom are trained under criteria that are usual and useful for linear discriminants, such as minimax, Fisher's, and other similar criteria. The reason is the learning difficulties that transformation-trainable machines suffer when applying such criteria. However, the possibility of using non-linear machines whose transformations are pre-designed merits attention. In this contribution, we propose and study an efficient and potentially effective option: Applying Disjoint Tangent Configurations (DTC), a formulation that includes discriminants such as Fisher's, Bayes for normal distributions, Minimax Probabilistic Decision Hyperplane (MPDH), and others, to the output of a Radial Basis Function (RBF) network which has been previously designed with a moderate number of nodes to reduce the computational load, but with a high quality centroid selection algorithm, Frequency Sensitive Competitive Learning (FSCL), which allows to obtain networks with high representation capabilities. Experiments demonstrate that this approach leads to good performance results with acceptable computational efforts. © 2019 Elsevier B.V.","Binary classification; Minimax; Non-linear discriminants; Radial basis functions; Single-hidden layer feedforward networks","Elsevier B.V."
"Tian L., Li X., Ye Y., Xie P., Li Y.","A Generative Adversarial Gated Recurrent Unit Model for Precipitation Nowcasting",2020,"IEEE Geoscience and Remote Sensing Letters",22,"10.1109/LGRS.2019.2926776","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082885321&doi=10.1109%2fLGRS.2019.2926776&partnerID=40&md5=9f918ad0c49ae9ec1edc85edc6f658e7","Precipitation nowcasting is an important task in operational weather forecasts. The key challenge of the task is the radar echo map extrapolation. The problem is mainly solved by an optical-flow method in existing systems. However, the method cannot model rapid and nonlinear movements. Recently, a convolutional gated recurrent unit (ConvGRU) method is developed, which aims to model such movements based on deep learning techniques. Despite the promising performance, ConvGRU tends to yield blurring extrapolation images and fails to multi-modal and skewed intensity distribution. To overcome the limitations, we propose in this letter a generative adversarial ConvGRU (GA-ConvGRU) model. The model is composed of two adversarial learning systems, which are a ConvGRU-based generator and a convolution neural network-based discriminator. The two systems are trained by playing a minimax game. With the adversarial learning scheme, GA-ConvGRU can yield more realistic and more accurate extrapolation. Experiments on real data sets have been conducted and the results demonstrate that the proposed GA-ConvGRU significantly outperforms state-of-the-art extrapolation methods ConvGRU and optical flow. © 2004-2012 IEEE.","Deep learning; image sequence prediction; nowcasting; radar echo extrapolation","Institute of Electrical and Electronics Engineers Inc."
"Ceryan N., Samui P.","Application of soft computing methods in predicting uniaxial compressive strength of the volcanic rocks with different weathering degree",2020,"Arabian Journal of Geosciences",13,"10.1007/s12517-020-5273-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082310759&doi=10.1007%2fs12517-020-5273-4&partnerID=40&md5=767ec2837d3867ae8b9f3fb25d446722","Uniaxial compressive strength (UCS) of rock material is very important parameter for rock engineering applications such as rock mass classification, numerical modelling bearing capacity, mechanical excavation, slope stability and supporting with respect to the engineering behaviors’ of rock. UCS is obtained directly or can be predicted by different methods including using existing tables and diagrams, regression, Bayesian approach and soft computing methods. The main purpose of this study is to examine the applicability and capability of the Extreme Learning Machine (ELM), Minimax Probability Machine Regression (MPMR) for prediction of UCS of the volcanic rocks and to compare its performance with Least Square Support Vector Machine (LS-SVM). The samples tested were taken from the volcanic rock masses exposed at the eastern Pontides (NE Turkey). In the soft computing model to estimate UCS of the samples investigated, porosity and slake durability index were used as input parameters. In this study, the root mean square error (RMSE), variance account factor (VAF), maximum determination coefficient value (R2), adjusted determination coefficient (Adj. R2) and performance index (PI), regression error characteristic (REC) curve and Taylor diagram were used to determine the accuracy of the ELM, MPMR and LS-SVM models developed. © 2020, Saudi Society for Geosciences.","Extreme learning machine; Least square support vector machine; Minimax probability machine regression; Porosity; Slake durability index; Uniaxial compressive strength; Volcanic rock","Springer"
"Gataric M., Wang T., Samworth R.J.","Sparse principal component analysis via axis-aligned random projections",2020,"Journal of the Royal Statistical Society. Series B: Statistical Methodology",4,"10.1111/rssb.12360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078660318&doi=10.1111%2frssb.12360&partnerID=40&md5=1dda6034fb7d3962a7212f210ba4bd04","We introduce a new method for sparse principal component analysis, based on the aggregation of eigenvector information from carefully selected axis-aligned random projections of the sample covariance matrix. Unlike most alternative approaches, our algorithm is non-iterative, so it is not vulnerable to a bad choice of initialization. We provide theoretical guarantees under which our principal subspace estimator can attain the minimax optimal rate of convergence in polynomial time. In addition, our theory provides a more refined understanding of the statistical and computational trade-off in the problem of sparse principal component estimation, revealing a subtle interplay between the effective sample size and the number of random projections that are required to achieve the minimax optimal rate. Numerical studies provide further insight into the procedure and confirm its highly competitive finite sample performance. © 2020 The Authors Journal of the Royal Statistical Society: Series B (Statistical Methodology) Published by John Wiley & Sons Ltd on behalf of the Royal Statistical Society.","Dimensionality reduction; Eigenspace estimation; Ensemble learning; Sketching; Statistical and computational trade-offs","Blackwell Publishing Ltd"
"Lu Y., Chen G., Yin Q., Sun H., Hou M.","Solving the ruin probabilities of some risk models with Legendre neural network algorithm",2020,"Digital Signal Processing: A Review Journal",6,"10.1016/j.dsp.2019.102634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077673427&doi=10.1016%2fj.dsp.2019.102634&partnerID=40&md5=1d3d1ce066bc47a83ecd03cdabd4d52c","This paper studies a numerical method based on Legendre polynomials and extreme learning machine algorithm to solve the ruin probabilities in the classical risk model and the Erlang(2) risk model. In our method, the hidden layer is eliminated by expanding the input pattern using Legendre polynomials. The network parameters are obtained by solving a system of linear equations using extreme learning machine algorithm. The numerical experiments of some risk models under exponential distribution and Pareto distribution have been performed to validate the accuracy and reliability of our proposed Legendre neural network algorithm. Compared with the existing method, the results obtained by our proposed Legendre neural network model can achieve very high accuracy. Legendre neural network algorithm is well suited for solving the ruin probabilities of the risk models. © 2019 Elsevier Inc.","Approximate solutions; Classical risk model; Erlang(2) risk model; Legendre neural network algorithm; Ruin probability","Elsevier Inc."
"Borisov A., Bosov A., Miller B., Miller G.","Passive underwater target tracking: Conditionally minimax nonlinear filtering with bearing-doppler observations",2020,"Sensors (Switzerland)",4,"10.3390/s20082257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083718275&doi=10.3390%2fs20082257&partnerID=40&md5=a2f64af9d3454dc718127147f391770d","The paper presents an application of the Conditionally-Minimax Nonlinear Filtering (CMNF) algorithm to the online estimation of underwater vehicle movement given a combination of sonar and Doppler discrete-time noisy sensor observations. The proposed filter postulates recurrent “prediction–correction” form with some predefined basic prediction and correction terms, and then they are optimally fused. The CMNF estimates have the following advantageous features. First, the obtained estimates are unbiased. Second, the theoretical covariance matrix of CMNF errors meets the real values. Third, the CMNF algorithm gives a possibility to choose the preliminary observation transform, basic prediction, and correction functions in any specific case of the observation system to improve the estimate accuracy significantly. All the features of conditionally-minimax estimates are demonstrated by the regression example of random position estimate given the noisy bearing observations. The contribution of the paper is the numerical study of the CMNF algorithm applied to the underwater target tracking given bearing-only and bearing-Doppler observations. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Bearing-Doppler measurements; Bearing-only measurements; Conditionally minimax nonlinear filter; Machine learning; Nonlinear filtering; Port-starboard ambiguity; Underwater target tracking","MDPI AG"
"Zhou Y., Zheng S.","Machine learning-based multi-objective optimisation of an aerogel glazing system using NSGA-II—study of modelling and application in the subtropical climate Hong Kong",2020,"Journal of Cleaner Production",14,"10.1016/j.jclepro.2020.119964","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077504580&doi=10.1016%2fj.jclepro.2020.119964&partnerID=40&md5=b43b223d902b165284b510385b85b29b","Application of super-insulating materials in building glazing system shows promising prospects for low-energy buildings. In this research, the heat transfer, solar radiation transmission and indoor illuminance of an aerogel glazing system were characterized through an experimentally validated numerical model. Contribution ratios of multi-variables to multi-objectives were thereafter quantified, following the Taguchi standard orthogonal array. In respect to the application of aerogel glazing system in subtropical climates, an energy-related contradiction between indoor illuminance from solar and indoor heat gain, has been presented, discussed, together with effective solutions. In order to minimise the total heat gain and maximise the indoor illuminance transmitted through the aerogel glazing system, a generic multi-objective optimisation methodology, with high computational efficiency and accuracy, has been developed, to identify the optimal design. The results indicate that through the Pareto front from the multi-objective optimisation results, a significant reduction of total heat gain and an obvious increase of the indoor illuminance can be noticed. Compared to the optimal case in the standard orthogonal array, with the application of the proposed multi-objective optimisation methodology, the annual total heat gain could be reduced from 489305.5 to 333396.4 Wh by 31.9% and the annual indoor illuminance could be increased from 56786.6 to 172973.5 lux by 67.2%. The year-round performance indicates that, compared to the bi-objective optimisation (annual transmitted heat gain and annual indoor illuminance) with the annual total heat gain at 333.4 kWh/m2 and annual indoor illuminance at 162.3 klux, the bi-objective optimisation (annual total heat gain and annual indoor illuminance) shows a lower annual total heat gain at 322.4 kWh/m2 by 3.4%) and a higher annual indoor illuminance at 173 klux by 6.6%. This study proposes an overall framework and technical guidance of a new multi-objective optimisation methodology, which can automatically learn mechanisms of heat transfer and solar radiation transmittance through nanoporous aerogel granules, and identify the optimal multi-variables setting for the robust system design and operation. © 2020 Elsevier Ltd","Aerogel glazing system; Indoor heat gain; Indoor illuminance; Machine learning; Multi-criteria decision making; Multi-objective optimisation","Elsevier Ltd"
"Liu Y., Yin J., Yu D., Zhao S., Shen J.","Multiple people tracking with articulation detection and stitching strategy",2020,"Neurocomputing",6,"10.1016/j.neucom.2019.12.037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077365413&doi=10.1016%2fj.neucom.2019.12.037&partnerID=40&md5=2c01f0f1decbd96bc51540a73f67e56a","Multiple people tracking in a monocular video of crowded scenes is a challenging problem, methods of which are mostly based on tracking-by-detection strategies. The result of detection preprocessing used by many tracking methods to avoid creating wrong targets, is likely to be contaminated when there are defective detections in datasets of benchmark. We propose an articulation-based detection selecting method to screen out detections unqualified for further processing. For the association part of tracking workflow, applying minimax operation can minimize the max intra-distance but results in discontinuous trajectories. We design a stitching strategy to link the tracklets created by minimax algorithm. The experimental results will demonstrate that the proposed method outperforms or is comparable to previous approaches. © 2019","Articulation detection; Multiple people tracking; Stitching strategy","Elsevier B.V."
"Zhang S., Li W., Wang C., Tari Z., Zomaya A.Y.","DyBatch: Efficient Batching and Fair Scheduling for Deep Learning Inference on Time-sharing Devices",2020,"Proceedings - 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGRID 2020",,"10.1109/CCGrid49817.2020.00-32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089081017&doi=10.1109%2fCCGrid49817.2020.00-32&partnerID=40&md5=c37800f0479b136e4c7f991bb185062a","Recently, Deep Learning (DL) is widely applied to intelligent systems equipped with resource-constraint hardware accelerators. With multiple DL applications sharing the resource, the execution model can be divided into two stages: (i) batching independent inference tasks initiated by each application, and (ii) scheduling batches to run in a time-sharing manner. The state-of-the-art DL serving systems employ the execution model by organizing sequential tasks into batches and then scheduling batches concerning their targeting deep neural network (DNN) models in a round-robin manner. However, we demonstrated that these practices fail to alleviate the slowdown of tasks, and there is a need to re-visit batching and scheduling in terms of efficiency and fairness. To this end, we formulated batching as a resource allocation problem and investigated scheduling in terms of each application's utilization on the device. Then, we proposed the fine-grained batching scheme and fairness-driven scheduling scheme for DL serving and implemented a prototype system called DyBatch. To be exact, DyBatch accomplishes efficient batching by taking into account Pareto efficiency of and envy between batches. Besides, DyBatch's fair scheduler monitors the resource utilization of all applications and assigns a batch from the application with the lowest utilization for execution first. Evaluation under various benchmarks with comparison to the baseline system Tensorflow Serving (TFS) shows the superiority of DyBatch, which achieves up to 55% reduction of slowdown, and up to 12% improvement of throughput. © 2020 IEEE.","batching; deep learning inference; efficiency; fairness; model serving; scheduling","Institute of Electrical and Electronics Engineers Inc."
"Fresard M.E., Erices R., Bravo M.L., Cuello M., Owen G.I., Ibanez C., Rodriguez-Fernandez M.","Multi-Objective Optimization for Personalized Prediction of Venous Thromboembolism in Ovarian Cancer Patients",2020,"IEEE Journal of Biomedical and Health Informatics",7,"10.1109/JBHI.2019.2943499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084720538&doi=10.1109%2fJBHI.2019.2943499&partnerID=40&md5=10a3ca2e1ff6aafda104c3435b557b88","Thrombotic events are one of the leading causes of mortality and morbidity related to cancer, with ovarian cancer having one of the highest incidence rates. The need to prevent these events through the prescription of adequate schemes of antithrombotic prophylaxis has motivated the development of models that aid the identification of patients at higher risk of thrombotic events with lethal consequences. However, antithrombotic prophylaxis increases the risk of bleeding and this risk depends on the class and intensity of the chosen antithrombotic prophylactic scheme, the clinical and personal condition of the patient and the disease characteristics. Moreover, the datasets used to obtain current models are imbalanced, i.e., they incorporate more patients who did not suffer thrombotic events than patients who experienced them what can lead to wrong predictions, especially for the clinically relevant patient group at high risk of thrombosis. Herein, predictive models based on machine learning were developed utilizing 121 high-grade serous ovarian carcinoma patients, considering the clinical variables of the patients and those typical of the disease. To properly manage the data imbalance, cost-sensitive classification together with multi-objective optimization was performed considering different combinations of metrics. In this way, five Pareto fronts and a series of optimal models with different false positive and false negative rates were obtained. With this novel approach to the development of clinical predictive models, personalized models can be developed, helping the clinician to achieve a better balance between the risk of bleeding and the risk of thrombosis. © 2013 IEEE.","Clinical biomarkers; multi-objective optimization; ovarian cancer; prediction models; venous thromboembolism","Institute of Electrical and Electronics Engineers Inc."
"Pantula P.D., Mitra K.","Towards Efficient Robust Optimization using Data based Optimal Segmentation of Uncertain Space",2020,"Reliability Engineering and System Safety",17,"10.1016/j.ress.2020.106821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078707908&doi=10.1016%2fj.ress.2020.106821&partnerID=40&md5=2e4bcb139d5acc3578e041ac5b42b935","Performing multi-objective optimization under uncertainty is a common requirement in industries and academia. Robust optimization (RO) is considered as an efficient and tractable approach provided one has access to behavioral data for the uncertain parameters. However, solutions of RO may be far from the real solution and less reliable due to inability to map the uncertain space accurately, especially when the data appears discontinuous and scattered in the uncertain domain. Amalgamating machine learning algorithms with RO, this paper proposes a data-driven methodology, where a novel fuzzy clustering mechanism is implemented along-with boundary construction, to transcript the uncertain space such that the specific regions of uncertainty are identified. Subsequently, using intelligent Sobol sampling, samples are generated in the mapped uncertain regions. Results of two test cases are presented along with a comprehensive comparison study. Considered case-studies include highly nonlinear model for continuous casting process from steelmaking industries, where a multi-objective optimization problem under uncertainty is solved to balance the conflict between productivity and energy consumption. The Pareto-optimal solutions of the resulting RO problem are obtained through Non-Dominated Sorting Genetic Algorithm – II, and ~23–29% improvement is observed in the uncertain objective function. Further, the spread and diversity metrics are enhanced by ~10–95% as compared to those obtained using other standard uncertainty sets. © 2020 Elsevier Ltd","Boundary construction; Data-driven robust optimization; Fuzzy clustering; Multi-objective optimization; Pareto-optimal solutions; Sobol sampling","Elsevier Ltd"
"Moradi B.","The new optimization algorithm for the vehicle routing problem with time windows using multi-objective discrete learnable evolution model",2020,"Soft Computing",6,"10.1007/s00500-019-04312-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073952870&doi=10.1007%2fs00500-019-04312-9&partnerID=40&md5=8d91819a3b1c68d134d4c53bacc3dd2e","This paper presents a new multi-objective discreet learnable evolution model (MODLEM) to address the vehicle routing problem with time windows (VRPTW). Learnable evolution model (LEM) includes a machine learning algorithm, like the decision trees, that can discover the correct directions of the evolution leading to significant improvements in the fitness of the individuals. We incorporate a robust strength Pareto evolutionary algorithm in the LEM presented here to govern the multi-objective property of this approach. A new priority-based encoding scheme for chromosome representation in the LEM as well as corresponding routing scheme is introduced. To improve the quality and the diversity of the initial population, we propose a novel heuristic manner which leads to a good approximation of the Pareto fronts within a reasonable computational time. Moreover, a new heuristic operator is employed in the instantiating process to confront incomplete chromosome formation. Our proposed MODLEM is tested on the problem instances of Solomon’s VRPTW benchmark. The performance of this proposed MODLEM for the VRPTW is assessed against the state-of-the-art approaches in terms of both the quality of solutions and the computational time. Experimental results and comparisons indicate the effectiveness and efficiency of our proposed intelligent routing approach. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Learnable evolution model (LEM); Multi-objective combinatorial optimization (MOCO); Strength Pareto evolutionary algorithm (SPEA); Vehicle routing problem with time windows (VRPTW)","Springer"
"Dutta D., Sil J., Dutta P.","A bi-phased multi-objective genetic algorithm based classifier",2020,"Expert Systems with Applications",9,"10.1016/j.eswa.2019.113163","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077766943&doi=10.1016%2fj.eswa.2019.113163&partnerID=40&md5=4c08a3eb9b115471002d8f8a56bf7828","This paper presents a novel Bi-Phased Multi-Objective Genetic Algorithm (BPMOGA) based classification method. It is a Learning Classifier System (LCS) designed for supervised learning tasks. Here we have used Genetic Algorithms (GAs) to discover optimal classifiers from data sets. The objective of the work is to find out a classifier or Complete Rule (CR) which comprises of several Class Specific Rules (CSRs). Phase-I of BPMOGA extracts optimized CSRs in IF−THEN form by following Michigan approach, without considering interaction among the rules. Phase-II of BPMOGA builds optimized CRs from CSRs by following Pittsburgh way. It combines the advantages of both approaches. Extracted CRs help to build CSRs for the next run of phase-I. Hence, phase-I and phase-II are cyclically related, which is one of the uniqueness of BPMOGA. With the help of twenty one benchmark data sets from the University of California at Irvine (UCI) machine learning repository we have compared performance of BPMOGA based classifier with fourteen GA and non-GA based classifiers. Statistical test shows that the performance of the proposed classifier is either superior or comparable to other classifiers. © 2019","Classification rules mining; Elitist Multi-Objective Genetic Algorithm; Pareto approach; Statistical test","Elsevier Ltd"
"Jiang W., Hu D., Yu C., Li M., Zhao Z.-Q.","A new steganography without embedding based on adversarial training",2020,"ACM International Conference Proceeding Series",,"10.1145/3393527.3393564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095848321&doi=10.1145%2f3393527.3393564&partnerID=40&md5=c98efbe389931550d3c9fd19607cae21","Steganography is an art to hide information in the carriers to prevent from being detected, while steganalysis is the opposite art to detect the presence of the hidden information. With the development of deep learning, several state-of-the-art steganography and steganalysis based on deep learning techniques have been proposed to improve hiding or detection capabilities. Generative Adversarial Networks (GANs) based steganography directly uses the minimax game between the generator and discriminator, to automatically generate steganography algorithms resisting being detected by powerful steganalysis. The steganography without embedding (SWE) based on GANs, where the generated cover images themselves are stego ones carrying secret information has shown its state-of-the-art steganography performance. However, SWE based on GANs has serious weaknesses, such as low information recovery accuracy, low steganography capacity and poor natural showing. To solve these problems, this paper proposes a new SWE based on adversarial training, with carefully designed generator, discriminator and extractor, as well as their loss functions and optimized training mode. The proposed method can achieve a very high information recovery accuracy (100% in some cases), and at the same time improve the steganography capacity and image quality. © 2020 ACM.","Generative adversarial networks; Steganalysis; Steganography; Steganography without embedding","Association for Computing Machinery"
"Brereton A.E., MacKinnon S., Safikhani Z., Reeves S., Alwas S., Shahani V., Windemuth A.","Predicting drug properties with parameter-free machine learning: Pareto-optimal embedded modeling (POEM)",2020,"Machine Learning: Science and Technology",5,"10.1088/2632-2153/ab891b","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107870990&doi=10.1088%2f2632-2153%2fab891b&partnerID=40&md5=0f0dcf0adea2104723ff10385fc00667","The prediction of absorption, distribution, metabolism, excretion, and toxicity (ADMET) of small molecules from their molecular structure is a central problem in medicinal chemistry with great practical importance in drug discovery. Creating predictive models conventionally requires substantial trial-and-error for the selection of molecular representations, machine learning (ML) algorithms, and hyperparameter tuning. A generally applicable method that performs well on all datasets without tuning would be of great value but is currently lacking. Here, we describe pareto-optimal embedded modeling (POEM), a similarity-based method for predicting molecular properties. POEM is a non-parametric, supervised ML algorithm developed to generate reliable predictive models without need for optimization. POEM's predictive strength is obtained by combining multiple different representations of molecular structures in a context-specific manner, while maintaining low dimensionality. We benchmark POEM relative to industry-standard ML algorithms and published results across 17 classifications tasks. POEM performs well in all cases and reduces the risk of overfitting. ©2020 The Author(s).","ADMET; Molecular graph convolution; POEM; Prediction; Random forest; Small molecule; SVM","IOP Publishing Ltd"
"Cannings T.I., Berrett T.B., Samworth R.J.","Local nearest neighbour classification with applications to semi-supervised learning",2020,"Annals of Statistics",6,"10.1214/19-AOS1868","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090452798&doi=10.1214%2f19-AOS1868&partnerID=40&md5=7d9d2fedc6401e4803e592a0d2f62e0e","We derive a new asymptotic expansion for the global excess risk of a local-k-nearest neighbour classifier, where the choice of k may depend upon the test point. This expansion elucidates conditions under which the dominant contribution to the excess risk comes from the decision boundary of the optimal Bayes classifier, but we also show that if these conditions are not satisfied, then the dominant contribution may arise from the tails of the marginal distribution of the features. Moreover, we prove that, provided the d-dimensional marginal distribution of the features has a finite ρth moment for some ρ &gt; 4 (as well as other regularity conditions), a local choice of k can yield a rate of convergence of the excess risk of O(n-4/(d+4)), where n is the sample size, whereas for the standard k-nearest neighbour classifier, our theory would require d ≥ 5 and ρ &gt; 4d/(d - 4) finite moments to achieve this rate. These results motivate a new k-nearest neighbour classifier for semi-supervised learning problems, where the unlabelled data are used to obtain an estimate of the marginal feature density, and fewer neighbours are used for classification when this density estimate is small. Our worst-case rates are complemented by a minimax lower bound, which reveals that the local, semi-supervised k-nearest neighbour classifier attains the minimax optimal rate over our classes for the excess risk, up to a subpolynomial factor in n. These theoretical improvements over the standard k-nearest neighbour classifier are also illustrated through a simulation study. © Institute of Mathematical Statistics, 2020.","Classification problems; Nearest neighbours; Nonparametric classification; Semi-supervised learning","Institute of Mathematical Statistics"
"Fischer A., Janneck J., Kussmaul J., Kratzschmar N., Kerschbaum F., Bodden E.","PASAPTO: Policy-aware Security and Performance Trade-off Analysis - Computation on Encrypted Data with Restricted Leakage",2020,"Proceedings - IEEE Computer Security Foundations Symposium",,"10.1109/CSF49147.2020.00024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090451994&doi=10.1109%2fCSF49147.2020.00024&partnerID=40&md5=356c3e2e480fd9e3ab65e9c279ceeee2","This work considers the trade-off between security and performance when revealing partial information about encrypted data computed on. The focus of our work is on information revealed through control flow side-channels when executing programs on encrypted data. We use quantitative information flow to measure security, running time to measure performance and program transformation techniques to alter the trade-off between the two. Combined with information flow policies, we perform a policy-aware security and performance trade-off (PASAPTO) analysis. We formalize the problem of PASAPTO analysis as an optimization problem, prove the NPhardness of the corresponding decision problem and present two algorithms solving it heuristically.We implemented our algorithms and combined them with the Dataflow Authentication (DFAuth) approach for outsourcing sensitive computations. Our DFAuth Trade-off Analyzer (DFATA) takes Java Bytecode operating on plaintext data and an associated information flow policy as input. It outputs semantically equivalent program variants operating on encrypted data which are policy-compliant and approximately Pareto-optimal with respect to leakage and performance. We evaluated DFATA in a commercial cloud environment using Java programs, e.g., a decision tree program performing machine learning on medical data. The decision tree variant with the worst performance is 357% slower than the fastest variant. Leakage varies between 0% and 17% of the input. © 2020 IEEE.",,"IEEE Computer Society"
"Sadeghi B., Boddeti V.N.","Imparting fairness to pre-trained biased representations",2020,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",3,"10.1109/CVPRW50498.2020.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090116609&doi=10.1109%2fCVPRW50498.2020.00016&partnerID=40&md5=f2ec9b1fc91efbf3aa98f21d2ff482db","Adversarial representation learning is a promising paradigm for obtaining data representations that are invariant to certain sensitive attributes while retaining the information necessary for predicting target attributes. Existing approaches solve this problem through iterative adversarial minimax optimization and lack theoretical guarantees. In this paper, we first study the ""linear"" form of this problem i.e., the setting where all the players are linear functions. We show that the resulting optimization problem is both non-convex and non-differentiable. We obtain an exact closed-form expression for its global optima through spectral learning. We then extend this solution and analysis to non-linear functions through kernel representation. Numerical experiments on UCI and CIFAR-100 datasets indicate that, (a) practically, our solution is ideal for ""imparting"" provable invariance to any biased pre-trained data representation, and (b) empirically, the trade-off between utility and invariance provided by our solution is comparable to iterative minimax optimization of existing deep neural network based approaches.Code is available at Human Analysis Lab. © 2020 IEEE.",,"IEEE Computer Society"
"Legaard K., Simons-Legaard E., Weiskittel A.","Multi-objective support vector regression reduces systematic error in moderate resolution maps of tree species abundance",2020,"Remote Sensing",3,"10.3390/rs12111739","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086451591&doi=10.3390%2frs12111739&partnerID=40&md5=080a0f9082ac514fb97addce9ccea1ba","When forest conditions are mapped from empirical models, uncertainty in remotely sensed predictor variables can cause the systematic overestimation of low values, underestimation of high values, and suppression of variability. This regression dilution or attenuation bias is a well-recognized problem in remote sensing applications, with few practical solutions. Attenuation is of particular concern for applications that are responsive to prediction patterns at the high end of observed data ranges, where systematic error is typically greatest. We addressed attenuation bias in models of tree species relative abundance (percent of total aboveground live biomass) based on multitemporal Landsat and topoclimatic predictor data. We developed a multi-objective support vector regression (MOSVR) algorithm that simultaneously minimizes total prediction error and systematic error caused by attenuation bias. Applied to 13 tree species in the Acadian Forest Region of the northeastern U.S., MOSVR performed well compared to other prediction methods including single-objective SVR (SOSVR) minimizing total error, Random Forest (RF), gradient nearest neighbor (GNN), and Random Forest nearest neighbor (RFNN) algorithms. SOSVR and RF yielded the lowest total prediction error but produced the greatest systematic error, consistent with strong attenuation bias. Underestimation at high relative abundance caused strong deviations between predicted patterns of species dominance/codominance and those observed at field plots. In contrast, GNN and RFNN produced dominance/codominance patterns that deviated little from observed patterns, but predicted species relative abundance with lower accuracy and substantial systematic error. MOSVR produced the least systematic error for all species with total error often comparable to SOSVR or RF. Predicted patterns of dominance/codominance matched observations well, though not quite as well as GNN or RFNN. Overall, MOSVR provides an effective machine learning approach to the reduction of systematic prediction error and should be fully generalizable to other remote sensing applications and prediction problems. © 2020 by the authors.","Attenuation bias; Genetic algorithm; Multi-objective optimization; Pareto optimization; Regression; Regression dilution bias; Species abundance; Species distribution modeling; Species dominance; Support vector machines","MDPI AG"
"Adayel R., Bazi Y., Alhichri H., Alajlan N.","Deep open-set domain adaptation for cross-scene classification based on adversarial learning and pareto ranking",2020,"Remote Sensing",11,"10.3390/rs12111716","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086443277&doi=10.3390%2frs12111716&partnerID=40&md5=afd9954360cc80fe792d4e0cd09bd15f","Most of the existing domain adaptation (DA) methods proposed in the context of remote sensing imagery assume the presence of the same land-cover classes in the source and target domains. Yet, this assumption is not always realistic in practice as the target domain may contain additional classes unknown to the source leading to the so-called open set DA. Under this challenging setting, the problem turns to reducing the distribution discrepancy between the shared classes in both domains besides the detection of the unknown class samples in the target domain. To deal with the openset problem, we propose an approach based on adversarial learning and pareto-based ranking. In particular, the method leverages the distribution discrepancy between the source and target domains using min-max entropy optimization. During the alignment process, it identifies candidate samples of the unknown class from the target domain through a pareto-based ranking scheme that uses ambiguity criteria based on entropy and the distance to source class prototype. Promising results using two cross-domain datasets that consist of very high resolution and extremely high resolution images, show the effectiveness of the proposed method. © 2020 by the authors.","Adversarial learning; Min-max entropy; Open-set domain adaptation; Pareto ranking; Scene classification","MDPI AG"
"Fan K., Cosenza B., Juurlink B.","Accurate energy and performance prediction for frequency-scaled GPU kernels",2020,"Computation",1,"10.3390/COMPUTATION8020037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085473186&doi=10.3390%2fCOMPUTATION8020037&partnerID=40&md5=5144eca51c6d3242109b15366098a4b1","Energy optimization is an increasingly important aspect of today's high-performance computing applications. In particular, dynamic voltage and frequency scaling (DVFS) has become a widely adopted solution to balance performance and energy consumption, and hardware vendors providemanagement libraries that allowthe programmer to change bothmemory and core frequencies manually to minimize energy consumption while maximizing performance. This article focuses on modeling the energy consumption and speedup of GPU applications while using different frequency configurations. The task is not straightforward, because of the large set of possible and uniformly distributed configurations and because of the multi-objective nature of the problem, which minimizes energy consumption and maximizes performance. This article proposes a machine learning-based method to predict the best core and memory frequency configurations on GPUs for an input OpenCL kernel. The method is based on two models for speedup and normalized energy predictions over the default frequency configuration. Those are later combined into a multi-objective approach that predicts a Pareto-set of frequency configurations. Results show that our approach is very accurate at predicting extema and the Pareto set, and finds frequency configurations that dominate the default configuration in either energy or performance. © 2020 by the authors.","Energy efficiency; Frequency scaling; GPU; Modeling","MDPI Multidisciplinary Digital Publishing Institute"
"Islam M.M., Tasnim N., Baek J.-H.","Human gender classification using transfer learning via pareto frontier CNN networks",2020,"Inventions",6,"10.3390/inventions5020016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085018997&doi=10.3390%2finventions5020016&partnerID=40&md5=f9a828402d8506e5734d1710b234da42","Human gender is deemed as a prime demographic trait due to its various usage in the practical domain. Human gender classification in an unconstrained environment is a sophisticated task due to large variations in the image scenarios. Due to the multifariousness of internet images, the classification accuracy suffers from traditional machine learning methods. The aim of this research is to streamline the gender classification process using the transfer learning concept. This research proposes a framework that performs automatic gender classification in unconstrained internet images deploying Pareto frontier deep learning networks; GoogleNet, SqueezeNet, and ResNet50. We analyze the experiment with three different Pareto frontier Convolutional Neural Network (CNN) models pre-trained on ImageNet. The massive experiments demonstrate that the performance of the Pareto frontier CNN networks is remarkable in the unconstrained internet image dataset as well as in the frontal images that pave the way to developing an automatic gender classification system. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Automatic gender classification; GoogLeNet; Pareto frontier networks; Pre-trained CNN; ResNet50; SqueezeNet; Transfer learning","MDPI Multidisciplinary Digital Publishing Institute"
"Kalita K., Mukhopadhyay T., Dey P., Haldar S.","Genetic programming-assisted multi-scale optimization for multi-objective dynamic performance of laminated composites: the advantage of more elementary-level analyses",2020,"Neural Computing and Applications",14,"10.1007/s00521-019-04280-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067840928&doi=10.1007%2fs00521-019-04280-z&partnerID=40&md5=1f016086f54ac86b07f2ace26b809d4e","High-fidelity multi-scale design optimization of many real-life applications in structural engineering still remains largely intractable due to the computationally intensive nature of numerical solvers like finite element method. Thus, in this paper, an alternate route of metamodel-based design optimization methodology is proposed in multi-scale framework based on a symbolic regression implemented using genetic programming (GP) coupled with d-optimal design. This approach drastically cuts the computational costs by replacing the finite element module with appropriately constructed robust and efficient metamodels. Resulting models are compact, have good interpretability and assume a free-form expression capable of capturing the non-linearly, complexity and vastness of the design space. Two robust nature-inspired optimization algorithms, viz. multi-objective genetic algorithm and multi-objective particle swarm optimization, are used to generate Pareto optimal solutions for several test problems with varying complexity. TOPSIS, a multi-criteria decision-making approach, is then applied to choose the best alternative among the Pareto optimal sets. Finally, the applicability of GP in efficiently tackling multi-scale optimization problems of composites is investigated, where a real-life scenario is explored by varying fractions of pertinent engineering materials to bring about property changes in the final composite structure across two different scales. The study reveals that a microscale optimization leads to better optimized solutions, demonstrating the advantage of carrying out a multi-scale optimization without any additional computational burden. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","d-Optimal design; Genetic programming; Machine learning-based optimization; Multi-scale optimization; Robust composite structures; Symbolic regression","Springer"
"Shah D., Xie Q., Xu Z.","Non-Asymptotic Analysis of Monte Carlo Tree Search",2020,"SIGMETRICS Performance 2020 - Abstracts of the 2020 SIGMETRICS/Performance Joint International Conference on Measurement and Modeling of Computer Systems",4,"10.1145/3393691.3394202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086998977&doi=10.1145%2f3393691.3394202&partnerID=40&md5=9e62d984382309704cf7396e6f8124a9","In this work, we consider the popular tree-based search strategy within the framework of reinforcement learning, the Monte Carlo Tree Search (MCTS), in the context of infinite-horizon discounted cost Markov Decision Process (MDP) with deterministic transitions. While MCTS is believed to provide an approximate value function for a given state with enough simulations, cf. [Kocsis and Szepesvari 2006; Kocsis et al. 2006], the claimed proof of this property is incomplete. This is due to the fact that the variant of MCTS, the Upper Confidence Bound for Trees (UCT), analyzed in prior works utilizes ""logarithmic"" bonus term for balancing exploration and exploitation within the tree-based search, following the insights from stochastic multi-arm bandit (MAB) literature, cf. [Agrawal 1995; Auer et al. 2002]. In effect, such an approach assumes that the regret of the underlying recursively dependent non-stationary MABs concentrates around their mean exponentially in the number of steps, which is unlikely to hold as pointed out in [Audibert et al. 2009], even for stationary MABs. As the key contribution of this work, we establish polynomial concentration property of regret for a class of non-stationary multi-arm bandits. This in turn establishes that the MCTS with appropriate polynomial rather than logarithmic bonus term in UCB has the claimed property of [Kocsis and Szepesvari 2006; Kocsis et al. 2006]. Interestingly enough, empirically successful approaches (cf. [Silver et al. 2017]) utilize a similar polynomial form of MCTS as suggested by our result. Using this as a building block, we argue that MCTS, combined with nearest neighbor supervised learning, acts as a ""policy improvement"" operator, i.e., it iteratively improves value function approximation for all states, due to combining with supervised learning, despite evaluating at only finitely many states. In effect, we establish that to learn an ϵ-approximation of the value function for deterministic MDPs with respect to ĝ.,""∞ norm, MCTS combined with nearest neighbor requires a sample size scaling as Õ (ϵ-(d+4), where d is the dimension of the state space. This is nearly optimal due to a minimax lower bound of ĝ1/4ω (ϵ-(d+2) [Shah and Xie 2018], suggesting the strength of the variant of MCTS we propose here and our resulting analysis. © 2019 Owner/Author.","monte carlo tree search; non stationary multi-arm bandit; reinforcement learning","Association for Computing Machinery, Inc"
"Pai K.N., Prasad V., Rajendran A.","Experimentally validated machine learning frameworks for accelerated prediction of cyclic steady state and optimization of pressure swing adsorption processes",2020,"Separation and Purification Technology",12,"10.1016/j.seppur.2020.116651","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079280183&doi=10.1016%2fj.seppur.2020.116651&partnerID=40&md5=7dbf471a5852e4b894edc94e509862ae","Machine learning-based surrogate models are presented to accelerate the optimization of pressure swing adsorption processes. Various supervised machine learning algorithms, such as decision trees, random forests, support vector machines, Gaussian process regression, and artificial neural networks, are tested for their ability to predict key performance indicators for a given set of operating conditions. Among the algorithms studied, Gaussian process regression-based surrogate models were found to be the best at predicting process outputs, with minimal training effort. The adjusted coefficient of determination for predictions using the surrogate model is greater than 0.98 using a sampled training set of 400 operating conditions. A surrogate model based on artificial neural networks is also presented to predict the bed profiles of the intensive variables at cyclic steady state. The surrogate models show very good agreement with the detailed model simulations. Experiments performed on a lab-scale two-column rig, for the concentration of CO2 from a mixture of CO2+N2 on Zeolite-13X, confirm performance indicators such as purity, recovery and axial profiles predicted by the surrogate models. Two new optimization frameworks are presented: Surrogate optimization in which the trained surrogate model is used to provide the process performance; and cyclic steady state optimization in which the predicted cyclic steady state profiles are provided as an initial condition for detailed model in order to accelerate convergence. Both techniques are shown to accurately predict Pareto fronts of Purity-Recovery and Energy-Productivity calculated from optimization that uses a detailed process model. The Surrogate optimization and the cyclic steady state accelerated Detailed optimization show ≈23× and 6× reduction in computational load, respectively, when compared to the traditional optimization using detailed models. © 2020 Elsevier B.V.","Machine learning; Multi-objective optimization; Neural networks; Post combustion carbon capture; Surrogate modelling and optimization; Vacuum swing adsorption","Elsevier B.V."
"Taylor M.B., Vega L., Khazraee M., Magaki I., Davidson S., Richmond D.","ASIC clouds Specializing the Datacenter for Planet-Scale Applications",2020,"Communications of the ACM",2,"10.1145/3399734","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086828131&doi=10.1145%2f3399734&partnerID=40&md5=b6644759ba75a382878751ac9f82a216","Planet-scale applications are driving the exponential growth of the Cloud, and datacenter specialization is the key enabler of this trend. GPU- and FPGA-based clouds have already been deployed to accelerate compute-intensive workloads. ASIC-based clouds are a natural evolution as cloud services expand across the planet. ASIC Clouds are purpose-built datacenters comprised of large arrays of ASIC accelerators that optimize the total cost of ownership (TCO) of large, high-volume scale-out computations. On the surface, ASIC Clouds may seem improbable due to high NREs and ASIC inflexibility, but large-scale ASIC Clouds have already been deployed for the Bitcoin cryptocurrency system. This paper distills lessons from these Bitcoin ASIC Clouds and applies them to other large scale workloads such as YouTube-style video-transcoding and Deep Learning, showing superior TCO versus CPU and GPU. It derives Pareto-optimal ASIC Cloud servers based on accelerator properties, by jointly optimizing ASIC architecture, DRAM, motherboard, power delivery, cooling, and operating voltage. Finally, the authors examine the impact of ASIC NRE and when it makes sense to build an ASIC Cloud. © 2020 ACM.",,"Association for Computing Machinery"
"Ozaki Y., Tanigaki Y., Watanabe S., Onishi M.","Multiobjective tree-structured parzen estimator for computationally expensive optimization problems",2020,"GECCO 2020 - Proceedings of the 2020 Genetic and Evolutionary Computation Conference",8,"10.1145/3377930.3389817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091791108&doi=10.1145%2f3377930.3389817&partnerID=40&md5=32f5baa343172b6493283e74eeeacbcc","Practitioners often encounter computationally expensive multiobjective optimization problems to be solved in a variety of real-world applications. On the purpose of challenging these problems, we propose a new surrogate-based multiobjective optimization algorithm that does not require a large evaluation budget. It is called Multiobjective Tree-structured Parzen Estimator (MOTPE) and is an extension of the tree-structured Parzen estimator widely used to solve expensive single-objective optimization problems. Our empirical evidences reveal that MOTPE can approximate Pareto fronts of many benchmark problems better than existing methods with a limited budget. In this paper, we discuss furthermore the influence of MOTPE configurations to understand its behavior. © 2020 Owner/Author.","Bayesian optimization; Computationally expensive optimization; Infill criteria; Machine learning; Multiobjective optimization; Surrogate modeling; Tree-structured parzen estimator","Association for Computing Machinery"
"Javaheripi M., Samragh M., Javidi T., Koushanfar F.","GeneCAI: <u>gene</u>tic evolution for acquiring <u>c</u>ompact <u>AI</u>",2020,"GECCO 2020 - Proceedings of the 2020 Genetic and Evolutionary Computation Conference",3,"10.1145/3377930.3390226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091753175&doi=10.1145%2f3377930.3390226&partnerID=40&md5=6f296c885f7617149c40930bd1b79dfa","In the contemporary big data realm, Deep Neural Networks (DNNs) are evolving towards more complex architectures to achieve higher inference accuracy. Model compression techniques can be leveraged to efficiently deploy these compute-intensive architectures on resource-limited mobile devices. Such methods comprise various hyperparameters that require per-layer customization to ensure high accuracy. Choosing the hyperparameters is cumbersome as the pertinent search space grows exponentially with model layers. This paper introduces GeneCAI, a novel optimization method that automatically learns how to tune per-layer compression hyperparameters. We devise a bijective translation scheme that encodes compressed DNNs to the genotype space. Each genotype's optimality is measured using a multi-objective score based on the accuracy and number of floating-point operations. We develop customized genetic operations to iteratively evolve the non-dominated solutions towards the optimal Pareto front, thus, capturing the optimal trade-off between model accuracy and complexity. GeneCAI optimization method is highly scalable and can achieve a near-linear performance boost on distributed multi-GPU platforms. Our extensive evaluations demonstrate that GeneCAI outperforms existing rule-based and reinforcement learning methods in DNN compression by finding models that lie on a better accuracy/complexity Pareto curve. © 2020 ACM.","Computer aided/automated design; Deep learning; Genetic algorithms; Multi-objective optimization; Parallel optimization","Association for Computing Machinery"
"Huang W., Huang W., Cai D.","Finding EFL and EQL Allocations of Indivisible Goods",2020,"Proceedings - 2020 International Conference on Computer Vision, Image and Deep Learning, CVIDL 2020",,"10.1109/CVIDL51233.2020.00-53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098601830&doi=10.1109%2fCVIDL51233.2020.00-53&partnerID=40&md5=801b193196b66dba1d5585bfefebf77b","Fair resource allocation has become an emerging research topic in Computer Science and Artificial Intelligence. We can judge whether the allocation is 'fair' from two aspects. First, if each agent prefers his own set of bundle, that is, envy-free, then we say that the allocation is fair; If each agent's valuation of his own item set is equal to other agents' valuation of its own item-equitability (EQ), then we also say that this allocation is fair. Solving the problem of envy-free (EF) or equitability (EQ) fair allocation is proved to be NP-hard, so this paper mainly studies the problem of approximate fair allocation i.e., approximate envy-free and approximate equitability. Our contribution are as follows. 1. We proved that equitable up to one less-preferred good (EQL) allocation always exists and can be found in polynomial time; 2. We proved that the allocation that satisfies both equitable up to one less-preferred good (EQL) and Pareto optimality (PO) exists and provides a pseudo-polynomial time algorithm that can find the allocation when the valuation function is additive with strictly positive; 3. We proved that when the allocation with specific valuation that satisfies equitable up to one less-preferred good (EQL), envy-free up to one less-preferred good (EFL) and Pareto optimality (PO) exists then it can be found in polynomial time. © 2020 IEEE.","Computational Economics; Fair allocation; Optimal allocation","Institute of Electrical and Electronics Engineers Inc."
"Guo X., Hu T., Wu Q.","Distributed minimum error entropy algorithms",2020,"Journal of Machine Learning Research",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094877140&partnerID=40&md5=cbaf0ee17105ebcef0815b4c14035301","Minimum Error Entropy (MEE) principle is an important approach in Information Theoretical Learning (ITL). It is widely applied and studied in various fields for its robustness to noise. In this paper, we study a reproducing kernel-based distributed MEE algorithm, DMEE, which is designed to work with both fully supervised data and semi-supervised data. The divide-and- conquer approach is employed, so there is no inter-node communication overhead. Similar as other distributed algorithms, DMEE significantly reduces the computational complexity and memory requirement on single computing nodes. With fully supervised data, our proved learning rates equal the minimax optimal learning rates of the classical pointwise kernel-based regressions. Under the semi-supervised learning scenarios, we show that DMEE exploits unlabeled data effectively, in the sense that first, under the settings with weak regularity assumptions, additional unlabeled data significantly improves the learning rates of DMEE. Second, with sufficient unlabeled data, labeled data can be distributed to many more computing nodes, that each node takes only O(1) labels, without spoiling the learning rates in terms of the number of labels. This conclusion overcomes the saturation phenomenon in unlabeled data size. It parallels a recent results for regularized least squares (Lin and Zhou, 2018), and suggests that an ination of unlabeled data is a solution to the MEE learning problems with decentralized data source for the concerns of privacy protection. Our work refers to pairwise learning and non-convex loss. The theoretical analysis is achieved by distributed U-statistics and error decomposition techniques in integral operators. © 2020 Xin Guo, Ting Hu and Qiang Wu.","Distributed method; Information theoretic learning; Minimum error entropy; Reproducing kernel Hilbert space; Semi-supervised data","Microtome Publishing"
"Wu H., Wang M.D.","Training Confidence-Calibrated Classifier via Distributionally Robust Learning",2020,"Proceedings - 2020 IEEE 44th Annual Computers, Software, and Applications Conference, COMPSAC 2020",,"10.1109/COMPSAC48688.2020.0-230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094166969&doi=10.1109%2fCOMPSAC48688.2020.0-230&partnerID=40&md5=e53bd9574a661a02bd4dd71eb7ac3a34","Supervised learning via empirical risk minimization, despite its solid theoretical foundations, faces a major challenge in generalization capability, which limits its application in real-world data science problems. In particular, current models fail to distinguish in-distribution and out-of-distribution and give over confident predictions for out-of-distribution samples. In this paper, we propose an distributionally robust learning method to train classifiers via solving an unconstrained minimax game between an adversary test distribution and a hypothesis. We showed the theoretical generalization performance guarantees, and empirically, our learned classifier when coupled with thresholded detectors, can efficiently detect out-of-distribution samples. © 2020 IEEE.","adversarial machine learning; distributionally robust optimization; robust machine learning; supervised learning","Institute of Electrical and Electronics Engineers Inc."
"Prabakaran B.S., Mrazek V., Vasicek Z., Sekanina L., Shafique M.","ApproxFPGAs: Embracing ASIC-Based approximate arithmetic components for FPGA-Based systems",2020,"Proceedings - Design Automation Conference",4,"10.1109/DAC18072.2020.9218533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093978304&doi=10.1109%2fDAC18072.2020.9218533&partnerID=40&md5=e56dc371268d6134242e2f5868b4055f","There has been abundant research on the development of Approximate Circuits (ACs) for ASICs. However, previous studies have illustrated that ASIC-based ACs offer asymmetrical gains in FPGA-based accelerators. Therefore, an AC that might be pareto-optimal for ASICs might not be pareto-optimal for FPGAs. In this work, we present the ApproxFPGAs methodology that uses machine learning models to reduce the exploration time for analyzing the state-of-the-art ASIC-based ACs to determine the set of pareto-optimal FPGA-based ACs. We also perform a case-study to illustrate the benefits obtained by deploying these pareto-optimal FPGA-based ACs in a state-of-the-art automation framework to systematically generate pareto-optimal approximate accelerators that can be deployed in FPGA-based systems to achieve high performance or low-power consumption. © 2020 IEEE.","Adder; Approximate Computing; Arithmetic Units; ASIC; FPGA; Machine Learning; Models; Multiplier; Statistics; Synthesis","Institute of Electrical and Electronics Engineers Inc."
"Khorshidi H.A., Kirley M., Aickelin U.","Machine learning with incomplete datasets using multi-objective optimization models",2020,"Proceedings of the International Joint Conference on Neural Networks",1,"10.1109/IJCNN48605.2020.9206742","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093873096&doi=10.1109%2fIJCNN48605.2020.9206742&partnerID=40&md5=5650c6ee1e418f1cb8c8557806b9c39a","Machine learning techniques have been developed to learn from complete data. When missing values exist in a dataset, the incomplete data should be preprocessed separately by removing data points with missing values or imputation. In this paper, we propose an online approach to handle missing values while a classification model is learnt. To reach this goal, we develop a multi-objective optimization model with two objective functions for imputation and model selection. We also propose three formulations for imputation objective function. We use an evolutionary algorithm based on NSGA II to find the optimal solutions as the Pareto solutions. We investigate the reliability and robustness of the proposed model using experiments by defining several scenarios in dealing with missing values and classification. We also describe how the proposed model can contribute to medical informatics. We compare the performance of three different formulations via experimental results. The proposed model results get validated by comparing with a comparable literature. © 2020 IEEE.","classification; incomplete data; model selection; multi-objective model; uncertainty","Institute of Electrical and Electronics Engineers Inc."
"Marchisio A., Bussolino B., Colucci A., Hanif M.A., Martina M., Masera G., Shafique M.","FasTrCaps: An Integrated Framework for Fast yet Accurate Training of Capsule Networks",2020,"Proceedings of the International Joint Conference on Neural Networks",4,"10.1109/IJCNN48605.2020.9207533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093829454&doi=10.1109%2fIJCNN48605.2020.9207533&partnerID=40&md5=f3e0f737b68cb375178a6b1f04f8fdd2","Recently, Capsule Networks (CapsNets) have shown improved performance compared to the traditional Convolutional Neural Networks (CNNs), by encoding and preserving spatial relationships between the detected features in a better way. This is achieved through the so-called Capsules (i.e., groups of neurons) that encode both the instantiation probability and the spatial information. However, one of the major hurdles in the wide adoption of CapsNets is their gigantic training time, which is primarily due to the relatively higher complexity of their new constituting elements that are different from CNNs.In this paper, we implement different optimizations in the training loop of the CapsNets, and investigate how these optimizations affect their training speed and the accuracy. Towards this, we propose a novel framework FasTrCaps that integrates multiple lightweight optimizations and a novel learning rate policy called WarmAdaBatch (that jointly performs warm restarts and adaptive batch size), and steers them in an appropriate way to provide high training-loop speedup at minimal accuracy loss. We also propose weight sharing for capsule layers. The goal is to reduce the hardware requirements of CapsNets by removing unused/redundant connections and capsules, while keeping high accuracy through tests of different learning rate policies and batch sizes. We demonstrate that one of the solutions generated by the FasTrCaps framework can achieve 58.6% reduction in the training time, while preserving the accuracy (even 0.12% accuracy improvement for the MNIST dataset), compared to the CapsNet by Google Brain [25]. Moreover, the Pareto-optimal solutions generated by FasTrCaps can be leveraged to realize trade-offs between training time and achieved accuracy. We have open-sourced our framework on GitHub1. © 2020 IEEE.","Accuracy; Adaptivity; Batch Sizing; Capsule Networks; Decoder; Efficiency; Machine Learning; Performance; Training; Weight Sharing","Institute of Electrical and Electronics Engineers Inc."
"Raju K.K., Eswaramoorthy M.","Reliability Evaluation of Grid Connected Roof Top Solar Photovoltaic Power Plant Using Markov Model Approach",2020,"Applied Solar Energy (English translation of Geliotekhnika)",,"10.3103/S0003701X2004009X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093357016&doi=10.3103%2fS0003701X2004009X&partnerID=40&md5=8401f25909c9083b70a8c34eab7f8a2b","Abstract—: Reliability of the solar power plant depends on its performance and economics factor compared to the conventional fueled power plants. In this paper, reliability performance assessment of grid connected roof top solar photovoltaic power plant (GCRTSPP) are presented at site location 12.0950° N, 75.5451° E) by considering various operating factors of subcomponents of solar photovoltaic panels, diode, capacitor and controller using Markov model approach. Critical stress factors are identified and are improved upon to enhance the system reliability. The performance of the solar photovoltaic array and the subcomponent of GCRTSPP have been examined with the sensitivity results. Also, sensitivity analysis of failure rate of these components with respect to stress factors is performed and critical stress factors are identified. Pareto analysis as a tool, reliability studies of grid connected solar photovoltaic system have been carried out to compute the highest failure rate of component. It is found that electronic controller and diode is more sensitive item compared to solar photovoltaic panels and capacitor. These components failure rate sensitivity analysis with respect to stress factors is performed. The reliability on standalone and grid connected photovoltaic system also compared. The critical stress factors of the components are identified. Artificial neural network (ANN) and machine learning programme (MLP) proposed for further study. © 2020, Allerton Press, Inc.","Markov model; reliability analysis; solar PV power plant","Pleiades journals"
"Bokhari S.M.A., Theel O.","A Genetic Programming-Based Multi-Objective Optimization Approach to Data Replication Strategies for Distributed Systems",2020,"2020 IEEE Congress on Evolutionary Computation, CEC 2020 - Conference Proceedings",4,"10.1109/CEC48606.2020.9185598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092072776&doi=10.1109%2fCEC48606.2020.9185598&partnerID=40&md5=1aa9784b07d7e946b6c09a0ba3dbe66e","Data replication is the core of distributed systems to enhance their fault tolerance and make services highly available to the end-users. Data replication masks run-time failures and hence, makes the system more reliable. There are many contemporary data replication strategies for this purpose, but the decision to choose an appropriate strategy for a certain environment and a specific scenario is a challenge and full of compromises. There exists a potentially indefinite number of scenarios that cannot be covered entirely by contemporary strategies. It demands designing new data replication strategies optimized for the given scenarios. The constraints of such scenarios are often conflicting in a sense that an increase in one objective could be sacrificial to the others, which implies there is no best solution to the problem but what serves the purpose. In this regard, this research provides a genetic programming-based multi-objective optimization approach that endeavors to not only identify, but also design new data replication strategies and optimize their conflicting objectives as a single-valued metric. The research provides an intelligent, automatic mechanism to generate new replication strategies as well as easing up the decision making so that relevant strategies with satisfactory trade-offs of constraints can easily be picked and used from the generated solutions at run-time. Moreover, it makes the notion of hybrid strategies easier to accomplish which otherwise would have been very cumbersome to achieve, therefore, to optimize. © 2020 IEEE.","Data Replication; Distributed Systems; Fault Tolerance; Genetic Programming; Machine Learning; Operation Availability; Operation Cost; Optimization; Pareto Front; Quorum Protocols; Voting Structures","Institute of Electrical and Electronics Engineers Inc."
"Zhang H., Tao K., Ma L., Yong Y.","Handling Constrained Multi-Objective optimization with Objective Space Mapping to Decision Space Based on Extreme Learning Machine",2020,"2020 IEEE Congress on Evolutionary Computation, CEC 2020 - Conference Proceedings",,"10.1109/CEC48606.2020.9185580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092066835&doi=10.1109%2fCEC48606.2020.9185580&partnerID=40&md5=8c69ff310b79ea8ad205b8f63444faa6","Constrained multi-objective optimization is frequently encountered from the point of view of practical problem solving. The difficulty of constrained multi-objective optimization is how to offer guarantee of finding feasible optimal solutions within a specified number of iterations. To address the issue, this paper proposes an innovative optimization framework with objective space mapping to decision space for constrained multiobjective optimization and a novel multi-objective optimization algorithms are proposed based on this framework. Extreme learning machine implements prediction of decision variables from modified objective values with distance measure and adaptive penalty. This algorithm employs the framework of artificial bee colony to divide this optimization process into two phases: the employed bees and the onlooker bees. In the phase of employed bees, multi-objective strategy employs fast non-dominant sort and crowded distance to push the population toward Pareto front. In the phase of onlooker bees, multi-objective strategy employs Tchebycheff approach to enhance the population diversity. The experimental results on a series of benchmark problems suggest that our proposed algorithm is quite effective, in comparison to other state-of-the-art constrained multi-objective optimizers. © 2020 IEEE.","artificial bee colony; constrained multi-objective optimization; decomposition; extreme learning machine; nondomination","Institute of Electrical and Electronics Engineers Inc."
"Lin F., Fang J.-Y., Hsieh H.-P.","A Gaussian-Prioritized Approach for Deploying Additional Route on Existing Mass Transportation with Neural-Network-Based Passenger Flow Inference",2020,"2020 IEEE Congress on Evolutionary Computation, CEC 2020 - Conference Proceedings",1,"10.1109/CEC48606.2020.9185869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092032799&doi=10.1109%2fCEC48606.2020.9185869&partnerID=40&md5=7d5163d0d11d23aeb47ae050b219cf83","Multi-criteria path planning is an important combinatorial optimization problem with broad real-world applications. Finding the Pareto-optimal set of paths ideal for all requiring features is time-consuming and unclear to obtain the subset of optimal paths efficiently for multiple origin states in the planning space. Meanwhile, due to the rise of deep learning, hybrid systems of computational intelligence thrive in recent years. When facing non-monotonic data or heuristics derived from pretrained neural networks, most of the existing methods for the oneto-all path problem fail to find an ideal solution. We employ Gaussian mixture model to propose a target-prioritized searching algorithm called Multi-Source Bidirectional Gaussian-Prioritized Spanning Tree (BiasSpan) in solving this non-monotonic multicriteria route planning problem given constraints including range, must-visit vertices, and the number of recommended vertices. Experimental results on mass transportation system in Tainan and Chicago cities show that BiasSpan outperforms comparative methods from 7% to 24% and runs in a reasonable time compared to state-of-art route-planning algorithms. © 2020 IEEE.","Bidirectional spanning tree; Constrained route planning; Deep Neural Network (DNN); Gaussian mixture model (GMM); Non-monotonicity","Institute of Electrical and Electronics Engineers Inc."
"Yuan Y., Srikant Adhatarao S., Lin M., Yuan Y., Liu Z., Fu X.","ADA: Adaptive Deep Log Anomaly Detector",2020,"Proceedings - IEEE INFOCOM",7,"10.1109/INFOCOM41043.2020.9155487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090281791&doi=10.1109%2fINFOCOM41043.2020.9155487&partnerID=40&md5=12e02dd0af106c12843f3957af1f3e9a","Large private and government networks are often subjected to attacks like data extrusion and service disruption. Existing anomaly detection systems use offline supervised learning and employ experts for labeling. Hence they cannot detect anomalies in real-time. Even though unsupervised algorithms are increasingly used nowadays, they cannot readily adapt to newer threats. Moreover, many such systems also suffer from high cost of storage and require extensive computational resources. In this paper, we propose ADA: Adaptive Deep Log Anomaly Detector, an unsupervised online deep neural network framework that leverages LSTM networks and regularly adapts to newer log patterns to ensure accurate anomaly detection. In ADA, an adaptive model selection strategy is designed to choose pareto-optimal configurations and thereby utilize resources efficiently. Further, a dynamic threshold algorithm is proposed to dictate the optimal threshold based on recently detected events to improve the detection accuracy. We also use the predictions to guide storage of abnormal data and effectively reduce the overall storage cost. We compare ADA with state-of-the-art approaches through leveraging the Los Alamos National Laboratory cyber security dataset and show that ADA accurately detects anomalies with high F1-score ~95% and it is 97 times faster than existing approaches and incurs very low storage cost. © 2020 IEEE.","Anomaly detection; deep neural networks; log-normal; logs; online training; threshold; unsupervised","Institute of Electrical and Electronics Engineers Inc."
"Wang J., Jiang C., Zhang H., Ren Y., Chen K.-C., Hanzo L.","Thirty Years of Machine Learning: The Road to Pareto-Optimal Wireless Networks",2020,"IEEE Communications Surveys and Tutorials",181,"10.1109/COMST.2020.2965856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090164691&doi=10.1109%2fCOMST.2020.2965856&partnerID=40&md5=22a8a91e7b6981dc7fb1e2c9cc3b394b","Future wireless networks have a substantial potential in terms of supporting a broad range of complex compelling applications both in military and civilian fields, where the users are able to enjoy high-rate, low-latency, low-cost and reliable information services. Achieving this ambitious goal requires new radio techniques for adaptive learning and intelligent decision making because of the complex heterogeneous nature of the network structures and wireless services. Machine learning (ML) algorithms have great success in supporting big data analytics, efficient parameter estimation and interactive decision making. Hence, in this article, we review the thirty-year history of ML by elaborating on supervised learning, unsupervised learning, reinforcement learning and deep learning. Furthermore, we investigate their employment in the compelling applications of wireless networks, including heterogeneous networks (HetNets), cognitive radios (CR), Internet of Things (IoT), machine to machine networks (M2M), and so on. This article aims for assisting the readers in clarifying the motivation and methodology of the various ML algorithms, so as to invoke them for hitherto unexplored services as well as scenarios of future wireless networks. © 1998-2012 IEEE.","classification; clustering; deep learning; future wireless network; Machine learning (ML); network association; regression; resource allocation","Institute of Electrical and Electronics Engineers Inc."
"Yan D., Cao H., Yu Y., Wang Y., Yu X.","Single-Objective/Multiobjective Cat Swarm Optimization Clustering Analysis for Data Partition",2020,"IEEE Transactions on Automation Science and Engineering",7,"10.1109/TASE.2020.2969485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087544710&doi=10.1109%2fTASE.2020.2969485&partnerID=40&md5=0a15e6748d23b7e5207da6b02c09a3dd","This article proposes single-objective/multiobjective cat swarm optimization clustering algorithms for data partition. The proposed methods use the cat swarm to search the optimal. The position of the cat tightly associates with the clustering centers and is updated by two submodes: the seeking mode and the tracing mode. The seeking mode uses the simulated annealing strategy to update the cat position at a probability. Inspired by the quantum theories, the tracing mode adopts the quantum model to update the cat position in the whole solution space. First, the single-objective method is proposed and adopts the cohesion of clustering as the objective function, in which the kernel method is applied. For considering more objective functions to reveal diverse aspects of data, the multiobjective method is proposed and adopts both the cohesion and the connectivity as the objective functions. The Pareto optimization method is applied to balance the objectives. In the experiments, three kinds of data sets are used to examine the effectiveness of the proposed methods, which are three synthetic data sets, four data sets from the UCI Machine Learning Repository, and a field data set. Experimental results verified that the proposed methods perform better than the traditional clustering algorithms, and the proposed multiobjective method has the highest accuracy. Note to Practitioners-This article presents single-objective/multiobjective cat swarm optimization clustering analysis methods for data partition. Through automatically extracting meaningful or useful classes, clustering analysis could help the practitioners or the intelligent devices find the specific meanings of data, natural data structure, the data relationships, or other characteristics. The proposed methods use the cat swarm to search the optimal clustering result. One or more criterion functions could be selected as the optimization objectives. The time complexity of the multiobjective type is higher than that of the single-objective type. Therefore, in the industrial field, engineers should choose the number of the optimization objectives based on the actual requirements. The proposed methods could be widely used into industrial applications to deal with complex data sets. Future research could consider some more progressive optimization schemes to improve the effectiveness. © 2004-2012 IEEE.","Clustering analysis; data partition; quantum model; single-objective/multiobjective optimization","Institute of Electrical and Electronics Engineers Inc."
"Allahbakhshian-Farsani P., Vafakhah M., Khosravi-Farsani H., Hertig E.","Regional Flood Frequency Analysis Through Some Machine Learning Models in Semi-arid Regions",2020,"Water Resources Management",6,"10.1007/s11269-020-02589-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087392184&doi=10.1007%2fs11269-020-02589-2&partnerID=40&md5=df0c807d3108641e56c8b8c8c4fcfefb","The machine learning models (MLMs), including support vector regression (SVR), multivariate adaptive regression spline (MARS), boosted regression trees (BRT), and projection pursuit regression (PPR) are compared to traditional method i.e. nonlinear regression (NLR) in regional flood frequency analysis (RFFA). In this study, the Karun and Karkheh watersheds, which is located in the southwestern of Iran, with the same climatic and physiographic conditions are considered. Fifty-four hydrometric stations with a period of 21 years (1993–2013) are selected based on the instructions of U.S. Federal Agencies Bulletin 17 B were applied for RFFA. The generalized normal (GNO) probability distribution function (PDF) is selected by the L-moment method among five PDFs, including the GNO, generalized Pareto (GP), generalized logistic (GL), generalized extreme value (GEV) and Pearson type 3 (P ІІІ) to estimate flood discharge for the expected return periods. Twenty-five predictor variables, such as physiographic, climatologic, geologic, soil and land use variables are extracted. Follow land, maximum 24-h rainfall, mean watershed slope, compactness coefficient, mean and maximum watershed elevation variables are recognized as the appropriate combination of input using gamma test (GT). The overall results indicate that the SVR, PPR, and MARS models in comparison to the NLR and BRT models have a better performance to estimate flood discharge with the expected return periods. Future, the SVR model based on radial basis function (RBF) kernel is chosen as the best model in terms of the mean of the Nash-Sutcliff coefficient (M-Ef) and the mean of relative root mean squared error (M-RMSEr) (i.e. 0.94 and 63.93, respectively) for different return periods. © 2020, Springer Nature B.V.","Data Driven models; Karun and Karkheh watersheds; L-moment; Land use; Maximum instantaneous discharge; Regionalization","Springer"
"Schmidhuber J.","Generative Adversarial Networks are special cases of Artificial Curiosity (1990) and also closely related to Predictability Minimization (1991)",2020,"Neural Networks",24,"10.1016/j.neunet.2020.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083520702&doi=10.1016%2fj.neunet.2020.04.008&partnerID=40&md5=deae14f50115979de814adfa8eeabd0e","I review unsupervised or self-supervised neural networks playing minimax games in game-theoretic settings: (i) Artificial Curiosity (AC, 1990) is based on two such networks. One network learns to generate a probability distribution over outputs, the other learns to predict effects of the outputs. Each network minimizes the objective function maximized by the other. (ii) Generative Adversarial Networks (GANs, 2010-2014) are an application of AC where the effect of an output is 1 if the output is in a given set, and 0 otherwise. (iii) Predictability Minimization (PM, 1990s) models data distributions through a neural encoder that maximizes the objective function minimized by a neural predictor of the code components. I correct a previously published claim that PM is not based on a minimax game. © 2020 Elsevier Ltd","Artificial Curiosity; Generative Adversarial Networks; Predictability Minimization","Elsevier Ltd"
"Wu Q., Chen W., Wang H., Hong W.","Machine Learning-Assisted Tolerance Analysis and Its Application to Antennas",2020,"2020 IEEE International Symposium on Antennas and Propagation and North American Radio Science Meeting, IEEECONF 2020 - Proceedings",1,"10.1109/IEEECONF35879.2020.9330387","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101600187&doi=10.1109%2fIEEECONF35879.2020.9330387&partnerID=40&md5=48c1d680b452f90e3011e26d3959eb96","An efficient machine learning-assisted tolerance analysis (MLATA) method is proposed by applying machine learning (ML) methods into multiple layers of the antenna tolerance analysis. The computational time for operations including worst case performance searching, maximum input tolerance hypervolume searching and robust optimization is greatly reduced while maintaining high reliability due to the introduction of the ML methods. The surrogate models which are built using ML methods have been introduced to predict both antenna performance and tolerance of parameters at given design points. The Pareto front combining antenna performance, robustness and size has been obtained to guide trade-offs for antenna robust design. A planar inverted-L antenna for mobile terminals is simulated to validate the proposed MLATA method. © 2020 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Hamilton N.H., Fulp E.W.","An evolutionary approach for constructing multi-stage classifiers",2020,"GECCO 2020 Companion - Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion",,"10.1145/3377929.3398088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089754689&doi=10.1145%2f3377929.3398088&partnerID=40&md5=22f2b05e27d1c600d76e38698828d863","Multi-stage classification is a supervised learning approach that distributes a set of features, each with an associated importance and cost of generation, across a series of classifiers (stages). Inputs are processed in a pipeline fashion through the stages, each of which utilizes only a subset of the complete feature set, until a confident classification decision can be made or until all features and stages have been exhausted. This design benefits from processing inputs in parallel and ensures that labels are assigned using only the necessary features, but the number and composition of stages used by the model can have significant impact on overall performance. Unfortunately, identifying these critical design aspects becomes more difficult as the number of features and possible stages increases, often making brute-force search or human intuition impractical. This paper introduces a novel evolutionary approach for discovering multi-stage configurations that provide high classification performance and fast processing times. Using this approach, multistage classifier configurations are modeled as chromosomes, and a series of selection, recombination, and mutation operations are iteratively performed to find better configurations. Since the problem has multiple objectives, a Pareto-based fitness measure is developed to rank chromosomes, where better chromosomes have high accuracy, high conclusiveness, and fast processing time. Experimental results indicate this approach is able to consistently find accurate and fast multi-stage classifier configurations under various conditions, including an increasing number of features and different feature synthesis time distributions. © 2020 ACM.",,"Association for Computing Machinery, Inc"
"Del Rosario Z., Rupp M., Kim Y., Antono E., Ling J.","Assessing the frontier: Active learning, model accuracy, and multi-objective candidate discovery and optimization",2020,"Journal of Chemical Physics",11,"10.1063/5.0006124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088157072&doi=10.1063%2f5.0006124&partnerID=40&md5=b571f856e195c21df8b5e8ef0a3f9ee8","Discovering novel chemicals and materials can be greatly accelerated by iterative machine learning-informed proposal of candidates - active learning. However, standard global error metrics for model quality are not predictive of discovery performance and can be misleading. We introduce the notion of Pareto shell error to help judge the suitability of a model for proposing candidates. Furthermore, through synthetic cases, an experimental thermoelectric dataset and a computational organic molecule dataset, we probe the relation between acquisition function fidelity and active learning performance. Results suggest novel diagnostic tools, as well as new insights for the acquisition function design. © 2020 Author(s).",,"American Institute of Physics Inc."
"Zhang N., Zhu K., Ying S., Wang X.","Software defect prediction based on stacked contractive autoencoder and multi-objective optimization",2020,"Computers, Materials and Continua",6,"10.32604/cmc.2020.011001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091007061&doi=10.32604%2fcmc.2020.011001&partnerID=40&md5=1ce56d98f950fec216ce0f8a625ea817","Software defect prediction plays an important role in software quality assurance. However, the performance of the prediction model is susceptible to the irrelevant and redundant features. In addition, previous studies mostly regard software defect prediction as a single objective optimization problem, and multi-objective software defect prediction has not been thoroughly investigated. For the above two reasons, we propose the following solutions in this paper: (1) we leverage an advanced deep neural network-Stacked Contractive AutoEncoder (SCAE) to extract the robust deep semantic features from the original defect features, which has stronger discrimination capacity for different classes (defective or non-defective). (2) we propose a novel multi-objective defect prediction model named SMONGE that utilizes the Multi-Objective NSGAII algorithm to optimize the advanced neural network-Extreme learning machine (ELM) based on state-of-the-art Pareto optimal solutions according to the features extracted by SCAE. We mainly consider two objectives. One objective is to maximize the performance of ELM, which refers to the benefit of the SMONGE model. Another objective is to minimize the output weight norm of ELM, which is related to the cost of the SMONGE model. We compare the SCAE with six state-of-the-art feature extraction methods and compare the SMONGE model with multiple baseline models that contain four classic defect predictors and the MONGE model without SCAE across 20 open source software projects. The experimental results verify that the superiority of SCAE and SMONGE on seven evaluation metrics. © 2020 Tech Science Press. All rights reserved.","Deep neural network; Extreme learning machine; Multi-objective optimization; Software defect prediction; Stacked contractive autoencoder","Tech Science Press"
"Dalkilic H.Y.","Evaporation modelling using soft computing techniques",2020,"Fresenius Environmental Bulletin",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091920272&partnerID=40&md5=da99ca2373c6251290131e58866c1643","Evaporation, which is one of the most important components of the hydrological cycle, is of great importance for developing, planning, operating, and managing water resources. In the present study, the average weekly evaporation and other hydrometeorological data measured by Manasgoan [1] between 1990 and 2004 were modelled using extreme learning machine (ELM), minimax probability machine regression (MPMR), and Gaussian process regression (GPR) methods. Wind speed, air temperature, relative humidity, and the number of sunshine hours were used as model input, and evaporation was the output. The correlation coefficient, mean absolute error (MAE), root mean square error (RMSE), and performance index were used as performance criteria in the evaluation of the model results. The model results indicated that the Gaussian process regression (GPR) model is more accurate and provides more successful results compared to other methods. © by PSP","Evaporation; Extreme learning machine; Gaussian process regression; Minimax probability machine regression; Prediction; Reservoir","Parlar Scientific Publications"
"Pan S., Wu J., Sun Y., Qu Y.","A Military Chess Game Tree Algorithm Based on Refresh Probability Table",2020,"Proceedings of the 32nd Chinese Control and Decision Conference, CCDC 2020",1,"10.1109/CCDC49329.2020.9164878","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091577243&doi=10.1109%2fCCDC49329.2020.9164878&partnerID=40&md5=660dd3cf0c9761bf80e19145346d2614","Computer game is divided into complete information game and incomplete information game. As a kind of incomplete information game, military chess game has many shortcomings in game-tree algorithm. In view of the fact that it is difficult to develop the game-tree because the specific information of the opponent's chess pieces can not be obtained accurately in military chess game, this paper proposes an algorithm to expand the game tree by refreshing the probability table formed by the rules of military chess, the result of the opponent's chess game and the result of the collision of the two opponents' chess pieces. The algorithm of the refresh probability table is used to provide the score support of the expanded game tree for the military chess game, thereby ensuring the expansion of the game tree. The initial values and weights in the refresh probability table algorithm are optimized by machine learning to improve the speed and accuracy of the refresh probability table, and the game tree is optimized by the minimax algorithm and the Alpha-beta pruning algorithm. Experiments show that the refresh probability table algorithm based on the game tree improves the winning rate in the game and has achieved good results. © 2020 IEEE.","Computer Game; Military chess; Probability table and Game tree","Institute of Electrical and Electronics Engineers Inc."
"Burke J.V., Engle A.","Strong Metric (Sub)regularity of Karush Kuhn Tucker Mappings for Piecewise Linear-Quadratic Convex-Composite Optimization and the Quadratic Convergence of Newton s Method",2020,"Mathematics of Operations Research",2,"10.1287/moor.2019.1027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090551114&doi=10.1287%2fmoor.2019.1027&partnerID=40&md5=0b17b21d14e13a3d6902e8ad4acd3197","This work concerns the local convergence theory of Newton and quasi-Newton methods for convex-composite optimization: where one minimizes an objective that can be written as the composition of a convex function with one that is continuiously differentiable. We focus on the case in which the convex function is a potentially infinite-valued piecewise linear-quadratic function. Such problems include nonlinear programming, minimax optimization, and estimation of nonlinear dynamics with non-Gaussian noise as well as many modern approaches to large-scale data analysis and machine learning. Our approach embeds the optimality conditions for convex-composite optimization problems into a generalized equation. We establish conditions for strong metric subregularity and strong metric regularity of the corresponding set-valued mappings. This allows us to extend classical convergence of Newton and quasi-Newton methods to the broader class of nonfinite valued piecewise linear-quadratic convex-composite optimization problems. In particular, we establish local quadratic convergence of the Newton method under conditions that parallel those in nonlinear programming. © 2020 INFORMS Inst.for Operations Res.and the Management Sciences. All rights reserved.","convex-composite optimization; generalized equations; Newton s method; partial smoothness; piecewise linear-quadratic; quadratic convergence; quasi-Newton methods; strong metric regularity; strong metric subregularity","INFORMS Inst.for Operations Res.and the Management Sciences"
"Mourtada J., Gaïffas S., Scornet E.","Minimax optimal rates for mondrian trees and forests",2020,"Annals of Statistics",4,"10.1214/19-AOS1886","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090432454&doi=10.1214%2f19-AOS1886&partnerID=40&md5=3f78b8008c9b31e2985cfeef5b512a78","Introduced by Breiman (Mach. Learn. 45 (2001) 5–32), Random Forests are widely used classification and regression algorithms. While being initially designed as batch algorithms, several variants have been proposed to handle online learning. One particular instance of such forests is the Mondrian forest (In Adv. Neural Inf. Process. Syst. (2014) 3140–3148; In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics (AISTATS) (2016)), whose trees are built using the so-called Mondrian process, therefore allowing to easily update their construction in a streaming fashion. In this paper we provide a thorough theoretical study of Mondrian forests in a batch learning setting, based on new results about Mondrian partitions. Our results include consistency and convergence rates for Mondrian trees and forests, that turn out to be minimax optimal on the set of s-Hölder function with s ∈ (0, 1] (for trees and forests) and s ∈ (1, 2] (for forests only), assuming a proper tuning of their complexity parameter in both cases. Furthermore, we prove that an adaptive procedure (to the unknown s ∈ (0, 2]) can be constructed by combining Mondrian forests with a standard model aggregation algorithm. These results are the first demonstrating that some particular random forests achieve minimax rates in arbitrary dimension. Owing to their remarkably simple distributional properties, which lead to minimax rates, Mondrian trees are a promising basis for more sophisticated yet theoretically sound random forests variants. © Institute of Mathematical Statistics, 2020.","Minimax rates; Nonparametric estimation; Random forests; Supervised learning","Institute of Mathematical Statistics"
"Boonstra S., van der Blom K., Hofmeyer H., Emmerich M.T.M.","Conceptual structural system layouts via design response grammars and evolutionary algorithms",2020,"Automation in Construction",5,"10.1016/j.autcon.2019.103009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085190201&doi=10.1016%2fj.autcon.2019.103009&partnerID=40&md5=f84c2bd35f0d30574dca4b5227ba1a35","Two new methods to generate structural system layouts for conceptual building spatial designs are presented. The first method, the design response grammar, uses design rules—configurable by parameters—to develop a structural system layout step by step as a function of a building spatial design's geometry and preliminary assessments of the structural system under development. The second method, design via optimizer assignment, uses an evolutionary algorithm to assign structural components to a building spatial design's geometry. In this work, the methods are demonstrated for two objectives: minimal strain energy (a commonly used objective for structural topology optimization) and minimal structural volume. In a first case study three building spatial designs have been subjected to the methods: Design via optimizer assignment yields a uniformly distributed Pareto front approximation, which incorporates the best performing layouts among both methods. On the other hand, results of the design response grammar show that layouts that correspond to specific positions on the Pareto front (e.g. layouts that perform well for strain energy), share the same parameter configurations among the three different building spatial designs. By generalizing, specific points on the Pareto front approximation have been expressed in terms of parameter configurations. A second case study addresses the use of a generic material and generic dimensions in the assessment of structural system layouts. The study applies a technique similar to topology optimization to optimize the material density distribution of each individual structural component, which can be regarded as a part of determining materials and dimensions in more advanced stages of the design of a system layout. This optimization approach is applied to the layouts that are part of the Pareto front approximations as found by the evolutionary algorithm in the first case study, the study shows that—after optimization—the fronts remain the same qualitatively, suggesting that the methods produce results that are also useful in more advanced design stages. A final case study tests the generalization that is established in the first case study by using the found configurations for the design response grammar, and it is shown that the generated layouts indeed are positioned near the desired positions on the Pareto front approximation found by the evolutionary algorithm. Although the evolutionary algorithm can find better performing solutions among a better distributed Pareto front approximation, the design response grammar uses only a fraction of the computational cost. As such it is concluded that the design response grammar is a promising support tool for the exploration and structural assessment of conceptual building spatial designs. Future research should focus on more types of structural elements; more objectives; new constraints to ensure feasible solutions, especially stress constraints; and the application of state-of-the-art techniques like machine learning to find more generalizations. © 2019 Elsevier B.V.","Automated design; Building spatial design; Conceptual design; Design grammar; Design optimization; Multi-disciplinary design; Structural design","Elsevier B.V."
"Singh K., Vakkantham P., Nistala S.H., Runkana V.","Multi-objective Optimization of Integrated Iron Ore Sintering Process Using Machine Learning and Evolutionary Algorithms",2020,"Transactions of the Indian Institute of Metals",2,"10.1007/s12666-020-01920-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084214103&doi=10.1007%2fs12666-020-01920-0&partnerID=40&md5=ba38edaed578b73bc7b9763153288f10","In the iron ore sintering process, it is desirable to maximize the productivity and quality of sinter while minimizing the fuel consumption for any given raw material (iron ore, flux and solid fuel) quality. However, given the complexity of the sintering process and the large number of manipulated variables, it is not practical for operators to identify appropriate set points for the manipulated variables to achieve these conflicting objectives. While significant amount of research is devoted to optimization of the on-strand sintering process, optimization of the integrated sintering process, viz. granulation and on-strand sintering together, has not received much attention. This is, however, necessary as the granulation process dictates the moisture content, mean size and voidage of the green mix bed, which in turn have a very strong influence on the sintering process and sinter quality. In this work, we have formulated and solved a multi-objective optimization problem to maximize both sinter productivity and quality for the integrated iron ore sintering process. Predictive models for productivity and quality parameters such as tumbler index (TI) and reduction degradation index (RDI) are built using machine learning algorithms. The optimization problem is solved using an evolutionary algorithm called non-dominated sorting genetic algorithm II (NSGA-II) to obtain a set of Pareto-optimal solutions. Optimal settings for key manipulated variables such as moisture content of green mix, fuel content, bed height and strand speed are obtained for the Pareto solutions. The optimization results are useful for identifying the operational range of the sintering process and can be used by operators for running the sinter plant optimally for a given set of raw materials. © 2020, The Indian Institute of Metals - IIM.","Data-based modeling; Granulation; Multi-objective optimization; Sintering","Springer"
"Qian C.","Distributed Pareto Optimization for Large-Scale Noisy Subset Selection",2020,"IEEE Transactions on Evolutionary Computation",9,"10.1109/TEVC.2019.2929555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078287966&doi=10.1109%2fTEVC.2019.2929555&partnerID=40&md5=80da4ea46b8debd622bbc798e844042a","Subset selection, aiming to select the best subset from a ground set with respect to some objective function, is a fundamental problem with applications in many areas, such as combinatorial optimization, machine learning, data mining, computer vision, information retrieval, etc. Along with the development of data collection and storage, the size of the ground set grows larger. Furthermore, in many subset selection applications, the objective function evaluation is subject to noise. We thus study the large-scale noisy subset selection problem in this paper. The recently proposed DPOSS algorithm based on multiobjective evolutionary optimization is a powerful distributed solver for large-scale subset selection. Its performance, however, has been only validated in the noise-free environment. In this paper, we first prove its approximation guarantee under two common noise models, i.e., multiplicative noise and additive noise, disclosing that the presence of noise degrades the performance of DPOSS largely. Next, we propose a new distributed multiobjective evolutionary algorithm called DPONSS for large-scale noisy subset selection. We prove that the approximation guarantee of DPONSS under noise is significantly better than that of DPOSS. We also conduct experiments on the application of sparse regression, where the objective evaluation is often estimated using a sample data, bringing noise. The results on various real-world data sets, whose size can reach millions, clearly show the excellent performance of DPONSS. © 1997-2012 IEEE.","Distributed algorithms; experimental studies; large-scale; multiobjective evolutionary algorithms (MOEAs); noise; Pareto optimization; subset selection; theoretical analyses","Institute of Electrical and Electronics Engineers Inc."
"Zhou Z., Wang K., Folkert M., Liu H., Jiang S., Sher D., Wang J.","Multifaceted radiomics for distant metastasis prediction in head & neck cancer",2020,"Physics in Medicine and Biology",4,"10.1088/1361-6560/ab8956","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088831332&doi=10.1088%2f1361-6560%2fab8956&partnerID=40&md5=9d925f3af17a3c1f498061ccc9217687","Accurately predicting distant metastasis in head & neck cancer has the potential to improve patient survival by allowing early treatment intensification with systemic therapy for high-risk patients. By extracting large amounts of quantitative features and mining them, radiomics has achieved success in predicting treatment outcomes for various diseases. However, there are several challenges associated with conventional radiomic approaches, including: (1) how to optimally combine information extracted from multiple modalities; (2) how to construct models emphasizing different objectives for different clinical applications; and (3) how to utilize and fuse output obtained by multiple classifiers. To overcome these challenges, we propose a unified model termed as multifaceted radiomics (M-radiomics). In M-radiomics, a deep learning with stacked sparse autoencoder is first utilized to fuse features extracted from different modalities into one representation feature set. A multi-objective optimization model is then introduced into M-radiomics where probability-based objective functions are designed to maximize the similarity between the probability output and the true label vector. Finally, M-radiomics employs multiple base classifiers to get a diverse Pareto-optimal model set and then fuses the output probabilities of all the Pareto-optimal models through an evidential reasoning rule fusion (ERRF) strategy in the testing stage to obtain the final output probability. Experimental results show that M-radiomics with the stacked autoencoder outperforms the model without the autoencoder. M-radiomics obtained more accurate results with a better balance between sensitivity and specificity than other single-objective or single-classifier-based models. © 2020 Institute of Physics and Engineering in Medicine.",,"IOP Publishing Ltd"
"Qi C., Chen Q., Sonny Kim S.","Integrated and intelligent design framework for cemented paste backfill: A combination of robust machine learning modelling and multi-objective optimization",2020,"Minerals Engineering",44,"10.1016/j.mineng.2020.106422","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084669642&doi=10.1016%2fj.mineng.2020.106422&partnerID=40&md5=495c5c729c6b15a3f8f3bbead9daa4e8","Modern mining industry thrives for energy-efficient, clean and sustainable mining processes. The cemented paste backfill (CPB) technology, which may constitute 25–30% of the total mining cost, is no exception. One of the major bottlenecks for the current CPB design is that different steps were considered separately. No integrated design frameworks have been proposed, hindering the selection of the optimal CPB processing parameters. Towards this end, this study introduces an integrated and intelligent design framework for CPB (IIDF_CPB). The efficiency and accuracy of the proposed IIDF_CPB rely on two important parts. For one thing, robust machine learning (ML) modelling from constituent materials/processing parameters to performance indicators is established. Accurate ML modelling can save lots of time and substantially reduce the number of lab experiments. For another, IIDF_CPB is inherently a multi-objective optimization problem where two or more objectives need to be optimized simultaneously. The methodology of IIDF_CPB is presented and its feasibility is validated using a comprehensive case study. In the case study, ML modelling is conducted using a hybrid method that combines gradient boosting regression tree (GBRT) and particle swarm optimization (PSO). The non-dominated sorting genetic algorithm II (NSGA-II) is employed to maximize two conflicting performance indicators, namely slump and unconfined compressive strength at 28 days (28-UCS). The case study shows that the GBRT-PSO is robust in the slump and 28-UCS predictions. The average correlation coefficient between experimental and predicted outputs is 0.970 for slump and 0.991 for UCS. NSGA-II is effective in the concurrent optimization of slump and 28-UCS, which determines the Pareto front and maintains the diversity of non-dominated points. © 2020 Elsevier Ltd","Cemented paste backfill; Integrated and intelligent design framework; Machine learning modelling; Multi-objective optimization","Elsevier Ltd"
"Immonen E., Lauren M., Roininen L., Särkkä S.","Multiobjective model-based optimization of diesel injection rate profile by machine learning methods",2020,"SYSCON 2020 - 14th Annual IEEE International Systems Conference, Proceedings",1,"10.1109/SysCon47679.2020.9349028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093366109&doi=10.1109%2fSysCon47679.2020.9349028&partnerID=40&md5=fde0628f7379fca7d11880e0845a73fa","The contribution of this article is to present a model-based machine learning methodology for automatic and simultaneous optimization of the power output and exhaust emissions of diesel internal combustion (IC) engines. We carry out parametric optimization of the rate profile at which fuel is injected into the cylinder for producing minimal nitrogen oxide (NOx) emissions and maximal cylinder power (nIMEP) output, on a computational simulation model of an Agco Power 44 AWI engine calibrated by measurements. Our results display the tradeoffs in reaching these two contradictory optimization objectives on the Pareto frontiers. We show that the so-called boot injection profile, which is commonly used in practice, also emerges through mathematical optimization as a reasonable compromise of the objectives. © 2020 IEEE.","Diesel engine; Fuel injection; Machine learning; Modeling and simulation; Multiobjective optimization; NOx emissions","Institute of Electrical and Electronics Engineers Inc."
"Xu Y., Chen L., Xie F., Hu W., Zhu J., Chen C., Zheng Z.","Directional adversarial training for recommender systems",2020,"Frontiers in Artificial Intelligence and Applications",,"10.3233/FAIA200138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091750164&doi=10.3233%2fFAIA200138&partnerID=40&md5=c4eeb966548bc944a5c192ccd619cf22","Adversarial training is shown as an effective method to improve the generalization ability of deep learning models by making random perturbations in the input space during model training. A recent study has successfully applied adversarial training into recommender systems by perturbing the embeddings of users and items through a minimax game. However, this method ignores the collaborative signal in recommender systems and fails to capture the smoothness in data distribution. We argue that the collaborative signal, which reveals the behavioural similarity between users and items, is critical to modeling recommender systems. In this work, we develop the Directional Adversarial Training (DAT) strategy by explicitly injecting the collaborative signal into the perturbation process. That is, both users and items are perturbed towards their similar neighbours in the embedding space with proper restriction. To verify its effectiveness, we demonstrate the use of DAT on Generalized Matrix Factorization (GMF), one of the most representative collaborative filtering methods. Our experimental results on three public datasets show that our method (called DAGMF) achieves a significant accuracy improvement over GMF and meanwhile, it is less prone to overfitting than GMF. © 2020 The authors and IOS Press.",,"IOS Press BV"
"Chen D., Wang Y., Gao W.","A two-stage multi-objective deep reinforcement learning framework",2020,"Frontiers in Artificial Intelligence and Applications",1,"10.3233/FAIA200202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090079565&doi=10.3233%2fFAIA200202&partnerID=40&md5=0966c608eb94e28e4b67cefd6e40121c","In multi-objective decision making problems, multi-objective reinforcement learning (MORL) algorithms aim to approximate the Pareto frontier uniformly. A naive approach is to learn multiple policies by repeatedly running a single-objective reinforcement learning (RL) algorithm on scalarized rewards. The scalarization methods denote the preferences of objectives, which are different in each run. However, in this way, the model representation and computation are redundant. Furthermore, uniform preferences can not guarantee a uniformly approximated Pareto frontier. To address these problems and leverage the expressive power of deep neural networks, we propose a two-stage MORL framework integrating a multi-policy deep RL algorithm and an evolution strategy algorithm. Firstly, a multi-policy soft actor-critic algorithm is proposed to collaboratively learn multiple policies which are assigned with different scalarization weights. The lower layers of all policy networks are shared. The first-stage learning can be regarded as representation learning. Secondly, the multi-objective covariance matrix adaptation evolution strategy (MO-CMA-ES) is applied to fine-tune policy-independent parameters to approach a dense and uniform estimation of the Pareto frontier. Experimental results on two benchmarks (Deep Sea Treasure and Adaptive Streaming) show the superiority of the proposed method. © 2020 The authors and IOS Press.",,"IOS Press BV"
"Zhang J., Huang Y., Wang Y., Ma G.","Multi-objective optimization of concrete mixture proportions using machine learning and metaheuristic algorithms",2020,"Construction and Building Materials",41,"10.1016/j.conbuildmat.2020.119208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083666890&doi=10.1016%2fj.conbuildmat.2020.119208&partnerID=40&md5=66b6efaedca35f1eea306bed392c6243","For the optimization of concrete mixture proportions, multiple objectives (e.g., strength, cost, slump) with many variables (e.g., concrete components) under highly nonlinear constraints need to be optimized simultaneously. The current single-objective optimization models are not applicable to multi-objective optimization (MOO). This study proposes an MOO method based on machine learning (ML) and metaheuristic algorithms to optimize concrete mixture proportions. First, the performances of different ML models in the prediction of concrete objectives are compared on data sets collected from the published literature. The winner is selected as the objective function for the optimization procedure. In the optimization step, a multi-objective particle swarm optimization algorithm is used to optimize mixture proportions to achieve optimal objectives. The results show that the backpropagation neural network has better performance on continuous data (e.g., strength), whereas the random forest algorithm has higher prediction accuracy on more discrete data (e.g., slump). The Pareto fronts of a bi-objective mixture optimization problem for high-performance concrete and a tri-objective mixture optimization problem for plastic concrete are successfully obtained by the MOO model. The MOO model can serve as a design guide to facilitate decision-making before the construction phase. © 2020 Elsevier Ltd","Compressive strength; Concrete; Machine learning; Multi-objective optimization; Particle swarm optimization; Slump","Elsevier Ltd"
"Moshtari S., Santos J.C.S., Mirakhorli M., Okutan A.","Looking for Software Defects? First Find the Nonconformists",2020,"Proceedings - 20th IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2020",,"10.1109/SCAM51674.2020.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097640999&doi=10.1109%2fSCAM51674.2020.00014&partnerID=40&md5=0f29b63483158990cb0e3ce5797e7491","Software defect prediction models play a key role to increase the quality and reliability of software systems. Because, they are used to identify defect prone source code components and assist testing activities during the development life cycle. Prior research used supervised and unsupervised Machine Learning models for software defect prediction. Supervised defect prediction models require labeled data, however it might be time consuming and expensive to obtain labeled data that has the desired quality and volume. The unsupervised defect prediction models usually use clustering techniques to relax the labeled data requirement, however labeling detected clusters as defective is a challenging task. The Pareto principle states that a small number of modules contain most of the defects. Getting inspired from the Pareto principle, this work proposes a novel, unsupervised learning approach that is based on outlier detection. We hypothesize that defect prone software components have different characteristics when compared to others and can be considered as outliers, therefore outlier detection techniques can be used to identify them. The experiment results on 16 software projects from two publicly available datasets (PROMISE and GitHub) indicate that the k-Nearest Neighbor (KNN) outlier detection method can be used to identify the majority of software defects. It could detect 94% of expected defects at best case and more than 63% of the defects in 75% of the projects. We compare our approach with the state-of-The-Art supervised and unsupervised defect prediction approaches. The results of rigorous empirical evaluations indicate that the proposed approach outperforms existing unsupervised models and achieves comparable results with the leading supervised techniques that rely on complex training and tuning algorithms. © 2020 IEEE.","Defect prediction; outlier detection; software metrics; software quality; unsupervised learning","Institute of Electrical and Electronics Engineers Inc."
"Cakici T.O., Islamoglu G., Guzelhan S.N., Afacan E., Dundar G.","Improving POF Quality in Multi Objective Optimization of Analog ICs via Deep Learning",2020,"ECCTD 2020 - 24th IEEE European Conference on Circuit Theory and Design",,"10.1109/ECCTD49232.2020.9218272","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096497745&doi=10.1109%2fECCTD49232.2020.9218272&partnerID=40&md5=5a8eddd4d34271aa0f94481ca24422b1","Multi-objective optimization (MOO) is commonly used in analog circuits to reveal the trade-offs among design specifications via Pareto optimal fronts (POF). Although the general trend of POF can be found in a reasonable time with MOO, a high-quality POF requires an excessive number of iterations, which results in extremely long synthesis times. In this paper, single-objective optimization (SOO) is utilized to increase the POF quality rather than running MOO algorithms for long duration. Moreover, deep neural networks (DNN) are used to replace SPICE, which reduces the synthesis time further. This approach provides up to 50.62% improvement in POF quality and DNNs speed up the process up to 29.6x. © 2020 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Bratanova K., Kareev I., Salimov R.","Minimax Modifications of Linear Discriminant Analysis for Classification with Rare Classes",2020,"2020 IEEE East-West Design and Test Symposium, EWDTS 2020 - Proceedings",,"10.1109/EWDTS50664.2020.9224895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096417870&doi=10.1109%2fEWDTS50664.2020.9224895&partnerID=40&md5=cf903e120112a9d856ac34af53215df8","We consider the problem of classification for imbalanced samples with rare classes. A common problem for machine learning methods in such setting is that a rare class would have extremely high classification error compared to more widespread classes. In general, this problem could be mitigated with re-sampling or fitting additional weights to control the classification errors in classes, though those methods are computationally expensive for large datasets and sometimes fail to attain appropriate results. It this paper we present cost-efficient modifications of Linear Discriminant Analysis allowing to mitigate the problem by minimizing maximal classification error among the classes. For example, this allows achieving more robust machinery malfunction detection algorithms where our expectations on recall would be more consistent among different malfunction types. © 2020 IEEE.","classification; imbalanced sample dataset; linear discriminant analysis; minimax error; rare class","Institute of Electrical and Electronics Engineers Inc."
"Nakada R., Imaizumi M.","Adaptive approximation and generalization of deep neural network with intrinsic dimensionality",2020,"Journal of Machine Learning Research",2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094902629&partnerID=40&md5=68247f3bf68d43b79308844d7c9fd3f7","In this study, we prove that an intrinsic low dimensionality of covariates is the main factor that determines the performance of deep neural networks (DNNs). DNNs generally provide outstanding empirical performance. Hence, numerous studies have actively investigated the theoretical properties of DNNs to understand their underlying mechanisms. In particular, the behavior of DNNs in terms of high-dimensional data is one of the most critical questions. However, this issue has not been sufficiently investigated from the aspect of covariates, although high-dimensional data have practically low intrinsic dimensionality. In this study, we derive bounds for an approximation error and a generalization error regarding DNNs with intrinsically low dimensional covariates. We apply the notion of the Minkowski dimension and develop a novel proof technique. Consequently, we show that convergence rates of the errors by DNNs do not depend on the nominal high dimensionality of data, but on its lower intrinsic dimension. We further prove that the rate is optimal in the minimax sense. We identify an advantage of DNNs by showing that DNNs can handle a broader class of intrinsic low dimensional data than other adaptive estimators. Finally, we conduct a numerical simulation to validate the theoretical results. © 2020 Ryumei Nakada and Masaaki Imaizumi.","Deep Learning; Deep Neural Network; Generalization Analysis; Intrinsic Dimension; Minimax Optimal Rate","Microtome Publishing"
"Hirose Y.","Regularization methods based on the Lq-likelihood for linear models with heavy-tailed errors",2020,"Entropy",,"10.3390/E22091036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092096644&doi=10.3390%2fE22091036&partnerID=40&md5=d5ece03587d7cc20c73ae3fe03873255","We propose regularization methods for linear models based on the Lq-likelihood, which is a generalization of the log-likelihood using a power function. Regularization methods are popular for the estimation in the normal linear model. However, heavy-tailed errors are also important in statistics and machine learning. We assume q-normal distributions as the errors in linear models. A q-normal distribution is heavy-tailed, which is defined using a power function, not the exponential function. We find that the proposed methods for linear models with q-normal errors coincide with the ordinary regularization methods that are applied to the normal linear model. The proposed methods can be computed using existing packages because they are penalized least squares methods. We examine the proposed methods using numerical experiments, showing that the methods perform well, even when the error is heavy-tailed. The numerical experiments also illustrate that our methods work well in model selection and generalization, especially when the error is slightly heavy-tailed. © 2020 by the author.","Least absolute shrinkage and selection operator (LASSO); Minimax concave penalty (MCP); Power function; Q-normal distribution; Smoothly clipped absolute deviation (SCAD); Sparse estimation","MDPI AG"
"Eldafrawy M., Boutros A., Yazdanshenas S., Betz V.","FPGA Logic Block Architectures for Efficient Deep Learning Inference",2020,"ACM Transactions on Reconfigurable Technology and Systems",6,"10.1145/3393668","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091027276&doi=10.1145%2f3393668&partnerID=40&md5=86414b60f10a5708e97250aa20f0f007","Reducing the precision of deep neural network (DNN) inference accelerators can yield large efficiency gains with little or no accuracy degradation compared to half or single precision floating-point by enabling more multiplication operations per unit area. A wide range of precisions fall on the pareto-optimal curve of hardware efficiency vs. accuracy with no single precision dominating, making the variable precision capabilities of FPGAs very valuable. We propose three types of logic block architectural enhancements and fully evaluate a total of six architectures that improve the area efficiency of multiplications and additions implemented in the soft fabric. Increasing the LUT fracturability and adding two adders to the ALM (4-bit Adder Double Chain architecture) leads to a 1.5× area reduction for arithmetic heavy machine learning (ML) kernels, while increasing their speed. In addition, this architecture also reduces the logic area of general applications by 6%, while increasing the critical path delay by only 1%. However, our highest impact option, which adds a 9-bit shadow multiplier to the logic clusters, reduces the area and critical path delay of ML kernels by 2.4× and 1.2×, respectively. These large gains come at a cost of 15% logic area increase for general applications. © 2020 ACM.","CAD tools; Deep neural networks; FPGA","Association for Computing Machinery"
"Song S., Das A., Kandasamy N.","Improving Dependability of Neuromorphic Computing with Non-Volatile Memory",2020,"Proceedings - 16th European Dependable Computing Conference, EDCC 2020",14,"10.1109/EDCC51268.2020.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090580950&doi=10.1109%2fEDCC51268.2020.00013&partnerID=40&md5=6a83d9905d3e3ecaa66a0a909d170f52","As process technology continues to scale aggressively, circuit aging in a neuromorphic hardware due to negative bias temperature instability (NBTI) and time-dependent dielectric breakdown (TDDB) is becoming a critical reliability issue and is expected to proliferate when using non-volatile memory (NVM) for synaptic storage. This is because NVM devices require high voltages and currents to access their synaptic weights, which further accelerate the circuit aging in neuromorphic hardware. Current methods for qualifying reliability are overly conservative, since they estimate circuit aging considering worst-case operating conditions and unnecessarily constrain performance. This paper proposes RENEU, a reliability-oriented approach to map machine learning applications to neuromorphic hardware, with the aim of improving system-wide reliability, without compromising key performance metrics such as execution time of these applications on the hardware. Fundamental to RENEU is a novel formulation of the aging of CMOS-based circuits in a neuromorphic hardware considering different failure mechanisms. Using this formulation, RENEU develops a system- wide reliability model which can be used inside a design-space exploration framework involving the mapping of neurons and synapses to the hardware. To this end, RENEU uses an instance of Particle Swarm Optimization (PSO) to generate mappings that are Pareto-optimal in terms of performance and reliability. We evaluate RENEU using different machine learning applications on a state-of-the-art neuromorphic hardware with NVM synapses. Our results demonstrate an average 38% reduction in circuit aging, leading to an average 18% improvement in the lifetime of the hardware compared to current practices. RENEU only introduces a marginal performance overhead of 5% compared to a performance-oriented state-of-the-art. © 2020 IEEE.","Dependability; Hot Carrier Injection (HCI); Machine Learning; Negative Bias Temperature Instability (NBTI); Neuromorphic Computing; Particle Swarm Optimization (PSO); Spiking Neural Network (SNN); Time Dependent Dielectric Breakdown (TDDB)","Institute of Electrical and Electronics Engineers Inc."
"Cirrincione G., Kumar R.R., Mohammadi A., Kia S.H., Barbiero P., Ferretti J.","Shallow Versus Deep Neural Networks in Gear Fault Diagnosis",2020,"IEEE Transactions on Energy Conversion",5,"10.1109/TEC.2020.2978155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089917504&doi=10.1109%2fTEC.2020.2978155&partnerID=40&md5=53541b12e7b1f93ac73a3ca336902f5b","Accurate gear defect detection in induction machine-based systems is a fundamental issue in several industrial applications. At this aim, shallow neural networks, i.e., architectures with only one hidden layer, have been used after a feature extraction step from vibration, torque, acoustic pressure and electrical signals. Their additional complexity is justified by their ability in extracting its own features and in the very high-test classification rates. These signals are here analyzed, both geometrically and topologically, in order to estimate the class manifolds and their reciprocal positioning. At this aim, the different states of the gears are studied by using linear (Pareto charts, biplots, principal angles) and nonlinear (curvilinear component analysis) techniques, while the class clusters are visualized by using the parallel coordinates. It is deduced that the class manifolds are compact and well separated. This result justifies the use of a shallow neural network, instead of a deep one, as already remarked in the literature, but with no theoretical justification. The experimental section confirms this assertion, and also compares the shallow neural network results with the other machine learning techniques used in the literature. © 1986-2012 IEEE.","Classification algorithm; fault detection; fault diagnosis; gears; induction motors; multilayer perceptron; neural networks; principal component analysis; vibrations","Institute of Electrical and Electronics Engineers Inc."
"Haghir Chehreghani M., Haghir Chehreghani M.","Learning representations from dendrograms",2020,"Machine Learning",3,"10.1007/s10994-020-05895-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089444036&doi=10.1007%2fs10994-020-05895-3&partnerID=40&md5=9979aa6d989f46e002869798b9631fa3","We propose unsupervised representation learning and feature extraction from dendrograms. The commonly used Minimax distance measures correspond to building a dendrogram with single linkage criterion, with defining specific forms of a level function and a distance function over that. Therefore, we extend this method to arbitrary dendrograms. We develop a generalized framework wherein different distance measures and representations can be inferred from different types of dendrograms, level functions and distance functions. Via an appropriate embedding, we compute a vector-based representation of the inferred distances, in order to enable many numerical machine learning algorithms to employ such distances. Then, to address the model selection problem, we study the aggregation of different dendrogram-based distances respectively in solution space and in representation space in the spirit of deep representations. In the first approach, for example for the clustering problem, we build a graph with positive and negative edge weights according to the consistency of the clustering labels of different objects among different solutions, in the context of ensemble methods. Then, we use an efficient variant of correlation clustering to produce the final clusters. In the second approach, we investigate the combination of different distances and features sequentially in the spirit of multi-layered architectures to obtain the final features. Finally, we demonstrate the effectiveness of our approach via several numerical studies. © 2020, The Author(s).","Dendrogram; Ensemble method; Feature extraction; Representation learning; Unsupervised learning","Springer"
"Montazeri M., Kebriaei H., Araabi B.N.","Learning pareto optimal solution of a multi-attribute bilateral negotiation using deep reinforcement",2020,"Electronic Commerce Research and Applications",1,"10.1016/j.elerap.2020.100987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088838659&doi=10.1016%2fj.elerap.2020.100987&partnerID=40&md5=a388673163e292e3fc23621f1936e5c9","This paper aims to design an intelligent buyer to learn how to decide in an incomplete information multi-attribute bilateral simultaneous negotiation. The buyer does not know the negotiation strategy of the seller and only have access to the historical data of the previous negotiations. Using the historical data and clustering method, the type of seller is identified online during the negotiation. Then, the deep reinforcement learning method is utilized to support the buyer to learn its optimal decision. In the complete information case, we prove that the negotiation admits a unique Nash bargaining solution with possibly asymmetric negotiation powers. In comprehensive simulation studies, the efficiency of the proposed learning agent is evaluated in different scenarios and we show that the learning negotiation with incomplete information is converged to a Pareto optimal solution. Then, using the concept of the Nash bargaining solution, the negotiation power of the buyer is assessed in negotiation. © 2020 Elsevier B.V.","Actor-critic; Bargaining power; Deep auto encoder; Multi-attribute negotiation; Nash bargaining solution","Elsevier B.V."
"Bohara G., Sadeghnejad Barkousaraie A., Jiang S., Nguyen D.","Using deep learning to predict beam-tunable Pareto optimal dose distribution for intensity-modulated radiation therapy",2020,"Medical Physics",7,"10.1002/mp.14374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088800886&doi=10.1002%2fmp.14374&partnerID=40&md5=393f5fc8dbc5b50f8a2459c4283e1dcf","Purpose: Many researchers have developed deep learning models for predicting clinical dose distributions and Pareto optimal dose distributions. Models for predicting Pareto optimal dose distributions have generated optimal plans in real time using anatomical structures and static beam orientations. However, Pareto optimal dose prediction for intensity-modulated radiation therapy (IMRT) prostate planning with variable beam numbers and orientations has not yet been investigated. We propose to develop a deep learning model that can predict Pareto optimal dose distributions by using any given set of beam angles, along with patient anatomy, as input to train the deep neural networks. We implement and compare two deep learning networks that predict with two different beam configuration modalities. Methods: We generated Pareto optimal plans for 70 patients with prostate cancer. We used fluence map optimization to generate 500 IMRT plans that sampled the Pareto surface for each patient, for a total of 35 000 plans. We studied and compared two different models, Models I and II. Although they both used the same anatomical structures — including the planning target volume (PTV), organs at risk (OARs), and body — these models were designed with two different methods for representing beam angles. Model I directly uses beam angles as a second input to the network as a binary vector. Model II converts the beam angles into beam doses that are conformal to the PTV. We divided the 70 patients into 54 training, 6 validation, and 10 testing patients, thus yielding 27 000 training, 3000 validation, and 5000 testing plans. Mean square loss (MSE) was taken as the loss function. We used the Adam optimizer with a default learning rate of 0.01 to optimize the network’s performance. We evaluated the models’ performance by comparing their predicted dose distributions with the ground truth (Pareto optimal) dose distribution, in terms of dose volume histogram (DVH) plots and evaluation metrics such as PTV D98, D95, D50, D2, Dmax, Dmean, Paddick Conformation Number, R50, and Homogeneity index. Results: Our deep learning models predicted voxel-level dose distributions that precisely matched the ground truth dose distributions. The DVHs generated also precisely matched the ground truth. Evaluation metrics such as PTV statistics, dose conformity, dose spillage (R50), and homogeneity index also confirmed the accuracy of PTV curves on the DVH. Quantitatively, Model I’s prediction error of 0.043 (confirmation), 0.043 (homogeneity), 0.327 (R50), 2.80% (D95), 3.90% (D98), 0.6% (D50), and 1.10% (D2) was lower than that of Model II, which obtained 0.076 (confirmation), 0.058 (homogeneity), 0.626 (R50), 7.10% (D95), 6.50% (D98), 8.40% (D50), and 6.30% (D2). Model I also outperformed Model II in terms of the mean dose error and the max dose error on the PTV, bladder, rectum, left femoral head, and right femoral head. Conclusions: Treatment planners who use our models will be able to use deep learning to control the trade-offs between the PTV and OAR weights, as well as the beam number and configurations in real time. Our dose prediction methods provide a stepping stone to building automatic IMRT treatment planning. © 2020 American Association of Physicists in Medicine","beam tunable; deep learning; intensity-modulated radiation therapy; neural networks; pareto optimality; prostate cancer","John Wiley and Sons Ltd"
"Lambert J.W., Hawk G.S.","Identifying Pareto-based solutions for regression subset selection via a feasible solution algorithm",2020,"International Journal of Data Science and Analytics",,"10.1007/s41060-020-00218-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087988682&doi=10.1007%2fs41060-020-00218-0&partnerID=40&md5=2aae936d52af46311a3600e452f9c586","The concept of Pareto optimality has been utilized in fields such as engineering and economics to understand fluid dynamics and consumer behavior. In machine learning contexts, Pareto-optimality has been used to identify tuning parameters that best optimize a set of m criteria (multi-objective optimization). During the process of regression model selection, data scientists are often concerned with choosing a model which has the best single criterion (e.g., Akaike information criterion (AIC) or R-squared (R2)) before continuing to check a number of other regression model characteristics (e.g., model size, form, diagnostics, and interpretability). This strategy is multi-objective in nature but single objective in its numeric execution. This paper will first introduce a feasible solution algorithm (FSA) and explain how it can be applied to multi-objective problems for regression subset selection. Then we introduce the general framework of Pareto optimality within the regression setting. We then apply the algorithm in a simulation setting where we seek to estimate the first four Pareto boundaries for regression models using two model fit criteria. Finally, we present an application where we use a US communities and crime dataset. © 2020, Springer Nature Switzerland AG.","Feasible solution; Multiple; Objective; Optimal; Pareto; Regression; Subset selection","Springer Science and Business Media Deutschland GmbH"
"van der Bijl E., Wang Y., Janssen T., Petit S.","Predicting patient specific Pareto fronts from patient anatomy only",2020,"Radiotherapy and Oncology",2,"10.1016/j.radonc.2020.05.050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086672303&doi=10.1016%2fj.radonc.2020.05.050&partnerID=40&md5=d9e5492c3fb99ff80bc48c42ed55aeed","Purpose: To demonstrate the feasibility of predicting the patient-specific treatment planning Pareto front (PF) for prostate cancer patients based only on delineations of PTV, rectum and body. Material/methods: Our methodology consists of four steps. First, using Erasmus-iCycle, the Pareto fronts of 112 prostate cancer patients were constructed by generating per patient 42 Pareto optimal treatment plans with different priorities. Dose parameters associated to homogeneity, conformity and dose to rectum were extracted. Second, a 3D convex function representing the PF spanned by the 42 plans was fitted for each patient using three patient-specific parameters. Third, ten features were extracted from the, aforementioned, structures to train a linear-regressor prediction algorithm to predict these three patient-specific parameters. Fourth, the quality of the predictions was assessed by calculating the average and maximum distances of the predicted PF to the 42 plans for patients in the validation cohort. Results: The prediction model was able to predict the clinically relevant PF within 2 Gy for 90% of the patients with a median average distance of 0.6 Gy. Conclusions: We demonstrate the feasibility of fast, accurate predictions of the patient-specific PF for prostate cancer patients based only on delineations of PTV, rectum and body. © 2020 Elsevier B.V.","Knowledge based planning (KBP); Pareto front; Prostate cancer; Treatment planning","Elsevier Ireland Ltd"
"Maksim B., Pavel W., Irina V., Mikhail S., Margarita C.","Development of a software library for game artificial intelligence",2020,"Proceedings of the 2020 IEEE International Conference ""Quality Management, Transport and Information Security, Information Technologies"", IT and QM and IS 2020",1,"10.1109/ITQMIS51053.2020.9322928","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100401874&doi=10.1109%2fITQMIS51053.2020.9322928&partnerID=40&md5=ae4fc932b84c81bee9cc02dd28d0a89f","Today, technologies of artificial neural networks are very popular and are used in various fields and tasks, such as pattern recognition, classification. To create artificial neural networks, constructors or software libraries for machine learning can be used. However, they do not always contain the necessary functions. In some cases, you need to write your own software library to solve non-standard tasks. The article discusses the development of a software library for creating artificial neural networks. Using the developed library is demonstrated in the task of implementing the game artificial intelligence of the opponent in a simple computer game 'Tic-tac-toe'. The effectiveness of the opponent's game is compared with the implementations of opponents based on the minimax algorithm and the random behavior algorithm. © 2020 IEEE.","Artificial neural networks; Game 'Tic-tac-toe'; Gaming artificial intelligence; Library","Institute of Electrical and Electronics Engineers Inc."
"Colucci A., Marchisio A., Bussolino B., Mrazek V., Martina M., Masera G., Shafique M.","A Fast Design Space Exploration Framework for the Deep Learning Accelerators: Work-in-Progress",2020,"Proceedings of the 2020 International Conference on Hardware/Software Codesign and System Synthesis, CODES+ISSS 2020",1,"10.1109/CODESISSS51650.2020.9244038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097640545&doi=10.1109%2fCODESISSS51650.2020.9244038&partnerID=40&md5=a162eee7df60302dad5c1ff1e2ecde62","The Capsule Networks (CapsNets) is an advanced form of Convolutional Neural Network (CNN), capable of learning spatial relations and being invariant to transformations. CapsNets requires complex matrix operations which current accelerators are not optimized for, concerning both training and inference passes. Current state-of-The-Art simulators and design space exploration (DSE) tools for DNN hardware neglect the modeling of training operations, while requiring long exploration times that slow down the complete design flow. These impediments restrict the real-world applications of CapsNets (e.g., autonomous driving and robotics) as well as the further development of DNNs in life-long learning scenarios that require training on low-power embedded devices. Towards this, we present XploreDL, a novel framework to perform fast yet high-fidelity DSE for both inference and training accelerators, supporting both CNNs and CapsNets operations. XploreDL enables a resource-efficient DSE for accelerators, focusing on power, area, and latency, highlighting Pareto-optimal solutions which can be a green-lit to expedite the design flow. XploreDL can reach the same fidelity as ARM's SCALE-sim, while providing 600x speedup and having a 50x lower memory-footprint. Preliminary results with a deep CapsNet model on MNIST for training accelerators show promising Pareto-optimal architectures with up to 0.4 TOPS/squared-mm and 800 fJ/op efficiency. With inference accelerators for AlexNet the Pareto-optimal solutions reach up to 1.8 TOPS/squared-mm and 200 fJ/op efficiency. © 2020 IEEE.","Capsule Networks; Convolutional Neural Networks; Design Space Exploration; Hardware Accelerator; Training","Institute of Electrical and Electronics Engineers Inc."
"Alsulaimawi Z.","Variational Bound of Mutual Information for Fairness in Classification",2020,"IEEE 22nd International Workshop on Multimedia Signal Processing, MMSP 2020",,"10.1109/MMSP48831.2020.9287139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099261763&doi=10.1109%2fMMSP48831.2020.9287139&partnerID=40&md5=52ba1ac90198d4cbf4bf32bc5468fbc1","Machine learning applications have emerged in many aspects of our lives, such as for credit lending, insurance rates, and employment applications. Consequently, it is required that such systems be nondiscriminatory and fair in sensitive features user, e.g., race, sexual orientation, and religion. To address this issue, this paper develops a minimax adversarial framework, called features protector (FP) framework, to achieve the information-theoretical trade-off between minimizing distortion of target data and ensuring that sensitive features have similar distributions. We evaluate the performance of the proposed framework on two real-world datasets. Preliminary empirical evaluation shows that our framework provides both accurate and fair decisions. © 2020 IEEE.","adversarial learning; big data security; deep learning; Fairness; privacy-preserving; variational mutual information","Institute of Electrical and Electronics Engineers Inc."
"Wan Y., Zhong Y., Ma A., Wang J., Feng R.","RSSM-Net: Remote Sensing Image Scene Classification Based on Multi-Objective Neural Architecture Search",2020,"International Geoscience and Remote Sensing Symposium (IGARSS)",,"10.1109/IGARSS39084.2020.9323429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101992640&doi=10.1109%2fIGARSS39084.2020.9323429&partnerID=40&md5=c62f1a4392b567db0d87c3814123c4e5","The deep learning (DL)-based scene classification methods have been obtained the remarkable attention for the high spatial resolution remote sensing (HRS) imagery. However, from one aspect, the existing DL methods in HRS image scene classification are usually the variations of the natural image processing methods and often the inherent network structures; from another aspect, the strenuous and significant efforts have been devoted to the design of relevant network structures by human experts. In this paper, learning from the natural evolution, the deep neural network is expected to be globally evolved by the machine for automatically adapting the structure of the HRS imagery, a multi-objective neural architecture search based HRS image scene classification method is proposed (RSSM-Net). The two objectives of minimizing a classification error and the computational complexity have been simultaneously optimized through the evolutionary multi-objective method, the competitive neural architectures in a Pareto solution set are then obtained. The effectiveness is proved by the experiment of the UC Merced dataset with several networks designed by human experts. © 2020 IEEE.","evolutionary algorithm; multiobjective optimization; neural architecture search; Remote sensing; scene classification","Institute of Electrical and Electronics Engineers Inc."
"Xie S.-M.","Comparative models in customer base analysis: Parametric model and observation-driven model",2020,"Journal of Business Economics and Management",1,"10.3846/jbem.2020.13194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093522761&doi=10.3846%2fjbem.2020.13194&partnerID=40&md5=c7697a6a4f671fdbb0b77797494eea43","This study conducts a dynamic rolling comparison between the Pareto/NBD model (para-metric model) and machine learning algorithms (observation-driven models) in customer base analysis, which the literature has not comprehensively investigated before. The aim is to find the comparative edge of these two approaches under customer base analysis and to define the implementation timing of these two paradigms. This research utilizes Pareto/NBD (Abe) as representative of Buy-Till-You-Die (BTYD) models in order to compete with machine learning algorithms and presents the following results. (1) The parametric model wins in transaction frequency prediction, whereas it loses in inactivity prediction. (2) The BTYD model outperforms machine learning in inactivity prediction when the customer base is active, performs better in an inactive customer base when competing with Poisson regression, and wins in a short-term active customer base when competing with a neural network algorithm in transaction frequency prediction. (3) The parametric model benefits more from a short calibration length and a long holdout/target period, which exhibit uncertainty. (4) The covariate effect helps Pareto/NBD (Abe) gain a better predictive result. These findings assist in defining the comparative edge and implementation timing of these two approaches and are useful for modeling and business decision making. © 2020 The Author(s). Published by VILNIUS TECH Press.","BTYD; Customer base analysis; Machine learning; Non-contractual setting; Observation-driven model; Parametric model; Pareto/NBD model","VGTU"
"Leipnitz M.T., Nazar G.L.","Throughput-Oriented Spatio-Temporal Optimization in Approximate High-Level Synthesis",2020,"Proceedings - IEEE International Conference on Computer Design: VLSI in Computers and Processors",1,"10.1109/ICCD50377.2020.00060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098889738&doi=10.1109%2fICCD50377.2020.00060&partnerID=40&md5=92061dac32877a1a0038452155cff630","Current and emerging systems for high-throughput applications, such as machine learning, cloud computing, and real-time video encoding demand real-time processing computations, heavily constrained by latency and power requirements. To deal with the increasing computational complexity, designers may resort to approximate accelerators for error-resilient compute-intensive kernels to meet such requirements with acceptable deviation from the exact implementation. However, since time-to-market is crucial when dealing with evolving applications, technologies, and standards, hand-crafting approximate accelerators may impose prohibitive development time and cost overheads. In this scenario, approximate High-Level Synthesis (HLS) methodologies have been proposed to deal with the complexity of exploring approximation techniques. Nevertheless, current tools are not suitable for exploring throughput optimizations, being instead constrained to perform specific improvements on area, power, and performance. In this work, we propose the use of HLS to generate Pareto-optimal accelerators for throughput-constrained applications. Particularly, we present a throughput-oriented approximate HLS methodology that explores both delay and area optimizations to increase the reuse over time and parallelism of such accelerators. Results show that our method is able to improve throughput by up to 80 % with no additional area costs or to sustain the same throughput of the exact design with about 45 % less area while introducing manageable error for most applications. Moreover, our method can attain throughput improvements of up to 18% when compared with recent works focusing only on performance or area optimizations, with no additional costs. © 2020 IEEE.","Approximate Computing; Design Space Exploration; High-Level Synthesis","Institute of Electrical and Electronics Engineers Inc."
"Iyer A., Zhang Y., Prasad A., Gupta P., Tao S., Wang Y., Prabhune P., Schadler L.S., Brinson L.C., Chen W.","Data centric nanocomposites design: Via mixed-variable Bayesian optimization",2020,"Molecular Systems Design and Engineering",1,"10.1039/d0me00079e","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094975961&doi=10.1039%2fd0me00079e&partnerID=40&md5=08aadd346c128396cfe64c8e025f8689","With an unprecedented combination of mechanical and electrical properties, polymer nanocomposites have the potential to be widely used across multiple industries. Tailoring nanocomposites to meet application specific requirements remains a challenging task, owing to the vast, mixed-variable design space that includes composition (i.e. choice of polymer, nanoparticle, and surface modification) and microstructures (i.e. dispersion and geometric arrangement of particles) of the nanocomposite material. Modeling properties of the interphase, the region surrounding a nanoparticle, introduces additional complexity to the design process and requires computationally expensive simulations. As a result, previous attempts at designing polymer nanocomposites have focused on finding the optimal microstructure for only a fixed combination of constituents. In this article, we propose a data centric design framework to concurrently identify optimal composition and microstructure using mixed-variable Bayesian optimization. This framework integrates experimental data with state-of-the-art techniques in interphase modeling, microstructure characterization and reconstructions and machine learning. Latent variable Gaussian processes (LVGPs) quantifies the lack-of-data uncertainty over the mixed-variable design space that consists of qualitative and quantitative material design variables. The design of electrically insulating nanocomposites is cast as a multicriteria optimization problem with the goal of maximizing dielectric breakdown strength while minimizing dielectric permittivity and dielectric loss. Within tens of simulations, our method identifies a diverse set of designs on the Pareto frontier indicating the tradeoff between dielectric properties. These findings project data centric design, effectively integrating experimental data with simulations for Bayesian Optimization, as an effective approach for design of engineered material systems. This journal is © The Royal Society of Chemistry.",,"Royal Society of Chemistry"
"Tan B., Chen H.","Multi-objective energy management of multiple microgrids under random electric vehicle charging",2020,"Energy",17,"10.1016/j.energy.2020.118360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088803517&doi=10.1016%2fj.energy.2020.118360&partnerID=40&md5=008b07083efeb093afe4523067307224","In view of the increasing development of decentralized power systems and electric vehicles, this paper seeks to improve the energy management performance of multiple microgrid systems under the uncertainty associated with electric vehicle charging. A multi-objective optimization model is established for minimizing the transmission losses, operating costs, and carbon emissions of multiple microgrid systems. Firstly, a novel method is proposed for forecasting electric vehicle charging loads based on a back propagation neural network improved by long short-term memory deep learning. Based on the forecast data, a double layer solution algorithm is proposed, which consists of an adaptive multi-objective evolutionary algorithm based on decomposition and differential evolution at the multiple microgrids layer and a modified consistency algorithm for fast economic scheduling at the single microgrid layer. Finally, a model system composed of four interconnected IEEE microgrids is simulated as a case study, and the performance of the proposed algorithm is compared with that of conventional multi-objective evolutionary algorithms based on decomposition. The simulation results demonstrate the superiority of the global search performance and the rapid convergence performance of the proposed improved algorithm. © 2020 Elsevier Ltd","Consistency algorithm; Electric vehicles; Long short-term memory; Multi-microgrids; Pareto optimality; Shannon-Wiener index","Elsevier Ltd"
"Chen D., Wang Y., Gao W.","Combining a gradient-based method and an evolution strategy for multi-objective reinforcement learning",2020,"Applied Intelligence",2,"10.1007/s10489-020-01702-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085925160&doi=10.1007%2fs10489-020-01702-7&partnerID=40&md5=675958d297b14c5cc60eb3f60c69cf1f","Multi-objective reinforcement learning (MORL) algorithms aim to approximate the Pareto frontier uniformly in multi-objective decision making problems. In the scenario of deep reinforcement learning (RL), gradient-based methods are often adopted to learn deep policies/value functions due to the fast convergence speed, while pure gradient-based methods can not guarantee a uniformly approximated Pareto frontier. On the other side, evolution strategies straightly manipulate in the solution space to achieve a well-distributed Pareto frontier, but applying evolution strategies to optimize deep networks is still a challenging topic. To leverage the advantages of both kinds of methods, we propose a two-stage MORL framework combining a gradient-based method and an evolution strategy. First, an efficient multi-policy soft actor-critic algorithm is proposed to learn multiple policies collaboratively. The lower layers of all policy networks are shared. The first-stage learning can be regarded as representation learning. Secondly, the multi-objective covariance matrix adaptation evolution strategy (MO-CMA-ES) is applied to fine-tune policy-independent parameters to approach a dense and uniform estimation of the Pareto frontier. Experimental results on three benchmarks (Deep Sea Treasure, Adaptive Streaming, and Super Mario Bros) show the superiority of the proposed method. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Multi-objective reinforcement learning; Multi-policy reinforcement learning; Pareto frontier; Sampling efficiency","Springer"
"Asgharnia A., Schwartz H.M., Atia M.","Deception in the Game of Guarding Multiple Territories: A Machine Learning Approach",2020,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",,"10.1109/SMC42975.2020.9283173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098854537&doi=10.1109%2fSMC42975.2020.9283173&partnerID=40&md5=242733f65269b84ca02dbbae11be0ce7","In this paper, a deceptive version of guarding a territory in a grid world is proposed. Like the original version, a defender tries to intercept an invader before it invades the targets. However, the discerning invader can deceive the defender about its real goal so that it can improve its performance. On the other hand, the defender tries to confront the invader by guessing its true goal. A two-level policy is obtained via reinforcement learning (RL). In the lower level, the invader and the defender learn their optimal policies to invade or defend a particular territory. In the higher level, the invader learns which territory it should pretend to invade in order to manipulate the defender's belief function. A multiagent reinforcement learning (MARL) algorithm is implemented for obtaining the optimal policies via the minimax Q-learning algorithm at the lower level. Whereas for the higher-level policy a single-agent Q-learning algorithm is utilized. Results of different reward functions are compared. The results show that the invader can improve its performance by taking advantage of deception. © 2020 IEEE.","Belief; Deception; Guarding a territory; Multiagent systems; Reinforcement Learning","Institute of Electrical and Electronics Engineers Inc."
"Jiang H., Shi D., Xue C., Wang Y., Wang G., Zhang Y.","Friend-or-Foe Deep Deterministic Policy Gradient",2020,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",1,"10.1109/SMC42975.2020.9283033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098852119&doi=10.1109%2fSMC42975.2020.9283033&partnerID=40&md5=3969b94341140b74b24727b4cb7443b0","One of the toughest challenges in the multi-agent deep reinforcement learning (MADRL) is that when the opponents' policies change rapidly, the collaborative agents can't learn well to respond to the opponents' policies effectively. This may lead to a local optimum w.r.t. the learned policy of the collaborative agents may be only locally optimal to the opponents' current policies. To address this problem, we propose a novel algorithm termed Friend-or-Foe Deep Deterministic Policy Gradient (FD2PG), in which the cooperative agents can be trained more robust and have stronger cooperation ability in continuous action space. These collaborative agents can generalize easily and respond correctly, even if their opponents' policies alter. Inspired by the classic Friend-or-Foe Q-learning algorithm (FFQ), we introduce the idea of minimizing the foes and maximizing the friends into the centralized training distributed execution framework, multi-agent deep deterministic policy gradient algorithm (MADDPG), to enhance collaborative agents' robustness and cooperativity. Besides, we introduce a Minimax Multi-Agent Learning (MMAL) method to explore two special equilibriums (the adversarial equilibrium and the coordination equilibrium), which can guarantee the convergence of FD2PG and improve optimization. Extensive fine-grained experiments, including four representative scenario experiments and two scale-performance correlation experiments, were conducted to demonstrate the superior performance of FD2PG comparing with existing baselines. © 2020 IEEE.","Deep Deterministic Policy Gradient; Friend-or-Foe; Multi-Agent Deep Reinforcement Learning","Institute of Electrical and Electronics Engineers Inc."
"Jackson D., Belakaria S., Cao Y., Rao Doppa J., Lu X.","Machine Learning Enabled Fast Multi-Objective Optimization for Electrified Aviation Power System Design",2020,"ECCE 2020 - IEEE Energy Conversion Congress and Exposition",5,"10.1109/ECCE44975.2020.9235599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097127104&doi=10.1109%2fECCE44975.2020.9235599&partnerID=40&md5=9a0dbda97b4117483b40dcae8beb7b3e","With the rise of more electric and all-electric aviation power systems, engineering efforts of system optimization shift to the electrical domain. A substantial amount of time and resources are dedicated to finding the best system architecture and design specifications to meet energy efficiency goals and physical constraints. Current processes utilize models of power system components to determine the optimal designs. However, such modeling is computationally expensive as numerous iterations are required to settle on an optimal design. This paper proposes a machine learning (ML) enabled constrained multi-objective optimization solver to drastically reduce the amount of design iterations required for Pareto set discovery for power systems. The process contributes significantly to design automation. A heavy-duty vertical-takeoff-landing (VTOL) unmanned aerial vehicle (UAV) power system is selected to demonstrate the efficacy and limitation of ML enabled optimization. Two extreme trials were run: 1) a search throughout the entire design space with only 9% valid designs within constraints; 2) a search throughout the valid design space. While Trial 1 was unsuccessful in discovering the Pareto front, Trial 2 uncovered all Pareto optimal designs with a 99% reduction of iterations compared to a brute force method. © 2020 IEEE.","Aviation; Design Automation; Machine Learning; Multi-Objective Optimization; Pareto Front; Power Electronics; Power System Design; UAV; VTOL","Institute of Electrical and Electronics Engineers Inc."
"Senhaji K., Ramchoun H., Ettaouil M.","Training feedforward neural network via multiobjective optimization model using non-smooth L1/2 regularization",2020,"Neurocomputing",2,"10.1016/j.neucom.2020.05.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086474667&doi=10.1016%2fj.neucom.2020.05.066&partnerID=40&md5=8560a52bdafc4cc5d55ae4068c26c8c6","The paper presents a new approach to optimize the Multilayer Perceptron Neural Network (MLPNN), to deal with the generalization problem. As known, most supervised learning algorithms aim to minimize the training error. However, the mentioned methods, based only on error minimizing, may generate a solution with an insufficient generalization performance. This present work proposes a multiobjective modelling problem involving two objectives: accuracy and complexity since the learning problem is multiobjective by nature. The learning task is carried on by minimizing both objectives simultaneously, according to Pareto domination concept, using NSGAII (Non-dominated Sorting Genetic Algorithm II) as a solver. This method leads us to a set of solutions called Pareto front, being the optimal solutions set, the adequate MLPNN need to be extracted. We show empirically that the proposed method is capable of reducing the neural networks topology and improved generalization performance, in addition to a good classification rate compared to different methods. © 2020","L1/2 regularization; Learning algorithm; Multiobjective optimization; Neural network; NSGAII","Elsevier B.V."
"Tang Z., Shen Y., Wan L., Zhou H., Yu F., Qiu D., Wang W., Cao X., Li T.","Study of over-sampling methods used in distribution transformer connectivity verification",2020,"2020 IEEE 4th Conference on Energy Internet and Energy System Integration: Connecting the Grids Towards a Low-Carbon High-Efficiency Energy System, EI2 2020",,"10.1109/EI250167.2020.9347335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101642413&doi=10.1109%2fEI250167.2020.9347335&partnerID=40&md5=1cf1b58ab787c271c1ac3d9cbb490193","Data-driven method has been used to carry out distribution transformer connectivity verification. The imbalanced dataset always results in bad performance of machine learning algorithms. In order to solve this problem, two kinds of over-sampling methods have been studied in this paper. Voltage curves of 3967 distribution transformer which belong to 197 10kV feeders have been collected. The performance of over-sampling methods under different sampling rate has also been studied. Pareto optimality has been carried out in order to obtain the best sampling rate. Results show that with the increase of sampling rate, the value of true negative (TN) increase and the value of true positive (TP) and accuracy decrease. The performance of synthetic minority over-sampling technique (SMOTE) is a little better compared with simple copy method (SCM). When the lower limits of TN, TP and accuracy are set as 0.93, the best sampling rate of SCM is 17 and the values for SMOTE are 16, 17 and 18. © 2020 IEEE.","Distribution transformer connectivity; Imbalance dataset; Over-sampling; Pareto optimality; SMOTE","Institute of Electrical and Electronics Engineers Inc."
"Saikia P., Gaurav, Rakshit D.","Designing a clean and efficient air conditioner with AI intervention to optimize energy-exergy interplay",2020,"Energy and AI",1,"10.1016/j.egyai.2020.100029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107884666&doi=10.1016%2fj.egyai.2020.100029&partnerID=40&md5=184de071dcb36ae9cc93e70d63fc26d2","Conventional refrigerants in air conditioners (A/Cs) although deliver localized comfort within dwellings, their overall detrimental impact on the environment is an alarming issue. This study investigates eco-friendly alternatives to the refrigerants R410A and R22 (which contribute to global warming and ozone depletion) through a comprehensive analysis of salient parameters such as coefficient of performance (COP), volumetric cooling capacity, and exergetic efficiency (ηex) featuring a sustainably retrofitted vapor compression based A/C. Diverse thermophysical properties of alternate refrigerants yield multiple options for contriving a sustainable A/C. Performance enhancement of the retrofitted system is then realized through a multifaceted genetic algorithm (GA) coupled with an artificial neural network (ANN). Subsequently, the incongruence of optimality between maximum system COP and maximum ηex is dealt by a dual ANN powered non dominated sorting genetic algorithm-2 (NSGA-2) optimizer which provides balanced output in terms of COP (4.37 for L20a and 4.238 for ARM71a refrigerant respectively) and ηex (26.208% for L20a and 25.413% for ARM71a refrigerant respectively). The artificial intelligence (AI) based approach helps comprehend the trade-off between different system performance indices (having different units/ranges of variation) during optimum design selection. Furthermore, the data-driven surrogate model reveals the dominating effect of energy performance over exergy performance of the system, urging for the higher priority of resource allocation for COP upgrade than ηex upgrade. Finally, the multi-objective optimization yields a broader set of Pareto optimal points which offer flexibility to the stakeholders to thrust the sustainable system towards higher COP or higher ηex mode of operation. © 2020","Artificial neural network; Energy; Exergy; Genetic algorithm; Machine learning; Refrigerant","Elsevier B.V."
"Biedermann T.M., Reich M., Paschereit C.O.","Multi-Objective Modeling of Leading-Edge Serrations Applied to Low-Pressure Axial Fans",2020,"Journal of Engineering for Gas Turbines and Power",,"10.1115/1.4048599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106006463&doi=10.1115%2f1.4048599&partnerID=40&md5=e2716a5d76158f1b910ef3ad35048bb7","A novel modeling strategy is proposed which allows high-accuracy predictions of aerodynamic and aeroacoustic target values for a low-pressure axial fan, equipped with serrated leading edges. Inspired by machine learning processes, the sampling of the experimental space is realized by use of a Latin hypercube design plus a factorial design, providing highly diverse information on the analyzed system. The effects of four influencing parameters (IP) are tested, characterizing the inflow conditions as well as the serration geometry. A total of 65 target values in the time and frequency domains are defined and can be approximated with high accuracy by individual artificial neural networks. Furthermore, the validation of the model against fully independent test points within the experimental space yields a remarkable fit, even for the spectral distribution in 1/3-octave bands, proving the ability of the model to generalize. A metaheuristic multi-objective optimization approach provides two-dimensional Pareto optimal solutions for selected pairs of target values. This is particularly important for reconciling opposing trends, such as the noise reduction capability and aerodynamic performance. The chosen optimization strategy also allows for a customized design of serrated leading edges, tailored to the specific operating conditions of the axial fan. © 2020 American Society of Mechanical Engineers (ASME). All rights reserved.",,"American Society of Mechanical Engineers (ASME)"
"Zhang L., Sato H.","Automated Test Input Generation for Convolutional Neural Networks by Implementing Multi-objective Evolutionary Algorithms",2020,"Proceedings - 2020 8th International Symposium on Computing and Networking Workshops, CANDARW 2020",1,"10.1109/CANDARW51189.2020.00040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102211137&doi=10.1109%2fCANDARW51189.2020.00040&partnerID=40&md5=1671e1120e5697f81383253e246e23c2","Deep Neural Networks (DNNs) have been widely applied in safety- and security-critical aspects, where the robustness of the system is of great significance, especially for corner case inputs. Traditionally, a DNN is tested with manually labeled data, which is not only labor-consuming, but also unable to contain statistically rare case inputs.In our work, we design, implement and evaluate the test input generation framework guided by multi-objective functions. The multi-objective functions are formed from neuron coverage, behavioral divergence and perturbation degree. We leverage evolutionary algorithms (EAs) to resolve such optimization problem by generating approximation to Pareto-optimal solutions. By implementing our framework, we successfully generated more than 6,000 test inputs for a convolutional neural network. And the generated test inputs help to improve the system's accuracy by up to 4.4%. © 2020 IEEE.","Automated test input generation; Deep learning testing; Evolutionary algorithms","Institute of Electrical and Electronics Engineers Inc."
"Lin F., Hsieh H.-P.","A goal-prioritized algorithm for additional route deployment on existing mass transportation system",2020,"Proceedings - IEEE International Conference on Data Mining, ICDM",1,"10.1109/ICDM50108.2020.00137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100893989&doi=10.1109%2fICDM50108.2020.00137&partnerID=40&md5=8c51ee18a52fda7a5c9be9bcecff36ea","Multi-criteria path planning is an important combinatorial optimization problem with broad real-world applications. Finding the Pareto-optimal set of paths ideal for all requiring features is time-consuming and unclear to obtain the subset of optimal paths efficiently for multiple origin states in the planning space. Meanwhile, due to the rise of deep learning, hybrid systems of computational intelligence thrive in recent years. When facing non-monotonic data or heuristics derived from pre-trained neural networks, most of the existing methods for the one-to-all path problem fail to find an ideal solution. We employ Gaussian mixture model to propose a target-prioritized searching algorithm called Multi-Source Bidirectional Gaussian-Prioritized Spanning Tree (BiasSpan) in solving this non-monotonic multi-criteria route planning problem given constraints including range, must-visit vertices, and the number of recommended vertices. Experimental results on mass transportation system in Tainan and Chicago cities show that BiasSpan outperforms comparative methods from 7% to 24% and runs in a reasonable time compared to state-of-art route-planning algorithms. © 2020 IEEE.","Bidirectional spanning tree; Constrained route planning; Deep Neural Network (DNN); Gaussian mixture model (GMM); Non-monotonicity","Institute of Electrical and Electronics Engineers Inc."
"Stitt G., Campbell D.","PANDORA: An Architecture-Independent Parallelizing Approximation-Discovery Framework",2020,"ACM Transactions on Embedded Computing Systems",,"10.1145/3391899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096875858&doi=10.1145%2f3391899&partnerID=40&md5=41246f651329968d5a183e56a537025c","In this article, we introduce a parallelizing approximation-discovery framework, PANDORA, for automatically discovering application- and architecture-specialized approximations of provided code. PANDORA complements existing compilers and runtime optimizers by generating approximations with a range of Pareto-optimal tradeoffs between performance and error, which enables adaptation to different inputs, different user preferences, and different runtime conditions (e.g., battery life). We demonstrate that PANDORA can create parallel approximations of inherently sequential code by discovering alternative implementations that eliminate loop-carried dependencies. For a variety of functions with loop-carried dependencies, PANDORA generates approximations that achieve speedups ranging from 2.3x to 81x, with acceptable error for many usage scenarios. We also demonstrate PANDORA's architecture-specialized approximations via FPGA experiments, and highlight PANDORA's discovery capabilities by removing loop-carried dependencies from a recurrence relation with no known closed-form solution. © 2020 ACM.","approximate computing; machine learning; Symbolic regression","Association for Computing Machinery"
"Bao G., Ye X., Zang Y., Zhou H.","Numerical solution of inverse problems by weak adversarial networks",2020,"Inverse Problems",1,"10.1088/1361-6420/abb447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096762053&doi=10.1088%2f1361-6420%2fabb447&partnerID=40&md5=07317361a0ce0ae620c0cc2209193625","In this paper, a weak adversarial network approach is developed to numerically solve a class of inverse problems, including electrical impedance tomography and dynamic electrical impedance tomography problems. The weak formulation of the partial differential equation for the given inverse problem is leveraged, where the solution and the test function are parameterized as deep neural networks. Then, the weak formulation and the boundary conditions induce a minimax problem of a saddle function of the network parameters. As the parameters are alternatively updated, the network gradually approximates the solution of the inverse problem. Theoretical justifications are provided on the convergence of the proposed algorithm. The proposed method is completely mesh-free without any spatial discretization, and is particularly suitable for problems with high dimensionality and low regularity on solutions. Numerical experiments on a variety of test inverse problems demonstrate the promising accuracy and efficiency of this approach. © 2020 IOP Publishing Ltd.","Adversarial network; Deep learning; Inverse problem; Stochastic gradient; Weak formulation","IOP Publishing Ltd"
"Fan B., He Z., Wu Y., He J., Chen Y., Jiang L.","Deep Learning Empowered Traffic Offloading in Intelligent Software Defined Cellular V2X Networks",2020,"IEEE Transactions on Vehicular Technology",3,"10.1109/TVT.2020.3023194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096323774&doi=10.1109%2fTVT.2020.3023194&partnerID=40&md5=57ed9e168007ac0e1d82446f9b751b57","The ever-increasing and unbalanced traffic load in cellular vehicle-to-everything (C-V2X) networks have increased the network congestion and led to user dissatisfaction. To relieve the network congestion and improve the traffic load balance, in this paper, we propose an intelligent software defined C-V2X network framework to enable flexible and low-complexity traffic offloading by decoupling the network data plane from the control plane. In the data plane, the cellular traffic offloading and the vehicle assisted traffic offloading are jointly performed. In the control plane, deep learning is deployed to reduce the software defined network (SDN) control complexity and improve the traffic offloading efficiency. Under the proposed framework, we investigate the traffic offloading problem, which can be formulated as a multi-objective optimization problem. Specifically, the first objective maximizes the cellular access point (AP) throughput with consideration of the load balance by associating the users with the APs. The second objective maximizes the vehicle throughput with consideration of the vehicle trajectory by associating the delay-insensitive users with the vehicles. The two objectives are coupled by the association between the cellular APs and the vehicles. A deep learning based online-offline approach is proposed to solve the multi-objective optimization problem. The online stage decouples the optimization problem into two sub-problems and utilizes the 'Pareto optimal' to find the solutions. The offline stage utilizes deep learning to learn from the historical optimization information of the online stage and helps predict the optimal solutions with reduced complexity. Numerical results are provided to validate the advantages of our proposed traffic offloading approach via deep learning in C-V2X networks. © 1967-2012 IEEE.","C-V2X networks; deep learning; software-defined-networking; traffic offloading","Institute of Electrical and Electronics Engineers Inc."
"Zhu B., Jiao J., Tse D.","Deconstructing Generative Adversarial Networks",2020,"IEEE Transactions on Information Theory",5,"10.1109/TIT.2020.2983698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094654092&doi=10.1109%2fTIT.2020.2983698&partnerID=40&md5=041083adde90ec0c127f50baaa93b38e","Generative Adversarial Networks (GANs) are a thriving unsupervised machine learning technique that has led to significant advances in various fields such as computer vision, natural language processing, among others. However, GANs are known to be difficult to train and usually suffer from mode collapse and the discriminator winning problem. To interpret the empirical observations of GANs and design better ones, we deconstruct the study of GANs into three components and make the following contributions. •Formulation: we propose a perturbation view of the population target of GANs. Building on this interpretation, we show that GANs can be connected to the robust statistics framework, and propose a novel GAN architecture, termed as Cascade GANs, to provably recover meaningful low-dimensional generator approximations when the real distribution is high-dimensional and corrupted by outliers.•Generalization: given a population target of GANs, we design a systematic principle, projection under admissible distance, to design GANs to meet the population requirement using only finite samples. We implement our principle in three cases to achieve polynomial and sometimes near-optimal sample complexities: (1) learning an arbitrary generator under an arbitrary pseudonorm; (2) learning a Gaussian location family under total variation distance, where we utilize our principle to provide a new proof for the near-optimality of the Tukey median viewed as GANs; (3) learning a low-dimensional Gaussian approximation of a high-dimensional arbitrary distribution under Wasserstein distance. We demonstrate a fundamental trade-off in the approximation error and statistical error in GANs, and demonstrate how to apply our principle in practice with only empirical samples to predict how many samples would be sufficient for GANs in order not to suffer from the discriminator winning problem.•Optimization: we demonstrate alternating gradient descent is provably not locally asymptotically stable in optimizing the GAN formulation of PCA. We found that the minimax duality gap being non-zero might be one of the causes, and propose a new GAN architecture whose duality gap is zero, where the value of the game is equal to the previous minimax value (not the maximin value). We prove the new GAN architecture is globally asymptotically stable in solving PCA under alternating gradient descent. © 1963-2012 IEEE.","generalization error; Generative Adversarial Networks (GANs); information-theoretic limit; optimal transport; robust statistics; wasserstein distance","Institute of Electrical and Electronics Engineers Inc."
"García J., Majadas R., Fernández F.","Learning adversarial attack policies through multi-objective reinforcement learning",2020,"Engineering Applications of Artificial Intelligence",6,"10.1016/j.engappai.2020.104021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092938471&doi=10.1016%2fj.engappai.2020.104021&partnerID=40&md5=4ae41c1e51220a0388a4f69d62c08f4d","Deep Reinforcement Learning has shown promising results in learning policies for complex sequential decision-making tasks. However, different adversarial attack strategies have revealed the weakness of these policies to perturbations to their observations. Most of these attacks have been built on existing adversarial example crafting techniques used to fool classifiers, where an adversarial attack is considered a success if it makes the classifier outputs any wrong class. The major drawback of these approaches when applied to decision-making tasks is that they are blind for long-term goals. In contrast, this paper suggests that it is more appropriate to view the attack process as a sequential optimization problem, with the aim of learning a sequence of attacks, where the attacker must consider the long-term effects of each attack. In this paper, we propose that such an attack policy must be learned with two objectives in view. On the one hand, the attack must pursue the maximum performance loss of the attacked policy. On the other hand, it also should minimize the cost of the attacks. Therefore, in this paper we propose a novel modelization of the process of learning an attack policy as a Multi-objective Markov Decision Process with two objectives: maximizing the performance loss of the attacked policy and minimizing the cost of the attacks. We also reveal the conflicting nature of these two objectives and use a Multi-objective Reinforcement Learning algorithm to draw the Pareto fronts for four well-known tasks: the GridWorld, the Cartpole, the Mountain car and the Breakout. © 2020 Elsevier Ltd","Adversarial reinforcement learning; Multi-objective reinforcement learning","Elsevier Ltd"
"Nguyen T.T., Nguyen N.D., Vamplew P., Nahavandi S., Dazeley R., Lim C.P.","A multi-objective deep reinforcement learning framework",2020,"Engineering Applications of Artificial Intelligence",6,"10.1016/j.engappai.2020.103915","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090039148&doi=10.1016%2fj.engappai.2020.103915&partnerID=40&md5=7d241fdd427c08a9d5535689c936ec44","This paper introduces a new scalable multi-objective deep reinforcement learning (MODRL) framework based on deep Q-networks. We develop a high-performance MODRL framework that supports both single-policy and multi-policy strategies, as well as both linear and non-linear approaches to action selection. The experimental results on two benchmark problems (two-objective deep sea treasure environment and three-objective Mountain Car problem) indicate that the proposed framework is able to find the Pareto-optimal solutions effectively. The proposed framework is generic and highly modularized, which allows the integration of different deep reinforcement learning algorithms in different complex problem domains. This therefore overcomes many disadvantages involved with standard multi-objective reinforcement learning methods in the current literature. The proposed framework acts as a testbed platform that accelerates the development of MODRL for solving increasingly complicated multi-objective problems. © 2020 Elsevier Ltd","Deep learning; Multi-objective; Multi-policy; Reinforcement learning; Single-policy","Elsevier Ltd"
"Cheng Y.-J., Hou M., Wang J.","An improved optimal trigonometric ELM algorithm for numerical solution to ruin probability of Erlang(2) risk model",2020,"Multimedia Tools and Applications",1,"10.1007/s11042-020-09382-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089449050&doi=10.1007%2fs11042-020-09382-8&partnerID=40&md5=86573a0e48f7b565723c7617cebe64ac","In this paper, we focus on accurately calculating the numerical solution of the integral-differential equation for ruin probability in Erlang(2) renewal risk model with arbitrary claim distribution. Because the analytical solutions of the equation do not usually exist, firstly, using machine learning method in modern artificial intelligence, the activation functions in the ELM model are changed to trigonometric function, the initial conditions in the integral-differential equation are added to the ELM linear solver to get the ITELM model, and the steps and feasibility of the algorithm are strictly deduced in theory. As the analytic solution for the integral-differential equation only exists when the claim is subject to exponential distribution, and the numerical solution can be gotten with the pareto distribution. And, since the number of hidden neurons in the ITELM model is uncertain, a good numerical value of hidden neurons can only be determined through a large number of iterative tests and comparisons in the actual calculation. Then, we construct a multi-objective optimization model and algorithm, which can get the optimal number of hidden neurons to obtain the IOTELM model and algorithm. Then, in the above two cases for exponential distribution and pareto distribution, the optimal number of hidden neurons is calculated by IOTELM model and algorithm, and then corresponding ITELM models and algorithms are constructed to calculate the corresponding ruin probability. Compared with the previous numerical experiments, it can be seen that the numerical accuracy is greatly improved, which verified the versatility, feasibility and superiority of the proposed IOTELM model and algorithm. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Erlang(2) risk model; IOTELM algorithm; Renewal integral-differential equation; Ruin probability","Springer"
"Haghir Chehreghani M.","Unsupervised representation learning with Minimax distance measures",2020,"Machine Learning",1,"10.1007/s10994-020-05886-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088710411&doi=10.1007%2fs10994-020-05886-4&partnerID=40&md5=bfda0051b9dc3cdd87eff9232ab595dd","We investigate the use of Minimax distances to extract in a nonparametric way the features that capture the unknown underlying patterns and structures in the data. We develop a general-purpose and computationally efficient framework to employ Minimax distances with many machine learning methods that perform on numerical data. We study both computing the pairwise Minimax distances for all pairs of objects and as well as computing the Minimax distances of all the objects to/from a fixed (test) object. We first efficiently compute the pairwise Minimax distances between the objects, using the equivalence of Minimax distances over a graph and over a minimum spanning tree constructed on that. Then, we perform an embedding of the pairwise Minimax distances into a new vector space, such that their squared Euclidean distances in the new space equal to the pairwise Minimax distances in the original space. We also study the case of having multiple pairwise Minimax matrices, instead of a single one. Thereby, we propose an embedding via first summing up the centered matrices and then performing an eigenvalue decomposition to obtain the relevant features. In the following, we study computing Minimax distances from a fixed (test) object which can be used for instance in K-nearest neighbor search. Similar to the case of all-pair pairwise Minimax distances, we develop an efficient and general-purpose algorithm that is applicable with any arbitrary base distance measure. Moreover, we investigate in detail the edges selected by the Minimax distances and thereby explore the ability of Minimax distances in detecting outlier objects. Finally, for each setting, we perform several experiments to demonstrate the effectiveness of our framework. © 2020, The Author(s).","Computational efficiency; Distance measure; Minimax distances; Representation learning","Springer"
"Yang J., Fan J., Wei Z., Li G., Liu T., Du X.","A game-based framework for crowdsourced data labeling",2020,"VLDB Journal",5,"10.1007/s00778-020-00613-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085303838&doi=10.1007%2fs00778-020-00613-w&partnerID=40&md5=758c8d6a6a42ecfc33549358a057c9fa","Data labeling, which assigns data with multiple classes, is indispensable for many applications, such as machine learning and data integration. However, existing labeling solutions either incur expensive cost for large datasets or produce noisy results. This paper introduces a cost-effective labeling approach and focuses on the labeling rule generation problem that aims to generate high-quality rules to largely reduce the labeling cost while preserving quality. To address the problem, we first generate candidate rules and then devise a game-based crowdsourcing approach CrowdGame to select high-quality rules by considering coverage and accuracy. CrowdGame employs two groups of crowd workers: One group answers rule validation tasks (whether a rule is valid) to play a role of rule generator, while the other group answers tuple checking tasks (whether the label of a data tuple is correct) to play a role of rule refuter. We let the two groups play a two-player game: Rule generator identifies high-quality rules with large coverage, while rule refuter tries to refute its opponent rule generator by checking some tuples that provide enough evidence to reject rules with low accuracy. This paper studies the challenges in CrowdGame. The first is to balance the trade-off between coverage and accuracy. We define the loss of a rule by considering the two factors. The second is rule accuracy estimation. We utilize Bayesian estimation to combine both rule validation and tuple checking tasks. The third is to select crowdsourcing tasks to fulfill the game-based framework for minimizing the loss. We introduce a minimax strategy and develop efficient task selection algorithms. We also develop a hybrid crowd-machine method for effective label assignment under budget-constrained crowdsourcing settings. We conduct experiments on entity matching and relation extraction, and the results show that our method outperforms state-of-the-art solutions. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Crowdsourcing; Data labeling; Labeling rules","Springer Science and Business Media Deutschland GmbH"
"Dutta P., Saha S., Chopra S., Miglani V.","Ensembling of Gene Clusters Utilizing Deep Learning and Protein-Protein Interaction Information",2020,"IEEE/ACM Transactions on Computational Biology and Bioinformatics",5,"10.1109/TCBB.2019.2918523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067008449&doi=10.1109%2fTCBB.2019.2918523&partnerID=40&md5=5db630a61830ee16556b9b70e2c79518","Cluster ensemble techniques aim to combine the outputs of multiple clustering algorithms to obtain a single consensus partitioning. The current paper reports about the development of a cluster ensemble based technique combining the concepts of multiobjective optimization and deep-learning models for gene clustering where some additional protein-protein interaction information are utilized for generating the consensus partitioning. The proposed ensemble based framework works in four phases: (i) filtering out the irrelevant genes from the microarray dataset: only the statistically significant genes are considered for further data analysis; (ii) generation of diverse base partitionings: a multi-objective optimization-based clustering technique is proposed which simultaneously optimizes three different cluster quality measures and generates a set of partitioning solutions on the Pareto optimal front; (iii) generation of a consensus partitioning: mentha scores, calculated by accessing a highly enriched protein-protein interaction archive named mentha, of different clustering solutions are considered for generating a weighted incidence matrix; (iv) finally, two approaches are used to generate a consensus partitioning from the obtained incidence matrix. The first approach is based on a traditional machine learning method, and another approach exploits the graph partitioning algorithm and two deep neural models to generate the final clustering. To validate the efficacy of the proposed ensemble framework, it is applied on five gene expression datasets. We present a comparative analysis of the proposed technique over different clustering algorithms in terms of biological homogeneity index (BHI) and biological stability index (BSI). The traditional approach attains an average 3 and 2 percent improvements over the best non-dominated solution with respect to BHI and BSI, respectively, whereas deep learning models illustrate an average 6.8 and 1.5 percent improvements over the proposed traditional approach with respect to BHI and BSI, respectively. Subsequently, Welch's t-test is executed to prove that the results obtained by the proposed methods are statistically significant. Availability of data and materials: https://github.com/sduttap16/DeepEnsm. © 2004-2012 IEEE.","clustering; deep learning; ensemble technique; Protein-protein interactions","Institute of Electrical and Electronics Engineers Inc."
"Marchisio A., Massa A., Mrazek V., Bussolino B., Martina M., Shafique M.","NASCaps: A Framework for Neural Architecture Search to Optimize the Accuracy and Hardware Efficiency of Convolutional Capsule Networks",2020,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",9,"10.1145/3400302.3415731","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097942672&doi=10.1145%2f3400302.3415731&partnerID=40&md5=22fe3148a9f762584b18e8456b1e75f5","Deep Neural Networks (DNNs) have made significant improvements to reach the desired accuracy to be employed in a wide variety of Machine Learning (ML) applications. Recently the Google Brain's team demonstrated the ability of Capsule Networks (CapsNets) to encode and learn spatial correlations between different input features, thereby obtaining superior learning capabilities compared to traditional (i.e., non-capsule based) DNNs. However, designing CapsNets using conventional methods is a tedious job and incurs significant training effort. Recent studies have shown that powerful methods to automatically select the best/optimal DNN model configuration for a given set of applications and a training dataset are based on the Neural Architecture Search (NAS) algorithms. Moreover, due to their extreme computational and memory requirements, DNNs are employed using the specialized hardware accelerators in IoT-Edge/CPS devices. In this paper, we propose NASCaps, an automated framework for the hardware-aware NAS of different types of DNNs, covering both traditional convolutional DNNs and CapsNets. We study the efficacy of deploying a multi-objective Genetic Algorithm (e.g., based on the NSGA-II algorithm). The proposed framework can jointly optimize the network accuracy and the corresponding hardware efficiency, expressed in terms of energy, memory, and latency of a given hardware accelerator executing the DNN inference. Besides supporting the traditional DNN layers (such as, convolutional and fully-connected), our framework is the first to model and supports the specialized capsule layers and dynamic routing in the NAS-flow. We evaluate our framework on different datasets, generating different network configurations, and demonstrate the tradeoffs between the different output metrics. We will open-source the complete framework and configurations of the Pareto-optimal architectures at https://github.com/ehw-fit/nascaps. © 2020 Association on Computer Machinery.","Accuracy; Capsule Networks; Deep Neural Networks; Design Space; DNNs; Energy Efficiency; Evolutionary Algorithms; Genetic Algorithms; Hardware Accelerators; Latency; Memory; Multi-Objective; Neural Architecture Search; Optimization","Institute of Electrical and Electronics Engineers Inc."
"Yang S., Meng Y., Meng X.","Image Transfer Applied in Electric Machine Optimization",2020,"2020 IEEE 61st Annual International Scientific Conference on Power and Electrical Engineering of Riga Technical University, RTUCON 2020 - Proceedings",,"10.1109/RTUCON51174.2020.9316579","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100043891&doi=10.1109%2fRTUCON51174.2020.9316579&partnerID=40&md5=0ee75a755126f50e0409cc830f940f74","Researches have been conducted on the surrogate-modeling for better trade-off between solution accuracy and solving effort in design space exploration. In this paper, a robust method combining the deep-learning technique, image-transfer, with finite-element-modeling (FEM) in the electric machine optimization to accelerate the convergence is proposed. Specifically, a conditional generative-adversarial network is built to learn from the FEM simulated data about the relationship between the geometric drawing input and magnetic field plot output. The learned model can obtain the result 24x faster than finite-element modeling while maintaining the accuracy. This approximation model is then applied as the sample filter prior to the FEM in the genetic-algorithm powered optimization framework. The test done on a V-shape magnet motor optimization shows that closely matched Pareto-frontier can be found by this approach while the computing time is reduced by >50% at beginning stage for acceleration. © 2020 IEEE.","Design optimization; Permanent magnet machines; Statistical learning","Institute of Electrical and Electronics Engineers Inc."
"Abbasi H.R., Sharifi Sedeh E., Pourrahmani H., Mohammadi M.H.","Shape optimization of segmental porous baffles for enhanced thermo-hydraulic performance of shell-and-tube heat exchanger",2020,"Applied Thermal Engineering",21,"10.1016/j.applthermaleng.2020.115835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089418233&doi=10.1016%2fj.applthermaleng.2020.115835&partnerID=40&md5=581158ae26154b0ea6506195f4750018","This study presents the development and evaluation of a novel shell-and-tube heat exchanger (STHX) design with segmental porous baffles. Computational fluid dynamics (CFD) in combination with machine learning tools are utilized to investigate the thermo-hydraulic impacts of segmental porous baffles on shell side flow of a STHX. Three geometric parameters (number of baffles, baffle angle, and baffle thickness) of these baffles, which are placed inside the STHX, are selected to perform the parametric study and multi-objective optimization. Higher number of baffles are beneficial to increase the rate of heat exchange; however, it would escalate the pressure drop considerably. Results also show that baffles angle plays a critical role on the performance of a STHX. An artificial neural network (ANN) is trained to predict the system's performance. As lowering the pressure drop and increasing the heat transfer are the two main objectives in STHX, a multi-objective optimization study is conducted. Different decision-making algorithms are also applied to find the best alternative among the Pareto frontier points. Results of optimization show that a STHX with 10 porous baffles, baffle angle of 111.9, and baffle thickness of 16.69 mm would be the best geometrical configuration which results in a heat transfer rate of 523.81 kW while the pressure drop of the shell side flow would be 48.87 kPa. With this novel design, it is also possible to improve both pressure drop and heat transfer rate of STHX, simultaneously. A particular configuration of the introduced STHX could reduce the pressure drop by 61.3% while heat transfer enhances by 11.15% simultaneously. © 2020 Elsevier Ltd","Artificial neural networks (ANN); Genetic algorithm (GA); Heat transfer enhancement; Porous baffles; Shell and tube heat exchanger (STHX)","Elsevier Ltd"
"Liu T., Liu L., Cui F., Ding F., Zhang Q., Li Y.","Predicting the performance of polyvinylidene fluoride, polyethersulfone and polysulfone filtration membranes using machine learning",2020,"Journal of Materials Chemistry A",6,"10.1039/d0ta07607d","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094893204&doi=10.1039%2fd0ta07607d&partnerID=40&md5=2d90ed986acfaa80091adf727cc2bfe4","Micro/ultra/nano-filtration membranes based on polyvinylidene fluoride, polyethersulfone and polysulfone are advancing steadily in laboratory research and scalable production. Variables associated with the composition, fabrication, and operation are highly diverse, and their quantitative correlations with the core performance in permeability, selectivity and their trade-off are still elusive. To predict the performance based on a comprehensive dataset with 1895 vectors, the coefficient of determination spans from 0.79 to 0.85 for regression models, and the area under the receiver operating characteristic curve (AUC) reaches from 0.94 to 0.97 for classification models to distinguish the top 20% (Pareto set) and top 50% (balanced set) membranes with superior performance in the separation of macromolecules and salts from water. Further including experimental structural information (porosity, thickness, surface contact angle and roughness) brings significant improvement for regression models, while filling with predicted values only shows marginal improvement. A standalone algorithm that integrated the predictive models was released at https://github.com/polySML/polySML to facilitate the development of advanced filtration membranes through virtual experiments. This journal is © The Royal Society of Chemistry.",,"Royal Society of Chemistry"
"Zhang J., Huang Y., Aslani F., Ma G., Nener B.","A hybrid intelligent system for designing optimal proportions of recycled aggregate concrete",2020,"Journal of Cleaner Production",26,"10.1016/j.jclepro.2020.122922","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088382955&doi=10.1016%2fj.jclepro.2020.122922&partnerID=40&md5=518cace36d3ca77d6d0505d77a5ec12a","The replacement of natural coarse aggregate (NCA) with recycled coarse aggregate (RCA) in concrete mixtures offers various advantages, including conservation of natural resources, reduction of CO2 emissions, and cost reduction. However, multiple related variables and objectives (e.g., mechanical, economic, and environmental objectives) need to be considered when optimizing mixtures of recycled aggregate concrete (RAC). This cannot be achieved through traditional laboratory- or statistics-based methods. This study proposes a hybrid intelligent system based on artificial intelligence (AI) and metaheuristic algorithms for designing optimal mixtures of RAC. To verify the proposed model, a data set containing 344 different RAC mixtures was collected from previous literature. A semi-supervised cotraining algorithm using two k-nearest neighbor (kNN) regressors with different distance metrics is developed to label the unlabeled data in the collected dataset. Different AI models are incorporated into the system for modeling the relationship between RAC strength and its influencing variables. A multi-objective optimization (MOO) model based on AI algorithms and on a multi-objective firefly algorithm is used to search for optimal mixtures of RAC. The results show that kNN-based semi-supervised cotraining can effectively exploit unlabeled data to improve the regression estimates. In the test set, A Random Forest and Backpropagation Neural Network achieve the best prediction accuracy for predicting, respectively, uniaxial compressive strength and splitting tensile strength of RAC, indicated by the highest correlation coefficients (0.9064 and 0.8387, respectively) and lowest root-mean-square errors (6.639 MPa and 0.5119 MPa, respectively). The Pareto fronts of the multi-objective mixture optimization problem are successfully obtained by the MOO model. The proposed system can also be used to optimize mixture proportions of other cementitious materials in civil engineering. © 2020 Elsevier Ltd","Artificial intelligence; Concrete mixture optimization; Firefly algorithm; Mechanical properties; Recycled aggregate concrete","Elsevier Ltd"
"Kwon J., Carloni L.P.","Transfer learning for design-space exploration with high-level synthesis",2020,"MLCAD 2020 - Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD",4,"10.1145/3380446.3430636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098244621&doi=10.1145%2f3380446.3430636&partnerID=40&md5=d546ac941cdf07edcd949769fad70867","High-level synthesis (HLS) raises the level of design abstraction, expedites the process of hardware design, and enriches the set of final designs by automatically translating a behavioral specification into a hardware implementation. To obtain different implementations, HLS users can apply a variety of knobs, such as loop unrolling or function inlining, to particular code regions of the specification. The applied knob configuration significantly affects the synthesized design's performance and cost, e.g., application latency and area utilization. Hence, HLS users face the design-space exploration (DSE) problem, i.e. determine which knob configurations result in Pareto-optimal implementations in this multi-objective space. Whereas it can be costly in time and resources to run HLS flows with an enormous number of knob configurations, machine learning approaches can be employed to predict the performance and cost. Still, they require a sufficient number of sample HLS runs. To enhance the training performance and reduce the sample complexity, we propose a transfer learning approach that reuses the knowledge obtained from previously explored design spaces in exploring a new target design space. We develop a novel neural network model for mixed-sharing multi-domain transfer learning. Experimental results demonstrate that the proposed model outperforms both single-domain and hard-sharing models in predicting the performance and cost at early stages of HLS-driven DSE. © 2020 Association for Computing Machinery.","Design space exploration; High-level synthesis; Machine learning; Multi-task learning; Neural networks; Transfer learning","Association for Computing Machinery, Inc"
"Huai Z., Wang H., Gong M.","A novel algorithm to keep the formation for multiple vehicles based on NSGA and DCNN",2020,"Proceedings of 2020 3rd International Conference on Unmanned Systems, ICUS 2020",,"10.1109/ICUS50048.2020.9275022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098959954&doi=10.1109%2fICUS50048.2020.9275022&partnerID=40&md5=4b3f7b21219b6ee88d6a7bb15319649d","To address the problem of keeping the formation for multiple vehicles, this paper proposes a novel algorithm based on non-dominated sorting genetic algorithm II (NSGA- II) and deep convolutional neural network(DCNN). Firstly, the problem of keeping the formation for multiple vehicles is translated into three objective functions. Secondly, NSGA- II is used to optimize and a strategy is designed to choose the guidance command from Pareto solution set. Thirdly, in order to improve the calculation speed, a 19-layer deep learning model is built based on DCNN, residual network and batch normalization layer, then a correction part is designed to avoid the phenomenon that the accumulation of generalization error will brings obvious error on keeping the formation. Finally, three sets of simulation demonstrate the effectiveness of this algorithm. © 2020 IEEE.","Deep convolutional neural network; Keeping the formation; Multiple vehicles; Nondominated sorting genetic","Institute of Electrical and Electronics Engineers Inc."
"Hu M., Liu L., Wang W., Liu Y.","APENAS: An asynchronous parallel evolution based multi-objective neural architecture search",2020,"Proceedings - 2020 IEEE International Symposium on Parallel and Distributed Processing with Applications, 2020 IEEE International Conference on Big Data and Cloud Computing, 2020 IEEE International Symposium on Social Computing and Networking and 2020 IEEE International Conference on Sustainable Computing and Communications, ISPA-BDCloud-SocialCom-SustainCom 2020",1,"10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108023880&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom51426.2020.00045&partnerID=40&md5=83e3ae38aaa355424b2e76326eb000e7","Machine learning is widely used in pattern classification, image processing and speech recognition. Neural architecture search (NAS) could reduce the dependence of human experts on machine learning effectively. Due to the high complexity of NAS, the tradeoff between time consumption and classification accuracy is vital. This paper presents APENAS, an asynchronous parallel evolution based multi-objective neural architecture search, using the classification accuracy and the number of parameters as objectives, encoding the network architectures as individuals. To make full use of computing resource, we propose a multi-generation undifferentiated fusion scheme to achieve asynchronous parallel evolution on multiple GPUs or CPUs, which speeds up the process of NAS. Accordingly, we propose an election pool and a buffer pool for two-layer filtration of individuals. The individuals are sorted in the election pool by non-dominated sorting and filtered in the buffer pool by the roulette algorithm to improve the elitism of the Pareto front. APENAS is evaluated on the CIFAR-10 and CIFAR-100 datasets [25]. The experimental results demonstrate that APENAS achieves 90.05% accuracy on CIFAR-10 with only 0.07 million parameters, which is comparable to state of the art. Especially, APENAS has high parallel scalability, achieving 92.5% parallel efficiency on 64 nodes. © 2020 IEEE.","Asynchronous parallel evolution; Automated machine learning; Multi-objective; Neural architecture search","Institute of Electrical and Electronics Engineers Inc."
"Papagiannis T., Alexandridis G., Stafylopatis A.","Applying Gradient Boosting Trees and Stochastic Leaf Evaluation to MCTS on Hearthstone",2020,"Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",,"10.1109/ICMLA51294.2020.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102507728&doi=10.1109%2fICMLA51294.2020.00034&partnerID=40&md5=6c067fee2315aa52be20c44cb0084e4e","Collectible card games are an interesting testing ground for artificial intelligence algorithms, mainly because of their stochasticity and high branching factor. In this work, the performance of a monte carlo tree search-based agent, enhanced with a gradient boosting tree classifier on the simulation phase, is investigated on Hearthstone. Furthermore, the impact of the combination of random simulations and the classifier's predictions is studied, as well as its correlation with the action space and the tree's depth. The aforementioned approach has been implemented in the Metastone framework and has been tested against the vanilla approach and the state-of-the-art algorithm, both provided by the framework itself. Over a set of evaluation games, it is demonstrated that the examined methodology significantly outperforms the vanilla-MCTS and is even matched with the heuristic-driven minimax algorithm. © 2020 IEEE.","Gradient Boosting Trees; Hearthstone; Metastone; Monte Carlo Tree Search; Stochastic Leaf Evaluation","Institute of Electrical and Electronics Engineers Inc."
"Hashima S., Hatano K., Mohamed E.M.","Multiagent Multi-Armed Bandit Schemes for Gateway Selection in UAV Networks",2020,"2020 IEEE Globecom Workshops, GC Wkshps 2020 - Proceedings",3,"10.1109/GCWkshps50303.2020.9367568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100001389&doi=10.1109%2fGCWkshps50303.2020.9367568&partnerID=40&md5=32cf7faadd3c94831aa9e70063f7337f","Lately, unmanned aerial vehicles (UAVs) communications acquired great attention because of its weighty new applications, particularly in rescue services. In such a case, access and gateway UAVS are spread to cover and fully support communications over disaster areas where the ground network is malfunctioned or wholly damaged. Each access UAV collects essential information from its assigned area, then flies and transfers it to the nearby gateway UAVs that deliver this collected information to the closest operating ground network. Meanwhile, collisions may occur as two or more access UAVs might target the same gateway UAV. This paper leverages and modifies two multi-armed bandit (MAB) based algorithms, namely, Kullback Leibler upper confidence bound (KLUCB) and minimax optimal stochastic strategy (MOSS) to formulate the gateway UAV selection issue. The issue is modeled as a budget-constrained multiagent MAB (MA-MAB) that maximizes data rates while considering access UAVs' flight battery consumption. Hence, MA battery aware KLUCB (MABA-KLUCB) and battery aware MOSS (MA-BA-MOSS) algorithms are proposed for efficient gateway UAV selection. The proposed MAB algorithms maximize the UAV network's total sum rate over the conventional selection techniques with assuring good convergence performance. © 2020 IEEE.","Gateway UAV selection; KLUCB; Machine learning; MOSS; Multiagent MAB; UAV","Institute of Electrical and Electronics Engineers Inc."
"Yi C., Li H., Wan R., Kot A.C.","Improving Robustness of DNNs against Common Corruptions via Gaussian Adversarial Training",2020,"2020 IEEE International Conference on Visual Communications and Image Processing, VCIP 2020",2,"10.1109/VCIP49819.2020.9301856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099485333&doi=10.1109%2fVCIP49819.2020.9301856&partnerID=40&md5=389dc9f53b05bc305712aa4d7d2388b6","Deep neural networks have demonstrated tremendous success in image classification, but their performance sharply degrades when evaluated on slightly different test data (e.g., data with corruptions). To address these issues, we propose a minimax approach to improve common corruption robustness of deep neural networks via Gaussian Adversarial Training. To be specific, we propose to train neural networks with adversarial examples where the perturbations are Gaussian-distributed. Our experiments show that our proposed GAT can improve neural networks' robustness to noise corruptions more than other baseline methods. It also outperforms the state-of-the-art method in improving the overall robustness to common corruptions. © 2020 IEEE.","Adversarial Training; Data Augmentation; Deep Learning; Robustness to Common Corruptions","Institute of Electrical and Electronics Engineers Inc."
"Li C.T., Wu X., Ozgur A., El Gamal A.","Minimax Learning for Distributed Inference",2020,"IEEE Transactions on Information Theory",1,"10.1109/TIT.2020.3029182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097409587&doi=10.1109%2fTIT.2020.3029182&partnerID=40&md5=1961bb0e76af07bbd9ca394537f85689","The classical problem of supervised learning is to infer an accurate estimate of a target variable $Y$ from a measured variable $X$ using a set of labeled training samples. Motivated by the increasingly distributed nature of data and decision making, this paper considers a variation of this classical problem in which the inference is distributed between two nodes, e.g., a mobile device and a cloud, with a rate constraint on the communication between them. The mobile device observes $X$ and sends a description $M$ of $X$ to the cloud, which computes an estimate $\hat {Y}$ of $Y$. We follow the recent minimax learning approach to study this inference problem and show that it corresponds to a one-shot minimax noisy lossy source coding problem. We then establish information theoretic bounds on the risk-rate Lagrangian cost, leading to a general method for designing a near-optimal descriptor-estimator pair. A key ingredient in the proof of our result is a refined version of the strong functional representation lemma previously used to establish several one-shot source coding theorems. Our results show that a naive estimate-compress scheme for rate-constrained inference is not optimal in general. When the distribution of $(X,Y)$ is known and the error is measured by the logarithmic loss, our bounds on the risk-rate Lagrangian cost provide a new one-shot operational interpretation of the information bottleneck. We also demonstrate a way to bound the excess risk of the descriptor-estimator pair obtained by our method. © 1963-2012 IEEE.","distributionally robust learning; functional representation; information bottleneck; Minimax learning; one-shot source coding","Institute of Electrical and Electronics Engineers Inc."
"Jensen P.J., Zhang J., Wu Q.J.","Technical note: Interpolated Pareto surface similarity metrics for multi-criteria optimization in radiation therapy",2020,"Medical Physics",1,"10.1002/mp.14541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096722747&doi=10.1002%2fmp.14541&partnerID=40&md5=ea088e06fae1ceec217e9c260e077146","Purpose: There is a strong clinical need to evaluate different multi-criteria optimization (MCO) algorithms, including inverse optimization sampling algorithms and machine learning-based predictions. This study aims to develop and compare several interpolated Pareto surface similarity metrics. Materials and methods: The first metric is the root-mean-square error (RMSE) evaluated between vertices on the interpolated surfaces, augmented by intra-simplex sampling of the barycentric coordinates of the surfaces’ simplicial complexes. The second metric is the average projected distance (APD), which evaluates the displacements between the vertices and computes their projections along the mean displacement. The third metric is the average nearest-point distance (ANPD), which numerically integrates point-to-simplex distances over the sampled simplices of the interpolated surfaces. These metrics were compared by their convergence rates, the times required to achieve convergence, and their representation of the underlying surface interpolations. For analysis, several interpolated Pareto surface pairs were constructed abstractly, with one pair from a nasopharyngeal treatment planning case using MCO. Results: Convergence within 1% is typically achieved at approximately 50 and 80 samples per barycentric dimension for the RMSE and the ANPD, respectively. Calculation requires approximately 1 and 10 ms to achieve convergence for the RMSE and the ANPD in two dimensions, respectively, while the APD always requires < 1 ms. These time costs are much higher in higher dimensions for just the RMSE and ANPD. The APD values more closely approximated the ANPD limits than the RMSE limits. Conclusion: The ANPD’s formulation and generality make it likely more meaningful than the RMSE and APD for representing the similarity between the underlying interpolated surfaces rather than the sampling points on the surfaces. However, in situations requiring high-speed evaluations, the APD may be more desirable due to its speed, independence from a subjectively chosen sampling rate, and similarity to the ANPD limits. © 2020 American Association of Physicists in Medicine","artificial intelligence; machine learning; multi-criteria optimization; Pareto surface; radiation therapy","John Wiley and Sons Ltd"
"Cui F., Salih S.Q., Choubin B., Bhagat S.K., Samui P., Yaseen Z.M.","Newly explored machine learning model for river flow time series forecasting at Mary River, Australia",2020,"Environmental Monitoring and Assessment",6,"10.1007/s10661-020-08724-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095931764&doi=10.1007%2fs10661-020-08724-1&partnerID=40&md5=0098f4ef93078a1610a8f08f65a8f1dd","Hourly river flow pattern monitoring and simulation is the indispensable precautionary task for river engineering sustainability, water resource management, flood risk mitigation, and impact reduction. Reliable river flow forecasting is highly emphasized to support major decision-makers. This research paper adopts a new implementation approach for the application of a river flow prediction model for hourly prediction of the flow of Mary River in Australia; a novel data-intelligent model called emotional neural network (ENN) was used for this purpose. A historical dataset measured over a 4-year period (2011–2014) at hourly timescale was used in building the ENN-based predictive model. The results of the ENN model were validated against the existing approaches such as the minimax probability machine regression (MPMR), relevance vector machine (RVM), and multivariate adaptive regression splines (MARS) models. The developed models are evaluated against each other for validation purposes. Various numerical and graphical performance evaluators are conducted to assess the predictability of the proposed ENN and the competitive benchmark models. The ENN model, used as an objective simulation tool, revealed an outstanding performance when applied for hourly river flow prediction in comparison with the other benchmark models. However, the order of the model, performance wise, is ENN > MARS > RVM > MPMR. In general, the present results of the proposed ENN model reveal a promising modeling strategy for the hourly simulation of river flow, and such a model can be explored further for its ability to contribute to the state-of-the-art of river engineering and water resources monitoring and future prediction at near real-time forecast horizons. © 2020, Springer Nature Switzerland AG.","River flow monitoring; Water resources management; Emotional neural network; Machine learning","Springer Science and Business Media Deutschland GmbH"
"Wang Y., Iyer A., Chen W., Rondinelli J.M.","Featureless adaptive optimization accelerates functional electronic materials design",2020,"Applied Physics Reviews",7,"10.1063/5.0018811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095864743&doi=10.1063%2f5.0018811&partnerID=40&md5=da7fa359165512fdea97136e9ec0ebdc","Electronic materials that exhibit phase transitions between metastable states (e.g., metal-insulator transition materials with abrupt electrical resistivity transformations) are challenging to decode. For these materials, conventional machine learning methods display limited predictive capability due to data scarcity and the absence of features that impede model training. In this article, we demonstrate a discovery strategy based on multi-objective Bayesian optimization to directly circumvent these bottlenecks by utilizing latent variable Gaussian processes combined with high-fidelity electronic structure calculations for validation in the chalcogenide lacunar spinel family. We directly and simultaneously learn phase stability and bandgap tunability from chemical composition alone to efficiently discover all superior compositions on the design Pareto front. Previously unidentified electronic transitions also emerge from our featureless adaptive optimization engine. Our methodology readily generalizes to optimization of multiple properties, enabling co-design of complex multifunctional materials, especially where prior data is sparse. © 2020 Author(s).",,"American Institute of Physics Inc."
"Banerjee T., Dey S., Sekhar A.P., Datta S., Das D.","Design of Alumina Reinforced Aluminium Alloy Composites with Improved Tribo-Mechanical Properties: A Machine Learning Approach",2020,"Transactions of the Indian Institute of Metals",4,"10.1007/s12666-020-02108-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094655387&doi=10.1007%2fs12666-020-02108-2&partnerID=40&md5=1370d322b692bfdbaf4068db58e5364b","Artificial intelligence approach for data-driven design is employed to design an alumina reinforced aluminium matrix composite (AMC) with improved tribo-mechanical properties. Machine learning tool, viz. Artificial neural network (ANN), is used as a tool to create a set of models describing the properties of the AMC. The database required for the ANN modelling was extracted from published literature. The objective functions to search the optimum combinations of composition, size and morphological properties were provided from those ANN models. Since the objectives are conflicting in nature, a multi-objective optimization is introduced using genetic algorithm as a tool and the achieved Pareto solutions are used for designing the composite with tailored properties. © 2020, The Indian Institute of Metals - IIM.","Alumina; Aluminium; Artificial neural network; Genetic algorithm; Mechanical behavior; Metal matrix composite; Multi-objective optimization; Pareto front; Wear","Springer"
"Garciarena U., Mendiburu A., Santana R.","Analysis of the transferability and robustness of GANs evolved for Pareto set approximations",2020,"Neural Networks",3,"10.1016/j.neunet.2020.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091227145&doi=10.1016%2fj.neunet.2020.09.003&partnerID=40&md5=2932d312536be44df165f2d363523fea","The generative adversarial network (GAN) is a good example of a strong-performing, neural network-based generative model, even though it does have some drawbacks of its own. Mode collapsing and the difficulty in finding the optimal network structure are two of the most concerning issues. In this paper, we address these two issues at the same time by proposing a neuro-evolutionary approach with an agile evaluation method for the fast evolution of robust deep architectures that avoid mode collapsing. The computation of Pareto set approximations with GANs is chosen as a suitable benchmark to evaluate the quality of our approach. Furthermore, we demonstrate the consistency, scalability, and generalization capabilities of the proposed method, which shows its potential applications to many areas. We finally readdress the issue of designing this kind of models by analyzing the characteristics of the best performing GAN specifications, and conclude with a set of general guidelines. This results in a reduction of the many-dimensional problem of structural manual design or automated search. © 2020 Elsevier Ltd","Generative adversarial networks; Knowledge transferability; Multi-objective optimization; Neuro-evolution; Pareto front approximation","Elsevier Ltd"
"Kaur A., Kumar K.","A Reinforcement Learning based evolutionary multi-objective optimization algorithm for spectrum allocation in Cognitive Radio networks",2020,"Physical Communication",5,"10.1016/j.phycom.2020.101196","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090359261&doi=10.1016%2fj.phycom.2020.101196&partnerID=40&md5=09e435bee966837fec33fdf528e69d3d","To cope up with drastically increasing demand for radio resources lead to raise a challenge to the wireless community. The limited radio spectrum and fixed spectrum allocation strategy have become a bottleneck for various wireless communication. Cognitive Radio (CR) technology along with potential benefits of machine learning has attracted substantial research interest especially in the context of spectrum management. However, a variety of performance attributes as objectives draw attention during the technological preparations for spectrum management such as higher spectral efficiency, lower latency, higher network capacity, and better energy efficiency as these objectives are often conflicting with each other. Hence, this paper addresses the spectrum allocation problem concerning network capacity and spectrum efficiency as conflicting objectives and model the scenario as a multi-objective optimization problem in CR networks. An improved version of the Non-dominated Sorting Genetic Algorithm-II (NSGA-II) which combines the feature of evolutionary algorithm and machine learning called Non-dominated Sorting Genetic Algorithm based on Reinforcement Learning (NSGA-RL) is proposed which incorporates a self-tuning parameter approach to handle multiple conflicting objectives. The numerical findings validate the effectiveness of the proposed algorithm through the Pareto optimal set and obtain optimal solution efficiently to satisfy various requirements of spectrum allocation in CR networks. © 2020 Elsevier B.V.","Cognitive Radio (CR) networks; Multi-objective optimization; NSGA-II; NSGA-RL; Reinforcement learning; Spectrum allocation","Elsevier B.V."
"You J., Ampomah W., Sun Q.","Co-optimizing water-alternating-carbon dioxide injection projects using a machine learning assisted computational framework",2020,"Applied Energy",4,"10.1016/j.apenergy.2020.115695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090196560&doi=10.1016%2fj.apenergy.2020.115695&partnerID=40&md5=41a4bd8d616ab343710560b6140cccbf","In this article, a robust machine-learning-based computational framework that couples multi-layer neural network (MLNN) proxies and a multi-objective particle swarm optimizer (MOPSO) to design water-alternating-carbon dioxide injection (CO2-WAG) projects is presented. The proposed optimization protocol considers various objectives, including oil recovery and CO2 storage volume. Expert MLNN systems are trained and employed as surrogate models of the high-fidelity compositional simulator in the optimization workflow. When multiple objective functions are considered, two approaches are employed to treat the objectives: the weighted sum method and the Pareto-front-based scheme. A field-scale implementation focusing on tertiary recovery in the Morrow B formation at Farnsworth Unit (FWU) is presented. The developed Pareto-optimal solutions indicate the maximal available oil production can be 1.64 × 107 barrels and maximal carbon storage can achieve 2.35 × 107 tons. Trade-offs factor is defined to divide the constructed Pareto front into 4 sections with the trade-off factors’ value ranges from 0.35 to 49.9. This work also compares the optimum solution found by the aggregative objective function and the solution repository covered by the Pareto front that considers the physical and operational constraints and reduces uncertainties involved by the multi-objective optimization process. Our comparison indicates multiple solutions exist to satisfy the objective criteria of the WAG design, and these results cannot be found using the traditional weighted sum method. The Pareto front solution can provide more options for project designers, but decisions regarding necessary trade-offs must be made using the solution repository to balance the project economics and CO2 storage amount. © 2020 Elsevier Ltd","Artificial neural network; Carbon dioxide sequestration; CO2-EOR; Multi-objective optimization","Elsevier Ltd"
"Zhang H., Li S.-J., Zhang H., Yang Z.-Y., Ren Y.-Q., Xia L.-Y., Liang Y.","Meta-Analysis Based on Nonconvex Regularization",2020,"Scientific Reports",1,"10.1038/s41598-020-62473-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082979377&doi=10.1038%2fs41598-020-62473-2&partnerID=40&md5=a501a5817158cca695b8d38bc9f61ba9","The widespread applications of high-throughput sequencing technology have produced a large number of publicly available gene expression datasets. However, due to the gene expression datasets have the characteristics of small sample size, high dimensionality and high noise, the application of biostatistics and machine learning methods to analyze gene expression data is a challenging task, such as the low reproducibility of important biomarkers in different studies. Meta-analysis is an effective approach to deal with these problems, but the current methods have some limitations. In this paper, we propose the meta-analysis based on three nonconvex regularization methods, which are L1/2 regularization (meta-Half), Minimax Concave Penalty regularization (meta-MCP) and Smoothly Clipped Absolute Deviation regularization (meta-SCAD). The three nonconvex regularization methods are effective approaches for variable selection developed in recent years. Through the hierarchical decomposition of coefficients, our methods not only maintain the flexibility of variable selection and improve the efficiency of selecting important biomarkers, but also summarize and synthesize scientific evidence from multiple studies to consider the relationship between different datasets. We give the efficient algorithms and the theoretical property for our methods. Furthermore, we apply our methods to the simulation data and three publicly available lung cancer gene expression datasets, and compare the performance with state-of-the-art methods. Our methods have good performance in simulation studies, and the analysis results on the three publicly available lung cancer gene expression datasets are clinically meaningful. Our methods can also be extended to other areas where datasets are heterogeneous. © 2020, The Author(s).",,"Nature Research"
"Dao D.-N., Guo L.-X.","New hybrid between SPEA/R with deep neural network: Application to predicting the multi-objective optimization of the stiffness parameter for powertrain mount systems",2020,"Journal of Low Frequency Noise Vibration and Active Control",1,"10.1177/1461348419868322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071941137&doi=10.1177%2f1461348419868322&partnerID=40&md5=2dae8af4cecc05cda36c5ac84b7dda45","In this study, a new methodology, hybrid Strength Pareto Evolutionary Algorithm Reference Direction (SPEA/R) with Deep Neural Network (HDNN&SPEA/R), has been developed to achieve cost optimization of stiffness parameter for powertrain mount systems. This problem is formalized as a multi-objective optimization problem involving six optimization objectives: mean square acceleration of a rear engine mount, mean square displacement of a rear engine mount, mean square acceleration of a front left engine mount, mean square displacement of a front left engine mount, mean square acceleration of a front right engine mount, and mean square displacement of a front right engine mount. A hybrid HDNN&SPEA/R is proposed with the integration of genetic algorithm, deep neural network, and a Strength Pareto evolutionary algorithm based on reference direction for multi-objective SPEA/R. Several benchmark functions are tested, and results reveal that the HDNN&SPEA/R is more efficient than the typical deep neural network. stiffness parameter for powertrain mount systems optimization with HDNN&SPEA/R is simulated, respectively. It proved the potential of the HDNN&SPEA/R for stiffness parameter for powertrain mount systems optimization problem. © The Author(s) 2019.","extreme learning machine; feed-forward artificial neural network; mounting system; multi-objective evolutionary algorithms; powertrain mount system stiffness; SPEA/R algorithm","SAGE Publications Inc."
"Singh D., Singh B.","Investigating the impact of data normalization on classification performance",2020,"Applied Soft Computing",130,"10.1016/j.asoc.2019.105524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066309707&doi=10.1016%2fj.asoc.2019.105524&partnerID=40&md5=aa2cd67a356ff4ad3fa63bdcc8c49d98","Data normalization is one of the pre-processing approaches where the data is either scaled or transformed to make an equal contribution of each feature. The success of machine learning algorithms depends upon the quality of the data to obtain a generalized predictive model of the classification problem. The importance of data normalization for improving data quality and subsequently the performance of machine learning algorithms has been presented in many studies. But, the work lacks for the feature selection and feature weighting approaches, a current research trend in machine learning for improving performance. Therefore, this study aims to investigate the impact of fourteen data normalization methods on classification performance considering full feature set, feature selection, and feature weighting. In this paper, we also present a modified Ant Lion optimization that search feature subsets and the best feature weights along with the parameter of Nearest Neighbor Classifier. Experiments are performed on 21 publicly available real and synthetic datasets, and results are analyzed based on the accuracy, the percentage of feature reduced and runtime. It has been observed from the results that no single method outperforms others. Therefore, we have suggested a set of the best and the worst methods combining the normalization procedure and empirical analysis of results. The better performers are z-Score and Pareto Scaling for the full feature set and feature selection, and tanh and its variant for feature weighting. The worst performers are Mean Centered, Variable Stability Scaling and Median and Median Absolute Deviation methods along with un-normalized data. © 2019","Ant lion optimization; Data normalization; Feature selection; Feature weighting; k-NN classifier","Elsevier Ltd"
"Tan B., Li Y., Zhao H., Li X., Ding S.","A novel dictionary learning method for sparse representation with nonconvex regularizations",2020,"Neurocomputing",1,"10.1016/j.neucom.2020.07.085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089522735&doi=10.1016%2fj.neucom.2020.07.085&partnerID=40&md5=1ea2118f818dd989c0e6e4daa7bbb261","In dictionary learning, sparse regularization is used to promote sparsity and has played a major role in the developing of dictionary learning algorithms. ℓ1-norm is of the most popular sparse regularization due to its convexity and the related tractable convex optimization problems. However, ℓ1-norm leads to biased solutions and provides inferior performance on certain applications compared with nonconvex sparse regularizations. In this work, we propose a generalized minimax-concave (GMC) sparse regularization, which is nonconvex, to promote sparsity to design dictionary learning model. Applying the alternate optimization scheme, we use the forward–backward splitting (FBS) algorithm to solve the sparse coding problem. As the improvement, we incorporate Nesterov's acceleration technique and adaptive threshold scheme into the FBS algorithm to improve the convergence efficiency and performance. In the dictionary update step, we apply the difference of convex functions (DC) programming and the DC algorithm (DCA) to address the dictionary update. Two dictionary update algorithms are designed; one updates the dictionary atoms one by one, and the other one updates the dictionary atoms simultaneously. The presented dictionary learning algorithms perform robustly in dictionary recovery. Numerical experiments are designed to verify the performance of proposed algorithms and to compare with the state-of-the-art algorithms. © 2020","DC programming and DCA; Dictionary learning; Forward-backward splitting algorithm; GMC regularization; Nonconvex","Elsevier B.V."
"Fu H., Cheng W., Qin Y.","Exploration of data-driven methods for multiphysics electromagnetic partial differential equations",2020,"2020 IEEE MTT-S International Conference on Numerical Electromagnetic and Multiphysics Modeling and Optimization, NEMO 2020",1,"10.1109/NEMO49486.2020.9343645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101188824&doi=10.1109%2fNEMO49486.2020.9343645&partnerID=40&md5=d3069969c0e3cf4bf37ec2cee7e2287b","In a complex electromagnetic environment, numerical solution of partial differential equations (PDEs) and how to sample less data to invert spatio-temporal dynamics to discover potential physical laws or governing equations have been facing quite difficult challenges. With rapid progress of data-driven methods for artificial intelligence and computational physics, this paper would like to discuss our attempt on data-driven inversion and forward model for electromagnetic Maxwell's Equations.First of all, we propose a deep learning neural network in conjunction with sparse regression and pareto analysis to retrieve the hidden governing equations - Maxwell's wave equations of multiphysics electromagnetic systems. The JEC-FDTD algorithm is adopted for calculating interaction between electromagnetic wave with magnetized plasmas. Based on the concept of automatic differentiation, the differentiation operator is approximated by convolution. The neural network by tempo-rally sampling data of few spatial points can retrieve multiple physical electromagnetic and inhomogeneous magnetized plasma parameters. Also, the arctecture with learned PDEs is capable of predicting electric fields throughout the whole process even with noise. The data-driven method for discovery of coupled partial differential equations describing the electromagnetic fields in a complex system may also be applied to solve changeling problems that may not be solvable from first principles.Secondly, we construct the relationship between the Maxwell's wave equations and the recurrent neural network (RNN) for multiphysics electromagnetic systems. Numerical solution and inversion of Maxwell's wave equations are investigated for multiphysics electromagnetic systems. Numerical results by RNN agrees with the traditional JEC-FDTD algorithm. Parameter inversion can be easily achieved with backpropagation.Finally, we would like to compare two methods and then discuss advantages, difficulties and challenges for data-driven method for multiphysics electromagnetic systems. © 2020 IEEE.","Data-driven discovery; Machine learning; Maxwell's wave equation; Microwave and plasma interaction; Recur-rent neural network","Institute of Electrical and Electronics Engineers Inc."
"Li P.L., Chai X., Wadsworth W.D., Liao J., Paddock B.","Empirical Evaluation of Federated Learning with Local Privacy for Real-World Application",2020,"Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",,"10.1109/BigData50022.2020.9378033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103846382&doi=10.1109%2fBigData50022.2020.9378033&partnerID=40&md5=6869c792038e0024f1b0232beba0a50c","As Machine Learning-based applications become increasingly pervasive, a growing concern is how to balance the need for large, representative data sets with the need to respect user data privacy. The increased compute and connectivity capabilities of edge devices (e.g. phones, PCs) presents us with new avenues for achieving this balance, including a promising approach known as federated learning with local privacy. However, today we have gaps in practical knowledge about applicability, trade-offs, and benefits for large-scale realworld implementation. In this paper, using large-scale data from a real-world Windows Update ML-driven application (as well as the publicly available CIFAR-10 data set to enhance reproducibility), we report empirical evaluations of four practical considerations: heterogeneity in device availability that may cause bias, resiliency of federated learning with local differential privacy, benefits of time-varying adaptive configurations, and data transmission/storage savings based on the Pareto principle. We discuss the implications of these findings for practitioners and researchers. © 2020 IEEE.","big data applications; data privacy; federated learning; learning (artificial intelligence); machine learning; machine learning algorithms; prediction methods; predictive models; privacy","Institute of Electrical and Electronics Engineers Inc."
"Yang Y., Nam A., Nasr-Azadani M., Tung T.","Resource-Aware Pareto-Optimal Automated Machine Learning Platform",2020,"2020 3rd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2020",,"10.1109/ISRITI51436.2020.9315336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100007972&doi=10.1109%2fISRITI51436.2020.9315336&partnerID=40&md5=5ce59aa7214eb14f824c42e47b39b91b","In this study, we introduce a novel platform Resource-Aware AutoML (RA-AutoML) which enables flexible and generalized algorithms to build machine learning models subjected to multiple objectives, as well as resource and hardware constraints. RA-AutoML intelligently conducts Hyper-Parameter Search (HPS) as well as Neural Architecture Search (NAS) to build models optimizing predefined objectives. RA-AutoML is a versatile framework that allows user to prescribe many resource/hardware constraints along with objectives demanded by the problem or even business requirements. At its core, RA-AutoML relies on our in-house search-engine algorithm, MOBOGA, which combines a modified constraint-aware Bayesian Osptimization and Genetic Algorithm to construct Pareto optimal candidates. Our experiments on CIFAR-10 dataset shows very good accuracy compared to results obtained by state-of-art neural network models, while subjected to resource constraints in the form of model size. © 2020 IEEE.","Automatic Machine Learning; Bayesian optimization; Constraint-aware AutoML Platform; Hardware-aware Machine; Learning Resource constraints; Pareto optimal; Resource-aware optimization","Institute of Electrical and Electronics Engineers Inc."
"Naranjo-Pérez J., Infantes M., Fernando Jiménez-Alonso J., Sáez A.","A collaborative machine learning-optimization algorithm to improve the finite element model updating of civil engineering structures",2020,"Engineering Structures",6,"10.1016/j.engstruct.2020.111327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091649494&doi=10.1016%2fj.engstruct.2020.111327&partnerID=40&md5=9d63644da583c60995b100540dd50cc3","Finite element model updating has become a key tool to improve the numerical modelling of existing civil engineering structures, by adjusting the numerical response to the observed experimental behaviour of the structure. At present, model updating is mostly conducted using the maximum likelihood method. Following this approach, the updating problem can be transformed into a multi-objective optimization problem. Due to the complex nonlinear behaviour of the resulting objective functions, metaheuristic optimization algorithms are normally employed to solve such optimization problem. However, and although this is nowadays a well-established technique, there are still two main drawbacks that need to be addressed for practical engineering applications, namely: (i) the high simulation time required to compute the problem; and (ii) the uncertainty associated with the selection of the best updated model among all the Pareto optimal solutions. In order to overcome these limitations, a new collaborative algorithm is proposed herein, which takes advantage of the collaborative coupling among two optimization algorithms (harmony search and active-set algorithms), a machine learning technique (artificial neural networks) and a statistical tool (principal component analysis). The implementation details of our proposal are discussed in detail throughout the paper and its performance is illustrated with a case study addressing the model updating of a real steel footbridge. Two are the main advantages of the newly proposed algorithm: (i) it leads to a clear reduction of the simulation time; and (ii) it further permits a robust selection of the best updated model. © 2020 Elsevier Ltd","Best Pareto solution; Collaborative algorithm; Finite element model updating; Machine learning; Maximum likelihood method; Multi-objective harmony search optimization","Elsevier Ltd"
"Yu M., Huang S., Chen D.","Chimera: A Hybrid Machine Learning-Driven Multi-Objective Design Space Exploration Tool for FPGA High-Level Synthesis",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-91608-4_52","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126480700&doi=10.1007%2f978-3-030-91608-4_52&partnerID=40&md5=43ee3ff4af890247c12634a4b6fb5b71","In recent years, hardware accelerators based on field programmable gate arrays (FPGA) have been widely applied and the high-level synthesis (HLS) tools were created to facilitate the design of these accelerators. However, achieving high performance with HLS is still time-consuming and requires expert knowledge. Therefore, we present Chimera, an automated design space exploration tool for applying HLS optimization directives. It utilizes a novel multi-objective exploration method that seamlessly integrates active learning, evolutionary algorithm, and Thompson sampling, which enables it to find a set of optimized designs on a Pareto curve by only evaluating a small number of design points. On the Rosetta benchmark suite, Chimera explored design points that have the same or superior performance compared to highly optimized hand-tuned designs created by expert HLS users in less than 24 h. Moreover, it explores a Pareto frontier, where the elbow point can save up to 26% of flip-flop resource with negligible performance overhead. © 2021, Springer Nature Switzerland AG.",,"Springer Science and Business Media Deutschland GmbH"
"Liuliakov A., Hammer B.","AutoML Technologies for the Identification of Sparse Models",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-91608-4_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126468474&doi=10.1007%2f978-3-030-91608-4_7&partnerID=40&md5=1e8a0881d9a012e9c72c5b4918232bc5","Automated machine learning (AutoML) technologies constitute promising tools to automatically infer model architecture, meta-parameters or processing pipelines for specific machine learning tasks given suitable training data. At present, the main objective of such technologies typically relies on the accuracy of the resulting model. Additional objectives such as sparsity can be integrated by pre-processing steps or according penalty terms in the objective function. Yet, sparsity and model accuracy are often contradictory goals, and optimum solutions form a Pareto front. Thereby, it is not guaranteed that solutions at different positions of the Pareto front share the same architectural choices, hence current AutoML technologies might yield sub-optimal results. In this contribution, we propose a novel method, based on the AutoML method TPOT, which enables an automated optimization of ML pipelines with sparse input features along the whole Pareto front. We demonstrate that, indeed, different architectures are found at different points of the Pareto front for benchmark examples from the domain of systems security. © 2021, Springer Nature Switzerland AG.","AutoML; Feature selection; TPOT","Springer Science and Business Media Deutschland GmbH"
"Sullivan C.J., Bosanac N.","USING MULTI-OBJECTIVE DEEP REINFORCEMENT LEARNING TO UNCOVER A PARETO FRONT IN MULTI-BODY TRAJECTORY DESIGN",2021,"Advances in the Astronautical Sciences",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126266268&partnerID=40&md5=47a8006f5802c34b6eb4d6d611a3f751","A multi-objective deep reinforcement learning algorithm, designated Multi-Reward Proximal Policy Optimization (MRPPO), is introduced to simultaneously train multiple policies, each with distinct reward functions. In this paper, MRPPO is used to uncover the Pareto front in a multi-objective optimization problem: designing a transfer for a low-thrust-enabled small satellite between two L2 southern halo orbits in the Earth-Moon Circular Restricted Three-Body Problem (CR3BP). Once the policies are trained on this scenario, they are evaluated on a shared set of perturbed initial conditions to facilitate comparisons between policies and explore the time-of-flight and propellant mass usage trade space. A hyperparameter selection exploration is also performed to determine the influence of MRPPO’s hyperparameters on the resulting behavior of the policies. © 2021, Univelt Inc. All rights reserved.",,"Univelt Inc."
"Panchal H., Mishra S., Shrivastava V.","Chess Moves Prediction using Deep Learning Neural Networks",2021,"10th International Conference on Advances in Computing and Communications, ICACC 2021",,"10.1109/ICACC-202152719.2021.9708405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125814064&doi=10.1109%2fICACC-202152719.2021.9708405&partnerID=40&md5=7df803575b6fcec0652bfd81c52f7cf2","Chess is a game that is popular for high intelligence and strategic thinking. There has been a lot of research on chess for predicting chess moves, applying chess game theory, and automating chess games. The art of playing chess using computer vision can be implemented using various learning algorithms. A class of Deep Learning has the ability to solve problems of predicting chess moves although facing the necessity of huge datasets. The traditional chess algorithm Minimax with the Convolutional Neural Network can perceive and learn the patterns and rules in chess i.e., identification of some small and native tactics of the game, and should be trained on this method with appropriate functions for smarter universal play. CNN when trained with appropriate architecture and validation data can learn to function based on the reasoning in complex logical tasks. Training on 15,00,000 board states in the dataset which is a board state represented as 8x8x14 dimensions. Each board state is given as an input to the input layer of the Convolutional Neural Network. The CNN model tested and validated against the stockfish chess engine achieved the best accuracy of 39.16% for board evaluation. However, this doesn't reflect the actual accuracy of the model since the evaluation by the model is relative for two different board states. CNN learning the game of chess and based on the result of chess is essentially pre-computation on a given situation. © 2021 IEEE.","Chess Moves Prediction; Convolution Neural Network; Deep Learning; Strategy Board Game","Institute of Electrical and Electronics Engineers Inc."
"Kampert D., Varbanescu A.-L., Muller-Brockhausen M., Plaat A.","Mimicking the Human Approach in the Game of Hive",2021,"2021 IEEE Symposium Series on Computational Intelligence, SSCI 2021 - Proceedings",,"10.1109/SSCI50451.2021.9659999","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125799338&doi=10.1109%2fSSCI50451.2021.9659999&partnerID=40&md5=e43973969a4f65e2f2e042f67433c11e","While Deep Blue and AlphaGo make it seem like board games have been solved, there are still plenty of games for which no good game playing program exists. Hive is such a game. It is, combinatorically, of similar complexity as chess or Go, yet the rules of the game are such that current methods can barely beat a randomly playing agent. A major bottleneck for progress is the high branching factor of the game. We apply state of the art methods for which we develop new heuristics that are based on human domain-knowledge, attempting to improve upon the current dire state of Hive agents. Our methods have improved playing strength compared to the state of the art, although our AI still fails against actual Humans. We also find that, while in most board games, brute force or deep learning approaches work best, in Hive, an approach based on mimicking human knowledge outperforms these other approaches, including Monte Carlo Tree Search or Deep Reinforcement Learning. Future work will show if this anomalous situation is inherent to the game. © 2021 IEEE.","Artificial-intelligence (AI); Game-playing agents; Heuristic; Minimax; Monte-Carlo Tree Search (MCTS); The game Hive","Institute of Electrical and Electronics Engineers Inc."
"Liu X., Fan X., Guo Y., Cao Y., Li C.","Multi-objective optimization of GFRP injection molding process parameters, using GA-ELM, MOFA, and GRA-TOPSIS",2021,"Transactions of the Canadian Society for Mechanical Engineering",,"10.1139/tcsme-2021-0053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125515879&doi=10.1139%2ftcsme-2021-0053&partnerID=40&md5=acabc22c04dba741db81170d97237b85","Owing to the influence of the injection molding process, warpage and volume shrinkage are two common quality defects for products manufactured by glass fiber-reinforced plastic (GFRP) injection molding. To minimize these two defects, an extreme learning machine optimized with a genetic algorithm (GA-ELM), multi-objective firefly algorithm (MOFA), and a multi-objective decision-making method (GRA-TOPSIS) were implemented in this study. All of the experiments, based on Latin hypercubic sampling (LHS), were conducted using Moldflow software to obtain the results for warpage and volume shrinkage. The prediction accuracy of the defect-prediction models based on the extreme learning machine (ELM) and GA-ELM algorithms were compared. The results show that the GA-ELM models can better predict the defect values. Finally, MOFA was used to find the Pareto optimal front, and the GRA-TOPSIS method was used to find the optimum solution from the Pareto optimal front. According to the results of the simulation verification, the warpage and volume shrinkage were effectively reduced by 12.25% and 6.11%, respectively, compared with before optimization, which indicates the effectiveness and reliability of the optimization method. © 2021 The Author(s).","Evaluation strategy; Extreme learning machine; Injection molding; Latin hypercube sampling; Multi-objective optimization","Canadian Science Publishing"
"Gao H., Wang X., Luo L., Shi X.","On the Convergence of Stochastic Compositional Gradient Descent Ascent Method",2021,"IJCAI International Joint Conference on Artificial Intelligence",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125497658&partnerID=40&md5=588c4fbff2aae83ba0e74197dac2e88d","The compositional minimax problem covers plenty of machine learning models such as the distributionally robust compositional optimization problem. However, it is yet another understudied problem to optimize the compositional minimax problem. In this paper, we develop a novel efficient stochastic compositional gradient descent ascent method for optimizing the compositional minimax problem. Moreover, we establish the theoretical convergence rate of our proposed method. To the best of our knowledge, this is the first work achieving such a convergence rate for the compositional minimax problem. Finally, we conduct extensive experiments to demonstrate the effectiveness of our proposed method. © 2021 International Joint Conferences on Artificial Intelligence. All rights reserved.",,"International Joint Conferences on Artificial Intelligence"
"Kannan A., Roy Choudhury A., Saxena V., Raje S., Ram P., Verma A., Sabharwal Y.","HyperASPO: Fusion of Model and Hyper Parameter Optimization for Multi-objective Machine Learning",2021,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",,"10.1109/BigData52589.2021.9671604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125348956&doi=10.1109%2fBigData52589.2021.9671604&partnerID=40&md5=75e55cea918a404e270cf6b2c09d919f","Current state of the art methods for generating Pareto-optimal solutions for multi-objective optimization problems mostly rely on optimizing the hyper-parameters of the models (HPO - hyper-parameter Optimization). Few recent, less studied methods focus on optimizing over the space of model parameters, leveraging the problem specific knowledge. We present a generic first-of-a-kind method, referred to as HyperASPO, that combines optimization over the spaces of both hyper-parameters and model parameters for multi-objective optimization of learning problems. HyperASPO consists of two stages. First, we perform a coarse HPO to determine a set of favorable hyper-parameter configurations. In the second step, for each of these configurations, we solve a sequence of weighted single objective optimization problems for estimating Pareto-optimal solutions. We generate the weights in the second step using an adaptive mesh constructed iteratively based on the metrics of interest, resulting in further refinement of Pareto frontier efficiently. We consider the widely used XGBoost (Gradient Boosted Trees) model and validate our method on multiple classification datasets. Our proposed method shows up to 20% improvement over the hypervolumes of Pareto fronts obtained through state of the art HPO based methods with up to 2× reduction in computational time. © 2021 IEEE.","HyperASPO; Hyperparameter optimization; Model parameters; Pareto Optimization; XGBoost","Institute of Electrical and Electronics Engineers Inc."
"Kulbach C., Thoma S.","Personalized Neural Architecture Search",2021,"IEEE International Conference on Data Mining Workshops, ICDMW",,"10.1109/ICDMW53433.2021.00077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125348260&doi=10.1109%2fICDMW53433.2021.00077&partnerID=40&md5=28eb0d06522bdd75fb05a0f38ef8d324","Existing approaches for Neural Architecture Search (NAS) aim at efficiently maximizing individual or sets of objectives (e.g. high accuracy or a low number of parameters) by exploiting Reinforcement Learning (RL), evolutionary algorithms, or Bayesian optimization. Most multi-objective NAS algorithms assume that all objectives are fully known and require them to be broadly explored to successfully approximate the Pareto front, which results in computational expensive search algorithms. To address this problem, we propose an interactive machine learning approach based on preference elicitation which enables end-users to explore and find a custom loss function and can be directly used for State-of-the-Art single-objective black-box optimization. We integrate our approach into State-of-the-Art single objective NAS algorithms and evaluate it against multi-objective approaches on the NATS-Bench benchmark dataset. Furthermore, we show that diverse end-user preferences can be successfully approximated in terms of loss functions, leading to suitable neural architectures. © 2021 IEEE.","Neural Architecture Search; Personalization; Ranking; User Centric AI","IEEE Computer Society"
"Elshawi R., Lekunze H., Sakr S.","CSmartML: A Meta Learning-Based Framework for Automated Selection and Hyperparameter Tuning for Clustering",2021,"Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",,"10.1109/BigData52589.2021.9671542","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125345192&doi=10.1109%2fBigData52589.2021.9671542&partnerID=40&md5=44e34399cbacab29944d1680bd57e834","Novel technologies in automated machine learning ease the complexity of algorithm selection and hyper-parameter optimization. However, these are usually restricted to supervised learning tasks such as classification and regression, while unsupervised learning remains a largely unexplored problem. In this paper, we offer a solution for automating machine learning specifically for the case of unsupervised learning with clustering, in a domain-agnostic manner. This is achieved through a combination of state-of-the-art processes based on meta-learning for algorithm and evaluation criteria selection, and evolutionary algorithm for hyper-parameter tuning. We introduce a robust and scalable interactive tool, named cSmartML, built on scikit-learn with 8 clustering algorithms. In order to capture more than a single measure of goodness of the output clustering solution, cSmartML optimizes multiple objective functions. A pareto-approach evaluates each objective simultaneously for each clustering solution. On each of the 27 real and synthetic benchmark datasets, we show that the performance of cSmartML is often much better than using standard selection and hyper-parameter optimization methods. In addition, experimentation reveals that cSmartML takes advantage of the defined objective functions on multi-objective functions framework. © 2021 IEEE.","clustering; hyper-parameter optimization; meta-learning","Institute of Electrical and Electronics Engineers Inc."
"Inan M.S.K., Hasan R., Prama T.T.","An Integrated Expert System with a Supervised Machine Learning based Probabilistic Approach to Play Tic-Tac-Toe",2021,"2021 IEEE 12th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2021",,"10.1109/UEMCON53757.2021.9666728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125168732&doi=10.1109%2fUEMCON53757.2021.9666728&partnerID=40&md5=2649bd29ddfb49ce2dde3b23faf92988","Tic-Tac-Toe, also known as Noughts and Crosses, is a widely popular game among people of all ages. In recent times, due to the rapid development of Artificial Intelligence (AI) based algorithms, AI in Games has become an interesting topic for research in both academia and industry. Due to the complicated yet competent nature of AI algorithms, the design and implementation of such AI-driven approaches in games are challenging and time intensive. In this regard, we propose a supervised Machine Learning (ML)-based approach that contributes in designing an innovative and less complex Tic-Tac-Toc expert system. Integrating AI and ML in the solution process will lead the concerned community toward a more lightweight and computationally efficient systems for playing games. In this study, we propose a novel algorithmic solution by combining an ensemble-based boosting approach and rule-based inference to build a probabilistic expert system that strategically chooses the best optimal move for next possible state of the game. A benchmark dataset containing 255,168 unique game states of Tic Tac Toe was utilized at training stage. The proposed strategy is able to successfully settle a draw against never-loosing MiniMax algorithm in 18 standard test cases. © 2021 IEEE.","Ai in games; Machine learning in games; Noughts and crosses; Tic tac toe; Xgboost","Institute of Electrical and Electronics Engineers Inc."
"Luo C., Huang Q., Kong F., Khan S., Qiu Q.","Applying Machine Learning in Designing Distributed Auction for Multi-agent Task Allocation with Budget Constraints",2021,"2021 20th International Conference on Advanced Robotics, ICAR 2021",,"10.1109/ICAR53236.2021.9659364","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124692216&doi=10.1109%2fICAR53236.2021.9659364&partnerID=40&md5=5c65c0355d3a28d44932a35060cadeb5","The multi-agent task allocation can be solved in a distributed manner using Consensus-Based Bundle Algorithm (CBBA). Under this distributed auction process, each agent greedily maximizes the global score, which is the difference of the reward and the cost, through an iterative bundle construction and conflict resolution procedure. The distributed algorithm has provable convergence and guarantees 50% optimality if the score function satisfies the condition of diminishing marginal gain (DMG). While the previous work focuses on unconstrained optimization of rewards, this paper aims at applying CBBA to task allocation with budget constraints. Several heuristics were proposed to build the bundle and calculate the bidding scores as improvements to the original CBBA algorithm. We then prove that some of the new score functions are DMG, and therefore guarantees the convergence of the distributed process. We also show that these heuristic extended CBBAs are Pareto efficient; using different heuristic extensions under different scenarios is more efficient than consistently using the same one. To decide which heuristic extension should be used for a given task allocation problem, a graph convolutional neural network (GCN) model is trained to extract and analyze the features of the constrained optimization problem as a graph, and predict the potential performance (i.e., global reward) of different heuristic extensions. Based on the prediction, the best heuristic extension will be selected. Experimental results show that the predicted reward has more than 0.98 correlation with the actual reward and for 70% of time the prediction guided selection picks the best heuristic extension for the budget constrained task allocation problem. © 2021 IEEE.","GCN; Graph embedding; Limited budget; Multi-agent; Task allocation","Institute of Electrical and Electronics Engineers Inc."
"Marra G.","Bridging symbolic and subsymbolic reasoning with minimax entropy models",2021,"Intelligenza Artificiale",,"10.3233/IA-210088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124655468&doi=10.3233%2fIA-210088&partnerID=40&md5=1ed6321c05e9a8f8ffd4575ae7ccce0d","In this paper, we investigate MiniMax Entropy models, a class of neural symbolic models where symbolic and subsymbolic features are seamlessly integrated. We show how these models recover classical algorithms from both the deep learning and statistical relational learning scenarios. Novel hybrid settings are defined and experimentally explored, showing state-of-The-Art performance in collective classification, knowledge base completion and graph (molecular) data generation. © 2021-IOS Press. All rights reserved.","deep learning; logic; Neural symbolic artificial intelligence; statistical relational artificial intelligence","IOS Press BV"
"Liu T., Song S., Li X., Tan L.","Approximating Pareto Optimal Set by An Incremental Learning Model",2021,"2021 IEEE Congress on Evolutionary Computation, CEC 2021 - Proceedings",,"10.1109/CEC45853.2021.9504996","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124628869&doi=10.1109%2fCEC45853.2021.9504996&partnerID=40&md5=3a6f4206e6f51be4b850567af8422f99","Combining a machine learning model within the search procedure has shown great potentials in evolutionary multiobjective optimization (EMO). The priori knowledge obtained from the property of Pareto optimal set (PS) is a great help for reproducing high-quality offspring solutions. However, the existing learning model in the framework of EMO is also accompanied with a high computational cost resulted from its iterative strategy or repetitive learning. To overcome this shortcoming, the paper proposes to approximate the PS by an incremental learning model. Specifically, it consists of two interdependent parts, i.e., a learning module and a forgetting module. The basic idea is to take the all new high-quality offspring solutions at the current evolution iteration as a data stream, and incrementally train a model based on Gaussian mixture models with the data stream to discover the manifold structure of the PS and guide the evolutionary search. The learning module is used to obtain the knowledge from the data stream in a batch manner, while the forgetting module is applied to delete the information from the relatively poor solution as is removed incrementally. The proposed algorithm is employed to test suites, and the numerical experiments demonstrates that the incremental learning model can help to improve the algorithm performance with less computational cost compared with the representative algorithms. © 2021 IEEE",,"Institute of Electrical and Electronics Engineers Inc."
"Da Costa P., Pereira P.T.L., Paim G., Da Costa E., Bampi S.","Boosting the Efficiency of the Harmonics Elimination VLSI Architecture by Arithmetic Approximations",2021,"2021 28th IEEE International Conference on Electronics, Circuits, and Systems, ICECS 2021 - Proceedings",,"10.1109/ICECS53924.2021.9665538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124621996&doi=10.1109%2fICECS53924.2021.9665538&partnerID=40&md5=f768565efe0c8dc66ab0a83c5ea8f1ec","Approximate computing emerged as a key alternative for trading off accuracy against energy efficiency and area reduction. Error-tolerant applications, such as multimedia processing, machine learning, and signal processing, can process the information with lower-than-standard accuracy at the circuit level while still fulfilling a good and acceptable service quality at the application level. Adaptive filtering-based systems have been demonstrating high resiliency against hardware errors due to their intrinsic self-healing characteristic. This paper investigates the design space exploration of arithmetic approximations in a Very Large-Scale Integration (VLSI) harmonic elimination (HE) hardware architecture based on Least Mean Square (LMS) adaptive filters. We evaluate the Pareto front of the area- and power versus quality curves by relaxing the arithmetic precision and by adopting both approximate multipliers (AxMs) in combination with approximate adders (AxAs). This paper explores the benefits and impacts of the Dynamic Range Unbiased (DRUM), Rounding-based Approximate (RoBA), and Leading one Bit-based Approximate (LoBA) multipliers in the power dissipation, circuit area, and quality of the VLSI HE architectures. Our results highlight the LoBA 0 as the most efficient AxM applied in the HE architecture. We combine the LoBA 0 with Copy and LOA AxAs with variations in the approximation level (L). Notably, LoBA 0 and LOA with L=6 resulted in savings of 43.7% in circuit area and 45.2% in power dissipation, compared to the exact HE, which uses multiplier and adder automatically selected by the logic synthesis tool. Finally, we demonstrate that the best hardware architecture found in our investigation successfully eliminates the contaminating spurious noise (i.e., 60 Hz and its harmonics) from the signal. © 2021 IEEE.","Approximate Computing; Approximate multipliers; Harmonics Suppression; LMS; VLSI Design","Institute of Electrical and Electronics Engineers Inc."
"Luo J., Zhou D., Jiang L., Ma H.","An Entropy Driven Multiobjective Particle Swarm Optimization Algorithm for Feature Selection",2021,"2021 IEEE Congress on Evolutionary Computation, CEC 2021 - Proceedings",,"10.1109/CEC45853.2021.9504837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124616026&doi=10.1109%2fCEC45853.2021.9504837&partnerID=40&md5=07d0fc80131ab107c8b4b5d41e6f8b68","Feature selection is an important research field in machine learning since high-dimensionality is a common characteristic of real-world data. It has two main objectives, which are to maximize the classification accuracy while minimizing the number of selected features. As the two objectives are usually in conflict with each other, it makes feature selection a multiobjective problem. However, the large search space and discrete Pareto front makes it not easy for existing evolutionary multiobjective algorithms. In order to deal with the above mentioned difficulties in feature selection, an entropy driven multiobjective particle swarm optimization algorithm is proposed to remove redundant feature and decrease computational complexity. First, its basic idea is to model feature selection as a multiobjective optimization problem by optimizing the number of features and the classification accuracy in supervised condition simultaneously. Second, a particle initialization strategy based on information entropy is designed to improve the quality of initial solutions, and an adaptive velocity update rule is used to swap between local search and global search. Besides, a specified discrete nondominated sorting is designed. These strategies enable the proposed algorithm to gain better performance on both the quality and size of feature subset. The experimental results show that the proposed algorithm can maintain or improve the quality of Pareto fronts evolved by the state-of-the-art algorithms for feature selection. © 2021 IEEE","Feature selection; Multiobjective optimization; Particle swarm optimization","Institute of Electrical and Electronics Engineers Inc."
"Cai R., Luo J.","Multi-Task Learning for Multi-Objective Evolutionary Neural Architecture Search",2021,"2021 IEEE Congress on Evolutionary Computation, CEC 2021 - Proceedings",,"10.1109/CEC45853.2021.9504721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124607422&doi=10.1109%2fCEC45853.2021.9504721&partnerID=40&md5=8afdb56e4469a059db701928f8420d97","Neural architecture search (NAS) is an exciting new field in automating machine learning. It can automatically search for the architecture of neural networks. But the current NAS has extremely high requirements for hardware equipment and time costs. In this work, we propose a predictor based on Radial basis function neural network (RBFNN) as a surrogate model of Bayesian optimization to predict the performance of neural architecture. The existing work does not consider the difficulty of directly searching for neural architectures that meet the performance requirements of NAS in real-world applications. Meanwhile, NAS needs to execute multiple times independently when facing multiple similar tasks. Therefore, we further propose a multi-task learning surrogate model with multiple RBFNNs. The model not only functions as a predictor, but also learns knowledge of similar tasks jointly. The performance of NAS is improved by processing multiple tasks simultaneously. Also, the current NAS is committed to searching for very high-performance networks and does not take into account that neural architectures are limited by device memory during actual deployment. The scale of architecture also needs to be considered. We use a multi-objective optimization algorithm to simultaneously balance the performance and the scale, and build a multi-objective evolutionary search framework to find the Pareto optimal front. Once the NAS is completed, decision-makers can choose the appropriate architecture for deployment according to different performance requirements and hardware conditions. Compared with existing NAS work, our proposed MT-ENAS algorithm is able to find a neural architecture with competitive performance and smaller scale in a shorter time. © 2021 IEEE","Multi-objective optimization; Multi-task learning; Neural architecture search; Surrogate model","Institute of Electrical and Electronics Engineers Inc."
"Van Zyl T.L., Woolway M., Paskaramoorthy A.","ParDen: Surrogate Assisted Hyper-Parameter Optimisation for Portfolio Selection",2021,"2021 8th International Conference on Soft Computing and Machine Intelligence, ISCMI 2021",,"10.1109/ISCMI53840.2021.9654934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124406006&doi=10.1109%2fISCMI53840.2021.9654934&partnerID=40&md5=5f92557f8a80819de11a1149518aa1e8","Portfolio optimisation is a multi-objective optimisation problem (MOP), where an investor aims to optimise the conflicting criteria of maximising a portfolio's expected return whilst minimising its risk and other costs. However, selecting a portfolio is a computationally expensive problem because of the cost associated with performing multiple evaluations on test data (""backtesting"") rather than solving the convex optimisation problem itself. In this research, we present ParDen, an algorithm for the inclusion of any discriminative or generative machine learning model as a surrogate to mitigate the computationally expensive backtest procedure. In addition, we compare the performance of alternative metaheuristic algorithms: NSGA-II, R-NSGA-II, NSGA-III, R-NSGA-III, U-NSGA-III, MO-CMA-ES, and COMO-CMA-ES. We measure performance using multi-objective performance indicators, including Generational Distance Plus, Inverted Generational Distance Plus and Hypervol-ume. We also consider meta-indicators, Success Rate and Average Executions to Success Rate, of the Hypervolume to provide more insight into the quality of solutions. Our results show that ParDen can reduce the number of evaluations required by almost a third while obtaining an improved Pareto front over the state-of-the-art for the problem of portfolio selection. © 2021 IEEE.","genetic algorithms; hyper-parameter optimisation; metaheuristics; multi-objective optimisation; portfolio selection; surrogate modelling","Institute of Electrical and Electronics Engineers Inc."
"Adams S., Cody T., Beling P.A.","Pareto-Optimal Active Learning with Cost",2021,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",,"10.1109/SMC52423.2021.9658761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124313604&doi=10.1109%2fSMC52423.2021.9658761&partnerID=40&md5=274be19941ae6df6b5f59a4977f4dbb4","Supervised learning algorithms require a set of labeled training data. In many engineering applications, acquiring and accurately labeling the training data can be time consuming, burdensome, and costly. Active learning is an area of machine learning that selects observations in an unlabeled set to be passed to an oracle to retrieve the ground truth label, thereby improving the efficiency of the labeling and training process. However, most active learning algorithms only consider model improvement and, therefore, ignore cost considerations. The active learning algorithms that do consider cost require the practitioner to specify the trade-off between model improvement and cost. We propose an active learning with cost method that does not require this trade-off to be specified by randomly sampling observations from the Pareto optimal frontier. Further, we propose an extension to this method that accounts for uncertainty in the cost estimate of labeling an observation. These methods are evaluated on publicly available data sets, and the numerical experiments demonstrate that the proposed methods can produce models that achieve similar performance to standard active learning algorithms while reducing the labeling cost. © 2021 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Troop D., Godin F., Yu J.Y.","Bias-Corrected Peaks-Over-Threshold Estimation of the CVaR",2021,"37th Conference on Uncertainty in Artificial Intelligence, UAI 2021",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124276899&partnerID=40&md5=52c2ea4a18b2d8a7c9167420b6adeed8","The conditional value-at-risk (CVaR) is a useful risk measure in fields such as machine learning, finance, insurance, energy, etc. When measuring very extreme risk, the commonly used CVaR estimation method of sample averaging does not work well due to limited data above the value-at-risk (VaR), the quantile corresponding to the CVaR level. To mitigate this problem, the CVaR can be estimated by extrapolating above a lower threshold than the VaR using a generalized Pareto distribution (GPD), which is often referred to as the peaks-over-threshold (POT) approach. This method often requires a very high threshold to fit well, leading to high variance in estimation, and can induce significant bias if the threshold is chosen too low. In this paper, we address this bias-variance tradeoff by deriving a new expression for the GPD approximation error of the CVaR, a bias term induced by the choice of threshold, as well as a bias correction method for the estimated GPD parameters. This leads to the derivation of a new CVaR estimator that is asymptotically unbiased and less sensitive to lower thresholds being used. An asymptotic confidence interval for the estimator is also constructed. In a practical setting, we show through experiments that our estimator provides a significant performance improvement compared with competing CVaR estimators in finite samples from heavy-tailed distributions. © 2021 37th Conference on Uncertainty in Artificial Intelligence, UAI 2021. All Rights Reserved.",,"Association For Uncertainty in Artificial Intelligence (AUAI)"
"Davis W.R., Franzon P., Francisco L., Huggins B., III, Jain R.","Fast and Accurate PPA Modeling with Transfer Learning",2021,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,"10.1109/ICCAD51958.2021.9643533","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124156164&doi=10.1109%2fICCAD51958.2021.9643533&partnerID=40&md5=cfd13f29516bf61b7621470e394ee585","The power, performance and area (PPA) of digital blocks can vary 10:1 based on their synthesis, place, and route tool recipes. With rapid increase in number of PVT corners and complexity of logic functions approaching 10M gates, industry has an acute need to minimize the human resources, compute servers, and EDA licenses needed to achieve a Pareto optimal recipe. We first present models for fast accurate PPA prediction that can reduce the manual optimization iterations with EDA tools. Secondly we investigate techniques to automate the PPA optimization using evolutionary algorithms. For PPA prediction, a baseline model is trained on a known design using Latin hypercube sample runs of the EDA tool, and transfer learning is then used to train the model for an unseen design. For a known design the baseline needed 150 training runs to achieve a 95% accuracy. With transfer learning the same accuracy was achieved on a different (unseen) design in only 15 runs indicating the viability of transfer learning to generalize PPA models. The PPA optimization technique, based on evolutionary algorithms, effectively combines the PPA modeling and optimization. Our approach reached the same PPA solution as human designers in the same or fewer runs for a CORTEX-M0 system design. This shows potential for automating the recipe optimization without needing more runs than a human designer would need. ©2021 IEEE","Area; Gradient Boost; Machine Learning; Neural Network; Performance; Power; PPA; Surrogate Modeling; Transfer Learning","Institute of Electrical and Electronics Engineers Inc."
"Esmaeilzadeh H., Ghodrati S., Gu J., Guo S., Kahng A.B., Kim J.K., Kinzer S., Mahapatra R., Manasi S.D., Mascarenhas E., Sapatnekar S.S., Varadarajan R., Wang Z., Xu H., Yatham B.R., Zeng Z.","VeriGOOD-ML: An Open-Source Flow for Automated ML Hardware Synthesis",2021,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",,"10.1109/ICCAD51958.2021.9643449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124151139&doi=10.1109%2fICCAD51958.2021.9643449&partnerID=40&md5=065880d048f622bc2f28c68200244995","This paper introduces VeriGOOD-ML, an automated methodology for generating Verilog with no human in the loop, starting from a high-level description of a machine learning (ML) algorithm in a standard format such as ONNX. The Verilog RTL is then translated through a back-end design flow to GDSII, driven by a design planning approach that is well tailored to the macro-intensive nature of ML platforms. VeriGOOD-ML uses three approaches to build ML hardware: the TABLA platform uses a dataflow architecture that is well suited to non-DNN ML algorithms; the GeneSys platform, with a systolic array and a SIMD array, is optimized for implementing DNNs; and the Axiline approach synthesizes small ML algorithms by hardcoding the structure of the algorithm into hardware, thus trading off flexibility for performance and power. The overall approach explores the design space of platform configurations and Pareto-optimal-PPA back-end implementations to yield designs that represent different tradeoffs at the algorithmic level between area, power, performance, and execution time. The overall methodology, from architecture to back-end design to hardware implementation, is described in this paper, and the results of VeriGOOD-ML are demonstrated on a set of ML benchmarks. © 2021 IEEE",,"Institute of Electrical and Electronics Engineers Inc."
"Bai C., Sun Q., Zhai J., Ma Y., Yu B., Wong M.D.E.","BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework",2021,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",1,"10.1109/ICCAD51958.2021.9643455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124140667&doi=10.1109%2fICCAD51958.2021.9643455&partnerID=40&md5=41502eeb90155ccd1ab2c845b15c8165","The microarchitecture design of a processor has been increasingly difficult due to the large design space and time-consuming verification flow. Previously, researchers rely on prior knowledge and cycle-accurate simulators to analyze the performance of different microarchitecture designs but lack sufficient discussions on methodologies to strike a good balance between power and performance. This work proposes an automatic framework to explore microarchitecture designs of the RISC-V Berkeley Out-of-Order Machine (BOOM), termed as BOOM-Explorer, achieving a good trade-off on power and performance. Firstly, the framework utilizes an advanced microarchitecture-aware active learning (MicroAL) algorithm to generate a diverse and representative initial design set. Secondly, a Gaussian process model with deep kernel learning functions (DKL-GP) is built to characterize the design space. Thirdly, correlated multi-objective Bayesian optimization is leveraged to explore Pareto-optimal designs. Experimental results show that BOOM-Explorer can search for designs that dominate previous arts and designs developed by senior engineers in terms of power and performance within a much shorter time. © 2021 IEEE",,"Institute of Electrical and Electronics Engineers Inc."
"Li M., Tian Y., Zhang J., Fan D., Zhao D.","The Trade-off Between Privacy and Utility in Local Differential Privacy",2021,"Proceedings - 2021 International Conference on Networking and Network Applications, NaNA 2021",,"10.1109/NaNA53684.2021.00071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124038191&doi=10.1109%2fNaNA53684.2021.00071&partnerID=40&md5=2e65d75a30135c5e08d34f3f54caffec","In statistical queries work, such as frequency estimation, the untrusted data collector could as an honest-but-curious (HbC) or malicious adversary to learn true values. Local differential privacy(LDP) protocols have been applied against the untrusted third party in data collecting. Nevertheless, excessive noise of LDP will reduce data utility, thus affecting the results of statistical queries. Therefore, it is significant to research the trade-off between privacy and utility. In this paper, we first measure the privacy loss by observing the maximum posterior confidence of the adversary (data collector). Then, through theoretical analysis and comparison we obtain the most suitable utility measure that is Wasserstein distance. Based on these, we introduce an originality framework for privacy-utility tradeoff framework, finding that this system conforms to the Pareto optimality state and formalizing a payoff function to find optimal equilibrium point under Pareto efficiency. Finally, we illustrate the efficacy of our system model by the Adult dataset from the UCI machine learning repository. © 2021 IEEE.","data collecting; local differential privacy; Pareto optimality; privacy metric; utility metric","Institute of Electrical and Electronics Engineers Inc."
"Huang C., Wang L., Luo X., Zhang H., Song Y.","Evolutionary computing assisted deep reinforcement learning for multi-objective integrated energy system management",2021,"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI",,"10.1109/ICTAI52525.2021.00082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123951064&doi=10.1109%2fICTAI52525.2021.00082&partnerID=40&md5=65d167b96b87f09a171fa3bb0c3405d2","This paper investigates the multi-objective optimal operation problem of an integrated energy system (IES) which integrates grid-connected photovoltaic (PV) generator, gas boiler, battery energy storage system, and thermal storage to satisfy energy demand in forms of electricity and heat. To handle the changes from the system uncertainty (e.g., PV generation, electrical loads, thermal loads, etc.) and unknown thermal dynamic model for temperature control, deep reinforcement learning-based model-free optimization method is proposed to solve the multi-objective optimization problem in which the multi-objective optimization problem is firstly formulated as a multi-objective Markov decision process (MDP) problem. The multi-objective MDP problem is converted to many single-objective MDP problems by the sum technique which are solved by multi-agent deep deterministic policy gradient (DDPG) algorithm. To improve the performance of multi-agent DDPG algorithm, evolutionary computing-based parameter-tuning method is further proposed to fine-tune the policy parameters in DDPG algorithm. The proposed methods are verified on real data. Experiments results illustrate that the multi-agent DDPG algorithm can efficiently solve the multi-objective optimal operation problem of the IES while the evolutionary computing-based policy parameter-tuning method can further improve the approximation of Pareto frontier. © 2021 IEEE.","deep reinforcement learning; evolutionary computing; integrated energy system; multi-objective optimization","IEEE Computer Society"
"Mendoza J.H., Tariq R., Espinosa L.F.S., Anguebes F., Bassam A.","Soft Computing Tools for Multiobjective Optimization of Offshore Crude Oil and Gas Separation Plant for the Best Operational Condition",2021,"CCE 2021 - 2021 18th International Conference on Electrical Engineering, Computing Science and Automatic Control",,"10.1109/CCE53527.2021.9633049","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123872139&doi=10.1109%2fCCE53527.2021.9633049&partnerID=40&md5=5ef3a5890eaaa034ed911e36f5372bbd","The selection of operating conditions in the oil and gas separation plants is obtained through data monitoring or through the experience of the operating personnel which can bring operational difficulties leading to inefficiencies and capital loss. The modern techniques of soft computing including artificial intelligence and genetic algorithm-based optimization can add value to this operation. In this work, five key controllable design variables of an oil and gas separation plant are optimized considering two performance indicators (oil flow productivity and gas compression power). The physical model of the plant is simulated using ASPEN HYSYS, and a digital twin model is generated using an artificial neural network. It is followed by a multiobjective optimization using non-dominating sorting genetic algorithm II to obtain the Pareto front. The results have indicated that operational optimization can enhance oil production by up to ∼6.2% and decrease the compression work by ∼3.2%. It is concluded that the proposed operation of the plant is energy-efficient and can increase productivity. © 2021 IEEE.","artificial neural network; data science; oil and gas separation; optimization; simulation; soft computing","Institute of Electrical and Electronics Engineers Inc."
"Torfah H., Shah S., Chakraborty S., Akshay S., Seshia S.A.","Synthesizing Pareto-Optimal Interpretations for Black-Box Models",2021,"Proceedings of the 21st Formal Methods in Computer-Aided Design, FMCAD 2021",,"10.34727/2021/isbn.978-3-85448-046-4_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123714970&doi=10.34727%2f2021%2fisbn.978-3-85448-046-4_24&partnerID=40&md5=0d37ed9c225fd33f14da048c418b3508","We present a new multi-objective optimization approach for synthesizing interpretations that 'explain' the behavior of black-box machine learning models. Constructing human-understandable interpretations for black-box models often requires balancing conflicting objectives. A simple interpretation may be easier to understand for humans while being less precise in its predictions vis-a-vis a complex interpretation. Existing methods for synthesizing interpretations use a single objective function and are often optimized for a single class of interpretations. In contrast, we provide a more general and multi-objective synthesis framework that allows users to choose (1) the class of syntactic templates from which an interpretation should be synthesized, and (2) quantitative measures on both the correctness and explainability of an interpretation. For a given black-box, our approach yields a set of Pareto-optimal interpretations with respect to the correctness and explainability measures. We show that the underlying multi-objective optimization problem can be solved via a reduction to quantitative constraint solving, such as weighted maximum satisfiability. To demonstrate the benefits of our approach, we have applied it to synthesize interpretations for black-box neural-network classifiers. Our experiments show that there often exists a rich and varied set of choices for interpretations that are missed by existing approaches. © 2021 FMCAD Associ.",,"Institute of Electrical and Electronics Engineers Inc."
"Khan F., Urooj A., Khan S.A., Alsubie A., Almaspoor Z., Muhammadullah S.","Comparing the Forecast Performance of Advanced Statistical and Machine Learning Techniques Using Huge Big Data: Evidence from Monte Carlo Experiments",2021,"Complexity",1,"10.1155/2021/6117513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122340042&doi=10.1155%2f2021%2f6117513&partnerID=40&md5=cbe03bc92080371cc9c63a554f1f648c","This research compares factor models based on principal component analysis (PCA) and partial least squares (PLS) with Autometrics, elastic smoothly clipped absolute deviation (E-SCAD), and minimax concave penalty (MCP) under different simulated schemes like multicollinearity, heteroscedasticity, and autocorrelation. The comparison is made with varying sample size and covariates. We found that in the presence of low and moderate multicollinearity, MCP often produces superior forecasts in contrast to small sample case, whereas E-SCAD remains better. In the case of high multicollinearity, the PLS-based factor model remained dominant, but asymptotically the prediction accuracy of E-SCAD significantly enhances compared to other methods. Under heteroscedasticity, MCP performs very well and most of the time beats the rival methods. In some circumstances under large samples, Autometrics provides a similar forecast as MCP. In the presence of low and moderate autocorrelation, MCP shows outstanding forecasting performance except for the small sample case, whereas E-SCAD produces a remarkable forecast. In the case of extreme autocorrelation, E-SCAD outperforms the rival techniques under both the small and medium samples, but further augmentation in sample size enables MCP forecast more accurate comparatively. To compare the predictive ability of all methods, we split the data into two halves (i.e., data over 1973-2007 as training data and data over 2008-2020 as testing data). Based on the root mean square error and mean absolute error, the PLS-based factor model outperforms the competitor models in terms of forecasting performance. © 2021 Faridoon Khan et al.",,"Hindawi Limited"
"Shirvani S., Shirvani S., Jazayeri S.A., Reitz R.","Optimization of the exergy efficiency, exergy destruction, and engine noise index in an engine with two direct injectors using NSGA-II and artificial neural network",2021,"International Journal of Engine Research",,"10.1177/14680874211057752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122144180&doi=10.1177%2f14680874211057752&partnerID=40&md5=6a66ef5c1d6d7bfbdf683143e3b74da8","Direct Dual Fuel Stratification (DDFS) strategy is a novel Low Temperature Combustion (LTC) strategy that has comparable thermal efficiency to the Reactivity Controlled Compression Ignition (RCCI) strategy, while it offers more control over the combustion process and the rate of heat release. The DDFS strategy uses two direct injectors for the low- and high-reactivity fuels (gasoline and diesel) to benefit from the RCCI concept. In this study, the injection strategy of the injectors of a gasoline/diesel DDFS engine was optimized from the thermodynamic perspective to maximize exergy efficiency and minimize exergy destruction and an engine noise index. An artificial neural network was developed with 576 samples from a CFD code to predict the DDFS mode behavior, and the non-dominated sorting genetic algorithm (NSGA-II) was used to obtain the Pareto Front and the optimal solutions. Compared to the base case, the exergy efficiency of the optimal cases increased by up to 2%, exergy destruction and Peak Pressure Rise Rate (PPRR) reduced by about 2.3%, and 2 bar/deg, respectively, in the optimal solutions. NOX and soot emissions were reduced by 40% and 35%, respectively, in the best-case scenarios. © IMechE 2021.","ANN; Direct dual fuel stratification; machine learning; NSGA-II; optimization","SAGE Publications Ltd"
"Do T., Luong N.H.","Training-Free Multi-objective Evolutionary Neural Architecture Search via Neural Tangent Kernel and Number of Linear Regions",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-92270-2_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121900200&doi=10.1007%2f978-3-030-92270-2_29&partnerID=40&md5=fe58749c7512dc40ed970892e2e8802a","A newly introduced training-free neural architecture search (TE-NAS) framework suggests that candidate network architectures can be ranked via a combined metric of expressivity and trainability. Expressivity is measured by the number of linear regions in the input space that can be divided by a network. Trainability is assessed based on the condition number of the neural tangent kernel (NTK), which affects the convergence rate of training a network with gradient descent. These two measurements have been found to be correlated with network test accuracy. High-performance architectures can thus be searched for without incurring the intensive cost of network training as in a typical NAS run. In this paper, we suggest that TE-NAS can be incorporated with a multi-objective evolutionary algorithm (MOEA), in which expressivity and trainability are kept separate as two different objectives rather than being combined. We also add the minimization of floating-point operations (FLOPs) as the third objective to be optimized simultaneously. On NAS-Bench-101 and NAS-Bench-201 benchmarks, our approach achieves excellent efficiency in finding Pareto fronts of a wide range of architectures exhibiting optimal trade-offs among network expressivity, trainability, and complexity. Network architectures obtained by our approach on CIFAR-10 also show high transferability on CIFAR-100 and ImageNet. © 2021, Springer Nature Switzerland AG.","Deep learning; Evolutionary computation; Multi-objective optimization; Neural architecture search; Neural tangent kernels","Springer Science and Business Media Deutschland GmbH"
"Qin J.","A Survey of Long-Tail Item Recommendation Methods",2021,"Wireless Communications and Mobile Computing",,"10.1155/2021/7536316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121624699&doi=10.1155%2f2021%2f7536316&partnerID=40&md5=28da8180d8c63046203ef88fa9cc5553","Recommender systems represent a critical field of AI technology applications. The core function of a recommender system is to recommend items of interest to users, but if it is only user history-based (purchasing or browsing data), it can only recommend similar products to a user, which makes the user feel fatigued (creating so-called ""Information Cocoons""). Besides, transaction data (purchasing or browsing data) in various fields usually follow Pareto distributions. Accordingly, 20% of products are purchased or viewed a greater number of times (short-head items), while the remaining 80% of products are purchased or viewed less frequently (long-tail items). Using the traditional recommendation method, considering only the accuracy of recommendations, the coverage rate is relatively low, and most of the recommended items are short-head items. The long-tail item recommendation method not only considers the recommendation of short-head items but also considers recommending more long-tail items to users, thus improving the coverage and diversity of the recommendation results. Long-tail item recommendation research has become a frontier issue in recommendation systems in recent years. While the current research paper is still scarce, there have been related research achievements in top-level conferences in the field of computers, such as VLDB and IJCAI. Due to the fact that there is no review literature in this field, to allow readers to better understand the research status of the long-tail item recommendation method, this paper summarizes the progress of the research on long-tail item recommendation methods (from clustering-based, which began in 2008, to deep learning-based methods, which began in 2020) and the future directions associated with this research. © 2021 Jing Qin.",,"Hindawi Limited"
"Senarath Y., Mukhopadhyay A., Vazirizade S.M., Purohit H., Nannapaneni S., Dubey A.","Practitioner-Centric Approach for Early Incident Detection Using Crowdsourced Data for Emergency Services",2021,"Proceedings - IEEE International Conference on Data Mining, ICDM",1,"10.1109/ICDM51629.2021.00164","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120723729&doi=10.1109%2fICDM51629.2021.00164&partnerID=40&md5=a5eed55d9c4e7d8bd1e645b5c92969ca","Emergency response is highly dependent on the time of incident reporting. Unfortunately, the traditional approach to receiving incident reports (e.g., calling 911 in the USA) has time delays. Crowdsourcing platforms such as Waze provide an opportunity for early identification of incidents. However, detecting incidents from crowdsourced data streams is difficult due to the challenges of noise and uncertainty associated with such data. Further, simply optimizing over detection accuracy can compromise spatial-temporal localization of the inference, thereby making such approaches infeasible for real-world deployment. This paper presents a novel problem formulation and solution approach for practitioner-centered incident detection using crowdsourced data by using emergency response management as a case-study. The proposed approach CROME (Crowdsourced Multi-objective Event Detection) quantifies the relationship between the performance metrics of incident classification (e.g., F1 score) and the requirements of model practitioners (e.g., 1 km. radius for incident detection). First, we show how crowdsourced reports, ground-truth historical data, and other relevant determinants such as traffic and weather can be used together in a Convolutional Neural Network (CNN) architecture for early detection of emergency incidents. Then, we use a Pareto optimization-based approach to optimize the output of the CNN in tandem with practitioner-centric parameters to balance detection accuracy and spatial-temporal localization. Finally, we demonstrate the applicability of this approach using crowdsourced data from Waze and traffic accident reports from Nashville, TN, USA. Our experiments demonstrate that the proposed approach outperforms existing approaches in incident detection while simultaneously optimizing the needs for real-world deployment and usability. © 2021 IEEE.","Crowdsourcing; Deep Learning; Emergency Response; Multi-Objective Optimization; Waze","Institute of Electrical and Electronics Engineers Inc."
"Mittal S., Saxena D.K., Deb K., Goodman E.D.","Enhanced Innovized Progress Operator for Evolutionary Multi-and Many-objective Optimization",2021,"IEEE Transactions on Evolutionary Computation",,"10.1109/TEVC.2021.3131952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120543150&doi=10.1109%2fTEVC.2021.3131952&partnerID=40&md5=2e2cc42b9656ee9bd056c61421983519","Innovization is a task of learning common relationships among some or all of the Pareto-optimal (PO) solutions in multi-and many-objective optimization problems. A recent study has shown that a chronological sequence of non-dominated solutions obtained along the successive generations of an optimizer possesses salient patterns that can be learnt using a Machine Learning (ML) model, and can help the offspring solutions progress in useful directions. This paper enhances each constitutive module of the above approach, including novel interventions on management of the convergence-diversity tradeoff while mapping the solutions from the previous and current generation; use of a computationally more efficient ML method, namely Random Forest; and changing the manner and extent to which the learnt ML model is utilized towards advancement of the offspring. The proposed modules constitute what is called the enhanced innovized progress (IP2) operator. To investigate the search efficacy provided by the IP2 operator, it is integrated with multi-and many-objective optimization algorithms, such as NSGA-II, NSGA-III, MOEA/D, and MaOEA-IGD, and tested on a range of two-to ten-objective test problems, and five real-world problems. Since the IP2 operator utilizes the history of gradual and progressive improvements in solutions over generations, without requiring any additional solution evaluations, it opens up a new direction for ML-assisted evolutionary optimization. IEEE","Electrooculography; History; Innovization; Innovized Progress; IP networks; Learning-assisted Optimization; Machine Learning; Maintenance engineering; Multiobjective Optimization; Online Innovization.; Optimization; Radio frequency; Search problems","Institute of Electrical and Electronics Engineers Inc."
"Newton T., Meech J.T., Marbell P.S.","Machine Learning for Sensor Transducer Conversion Routines",2021,"IEEE Embedded Systems Letters",,"10.1109/LES.2021.3129892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120037384&doi=10.1109%2fLES.2021.3129892&partnerID=40&md5=941a94690787389fa83672d9c37ba723","Sensors with digital outputs require software conversion routines to transform the unitless analogue-to-digital converter samples to physical quantities with correct units. These conversion routines are computationally complex given the limited computational resources of low-power embedded systems. This article presents a set of machine learning methods to learn new, less-complex conversion routines that do not sacrifice accuracy for the BME680 environmental sensor. We present a Pareto analysis of the tradeoff between accuracy and computational overhead for the models and models that reduce the computational overhead of the existing industry-standard conversion routines for temperature, pressure, and humidity by 62%, 71%, and 18% respectively. The corresponding RMS errors are 0:0114&#x2218;C, 0:0280KPa, and 0:0337%. These results show that machine learning methods for learning conversion routines can produce conversion routines with reduced computational overhead which maintain good accuracy. IEEE","Ash; Computational modeling; Data models; Humidity; Interpolation; Machine Learning; Random access memory; Regression; Sensor.; Temperature measurement","Institute of Electrical and Electronics Engineers Inc."
"Li C., Xu K., Zhu J., Liu J., Zhang B.","Triple Generative Adversarial Networks",2021,"IEEE Transactions on Pattern Analysis and Machine Intelligence",,"10.1109/TPAMI.2021.3127558","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118991649&doi=10.1109%2fTPAMI.2021.3127558&partnerID=40&md5=4f62be24a12a6bf6ac36d0ac3f8e569a","We propose a unified game-theoretical framework to perform classification and conditional image generation given limited supervision. It is formulated as a three-player minimax game consisting of a generator, a classifier and a discriminator, and therefore is referred to as Triple Generative Adversarial Network (Triple-GAN). The generator and the classifier characterize the conditional distributions between images and labels to perform conditional generation and classification, respectively. The discriminator solely focuses on identifying fake image-label pairs. Theoretically, the three-player formulation guarantees consistency. Namely, under a nonparametric assumption, the unique equilibrium of the game is that the distributions characterized by the generator and the classifier converge to the data distribution. As a byproduct of the three-player formulation, Triple-GAN is flexible to incorporate different semi-supervised classifiers and GAN architectures. We evaluate Triple-GAN in two challenging settings, namely, semi-supervised learning and the extreme low data regime. In both settings, Triple-GAN can achieve excellent classification results and generate meaningful samples in a specific class simultaneously. In particular, using a commonly adopted 13-layer CNN classifier, Triple-GAN outperforms extensive semi-supervised learning methods substantially on several benchmarks no matter data augmentation is applied or not. IEEE","conditional image generation; deep generative model; Entropy; extremely low data regime; Games; Generative adversarial network; Generative adversarial networks; Generators; Linear programming; semi-supervised learning; Semisupervised learning; Task analysis","IEEE Computer Society"
"Aotani T., Kobayashi T., Sugimoto K.","Meta-Optimization of Bias-Variance Trade-Off in Stochastic Model Learning",2021,"IEEE Access",,"10.1109/ACCESS.2021.3125000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118661840&doi=10.1109%2fACCESS.2021.3125000&partnerID=40&md5=f9a52191babf476c5bc2a36039e94623","Model-based reinforcement learning is expected to be a method that can safely acquire the optimal policy under real-world conditions by using a stochastic dynamics model for planning. Since the stochastic dynamics model of the real world is generally unknown, a method for learning from state transition data is necessary. However, model learning suffers from the problem of bias-variance trade-off. Conventional model learning can be formulated as a minimization problem of expected loss. Failure to consider higher-order statistics for loss would lead to fatal errors in long-term model prediction. Although various methods have been proposed to explicitly handle bias and variance, this paper first formulates a new loss function, especially for sequential training of the deep neural networks. To explicitly consider the bias-variance trade-off, a new multi-objective optimization problem with the augmented weighted Tchebycheff scalarization, is proposed. In this problem, the bias-variance trade-off can be balanced by adjusting a weight hyperparameter, although its optimal value is task-dependent and unknown. We additionally propose a general-purpose and efficient meta-optimization method for hyperparameter(s). According to the validation result on each epoch, the proposed meta-optimization can adjust the hyperparameter(s) towards the preferred solution simultaneously with model learning. In our case, the proposed meta-optimization enables the bias-variance trade-off to be balanced for maximizing the long-term prediction ability. Actually, the proposed method was applied to two simulation environments with uncertainty, and the numerical results showed that the well-balanced bias and variance of the stochastic model suitable for the long-term prediction can be achieved. © 2013 IEEE.","bias-variance trade-off; Machine learning algorithms; Pareto optimization; systems modeling","Institute of Electrical and Electronics Engineers Inc."
"Pokala P.K., Hemadri R.V., Seelamantula C.S.","Iteratively Reweighted Minimax-Concave Penalty Minimization for Accurate Low-rank Plus Sparse Matrix Decomposition",2021,"IEEE Transactions on Pattern Analysis and Machine Intelligence",,"10.1109/TPAMI.2021.3122259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118535461&doi=10.1109%2fTPAMI.2021.3122259&partnerID=40&md5=34d0fa508ee4ab988b133cdb97a9fd3c","Low-rank plus sparse matrix decomposition (LSD) is an important problem in computer vision and machine learning. It has been solved using convex relaxations of the matrix rank and l0-pseudo-norm, which are the nuclear norm and l1-norm, respectively. Convex approximations are known to result in biased estimates, to overcome which, nonconvex regularizers such as weighted nuclear-norm minimization and weighted Schatten p-norm minimization have been proposed. However, works employing these regularizers have used heuristic weight-selection strategies. We propose weighted minimax-concave penalty (WMCP) as the nonconvex regularizer and show that it admits an equivalent representation that enables weight adaptation. Similarly, an equivalent representation to the weighted matrix gamma norm (WMGN) enables weight adaptation for the low-rank part. The optimization algorithms are based on the alternating direction method of multipliers technique. We show that the optimization frameworks relying on the two penalties, WMCP and WMGN, coupled with a novel iterative weight update strategy, result in accurate low-rank plus sparse matrix decomposition. The algorithms are also shown to satisfy descent properties and convergence guarantees. On the applications front, we consider the problem of foreground-background separation in video sequences. Simulation experiments and validations on standard datasets, namely, I2R, CDnet 2012, and BMC 2012 show that the proposed techniques outperform the benchmark techniques. IEEE","Convergence; Costs; equivalent minimax-concave penalty; Image reconstruction; low-rank and sparse matrix decomposition; Matrix decomposition; Minimax-concave penalty; Minimization; nonconvex penalty; Nuclear-norm minimization; Optimization; Sparse matrices; weighted 1 minimization","IEEE Computer Society"
"Candelieri A., Ponti A., Archetti F.","Uncertainty quantification and exploration–exploitation trade-off in humans",2021,"Journal of Ambient Intelligence and Humanized Computing",,"10.1007/s12652-021-03547-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118310833&doi=10.1007%2fs12652-021-03547-5&partnerID=40&md5=42a20d76b8151d5b548d5704fc9b0373","The main objective of this paper is to outline a theoretical framework to analyse how humans’ decision-making strategies under uncertainty manage the trade-off between information gathering (exploration) and reward seeking (exploitation). A key observation, motivating this line of research, is the awareness that human learners are amazingly fast and effective at adapting to unfamiliar environments and incorporating upcoming knowledge: this is an intriguing behaviour for cognitive sciences as well as an important challenge for Machine Learning. The target problem considered is active learning in a black-box optimization task and more specifically how the exploration/exploitation dilemma can be modelled within Gaussian Process based Bayesian Optimization framework, which is in turn based on uncertainty quantification. The main contribution is to analyse humans’ decisions with respect to Pareto rationality where the two objectives are improvement expected and uncertainty quantification. According to this Pareto rationality model, if a decision set contains a Pareto efficient (dominant) strategy, a rational decision maker should always select the dominant strategy over its dominated alternatives. The distance from the Pareto frontier determines whether a choice is (Pareto) rational (i.e., lays on the frontier) or is associated to “exasperate” exploration. However, since the uncertainty is one of the two objectives defining the Pareto frontier, we have investigated three different uncertainty quantification measures and selected the one resulting more compliant with the Pareto rationality model proposed. The key result is an analytical framework to characterize how deviations from “rationality” depend on uncertainty quantifications and the evolution of the reward seeking process. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Active learning; Exploration/exploitation dilemma; Human learning; Pareto analysis; Uncertainty quantification","Springer Science and Business Media Deutschland GmbH"
"Wang Z., Xian W., Baccouche M.R., Lanzerath H., Li Y., Xu H.","A Gaussian mixture variational autoencoder-based approach for designing phononic bandgap metamaterials",2021,"Proceedings of the ASME Design Engineering Technical Conference",,"10.1115/DETC2021-67629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118302907&doi=10.1115%2fDETC2021-67629&partnerID=40&md5=e8515bc5121b1e1371d4205b631cc8a2","Phononic bandgap metamaterials, which consist of periodic cellular structures, are capable of absorbing energy within a certain frequency range. Designing metamaterials that trap waves across a wide wave frequency range is still a challenging task. In this study, we proposed a deep feature learning-based framework to design cellular metamaterial structures considering two design objectives: bandgap width and stiffness. A Gaussian mixture variational autoencoder (GM-VAE) is employed to extract structural features and a Gaussian Process (GP) model is employed to enable property-driven structure optimization. By comparing the GM-VAE and a regular variational autoencoder (VAE), we demonstrate that (i) GM-VAE has the advantage of learning capability, and (ii) GM-VAE discovers a more diversified design set (in terms of the distribution in the performance space) in the unsupervised learning-based generative design. Two supervised learning strategies, building independent single-response GP models for each output and building an all-in-one multi-response GP model for all outputs, are employed and compared to establish the relationship between the latent features and the properties of interest. Multi-objective design optimization is conducted to obtain the Pareto frontier with respect to bandgap width and stiffness. The effectiveness of the proposed design framework is validated by comparing the performances of newly discovered designs with existing designs. The caveats to designing phonic bandgap metamaterials are summarized. © 2021 by ASME","Gaussian mixture variational autoencoder; Gaussian process; Metamaterial; Optimization; Phononic bandgap","American Society of Mechanical Engineers (ASME)"
"Obulesu O., Kallam S., Dhiman G., Patan R., Kadiyala R., Raparthi Y., Kautish S.","Adaptive Diagnosis of Lung Cancer by Deep Learning Classification Using Wilcoxon Gain and Generator",2021,"Journal of Healthcare Engineering",2,"10.1155/2021/5912051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118292020&doi=10.1155%2f2021%2f5912051&partnerID=40&md5=20e761ee0d2ebcf75a296b252b502a08","Cancer is a complicated worldwide health issue with an increasing death rate in recent years. With the swift blooming of the high throughput technology and several machine learning methods that have unfolded in recent years, progress in cancer disease diagnosis has been made based on subset features, providing awareness of the efficient and precise disease diagnosis. Hence, progressive machine learning techniques that can, fortunately, differentiate lung cancer patients from healthy persons are of great concern. This paper proposes a novel Wilcoxon Signed-Rank Gain Preprocessing combined with Generative Deep Learning called Wilcoxon Signed Generative Deep Learning (WS-GDL) method for lung cancer disease diagnosis. Firstly, test significance analysis and information gain eliminate redundant and irrelevant attributes and extract many informative and significant attributes. Then, using a generator function, the Generative Deep Learning method is used to learn the deep features. Finally, a minimax game (i.e., minimizing error with maximum accuracy) is proposed to diagnose the disease. Numerical experiments on the Thoracic Surgery Data Set are used to test the WS-GDL method's disease diagnosis performance. The WS-GDL approach may create relevant and significant attributes and adaptively diagnose the disease by selecting optimal learning model parameters. Quantitative experimental results show that the WS-GDL method achieves better diagnosis performance and higher computing efficiency in computational time, computational complexity, and false-positive rate compared to state-of-the-art approaches. © 2021 O. Obulesu et al.",,"Hindawi Limited"
"Touloupas K., Sotiriadis P.P.","LoCoMOBO: A Local Constrained Multi-Objective Bayesian Optimization for Analog Circuit Sizing",2021,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",,"10.1109/TCAD.2021.3121263","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118238709&doi=10.1109%2fTCAD.2021.3121263&partnerID=40&md5=e0c58966b765cc4c86c8b44986fb0acb","A Local Constrained Multi-Objective Bayesian Optimization (LoCoMOBO) method is introduced to address automatic sizing and trade-off exploration for analog and RF integrated circuits (IC). LoCoMOBO applies to constrained optimization problems utilizing multiple Gaussian Process (GP) models that approximate the objective and constraint functions locally in the search space. It searches for potential pareto optimal solutions within trust regions of the search space using only a few time-consuming simulations. The trust regions are adaptively updated during the optimization process based on feasibility and Hypervolume metrics. In contrast to mainstream Bayesian Optimization approaches, LoCoMOBO uses a new acquisition function that can provide multiple query points, therefore allowing for parallel execution of costly simulations. GP inference is also enhanced by using GPU acceleration in order to handle highly constrained problems that require large sample budgets. Combined with a framework for schematic parametrization and simulator calls, LoCoMOBO provides improved performance trade-offs and sizing results on three real-world circuit examples, while reducing the total run-time up to &#x00D7;43 times compared to state-of-the-art methods. IEEE","Analog Sizing; Bayes methods; Bayesian Methods.; Computational modeling; Gaussian processes; Integrated circuit modeling; Machine Learning; Mathematical models; Optimization; Optimization; Radio frequency","Institute of Electrical and Electronics Engineers Inc."
"Wei S., Niethammer M.","The fairness-accuracy Pareto front",2021,"Statistical Analysis and Data Mining",,"10.1002/sam.11560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118102341&doi=10.1002%2fsam.11560&partnerID=40&md5=6e9db56892eb2d02598f4abec048db28","Algorithmic fairness seeks to identify and correct sources of bias in machine learning algorithms. Confoundingly, ensuring fairness often comes at the cost of accuracy. We provide formal tools in this work for reconciling this fundamental tension in algorithm fairness. Specifically, we put to use the concept of Pareto optimality from multiobjective optimization and seek the fairness-accuracy Pareto front of a neural network classifier. We demonstrate that many existing algorithmic fairness methods are performing the so-called linear scalarization scheme, which has severe limitations in recovering Pareto optimal solutions. We instead apply the Chebyshev scalarization scheme which is provably superior theoretically and no more computationally burdensome at recovering Pareto optimal solutions compared to the linear scheme. © 2021 Wiley Periodicals LLC.","fairness; multiobjective optimization; neural network; Pareto front; Pareto optimality","John Wiley and Sons Inc"
"Ruchte M., Grabocka J.","Scalable Pareto Front Approximation for Deep Multi-Objective Learning",2021,"Proceedings - IEEE International Conference on Data Mining, ICDM",,"10.1109/ICDM51629.2021.00162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118033701&doi=10.1109%2fICDM51629.2021.00162&partnerID=40&md5=4b492dabf7b46733d370abf70aa78921","Multi-objective optimization is important for various Deep Learning applications, however, no prior multi-objective method suits very deep networks. Existing approaches either require training a new network for every solution on the Pareto front or add a considerable overhead to the number of parameters by introducing hyper-networks conditioned on modifiable preferences. In this paper, we present a novel method that contextualizes the network directly on the preferences by adding them to the input space. In addition, we ensure a well-spread Pareto front by forcing the solutions to preserve a small angle to the preference vector. Through extensive experiments, we demonstrate that our Pareto fronts achieve state-of-the-art quality despite being computed significantly faster. Furthermore, we demonstrate the scalability as our method approximates the full Pareto front on the CelebA dataset with an EfficientNet network at a marginal training time overhead of 7% compared to a single-objective optimization. We make the code publicly available at https://github.com/ruchtem/cosmos. © 2021 IEEE.","Deep Learning; Fairness; Multi-objective optimization","Institute of Electrical and Electronics Engineers Inc."
"Li Z., Yang Z., Zhao H., Xie S.","Direct-Optimization-Based DC Dictionary Learning With the MCP Regularizer",2021,"IEEE Transactions on Neural Networks and Learning Systems",1,"10.1109/TNNLS.2021.3114400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117314257&doi=10.1109%2fTNNLS.2021.3114400&partnerID=40&md5=6a264df815d73689c336f363a6e7951f","Direct-optimization-based dictionary learning has attracted increasing attention for improving computational efficiency. However, the existing direct optimization scheme can only be applied to limited dictionary learning problems, and it remains an open problem to prove that the whole sequence obtained by the algorithm converges to a critical point of the objective function. In this article, we propose a novel direct-optimization-based dictionary learning algorithm using the minimax concave penalty (MCP) as a sparsity regularizer that can enforce strong sparsity and obtain accurate estimation. For solving the corresponding optimization problem, we first decompose the nonconvex MCP into two convex components. Then, we employ the difference of the convex functions algorithm and the nonconvex proximal-splitting algorithm to process the resulting subproblems. Thus, the direct optimization approach can be extended to a broader class of dictionary learning problems, even if the sparsity regularizer is nonconvex. In addition, the convergence guarantee for the proposed algorithm can be theoretically proven. Our numerical simulations demonstrate that the proposed algorithm has good convergence performances in different cases and robust dictionary-recovery capabilities. When applied to sparse approximations, the proposed approach can obtain sparser and less error estimation than the different sparsity regularizers in existing methods. In addition, the proposed algorithm has robustness in image denoising and key-frame extraction. IEEE","Approximation algorithms; Convergence; Convergence analysis; Convex functions; Dictionaries; dictionary learning; direct optimization; Machine learning; minimax concave penalty (MCP) regularizer.; Optimization; Signal processing algorithms","Institute of Electrical and Electronics Engineers Inc."
"Cai Y., Jelovica J.","Adaptive constraint handling in optimization of complex structures by using machine learning",2021,"Proceedings of the International Conference on Offshore Mechanics and Arctic Engineering - OMAE",,"10.1115/OMAE2021-62304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117076199&doi=10.1115%2fOMAE2021-62304&partnerID=40&md5=c24346e293872189be66e92dd9017757","Optimization of complex systems requires robust and computationally efficient global search algorithms. Constraints make this a very difficult task, significantly slowing down an algorithm, and can even prevent finding the true Pareto front. This study continues the development of a recently proposed repair approach that exploits infeasible designs to increase computational efficiency of a prominent genetic algorithm, and to find a wider spread of the Pareto front. This paper proposes adaptive and automatized discovery of sensitivity of constraints to variables, i.e. the link, which needed direct designer's input in the previous version of the repair approach. This is achieved by using machine learning in the form of artificial neural networks (ANN). A surrogate model is afterwards utilized in optimization based on ANN. The proposed approach is used for the recently proposed constraint handling implemented into NSGA-II optimization algorithm. The proposed framework is compared with two other constraint handling methods. The performance is analyzed on a structural optimization of a 178 m long chemical tanker which needs to fulfil class society's criteria for strength. The results show that the proposed framework is competitive in terms of convergence and spread of the front. This is achieved while discovering the link automatically using ANN, without an input from a user. In addition, computational time is reduced by 60%. © 2021 by ASME","Artificial neural networks; Constraint-handling; Deep learning; Machine learning; Multi-objective optimization; Structural optimization","American Society of Mechanical Engineers (ASME)"
"Lasloum T., Alhichri H., Bazi Y., Alajlan N.","Ssdan: Multi-source semi-supervised domain adaptation network for remote sensing scene classification",2021,"Remote Sensing",4,"10.3390/rs13193861","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116286769&doi=10.3390%2frs13193861&partnerID=40&md5=43462ac518b0c5dd1d6e8667af51ee2a","We present a new method for multi-source semi-supervised domain adaptation in remote sensing scene classification. The method consists of a pre-trained convolutional neural network (CNN) model, namely EfficientNet-B3, for the extraction of highly discriminative features, followed by a classification module that learns feature prototypes for each class. Then, the classification module computes a cosine distance between feature vectors of target data samples and the feature prototypes. Finally, the proposed method ends with a Softmax activation function that converts the distances into class probabilities. The feature prototypes are also divided by a temperature parameter to normalize and control the classification module. The whole model is trained on both the unlabeled and labeled target samples. It is trained to predict the correct classes utilizing the standard cross-entropy loss computed over the labeled source and target samples. At the same time, the model is trained to learn domain invariant features using another loss function based on entropy computed over the unlabeled target samples. Unlike the standard cross-entropy loss, the new entropy loss function is computed on the model’s predicted probabilities and does not need the true labels. This entropy loss, called minimax loss, needs to be maximized with respect to the classification module to learn features that are domain-invariant (hence removing the data shift), and at the same time, it should be minimized with respect to the CNN feature extractor to learn discriminative features that are clustered around the class prototypes (in other words reducing intra-class variance). To accomplish these maximization and minimization processes at the same time, we use an adversarial training approach, where we alternate between the two processes. The model combines the standard cross-entropy loss and the new minimax entropy loss and optimizes them jointly. The proposed method is tested on four RS scene datasets, namely UC Merced, AID, RESISC45, and PatternNet, using two-source and three-source domain adaptation scenarios. The experimental results demonstrate the strong capability of the proposed method to achieve impressive performance despite using only a few (six in our case) labeled target samples per class. Its performance is already better than several state-of-the-art methods, including RevGrad, ADDA, Siamese-GAN, and MSCN. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural networks; Deep learning; Domain adaptation; EfficientNet-B3; Remote sensing; Semi-supervised scene classification","MDPI"
"Jackson D., Belakaria S., Cao Y., Doppa J.R., Lu X.","Machine Learning Enabled Design Automation and Multi-Objective Optimization for Electric Transportation Power Systems",2021,"IEEE Transactions on Transportation Electrification",,"10.1109/TTE.2021.3113958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115709337&doi=10.1109%2fTTE.2021.3113958&partnerID=40&md5=9a75a8e4b30be663034bddc1e2e6ccbe","This paper presents an automated design and optimization framework for electric transportation power systems (ETPS), enabled by machine learning (ML). The use of physical models, simulations, and optimization methods can greatly aid the engineering design process. However, when considering the optimal co-design of multiple inter-dependent subsystems that span multiple physical domains, such model-based simulations can be computationally expensive, and traditional metaheuristic optimization methods can be unreliable. Bayesian optimization (BO), a ML framework, paves one feasible pathway to realize an efficient design process practically. However, current state-of-the-art BO algorithms are non-compatible or perform poorly when applied to system-level ETPS design with multiple objectives and constraints. This paper proposes a novel BO algorithm referred to as Max-value Entropy Search for Multi-objective Optimization with Constraints (MESMOC) to solve multi-objective optimization (MOO) problems with black-box constraints that can only be evaluated through design simulations. After full presentation of the algorithm, MESMOC is applied to a realistic ETPS design case using a heavy-duty electric vertical-takeoff-landing (eVTOL) urban aerial vehicle (UAV) power system. Two MOO experimental trials show a drastic reduction in the number of design simulations to discover a high-quality Pareto front. In Trial 1, MESMOC uncovered the entire Pareto front while only requiring to explore &#x007E;4% of the design space. With expanded design parameters and a larger design space in Trial 2, a near-complete but high-quality Pareto front was uncovered. Both trials compared MESMOC to the popular genetic algorithm NSGA-II and another BO algorithm PESMOC, showing superior performance. IEEE","Aviation; Bayesian Optimization; Computational modeling; Design Automation; Electric Transportation; Heuristic algorithms; Machine learning; Machine Learning; Mathematical model; Model-based Design; Multi-Objective Optimization; Optimization; Power System Design; Search problems; Transportation; UAV","Institute of Electrical and Electronics Engineers Inc."
"Bieker K., Gebken B., Peitz S.","On the Treatment of Optimization Problems with L1 Penalty Terms via Multiobjective Continuation",2021,"IEEE Transactions on Pattern Analysis and Machine Intelligence",,"10.1109/TPAMI.2021.3114962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115680822&doi=10.1109%2fTPAMI.2021.3114962&partnerID=40&md5=9864c8b1a392e5814bde27eaf622fafe","We present a novel algorithm that allows us to gain detailed insight into the effects of sparsity in linear and nonlinear optimization. Sparsity is of great importance in many scientific areas such as image and signal processing, medical imaging, compressed sensing, and machine learning, as it ensures robustness against noisy data and yields models that are easier to interpret due to the small number of relevant terms. It is common practice to enforce sparsity by adding the l1-norm as a penalty term. In order to gain a better understanding and to allow for an informed model selection, we directly solve the corresponding multiobjective optimization problem (MOP) that arises when minimizing the main objective and the l1-norm simultaneously. As this MOP is in general non-convex for nonlinear objectives, the penalty method will fail to provide all optimal compromises. To avoid this issue, we present a continuation method specifically tailored to MOPs with two objective functions one of which is the l1-norm. Our method can be seen as a generalization of homotopy methods for linear regression problems to the nonlinear case. Several numerical examples - including neural network training- demonstrate our theoretical findings and the additional insight gained by this multiobjective approach. Author","Linear programming; Machine Learning; Mathematical models; Multiobjective Optimization; Neural networks; Nonsmooth Optimization; Optimization; Pareto optimization; Signal processing; Sparsity; Training","IEEE Computer Society"
"Zhang Q., Liu J., Zhang Z., Wen J., Mao B., Yao X.","Fairer Machine Learning Through Multi-objective Evolutionary Learning",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-86380-7_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115673628&doi=10.1007%2f978-3-030-86380-7_10&partnerID=40&md5=da293a478b6328473b9eaf64f6f8a7d0","Dilemma between model accuracy and fairness in machine learning models has been shown theoretically and empirically. So far, dozens of fairness measures have been proposed, among which incompatibility and complementarity exist. However, no fairness measure has been universally accepted as the single fairest measure. No one has considered multiple fairness measures simultaneously. In this paper, we propose a multi-objective evolutionary learning framework for mitigating unfairness caused by considering a single measure only, in which a multi-objective evolutionary algorithm is used during training to balance accuracy and multiple fairness measures simultaneously. In our case study, besides the model accuracy, two fairness measures that are conflicting to each other are selected. Empirical results show that our proposed multi-objective evolutionary learning framework is able to find Pareto-front models efficiently and provide fairer machine learning models that consider multiple fairness measures. © 2021, Springer Nature Switzerland AG.","AI ethics; Discrimination in machine learning; Fairness in machine learning; Fairness measures; Multi-objective learning","Springer Science and Business Media Deutschland GmbH"
"Lozano M.A., Orts Ò.G., Piñol E., Rebollo M., Polotskaya K., Garcia-March M.A., Conejero J.A., Escolano F., Oliver N.","Open Data Science to Fight COVID-19: Winning the 500k XPRIZE Pandemic Response Challenge",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-86514-6_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115672525&doi=10.1007%2f978-3-030-86514-6_24&partnerID=40&md5=6b941e880c603d33b5513cb9301e9f90","In this paper, we describe the deep learning-based COVID-19 cases predictor and the Pareto-optimal Non-Pharmaceutical Intervention (NPI) prescriptor developed by the winning team of the 500k XPRIZE Pandemic Response Challenge, a four-month global competition organized by the XPRIZE Foundation. The competition aimed at developing data-driven AI models to predict COVID-19 infection rates and to prescribe NPI Plans that governments, business leaders and organizations could implement to minimize harm when reopening their economies. In addition to the validation performed by XPRIZE with real data, the winning models were validated in a real-world scenario thanks to an ongoing collaboration with the Valencian Government in Spain. We believe that this experience contributes to the necessary transition to more evidence-driven policy-making, particularly during a pandemic. © 2021, Springer Nature Switzerland AG.","Computational epidemiology; Data science for public health; Non-pharmaceutical interventions; Pareto-front optimization; Recurrent neural networks; SARS-CoV-2","Springer Science and Business Media Deutschland GmbH"
"Millot A., Cazabet R., Boulicaut J.-F.","Exceptional model mining meets multi-objective optimization",2021,"SIAM International Conference on Data Mining, SDM 2021",1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115665604&partnerID=40&md5=c0f677a0e2b2da8c95cb9756b47317f1","Exceptional Model Mining (EMM) is a local pattern mining framework that generalizes subgroup discovery. In EMM, we look for subsets of objects - subgroups - whose model deviates significantly from the same model fitted on the overall dataset. Multi-objective Optimization (MOO) is an area of Multiple Criteria Decision Making where two or more functions need to be optimized at the same time and the goal is to find the best compromise between the concurrent objectives. We introduce a new model class for EMM in a MOO setting called Exceptional Pareto Front Mining. We design fitting quality measures that take into account both the distance between models and the relevance of the subgroups. We propose a beam search for top-K EMM whose added-value is studied on both synthetic and real life datasets. Among others, we discuss a use case on hyperparameter optimization in machine learning for both regression and multi-label classification. © 2021 by SIAM.",,"Siam Society"
"Briones A.M., Erdmann T.J., Rankin B.A.","On-design component-level multiple-objective optimization of a small-scale cavity-stabilized combustor",2021,"Proceedings of the ASME Turbo Expo",1,"10.1115/GT2021-60102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115448299&doi=10.1115%2fGT2021-60102&partnerID=40&md5=7377cceacd77059857c942b3e51835cf","This work presents an on-design component-level multiple-objective optimization of a small-scaled uncooled cavity-stabilized combustor. Optimization is performed at the maximum power condition of the engine thermodynamic cycle. The CFD simulations are managed by a supervised machine learning algorithm to divide a continuous and deterministic design space into non-dominated Pareto frontier and dominated design points. Steady, compressible three-dimensional simulations are performed using a multi-phase Realizable k-∈ RANS and non-adiabatic FPV combustion model. Conjugate heat transfer through the combustor liner is also considered. There are fifteen geometrical input parameters and four objective functions viz., maximization of combustion efficiency, and minimization of total pressure losses, pattern factor, and critical liner area factor. The baseline combustor design is based on engineering guidelines developed over the past two decades. The small-scale baseline design performs remarkably well. Direct optimization calculations are performed on this baseline design. In terms of Pareto optimality, the baseline design remains in the Pareto frontier throughout the optimization. However, the optimization calculations show improvement from an initial design point population to later iteration design points. The optimization calculations report other non-dominated designs in the Pareto frontier. The Euclidean distance from design points to the utopic point is used to select a ""best""and ""worst""design point for future fabrication and experimentation. The methodology to perform CFD optimization calculations of a small-scale uncooled combustor is expected to be useful for guiding the design and development of future gas turbine combustors. Copyright © 2021 by The United States Government.",,"American Society of Mechanical Engineers (ASME)"
"Zhang Y., McQuillan F., Jayaram N., Kak N., Khanna E., Kislal O., Valdano D., Kumar A.","Distributed deep learning on data systems: A comparative analysis of approaches",2021,"Proceedings of the VLDB Endowment",1,"10.14778/3467861.3467867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115442324&doi=10.14778%2f3467861.3467867&partnerID=40&md5=f9f531046313f06526e8661f7cfc1da8","Deep learning (DL) is growing in popularity for many data analytics applications, including among enterprises. Large business-critical datasets in such settings typically reside in RDBMSs or other data systems. The DB community has long aimed to bring machine learning (ML) to DBMS-resident data. Given past lessons from in-DBMS ML and recent advances in scalable DL systems, DBMS and cloud vendors are increasingly interested in adding more DL support for DB-resident data. Recently, a new parallel DL model selection execution approach called Model Hopper Parallelism (MOP) was proposed. In this paper, we characterize the particular suitability of MOP for DL on data systems, but to bring MOP-based DL to DBresident data, we show that there is no single “best” approach, and an interesting tradeoff space of approaches exists. We explain four canonical approaches and build prototypes upon Greenplum Database, compare them analytically on multiple criteria (e.g., runtime efficiency and ease of governance) and compare them empirically with large-scale DL workloads. Our experiments and analyses show that it is non-trivial to meet all practical desiderata well and there is a Pareto frontier; for instance, some approaches are 3x-6x faster but fare worse on governance and portability. Our results and insights can help DBMS and cloud vendors design better DL support for DB users. All of our source code, data, and other artifacts are available at https://github.com/makemebitter/cerebro-ds. © by the owner/author(s).",,"VLDB Endowment"
"Cai T., Song L., Li G., Liao M.","Multi-task Learning with Riemannian Optimization",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-84529-2_42","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115209145&doi=10.1007%2f978-3-030-84529-2_42&partnerID=40&md5=fcaac06b3a6dcd73125ab9674cebf074","Multi-task learning (MTL) is a promising research field of machine learning, in which the training process of the neural network is equivalent to multi-objective optimization. On one hand, MTL trains all the network weights simultaneously to converge the multi-task loss. On the other hand, multi-objective optimization aims to find the optimum solution, which satisfies the constraints and optimizes the vector of objective functions. Therefore, the performance of MTL is dominated by the computation of the multi-objective solution. This paper proposes a method based on Riemannian optimization to solve the multi-objective optimization in MTL. Firstly, multi-objective optimization is reduced to its Karush-Kuhn-Tucker (KKT) condition as the optimum solution of constrained quadratic optimization. Secondly, by mapping the Euclidean space of the constraint into manifold, the quadratic optimization is transformed to an unconstrained problem. Finally, Riemannian optimization algorithm is used to compute the solution of this problem, which gives a Pareto direction towards the KKT condition. We perform experiments on the MultiMNIST and Fashion MNIST datasets, and the experimental results demonstrate the efficiency of our method. © 2021, Springer Nature Switzerland AG.","Multi-objective optimization; Multi-task learning; Riemannian optimization","Springer Science and Business Media Deutschland GmbH"
"Villar D., Casillas J.","Facing Many Objectives for Fairness in Machine Learning",2021,"Communications in Computer and Information Science",,"10.1007/978-3-030-85347-1_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115203781&doi=10.1007%2f978-3-030-85347-1_27&partnerID=40&md5=345e243cab3feb5d0c843d54fed4ea33","Fairness is an increasingly important topic in the world of Artificial Intelligence. Machine learning techniques are widely used nowadays to solve huge amounts of problems, but those techniques may be biased against certain social groups due to different reasons. Using fair classification methods we can attenuate this discrimination source. Nevertheless, there are lots of valid fairness definitions which may be mutually incompatible. The aim of this paper is to propose a method which generates fair solutions for machine learning binary classification problems with one sensitive attribute. As we want accurate, fair and interpretable solutions, our method is based on Many Objective Evolutionary Algorithms (MaOEAs). The decision space will represent hyperparameters for training our classifiers, which will be decision trees, while the objective space will be a four-dimensional space representing the quality of the classifier in terms of an accuracy measure, two contradictory fairness criteria and an interpretability indicator. Experimentation have been done using four well known fairness datasets. As we will see, our algorithm generates good solutions compared to previous work, and a presumably well populated pareto-optimal population is found so that different classifiers could be used depending on our needs. © 2021, Springer Nature Switzerland AG.","Decision trees; Fairness in machine learning; Many objective evolutionary algorithm","Springer Science and Business Media Deutschland GmbH"
"Dreifuerst R.M., Daulton S., Qian Y., Varkey P., Balandat M., Kasturia S., Tomar A., Yazdan A., Ponnampalam V., Heath R.W.","Optimizing coverage and capacity in cellular networks using machine learning",2021,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",3,"10.1109/ICASSP39728.2021.9414155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115036912&doi=10.1109%2fICASSP39728.2021.9414155&partnerID=40&md5=7ff393448c3e2b585b227598bcf16274","Wireless cellular networks have many parameters that are normally tuned upon deployment and re-tuned as the network changes. Many operational parameters affect reference signal received power (RSRP), reference signal received quality (RSRQ), signal-to-interference-plus-noise-ratio (SINR), and, ultimately, throughput. In this paper, we develop and compare two approaches for maximizing coverage and minimizing interference by jointly optimizing the transmit power and downtilt (elevation tilt) settings across sectors. To evaluate different parameter configurations offline, we construct a realistic simulation model that captures geographic correlations. Using this model, we evaluate two optimization methods: deep deterministic policy gradient (DDPG), a reinforcement learning (RL) algorithm, and multi-objective Bayesian optimization (BO). Our simulations show that both approaches significantly outperform random search and converge to comparable Pareto frontiers, but that BO converges with two orders of magnitude fewer evaluations than DDPG. Our results suggest that data-driven techniques can effectively self-optimize coverage and capacity in cellular networks. ©2021 IEEE","Bayesian optimization; Coverage and capacity optimization; Machine learning; Reinforcement learning","Institute of Electrical and Electronics Engineers Inc."
"Li Y., Hao G., Liu Y., Yu Y., Ni Z., Zhao Y.","Many-Objective Distribution Network Reconfiguration via Deep Reinforcement Learning Assisted Optimization Algorithm",2021,"IEEE Transactions on Power Delivery",2,"10.1109/TPWRD.2021.3107534","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114616660&doi=10.1109%2fTPWRD.2021.3107534&partnerID=40&md5=3227bacca6adddbfdfede04bd66e4aec","With the increasing penetration of renewable energy (RE), the operation of distribution network is threatened and some issues may appear, i.e., large voltage deviation, deterioration of statistic voltage stability, high power loss, etc. In turn, RE accommodation would be significantly impacted. Therefore, we propose a many-objective distribution network reconfiguration (MDNR) model, with the consideration of RE curtailment, voltage deviation, power loss, statistic voltage stability, and generation cost. This aims to assess the trade-off among these objectives for better operations of distribution networks. As this proposed model is a non-convex, non-linear, many-objective optimization problem, it is difficult to be solved. We further propose a deep reinforcement learning (DRL) assisted multi-objective bacterial foraging optimization (DRLMBFO) algorithm. This algorithm combines the advantages of DRL and MBFO, and is targeted to find the Pareto front of proposed MDNR model with better searching efficiency. Finally, case study based on a modified IEEE 33-bus distribution system verifies the effectiveness of MDNR model and outperformance of DRL-MBFO. IEEE","deep reinforcement learning; Distribution network reconfiguration; Distribution networks; Generators; many-objective optimization; Microorganisms; Optimization; Power system stability; Reinforcement learning; renewable energy; Renewable energy sources","Institute of Electrical and Electronics Engineers Inc."
"Li Y.-H., Aslam M.S., Harfiya L.N., Chang C.-C.","Conditional Wasserstein generative adversarial networks for rebalancing iris image datasets",2021,"IEICE Transactions on Information and Systems",1,"10.1587/transinf.2021EDP7079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114384136&doi=10.1587%2ftransinf.2021EDP7079&partnerID=40&md5=e6212e2b34ef964ce51fbc7828c712fd","The recent development of deep learning-based generative models has sharply intensified the interest in data synthesis and its applications. Data synthesis takes on an added importance especially for some pattern recognition tasks in which some classes of data are rare and difficult to collect. In an iris dataset, for instance, the minority class samples include images of eyes with glasses, oversized or undersized pupils, misaligned iris locations, and iris occluded or contaminated by eyelids, eyelashes, or lighting reflections. Such class-imbalanced datasets often result in biased classification performance. Generative adversarial networks (GANs) are one of the most promising frameworks that learn to generate synthetic data through a two-player minimax game between a generator and a discriminator. In this paper, we utilized the state-of-the-art conditional Wasserstein generative adversarial network with gradient penalty (CWGAN-GP) for generating the minority class of iris images which saves huge amount of cost of human labors for rare data collection. With our model, the researcher can generate as many iris images of rare cases as they want and it helps to develop any deep learning algorithm whenever large size of dataset is needed. Copyright © 2021 The Institute of Electronics, Information and Communication Engineers","Deep learning; Generative adversarial network; Iris image generation; Machine learning neural networks; Signal synthesis","Institute of Electronics Information Communication Engineers"
"Kaloop M.R., Pijush S., Rabah M., Al-Ajami H., Hu J.W., Zaki A.","Improving accuracy of local geoid model using machine learning approaches and residuals of GPS/levelling geoid height",2021,"Survey Review",2,"10.1080/00396265.2021.1970918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113593459&doi=10.1080%2f00396265.2021.1970918&partnerID=40&md5=d171bbc30b5dc891391507367d885d1b","This study aims to use GPS/Levelling data and machine learning techniques (MLs) to model a high precision local geoid for Kuwait. To improve the accuracy of a local geoid the global geopotential model and local terrain effect should be incorporated. The geoid model was improved based on the modelling of geoid residuals using three MLs. Minimax Probability Machine Regression (MPMR), Gaussian Process Regression (GPR), and Multivariate Adaptive Regression Splines (MARS) MLs were developed for modelling the calculated geoid residuals. The results show that the accuracy of the three MLs was improved compared to previous studies, and the accuracy of the GPR model was better than the other models. The standard deviations of Kuwait geoid undulation determined by GPS/Levelling, gravimetric, and developed GPR models were 1.377, 1.375, 1.375 m, respectively. Thus, the developed GPR model has successfully predicted an accurate geoid height of Kuwait with maximum variation approaches ±0.02 m. © 2021 Survey Review Ltd.","Geoid; Geoid residuals; GGM; GPS/Levelling; Machine learning","Taylor and Francis Ltd."
"Bui K., Park F., Zhang S., Qi Y., Xin J.","Improving Network Slimming with Nonconvex Regularization",2021,"IEEE Access",,"10.1109/ACCESS.2021.3105366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113243442&doi=10.1109%2fACCESS.2021.3105366&partnerID=40&md5=16af8de33ce2d0de136e78f476af9cf1","Convolutional neural networks (CNNs) have developed to become powerful models for various computer vision tasks ranging from object detection to semantic segmentation. However, most of the state-of-the-art CNNs cannot be deployed directly on edge devices such as smartphones and drones, which need low latency under limited power and memory bandwidth. One popular, straightforward approach to compressing CNNs is network slimming, which imposes ℓ1 regularization on the channel-associated scaling factors via the batch normalization layers during training. Network slimming thereby identifies insignificant channels that can be pruned for inference. In this paper, we propose replacing the ℓ1 penalty with an alternative nonconvex, sparsity-inducing penalty in order to yield a more compressed and/or accurate CNN architecture. We investigate ℓp (0 < p < 1) , transformed ℓ1 ( Tℓ1 ), minimax concave penalty (MCP), and smoothly clipped absolute deviation (SCAD) due to their recent successes and popularity in solving sparse optimization problems, such as compressed sensing and variable selection. We demonstrate the effectiveness of network slimming with nonconvex penalties on three neural network architectures - VGG-19, DenseNet-40, and ResNet-164 - on standard image classification datasets. Based on the numerical experiments, T ℓ1 preserves model accuracy against channel pruning, ℓ1/2, 3/4 yield better compressed models with similar accuracies after retraining as ℓ1 , and MCP and SCAD provide more accurate models after retraining with similar compression as ℓ1. Network slimming with T ℓ1 regularization also outperforms the latest Bayesian modification of network slimming in compressing a CNN architecture in terms of memory storage while preserving its model accuracy after channel pruning. © 2013 IEEE.","Convolutional neural networks (CNN); deep learning; machine learning; network pruning; nonconvex optimization","Institute of Electrical and Electronics Engineers Inc."
"Lee E., Lee J., Kim Y., No J.","Minimax Approximation of Sign Function by Composite Polynomial for Homomorphic Comparison",2021,"IEEE Transactions on Dependable and Secure Computing",,"10.1109/TDSC.2021.3105111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113231167&doi=10.1109%2fTDSC.2021.3105111&partnerID=40&md5=26df7e1b5601bac6ba1b3ad0fc79ec6f","The comparison operation for two numbers is one of the most frequently used operations in several applications, including deep learning. As such, lots of research has been conducted with the goal of efficiently evaluating the comparison operation in homomorphic encryption schemes. Recently, Cheon et al. (Asiacrypt 2020) proposed new comparison methods that approximated the sign function on homomorphically encrypted data using composite polynomials and proved that these methods had optimal asymptotic complexity. In this paper, we propose a practically optimal method that approximates the sign function using compositions of minimax approximation polynomials. We prove that this approximation method is optimal with respect to depth consumption and the number of non-scalar multiplications. In addition, we propose a polynomial-time algorithm that determines the optimal composition of minimax approximation polynomials for the proposed homomorphic comparison operation using dynamic programming. The numerical analysis demonstrates that when minimizing runtime, the proposed comparison operation reduces the runtime by approximately 45% on average when compared to the previous algorithm. Likewise, when minimizing depth consumption, the proposed algorithm reduces the runtime by approximately 41% on average. In addition, when high precision in the comparison operation is required, the previous algorithm does not achieve 128-bit security, while the proposed algorithm does due to its small depth consumption. IEEE","Approximation algorithms; Cheon-Kim-Kim-Song (CKKS) scheme; Deep learning; Encryption; fully homomorphic encryption; Heuristic algorithms; homomorphic comparison operation; minimax approximation polynomial; Remez algorithm; Runtime; sign function; Sorting; Upper bound","Institute of Electrical and Electronics Engineers Inc."
"Puranik B., Madhow U., Pedarsani R.","Adversarially robust classification based on GLRT",2021,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",1,"10.1109/ICASSP39728.2021.9413587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112691036&doi=10.1109%2fICASSP39728.2021.9413587&partnerID=40&md5=207d641b40a8900b6abe88cd05b25842","Machine learning models are vulnerable to adversarial attacks that can often cause misclassification by introducing small but well designed perturbations. In this paper, we explore, in the setting of classical composite hypothesis testing, a defense strategy based on the generalized likelihood ratio test (GLRT), which jointly estimates the class of interest and the adversarial perturbation. We evaluate the GLRT approach for the special case of binary hypothesis testing in white Gaussian noise under `∞ norm-bounded adversarial perturbations, a setting for which a minimax strategy optimizing for the worst-case attack is known. We show that the GLRT approach yields performance competitive with that of the minimax approach under the worst-case attack, while yielding a better robustness-accuracy trade-off under weaker attacks. The GLRT defense is applicable in multi-class settings and generalizes naturally to more complex models for which optimal minimax classifiers are not known. © 2021 IEEE","Adversarial machine learning; Hypothesis testing; Robust classification","Institute of Electrical and Electronics Engineers Inc."
"Chen T., Wu S., Yang X., Xu Y., Wong H.","Semantic Regularized Class-Conditional GANs for Semi-Supervised Fine-Grained Image Synthesis",2021,"IEEE Transactions on Multimedia",,"10.1109/TMM.2021.3091859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112141318&doi=10.1109%2fTMM.2021.3091859&partnerID=40&md5=08f532cd8e66304fe97e5efebc17a726","Learning effective generative models for natural image synthesis is a promising way to reduce the dependence of deep models on massive training data. This work focuses on Fine-Grained Image Synthesis (FGIS) in the semi-supervised setting where a small number of training instances are labeled. Different from generic image synthesis tasks, the available fine-grained data may be inadequate, and the differences among the object categories are typically subtle. To address these issues, we propose a Semantic Regularized class-conditional Generative Adversarial Network, which is referred to as SReGAN. We incorporate an additional discriminator and classifier into the generator-discriminator minimax game. Competing with two discriminators enforces the generator to model both marginal and class-conditional data distributions, which alleviates the problem of limited training data and labels. However, the discriminators may overlook the class separability. To induce the generator to discover the distinctions between classes, we construct semantically congruent and incongruent pairs in the generation process, and further regularize the generator by encouraging high similarities of congruent pairs, while penalizing that of incongruent ones in the classifier's feature space. We have conducted extensive experiments to verify the capability of SReGAN in generating high-fidelity images on a variety of FGIS benchmarks. IEEE","Data models; fine-grained image synthesis; Generative adversarial networks; generative adversarial networks; Generators; Image synthesis; semantic regularization; Semantics; Semi-supervised learning; Task analysis; Training","Institute of Electrical and Electronics Engineers Inc."
"Bakurova A.V., Ropalo H.M., Tereschenko E.V.","Analysis of the effectiveness of the successive concessions method to solve the problem of diversification",2021,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111813352&partnerID=40&md5=84836b3cbebfe3b3461b21ba3bce693f","The subject of the paper is multicriteria problems that arise when modeling the complex diversification of a centralized pharmacy network. The purpose of the work is to analyze the peculiarities of solving the three-criteria problem of pharmacy network diversification by the method of successive concessions in the MATLAB package. The paper solves the following problems: research of the advantages of the proposed three-criteria model of pharmacy network diversification in relation to the classical two-criteria model of portfolio theory; construction of the relation of dominance on a set of criteria; determination of the area of stability in the space of the parameters of the concessions method; evaluating the effectiveness of the method for problems of different sizes. The following methods are used: classical portfolio theory, multicriteria optimization, the successive concessions method, computer modeling of the Pareto set. The results obtained: a study of the processes of complex diversification of the pharmacy network by building portfolio models and solving the relevant multicriteria problems by the successive concessions method. Acceptable sets and sets of pareto-optimal portfolios for the risk management are graphically found, taking into account the activity of the network itself and the client portfolio. Conclusions: The results of computer modeling and numerical analysis of solutions by sequential concessions will be useful for automating the business processes of pharmacy networks, risk management, analysis of market data to improve their efficiency. © 2021 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)","Entropy; Multicriteria problem; Optimal portfolio problem; Pareto set; Pharmacy network; Successive concessions method","CEUR-WS"
"Zhang J., Dong Q., Song W.","GGADN: Guided generative adversarial dehazing network",2021,"Soft Computing",,"10.1007/s00500-021-06049-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111781779&doi=10.1007%2fs00500-021-06049-w&partnerID=40&md5=0ab0dca4af224edd89d8dd83e00e0b92","Image dehazing has always been a challenging topic in image processing. The development of deep learning methods, especially the generative adversarial networks (GAN), provides a new way for image dehazing. In recent years, many deep learning methods based on GAN have been applied to image dehazing. However, GAN has two problems in image dehazing. Firstly, For haze image, haze not only reduces the quality of the image but also blurs the details of the image. For GAN network, it is difficult for the generator to restore the details of the whole image while removing the haze. Secondly, GAN model is defined as a minimax problem, which weakens the loss function. It is difficult to distinguish whether GAN is making progress in the training process. Therefore, we propose a guided generative adversarial dehazing network (GGADN). Different from other generation adversarial networks, GGADN adds a guided module on the generator. The guided module verifies the network of each layer of the generator. At the same time, the details of the map generated by each layer are strengthened. Network training is based on the pre-trained VGG feature model and L1-regularized gradient prior which is developed by new loss function parameters. From the dehazing results of synthetic images and real images, the proposed method is better than the state-of-the-art dehazing methods. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Dehazing; Generative adversarial networks; Guidance; Loss function","Springer Science and Business Media Deutschland GmbH"
"Chen Z., Ge J., Zhan H., Huang S., Wang D.","Pareto self-supervised training for few-shot learning",2021,"Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition",4,"10.1109/CVPR46437.2021.01345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110327392&doi=10.1109%2fCVPR46437.2021.01345&partnerID=40&md5=563a97394823e7ce44081a3a30f0e030","While few-shot learning (FSL) aims for rapid generalization to new concepts with little supervision, self-supervised learning (SSL) constructs supervisory signals directly computed from unlabeled data. Exploiting the complementarity of these two manners, few-shot auxiliary learning has recently drawn much attention to deal with few labeled data. Previous works benefit from sharing inductive bias between the main task (FSL) and auxiliary tasks (SSL), where the shared parameters of tasks are optimized by minimizing a linear combination of task losses. However, it is challenging to select a proper weight to balance tasks and reduce task conflict. To handle the problem as a whole, we propose a novel approach named as Pareto self-supervised training (PSST) for FSL. PSST explicitly decomposes the few-shot auxiliary problem into multiple constrained multi-objective subproblems with different trade-off preferences, and here a preference region in which the main task achieves the best performance is identified. Then, an effective preferred Pareto exploration is proposed to find a set of optimal solutions in such a preference region. Extensive experiments on several public benchmark datasets validate the effectiveness of our approach by achieving state-of-the-art performance. © 2021 IEEE",,"IEEE Computer Society"
"Campbell S.D., Werner D.H., Werner P.L.","Inverse design of broadband and reconfigurable meta-optics",2021,"Proceedings of SPIE - The International Society for Optical Engineering",1,"10.1117/12.2589333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109347641&doi=10.1117%2f12.2589333&partnerID=40&md5=c11fdeb6ce0d1a4e26c7a62178b0af6f","By exploiting the generalized form of Snell’s law, metasurfaces afford optical engineers a tremendous increase in degrees of design freedom compared to conventional optical components. These “meta-optics” can achieve unprecedented levels of performance through engineered wavelength-, angular-, and polarization-dependent responses which can be tailored by arranging subwavelength unit cells, or meta-atoms, in an intelligent way. Moreover, these meta-atoms can be constructed from phase change materials which give the added flexibility of realizing reconfigurable meta-optics. Devices such as achromatic flat lenses and non-mechanical zoom lenses are becoming a reality through the advent of metasurface-augmented optical systems. However, achieving high-performance meta-optics relies heavily on proper meta-atom design. This challenge is best overcome through the use of advanced inverse-design tools and state-of-the-art optimization algorithms. To this end, a number of successful meta-device inverse-design approaches have been demonstrated in the literature including those based on topology optimization, deep learning, and global optimization. While each has its pros and cons, multi-objective optimization strategies have proven quite successful do their ability to optimize problems with multiple competing objectives: a common occurrence in optical design. Moreover, multi-objective algorithms produce a Pareto Set of optimal solutions that designers can analyze in order to directly study the tradeoffs between the various design goals. In our presentation, we will introduce an efficient multi-objective optimization enabled design framework for the generation of broadband and multifunctional meta-atoms. Additionally, several meta-optic design examples will be presented, and future research directions discussed. © 2021 SPIE.","Inverse-design; Metamaterials; Metasurfaces; Optical design; Optimization","SPIE"
"Herrmann T.A., Celi R., Baeder J.D.","Multidisciplinary trim analysis using improved optimization, image analysis, and machine learning algorithms",2021,"77th Annual Vertical Flight Society Forum and Technology Display, FORUM 2021: The Future of Vertical Flight",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108947265&partnerID=40&md5=9324cd4bd23b968cb0f27ee0502533ee","A multiobjective design optimization methodology is used to determine the trim controls that minimize power required, noise, and blade loads of a coaxial-pusher rotorcraft, and to quantify the trade-offs among those three objectives in the form of 3-dimensional Pareto frontiers. A moderate-fidelity simulation model is used, which includes blade flexibility and a free vortex rotor wake model. A hybrid optimizer is developed, which starts with a genetic algorithm and radial basis function-based response surfaces, and ends with a gradient-based refinement. A new gradient-based method for constrained multiobjective optimization is developed, based on an extension of the method of feasible directions. A new technique for the automatic interpretation of rotor maps, based on image analysis and k-means clustering is presented. A new technique based on a k-nearest neighbor algorithm predicts trimmability. These two techniques reduce the need for analyst intervention during the optimization and improve accuracy. Results are presented for a 6- and an 8-control effector coaxial configuration in high speed flight. Copyright © 2021 by the Vertical Flight Society. All rights reserved.",,"Vertical Flight Society"
"Fang Z., Zhao M., Yu Z., Li M., Yang Y.","A guiding teaching and dual adversarial learning framework for a single image dehazing",2021,"Visual Computer",1,"10.1007/s00371-021-02184-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107746836&doi=10.1007%2fs00371-021-02184-5&partnerID=40&md5=eedfb4d20555baa72de1ad5c27fde6ac","In most existing deep learning-based image dehazing methods, the haze-free source images are only used as the ground truth for the design of the loss function, whereas the guiding role that the source image should play on different feature levels has been ignored. This will result in a sub-optimal dehazing output. To address this issue, inspired by the knowledge distillation, a guiding teaching framework is designed for single image dehazing in an end-to-end manner, where the features of the haze-free source image at different levels are completely used to promoting the restoration of the hazy image. Specifically, the framework consists of a two-stream convolutional neural network termed teacher stream (TS) and student stream (SS), respectively. The input of the former is a haze-free image while the output is the desired image after reconstruction. The input of the latter is the hazy image, and the output is the restored image. Moreover, a dual adversarial strategy is designed to further improve the ability of SS to imitate teacher stream. In this process, the output results of SS are divided into two categories according to their hazy intensity levels. Then a thick light discriminator is introduced and made against the SS pit, such that the images with better dehazing effects can be used to deal with the ones poorly dehazed. A second discriminator termed light clear discriminator (LCD) is further introduced and a minimax game between the LCD and the SS is defined to drive the final result produced by SS closer to the reconstruction result of the TS. Experimental results show that the proposed method outperforms several latest methods applied to both artificial hazy images and the hazy images from the real scene. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Adversarial learning; Image dehazing; Knowledge distillation; Student stream; Teacher stream","Springer Science and Business Media Deutschland GmbH"
"Crowley E.J., Gray G., Turner J., Storkey A.","Substituting Convolutions for Neural Network Compression",2021,"IEEE Access",,"10.1109/ACCESS.2021.3086321","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107388590&doi=10.1109%2fACCESS.2021.3086321&partnerID=40&md5=4601c3fb5a1dee3a452848b114c62960","Many practitioners would like to deploy deep, convolutional neural networks in memory-limited scenarios, e.g., on an embedded device. However, with an abundance of compression techniques available it is not obvious how to proceed; many bring with them additional hyperparameter tuning, and are specific to particular network types. In this paper, we propose a simple compression technique that is general, easy to apply, and requires minimal tuning. Given a large, trained network, we propose (i) substituting its expensive convolutions with cheap alternatives, leaving the overall architecture unchanged; (ii) treating this new network as a student and training it with the original as a teacher through distillation. We demonstrate this approach separately for (i) networks predominantly consisting of full 3 × 3 convolutions and (ii) 1 × 1 or pointwise convolutions which together make up the vast majority of contemporary networks. We are able to leverage a number of methods that have been developed as efficient alternatives to fully-connected layers for pointwise substitution, allowing us provide Pareto-optimal benefits in efficiency/accuracy. © 2013 IEEE.","computer vision; deep neural networks; DNN compression; Machine learning","Institute of Electrical and Electronics Engineers Inc."
"Liu M., Chen D., Zhang Q., Jiang L.","An Online Machine Learning-Based Prediction Strategy for Dynamic Evolutionary Multi-objective Optimization",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-030-72062-9_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107287523&doi=10.1007%2f978-3-030-72062-9_16&partnerID=40&md5=b141a40c0037d027079227b4607c6467","Due to the impact of environmental changes, dynamic evolutionary multi-objective optimization algorithms need to track the time-varying Pareto optimal solution set of dynamic multi-objective optimization problems (DMOPs) as soon as possible by effectively mining historical data. Since online machine learning can help algorithms dynamically adapt to new patterns in the data in machine learning community, this paper introduces Passive-Aggressive Regression (PAR, a common online learning technology) into dynamic evolutionary multi-objective optimization research area. Specifically, a PAR-based prediction strategy is proposed to predict the new Pareto optimal solution set of the next environment. Furthermore, we integrate the proposed prediction strategy into the multi-objective evolutionary algorithm based on decomposition with a differential evolution operator (MOEA/D-DE) to handle DMOPs. Finally, the proposed prediction strategy is compared with three state-of-the-art prediction strategies under the same dynamic MOEA/D-DE framework on CEC2018 dynamic optimization competition problems. The experimental results indicate that the PAR-based prediction strategy is promising for dealing with DMOPs. © 2021, Springer Nature Switzerland AG.","Dynamic environment; Evolutionary multi-objective optimization; Online machine learning; Prediction strategy","Springer Science and Business Media Deutschland GmbH"
"Roy S.S., Samui P.","Predicting longitudinal dispersion coefficient in natural streams using minimax probability machine regression and multivariate adaptive regression spline",2021,"International Journal of Advanced Intelligence Paradigms",,"10.1504/IJAIP.2021.115244","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106939158&doi=10.1504%2fIJAIP.2021.115244&partnerID=40&md5=6ced091fc8666d653baac92622e2e6c2","This article employs minimax probability machine regression (MPMR) and multivariate adaptive regression spline (MARS) for prediction of longitudinal dispersion coefficient in natural streams. The variables of hydraulic features such as channel width (B), flow depth (H), flow velocity (U), shear velocity (u*) and geometric features such as channel sinuosity (σ) and channel shape parameter (β) were taken as the input. The dispersion coefficient Kx was the decision parameter for the proposed machine learning models. MARS does not assume any functional relationship between inputs and output. The MARS model is a non-parametric regression model that splits the data and fits each interval into a basis function. MPMR is a probabilistic model which maximises the minimum probability of predicted output. MPMR also provides output within some bound of the true regression function. The proposed study gives an equation for prediction of longitudinal dispersion coefficient based on the developed MARS. The developed MARS has been compared with proposed MPMR. Finally, the performances of the models have been measured by different performance metrics. Copyright © 2021 Inderscience Enterprises Ltd.","Longitudinal dispersion coefficient; MARS; Minimax probability machine regression; MPMR; Multivariate adaptive regression spline; Natural streams; Prediction","Inderscience Publishers"
"Sharma V., Zaki M., Jha K.N., Krishnan N.M.A.","Machine learning-aided cost prediction and optimization in construction operations",2021,"Engineering, Construction and Architectural Management",1,"10.1108/ECAM-10-2020-0778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106055875&doi=10.1108%2fECAM-10-2020-0778&partnerID=40&md5=3acd3acdfa012aaba64a83fd0b218ac2","Purpose: This paper aims to use a data-driven approach towards optimizing construction operations. To this extent, it presents a machine learning (ML)-aided optimization approach, wherein the construction cost is predicted as a function of time, resources and environmental impact, which is further used as a surrogate model for cost optimization. Design/methodology/approach: Taking a dataset from literature, the paper has applied various ML algorithms, namely, simple and regularized linear regression, random forest, gradient boosted trees, neural network and Gaussian process regression (GPR) to predict the construction cost as a function of time, resources and environmental impact. Further, the trained models were used to optimize the construction cost applying single-objective (with and without constraints) and multi-objective optimizations, employing Bayesian optimization, particle swarm optimization (PSO) and non-dominated sorted genetic algorithm. Findings: The results presented in the paper demonstrate that the ensemble methods, such as gradient boosted trees, exhibit the best performance for construction cost prediction. Further, it shows that multi-objective optimization can be used to develop a Pareto front for two competing variables, such as cost and environmental impact, which directly allows a practitioner to make a rational decision. Research limitations/implications: Note that the sequential nature of events which dictates the scheduling is not considered in the present work. This aspect could be incorporated in the future to develop a robust scheme that can optimize the scheduling dynamically. Originality/value: The paper demonstrates that a ML approach coupled with optimization could enable the development of an efficient and economic strategy to plan the construction operations. © 2021, Emerald Publishing Limited.","Construction planning; Methodology; Optimization; Simulation","Emerald Group Holdings Ltd."
"Zhang C., Gao L., Li X., Shen W., Zhou J., Tan K.C.","Resetting Weight Vectors in MOEA/D for Multiobjective Optimization Problems With Discontinuous Pareto Front",2021,"IEEE Transactions on Cybernetics",,"10.1109/TCYB.2021.3062949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104576100&doi=10.1109%2fTCYB.2021.3062949&partnerID=40&md5=d4818947d50c45da16db3a85e0ca573c","When a multiobjective evolutionary algorithm based on decomposition (MOEA/D) is applied to solve problems with discontinuous Pareto front (PF), a set of evenly distributed weight vectors may lead to many solutions assembling in boundaries of the discontinuous PF. To overcome this limitation, this article proposes a mechanism of resetting weight vectors (RWVs) for MOEA/D. When the RWV mechanism is triggered, a classic data clustering algorithm DBSCAN is used to categorize current solutions into several parts. A classic statistical method called principal component analysis (PCA) is used to determine the ideal number of solutions in each part of PF. Thereafter, PCA is used again for each part of PF separately and virtual targeted solutions are generated by linear interpolation methods. Then, the new weight vectors are reset according to the interrelationship between the optimal solutions and the weight vectors under the Tchebycheff decomposition framework. Finally, taking advantage of the current obtained solutions, the new solutions in the decision space are updated via a linear interpolation method. Numerical experiments show that the proposed MOEA/D-RWV can achieve good results for bi-objective and tri-objective optimization problems with discontinuous PF. In addition, the test on a recently proposed MaF benchmark suite demonstrates that MOEA/D-RWV also works for some problems with other complicated characteristics. IEEE","Clustering algorithms; DBSCAN; Evolutionary computation; Heuristic algorithms; Machine learning; Machine learning algorithms; multiobjective evolutionary algorithm (MOEA); multiobjective evolutionary algorithm based on decomposition (MOEA/D); Optimization; Principal component analysis; principal component analysis (PCA); weight vectors","Institute of Electrical and Electronics Engineers Inc."
"Linets G., Voronkin R., Govorova S., Palkanov I., Grilo C.","The regression analysis of the data to determine the buffer size when serving a self-similar packets flow",2021,"CEUR Workshop Proceedings",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103573411&partnerID=40&md5=2278a7e5a73856281ed4af38fa917ad7","Using the methods of regression analysis on the basis of simulation data, a model for predicting the queue size of the input self-similar packet flow, distributed according to the Pareto law when it is transformed into a flow having an exponential distribution, is constructed. Since the amount of losses in the general case does not give any information about the efficiency of using the buffer memory space in the process of transforming a self-similar packet flow, a quality metric (penalty) was introduced to get the quality of the models after training, which is a complex score. This criterion considers both packet loss during functional transformations and ineffective use of the buffer space in switching nodes. The choice of the best model for predicting the queue size when servicing a self-similar packet flow was carried out using the following characteristics: the coefficient of determination; root-mean-square regression error; mean absolute error; the penalty score. The best in terms of the investigated characteristics are the models using the isotonic regression and the support vector regression. © 2020 this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","Hurst exponent; Machine learning; Packet loss; Pareto distribution; Penalty score; Quality metrics; Regression analysis; Self-similar traffic; Telecommunication network","CEUR-WS"
"Wang X., Wang X., Jin L., Lv R., Dai B., He M., Lv T.","Evolutionary Algorithm-Based and Network Architecture Search-Enabled Multiobjective Traffic Classification",2021,"IEEE Access",2,"10.1109/ACCESS.2021.3068267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103272511&doi=10.1109%2fACCESS.2021.3068267&partnerID=40&md5=ba2c4e7ab68207e139ad8a22362202c6","Network traffic classification technology plays an important role in network security management. However, the inherent limitations of traditional methods have become increasingly obvious, and they cannot address existing traffic classification tasks. Very recently, neural architecture search (NAS) has aroused widespread interest as a tool to automate the manual architecture construction process. To this end, this paper proposes NAS based on multiobjective evolutionary algorithms (MOEAs) to classify malicious network traffic. The main purpose is to simplify the search space by reducing the spatial ratio and number of channels of the model. In addition, the search strategy is changed in the effective search space, and the utilized strategies include EAs with the nondominated sorting genetic algorithm with the elite retention strategy (NSGA-II), strength Pareto evolutionary algorithm (SPEA-II) and multiobjective particle swarm optimization (MOPSO) to solve the formulated multiobjective NAS. Through comprehensive comparison of the population convergence times, model accuracies, Pareto optimality sets, model complexities and running speeds of the strategies, it is concluded that the model based on NSGA-II search has the best performance. The experimental results of the current machine learning algorithms and artificial learning methods based on the network are compared, showing that our method achieved better classification performance on two public datasets with a lower computational complexity, as mainly measured by FLOPs. Our approach is able to achieve 99.806% and 99.369% F1-score with 11.501 MB and 4.718 MB FLOPs on both IDS2012 and ISCX VPN dataset respectively. © 2013 IEEE.","Deep learning; multiobjective; neural architecture search; traffic classification","Institute of Electrical and Electronics Engineers Inc."
"Xu K., Du C., Li C., Zhu J., Zhang B.","Learning Implicit Generative Models by Teaching Density Estimators",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",1,"10.1007/978-3-030-67661-2_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103247705&doi=10.1007%2f978-3-030-67661-2_15&partnerID=40&md5=041002539752e58807dddc23b04beebf","Implicit generative models are difficult to train as no explicit density functions are defined. Generative adversarial nets (GANs) present a minimax framework to train such models, which however can suffer from mode collapse due to the nature of the JS-divergence. This paper presents a learning by teaching (LBT) approach to learning implicit models, which intrinsically avoids the mode collapse problem by optimizing a KL-divergence rather than the JS-divergence in GANs. In LBT, an auxiliary density estimator is introduced to fit the implicit model’s distribution while the implicit model teaches the density estimator to match the data distribution. LBT is formulated as a bilevel optimization problem, whose optimal generator matches the true data distribution. LBT can be naturally integrated with GANs to derive a hybrid LBT-GAN that enjoys complimentary benefits. Finally, we present a stochastic gradient ascent algorithm with unrolling to solve the challenging learning problems. Experimental results demonstrate the effectiveness of our method. © 2021, Springer Nature Switzerland AG.","Deep generative models; Generative adversarial nets; Mode collapse problem","Springer Science and Business Media Deutschland GmbH"
"Liu S., Vicente L.N.","The stochastic multi-gradient algorithm for multi-objective optimization and its application to supervised machine learning",2021,"Annals of Operations Research",3,"10.1007/s10479-021-04033-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102948968&doi=10.1007%2fs10479-021-04033-z&partnerID=40&md5=09b050908c2cfb0a28748455e26f5c51","Optimization of conflicting functions is of paramount importance in decision making, and real world applications frequently involve data that is uncertain or unknown, resulting in multi-objective optimization (MOO) problems of stochastic type. We study the stochastic multi-gradient (SMG) method, seen as an extension of the classical stochastic gradient method for single-objective optimization. At each iteration of the SMG method, a stochastic multi-gradient direction is calculated by solving a quadratic subproblem, and it is shown that this direction is biased even when all individual gradient estimators are unbiased. We establish rates to compute a point in the Pareto front, of order similar to what is known for stochastic gradient in both convex and strongly convex cases. The analysis handles the bias in the multi-gradient and the unknown a priori weights of the limiting Pareto point. The SMG method is framed into a Pareto-front type algorithm for calculating an approximation of the entire Pareto front. The Pareto-front SMG algorithm is capable of robustly determining Pareto fronts for a number of synthetic test problems. One can apply it to any stochastic MOO problem arising from supervised machine learning, and we report results for logistic binary classification where multiple objectives correspond to distinct-sources data groups. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Multi-objective optimization; Pareto front; Stochastic gradient descent; Supervised machine learning","Springer"
"Bai C., Li H., Zhang J., Huang L., Zhang L.","Unsupervised Adversarial Instance-Level Image Retrieval",2021,"IEEE Transactions on Multimedia",4,"10.1109/TMM.2021.3065578","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102700517&doi=10.1109%2fTMM.2021.3065578&partnerID=40&md5=81f80a127e59bf0bb14a6d407add1631","With the wide use of visual sensors in the Internet of Things (IoT) in the past decades, huge amounts of images are captured in people's daily lives, which poses challenges to traditional deep-learning-based image retrieval frameworks. Most such frameworks need a large amount of annotated training data, which are expensive. Moreover, machines still lack human intelligence, as illustrated by the fact that they pay less attention to the interesting regions that humans generally focus on when searching for images. Hence, this paper proposes a novel unsupervised framework that focuses on the instance object in the image and integrates human intelligence into the deep-learning-based image retrieval. This framework is called adversarial instance-level image retrieval (AILIR). We incorporate adversarial training and an attention mechanism into this framework that considers human intelligence with artificial intelligence. The generator and discriminator are redesigned to guarantee that the generator retrieves similar images while the discriminator selects unmatched images and creates an adversarial reward for the generator. A minimax game is conducted by the adversarial reward retrieval mechanism until the discriminator is unable to judge whether the image sequence retrieved matches the query. Comparison and ablation experiments on four benchmark datasets prove that the proposed adversarial training framework indeed improves instance retrieval and outperforms the state-of-the-art methods focused on instance retrieval. © 1999-2012 IEEE.","Generative adversarial training; human intelligence simulation; instance level image retrieval; unsupervised training","Institute of Electrical and Electronics Engineers Inc."
"Kaur M., Kumar V., Yadav V., Singh D., Kumar N., Das N.N.","Metaheuristic-based Deep COVID-19 Screening Model from Chest X-Ray Images",2021,"Journal of Healthcare Engineering",32,"10.1155/2021/8829829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102636307&doi=10.1155%2f2021%2f8829829&partnerID=40&md5=b58a6c44f3a724b43bcd769d46e52e2c","COVID-19 has affected the whole world drastically. A huge number of people have lost their lives due to this pandemic. Early detection of COVID-19 infection is helpful for treatment and quarantine. Therefore, many researchers have designed a deep learning model for the early diagnosis of COVID-19-infected patients. However, deep learning models suffer from overfitting and hyperparameter-tuning issues. To overcome these issues, in this paper, a metaheuristic-based deep COVID-19 screening model is proposed for X-ray images. The modified AlexNet architecture is used for feature extraction and classification of the input images. Strength Pareto evolutionary algorithm-II (SPEA-II) is used to tune the hyperparameters of modified AlexNet. The proposed model is tested on a four-class (i.e., COVID-19, tuberculosis, pneumonia, or healthy) dataset. Finally, the comparisons are drawn among the existing and the proposed models. © 2021 Manjit Kaur et al.",,"Hindawi Limited"
"Sun Z., Huang Y., Sun W., Chen Z.","A Posteriori Preference Multi-objective Optimization Using Machine Learning",2021,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-68884-4_40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102486155&doi=10.1007%2f978-3-030-68884-4_40&partnerID=40&md5=b41cae0162094b695c298a89f54dea1d","As a widely accepted way to solve multi-objective optimization problems (MOPs), evolutionary algorithms (EAs) can produce a well converged and well diverse Pareto Front (PF). However, only the partial PF around the decision maker (DM) preference is crucial in making decisions. The paper proposed an a posteriori method to help DMs to find solutions of interest (SOIs), i.e. solutions DMs interested in and to make well decisions. The proposed method is divided into three parts: the optimization part, learning part and operation part. With an EA, the optimization part works out optimal nondominated solutions. Then, the learning part trains an inverse mapping model according to the solutions. In the operation part, a set of probable preference vectors (PPVs) are generated to predict more SOIs. Finally, the feasibility of the proposed method is verified with the experiments on 2- and 3-objective test problems. © 2021, Springer Nature Switzerland AG.","A posteriori; Decision maker; Evolutionary computation; Multi-objective optimization; Preference; Random forest","Springer Science and Business Media Deutschland GmbH"
"Blott M., Vasilciuc A., Leeser M., Doyle L.","Evaluating Theoretical Baselines for ML Benchmarking Across Different Accelerators",2021,"IEEE Design and Test",,"10.1109/MDAT.2021.3063340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102320471&doi=10.1109%2fMDAT.2021.3063340&partnerID=40&md5=c160bd47e522fcabe07370d33ebc63f3","Benchmarking in Machine Learning (ML) becomes increasingly important as the design space complexity escalates, with a growing number of ML algorithms, optimization techniques and spectrum of novel hardware architectures. QuTiBench is a quantized, tiered benchmarking suite for ML on heterogeneous hardware. It is unique in that it provides a theoretical baseline for performance predictions across a broad spectrum of hardware architecture and takes optimizations into account. The goal of this theoretical baseline is to minimize the amount of experiments required and provide fast guidance on which hardware platforms with which optimizations work best for a given design task. In this article, we analyze how well this theoretical analysis can represent actual system behaviour. Our evaluation shows that the theoretical baselines can predict performance with a correlation coefficient between 0.64 and 0.96 across the selected hardware platforms. The optimization techniques are successfully represented and pareto-optimal design points instantly identified. Furthermore, we highlight a number of suggestions on how to improve prediction accuracy in the future. Thus, we believe that theoretical baselines can bring significant benefits to ML benchmarking in the future. IEEE","Benchmark testing; Benchmarking; Deep Learning; FPGA; GPU; Hardware; Micromechanical devices; Neural Nets; Optimization; Performance evaluation; Task analysis; Topology","IEEE Computer Society"
"Wang X., Hu T., Tang L.","A Multiobjective Evolutionary Nonlinear Ensemble Learning With Evolutionary Feature Selection for Silicon Prediction in Blast Furnace",2021,"IEEE Transactions on Neural Networks and Learning Systems",1,"10.1109/TNNLS.2021.3059784","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102311560&doi=10.1109%2fTNNLS.2021.3059784&partnerID=40&md5=f77fc7aa44c476f7d15b1b73b7114906","In the blast furnace ironmaking process, accurate prediction of silicon content in molten iron is of great significance for maintaining stable furnace conditions, improving hot metal quality, and reducing energy consumption. However, most of the current research works employ linear correlation coefficient methods to select input features in modeling, which may not fully take the nonlinear and coupling relationships between features into account. Therefore, this article considers the input feature selection issue of silicon content prediction model from a new perspective and proposes a multiobjective evolutionary nonlinear ensemble learning model with evolutionary feature selection mechanism (MOENE-EFS), in which extreme learning machine is adopted as the base learner. MOENE-EFS takes the input feature scheme of each base learner as well as their network structure and parameters as decision variables and proposes a modified nondominated sorting differential evolution algorithm to optimize two conflicting objectives, i.e., accuracy and diversity of base learners, simultaneously. Through the optimization, a set of Pareto optimal base learners with high accuracy and strong diversity can be obtained. Moreover, different from the linear ensemble methods commonly used in classical evolutionary ensemble learning, this article proposes a nonlinear ensemble method to combine the obtained base learners based on differential evolution. Experimental results indicate that the two proposed strategies, i.e., evolutionary feature selection and nonlinear ensemble, are very effective in improving the accuracy and stability of the prediction model. MOENE-EFS also outperforms the other prediction models in both benchmark data and practical industrial data. Furthermore, analysis on the input features of all Pareto optimal base learners shows that the evolutionary feature selection is capable of selecting essential features and is consistent with human experience, which indicates it is a promising method to deal with the input feature selection issue in silicon content prediction. IEEE","Extreme learning machine (ELM); Feature extraction; Iron; Metals; Modeling; multiobjective evolutionary ensemble learning; nonlinear ensemble; Optimization; Predictive models; Silicon; silicon content","Institute of Electrical and Electronics Engineers Inc."
"Abdollahzadeh B., Gharehchopogh F.S.","A multi-objective optimization algorithm for feature selection problems",2021,"Engineering with Computers",13,"10.1007/s00366-021-01369-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102301686&doi=10.1007%2fs00366-021-01369-9&partnerID=40&md5=07186ed60286a95e66eb9f009fc1cf25","Feature selection (FS) is a critical step in data mining, and machine learning algorithms play a crucial role in algorithms performance. It reduces the processing time and accuracy of the categories. In this paper, three different solutions are proposed to FS. In the first solution, the Harris Hawks Optimization (HHO) algorithm has been multiplied, and in the second solution, the Fruitfly Optimization Algorithm (FOA) has been multiplied, and in the third solution, these two solutions are hydride and are named MOHHOFOA. The results were tested with MOPSO, NSGA-II, BGWOPSOFS and B-MOABC algorithms for FS on 15 standard data sets with mean, best, worst, standard deviation (STD) criteria. The Wilcoxon statistical test was also used with a significance level of 5% and the Bonferroni–Holm method to control the family-wise error rate. The results are shown in the Pareto front charts, indicating that the proposed solutions' performance on the data set is promising. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Bonferroni–Holm; Family-wise error rate; Feature selection; Fruitfly optimization algorithm; Harris hawks optimization; Multiobjective","Springer Science and Business Media Deutschland GmbH"
"Alvar S.R., Bajic I.V.","Pareto-Optimal Bit Allocation for Collaborative Intelligence",2021,"IEEE Transactions on Image Processing",2,"10.1109/TIP.2021.3060875","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101819887&doi=10.1109%2fTIP.2021.3060875&partnerID=40&md5=959480ff679f6b6a2a541371b4a8c208","In recent studies, collaborative intelligence (CI) has emerged as a promising framework for deployment of Artificial Intelligence (AI)-based services on mobile/edge devices. In CI, the AI model (a deep neural network) is split between the edge and the cloud, and intermediate features are sent from the edge sub-model to the cloud sub-model. In this article, we study bit allocation for feature coding in multi-stream CI systems. We model task distortion as a function of rate using convex surfaces similar to those found in distortion-rate theory. Using such models, we are able to provide closed-form bit allocation solutions for single-task systems and scalarized multi-task systems. Moreover, we provide analytical characterization of the full Pareto set for 2-stream k -task systems, and bounds on the Pareto set for 3-stream 2-task systems. Analytical results are examined on a variety of DNN models from the literature to demonstrate wide applicability of the results. © 1992-2012 IEEE.","Bit allocation; collaborative intelligence; deep learning; multi objective optimization; multi-task learning; rate distortion optimization","Institute of Electrical and Electronics Engineers Inc."
"Koziel S., Pietrenko-Dabrowska A.","Rapid multi-criterial antenna optimization by means of pareto front triangulation and interpolative design predictors",2021,"IEEE Access",1,"10.1109/ACCESS.2021.3062449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101811975&doi=10.1109%2fACCESS.2021.3062449&partnerID=40&md5=9bc073a844531eaab94c0b1a90a40ab9","Modern antenna systems are designed to meet stringent performance requirements pertinent to both their electrical and field properties. The objectives typically stay in conflict with each other. As the simultaneous improvement of all performance parameters is rarely possible, compromise solutions have to be sought. The most comprehensive information about available design trade-offs can be obtained through multi-objective optimization (MO), typically in the form of a Pareto set. Notwithstanding, MO is a numerically challenging task, in a large part due to high CPU cost of evaluating the antenna properties, normally carried out through full-wave electromagnetic (EM) analysis. Surrogate-assisted procedures can mitigate the cost issue to a certain extent but construction of reliable metamodels is hindered by the curse of dimensionality, and often highly nonlinear antenna characteristics. This work proposes an alternative approach to MO of antennas. The major contribution of our work consists in establishing a deterministic machine learning procedure, which involves sequential generation of Pareto-optimal designs based on the knowledge gathered so far in the process (specifically, by triangulation of the already obtained Pareto set), and local surrogate-assisted refinement procedures. Our methodology allows for rendering uniformly-distributed Pareto designs at the cost of a few hundreds of antenna EM simulations, as demonstrated by means of three verification case studies. Benchmarking against state-of-the-art MO techniques is provided as well. © 2013 IEEE.","Antenna optimization; EM-driven design; multi-criterial design; Pareto front triangulation; surrogate modeling","Institute of Electrical and Electronics Engineers Inc."
"Ge Q., Sun H., Liu Z., Yang B., Lacasse S., Nadim F.","A novel approach for displacement interval forecasting of landslides with step-like displacement pattern",2021,"Georisk",2,"10.1080/17499518.2021.1892769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101731750&doi=10.1080%2f17499518.2021.1892769&partnerID=40&md5=d0531e6db89853d80f483506b0fa625a","Quantifying the uncertainties in the prediction of landslide displacement is important for making reliable predictions and for managing landslide risk. This study develops a novel approach for the interval prediction (i.e. uncertainty) of landslide with step-like displacement pattern in the Three Gorges Reservoir (TGR) area using Density-Based Spatial Clustering of Applications with Noise (DBSCAN), Synthetic Minority Oversampling Technique and Edited Nearest Neighbor (SMOTEENN) based Random Forest (RF) and bootstrap-Multilayer Perceptron (MLPs). DBSCAN was employed to carry out clustering analysis for different deformation states of the landslide with step-like displacement pattern. The SMOTEENN based RF classifier was trained to deal with imbalanced classification problems. A dynamic switching prediction scheme to construct high-quality Prediction Intervals (PIs) using bootstrap-MLPs was established. The concepts of Pareto front and Knee point were adopted to select the PIs that could provide the best compromise between reliability and accuracy. The proposed DBSCAN-RF-bootstrap-MLP method is illustrated and verified with one typical landslide with step-like displacement pattern, the Bazimen landslide from the TGR area in China. The method showed to perform well and provides the uncertainties associated with landslide displacement prediction for decision making. © 2021 Informa UK Limited, trading as Taylor & Francis Group.","Landslide displacement prediction; landslide risk; machine learning; prediction intervals; switched prediction; uncertainty","Taylor and Francis Ltd."
"Khan M.S.R., Hussain Z., Ahmad I.","Regional flood frequency analysis, using L-moments, artificial neural networks and ols regression, of various sites of Khyber-Pakhtunkhwa, Pakistan",2021,"Applied Ecology and Environmental Research",,"10.15666/aeer/1901_471489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100076624&doi=10.15666%2faeer%2f1901_471489&partnerID=40&md5=52ec6340d4a94762e4e7ccb696d183df","This study provides the results of flood frequency analysis adopting a regional approach using annual maxima’s of peak flows (APF) of eight catchments located on various small rivers of Khyber-Pakhtunkhwa, Pakistan. Initial screening reveals that the recorded data of APF for all catchments are independent, random, free from significant trend and identically distributed. L-moments based heterogeneity measure indicates that the study region is homogeneous. The results of |Z-Dist| statistic and L-moment ratio diagram being goodness of fit measures are in favor of Generalized Pareto (GPA) distribution among five candidates of regional distribution. For the ungauged sites, flood quantiles have been estimated through OLS regression and artificial neural networks (ANN). The estimated quantiles using ANN method are relatively accurate compared to OLS regression. The historical assessment indicates that quantile estimates obtained through ANN and index flood method are close to the highest recorded APF values for shorter as well as longer return periods for each site. © 2021, ALÖKI Kft., Budapest, Hungary.","Annual maximum peaks; GPA distribution; L-moments; Least squares regression; Machine learning methods; Ungauged sites","Corvinus University of Budapest"
"Farrell M.H., Liang T., Misra S.","Deep Neural Networks for Estimation and Inference",2021,"Econometrica",17,"10.3982/ECTA16901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100029361&doi=10.3982%2fECTA16901&partnerID=40&md5=2c955ed902bb84748ac64858b0d06404","We study deep neural networks and their use in semiparametric inference. We establish novel nonasymptotic high probability bounds for deep feedforward neural nets. These deliver rates of convergence that are sufficiently fast (in some cases minimax optimal) to allow us to establish valid second-step inference after first-step estimation with deep learning, a result also new to the literature. Our nonasymptotic high probability bounds, and the subsequent semiparametric inference, treat the current standard architecture: fully connected feedforward neural networks (multilayer perceptrons), with the now-common rectified linear unit activation function, unbounded weights, and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed-width, very deep networks. We establish the nonasymptotic bounds for these deep nets for a general class of nonparametric regression-type loss functions, which includes as special cases least squares, logistic regression, and other generalized linear models. We then apply our theory to develop semiparametric inference, focusing on causal parameters for concreteness, and demonstrate the effectiveness of deep learning with an empirical application to direct mail marketing. © 2021 The Econometric Society","convergence rates; Deep learning; neural networks; nonasymptotic bounds; program evaluation; rectified linear unit; semiparametric inference; treatment effects","Blackwell Publishing Ltd"
"Nguyen D.D., Nguyen L.","An Adaptive Control for Surrogate Assisted Multi-objective Evolutionary Algorithms",2021,"Advances in Intelligent Systems and Computing",1,"10.1007/978-981-15-8289-9_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098223798&doi=10.1007%2f978-981-15-8289-9_12&partnerID=40&md5=703a43cc1efedbe625ab03c6e8130294","Multi-objective problems (MOPs), a class of optimization problems in the real-world, have multiple conflicting objectives. Multi-objective evolutionary algorithms (MOEAs) are known as great potential algorithms to solve difficult MOPs. With MOEAs, based on the principle of population, we have a set of optimal solutions (feasible solution set) after the search. We often use the concept of dominance relationship in population, and it is not difficult to find out set of Pareto optimal solutions during generations. However, with expensive optimization problems in the real world, it has to use a lot of fitness function evaluations during the search. To avoid expensive physical experiments, we can use computer simulations methods to solve the difficult MOPs. In fact, this way often costs expensive in computation and times for the simulation. In these cases, researchers discussed on the usage of surrogate models for evolutionary algorithms, especially for MOEAs to minimize the number of fitness callings. There are a series of proposals which were introduced with the usage of RBF, PRS, Kriging, SVM models. With the concept of machine learning, these MOEAs can solve expensive MOPS effectively. However, with our analysis, we found that using a fixed ratio of fitness functions and surrogate functions may make the unbalance of exploitation and exploration of the evolutionary process. In this paper, we suggest to use an adaptive control to determine the effective ratio during the search. The proposal is confirmed though an experiment with standard measurements on well-known benchmark sets. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Adaptive control; K-RVEA; Kriging; Surrogate","Springer Science and Business Media Deutschland GmbH"
"Pinciroli L., Baraldi P., Shokry A., Zio E., Seraoui R., Mai C.","A semi-supervised method for the characterization of degradation of nuclear power plants steam generators",2021,"Progress in Nuclear Energy",3,"10.1016/j.pnucene.2020.103580","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097341306&doi=10.1016%2fj.pnucene.2020.103580&partnerID=40&md5=c4e0ef46f7203e9de035be3e62548df4","The digitalization of nuclear power plants, with the rapid growth of information technology, opens the door to the development of new methods of condition-based maintenance. In this work, a semi-supervised method for characterizing the level of degradation of nuclear power plant components using measurements collected during plant operational transients is proposed. It is based on the fusion of selected features extracted from the monitored signals. Feature selection is formulated as a multi-objective optimization problem. The objectives are the maximization of the feature monotonicity and trendability, and the maximization of a novel measure of correlation between the feature values and the results of non-destructive tests performed to assess the component degradation. The features of the Pareto optimal set are normalized and the component degradation level is defined as the median of the obtained values. The developed method is applied to real data collected from steam generators of pressurized water reactors. It is shown able to identify degradation level with errors comparable to those obtained by ad-hoc non-destructive tests. © 2020 Elsevier Ltd","Condition-based maintenance; Degradation assessment; Feature selection; Nuclear power plant; Semi-supervised; Steam generator","Elsevier Ltd"
"Pan W., Shen J., Xu Z.","An efficient algorithm for nonconvex-linear minimax optimization problem and its application in solving weighted maximin dispersion problem",2021,"Computational Optimization and Applications",1,"10.1007/s10589-020-00237-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095705826&doi=10.1007%2fs10589-020-00237-4&partnerID=40&md5=93d2f483470c7783ea228971813e0600","In this paper, we study the minimax optimization problem that is nonconvex in one variable and linear in the other variable, which is a special case of nonconvex-concave minimax problem, which has attracted significant attention lately due to their applications in modern machine learning tasks, signal processing and many other fields. We propose a new alternating gradient projection algorithm and prove that it can find an ε-first-order stationary solution within O(ε- 3) projected gradient step evaluations. Moreover, we apply it to solve the weighted maximin dispersion problem and the numerical results show that the proposed algorithm outperforms the state-of-the-art algorithms. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Complexity analysis; Nonconvex-linear minimax problem; Weighted maximin dispersion problem","Springer"
"Thrampoulidis E., Mavromatidis G., Lucchi A., Orehounig K.","A machine learning-based surrogate model to approximate optimal building retrofit solutions",2021,"Applied Energy",7,"10.1016/j.apenergy.2020.116024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095448472&doi=10.1016%2fj.apenergy.2020.116024&partnerID=40&md5=0197b112c7625d2a5d0790b77b232e75","The building sector has the highest share of operational energy consumption and greenhouse gas emissions among all sectors. Environmental targets set by many countries impose the need to improve the environmental footprint of the existing building stock. Building retrofit is considered one of the most promising solutions towards this direction. In this paper, a surrogate model for evaluating the necessary building envelope and energy system measures for building retrofit is presented. Artificial neural networks are exploited to build up this model in order to provide a good balance between accuracy and computational cost. The proposed model is trained and tested for the case study of the city of Zurich, in Switzerland, and is compared with one of the most advanced models for building retrofit that uses building simulation and optimization tools. The surrogate model operates on a smaller input set and the time required to derive retrofit solutions is reduced from 3.5 min to 16.4 μsec. Results show that the proposed model can provide significantly reduced computational cost without compromising accuracy for most of the retrofit dimensions. For instance, the retrofit costs and the energy system selections are approximated with an average accuracy of R2=0.9408 and f1score=0.9450, respectively. Finally, yet importantly, such surrogate retrofit models may effectively be used for bottom-up retrofit analyses for wide areas and can contribute towards accelerating the adoption of retrofit measures. © 2020 The Authors","Building retrofit; Energy efficiency; Machine learning; Multi-objective optimization; Pareto-optimal; Surrogate model","Elsevier Ltd"
"Wincott C., Collette M.","Communication of Design Space Relationships Learned by Bayesian Networks",2021,"Lecture Notes in Civil Engineering",,"10.1007/978-981-15-4680-8_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092789845&doi=10.1007%2f978-981-15-4680-8_2&partnerID=40&md5=ec62f052b9ac364831eee2ee34577661","Modern ship design often involves the automated creation of thousands of design alternatives; even when provided a Pareto front of optimal solutions designers may struggle to understand the differences in designs and the relationships of design variables. Machine learning Bayesian networks from automatically developed design data can allow us to analyze the designs, understand the variable relationships that drive their differences and optimalities, and lead engineers to better designs. However, the information about variable relationships in Bayesian network are encoded in difficult to interpret conditional probability tables (CPTs). Translation of a Bayesian network’s CPTs into simpler edge weights defining the strength of relationship between nodes allows engineers to more easily interpret and use the complex information encoded in the network through standard network analysis techniques. Bayesian networks developed from a multi-objective bulk carrier design problem developed by Sen are transformed to network adjacency matrices for such analysis in this work. © 2021, Springer Nature Singapore Pte Ltd.","Bayesian networks; Design space exploration","Springer Science and Business Media Deutschland GmbH"
"Li J., Zhu X., Li Y., Tong Y.W., Ok Y.S., Wang X.","Multi-task prediction and optimization of hydrochar properties from high-moisture municipal solid waste: Application of machine learning on waste-to-resource",2021,"Journal of Cleaner Production",22,"10.1016/j.jclepro.2020.123928","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090346771&doi=10.1016%2fj.jclepro.2020.123928&partnerID=40&md5=1359e39f097d33667b7f21bd245dd973","Hydrothermal carbonization (HTC) is a promising technology for valuable resources recovery from high-moisture wastes without pre-drying, while optimization of operational conditions for desired products preparation through experiments is always energy and time consuming. To accelerate the experiments in an efficient, sustainable, and economic way, machine learning (ML) tools were employed for bridging the inputs and outputs, which can realize the prediction of hydrochar properties, and development of ML-based optimization for achieving desired hydrochar. The results showed that deep neural network (DNN) model was the best one for joint prediction of both fuel properties (FP) and carbon capture and storage (CCS) stability of hydrochar with an average R2 and root mean squared error (RMSE) of 0.91 and 3.29. The average testing prediction errors for all the targets were below 20%, furtherly within 10% for HHV, carbon content and H/C predictions. ML-based feature analysis unveiled that both elementary composition and temperature were crucial to FP and CCS. Furthermore, a ML-based software interface was provided for practitioners and researchers to freely access. The insights and Pareto solution provided from ML-based multi-objective optimization benefitted desired hydrochar preparation for the potential application of fuel substitution or carbon sequestration in soil. © 2020 Elsevier Ltd","Biochar; Carbon sequestration; Hydrothermal carbonization; Multi-objective optimization; Renewable energy; Waste-to-energy","Elsevier Ltd"
"Roccetti M., Casini L., Delnevo G., Bonfante S.","Dimensionality reduction and the strange case of categorical data for predicting defective water meter devices",2021,"Advances in Intelligent Systems and Computing",1,"10.1007/978-3-030-55307-4_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089623314&doi=10.1007%2f978-3-030-55307-4_24&partnerID=40&md5=7217f81a65c5f7a77462521c1a763e1d","Further to an experiment conducted with a deep learning (DL) model, tailored to predict whether a water meter device would fail with passage of time, we came across a very strange case, occurring when we tried to strengthen the training activity of our classifier by using, besides the numerical measurements of consumed water, also other contextual available information, of categorical type. Surprisingly, that further categorical information did not improve the prediction accuracy, which instead fell down, sensibly. Recognized the problem as a case of an excessive increase of the dimensions of the space of data under observation, with a correspondent loss of statistical significance, we changed the training strategy. Observing that every categorical variable followed a quasi-Pareto distribution, we re-trained our DL models, for each single categorical variable, only on that fraction of meter devices (and corresponding measurements of consumed water) that exhibited the most frequent qualitative values for that categorical variable. This new strategy yielded a prediction accuracy level never reached before, amounting to a value of 87–88% on average. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.","Human data science; Human-machine-bigdata interaction loop; Machine learning design; Water metering and consumption","Springer"
"Karagoz G.N., Yazici A., Dokeroglu T., Cosar A.","A new framework of multi-objective evolutionary algorithms for feature selection and multi-label classification of video data",2021,"International Journal of Machine Learning and Cybernetics",6,"10.1007/s13042-020-01156-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086861707&doi=10.1007%2fs13042-020-01156-w&partnerID=40&md5=b4ce1f2ce9b1855650edbb7109d7580f","There are few studies in the literature to address the multi-objective multi-label feature selection for the classification of video data using evolutionary algorithms. Selecting the most appropriate subset of features is a significant problem while maintaining/improving the accuracy of the prediction results. This study proposes a framework of parallel multi-objective Non-dominated Sorting Genetic Algorithms (NSGA-II) for exploring a Pareto set of non-dominated solutions. The subsets of non-dominated features are extracted and validated by multi-label classification techniques, Binary Relevance (BR), Classifier Chains (CC), Pruned Sets (PS), and Random k-Labelset (RAkEL). Base classifiers such as Support Vector Machines (SVM), J48-Decision Tree (J48), and Logistic Regression (LR) are performed in the classification phase of the algorithms. Comprehensive experiments are carried out with local feature descriptors extracted from two multi-label data sets, the well-known MIR-Flickr dataset and a Wireless Multimedia Sensor (WMS) dataset that we have generated from our video recordings. The prediction accuracy levels are improved by 6.36% and 25.7% for the MIR-Flickr and WMS datasets respectively while the number of features is significantly reduced. The results verify that the algorithms presented in this new framework outperform the state-of-the-art algorithms. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Evolutionary; Feature selection; Machine learning; Multi-label classification; Multi-objective optimization","Springer Science and Business Media Deutschland GmbH"
"Yang Z., Zhang S., Li R., Li C., Wang M., Wang D., Zhang M.","Efficient resource-aware convolutional neural architecture search for edge computing with Pareto-Bayesian optimization",2021,"Sensors (Switzerland)",2,"10.3390/s21020444","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099242012&doi=10.3390%2fs21020444&partnerID=40&md5=6c4d51c4b8cdd58328163a2860f0dda9","With the development of deep learning technologies and edge computing, the combination of them can make artificial intelligence ubiquitous. Due to the constrained computation resources of the edge device, the research in the field of on-device deep learning not only focuses on the model accuracy but also on the model efficiency, for example, inference latency. There are many attempts to optimize the existing deep learning models for the purpose of deploying them on the edge devices that meet specific application requirements while maintaining high accuracy. Such work not only requires professional knowledge but also needs a lot of experiments, which limits the customization of neural networks for varied devices and application scenarios. In order to reduce the human intervention in designing and optimizing the neural network structure, multi-objective neural architecture search methods that can automatically search for neural networks featured with high accuracy and can satisfy certain hardware performance requirements are proposed. However, the current methods commonly set accuracy and inference latency as the performance indicator during the search process, and sample numerous network structures to obtain the required neural network. Lacking regulation to the search direction with the search objectives will generate a large number of useless networks during the search process, which influences the search efficiency to a great extent. Therefore, in this paper, an efficient resource-aware search method is proposed. Firstly, the network inference consumption profiling model for any specific device is established, and it can help us directly obtain the resource consumption of each operation in the network structure and the inference latency of the entire sampled network. Next, on the basis of the Bayesian search, a resource-aware Pareto Bayesian search is proposed. Accuracy and inference latency are set as the constraints to regulate the search direction. With a clearer search direction, the overall search efficiency will be improved. Furthermore, cell-based structure and lightweight operation are applied to optimize the search space for further enhancing the search efficiency. The experimental results demonstrate that with our method, the inference latency of the searched network structure reduced 94.71% without scarifying the accuracy. At the same time, the search efficiency increased by 18.18%. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Edge computing; Latency profiling model; Neural architecture search; Pareto-Bayesian optimization","MDPI AG"
"Le A.V., Kyaw P.T., Veerajagadheswar P., Muthugala M.A.V.J., Elara M.R., Kumar M., Khanh Nhan N.H.","Reinforcement learning-based optimal complete water-blasting for autonomous ship hull corrosion cleaning system",2021,"Ocean Engineering",7,"10.1016/j.oceaneng.2020.108477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097748502&doi=10.1016%2fj.oceaneng.2020.108477&partnerID=40&md5=b86e7a5a9aac54262577b576678d6b9e","Routine cleaning of the corroded ship hulls in dry dock maintenance guarantees the smooth operation of the shipping industry. Deploying the autonomous system to remove the corrosion by water-blasting is a feasible approach to ease the burden in manual operation and to reduce water, time, and energy consumption. In this paper, the water-blasting framework is proposed for a novel robot platform named Hornbill with the adhesion mechanism by permanent magnetic, self-localization by sensor fusion to navigate smoothly on a vertical surface. Hence, we propose a complete waypoint path planning (CWPP) to re-blast the self-synthesizing deep convolutional neural network (DCNN) based corrosion heatmap by initial-blasting. The optimal CWPP problem, including the shortest travel distance and shortest travel time to save water, power while ensuring visiting all predefined waypoints by benchmarking output, is modeled as the classic Travel Salesman Problem (TSP). Further, the Pareto-optimal trajectory for given TSP has been driven by the reinforcement learning (RL) technique with a proposed reward function based on the robot's operation during blasting. From the experimental results at the shipyard site, the proposed RL-based CWPP generates the Pareto-optimal trajectory that enables the water-blasting robot to spend about 10% of energy and 9% of water less than the second-best evolutionary-based optimization method in various workspaces. © 2020 Elsevier Ltd","Benchmarking blasting quality; Corrosion cleaning; Path planning; Reinforcement learning; Ship maintenance industry","Elsevier Ltd"
"Xie S.-M., Huang C.-Y.","Systematic comparisons of customer base prediction accuracy: Pareto/NBD versus neural network",2021,"Asia Pacific Journal of Marketing and Logistics",,"10.1108/APJML-09-2019-0520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084464436&doi=10.1108%2fAPJML-09-2019-0520&partnerID=40&md5=f8b7b5e82f9aedacea27c8d6b70f3337","Purpose: Predicting the inactivity and the repeat transaction frequency of a firm's customer base is critical for customer relationship management. The literature offers two main approaches to such predictions: stochastic modeling efforts represented by Pareto/NBD and machine learning represented by neural network analysis. As these two approaches have been developed and applied in parallel, this study systematically compares the two approaches in their prediction accuracy and defines the relatively appropriate implementation scenarios of each model. Design/methodology/approach: By designing a rolling exploration scheme with moving calibration/holdout combinations of customer data, this research explores the two approaches' relative performance by first utilizing three real world datasets and then a wide range of simulated datasets. Findings: The empirical result indicates that neither approach is dominant and identifies patterns of relative applicability between the two. Such patterns are consistent across the empirical and the simulated datasets. Originality/value: This study contributes to the literature by bridging two previously parallel analytical approaches applicable to customer base predictions. No prior research has rendered a comprehensive comparison on the two approaches' relative performance in customer base predictions as this study has done. The patterns identified in the two approaches' relative prediction performance provide practitioners with a clear-cut menu upon selecting approaches for customer base predictions. The findings further urge marketing scientists to reevaluate prior modeling efforts during the past half century by assessing what can be replaced by black boxes such as NNA and what cannot. © 2020, Emerald Publishing Limited.","Activity prediction; Neural network analysis; Pareto/NBD; Rolling comparison; Transaction frequency","Emerald Group Holdings Ltd."
"Hamad H.S., Kapur N., Khatir Z., Querin O.M., Thompson H.M., Wang Y., Wilson M.C.T.","Computational fluid dynamics analysis and optimisation of polymerase chain reaction thermal flow systems",2021,"Applied Thermal Engineering",1,"10.1016/j.applthermaleng.2020.116122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092747263&doi=10.1016%2fj.applthermaleng.2020.116122&partnerID=40&md5=9b3f925a7aff5a96fc16797c80258a63","A novel Computational Fluid Dynamics-enabled multi-objective optimisation methodology for Polymerase Chain Reaction flow systems is proposed and used to explore the effect of geometry, material and flow variables on the temperature uniformity, pressure drop and heating power requirements, in a prototype three-zone thermal flow system. A conjugate heat transfer model for the three-dimensional flow and heat transfer is developed and solved numerically using COMSOL Multiphysics® and the solutions obtained demonstrate how the design variables affect each of the three performance parameters. These show that choosing a substrate with high conductivity and small thickness, together with a small channel area, generally improves the temperature uniformity in each zone, while channel area and substrate conductivity have the key influences on pressure drop and heating power respectively. The multi-objective optimisation methodology employs accurate surrogate modelling facilitated by Machine Learning via fully-connected Neural Networks to create Pareto curves which demonstrate clearly the compromises that can be struck between temperature uniformity throughout the three zones and the pressure drop and heating power required. © 2020 Elsevier Ltd","Computational fluid dynamics; Machine learning; Multi-objective optimisation; PCR","Elsevier Ltd"
"Mishra B.B., Kumar A., Samui P., Roshni T.","Buckling of laminated composite skew plate using FEM and machine learning methods",2021,"Engineering Computations (Swansea, Wales)",1,"10.1108/EC-08-2019-0346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092490396&doi=10.1108%2fEC-08-2019-0346&partnerID=40&md5=2d862a20ad45e5d1fec98dceabb7f680","Purpose: The purpose of this paper is to attempt the buckling analysis of a laminated composite skew plate using the C0 finite element (FE) model based on higher-order shear deformation theory (HSDT) in conjunction with minimax probability machine regression (MPMR) and multivariate adaptive regression spline (MARS). Design/methodology/approach: HSDT considers the third-order variation of in-plane displacements which eliminates the use of shear correction factor owing to realistic parabolic transverse shear stresses across the thickness coordinate. At the top and bottom of the plate, zero transverse shear stress condition is imposed. C0 FE model based on HSDT is developed and coded in formula translation (FORTRAN). FE model is validated and found efficient to create new results. MPMR and MARS models are coded in MATLAB. Using skew angle (α), stacking sequence (Ai) and buckling strength (Y) as input parameters, a regression problem is formulated using MPMR and MARS to predict the buckling strength of laminated composite skew plates. Findings: The results of the MPMR and MARS models are in good agreement with the FE model result. MPMR is a better tool than MARS to analyze the buckling problem. Research limitations/implications: The present work considers the linear behavior of the laminated composite skew plate. Originality/value: To the authors’ best of knowledge, there is no work in the literature on the buckling analysis of a laminated composite skew plate using C0 FE formulation based on third-order shear deformation theory in conjunction with MPMR and MARS. These machine-learning techniques increase efficiency, reduce the computational time and reduce the cost of analysis. Further, an equation is generated with the MARS model via which the buckling strength of the laminated composite skew plate can be predicted with ease and simplicity. © 2020, Emerald Publishing Limited.","Buckling; Composite laminate; FEM; MARS; MPMR; Regression; Skew","Emerald Group Holdings Ltd."
"Cai T., Gao X., Song L., Liao M.","The multi-task learning with an application of Pareto improvement",2021,"ACM International Conference Proceeding Series",,"10.1145/3448734.3450463","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106010692&doi=10.1145%2f3448734.3450463&partnerID=40&md5=cbf50c2f2a3f96e4d480ee7288be8a0d","Multi-task learning is a promising field in machine learning, which aims to improve the performance of multiple related learning tasks by taking advantage of useful information between them. Multi-task learning is essentially equivalent to multi-objective optimization problem, the purpose is to find the most appropriate weight, and because the performance of many deep learning systems based on multi-task learning largely depends on the relative weight of each task loss. It's a problem that we need to study how to calculate the weight value under some constraint conditions by reasonable method. Therefore, this paper employs a powerful method based on convex optimization theory, whose purpose is to find the Pareto optimal solution and get the specific task loss weight. The optimization process is closely related to the gradient in deep learning. In addition, to improve the accuracy, we add the modules of gradient normalization and weight standardization. The experimental results show that the performance of our method is better than that of single task experiment or multi-task experiment under fixed weight, and multi-task experiment based on uncertainty based adaptive learning, and the accuracy is further improved after adding the above modules. © 2021 ACM.","multi-objective optimization; Multi-task learning; Pareto improvement","Association for Computing Machinery"
"Lam-Weil J., Laurent B., Loubes J.-M.","Minimax optimal goodness-of-fit testing for densities and multinomials under a local differential privacy constraint",2021,"Bernoulli",1,"10.3150/21-BEJ1358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120373578&doi=10.3150%2f21-BEJ1358&partnerID=40&md5=a18f59164dd86ae7acd6b409d0396941","Finding anonymization mechanisms to protect personal data is at the heart of recent machine learning research. Here, we consider the consequences of local differential privacy constraints on goodness-of-fit testing, that is, the statistical problem assessing whether sample points are generated from a fixed density f0, or not. The observations are kept hidden and replaced by a stochastic transformation satisfying the local differential privacy constraint. In this setting, we propose a testing procedure which is based on an estimation of the quadratic distance between the density f of the unobserved samples and f0. We establish an upper bound on the separation distance associated with this test, and a matching lower bound on the minimax separation rates of testing under non-interactive privacy in the case that f0 is uniform, in discrete and continuous settings. To the best of our knowledge, we provide the first minimax optimal test and associated private transformation under a local differential privacy constraint over Besov balls in the continuous setting, quantifying the price to pay for data privacy. We also present a test that is adaptive to the smoothness parameter of the unknown density and remains minimax optimal up to a logarithmic factor. Finally, we note that our results can be translated to the discrete case, where the treatment of probability vectors is shown to be equivalent to that of piecewise constant densities in our setting. That is why we work with a unified setting for both the continuous and the discrete cases. © 2022 ISI/BS.","Continuous; Discrete distributions; Goodness-of-fit testing; Local differential privacy; Minimax separation rates; Non-interactive privacy","International Statistical Institute"
"Zandigohar M., Erdogmus D., Schirner G.","NetCut: Real-Time DNN Inference Using Layer Removal",2021,"Proceedings -Design, Automation and Test in Europe, DATE",,"10.23919/DATE51398.2021.9474052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111038359&doi=10.23919%2fDATE51398.2021.9474052&partnerID=40&md5=5e86c99c0b52b75c23f7a30005dda5b0","Deep Learning plays a significant role in assisting humans in many aspects of their lives. As these networks tend to get deeper over time, they extract more features to increase accuracy at the cost of additional inference latency. This accuracy-performance trade-off makes it more challenging for Embedded Systems, as resource-constrained processors with strict deadlines, to deploy them efficiently. This can lead to selection of networks that can prematurely meet a specified deadline with excess slack time that could have potentially contributed to increased accuracy. In this work, we propose: (i) the concept of layer removal as a means of constructing TRimmed Networks (TRNs) that are based on removing problem-specific features of a pretrained network used in transfer learning, and (ii) NetCut, a methodology based on an empirical or an analytical latency estimator, which only proposes and retrains TRNs that can meet the application's deadline, hence reducing the exploration time significantly. We demonstrate that TRNs can expand the Pareto frontier that trades off latency and accuracy to provide networks that can meet arbitrary deadlines with potential accuracy improvement over off-the-shelf networks. Our experimental results show that such utilization of TRNs, while transferring to a simpler dataset, in combination with NetCut, can lead to the proposal of networks that can achieve relative accuracy improvement of up to 10.43% among existing off-the-shelf neural architectures while meeting a specific deadline, and 27x speedup in exploration time. © 2021 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Colucci A., Juhasz D., Mosbeck M., Marchisio A., Rehman S., Kreutzer M., Nadbath G., Jantsch A., Shafique M.","MLComp: A Methodology for Machine Learning-based Performance Estimation and Adaptive Selection of Pareto-Optimal Compiler Optimization Sequences",2021,"Proceedings -Design, Automation and Test in Europe, DATE",,"10.23919/DATE51398.2021.9474158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111031204&doi=10.23919%2fDATE51398.2021.9474158&partnerID=40&md5=5166e3a49efe6659679f7b50aca83d84","Embedded systems have proliferated in various consumer and industrial applications with the evolution of Cyber-Physical Systems and the Internet of Things. These systems are subjected to stringent constraints so that embedded software must be optimized for multiple objectives simultaneously, namely reduced energy consumption, execution time, and code size. Compilers offer optimization phases to improve these metrics. However, proper selection and ordering of them depends on multiple factors and typically requires expert knowledge. State-of-the-art optimizers facilitate different platforms and applications case by case, and they are limited by optimizing one metric at a time, as well as requiring a time-consuming adaptation for different targets through dynamic profiling. To address these problems, we propose the novel MLComp methodology, in which optimization phases are sequenced by a Reinforcement Learning-based policy. Training of the policy is supported by Machine Learning-based analytical models for quick performance estimation, thereby drastically reducing the time spent for dynamic profiling. In our framework, different Machine Learning models are automatically tested to choose the best-fitting one. The trained Performance Estimator model is leveraged to efficiently devise Reinforcement Learning-based multi-objective policies for creating quasi-optimal phase sequences. Compared to state-of-the-art estimation models, our Performance Estimator model achieves lower relative error (< 2%) with up to 50 × faster training time over multiple platforms and application domains. Our Phase Selection Policy improves execution time and energy consumption of a given code by up to 12% and 6%, respectively. The Performance Estimator and the Phase Selection Policy can be trained efficiently for any target platform and application domain. © 2021 EDAA.",,"Institute of Electrical and Electronics Engineers Inc."
"Hu Y., Zhang Y., Gong D.","Multiobjective Particle Swarm Optimization for Feature Selection with Fuzzy Cost",2021,"IEEE Transactions on Cybernetics",43,"10.1109/TCYB.2020.3015756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099727731&doi=10.1109%2fTCYB.2020.3015756&partnerID=40&md5=b6f2a1064467f4657741c71b8b404e02","Feature selection (FS) is an important data processing technique in the field of machine learning. There have been various FS methods, but all assume that the cost associated with a feature is precise, which restricts their real applications. Focusing on the FS problem with fuzzy cost, a fuzzy multiobjective FS method with particle swarm optimization, called PSOMOFS, is studied in this article. The proposed method develops a fuzzy dominance relationship to compare the goodness of candidate particles and defines a fuzzy crowding distance measure to prune the elitist archive and determine the global leader of particles. Also, a tolerance coefficient is introduced into the proposed method to ensure that the Pareto-optimal solutions obtained satisfy decision makers' preferences. The developed method is used to tackle a series of the UCI datasets and is compared with three fuzzy multiobjective evolutionary methods and three typical multiobjective FS methods. Experimental results show that the proposed method can achieve feature sets with superior performances in approximation, diversity, and feature cost. © 2013 IEEE.","Feature selection (FS); fuzzy cost; multiobjective optimization; particle swarm optimization (PSO)","Institute of Electrical and Electronics Engineers Inc."
"Hua Y., Liu Q., Hao K., Jin Y.","A Survey of Evolutionary Algorithms for Multi-Objective Optimization Problems with Irregular Pareto Fronts",2021,"IEEE/CAA Journal of Automatica Sinica",15,"10.1109/JAS.2021.1003817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099558274&doi=10.1109%2fJAS.2021.1003817&partnerID=40&md5=fb961d350eed3b154d51d7a2a662afc7","Evolutionary algorithms have been shown to be very successful in solving multi-objective optimization problems (MOPs). However, their performance often deteriorates when solving MOPs with irregular Pareto fronts. To remedy this issue, a large body of research has been performed in recent years and many new algorithms have been proposed. This paper provides a comprehensive survey of the research on MOPs with irregular Pareto fronts. We start with a brief introduction to the basic concepts, followed by a summary of the benchmark test problems with irregular problems, an analysis of the causes of the irregularity, and real-world optimization problems with irregular Pareto fronts. Then, a taxonomy of the existing methodologies for handling irregular problems is given and representative algorithms are reviewed with a discussion of their strengths and weaknesses. Finally, open challenges are pointed out and a few promising future directions are suggested. © 2014 Chinese Association of Automation.","Evolutionary algorithm; irregular Pareto fronts; machine learning; multiobjective optimization problems (MOPs)","Institute of Electrical and Electronics Engineers Inc."
"Brias A., Munch S.B.","Ecosystem based multi-species management using Empirical Dynamic Programming",2021,"Ecological Modelling",4,"10.1016/j.ecolmodel.2020.109423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099005730&doi=10.1016%2fj.ecolmodel.2020.109423&partnerID=40&md5=aee8cf11b626de8f4f17552095502930","Control theory and stochastic dynamic programming have long been used to develop optimal single-species management policies. However, most species interact with others through competition and predation as parts of complex ecosystems. As a consequence, it is unclear how far from optimal the single species policies currently in use actually are. Moreover, there are as yet no scalable algorithms for optimal ecosystem management. Here, we merge recently developed tools from machine learning and nonlinear dynamics to construct and evaluate near-optimal policies in multi-species systems. Specifically, a non-parametric model for the dynamics is estimated from time series data using Gaussian process-based dynamic modeling. A policy is then derived from the inferred dynamics using a temporal difference learning algorithm. Policy performance is benchmarked against single-species policies and the ad hoc ecosystem policies that have been previously offered. We found that EDP policies are closer to the true optimal policies than single-species policies in multi-species systems with two controls and three objectives. The Pareto fronts illustrate the flexibility of EDP policies compared with single-species policies. © 2021 Elsevier B.V.","Approximate dynamic programming; Gaussian process regression; Multi-objectives management; Multi-species management; Non-linear methods; Temporal difference learning","Elsevier B.V."
"Ma A., Wan Y., Zhong Y., Wang J., Zhang L.","SceneNet: Remote sensing scene classification deep learning network using multi-objective neural evolution architecture search",2021,"ISPRS Journal of Photogrammetry and Remote Sensing",16,"10.1016/j.isprsjprs.2020.11.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098986125&doi=10.1016%2fj.isprsjprs.2020.11.025&partnerID=40&md5=137757dea49a63b18ac14ee85eadbd8d","The scene classification approaches using deep learning have been the subject of much attention for remote sensing imagery. However, most deep learning networks have been constructed with a fixed architecture for natural image processing, and they are difficult to apply directly to remote sensing images, due to the more complex geometric structural features. Thus, there is an urgent need for automatic search for the most suitable neural network architecture from the image data in scene classification, in which a powerful search mechanism is required, and the computational complexity and performance error of the searched network should be balanced for a practical choice. In this article, a framework for scene classification network architecture search based on multi-objective neural evolution (SceneNet) is proposed. In SceneNet, the network architecture coding and searching are achieved using an evolutionary algorithm, which can implement a more flexible hierarchical extraction of the remote sensing image scene information. Moreover, the computational complexity and the performance error of the searched network are balanced by employing the multi-objective optimization method, and the competitive neural architectures are obtained in a Pareto solution set. The effectiveness of SceneNet is demonstrated by experimental comparisons with several deep neural networks designed by human experts. © 2020 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","deep neural network; evolutionary algorithm; multi-objective optimization; neural architecture search; remote sensing; Scene classification","Elsevier B.V."
"Qu H., Yin L., Tang X.","An automatic clustering method using multi-objective genetic algorithm with gene rearrangement and cluster merging",2021,"Applied Soft Computing",3,"10.1016/j.asoc.2020.106929","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096873098&doi=10.1016%2fj.asoc.2020.106929&partnerID=40&md5=d3f75e3dfb571dcb1769e3d887b84533","As an unsupervised approach of machine learning, clustering is an important method to understand and learn structural information from data. However, current adaptive clustering approach based on multi-objective genetic algorithm have two apparent limitations. The first is that prior knowledge, i.e., sample information is needed to get the correct cluster number. The second is that no effective method can be found to select the best clustering solution from the Pareto Optimal Front (POF) generated by a multi-objective optimization. These problems become severer in applications applied on non-category datasets. Therefore, the primary goal of this research is to establish a genetic optimization based multi-objective clustering framework, in which multiple clustering validity indexes (CVIs) can be tested simultaneously to automatically obtain the optimal cluster number without knowing any sample label information in advance. In this effort, we will not only be able to consider clustering measurements such as cluster cohesion and separation, but also take other aspects, such as compactness, connectivity, variation among data elements, into consideration as well. Then, we aim to design a procedure to recommend three best solutions from the POF by using appropriate combination of CVIs without increasing computational cost. This procedure is expected to control the cluster number in a reasonable range and consequently decrease the difficulty in best solution recommendation. Finally, since we have the knowledge that using gene rearrangement in the genetic optimization does not affect partition, we take this advantage to merge clusters effectively and significantly speed the convergence of the algorithm. Our approach can outperform the state-of-the-art counterparts across diverse benchmark datasets in terms of partitioning accuracy and performance, as demonstrated in three experiments conducted on both artificial and typical real-world datasets. © 2020 Elsevier B.V.","Automatic clustering; Gene rearrangement; Genetic algorithm; Multi-objective optimization","Elsevier Ltd"
"Daksha C.M., Yeon J., Chowdhury S.C., Gillespie J.W., Jr.","Automated ReaxFF parametrization using machine learning",2021,"Computational Materials Science",8,"10.1016/j.commatsci.2020.110107","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095592420&doi=10.1016%2fj.commatsci.2020.110107&partnerID=40&md5=355a40a6fa6cc5816b88a79812800e4b","Molecular dynamics (MD) simulation requires an accurate potential energy function to describe atomic interactions of interest. Optimization of the function's numerous parameters is often time-consuming and labor-intensive. In this study, a machine learning inspired evolutionary parametrization technique using the genetic algorithm is developed to decrease the time required to optimize the parameters of the ReaxFF interatomic potential. An artificial neural network is used as a surrogate for the ReaxFF potential to reduce computational time. Changes to the genetic algorithm are incrementally benchmarked for accuracy and time cost with respect to a moderately complex zinc-oxide model to find superior operators for ReaxFF parametrization. It is found that utilizing an artificial neural network significantly boosted performance, as measured by the final total error and the rate of decrease of total error with respect to time. The double-Pareto probability density based crossover operator and a multiple standard deviation based Gaussian mutation scheme outperform their counterparts. The computational time cost to achieve the same level of accuracy relative to manual training is decreased from months to days. © 2020 Elsevier B.V.","Genetic algorithm; Machine learning; Molecular dynamics simulation; Neural network; Reactive potential","Elsevier B.V."
"Piltaver R., Luštrek M., Džeroski S., Gjoreski M., Gams M.","Learning comprehensible and accurate hybrid trees",2021,"Expert Systems with Applications",3,"10.1016/j.eswa.2020.113980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091335378&doi=10.1016%2fj.eswa.2020.113980&partnerID=40&md5=c8d0860234cd9faa00802c2909c69b9a","Finding the best classifiers according to different criteria is often performed by a multi-objective machine learning algorithm. This study considers two criteria that are usually treated as the most important when deciding which classifier to apply in practice: comprehensibility and accuracy. A model that offers a broad range of trade-offs between the two criteria is introduced because they conflict; i.e., increasing one decreases the other. The choice of the model is motivated by the fact that domain experts often formalize decisions based on knowledge that can be represented by comprehensible rules and some tacit knowledge. This approach is mimicked by a hybrid tree that consists of comprehensible parts that originate from a regular classification tree and incomprehensible parts that originate from an accurate black-box classifier. An empirical evaluation on 23 UCI datasets shows that the hybrid trees provide trade-offs between the accuracy and comprehensibility that are not possible using traditional machine learning models. A corresponding hybrid-tree comprehensibility metric is also proposed. Furthermore, the paper presents a novel algorithm for learning MAchine LeArning Classifiers with HybrId TrEes (MALACHITE), and it proves that the algorithm finds a complete set of nondominated hybrid trees with regard to their accuracy and comprehensibility. The algorithm is shown to be faster than the well-known multi-objective evolutionary optimization algorithm NSGA-II for trees with moderate size, which is a prerequisite for comprehensibility. On the other hand, the MALACHITE algorithm can generate considerably larger hybrid-trees than a naïve exhaustive search algorithm in a reasonable amount of time. In addition, an interactive iterative data mining process based on the algorithm is proposed that enables inspection of the Pareto set of hybrid trees. In each iteration, the domain expert analyzes the current set of nondominated hybrid trees, infers domain relations, and sets the parameters for the next machine learning step accordingly. © 2020 Elsevier Ltd","Accuracy; Classification; Comprehensibility; Hybrid tree; Multi-objective learning","Elsevier Ltd"
"Asilian Bidgoli A., Ebrahimpour-Komleh H., Rahnamayan S.","Reference-point-based multi-objective optimization algorithm with opposition-based voting scheme for multi-label feature selection",2021,"Information Sciences",8,"10.1016/j.ins.2020.08.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089748498&doi=10.1016%2fj.ins.2020.08.004&partnerID=40&md5=e3508380de2478c9ef34851d33997e39","Multi-label classification is a machine learning task to construct a model for assigning an entity in the dataset to two or more class labels. In order to improve the performance of multi-label classification, a multi-objective feature selection algorithm has been proposed in this paper. Feature selection as a preprocessing task for Multi-label classification problems aims to choose a subset of relevant features. Selecting a small number of high-quality features decreases the computational cost and at the same time maximizes the classification performance. However extreme decreasing the number of features causes the failure of classification. As a result, feature selection has two conflicting objectives, namely, minimizing the classification error and minimizing the number of selected features. This paper proposes a multi-objective optimization algorithm to tackle the multi-label feature selection. The task is to find a set of solutions (a subset of features) in a sophisticated large-scale search space using a reference-based multi-objective optimization method. The proposed algorithm utilizes an opposition-based binary operator to generate more diverse solutions. Injection of extreme point of the Pareto-front is another component of the algorithm which aims to find feature subsets with less classification error. The proposed method is compared with two other existing methods on eight multi-label benchmark datasets. The experimental results show that the proposed method outperforms existing algorithms in terms of various multi-objective evaluation measures, such as Hyper-volume indicator, Pure diversity, Two-set coverage, and Pareto-front proportional contribution. The proposed method leads to get a set of well-distributed trade-off solutions which reach less classification error in comparing with competitors, even with the fewer number of features. © 2020 Elsevier Inc.","Evolutionary algorithm; Feature selection; Multi-label classification; Multi-objective optimization; Opposition-based computation","Elsevier Inc."
"Cai Z., Liu Z., Maleki S., Musuvathi M., Mytkowicz T., Nelson J., Saarikivi O.","Synthesizing optimal collective algorithms",2021,"Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPOPP",,"10.1145/3437801.3441620","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101726262&doi=10.1145%2f3437801.3441620&partnerID=40&md5=2ffe866c7e1c1428128b0f0c8a2ede87","Collective communication algorithms are an important component of distributed computation. Indeed, in the case of deep-learning, collective communication is the Amdahl's bottleneck of data-parallel training. This paper introduces SCCL (for Synthesized Collective Communication Library), a systematic approach to synthesizing collective communication algorithms that are explicitly tailored to a particular hardware topology. SCCL synthesizes algorithms along the Pareto-frontier spanning from latency-optimal to bandwidth-optimal implementations of a collective. The paper demonstrates how to encode the synthesis problem as a quantifier-free SMT formula which can be discharged to a theorem prover. We show how our carefully built encoding enables SCCL to scale. We synthesize novel latency and bandwidth optimal algorithms not seen in the literature on two popular hardware topologies. We also show how SCCL efficiently lowers algorithms to implementations on two hardware architectures (NVIDIA and AMD) and demonstrate competitive performance with hand optimized collective communication libraries. © 2021 ACM.","collective communication; GPU; interconnection; network; synthesis","Association for Computing Machinery"
"Yu X., Sreekanth J., Cui T., Pickett T., Xin P.","Adaptative DNN emulator-enabled multi-objective optimization to manage aquifer−sea flux interactions in a regional coastal aquifer",2021,"Agricultural Water Management",3,"10.1016/j.agwat.2020.106571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092268977&doi=10.1016%2fj.agwat.2020.106571&partnerID=40&md5=9702a04081dd027e05c139e5356576c0","This study focuses on the analyses of influx and efflux of groundwater at the aquifer−sea interface in response to the total groundwater extraction from a regional coastal aquifer. The groundwater planning and management goal is formulated as a multi-objective optimization problem to optimize the total pumping, groundwater influx and efflux through the coastal boundary. A four-stage optimization strategy is implemented for solving this optimization problem, whereby the first three stages are the iterative optimizations using the proposed Multi-Objective Particle Swarm Optimization algorithm and the analysis of Pareto-optimal solutions, and the last stage is the selection of one bargaining solution using the Kalai-Smorodinsky approach considering compromises among multiple objectives. In order to improve the efficiency of the simulation-optimization model, Deep Neural Networks emulators are fitted to approximate individual optimization objective, and a novel dynamic sampling strategy is applied to adaptively improve the accuracy of the emulators. This study demonstrates that accurate and efficient emulators can be achieved for the regional coastal aquifer with zone-based pumping rate multipliers from eight bands (Band 1 to Band 8) of increasing distance from the coastal boundary as the decision variables. The results from the Pareto-front suggest that the abstractions of Band 2 (close to the sea) can be reduced to the lower boundary of the rate multiplier (0.5) whereas the abstraction of farther bands can be significantly enhanced. The water influx through the coastal boundary was decreased by 15.69% under the slight compromise of the total pumping and water efflux by the selected compromising pumping pattern in the regional model. The final Pareto-optimal solution set and the compromised solution provide valuable information for the groundwater manager to plan sustainable groundwater use. The proposed simulation-optimization approach used in this study can be applied for a wide range of groundwater management problems. © 2020 Elsevier B.V.","Deep neural networks; Kalai−Smorodinsky bargaining solution; Machine learning; Multi-Objective Particle Swarm Optimization; Pumping optimization; Regional groundwater modelling","Elsevier B.V."
"Shi Y., Davaslioglu K., Sagduyu Y.E.","Generative Adversarial Network in the Air: Deep Adversarial Learning for Wireless Signal Spoofing",2021,"IEEE Transactions on Cognitive Communications and Networking",8,"10.1109/TCCN.2020.3010330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102275140&doi=10.1109%2fTCCN.2020.3010330&partnerID=40&md5=c88f2d80bda24826a03cf2d8fe8e2011","The spoofing attack is critical to bypass physical-layer signal authentication. This paper presents a deep learning-based spoofing attack to generate synthetic wireless signals that cannot be statistically distinguished from intended transmissions. The adversary is modeled as a pair of a transmitter and a receiver that build the generator and discriminator of the generative adversarial network, respectively, by playing a minimax game over the air. The adversary transmitter trains a deep neural network to generate the best spoofing signals and fool the best defense trained as another deep neural network at the adversary receiver. Each node (defender or adversary) may have multiple transmitter or receiver antennas. Signals are spoofed by jointly capturing waveform, channel, and radio hardware effects that are inherent to wireless signals under attack. Compared with spoofing attacks using random or replayed signals, the proposed attack increases the probability of misclassifying spoofing signals as intended signals for different network topology and mobility patterns. The adversary transmitter can increase the spoofing attack success by using multiple antennas, while the attack success decreases when the defender receiver uses multiple antennas. For practical deployment, the attack implementation on embedded platforms demonstrates the low latency of generating or classifying spoofing signals. © 2015 IEEE.","Adversarial machine learning; deep learning; generative adversarial network (GAN); spoofing attack","Institute of Electrical and Electronics Engineers Inc."
"Asadi S., Roshan S., Kattan M.W.","Random forest swarm optimization-based for heart diseases diagnosis",2021,"Journal of Biomedical Informatics",5,"10.1016/j.jbi.2021.103690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100626962&doi=10.1016%2fj.jbi.2021.103690&partnerID=40&md5=3c7adbd6cc709fcffe21f9fb5c0552b4","Heart disease has been one of the leading causes of death worldwide in recent years. Among diagnostic methods for heart disease, angiography is one of the most common methods, but it is costly and has side effects. Given the difficulty of heart disease prediction, data mining can play an important role in predicting heart disease accurately. In this paper, by combining the multi-objective particle swarm optimization (MOPSO) and Random Forest, a new approach is proposed to predict heart disease. The main goal is to produce diverse and accurate decision trees and determine the (near) optimal number of them simultaneously. In this method, an evolutionary multi-objective approach is used instead of employing a commonly used approach, i.e., bootstrap, feature selection in the Random Forest, and random number selection of training sets. By doing so, different training sets with different samples and features for training each tree are generated. Also, the obtained solutions in Pareto-optimal fronts determine the required number of training sets to build the random forest. By doing so, the random forest's performance can be enhanced, and consequently, the prediction accuracy will be improved. The proposed method's effectiveness is investigated by comparing its performance over six heart datasets with individual and ensemble classifiers. The results suggest that the proposed method with the (near) optimal number of classifiers outperforms the random forest algorithm with different classifiers. © 2021 Elsevier Inc.","Data mining; Diversity; Ensemble learning; Heart disease; Random forest","Academic Press Inc."
"Li Y., Zhao G., Zhang Q., Lin Y., Wang M.","SAP-cGAN: Adversarial learning for breast mass segmentation in digital mammogram based on superpixel average pooling",2021,"Medical Physics",2,"10.1002/mp.14671","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099024990&doi=10.1002%2fmp.14671&partnerID=40&md5=86f64b10333b1449178233e8096b2b57","Purpose: Breast mass segmentation is a prerequisite step in the use of computer-aided tools designed for breast cancer diagnosis and treatment planning. However, mass segmentation remains challenging due to the low contrast, irregular shapes, and fuzzy boundaries of masses. In this work, we propose a mammography mass segmentation model for improving segmentation performance. Methods: We propose a mammography mass segmentation model called SAP-cGAN, which is based on an improved conditional generative adversarial network (cGAN). We introduce a superpixel average pooling layer into the cGAN decoder, which utilizes superpixels as a pooling layout to improve boundary segmentation. In addition, we adopt a multiscale input strategy to enable the network to learn scale-invariant features with increased robustness. The performance of the model is evaluated with two public datasets: CBIS-DDSM and INbreast. Moreover, ablation analysis is conducted to evaluate further the individual contribution of each block to the performance of the network. Results: Dice and Jaccard scores of 93.37% and 87.57%, respectively, are obtained for the CBIS-DDSM dataset. The Dice and Jaccard scores for the INbreast dataset are 91.54% and 84.40%, respectively. These results indicate that our proposed model outperforms current state-of-the-art breast mass segmentation methods. The superpixel average pooling layer and multiscale input strategy has improved the Dice and Jaccard scores of the original cGAN by 7.8% and 12.79%, respectively. Conclusions: Adversarial learning with the addition of a superpixel average pooling layer and multiscale input strategy can encourage the Generator network to generate masks with increased realism and improve breast mass segmentation performance through the minimax game between the Generator network and Discriminator network. © 2020 American Association of Physicists in Medicine","breast mass segmentation; generative adversarial network; multiscale features; superpixel pooling","John Wiley and Sons Ltd"
"Akbar A., Ibrar M., Jan M.A., Bashir A.K., Wang L.","SDN-Enabled Adaptive and Reliable Communication in IoT-Fog Environment Using Machine Learning and Multiobjective Optimization",2021,"IEEE Internet of Things Journal",11,"10.1109/JIOT.2020.3038768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098793301&doi=10.1109%2fJIOT.2020.3038768&partnerID=40&md5=3b8cc5aad32f4ff7b67cbdf8081e2f01","The Internet-of-Things (IoT) devices, backed by resourceful fog computing, are capable of meeting the requirements of computationally-intensive tasks. However, many existing IoT applications are unable to perform well, due to different Quality-of-Service (QoS) requirements, while communicating with the fog server. Besides, constantly changing traffic demands of applications is another challenge. For example, the demand for real-time applications includes communicating over a path that is less prone to delay, and applications that offload computationally intensive tasks to the fog server need a reliable path that has a lower probability of link failure. This results in a tradeoff between conflicting objectives that are constantly evolving, i.e., minimizing end-to-end delay and maximizing the reliability of paths between IoT devices and the fog server. We propose a novel approach that takes advantage of machine learning (ML) and multiobjective optimization (MOO)-based techniques. The reliability of links is evaluated using an ML-based algorithm in an software-defined network (SDN)-enabled multihop scenario for the IoT-fog environment. By considering the two conflicting objectives, the MOO algorithm is used to find the Pareto-optimal paths. Our experimental evaluation considers two applications with different QoS requirements-a real-time application (App-1) using UDP sockets and a task offloading application (App-2) using TCP sockets. Our results show that: 1) the tradeoff between the two objectives can be optimized and 2) the SDN controller was able to make adaptive decision on-the-fly to choose the best path from the Pareto-optimal set. The App-1 communicating over the selected path finished its execution in 13% less time than communicating over the shortest path. The App-2 had 41% less packet loss using the selected path compared to using the shortest path. © 2014 IEEE.","Fog computing; Internet of Things (IoT); machine learning (ML); multiobjective optimization (MOO); software-defined networks (SDNs)","Institute of Electrical and Electronics Engineers Inc."
"Jesus J., Canuto A., Araújo D.","An exploratory analysis of data noisy scenarios in a Pareto-front based dynamic feature selection method",2021,"Applied Soft Computing",2,"10.1016/j.asoc.2020.106951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097712368&doi=10.1016%2fj.asoc.2020.106951&partnerID=40&md5=ad0acaa3f84356eb7dce6aef1c0f0d8d","Feature selection has become a mandatory step in several data exploration and Machine Learning applications since data quality can have a strong impact in the performance of machine learning models. Many feature selection strategies have been developed in the past decades, using different criteria to select the most relevant features. The use of dynamic feature selection, however, has showed that the use of multiple simultaneously criteria to determine the best attribute subset for similar instances can deliver encouraging results. In this context, this paper proposes to analyze the performance of a pareto-front based dynamic feature selection (PF-DFS) method under data noise scenarios. In order to do this, we intentionally added noise in 15 datasets and evaluated the PF-DFS performance in order to measure its stability under two different data noise scenarios. The obtained results are compared to some state-of-the-art algorithms and show that, in terms of accuracy, the PF-DFS method is more robust to the other methods for the majority of the analyzed scenarios. © 2020","Clustering algorithms; Feature selection; Noisy data; Pareto-front selection","Elsevier Ltd"
"Langer S.","Analysis of the rate of convergence of fully connected deep neural network regression estimates with smooth activation function",2021,"Journal of Multivariate Analysis",7,"10.1016/j.jmva.2020.104695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097397602&doi=10.1016%2fj.jmva.2020.104695&partnerID=40&md5=89221e1699626300b2e439bba905c201","This article contributes to the current statistical theory of deep neural networks (DNNs). It was shown that DNNs are able to circumvent the so-called curse of dimensionality in case that suitable restrictions on the structure of the regression function hold. In most of those results the tuning parameter is the sparsity of the network, which describes the number of non-zero weights in the network. This constraint seemed to be the key factor for the good rate of convergence results. Recently, the assumption was disproved. In particular, it was shown that simple fully connected DNNs can achieve the same rate of convergence. Those fully connected DNNs are based on the unbounded ReLU activation function. In this article we extend the results to smooth activation functions, i.e., to the sigmoid activation function. It is shown that estimators based on fully connected DNNs with sigmoid activation function also achieve the minimax rates of convergence (up to lnn-factors). In our result the number of hidden layers is fixed, the number of neurons per layer tends to infinity for sample size tending to infinity and a bound for the weights in the network is given. © 2020 Elsevier Inc.","Curse of dimensionality; Deep learning; Neural networks; Nonparametric regression; Rate of convergence","Academic Press Inc."
"Mehrotra A., Celis L.E.","Mitigating bias in set selection with noisy protected attributes",2021,"FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",,"10.1145/3442188.3445887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101951718&doi=10.1145%2f3442188.3445887&partnerID=40&md5=7bd1d01c6e247dd00a5c6168c5647674","Subset selection algorithms are ubiquitous in AI-driven applications, including, online recruiting portals and image search engines, so it is imperative that these tools are not discriminatory on the basis of protected attributes such as gender or race. Currently, fair subset selection algorithms assume that the protected attributes are known as part of the dataset. However, protected attributes may be noisy due to errors during data collection or if they are imputed (as is often the case in real-world settings). While a wide body of work addresses the effect of noise on the performance of machine learning algorithms, its effect on fairness remains largely unexamined. We find that in the presence of noisy protected attributes, in attempting to increase fairness without considering noise, one can, in fact, decrease the fairness of the result! Towards addressing this, we consider an existing noise model in which there is probabilistic information about the protected attributes (e.g., [19, 32, 44, 56]), and ask is fair selection possible under noisy conditions? We formulate a ""denoised""selection problem which functions for a large class of fairness metrics; given the desired fairness goal, the solution to the denoised problem violates the goal by at most a small multiplicative amount with high probability. Although this denoised problem turns out to be NP-hard, we give a linear-programming based approximation algorithm for it. We evaluate this approach on both synthetic and real-world datasets. Our empirical results show that this approach can produce subsets which significantly improve the fairness metrics despite the presence of noisy protected attributes, and, compared to prior noise-oblivious approaches, has better Pareto-tradeoffs between utility and fairness. © 2021 ACM.",,"Association for Computing Machinery, Inc"
"Fitch N., Clancy D.","Agent Decision Processes Using Double Deep Q-Networks + Minimax Q- Learning",2021,"IEEE Aerospace Conference Proceedings",,"10.1109/AERO50100.2021.9438149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111347941&doi=10.1109%2fAERO50100.2021.9438149&partnerID=40&md5=71d46502b7a0f1041ede6b51134c0ac5","Aerospace battle scenarios represent a challenging modeling effort, often requiring large, continuous, and simultaneous state and/ or action spaces with imperfect information. We model a battle as a Multi-Stage Markov Stochastic Game (MSMSG) and facilitate agent decision making using a Double Deep Q-Network (DDQN) paradigm with Minimax Q-Learning. We demonstrate our model performance in contrast with a DDQN agent trained using a traditional Q-learning algorithm in a 1D dynamic battle environment. Preliminary findings suggest that the DDQN + Minimax-Q agent is more robust to parameter tuning and can learn true optimal mixed strategies compared to its traditional Q-learning counterpart. © 2021 IEEE.",,"IEEE Computer Society"
"Wang T., Lin Q.","Hybrid predictive models: when an interpretable model collaborates with a black-box model",2021,"Journal of Machine Learning Research",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112424553&partnerID=40&md5=7815f2f418fbb2e2798697e31b708e16","Interpretable machine learning has become a strong competitor for black-box models. However, the possible loss of the predictive performance for gaining understandability is often inevitable, especially when it needs to satisfy users with diverse backgrounds or high standards for what is considered interpretable. This tension puts practitioners in a dilemma of choosing between high accuracy (black-box models) and interpretability (interpretable models). In this work, we propose a novel framework for building a Hybrid Predictive Model that integrates an interpretable model with any pre-trained black-box model to combine their strengths. The interpretable model substitutes the black-box model on a subset of data where the interpretable model is most competent, gaining transparency at a low cost of the predictive accuracy. We design a principled objective function that considers predictive accuracy, model interpretability, and model transparency (defined as the percentage of data processed by the interpretable substitute.) Under this framework, we propose two hybrid models, one substituting with association rules and the other with linear models, and design customized training algorithms for both models. We test the hybrid models on structured data and text data where interpretable models collaborate with various state-of-the-art black-box models. Results show that hybrid models obtain an efficient trade-off between transparency and predictive performance, characterized by pareto frontiers. Finally, we apply the proposed model on a real-world patients dataset for predicting cardiovascular disease and propose multi-model Pareto frontiers to assist model selection in real applications. © 2021 Tong Wang and Qihang Lin.","Association rules; Hybrid model; Interpretable machine learning; Linear model; Pareto frontier","Microtome Publishing"
"Liu Y., Guo B., Zhang D., Zeghlache D., Chen J., Hu K., Zhang S., Zhou D., Yu Z.","Knowledge Transfer with Weighted Adversarial Network for Cold-Start Store Site Recommendation",2021,"ACM Transactions on Knowledge Discovery from Data",,"10.1145/3442203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105458040&doi=10.1145%2f3442203&partnerID=40&md5=04b1639aa4c1acde6956360df23ea3f4","Store site recommendation aims to predict the value of the store at candidate locations and then recommend the optimal location to the company for placing a new brick-and-mortar store. Most existing studies focus on learning machine learning or deep learning models based on large-scale training data of existing chain stores in the same city. However, the expansion of chain enterprises in new cities suffers from data scarcity issues, and these models do not work in the new city where no chain store has been placed (i.e., cold-start problem). In this article, we propose a unified approach for cold-start store site recommendation, Weighted Adversarial Network with Transferability weighting scheme (WANT), to transfer knowledge learned from a data-rich source city to a target city with no labeled data. In particular, to promote positive transfer, we develop a discriminator to diminish distribution discrepancy between source city and target city with different data distributions, which plays the minimax game with the feature extractor to learn transferable representations across cities by adversarial learning. In addition, to further reduce the risk of negative transfer, we design a transferability weighting scheme to quantify the transferability of examples in source city and reweight the contribution of relevant source examples to transfer useful knowledge. We validate WANT using a real-world dataset, and experimental results demonstrate the effectiveness of our proposed model over several state-of-the-art baseline models. © 2021 Association for Computing Machinery.","cold-start problem; neural networks; store site recommendation; transfer learning; Urban computing","Association for Computing Machinery"
"Lu Z., Whalen I., Dhebar Y., Deb K., Goodman E.D., Banzhaf W., Boddeti V.N.","Multiobjective Evolutionary Design of Deep Convolutional Neural Networks for Image Classification",2021,"IEEE Transactions on Evolutionary Computation",10,"10.1109/TEVC.2020.3024708","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103037642&doi=10.1109%2fTEVC.2020.3024708&partnerID=40&md5=4f5b2b9103f034c5844fcab0a91a9654","Convolutional neural networks (CNNs) are the backbones of deep learning paradigms for numerous vision tasks. Early advancements in CNN architectures are primarily driven by human expertise and by elaborate design processes. Recently, neural architecture search was proposed with the aim of automating the network design process and generating task-dependent architectures. While existing approaches have achieved competitive performance in image classification, they are not well suited to problems where the computational budget is limited for two reasons: 1) the obtained architectures are either solely optimized for classification performance, or only for one deployment scenario and 2) the search process requires vast computational resources in most approaches. To overcome these limitations, we propose an evolutionary algorithm for searching neural architectures under multiple objectives, such as classification performance and floating point operations (FLOPs). The proposed method addresses the first shortcoming by populating a set of architectures to approximate the entire Pareto frontier through genetic operations that recombine and modify architectural components progressively. Our approach improves computational efficiency by carefully down-scaling the architectures during the search as well as reinforcing the patterns commonly shared among past successful architectures through Bayesian model learning. The integration of these two main contributions allows an efficient design of architectures that are competitive and in most cases outperform both manually and automatically designed architectures on benchmark image classification datasets: CIFAR, ImageNet, and human chest X-ray. The flexibility provided from simultaneously obtaining multiple architecture choices for different compute requirements further differentiates our approach from other methods in the literature. © 1997-2012 IEEE.","Convolutional neural networks (CNNs); evolutionary deep learning; genetic algorithms (GAs); neural architecture search (NAS)","Institute of Electrical and Electronics Engineers Inc."
"Kertész G., Szénási S., Vámossy Z.","Comparative analysis of image projection-based descriptors in Siamese neural networks",2021,"Advances in Engineering Software",5,"10.1016/j.advengsoft.2020.102963","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099788723&doi=10.1016%2fj.advengsoft.2020.102963&partnerID=40&md5=491d615bb059d74d176092b763714a95","Low-level object matching can be done using projection signatures. In case of a large number of projections, the matching algorithm has to deal with less significant slices. A trivial approach would be to do statistical analysis or apply machine learning to determine the significant features. To take adjacent values of the projection matrices into account, a convolutional neural network should be used. To compare two matrices, a Siamese-structure of convolutional heads can be applied. In this paper, an experiment is designed and implemented to analyze the object matching performance of Siamese Convolutional Neural Networks based on multi-directional image projection data. A backtracking search-based Neural Architecture Generation method is used to create convolutional architectures, and a Master/Worker structured distributed processing with highly efficient scheduling based on the Longest Processing Times-heuristics is used for parallel training and evaluation of the models. Results show that the projection-based methods are Pareto optimal in terms of one-shot classification accuracy and memory consumption. © 2021 The Author(s)","Multi-directional image projections; Neural architecture generation; one-shot classification accuracy; Siamese neural networks; Vehicle re-identification","Elsevier Ltd"
"Liu D., Wang Y.","A Dual-Dimer method for training physics-constrained neural networks with minimax architecture",2021,"Neural Networks",,"10.1016/j.neunet.2020.12.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099505489&doi=10.1016%2fj.neunet.2020.12.028&partnerID=40&md5=3c159fee71b235fc9102771f33f983c9","Data sparsity is a common issue to train machine learning tools such as neural networks for engineering and scientific applications, where experiments and simulations are expensive. Recently physics-constrained neural networks (PCNNs) were developed to reduce the required amount of training data. However, the weights of different losses from data and physical constraints are adjusted empirically in PCNNs. In this paper, a new physics-constrained neural network with the minimax architecture (PCNN-MM) is proposed so that the weights of different losses can be adjusted systematically. The training of the PCNN-MM is searching the high-order saddle points of the objective function. A novel saddle point search algorithm called Dual-Dimer method is developed. It is demonstrated that the Dual-Dimer method is computationally more efficient than the gradient descent ascent method for nonconvex–nonconcave functions and provides additional eigenvalue information to verify search results. A heat transfer example also shows that the convergence of PCNN-MMs is faster than that of traditional PCNNs. © 2021 Elsevier Ltd","Machine learning; Minimax problem; Partial differential equation; Physics-constrained neural networks; Saddle point search","Elsevier Ltd"
"Zhang J., Huang Y., Ma G., Nener B.","Mixture optimization for environmental, economical and mechanical objectives in silica fume concrete: A novel frame-work based on machine learning and a new meta-heuristic algorithm",2021,"Resources, Conservation and Recycling",8,"10.1016/j.resconrec.2021.105395","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099449186&doi=10.1016%2fj.resconrec.2021.105395&partnerID=40&md5=c93973e6d759295cca66a43d84af7515","Partial replacement of cement by silica fume in concrete provides advantages such as mitigation of the impact on the environment of carbon dioxide emitted during cement production, recycling of industrial by-products and improvement of concrete strength and durability. The optimization of the mixture of silica fume concrete (SFC) requires trade-off among multiple objectives (strength, cost and embodied CO2) and consideration of a large number of variables under highly nonlinear constraints. Obtaining the Pareto front of this multi-objective optimization (MOO) problem is computationally expensive. To address this issue, the present study develops a MOO model using machine learning (ML) techniques and a new meta-heuristic algorithm. Firstly, the relationships between components and SFC properties are modelled on a dataset using a back propagation neural network (BPNN) model. Then an individual-intelligence-based multi-objective beetle antennae search algorithm (MOBAS) is developed to search for optimal SFC mixtures that maximize UCS, and minimize cost and embodied CO2 under defined constraints. Results indicate that the proposed MOBAS is more computationally efficient with satisfactory accuracy in comparison with algorithms based on swarm intelligence. The MOO model achieves reliable predictions for UCS with a very high correlation coefficient (0.9663) on the test set. The Pareto front of optimal SFC mixture proportions of the MOO problem is successfully obtained using the proposed model. The proposed frame-work improves the efficiency in SFC mixture optimization and can facilitate appropriate decision making before construction. © 2021","Carbon dioxide; Cost; Mixture design; Multi-objective optimization; Silica fume concrete; Uniaxial compressive strength","Elsevier B.V."
"Valdivia A., Sánchez-Monedero J., Casillas J.","How fair can we go in machine learning? Assessing the boundaries of accuracy and fairness",2021,"International Journal of Intelligent Systems",3,"10.1002/int.22354","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098479106&doi=10.1002%2fint.22354&partnerID=40&md5=277811f4b5f59cc7f74965185862de6c","Fair machine learning has been focusing on the development of equitable algorithms that address discrimination. Yet, many of these fairness-aware approaches aim to obtain a unique solution to the problem, which leads to a poor understanding of the statistical limits of bias mitigation interventions. In this study, a novel methodology is presented to explore the tradeoff in terms of a Pareto front between accuracy and fairness. To this end, we propose a multiobjective framework that seeks to optimize both measures. The experimental framework is focused on logistiregression and decision tree classifiers since they are well-known by the machine learning community. We conclude experimentally that our method can optimize classifiers by being fairer with a small cost on the classification accuracy. We believe that our contribution will help stakeholders of sociotechnical systems to assess how far they can go being fair and accurate, thus serving in the support of enhanced decision making where machine learning is used. © 2020 Wiley Periodicals LLC","algorithmic fairness; group fairness; multiobjective optimization","John Wiley and Sons Ltd"
"Lin J.C.-W., Srivastava G., Zhang Y., Djenouri Y., Aloqaily M.","Privacy-preserving multiobjective sanitization model in 6G iot environments",2021,"IEEE Internet of Things Journal",41,"10.1109/JIOT.2020.3032896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096801361&doi=10.1109%2fJIOT.2020.3032896&partnerID=40&md5=a0075c750832875470dcde3423f24e5a","The next revolution of the smart industry relies on the emergence of the Industrial Internet of Things (IoT) and 5G/6G technology. The properties of such sophisticated communication technologies will change our perspective of information and communication by enabling seamless connectivity and bring closer entities, data, and 'things.' Terahertz-based 6G networks promise the best speed and reliability, but they will face new man-in-the-middle attacks. In such critical and high-sensitive environments, the security of data and privacy of information still a big challenge. Without privacy-preserving considerations, the configuration state may be attacked or modified, thus causing security problems and damage to data. In this article, motivated by the need to secure 6G IoT networks, an ant colony optimization (ACO) approach is presented by adopting multiple objectives as well as using transaction deletion to secure confidential and sensitive information. Each ant in the population is represented as a set of possible deletion transactions for hiding sensitive information. We utilize the use of a prelarge concept to assist in the reduction of multiple database scans in the evaluation progress. We then also adopt external solutions to maintain discovered Pareto solutions, thus improving effectiveness to find optimized solutions. Experiments are conducted comparing our methodology to state-of-the-art bioinspired particle swarm optimization (PSO) as well as genetic algorithm (GA). Our strong results clearly show that the designed approach achieves fewer side effects while maintaining low computational cost overall (Chen et al., 2020). © 2014 IEEE.","5G/6G; ant colony; decomposition; deep learning; IIoT; object detection; particle swarm optimization (PSO); smart factory","Institute of Electrical and Electronics Engineers Inc."
"Le A.V., Veerajagadheswar P., Kyaw P.T., Elara M.R., Nhan N.H.K.","Coverage path planning using reinforcement learning-based tsp for htetran — A polyabolo-inspired self-reconfigurable tiling robot",2021,"Sensors",6,"10.3390/s21082577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103558380&doi=10.3390%2fs21082577&partnerID=40&md5=b146ea7fc40fd8d8130c3b947c6867b6","One of the critical challenges in deploying the cleaning robots is the completion of covering the entire area. Current tiling robots for area coverage have fixed forms and are limited to cleaning only certain areas. The reconfigurable system is the creative answer to such an optimal coverage problem. The tiling robot’s goal enables the complete coverage of the entire area by reconfiguring to different shapes according to the area’s needs. In the particular sequencing of navigation, it is essential to have a structure that allows the robot to extend the coverage range while saving energy usage during navigation. This implies that the robot is able to cover larger areas entirely with the least required actions. This paper presents a complete path planning (CPP) for hTetran, a polyabolo tiled robot, based on a TSP-based reinforcement learning optimization. This structure simultaneously produces robot shapes and sequential trajectories whilst maximizing the reward of the trained reinforcement learning (RL) model within the predefined polyabolo-based tileset. To this end, a reinforcement learning-based travel sales problem (TSP) with proximal policy optimization (PPO) algorithm was trained using the complementary learning computation of the TSP sequencing. The reconstructive results of the proposed RL-TSP-based CPP for hTetran were compared in terms of energy and time spent with the conventional tiled hypothetical models that incorporate TSP solved through an evolutionary based ant colony optimization (ACO) approach. The CPP demonstrates an ability to generate an ideal Pareto optima trajectory that enhances the robot’s navigation inside the real environment with the least energy and time spent in the company of conventional techniques. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Energy-aware reward function; Reconfigurable system; Reinforcement learning TSP, complete path planning; Tiling robotic","MDPI AG"
"Jensen P.J., Zhang J., Koontz B.F., Wu Q.J.","A Novel Machine Learning Model for Dose Prediction in Prostate Volumetric Modulated Arc Therapy Using Output Initialization and Optimization Priorities",2021,"Frontiers in Artificial Intelligence",1,"10.3389/frai.2021.624038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117825006&doi=10.3389%2ffrai.2021.624038&partnerID=40&md5=e3e0cfbe33fa8e4eb2c46d19e41eaf7d","Treatment planning for prostate volumetric modulated arc therapy (VMAT) can take 5–30 min per plan to optimize and calculate, limiting the number of plan options that can be explored before the final plan decision. Inspired by the speed and accuracy of modern machine learning models, such as residual networks, we hypothesized that it was possible to use a machine learning model to bypass the time-intensive dose optimization and dose calculation steps, arriving directly at an estimate of the resulting dose distribution for use in multi-criteria optimization (MCO). In this study, we present a novel machine learning model for predicting the dose distribution for a given patient with a given set of optimization priorities. Our model innovates upon the existing machine learning techniques by utilizing optimization priorities and our understanding of dose map shapes to initialize the dose distribution before dose refinement via a voxel-wise residual network. Each block of the residual network individually updates the initialized dose map before passing to the next block. Our model also utilizes contiguous and atrous patch sampling to effectively increase the receptive fields of each layer in the residual network, decreasing its number of layers, increasing model prediction and training speed, and discouraging overfitting without compromising on the accuracy. For analysis, 100 prostate VMAT cases were used to train and test the model. The model was evaluated by the training and testing errors produced by 50 iterations of 10-fold cross-validation, with 100 cases randomly shuffled into the subsets at each iteration. The error of the model is modest for this data, with average dose map root-mean-square errors (RMSEs) of 2.38 ± 0.47% of prescription dose overall patients and all optimization priority combinations in the patient testing sets. The model was also evaluated at iteratively smaller training set sizes, suggesting that the model requires between 60 and 90 patients for optimal performance. This model may be used for quickly estimating the Pareto set of feasible dose objectives, which may directly accelerate the treatment planning process and indirectly improve final plan quality by allowing more time for plan refinement. © Copyright © 2021 Jensen, Zhang, Koontz and Wu.","artificial intelligence; dose prediction; machine learning; multi-criterial optimization; prostate VMAT; residual neural networks; treatment planning","Frontiers Media S.A."
"Goncharenko V.I., Zheltov S.Y., Knyaz V.A., Lebedev G.N., Mikhaylin D.A., Tsareva O.Y.","Intelligent System for Planning Group Actions of Unmanned Aircraft in Observing Mobile Objects on the Ground in the Specified Area",2021,"Journal of Computer and Systems Sciences International",1,"10.1134/S1064230721030047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109168906&doi=10.1134%2fS1064230721030047&partnerID=40&md5=aedbac75bb381305630ad5b5eedc455a","Abstract: The multicriteria task of preflight and operational planning of group actions of unmanned aerial vehicles (UAVs), taking into account the required service schedule, is considered. A minimax criterion for the operational planning of group actions when the dynamic situation changes is proposed. The shape of the expert system for controlling the duration of observation during the search and detection of ground objects is formed. The obtained results of assessing the quality of the solution to the subproblem of neural network recognition of mobile objects based on deep learning confirm the effectiveness of the proposed approach in monitoring the controlled area. © 2021, Pleiades Publishing, Ltd.",,"Pleiades journals"
"Dong Z., Gao Y., Huang Q., Wawrzynek J., So H.K.H., Keutzer K.","HAO: Hardware-aware Neural Architecture Optimization for Efficient Inference",2021,"Proceedings - 29th IEEE International Symposium on Field-Programmable Custom Computing Machines, FCCM 2021",4,"10.1109/FCCM51124.2021.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107681989&doi=10.1109%2fFCCM51124.2021.00014&partnerID=40&md5=e20991de715284f1ee693e8dd2848230","Automatic algorithm-hardware co-design for DNN has shown great success in improving the performance of DNNs on FPGAs. However, this process remains challenging due to the intractable search space of neural network architectures and hardware accelerator implementation. Differing from existing hardware-aware neural architecture search (NAS) algorithms that rely solely on the expensive learning-based approaches, our work incorporates integer programming into the search algorithm to prune the design space. Given a set of hardware resource constraints, our integer programming formulation directly outputs the optimal accelerator configuration for mapping a DNN subgraph that minimizes latency. We use an accuracy predictor for different DNN subgraphs with different quantization schemes and generate accuracy-latency pareto frontiers. With low computational cost, our algorithm can generate quantized networks that achieve state-of-the-art accuracy and hardware performance on Xilinx Zynq (ZU3EG) FPGA for image classification on ImageNet dataset. The solution searched by our algorithm achieves 72.5% top-1 accuracy on ImageNet at framerate 50, which is 60% faster than MnasNet [37] and 135% faster than FBNet [43] with comparable accuracy. © 221 IEEE.","Efficient Deep Learning; HW SW Codesign; Image Classification; Neural Architecture Optimization; Neural Architecture Search; Quantization","Institute of Electrical and Electronics Engineers Inc."
"Jiang H., Nie Z., Yeo R., Farimani A.B., Kara L.B.","StressGAN: A generative deep learning model for two-dimensional stress distribution prediction",2021,"Journal of Applied Mechanics, Transactions ASME",10,"10.1115/1.4049805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106099489&doi=10.1115%2f1.4049805&partnerID=40&md5=49398e32b09ba2c15c88a293f68ff0db","Using deep learning to analyze mechanical stress distributions is gaining interest with the demand for fast stress analysis. Deep learning approaches have achieved excellent outcomes when utilized to speed up stress computation and learn the physical nature without prior knowledge of underlying equations. However, most studies restrict the variation of geometry or boundary conditions, making it difficult to generalize the methods to unseen configurations. We propose a conditional generative adversarial network (cGAN) model called StressGAN for predicting 2D von Mises stress distributions in solid structures. The StressGAN model learns to generate stress distributions conditioned by geometries, loads, and boundary conditions through a two-player minimax game between two neural networks with no prior knowledge. By evaluating the generative network on two stress distribution datasets under multiple metrics, we demonstrate that our model can predict more accurate stress distributions than a baseline convolutional neural-network model, given various and complex cases of geometries, loads, and boundary conditions. © 2021 by ASME","Conditional generative adversarial network; Deep learning; Stress; StressGAN","American Society of Mechanical Engineers (ASME)"
"Farkas S., Lopez O., Thomas M.","Cyber claim analysis using Generalized Pareto regression trees with applications to insurance",2021,"Insurance: Mathematics and Economics",3,"10.1016/j.insmatheco.2021.02.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103055526&doi=10.1016%2fj.insmatheco.2021.02.009&partnerID=40&md5=21d92fb32d8df4720a9ab738f693d5db","With the rise of the cyber insurance market, there is a need for better quantification of the economic impact of this risk and its rapid evolution. Due to the heterogeneity of cyber claims, evaluating the appropriate premium and/or the required amount of reserves is a difficult task. In this paper, we propose a method for cyber claim analysis based on regression trees to identify criteria for claim classification and evaluation. We particularly focus on severe/extreme claims, by combining a Generalized Pareto modeling – legitimate from Extreme Value Theory – and a regression tree approach. Coupled with an evaluation of the frequency, our procedure allows computations of central scenarios and of extreme loss quantiles for a cyber portfolio. Finally, the method is illustrated on a public database. © 2021 Elsevier B.V.","Clustering; Cyber insurance; Extreme value analysis; Generalized Pareto distribution; Machine learning; Regression trees","Elsevier B.V."
"Garland A.P., White B.C., Jensen S.C., Boyce B.L.","Pragmatic generative optimization of novel structural lattice metamaterials with machine learning",2021,"Materials and Design",4,"10.1016/j.matdes.2021.109632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102406479&doi=10.1016%2fj.matdes.2021.109632&partnerID=40&md5=ce34ef4889b16c0be3b39332bfa01475","Metamaterials, otherwise known as architected or programmable materials, enable designers to tailor mesoscale topology and shape to achieve unique material properties that are not present in nature. Additionally, with the recent proliferation of additive manufacturing tools across industrial sectors, the ability to readily fabricate geometrically complex metamaterials is now possible. However, in many high-performance applications involving complex multi-physics interactions, design of novel lattice metamaterials is still difficult. Design is primarily guided by human intuition or gradient optimization for simple problems. In this work, we show how machine learning guides discovery of new unit cells that are Pareto optimal for multiple competing objectives; specifically, maximizing elastic stiffness during static loading and minimizing wave speed through the metamaterial during an impact event. Additionally, we show that our artificial intelligence approach works with relatively few (3500) simulation calls. © 2021 The Authors",,"Elsevier Ltd"
"Bi Y., Xue B., Zhang M.","Multi-objective genetic programming for feature learning in face recognition",2021,"Applied Soft Computing",3,"10.1016/j.asoc.2021.107152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100689451&doi=10.1016%2fj.asoc.2021.107152&partnerID=40&md5=aff15a52b3de969baeaad05df8056fd3","Face recognition is a challenging task due to high variations of pose, expression, ageing, and illumination. As an effective approach to face recognition, feature learning can be formulated as a multi-objective optimisation task of maximising classification accuracy and minimising the number of learned features. However, most of the existing algorithms focus on improving classification accuracy without considering the number of learned features. In this paper, we propose new multi-objective genetic programming (GP) algorithms for feature learning in face recognition. To achieve effective face feature learning, a new individual representation is developed to allow GP to select informative regions from the input image, extract features using various descriptors, and combine the extracted features for classification. Then two new multi-objective genetic programming (GP) algorithms, one with the idea of non-dominated sorting (NSGPFL) and the other with the idea of Strength Pareto (SPGPFL), are proposed to simultaneously optimise these two objectives. NSGPFL and SPGPFL are compared with a single-objective GP for feature learning (GPFL), a single-objective GP for weighting two objectives (GPFLW), and a large number of baseline methods. The experimental results show the effectiveness of the NSGPFL and SPGPFL algorithms by achieving better or comparable classification performance and learning a small number of features. © 2021 Elsevier B.V.","Evolutionary computation; Face recognition; Feature learning; Genetic programming; Multi-objective optimisation","Elsevier Ltd"
"Stoeckel S., Porro B., Arnaud-Haond S.","The discernible and hidden effects of clonality on the genotypic and genetic states of populations: Improving our estimation of clonal rates",2021,"Molecular Ecology Resources",2,"10.1111/1755-0998.13316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099983226&doi=10.1111%2f1755-0998.13316&partnerID=40&md5=62551c2083b1fc5b2ea76b2a81792f20","Partial clonality is widespread across the tree of life, but most population genetic models are designed for exclusively clonal or sexual organisms. This gap hampers our understanding of the influence of clonality on evolutionary trajectories and the interpretation of population genetic data. We performed forward simulations of diploid populations at increasing rates of clonality (c), analysed their relationships with genotypic (clonal richness, R, and distribution of clonal sizes, Pareto β) and genetic (FIS and linkage disequilibrium) indices, and tested predictions of c from population genetic data through supervised machine learning. Two complementary behaviours emerged from the probability distributions of genotypic and genetic indices with increasing c. While the impact of c on R and Pareto β was easily described by simple mathematical equations, its effects on genetic indices were noticeable only at the highest levels (c &gt; 0.95). Consequently, genotypic indices allowed reliable estimates of c, while genetic descriptors led to poorer performances when c &lt; 0.95. These results provide clear baseline expectations for genotypic and genetic diversity and dynamics under partial clonality. Worryingly, however, the use of realistic sample sizes to acquire empirical data systematically led to gross underestimates (often of one to two orders of magnitude) of c, suggesting that many interpretations hitherto proposed in the literature, mostly based on genotypic richness, should be reappraised. We propose future avenues to derive realistic confidence intervals for c and show that, although still approximate, a supervised learning method would greatly improve the estimation of c from population genetic data. © 2021 John Wiley & Sons Ltd","F-statistics; genotypic diversity; population genetics; rates of clonality; sampling","Blackwell Publishing Ltd"
"Marrone S., Papa C., Sansone C.","Effects of hidden layer sizing on CNN fine-tuning",2021,"Future Generation Computer Systems",1,"10.1016/j.future.2020.12.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098942433&doi=10.1016%2fj.future.2020.12.020&partnerID=40&md5=5df0e7f497a521eba691e19578aab640","Some applications have the property of being resilient, meaning that they are robust to noise (e.g. due to error) in the data. This characteristic is very useful in situations where an approximate computation allows to perform the task in less time or to deploy the algorithm on embedded hardware. Deep learning is one of the fields that can benefit from approximate computing to reduce the high number of involved parameters thanks to its impressive generalization ability. A common approach is to prune some neurons and perform an iterative re-training with the aim of both reducing the required memory and to speed-up the inference stage. In this work we propose to face CNN size reduction from a different perspective: instead of reducing the network weights or look for an approximated network very close to the Pareto frontier, we investigate whether it is possible to remove some neurons only from the fully connected layers before the network training without substantially affecting the network performance. As a case study, we will focus on “fine-tuning”, a branch of transfer learning that has shown its effectiveness especially in domains lacking effective expert-designed features. To further compact the network, we apply weight quantization to the convolutional kernels. Results show that it is possible to tailor some layers to reduce the network size, both in terms of the number of parameters to learn and required memory, without statistically affecting the performance and without the need for any additional training. Finally, we investigate to what extent the sizing operation affects the network robustness against adversarial perturbations, a set of approaches aimed at misleading deep neural networks. © 2020 Elsevier B.V.","Adversarial perturbation; Approximate computing; CNN; Fine-tuning","Elsevier B.V."
"Yu C., Hu D., Zheng S., Jiang W., Li M., Zhao Z.-Q.","An improved steganography without embedding based on attention GAN",2021,"Peer-to-Peer Networking and Applications",,"10.1007/s12083-020-01033-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098537348&doi=10.1007%2fs12083-020-01033-x&partnerID=40&md5=b6e532b0dfe939b9e161f4959866a7f8","Steganography is an art to hide information in the carriers to prevent from being detected, while steganalysis is the opposite art to detect the presence of the hidden information. With the development of deep learning, several state-of-the-art steganography and steganalysis based on deep learning techniques have been proposed to improve hiding or detection capabilities. Generative Adversarial Networks (GANs) based steganography directly uses the minimax game between the generator and discriminator, to automatically generate steganography algorithms resisting being detected by powerful steganalysis. The steganography without embedding (SwE) based on GANs, where the generated cover images themselves are stego images carrying secret information has shown its state-of-the-art steganography performance. However, SwE based on GANs has serious weaknesses, such as low information recovery accuracy, low steganography capacity and poor natural showing. To solve these problems, this paper proposes a new SwE based on attention-GAN model, with carefully designed generator, discriminator and extractor, as well as their loss functions and optimized training mode. The generative model utilizes the attention method to improve the correlation among pixels and to correct errors such as image distortion and background abnormality. The soft margin discriminator is used to improve the compatibility of information recovery and fault tolerance of image generation. Experimental evaluations show that our method can achieve a very high information recovery accuracy (100% in some cases), and at the same time improve the steganography capacity and image quality. © 2021, Springer Science+Business Media, LLC, part of Springer Nature.","Attention; Generative adversarial networks; Soft margin; Steganography; Steganography without embedding","Springer"
"Shu L., He F., Hu X., Li H.","A Novel Feature Selection with Many-Objective Optimization and Learning Mechanism",2021,"Proceedings of the 2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2021",,"10.1109/CSCWD49262.2021.9437707","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107787532&doi=10.1109%2fCSCWD49262.2021.9437707&partnerID=40&md5=f156bb09d3350d00893808e5f5969abe","Feature selection is extremely important in machine learning and data mining. Typical two-objective feature selection methods aim to minimize the number of features and maximize classification performance. However, they overlook the fact that there may be multiple subsets with similar information content for a given cardinality. The paper presents a many-objective feature selection approach to address this problem. Firstly, we establish a five-objective optimization model, which consists of classification accuracy, the number of features, feature relevance, feature redundancy, and feature complementarity. Therefore, the proposed model can enlarge the search space with more Pareto solutions. Secondly, we propose a wrapper structure for many-objective feature selection, which integrates a learning algorithm. Thirdly, in order to reduce the computional overhead, we propose a filter structure, which separates the learning algorithm. For implementation, we adopt NSGA-III multi-objective evolutionary algorithm and extreme learning machine. The experiments on mainstream datasets confirm the superiority of the proposed method. © 2021 IEEE.","classification; collaborative processing of big data; extreme learning machine; feature selection; intelligent cloud manufacturing; many-objective optimization; optimization driven design","Institute of Electrical and Electronics Engineers Inc."
"Raimundo M.M., Drumond T.F., Marques A.C.R., Lyra C., Rocha A., Von Zuben F.J.","Exploring multiobjective training in multiclass classification",2021,"Neurocomputing",1,"10.1016/j.neucom.2020.12.087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100512625&doi=10.1016%2fj.neucom.2020.12.087&partnerID=40&md5=27da5845ca4f143b7167de6f00007d3b","Multinomial logistic loss and L2 regularization are often conflicting objectives as more robust regularization leads to restrained multinomial parameters. For many practical problems, leveraging the best of both worlds would be invaluable for better decision-making processes. This research proposes a novel framework to obtain representative and diverse L2-regularized multinomial models, based on valuable trade-offs between prediction error and model complexity. The framework relies upon the Non-Inferior Set Estimation (NISE) method – a deterministic multiobjective solver. NISE automatically implements hyperparameter tuning in a multiobjective context. Given the diverse set of efficient learning models, model selection and aggregation of the multiple models in an ensemble framework promote high performance in multiclass classification. Additionally, NISE uses the weighted sum method as scalarization, thus being able to deal with the learning formulation directly. Its deterministic nature and the convexity of the learning problem confer scalability to the proposal. The experiments show competitive performance in various setups, taking a broad set of multiclass classification methods as contenders. © 2021 Elsevier B.V.","Diversity of Pareto-optimal models; Ensemble learning; Multiclass classification; Multiobjective optimization","Elsevier B.V."
"Ismayilov G., Yilmaz C.D.","Multi-Criteria Evaluation of Publication Impacts: Deep Learning in Autonomous Vehicles",2021,"Conference of Open Innovation Association, FRUCT",,"10.23919/FRUCT52173.2021.9435554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107412278&doi=10.23919%2fFRUCT52173.2021.9435554&partnerID=40&md5=3efe88ca5a4946a4c8d9b09202cbdf0b","Deep learning is the state-of-the-art approach that has been extensively used in the recent years to variety of real-world problems in the literature. The autonomous vehicles are among the applications where their integration with deep learning techniques has potential to disruptively change our daily lives. In this work, we have proposed a multi-criteria framework to evaluate the relative impacts of both publications and authors for deep learning in autonomous vehicles. For the framework, we have considered several criteria extracted from the metadata of the publications and the authors. The conflicts among the criteria are also justified through Pearson correlation. For the experiments, two comprehensive datasets for the publication and the author impacts have been constructed. The resulting pareto-fronts of the datasets after ranking are presented. Moreover, top 30 most impactful publications and authors in the literature are identified. We hope that our findings will be useful for researchers to accelerate the further technological advancements. © 2021 FRUCT.",,"IEEE Computer Society"
"Li H., Xu B., Lu G., Du C., Huang N.","Multi-objective optimization of PEM fuel cell by coupled significant variables recognition, surrogate models and a multi-objective genetic algorithm",2021,"Energy Conversion and Management",35,"10.1016/j.enconman.2021.114063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103097082&doi=10.1016%2fj.enconman.2021.114063&partnerID=40&md5=e2a56d7c2eac099d2ce6921d22e4bc3b","This paper aims to present a fast and systematic optimization approach for proton exchange membrane fuel cell (PEMFC) by combining variance analysis, surrogate models and non-dominated sorting genetic algorithm (NSGA-II). First, a three-dimensional steady-state PEMFC computational fluid dynamics (CFD) model is developed as the base model for optimization. Second, six variables that have significant effect on PEMFC performance are selected from numerious common parameters using variance analysis, reducing the number of decision variables from 11 to 6. Then, three data-driven ensemble learning models are trained as surrogate models to accelerate the fitness values evaluation of the optimization algorithm. Finally, three PEMFC performance indexes, including power density, system efficiency and oxygen distribution uniformity on cathode catalyst layer are optimized simultaneously based on NSGA-II. Using the NSGA-II combined with surrogate models, a set of Pareto solutions is obtained in a short time. The results indicate that PEMFCs with optimized parameters perform better than the base model in terms of all three performance indexes, demonstrating the success of this approach in solving time-consuming multi-optimization problems. This study provides a fast and systematic approach for PEMFC multi-objective optimization and can be a guide for engineering applications. © 2021 Elsevier Ltd","Ensemble learning model; Multi-objective optimization; NSGA-II; Proton exchange membrane fuel cell (PEMFC); Significant variables recognition","Elsevier Ltd"
"Yuan Y., Ma M., Han S., Zhang D., Miao F., Stankovic J., Lin S.","DeResolver: A decentralized negotiation and conflict resolution framework for smart city services",2021,"ICCPS 2021 - Proceedings of the 2021 ACM/IEEE 12th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2021)",,"10.1145/3450267.3450538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104186561&doi=10.1145%2f3450267.3450538&partnerID=40&md5=01bc31fb26344e1f9db215974f6213c0","As various smart services are increasingly deployed in modern cities, many unexpected conflicts arise due to various physical world couplings. Existing solutions for conflict resolution often rely on centralized control to enforce predetermined and fixed priorities of different services, which is challenging due to the inconsistent and private objectives of the services. Also, the centralized solutions miss opportunities to more effectively resolve conflicts according to their spatiotemporal locality of the conflicts. To address this issue, we design a decentralized negotiation and conflict resolution framework named DeResolver, which allows services to resolve conflicts by communicating and negotiating with each other to reach a Pareto-optimal agreement autonomously and efficiently. Our design features a two-level semi-supervised learning-based algorithm to predict acceptable proposals and their rankings of each opponent through the negotiation. Our design is evaluated with a smart city case study of three services: intelligent traffic light control, pedestrian service, and environmental control. In this case study, a data-driven evaluation is conducted using a large data set consisting of the GPS locations of 246 surveillance cameras and an automatic traffic monitoring system with more than 3 million records per day to extract real-world vehicle routes. The evaluation results show that our solution achieves much more balanced results, i.e., only increasing the average waiting time of vehicles, the measurement metric of intelligent traffic light control service, by 6.8% while reducing the weighted sum of air pollutant emission, measured for environment control service, by 12.1%, and the pedestrian waiting time, the measurement metric of pedestrian service, by 33.1%, compared to priority-based solution. © 2021 ACM.","conflicts across services; decentralized resolution; multiple services negotiation; smart services","Association for Computing Machinery, Inc"
"Abdolrashidi A., Wang L., Agrawal S., Malmaud J., Rybakov O., Leichner C., Lew L.","Pareto-optimal quantized resnet is mostly 4-bit",2021,"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",,"10.1109/CVPRW53098.2021.00345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115998098&doi=10.1109%2fCVPRW53098.2021.00345&partnerID=40&md5=508548df48732580fcfbab3ac9175586","Quantization has become a popular technique to compress neural networks and reduce compute cost, but most prior work focuses on studying quantization without changing the network size. Many real-world applications of neural networks have compute cost and memory budgets, which can be traded off with model quality by changing the number of parameters. In this work, we use ResNet as a case study to systematically investigate the effects of quantization on inference compute cost-quality tradeoff curves. Our results suggest that for each bfloat16 ResNet model, there are quantized models with lower cost and higher ac-curacy; in other words, the bfloat16 compute cost-quality tradeoff curve is Pareto-dominated by the 4-bit and 8-bit curves, with models primarily quantized to 4-bit yielding the best Pareto curve. Furthermore, we achieve state-of-the-art results on ImageNet for 4-bit ResNet-50 with quantization-aware training, obtaining a top-1 eval accuracy of 77.09%. We demonstrate the regularizing effect of quantization by measuring the generalization gap. The quantization method we used is optimized for practicality: It requires little tuning and is designed with hardware capabilities in mind. Our work motivates further research into optimal numeric formats for quantization, as well as the development of machine learning accelerators supporting these formats. As part of this work, we contribute a quantization library written in JAX, which is open-sourced at https://github.com/google-research/google-research/tree/master/aqt. © 2021 IEEE.",,"IEEE Computer Society"
"Duchi J.C., Namkoong H.","Learning models with uniform performance via distributionally robust optimization",2021,"Annals of Statistics",1,"10.1214/20-AOS2004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113174117&doi=10.1214%2f20-AOS2004&partnerID=40&md5=46c80c408ed51834aa12d56f46d37ec4","A common goal in statistics and machine learning is to learn models that can perform well against distributional shifts, such as latent heterogeneous subpopulations, unknown covariate shifts or unmodeled temporal effects. We develop and analyze a distributionally robust stochastic optimization (DRO) framework that learns a model providing good performance against perturbations to the data-generating distribution. We give a convex formulation for the problem, providing several convergence guarantees. We prove finite-sample minimax upper and lower bounds, showing that distributional robustness sometimes comes at a cost in convergence rates. We give limit theorems for the learned parameters, where we fully specify the limiting distribution so that confidence intervals can be computed. On real tasks including generalizing to unknown subpopulations, fine-grained recognition and providing good tail performance, the distributionally robust approach often exhibits improved performance. © Institute of Mathematical Statistics, 2021","Minimax optimality; Risk-averse learning; Robust optimization","Institute of Mathematical Statistics"
"Luo Y., Raskutti G., Yuan M., Zhang A.R.","A sharp blockwise tensor perturbation bound for orthogonal iteration",2021,"Journal of Machine Learning Research",,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112479298&partnerID=40&md5=f28ee0a9ef70e047ef58a1dc9e3f5905","In this paper, we develop novel perturbation bounds for the higher-order orthogonal iteration (HOOI) (De Lathauwer et al., 2000a). Under mild regularity conditions, we establish blockwise tensor perturbation bounds for HOOI with guarantees for both tensor reconstruction in Hilbert-Schmidt norm ∥ p T -T ∥HS and mode-k singular subspace estimation in Schatten-q norm - sinΘ(Uk;Uk)∥q for any q ≥ 1. We show the upper bounds of mode-k singular subspace estimation are unilateral and converge linearly to a quantity characterized by blockwise errors of the perturbation and signal strength. For the tensor reconstruction error bound, we express the bound through a simple quantity _, which depends only on perturbation and the multilinear rank of the underlying signal. Rate matching deterministic lower bound for tensor reconstruction, which demonstrates the optimality of HOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI with only a single iteration) is also optimal in terms of tensor reconstruction and can be used to lower the computational cost. The perturbation results are also extended to the case that only partial modes of T have low-rank structure. We support our theoretical results by extensive numerical studies. Finally, we apply the novel perturbation bounds of HOOI on two applications, tensor denoising and tensor co-clustering, from machine learning and statistics, which demonstrates the superiority of the new perturbation results. © 2021 Yuetian Luo, Garvesh Raskutti, Ming Yuan, and Anru R. Zhang.","Higher-order orthogonal iteration; Minimax optimality; Perturbation bounds; Tensor","Microtome Publishing"
"Sun H., Wu Q.","Optimal rates of distributed regression with imperfect kernels",2021,"Journal of Machine Learning Research",3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112402656&partnerID=40&md5=c7d92b6d1bd19466a924490e3112832e","Distributed machine learning systems have been receiving increasing attentions for their efficiency to process large scale data. Many distributed frameworks have been proposed for different machine learning tasks. In this paper, we study the distributed kernel regression via the divide and conquer approach. The learning process consists of three stages. Firstly, the data is partitioned into multiple subsets. Then a base kernel regression algorithm is applied to each subset to learn a local regression model. Finally the local models are averaged to generate the final regression model for the purpose of predictive analytics or statistical inference. This approach has been proved asymptotically minimax optimal if the kernel is perfectly selected so that the true regression function lies in the associated reproducing kernel Hilbert space. However, this is usually, if not always, impractical because kernels that can only be selected via prior knowledge or a tuning process are hardly perfect. Instead it is more common that the kernel is good enough but imperfect in the sense that the true regression can be well approximated by but does not lie exactly in the kernel space. We show distributed kernel regression can still achieve capacity independent optimal rate in this case. To this end, we first establish a general framework that allows to analyze distributed regression with response weighted base algorithms by bounding the error of such algorithms on a single data set, provided that the error bounds have factored the impact of unexplained variance of the response variable. Then we perform a leave one out analysis of the kernel ridge regression and bias corrected kernel ridge regression, which in combination with the aforementioned framework allows us to derive sharp error bounds and capacity independent optimal rates for the associated distributed kernel regression algorithms. As a byproduct of the thorough analysis, we also prove the kernel ridge regression can achieve rates faster than O(N-1) (where N is the sample size) in the noise free setting which, to our best knowledge, are first observed and novel in regression learning. © 2021 Hongwei Sun and Qiang Wu.","Distributed regression learning; Imperfect kernels; Learning Theory; Leave one out analysis; Optimal rates","Microtome Publishing"
"Wang E.K., Xu S.P., Chen C.-M., Kumar N.","Neural-Architecture-Search-Based Multiobjective Cognitive Automation System",2021,"IEEE Systems Journal",8,"10.1109/JSYST.2020.3002428","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110888310&doi=10.1109%2fJSYST.2020.3002428&partnerID=40&md5=1d3ef650f93693461a10abbd0013f24b","Currently, deep-learning-based cognitive automation for decision-making in industrial informatics is a new hot topic in the field of cognitive computing, among which multiobjective architecture optimization is of great difficulty in the research area. When the existing algorithms face multiobjective cognitive model problems, it often takes a lot of time to continuously set different search preference parameters to generate a new search process. This article mainly aims to solve the problem in a multiobjective neural architecture search process, and the key issue is how to adapt user preferences during architectural search. We propose a new algorithm: linear-prefer coevolutionary algorithm. Compared to the original user-constrained method and the Pareto-dominant NSGA-II algorithm, we have faster adaptation time and better quality of adaptation. At the same time, it can respond to user's needs at a relatively faster pace during the reasoning phase. Based on a large number of comparative test results, our algorithm is superior to the traditional cognitive automation algorithms for the multiobjective problem in search quality. © 2007-2012 IEEE.","Cognitive automation; evolutional algorithm; multiobjective; neural architecture search (NAS); Pareto dominant","Institute of Electrical and Electronics Engineers Inc."
"Cornejo-Bueno S., Casillas-Pérez D., Cornejo-Bueno L., Chidean M.I., Caamaño A.J., Cerro-Prada E., Casanova-Mateo C., Salcedo-Sanz S.","Statistical analysis and machine learning prediction of fog-caused low-visibility events at a-8 motor-road in spain",2021,"Atmosphere",1,"10.3390/atmos12060679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109211069&doi=10.3390%2fatmos12060679&partnerID=40&md5=cd398cf12474402794efeca1b6ce365c","This work presents a full statistical analysis and accurate prediction of low-visibility events due to fog, at the A-8 motor-road in Mondoñedo (Galicia, Spain). The present analysis covers two years of study, considering visibility time series and exogenous variables collected in the zone affected the most by extreme low-visibility events. This paper has then a two-fold objective: first, we carry out a statistical analysis for estimating the fittest probability distributions to the fog event duration, using the Maximum Likelihood method and an alternative method known as the L-moments method. This statistical study allows association of the low-visibility depth with the event duration, showing a clear relationship, which can be modeled with distributions for extremes such as Generalized Extreme Value and Generalized Pareto distributions. Second, we apply a neural network approach, trained by means of the ELM (Extreme Learning Machine) algorithm, to predict the occurrence of low-visibility events due to fog, from atmospheric predictive variables. This study provides a full characterization of fog events at this motor-road, in which orographic fog is predominant, causing important traffic problems during all year. We also show how the ELM approach is able to obtain highly accurate low-visibility events predictions, with a Pearson correlation coefficient of 0.8, within a half-hour time horizon, enough to initialize some protocols aiming at reducing the impact of these extreme events in the traffic of the A-8 motor road. © MDPI AG. All rights reserved.","Extreme learning machines; Low-visibility events; Machine learning algorithms; Orographic and hill-fogs; Prediction problems","MDPI AG"
"Ghosal S., Dey S., Chattopadhyay P.P., Datta S., Bhattacharyya P.","Designing optimized ternary catalytic alloy electrode for efficiency improvement of semiconductor gas sensors using a machine learning approach",2021,"Decision Making: Applications in Management and Engineering",1,"10.31181/DMAME210402126G","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109066280&doi=10.31181%2fDMAME210402126G&partnerID=40&md5=8aeaf1f24c52ca2b69e6ee922872e1f6","Catalytic noble metal (s) or its alloy (s) has long been used as the electrode material to enhance the sensing performance of the semiconducting oxide-based gas sensors. In the present paper, optimized ternary metal alloy electrode has been designed, while the database is in pure or binary alloy compositions, using a machine learning methodology is reported for detection of CH4 gas as a test case. Pure noble metals or their binary alloys as the electrode on the semiconducting ZnO sensing layer were investigated by the earlier researchers to enhance the sensitivity towards CH4. Based on those research findings, an artificial neural network (ANN) model was developed considering the three main features of the gas sensor devices, viz. response magnitude, response time and recovery time as a function of ZnO particle size and the composition of the catalytic alloy. A novel methodology was introduced by using ANN models considered for optimized ternary alloy with enriched presentation through the multi-objective genetic algorithm (GA) wherever the generated Pareto front was used. The prescriptive data analytics methodology seems to offer more or less convinced evidence for future experimental studies. © 2018 by the authors.","Artificial neural network; Genetic algorithm; Multi-objective optimization; Oxide based gas sensor; Sensing parameters; Ternary alloy catalyst design","Regional Association for Security and crisis management"
"Diana E., Gill W., Globus-Harris I., Kearns M., Roth A., Sharifi-Malvajerdi S.","Lexicographically fair learning: Algorithms and generalization",2021,"Leibniz International Proceedings in Informatics, LIPIcs",,"10.4230/LIPIcs.FORC.2021.6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108183203&doi=10.4230%2fLIPIcs.FORC.2021.6&partnerID=40&md5=df6d3c0cf70542bf3c3d41fbbc54e778","We extend the notion of minimax fairness in supervised learning problems to its natural conclusion: lexicographic minimax fairness (or lexifairness for short). Informally, given a collection of demographic groups of interest, minimax fairness asks that the error of the group with the highest error be minimized. Lexifairness goes further and asks that amongst all minimax fair solutions, the error of the group with the second highest error should be minimized, and amongst all of those solutions, the error of the group with the third highest error should be minimized, and so on. Despite its naturalness, correctly defining lexifairness is considerably more subtle than minimax fairness, because of inherent sensitivity to approximation error. We give a notion of approximate lexifairness that avoids this issue, and then derive oracle-efficient algorithms for finding approximately lexifair solutions in a very general setting. When the underlying empirical risk minimization problem absent fairness constraints is convex (as it is, for example, with linear and logistic regression), our algorithms are provably efficient even in the worst case. Finally, we show generalization bounds - approximate lexifairness on the training sample implies approximate lexifairness on the true distribution with high probability. Our ability to prove generalization bounds depends on our choosing definitions that avoid the instability of naive definitions. © Emily Diana, Wesley Gill, Ira Globus-Harris, Michael Kearns, Aaron Roth, and Saeed Sharifi-Malvajerdi; licensed under Creative Commons License CC-BY 4.0 2nd Symposium on Foundations of Responsible Computing (FORC 2021).","Fair learning; Game theory; Lexicographic fairness; Online learning","Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing"
"Li K., Zhang T., Wang R.","Deep Reinforcement Learning for Multiobjective Optimization",2021,"IEEE Transactions on Cybernetics",9,"10.1109/TCYB.2020.2977661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106500341&doi=10.1109%2fTCYB.2020.2977661&partnerID=40&md5=e457fb99664bba8442e8601fb093f411","This article proposes an end-to-end framework for solving multiobjective optimization problems (MOPs) using deep reinforcement learning (DRL), that we call DRL-based multiobjective optimization algorithm (DRL-MOA). The idea of decomposition is adopted to decompose the MOP into a set of scalar optimization subproblems. Then, each subproblem is modeled as a neural network. Model parameters of all the subproblems are optimized collaboratively according to a neighborhood-based parameter-transfer strategy and the DRL training algorithm. Pareto-optimal solutions can be directly obtained through the trained neural-network models. Specifically, the multiobjective traveling salesman problem (MOTSP) is solved in this article using the DRL-MOA method by modeling the subproblem as a Pointer Network. Extensive experiments have been conducted to study the DRL-MOA and various benchmark methods are compared with it. It is found that once the trained model is available, it can scale to newly encountered problems with no need for retraining the model. The solutions can be directly obtained by a simple forward calculation of the neural network; thereby, no iteration is required and the MOP can be always solved in a reasonable time. The proposed method provides a new way of solving the MOP by means of DRL. It has shown a set of new characteristics, for example, strong generalization ability and fast solving speed in comparison with the existing methods for multiobjective optimizations. The experimental results show the effectiveness and competitiveness of the proposed method in terms of model performance and running time. © 2013 IEEE.","Deep reinforcement learning (DRL); multiobjective optimization; Pointer Network; traveling salesman problem","Institute of Electrical and Electronics Engineers Inc."
"Du X., Xu H., Zhu F.","Understanding the Effect of Hyperparameter Optimization on Machine Learning Models for Structure Design Problems",2021,"CAD Computer Aided Design",4,"10.1016/j.cad.2021.103013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102586235&doi=10.1016%2fj.cad.2021.103013&partnerID=40&md5=e473e1cf7bcbb45a317d2c387a116734","To relieve the computational cost of design evaluations using expensive finite element (FE) simulations, surrogate models have been widely applied in computer-aided engineering design. Machine learning algorithms (MLAs) have been implemented as surrogate models due to their capability of learning the complex interrelations between the design variables and the response from big datasets. Typically, an MLA regression model contains model parameters and hyperparameters. The model parameters are obtained by fitting the training data. Hyperparameters, which govern the model structures and the training processes, are assigned by users before training. There is a lack of systematic studies on the effect of hyperparameters on the accuracy and robustness of the surrogate model. In this work, we proposed to establish a hyperparameter optimization framework to deepen our understanding of the effect. Based on the sequential model-based optimization method, the Pareto front is generated by running the optimal acquisition and updating the surrogate model iteratively. The optimum acquisition works by repeating a design space shrinking process. Using the acquired optimum, the surrogate model is updated, which describes the relationship between the hyperparameter combinations (inputs) generated by Latin hypercube sampling from the design space and structural response (outputs) to evaluate the modeling accuracy. The updated model will then be used for the next iteration of optimal acquisition until the termination criterion is met. Four frequently used MLAs, namely Gaussian Process Regression (GPR), Support Vector Machine (SVM), Random Forest Regression (RFR), and Artificial Neural Network (ANN), are tested on four benchmark examples of structure design optimization. For each MLA model, the model accuracy and robustness before and after the hyperparameters optimization (HOpt) are compared. The results show that HOpt can generally improve the performance of the MLA models in general with dependency on model complexity. HOpt leads to unstable improvements in the MLAs accuracy and robustness for complex problems, which are featured by high-dimensional mixed-variable design space. We also investigated the additional computational costs incurred by HOpt. The training cost is closely related to the MLA architecture. After HOpt, the training cost of ANN and RFR is increased more than that of the GPR and SVM. In summary, this study benefits the selection of HOpt method for different types of design problems based on their complexity (i.e. design domain continuity and the number of design variables, etc.). © 2021 Elsevier Ltd","Hyperparameters optimization; Machine learning; Structure design; Surrogate models","Elsevier Ltd"
"Romano J.D., Le T.T., Fu W., Moore J.H.","TPOT-NN: augmenting tree-based automated machine learning with neural network estimators",2021,"Genetic Programming and Evolvable Machines",3,"10.1007/s10710-021-09401-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102074130&doi=10.1007%2fs10710-021-09401-z&partnerID=40&md5=241268de37c970d9aaf1e165d39d50e8","Automated machine learning (AutoML) and artificial neural networks (ANNs) have revolutionized the field of artificial intelligence by yielding incredibly high-performing models to solve a myriad of inductive learning tasks. In spite of their successes, little guidance exists on when to use one versus the other. Furthermore, relatively few tools exist that allow the integration of both AutoML and ANNs in the same analysis to yield results combining both of their strengths. Here, we present TPOT-NN—a new extension to the tree-based AutoML software TPOT—and use it to explore the behavior of automated machine learning augmented with neural network estimators (AutoML+NN), particularly when compared to non-NN AutoML in the context of simple binary classification on a number of public benchmark datasets. Our observations suggest that TPOT-NN is an effective tool that achieves greater classification accuracy than standard tree-based AutoML on some datasets, with no loss in accuracy on others. We also provide preliminary guidelines for performing AutoML+NN analyses, and recommend possible future directions for AutoML+NN methods research, especially in the context of TPOT. © 2021, The Author(s).","Artificial neural networks; Automated machine learning; Evolutionary algorithms; Genetic programming; Pareto optimization","Springer"
"Zhao Z., Liu S., Zhou M., Abusorrah A.","Dual-Objective Mixed Integer Linear Program and Memetic Algorithm for an Industrial Group Scheduling Problem",2021,"IEEE/CAA Journal of Automatica Sinica",10,"10.1109/JAS.2020.1003539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099089450&doi=10.1109%2fJAS.2020.1003539&partnerID=40&md5=48414d8f76067d952f3c5349f9598f97","Group scheduling problems have attracted much attention owing to their many practical applications. This work proposes a new bi-objective serial-batch group scheduling problem considering the constraints of sequence-dependent setup time, release time, and due time. It is originated from an important industrial process, i.e., wire rod and bar rolling process in steel production systems. Two objective functions, i.e., the number of late jobs and total setup time, are minimized. A mixed integer linear program is established to describe the problem. To obtain its Pareto solutions, we present a memetic algorithm that integrates a population-based nondominated sorting genetic algorithm II and two single-solution-based improvement methods, i.e., an insertion-based local search and an iterated greedy algorithm. The computational results on extensive industrial data with the scale of a one-week schedule show that the proposed algorithm has great performance in solving the concerned problem and outperforms its peers. Its high accuracy and efficiency imply its great potential to be applied to solve industrial-size group scheduling problems. © 2014 Chinese Association of Automation.","Insertion-based local search; iterated greedy algorithm; machine learning; memetic algorithm; nondominated sorting genetic algorithm II (NSGA-II); production scheduling","Institute of Electrical and Electronics Engineers Inc."
"Sun Y., Dai H.","Constructing accuracy and diversity ensemble using Pareto-based multi-objective learning for evolving data streams",2021,"Neural Computing and Applications",1,"10.1007/s00521-020-05386-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092082567&doi=10.1007%2fs00521-020-05386-5&partnerID=40&md5=9134ade36b241583b29d85d89da8df7d","Ensemble learning is one of the most frequently used techniques for handling concept drift, which is the greatest challenge for learning high-performance models from big evolving data streams. In this paper, a Pareto-based multi-objective optimization technique is introduced to learn high-performance base classifiers. Based on this technique, a multi-objective evolutionary ensemble learning scheme, named Pareto-optimal ensemble for a better accuracy and diversity (PAD), is proposed. The approach aims to enhance the generalization ability of ensemble in evolving data stream environment by balancing the accuracy and diversity of ensemble members. In addition, an adaptive window change detection mechanism is designed for tracking different kinds of drifts constantly. Extensive experiments show that PAD is capable of adapting to dynamic change environments effectively and efficiently in achieving better performance. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Classifier selection; Concept drift; Data streams; Diversity; Ensemble learning; Multi-objective optimization","Springer Science and Business Media Deutschland GmbH"
"Pasquevich F., Ramirez A.F., Ayarde J.M., Briones G.C.","Adaptive Modulation Using Multi-Objective Reinforcement Learning for LEO Satellites",2021,"2021 IEEE Cognitive Communications for Aerospace Applications Workshop, CCAAW 2021",,"10.1109/CCAAW50069.2021.9527292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115829338&doi=10.1109%2fCCAAW50069.2021.9527292&partnerID=40&md5=14f8b9c51d43b49f54b49d53bd313822","In this paper, an emerging Machine Learning technique, named Multi-Objective Reinforcement Learning (MORL), is applied and analyzed aiming to achieve a two-fold optimization in a Satellite-To-Ground communication. The objectives pursued in this work using MORL are to minimize the Bit Error Rate and keep simultaneously the best performance in terms of the maximum bit rate transmission. The scenario under test consists of a Low-Earth Orbit satellite moving in a circular orbit while establishing a line-of-sight communication with a Ground Station. Two approaches are evaluated, the Weighted Sum and the Thresholded Lexicographic Q-Learning. We show that these two approaches can not find all the solutions. To alleviate this situation, a novel proposal is considered based on an inverse scalarization function that allows to select any solution from the Pareto front. We show that the proposed algorithm is able to implement a suitable operation for many different digital modulation schemes to obtain the maximum throughput. © 2021 IEEE.","LEO; ML; MORL; Pareto","Institute of Electrical and Electronics Engineers Inc."
"Martsenyuk V., Milian R., Milian N.","The U-Net model application for retinal vessels segmentation using minimax approach",2021,"International Conference on Information and Digital Technologies 2021, IDT 2021",,"10.1109/IDT52577.2021.9532495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115965434&doi=10.1109%2fIDT52577.2021.9532495&partnerID=40&md5=616069bb73350814ab1e0c687482be82","In this article the implementation of neural network architecture based on a dense U-Net network is proposed. It is noted that retinal blood vessels are the basis for clinical diagnosis of some diseases. A review of the convolutional networks use for classification tasks and generalizion retinal vessel segmentation algorithms is performed. The general process of the neural network is presented. The differences between the real and the obtained results were evaluated. Evaluation of the neural network is carried out on several parameters. Indicators of binary cross-entropy and learning time when using different tile sizes are presented, based on these data determined by the solution to the problem of minimax ML for binary cross-entropy and learning time. The figure with the recognized blood vessels as a result of the model is presented. © 2020 IEEE Computer Society. All rights reserved.","Machine learning; Machine learning library; Minimax; Neural network; Retinal vessels segmentation","Institute of Electrical and Electronics Engineers Inc."
"Ahmmed B., Karra S., Vesselinov V.V., Mudunuru M.K.","Machine learning to discover mineral trapping signatures due to CO2 injection",2021,"International Journal of Greenhouse Gas Control",2,"10.1016/j.ijggc.2021.103382","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108336559&doi=10.1016%2fj.ijggc.2021.103382&partnerID=40&md5=8336ec30356608437eec0f10ae5488ab","Mineral trapping is pursued as a geological CO2 sequestration (GCS) mechanism because it permanently stores CO2 in solid phases or minerals. However, CO2 mineral-trapping mechanisms are poorly understood due to (1) lack of sufficient field and laboratory data characterizing these complex processes, and (2) challenges to develop site-specific reactive-transport models coupling fluid flow and geochemical reactions occurring at various temporal (from milliseconds to years) and spatial (from pore (millimeters) to field (kilometers)) scales. Reactive transport with additional complexities such as heterogeneity can make the simulation outputs even more difficult to interpret because of complex nonlinearity and multi-scale interdependencies. Furthermore, the values of model outputs such as concentrations can vary by several orders of magnitude, making it harder to correlate and characterize the impact of the variables via traditional data interpretation techniques such as exploratory data analyses. Recently, machine learning (ML) has shown promise in feature discovery and in highlighting hidden mechanisms that cannot be obtained by existing data-analytics and statistical methods. In this study, we applied an unsupervised ML approach, non-negative matrix factorization with custom k-means clustering (NMFk) to the data generated by reactive-transport simulations of GCS. The reactive-transport data consisted of 19 attributes, including four physio-chemical variables (pH, porosity, aqueous CO2, and sequestered CO2), six chemical species (K+, Na+, HCO3−, Ca2+, Mg2+, Fe2+), and four carbonate minerals (calcite, dolomite, siderite, and ankerite), a feldspar mineral (albite), and four clay minerals (illite, clinochlore, kaolinite, and smectite) over a period of 200 years of simulation time. The simulation data used was for Morrow B sandstone at the Farnsworth hydrocarbon unit in Texas. Data are sampled at two locations within the model domain: (1) at the injection well and (2) 200 m west of the injection well. The injection was performed for a period of 10 years. Using NMFk, we estimated the temporal interdependencies among the 19 attributes over a span of 200 years. We found that NMFk was able to identify four reaction stages and their dominant attributes; these cannot be directly discerned through traditional visualization (e.g., line plots, Pareto analysis, Glyph-based visualization methods) or exploratory data analysis tools of the simulation data. The four stages were: reactions in the injection phase followed by short-, mid-, and long-term reactions. The NMFk analysis also revealed that 10 among the 19 attributes are dominant. These dominant attributes for mineral trapping include calcite, dolomite at injection well, siderite at 200 m away from the injection well, clinochlore, kaolinite, Na+, K+, Ca2+, Mg2+, pH, and aqeuous CO2. Finally, at late times (65–200 years), our results showed that calcite plays a major role in mineral trapping with insignificant contribution from siderite, ankerite, and clay minerals. These findings make the proposed unsupervised ML-model attractive for reactive-transport sensing towards real-time GCS monitoring. © 2021 Elsevier Ltd","CO2 sequestration; Hidden features; Matrix factorization; Reactive-transport simulation; Unsupervised machine learning","Elsevier Ltd"
"Asteris P.G., Skentou A.D., Bardhan A., Samui P., Pilakoutas K.","Predicting concrete compressive strength using hybrid ensembling of surrogate machine learning models",2021,"Cement and Concrete Research",39,"10.1016/j.cemconres.2021.106449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104364650&doi=10.1016%2fj.cemconres.2021.106449&partnerID=40&md5=23d4a047ea0f25e273f9359312527bbe","This study aims to implement a hybrid ensemble surrogate machine learning technique in predicting the compressive strength (CS) of concrete, an important parameter used for durability design and service life prediction of concrete structures in civil engineering projects. For this purpose, an experimental database consisting of 1030 records has been compiled from the machine learning repository of the University of California, Irvine. The database was used to train and validate four conventional machine learning (CML) models, namely Artificial Neural Network (ANN), Linear and Non-Linear Multivariate Adaptive Regression Splines (MARS-L and MARS-C), Gaussian Process Regression (GPR), and Minimax Probability Machine Regression (MPMR). Subsequently, the predicted outputs of CML models were combined and trained using ANN to construct the Hybrid Ensemble Model (HENSM). It is observed that the proposed HENSM produces higher predictive accuracy compared to the CML models used in the present study. The predictive performance of all models for CS prediction was compared using the testing dataset and it is found that the HENSM model attained the highest predictive accuracy in both phases. Based on the experimental results, the newly constructed HENSM model is very potential to be a new alternative in handling the overfitting issues of CML models and hence, can be used to predict the concrete CS, including the design of less polluting and more sustainable concrete constructions. © 2021 Elsevier Ltd","Artificial intelligence; Compressive strength; Hybrid modelling; Score analysis; Soft computing","Elsevier Ltd"
"Hao M., Zhang W., Wang Y., Lu G., Wang F., Vasilakos A.V.","Fine-Grained Powercap Allocation for Power-Constrained Systems Based on Multi-Objective Machine Learning",2021,"IEEE Transactions on Parallel and Distributed Systems",8,"10.1109/TPDS.2020.3045983","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098785097&doi=10.1109%2fTPDS.2020.3045983&partnerID=40&md5=7e8f311c9885c837cdf3674933580298","Power capping is an important solution to keep the system within a fixed power constraint. However, for the over-provisioned and power-constrained systems, especially the future exascale supercomputers, powercap needs to be reasonably allocated according to the workloads of compute nodes to achieve trade-offs among performance, energy and powercap. Thus it is necessary to model performance and energy and to predict the optimal powercap allocation strategies. Existing power allocation approaches have insufficient granularity within nodes. Modeling approaches usually model performance and energy separately, ignoring the correlation between objectives, and do not expose the Pareto-optimal powercap configurations. Therefore, this article combines the powercap with uncore frequency scaling and proposes an approach to predict the Pareto-optimal powercap configurations on the power-constrained system for input MPI and OpenMP parallel applications. Our approach first uses the elaborately designed micro-benchmarks and a small number of existing benchmarks to build the training set, and then applies a multi-objective machine learning algorithm which combines the stacked single-target method with extreme gradient boosting to build multi-objective models of performance and energy. The models can be used to predict the optimal processor and memory powercap settings, helping compute nodes perform fine-grained powercap allocation. When the optimal powercap configuration is determined, the uncore frequency scaling is used to further optimize the energy consumption. Compared with the reference powercap configuration, the predicted optimal configurations predicted by our method can achieve an average powercap reduction of 31.35 percent, an average energy reduction of 12.32 percent, and average performance degradation of only 2.43 percent. © 1990-2012 IEEE.","multi-objective machine learning; pareto front; performance and energy modeling; Power capping","IEEE Computer Society"
"Kim K.-R., Kim Y., Park S.","A Probabilistic Machine Learning Approach to Scheduling Parallel Loops with Bayesian Optimization",2021,"IEEE Transactions on Parallel and Distributed Systems",2,"10.1109/TPDS.2020.3046461","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098784928&doi=10.1109%2fTPDS.2020.3046461&partnerID=40&md5=a1d8f2b87a129ffc7abfe27973098026","This article proposes Bayesian optimization augmented factoring self-scheduling (BO FSS), a new parallel loop scheduling strategy. BO FSS is an automatic tuning variant of the factoring self-scheduling (FSS) algorithm and is based on Bayesian optimization (BO), a black-box optimization algorithm. Its core idea is to automatically tune the internal parameter of FSS by solving an optimization problem using BO. The tuning procedure only requires online execution time measurement of the target loop. In order to apply BO, we model the execution time using two Gaussian process (GP) probabilistic machine learning models. Notably, we propose a locality-aware GP model, which assumes that the temporal locality effect resembles an exponentially decreasing function. By accurately modeling the temporal locality effect, our locality-aware GP model accelerates the convergence of BO. We implemented BO FSS on the GCC implementation of the OpenMP standard and evaluated its performance against other scheduling algorithms. Also, to quantify our method's performance variation on different workloads, or workload-robustness in our terms, we measure the minimax regret. According to the minimax regret, BO FSS shows more consistent performance than other algorithms. Within the considered workloads, BO FSS improves the execution time of FSS by as much as 22% and 5% on average. © 1990-2012 IEEE.","Bayesian optimization; OpenMP; parallel computing; Parallel loop scheduling","IEEE Computer Society"
"Lomurno E., Samele S., Matteucci M., Ardagna D.","Pareto-optimal progressive neural architecture search",2021,"GECCO 2021 Companion - Proceedings of the 2021 Genetic and Evolutionary Computation Conference Companion",1,"10.1145/3449726.3463146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111036169&doi=10.1145%2f3449726.3463146&partnerID=40&md5=62da5a444853d749a907d302da270862","Neural Architecture Search (NAS) is the process of automating architecture engineering, searching for the best deep learning configuration. One of the main NAS approaches proposed in the literature, Progressive Neural Architecture Search (PNAS), seeks for the architectures with a sequential model-based optimization strategy: it defines a common recursive structure to generate the networks, whose number of building blocks rises through iterations. However, NAS algorithms are generally designed for an ideal setting without considering the needs and the technical constraints imposed by practical applications. In this paper, we propose a new architecture search named Pareto-Optimal Progressive Neural Architecture Search (POPNAS) that combines the benefits of PNAS to a time-accuracy Pareto optimization problem. POPNAS adds a new time predictor to the existing approach to carry out a joint prediction of time and accuracy for each candidate neural network, searching through the Pareto front. This allows us to reach a trade-off between accuracy and training time, identifying neural network architectures with competitive accuracy in the face of a drastically reduced training time. © 2021 ACM.","convolution; deep learning; machine learning; NAS; Pareto optimality; PNAS; POPNAS","Association for Computing Machinery, Inc"
"Lopes C.L.V., Martins F.V.C., Wanner E.F., Deb K.","An approximate MIP-DoM calculation for multi-objective optimization using affinity propagation clustering algorithm",2021,"GECCO 2021 Companion - Proceedings of the 2021 Genetic and Evolutionary Computation Conference Companion",,"10.1145/3449726.3459445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111030063&doi=10.1145%2f3449726.3459445&partnerID=40&md5=940a283204b4d817a63550404fc44189","Dominance move (DoM) is a quality indicator that compares two solution sets in a Pareto-optimal sense. The main issue related to DoM is its computational expense. A recent paper proposed a mixed-integer programming (MIP) approach for computing DoM that exhibited a computational complexity that is linear to the number of objectives and polynomial to the number of solutions. Even with this property, considering practical situations, the MIP-DoM calculation on some problems may take many hours. This paper presents an approximation method to deal with the problem using a cluster-based and divide-and-conquer strategy. Some experiments are tested, showing that the cluster based-algorithm is computationally much faster and makes a small percentage error from the original DoM value. © 2021 Owner/Author.","cluster algorithms; computationally expensive optimization; evolutionary multi-objective optimization; machine learning; multi-objective optimization","Association for Computing Machinery, Inc"
"Shah K., Gupta P., Deshpande A., Bhattacharyya C.","Rawlsian Fair Adaptation of Deep Learning Classifiers",2021,"AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",,"10.1145/3461702.3462592","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112480937&doi=10.1145%2f3461702.3462592&partnerID=40&md5=4f4175b17ed6c12e71b2b3c24b42f1e3","Group-fairness in classification aims for equality of a predictive utility across different sensitive sub-populations, e.g., race or gender. Equality or near-equality constraints in group-fairness often worsen not only the aggregate utility but also the utility for the least advantaged sub-population. In this paper, we apply the principles of Pareto-efficiency and least-difference to the utility being accuracy, as an illustrative example, and arrive at the Rawls classifier that minimizes the error rate on the worst-off sensitive sub-population. Our mathematical characterization shows that the Rawls classifier uniformly applies a threshold to an ideal score of features, in the spirit of fair equality of opportunity. In practice, such a score or a feature representation is often computed by a black-box model that has been useful but unfair. Our second contribution is practical Rawlsian fair adaptation of any given black-box deep learning model, without changing the score or feature representation it computes. Given any score function or feature representation and only its second-order statistics on the sensitive sub-populations, we seek a threshold classifier on the given score or a linear threshold classifier on the given feature representation that achieves the Rawls error rate restricted to this hypothesis class. Our technical contribution is to formulate the above problems using ambiguous chance constraints, and to provide efficient algorithms for Rawlsian fair adaptation, along with provable upper bounds on the Rawls error rate. Our empirical results show significant improvement over state-of-the-art group-fair algorithms, even without retraining for fairness. © 2021 ACM.","fair adaptation; fairness for deep learning classifiers; Rawlsian fairness","Association for Computing Machinery, Inc"
"Diana E., Gill W., Kearns M., Kenthapadi K., Roth A.","Minimax Group Fairness: Algorithms and Experiments",2021,"AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",3,"10.1145/3461702.3462523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111198531&doi=10.1145%2f3461702.3462523&partnerID=40&md5=b47fbafddb1c840bff82a0a985bd4840","We consider a recently introduced framework in which fairness is measured by worst-case outcomes across groups, rather than by the more standard differences between group outcomes. In this framework we provide provably convergent oracle-efficient learning algorithms (or equivalently, reductions to non-fair learning) for minimax group fairness. Here the goal is that of minimizing the maximum loss across all groups, rather than equalizing group losses. Our algorithms apply to both regression and classification settings and support both overall error and false positive or false negative rates as the fairness measure of interest. They also support relaxations of the fairness constraints, thus permitting study of the tradeoff between overall accuracy and minimax fairness. We compare the experimental behavior and performance of our algorithms across a variety of fairness-sensitive data sets and show empirical cases in which minimax fairness is strictly and strongly preferable to equal outcome notions. © 2021 ACM.","fair machine learning; game theory; minimax fairness","Association for Computing Machinery, Inc"
"Horii H.","Advancement of vehicle occupant restraint system design by integration of artificial intelligence technologieS",2021,"International Journal of Transport Development and Integration",1,"10.2495/TDI-V5-N3-242-253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112224766&doi=10.2495%2fTDI-V5-N3-242-253&partnerID=40&md5=7806cb229b660f4426795e6acc044497","In order to improve the design method of vehicle occupant restraint systems, it is necessary to reduce the computational load of simulations, to improve the global search capability, and to examine and integrate analytical methods to understand the complex interaction between design variables and objective functions. Therefore, in this study, we integrated the following three artificial intelligence technologies and applied them to the design of a vehicle occupant restraint system: (1) construction of a highly accurate approximate model by machine learning, (2) improvement of global search capability by evolutionary multi-objective optimization and (3) visualization and knowledge acquisition of multidimensional information using multivariate analysis methods. First, we obtained the minimum number of actual calculation samples using a crash analysis model with the design of experiments, and then used these samples to construct a highly accurate approximate model using machine learning. Next, we used the approximate model to perform a global search in the design space by evolutionary multi-objective optimization to obtain a Pareto solution set that takes into account the trade-off relationship between the objective functions. Finally, multivariate analysis using cluster analysis and self-organizing maps was performed on the Pareto solution set. As a result, a fast global search was realized by substituting the evaluation calculation of evolutionary multi-objective optimization with a highly accurate approximate model. The Pareto solution set obtained therein was then partitioned into clusters by cluster analysis, and the partitioned clusters were analysed by self-organizing maps, which provided perceptual information on the factors governing the trade-offs between the objective functions and the interactions between the design variables, and were useful for design engineers' insights. © 2021 WIT Press.","Cluster analysis; Evolutionary computation; Machine learning; Multi-objective optimization; Self-organizing maps; Vehicle occupant restraint system","WITPress"
"Akolekar H.D., Waschkowski F., Zhao Y., Pacciani R., Sandberg R.D.","Transition modeling for low pressure turbines using computational fluid dynamics driven machine learning",2021,"Energies",3,"10.3390/en14154680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112673817&doi=10.3390%2fen14154680&partnerID=40&md5=09f417171e9f510909f994157f804583","Existing Reynolds Averaged Navier–Stokes-based transition models do not accurately predict separation induced transition for low pressure turbines. Therefore, in this paper, a novel framework based on computational fluids dynamics (CFD) driven machine learning coupled with multi-expression and multi-objective optimization is explored to develop models which can improve the transition prediction for the T106A low pressure turbine at an isentropic exit Reynolds number of Re2is = 100, 000. Model formulations are proposed for the transfer and laminar eddy viscosity terms of the laminar kinetic energy transition model using seven non-dimensional pi groups. The multi-objective optimization approach makes use of cost functions based on the suction-side wall-shear stress and the pressure coefficient. A family of solutions is thus developed, whose performance is assessed using Pareto analysis and in terms of physical characteristics of separated-flow transition. Two models are found which bring the wall-shear stress profile in the separated region at least two times closer to the reference high-fidelity data than the baseline transition model. As these models are able to accurately predict the flow coming off the blade trailing edge, they are also able to significantly enhance the wake-mixing prediction over the baseline model. This is the first known study which makes use of ‘CFD-driven’ machine learning to enhance the transition prediction for a non-canonical flow. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Low pressure turbine; Machine learning; Multi-objective optimization; Transition; Turbulence modeling","MDPI AG"
"Hui X., Wang H., Li W., Bai J., Qin F., He G.","Multi-object aerodynamic design optimization using deep reinforcement learning",2021,"AIP Advances",,"10.1063/5.0058088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112352458&doi=10.1063%2f5.0058088&partnerID=40&md5=0ecee6c119c84f66aec18f3a56e87048","Aerodynamic design optimization is a key aspect in aircraft design. The further evolution of advanced aircraft derivatives requires a powerful optimization toolbox. Reinforcement learning (RL) is a powerful optimization tool but has rarely been utilized in the aerodynamic design. It can potentially obtain results similar to those of a human designer, by accumulating experience from training. In this work, a popular RL method called proximal policy optimization (PPO) is proposed to investigate multi-object aerodynamic design optimization. By observing the aerodynamic performances of different airfoils, the PPO updates a reasonable policy to generate the optimal airfoils in a single step. In a Pareto optimization problem with constraints, the PPO requires only 15% of the computational time of the non-dominated sorted genetic algorithm (II) to achieve the same accuracy. The results from testing show that the agent learns a policy that can achieve ∼4.3%-10.1% improvements of the aerodynamic performance compared with the results of baseline. © 2021 Author(s).",,"American Institute of Physics Inc."
"Ma J., Nguyen D., Bai T., Folkerts M., Jia X., Lu W., Zhou L., Jiang S.","A feasibility study on deep learning-based individualized 3D dose distribution prediction",2021,"Medical Physics",1,"10.1002/mp.15025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109411338&doi=10.1002%2fmp.15025&partnerID=40&md5=e41f602a03b5e3efe687b8a522ffb3fb","Purpose: Radiation therapy treatment planning is a trial-and-error, often time-consuming process. An approximately optimal dose distribution corresponding to a specific patient's anatomy can be predicted by using pre-trained deep learning (DL) models. However, dose distributions are often optimized based not only on patient-specific anatomy but also on physicians’ preferred trade-offs between planning target volume (PTV) coverage and organ at risk (OAR) sparing or among different OARs. Therefore, it is desirable to allow physicians to fine-tune the dose distribution predicted based on patient anatomy. In this work, we developed a DL model to predict the individualized 3D dose distributions by using not only the patient's anatomy but also the desired PTV/OAR trade-offs, as represented by a dose volume histogram (DVH), as inputs. Methods: In this work, we developed a modified U-Net network to predict the 3D dose distribution by using patient PTV/OAR masks and the desired DVH as inputs. The desired DVH, fine-tuned by physicians from the initially predicted DVH, is first projected onto the Pareto surface, then converted into a vector, and then concatenated with feature maps encoded from the PTV/OAR masks. The network output for training is the dose distribution corresponding to the Pareto optimal DVH. The training/validation datasets contain 77 prostate cancer patients, and the testing dataset has 20 patients. Results: The trained model can predict a 3D dose distribution that is approximately Pareto optimal while having the DVH closest to the input desired DVH. We calculated the difference between the predicted dose distribution and the optimized dose distribution that has a DVH closest to the desired one for the PTV and for all OARs as a quantitative evaluation. The largest absolute error in mean dose was about 3.6% of the prescription dose, and the largest absolute error in the maximum dose was about 2.0% of the prescription dose. Conclusions: In this feasibility study, we have developed a 3D U-Net model with the patient's anatomy and the desired DVH curves as inputs to predict an individualized 3D dose distribution that is approximately Pareto optimal while having the DVH closest to the desired one. The predicted dose distributions can be used as references for dosimetrists and physicians to rapidly develop a clinically acceptable treatment plan. © 2021 American Association of Physicists in Medicine","deep learning; dose volume histogram; Pareto optimal dose distribution prediction; physicians’ preferred trade-offs","John Wiley and Sons Ltd"
"Javad Dehghani M.","Enhancing energo-exergo-economic performance of Kalina cycle for low- to high-grade waste heat recovery: Design and optimization through deep learning methods",2021,"Applied Thermal Engineering",2,"10.1016/j.applthermaleng.2021.117221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109192677&doi=10.1016%2fj.applthermaleng.2021.117221&partnerID=40&md5=583c2f7b1b05ada06d9d2cdc28b87c82","The Kalina cycle has proven to be a reliable bottoming cycle for low-grade waste heat recovery. However, compared with other recovery cycles (e.g. the Rankine cycle), it is characterized by a lower efficiency rate and constraints on the heating medium inlet temperature. This study proposes a systematic method for configuring and optimizing three novel Kalina-trilateral-based systems to overcome those disadvantages. This accurate technique integrates thermodynamics with deep learning to accelerate the computation process. First, the actual thermodynamic-economic features of the alternative systems are modeled through the analyses of energy, exergy, and economy. Second, the surrogate models of the systems are developed through a long short-term memory (LSTM) network. Third, the direct and hybrid optimization algorithms are applied separately to the actual and surrogate models. The objective functions yield thermal efficiency, exergy efficiency, and distributed payback time. Moreover, the strength Pareto evolutionary algorithm (SPEA-II) is employed to solve the multi-objective optimization problem. According to the results, the LSTM network had considerable power to simulate and predict the energo-exergo-economic performance of an energy system. Furthermore, the computation time was much shorter for a hybrid algorithm with the maintained accuracy. Consequently, the heating source temperature constraint was eliminated in the final alternative cycle (KTS-36). Compared with the base system (KCS-34), the thermodynamic and economic objective functions were improved by 74.3% and 34%, respectively. © 2021 Elsevier Ltd","Hybrid optimization algorithm (HOA); Kalina cycle; LSTM; SPEA-II; Trilateral cycle (TLC)","Elsevier Ltd"
"Liu L., Martín-Barragán B., Prieto F.J.","A projection multi-objective SVM method for multi-class classification",2021,"Computers and Industrial Engineering",1,"10.1016/j.cie.2021.107425","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107625571&doi=10.1016%2fj.cie.2021.107425&partnerID=40&md5=2856979ee8cb995b683ef1364b18fce6","Support Vector Machines (SVMs), originally proposed for classifications of two classes, have become a very popular technique in the machine learning field. For multi-class classifications, various single-objective models and multi-objective ones have been proposed. However,in most single-objective models, neither the different costs of different misclassifications nor the users’ preferences were considered. This drawback has been taken into account in multi-objective models.In these models, large and hard second-order cone programs(SOCPs) were constructed ane weakly Pareto-optimal solutions were offered. In this paper, we propose a Projected Multi-objective SVM (PM), which is a multi-objective technique that works in a higher dimensional space than the object space. For PM, we can characterize the associated Pareto-optimal solutions. Additionally, it significantly alleviates the computational bottlenecks for classifications with large numbers of classes. From our experimental results, we can see PM outperforms the single-objective multi-class SVMs (based on an all-together method, one-against-all method and one-against-one method) and other multi-objective SVMs. Compared to the single-objective multi-class SVMs, PM provides a wider set of options designed for different misclassifications, without sacrificing training time. Compared to other multi-objective methods, PM promises the out-of-sample quality of the approximation of the Pareto frontier, with a considerable reduction of the computational burden. © 2021 Elsevier Ltd","Multi-class multi-objective SVM; Multiple objective programming; Pareto-optimal solution; Support vector machine","Elsevier Ltd"
"Zhang J., Huang Y., Ma G., Yuan Y., Nener B.","Automating the mixture design of lightweight foamed concrete using multi-objective firefly algorithm and support vector regression",2021,"Cement and Concrete Composites",6,"10.1016/j.cemconcomp.2021.104103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106495196&doi=10.1016%2fj.cemconcomp.2021.104103&partnerID=40&md5=b49223bd79ac36a7ef1b2cc7b43b52a9","Lightweight concrete (LWC) is widely used in the construction industry due to a variety of advantages. However, compared with traditional normal-weight concrete, more influencing variables (e.g. types of lightweight aggregates) must be considered to optimize multiple properties including uniaxial compressive strength (UCS), density and cost. This makes the mixture design of LWC more difficult or sometimes impossible using laboratory experiments. To address this issue, this study proposes a multi-objective optimization (MOO) method using machine learning and metaheuristic approaches for LWC mixture design through a two-step approach. In the first step, a least squares support vector regression (LSSVR) model is constructed to predict multiple properties of LWC. The hyper-parameters of the LSSVR model are tuned using the firefly algorithm (FA). A dataset containing a large number of different mixtures of LWC is compiled from published literature. High prediction accuracy (0.97 for UCS and 0.90 for density) is achieved on the test dataset (including 30% of all the instances). In the second step, a newly developed multi-objective FA (MOFA) model is used to optimize the LWC mixture, while satisfying the constraints. The Pareto fronts of the triple objectives (UCS, cost and density) are successfully obtained. The proposed MOO method is powerful and efficient in finding optimal LWC mixtures with conflicting objectives and therefore decision making can be facilitated in early phases of construction. © 2021 Elsevier Ltd","Density; Firefly algorithm; Least-square support vector regression; Lightweight concrete; Mixture design; Multi-objective optimization; Uniaxial compressive strength","Elsevier Ltd"
"Hofmann J., Schüttrumpf H.","Floodgan: Using deep adversarial learning to predict pluvial flooding in real time",2021,"Water (Switzerland)",1,"10.3390/w13162255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113534613&doi=10.3390%2fw13162255&partnerID=40&md5=ee80c926deda419c432228b624fdf72b","Using machine learning for pluvial flood prediction tasks has gained growing attention in the past years. In particular, data-driven models using artificial neuronal networks show promising results, shortening the computation times of physically based simulations. However, recent approaches have used mainly conventional fully connected neural networks which were (a) restricted to spatially uniform precipitation events and (b) limited to a small amount of input data. In this work, a deep convolutional generative adversarial network has been developed to predict pluvial flooding caused by nonlinear spatial heterogeny rainfall events. The model developed, floodGAN, is based on an image-to-image translation approach whereby the model learns to generate 2D inundation predictions conditioned by heterogenous rainfall distributions—through the minimax game of two adversarial networks. The training data for the floodGAN model was generated using a physically based hydrodynamic model. To evaluate the performance and accuracy of the floodGAN, model multiple tests were conducted using both synthetic events and a historic rainfall event. The results demonstrate that the proposed floodGAN model is up to 106 times faster than the hydrodynamic model and promising in terms of accuracy and generalizability. Therefore, it bridges the gap between detailed flood modelling and real-time applications such as end-to-end early warning systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Flood modelling; Generative adversarial networks; Machine learning; Real-time flood forecasting","MDPI"
"Al-Najjar H.A.H., Pradhan B., Kalantar B., Sameen M.I., Santosh M., Alamri A.","Landslide susceptibility modeling: An integrated novel method based on machine learning feature transformation",2021,"Remote Sensing",5,"10.3390/rs13163281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113361845&doi=10.3390%2frs13163281&partnerID=40&md5=fb3b893d59d1259f8e0bdc45d4e5c606","Landslide susceptibility modeling, an essential approach to mitigate natural disasters, has witnessed considerable improvement following advances in machine learning (ML) techniques. However, in most of the previous studies, the distribution of input data was assumed as being, and treated, as normal or Gaussian; this assumption is not always valid as ML is heavily dependent on the quality of the input data. Therefore, we examine the effectiveness of six feature transformations (minimax normalization (Std-X), logarithmic functions (Log-X), reciprocal function (Rec-X), power functions (Power-X), optimal features (Opt-X), and one-hot encoding (Ohe-X) over the 11conditioning factors (i.e., altitude, slope, aspect, curvature, distance to road, distance to lineament, distance to stream, terrain roughness index (TRI), normalized difference vegetation index (NDVI), land use, and vegetation density). We selected the frequent landslide-prone area in the Cameron Highlands in Malaysia as a case study to test this novel approach. These transformations were then assessed by three benchmark ML methods, namely extreme gradient boosting (XGB), logistic regression (LR), and artificial neural networks (ANN). The 10-fold cross-validation method was used for model evaluations. Our results suggest that using Ohe-X transformation over the ANN model considerably improved performance from 52.244 to 89.398 (37.154% improvement). © 2021 by the author. Licensee MDPI, Basel, Switzerland.","Feature transformations; GIS; Landslide susceptibility; LiDAR; Machine learning; Remote sensing","MDPI AG"
"Banisetty S.B., Rajamohan V., Vega F., Feil-Seifer D.","A deep learning approach to multi-context socially-aware navigation",2021,"2021 30th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2021",,"10.1109/RO-MAN50785.2021.9515424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115112552&doi=10.1109%2fRO-MAN50785.2021.9515424&partnerID=40&md5=d69fe5fa6ec877334ac30d37395285c6","We present a context classification pipeline to allow a robot to change its navigation strategy based on the observed social scenario. Socially-Aware Navigation considers social behavior in order to improve navigation around people. Most of the existing research uses different techniques to incorporate social norms into robot path planning for a single context. Methods that work for hallway behavior might not work for approaching people, and so on. We developed a high-level decision-making subsystem, a model-based context classifier, and a multi-objective optimization-based local planner to achieve socially-aware trajectories for autonomously sensed contexts. Using a context classification system, the robot can select social objectives that are later used by Pareto Concavity Elimination Transformation (PaCcET) based local planner to generate safe, comfortable, and socially appropriate trajectories for its environment. This was tested and validated in multiple environments on a Pioneer mobile robot platform; results show that the robot could select and account for social objectives related to navigation autonomously. © 2021 IEEE.",,"Institute of Electrical and Electronics Engineers Inc."
"Wang Y., Wang X., Beutel A., Prost F., Chen J., Chi E.H.","Understanding and Improving Fairness-Accuracy Trade-offs in Multi-Task Learning",2021,"Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",,"10.1145/3447548.3467326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114932943&doi=10.1145%2f3447548.3467326&partnerID=40&md5=9a58dc6205391f333faca89f37d1e972","As multi-task models gain popularity in a wider range of machine learning applications, it is becoming increasingly important for practitioners to understand the fairness implications associated with those models. Most existing fairness literature focuses on learning a single task more fairly, while how ML fairness interacts with multiple tasks in the joint learning setting is largely under-explored. In this paper, we are concerned with how group fairness (e.g., equal opportunity, equalized odds) as an ML fairness concept plays out in the multi-task scenario. In multi-task learning, several tasks are learned jointly to exploit task correlations for a more efficient inductive transfer. This presents a multi-dimensional Pareto frontier on (1) the trade-off between group fairness and accuracy with respect to each task, as well as (2) the trade-offs across multiple tasks. We aim to provide a deeper understanding on how group fairness interacts with accuracy in multi-task learning, and we show that traditional approaches that mainly focus on optimizing the Pareto frontier of multi-task accuracy might not perform well on fairness goals. We propose a new set of metrics to better capture the multi-dimensional Pareto frontier of fairness-accuracy trade-offs uniquely presented in a multi-task learning setting. We further propose a Multi-Task-Aware Fairness (MTA-F) approach to improve fairness in multi-task learning. Experiments on several real-world datasets demonstrate the effectiveness of our proposed approach. © 2021 Owner/Author.","fairness; multi-task learning; multi-task-aware fairness treatment; pareto frontier","Association for Computing Machinery"
"Guo C., Ryoo H.S.","On Pareto-Optimal Boolean Logical Patterns for Numerical Data",2021,"Applied Mathematics and Computation",3,"10.1016/j.amc.2021.126153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103388036&doi=10.1016%2fj.amc.2021.126153&partnerID=40&md5=2b719725c76f0d9f25fa594ddc55b14b","This paper clarifies the difference between intrinsically 0–1 data and binarized numerical data for Boolean logical patterns and strengthens mathematical results and methods from the literature on Pareto-optimal LAD patterns. Toward this end, we select suitable pattern definitions from the literature and adapt them with attention given to unique characteristics of individual patterns and the disparate natures of Boolean and numerical data. Next, we propose a set of revised criteria and definitions by which useful LAD patterns are clearly characterized for both 0–1 and real-valued data. Furthermore, we fortify recent pattern generation optimization models and demonstrate how earlier results on Pareto-optimal patterns can be adapted in accordance with revised pattern definitions. A numerical study validates practical benefits of the results of this paper through optimization-based pattern generation experiments. © 2021","Boolean logical pattern; Knowledge discovery; Logical analysis of data; Pareto-optimal pattern; Supervised learning","Elsevier Inc."
"Yu Y., Liew S.C., Wang T.","Non-Uniform Time-Step Deep Q-Network for Carrier-Sense Multiple Access in Heterogeneous Wireless Networks",2021,"IEEE Transactions on Mobile Computing",3,"10.1109/TMC.2020.2990399","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112710104&doi=10.1109%2fTMC.2020.2990399&partnerID=40&md5=23a579da14c9e9c4ebac5680fb7cc44c","This paper investigates a new class of carrier-sense multiple access (CSMA) protocols that employ deep reinforcement learning (DRL) techniques, referred to as carrier-sense deep-reinforcement learning multiple access (CS-DLMA). The goal of CS-DLMA is to enable efficient and equitable spectrum sharing among a group of co-located heterogeneous wireless networks. Existing CSMA protocols, such as the medium access control (MAC) protocol of WiFi, are designed for a homogeneous network in which all nodes adopt the same protocol. Such protocols suffer from severe performance degradation in a heterogeneous environment where there are nodes adopting other MAC protocols. CS-DLMA aims to circumvent this problem by making use of DRL. In particular, this paper adopts $\alpha$α-fairness as the general objective of CS-DLMA. With $\alpha$α-fairness, CS-DLMA can achieve a range of different objectives (e.g., maximizing sum throughput, achieving proportional fairness, or achieving max-min fairness) when coexisting with other MACs by changing the value of $\alpha$α. A salient feature of CS-DLMA is that it can achieve these objectives without knowing the coexisting MACs through a learning process based on DRL. The underpinning DRL technique in CS-DLMA is deep Q-network (DQN). However, the conventional DQN algorithms are not suitable for CS-DLMA due to their uniform time-step assumption. In CSMA protocols, time steps are non-uniform in that the time duration required for carrier sensing is smaller than the duration of data transmission. This paper introduces a non-uniform time-step formulation of DQN to address this issue. Our simulation results show that CS-DLMA can achieve the general $\alpha$α-fairness objective when coexisting with TDMA, ALOHA, and WiFi protocols by adjusting its own transmission strategy. Interestingly, we also find that CS-DLMA is more Pareto efficient than other CSMA protocols, e.g., p-persistent CSMA, when coexisting with WiFi. Although this paper focuses on the use of our non-uniform time-step DQN formulation in wireless networking, we believe this new DQN formulation can also find use in other domains. © 2002-2012 IEEE.","Deep reinforcement learning; Heterogeneous wireless networks; Medium access control (MAC); α-fairness","Institute of Electrical and Electronics Engineers Inc."
"chen C., Xu X., Zou B., Peng H., Li Z.","Optimal decision of multiobjective and multiperiod anticipatory shipping under uncertain demand: A data-driven framework",2021,"Computers and Industrial Engineering",1,"10.1016/j.cie.2021.107445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109175944&doi=10.1016%2fj.cie.2021.107445&partnerID=40&md5=9aa0b413c3f72a16586cc4c998af86b3","Anticipatory shipping helps to reduce the waiting time of online customers to receive their products. Present studies on anticipatory shipping mainly consider a single period and ignore the waiting time saved for customers. This paper develops a data-driven framework to investigate the multiperiod anticipatory shipping problem with the objectives of minimizing the cost of online retailers and maximizing the saved waiting time of customers. First, we propose a dual-process sales forecasting framework that employs five machine learning algorithms to forecast online retailers’ daily sales using clickstream data and historical sales data. Then, we build a multiperiod and multiobjective integer programming model based on the forecasting sales and forecasting errors to explore the optimal quantity and time of products of anticipatory shipping. Finally, using TOPSIS, Shannon entropy, and LINMAP decision-making methods, the final optimal solution is selected from the Pareto set obtained by the NSGA-II algorithm. The case study results show that anticipatory shipping saves 5.96% cost for the online retailer and 1.69 days of waiting time on average for the customer compared with non-anticipatory shipping. Moreover, performing anticipatory shipping is especially beneficial in the case of high inventory holding cost, large distribution center capacity, and long transportation duration. © 2021 Elsevier Ltd","Anticipatory shipping; Data-driven; Integer programming model; Multiobjective; Online retail","Elsevier Ltd"
"Wang Y., Liu T., Zhang D., Xie Y.","Dual-convolutional neural network based aerodynamic prediction and multi-objective optimization of a compact turbine rotor",2021,"Aerospace Science and Technology",6,"10.1016/j.ast.2021.106869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107740524&doi=10.1016%2fj.ast.2021.106869&partnerID=40&md5=555d90af96ee5d3da7dca5987ab35e64","With the development of neural network technology, surrogate models and dimensionality reduction strategies based on machine learning have become the research hotspots of aerodynamic shape optimization recently. In order to further improve the accuracy and interpretability of the traditional surrogate models, this research establishes a deep learning model, named Dual Convolutional Neural Network (Dual-CNN) for the aero-engine turbines. The aerodynamic performances are predicted and the pressure, temperature fields are reconstructed for multiple rotor profile conditions. The prediction of efficiency is compared with the accuracy of Gaussian Process Regression (GPR) and Artificial Neural Network (ANN) models. The results show that the proposed Dual-CNN model can accurately reconstruct the fields, thus interpreting the mechanism for the change of aerodynamic performance. Dual-CNN is more accurate than GPR and ANN in predicting efficiency and torque, whose error is within an acceptable range of optimization. Then, efficiency and torque are selected as the objective functions to perform a gradient-based multi-objective optimization by the automatic differentiation method and a Pareto solution is obtained. The trained Dual-CNN provides rapid and accurate prediction of performance without CFD calculation in the optimization. Finally, the sensitivity to train size is analyzed for the Dual-CNN model, which indicates that the sampling of 1500 cases for eight design variables in this dataset enables Dual-CNN to achieve favorable effect of field reconstruction and performance prediction. © 2021 Elsevier Masson SAS","Aerodynamic prediction; Convolution neural network; Deep learning; Multi-objective optimization; Turbine","Elsevier Masson s.r.l."
"Yan X., Mohammadian A., Khelifa A.","Modeling spatial distribution of flow depth in fluvial systems using a hybrid two-dimensional hydraulic-multigene genetic programming approach",2021,"Journal of Hydrology",3,"10.1016/j.jhydrol.2021.126517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107598478&doi=10.1016%2fj.jhydrol.2021.126517&partnerID=40&md5=cc162b5c0ec6af14db2892d9d448e5af","Modeling spatial distribution of flow depth in fluvial systems is crucial for flow mitigation, river rehabilitation, and design of water resources infrastructure. Flow depth in fluvial systems can be typically estimated using hydrological or physics-based hydraulic models. However, hydrological models may not be able to provide satisfactory predictions for catchments with limited data because they normally ignored the strict conservation of momentum. Traditional fully physics-based hydraulic models are often very computationally expensive, limiting their wide usage in practical applications. In this study, a novel method, based on a hybrid two-dimensional (2D) hydraulic-multigene genetic programming (MGGP) approach, is proposed and employed to model the spatial distribution of flow depth in fluvial systems. A 2D hydraulic model was constructed using the TELEMAC-2D software and validated against field measurements. The validated model was then assumed to reflect the real physical processes and utilized to carry out additional computations to obtain spatial distribution of flow depth under different discharge scenarios, which provided a sufficient synthetic dataset for training machine learning models based on the MGGP technique. The study area (a segment of the Ottawa River near the island named Île Kettle) was divided into 34 sub-regions to further reduce the computational costs of the training processes and the complexity of the evolved models. The numerical data were distributed to the corresponding sub-regions, and an MGGP-based model was trained for each sub-region. These models are compact explicit arithmetic equations that can be readily transferable and can immediately output the flow depth at any point in the corresponding sub-region as functions of the flow rate, longitudinal, and transversal coordinates. The best MGGP model for each sub-region amongst all the generated models was identified using the Pareto optimization approach. The results showed that the best MGGP models satisfactorily reproduced the training data and predicted the testing data (the root mean square errors were 0.303 m and 0.306 m, respectively), demonstrating the predictive capability of the approach. A comparison between MGGP and single-gene genetic programming (SGGP) approaches and confidence analysis were also reported, which demonstrated the good performance of the proposed approach. Furthermore, it took about 53 min for the hydraulic model to complete each simulation, but it took only about 0.56 s using the final model; the total size of the hydraulic output files for 12 different sizes was 432, 948 KB, but the total size of the script file for the final model was only about 46 KB. Therefore, the present study found that the hybrid 2D hydraulic-MGGP approach was satisfactorily accurate, fast to run, and easy to use, and thus, it is a promising tool for modeling spatial distribution of flow depth in fluvial systems. © 2021","2D hydraulic; Flow depth; Multigene genetic programming; Ottawa River; Spatial distribution","Elsevier B.V."
"Khursheed S., Jagan J., Samui P., Kumar S.","Compressive strength prediction of fly ash concrete by using machine learning techniques",2021,"Innovative Infrastructure Solutions",1,"10.1007/s41062-021-00506-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107005426&doi=10.1007%2fs41062-021-00506-z&partnerID=40&md5=3a8a571e4c4729778d90898fbffc7508","In this research, the machine learning techniques such as, minimax probability machine regression (MPMR), relevance vector machine (RVM), genetic programming (GP), emotional neural network (ENN) and extreme learning machine (ELM) were utilized in the event of forecasting the 28 days compressive strength of fly ash concrete. In the present examination, exploratory database enveloping appropriate information recovered from a few past investigations has been made and used to prepare and approve the abovementioned MPMR, RVM, GP, ENN and ELM models. The database consists of cement, fly ash, coarse aggregate, fine aggregate, water, and water-binder ratio as the inputs whereas compressive strength of the concrete for 28 days is the output. The capability of the described models can be assessed by distinctive statistical parameters. The results from the mentioned models have been compared and decided that the MPMR model (R = 0.992) could be occupied as a decisive and authoritative data astute approach for forecasting the compressive strength of concrete which was fusion with fly ash as the admixture, thus preserving the tedious laboratory works. The accuracy of the adopted techniques was justified by comparing the distinct statistical parameters, distribution figures, and Taylor diagrams. © 2021, Springer Nature Switzerland AG.","Compressive strength; Fly ash; Minimax probability machine regression; Prediction; Relevance vector machine","Springer Science and Business Media Deutschland GmbH"
"Riahi-Madvar H., Gholami M., Gharabaghi B., Morteza Seyedian S.","A predictive equation for residual strength using a hybrid of subset selection of maximum dissimilarity method with Pareto optimal multi-gene genetic programming",2021,"Geoscience Frontiers",1,"10.1016/j.gsf.2021.101222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105565032&doi=10.1016%2fj.gsf.2021.101222&partnerID=40&md5=57260b53ad4dec9b3ad9905a2c918a57","More accurate and reliable estimation of residual strength friction angle (ϕr) of clay is crucial in many geotechnical engineering applications, including riverbank stability analysis, design, and assessment of earthen dam slope stabilities. However, a general predictive equation for ϕr, with applicability in a wide range of effective parameters, remains an important research gap. The goal of this study is to develop a more accurate equation for ϕr using the Pareto Optimal Multi-gene Genetic Programming (POMGGP) approach by evaluating a comprehensive dataset of 290 experiments compiled from published literature databases worldwide. A new framework for integrated equation derivation proposed that hybridizes the Subset Selection of Maximum Dissimilarity Method (SSMD) with Multi-gene Genetic Programming (MGP) and Pareto-optimality (PO) to find an accurate equation for ϕr with wide range applicability. The final predictive equation resulted from POMGGP modeling was assessed in comparison with some previously published machine learning-based equations using statistical error analysis criteria, Taylor diagram, revised discrepancy ratio (RDR), and scatter plots. Base on the results, the POMGGP has the lowest uncertainty with U95 = 2.25, when compared with Artificial Neural Network (ANN) (U95 = 2.3), Bayesian Regularization Neural Network (BRNN) (U95 = 2.94), Levenberg-Marquardt Neural Network (LMNN) (U95 = 3.3), and Differential Evolution Neural Network (DENN) (U95 = 2.37). The more reliable results in estimation of ϕr derived by POMGGP with reliability 59.3%, and resiliency 60% in comparison with ANN (reliability = 30.23%, resiliency = 28.33%), BRNN (reliability = 10.47%, resiliency = 10.39%), LMNN (reliability = 19.77%, resiliency = 20.29%) and DENN (reliability = 27.91%, resiliency = 24.19%). Besides the simplicity and ease of application of the new POMGGP equation to a broad range of conditions, using the uncertainty, reliability, and resilience analysis confirmed that the derived equation for ϕr significantly outperformed other existing machine learning methods, including the ANN, BRNN, LMNN, and DENN equations. © 2021 China University of Geosciences (Beijing) and Peking University","Earth slopes; Friction angle; Maximum dissimilarity; Multi-gene genetic programming; Pareto-optimality; Residual strength","Elsevier B.V."
"Prabakaran B.S., Akhtar A., Rehman S., Hasan O., Shafique M.","BioNetExplorer: Architecture-Space Exploration of Biosignal Processing Deep Neural Networks for Wearables",2021,"IEEE Internet of Things Journal",2,"10.1109/JIOT.2021.3065815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102681138&doi=10.1109%2fJIOT.2021.3065815&partnerID=40&md5=14ee8b46b315c9933dd6fc6d6bf2b24f","Deep learning (DL) has been shown to be highly effective in solving various problems across numerous applications and domains, such as autonomous driving and image recognition. Due to the advent of DL, plenty of research works have explored the applicability of DL, more specifically deep neural networks (DNNs), to solve pattern recognition and computer vision challenges. More recently, researchers have focused on the topic of automated generation and exploration of DNN architectures, which tend to mostly focus on image recognition or visual data sets, primarily, due to the computer vision-related DL advancements. In this work, we propose the BioNetExplorer framework to systematically generate and explore multiple DNN architectures for biosignal processing in wearable devices. Our framework varies key neural architecture parameters to search for an embedded DNN architecture with a low hardware overhead, which can be deployed in wearable edge devices to analyze the biosignal data and to extract the relevant information, such as arrhythmia and seizure. Furthermore, BioNetExplorer reduces the exploration time by deploying genetic algorithms, such as NSGA-II, SPEA-2, etc. Our framework also enables the hardware-aware DNN architecture search by imposing user requirements and hardware constraints (storage, FLOPs, etc.) during the exploration stage, thereby limiting the number of networks explored. Moreover, BioNetExplorer can also be used to search for DNNs based on the user-required output classes; for instance, a user might require a specific output class, attributed toward ventricular fibrillation, due to genetic predisposition or a preexisting heart condition. The use of genetic algorithms reduces the exploration time, on average, by 9\times , compared to exhaustive exploration. We are successful in identifying Pareto-optimal designs, which can reduce the storage overhead of DNN by \sim 30 MB for a quality loss of less than 0.5%. To enable low-cost embedded DNNs, BioNetExplorer also employs different model compression techniques to further reduce the storage overhead of the network by up to 53\times for a quality loss of < 0.2\%. © 2014 IEEE.","Bio-signals; convolution; deep neural networks (DNNs); efficiency; embedded systems; exploration; healthcare; long short-term memory (LSTM); performance; wearables","Institute of Electrical and Electronics Engineers Inc."
"Marchisio A., Mrazek V., Hanif M.A., Shafique M.","DESCNet: Developing Efficient Scratchpad Memories for Capsule Network Hardware",2021,"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",2,"10.1109/TCAD.2020.3030610","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092935204&doi=10.1109%2fTCAD.2020.3030610&partnerID=40&md5=5ed9a7b969d540cb99ec08dec002fbc1","Deep neural networks (DNNs) have been established as the state-of-the-art method for advanced machine learning applications. Recently proposed by the Google Brain's team, the capsule networks (CapsNets) have improved the generalization ability, as compared to DNNs, due to their multidimensional capsules and preserving the spatial relationship between different objects. However, they pose significantly high computational and memory requirements, making their energy-efficient inference a challenging task. This article provides, for the first time, an in-depth analysis to highlight the design and runtime challenges for the (on-chip scratchpad) memories deployed in hardware accelerators executing fast CapsNets inference. To enable an efficient design, we propose an application-specific memory architecture, called DESCNet, which minimizes the off-chip memory accesses, while efficiently feeding the data to the hardware accelerator executing CapsNets inference. We analyze the corresponding on-chip memory requirement and leverage it to propose a methodology for exploring different scratchpad memory (SPM) designs and their energy/area tradeoffs. Afterward, an application-specific power-gating technique for the on-chip SPM is employed to further reduce its energy consumption, depending upon the mapped dataflow of the CapsNet and the utilization across different operations of its processing. We integrated our DESCNet memory design, as well as another state-of-the-art memory design Marchisio et al. [2018] for comparison studies, with an opensource DNN accelerator executing Google's CapsNet model Sabour et al. [2017] for the MNIST dataset. We also enhanced the design to execute the recent deep CapsNet model Rajasegaran et al. [2019] for the CIFAR10 dataset. Note: we use the same benchmarks and test conditions for which these CapsNets have been proposed and evaluated by their respective teams. The complete hardware is synthesized for a 32-nm CMOS technology using the ASIC-design flow with Synopsys tools and CACTI-P, and detailed area, performance, and power/energy estimation is performed using different configurations. Our results for a selected Pareto-optimal solution demonstrate no performance loss and an energy reduction of 79% for the complete accelerator, including computational units and memories, when compared to the state-of-the-art design. © 1982-2012 IEEE.","Capsule networks (CapsNets); design space exploration (DSE); energy efficiency; machine learning (ML); memory design; memory management; performance; power gating; scratchpad memory (SPM); special-purpose hardware","Institute of Electrical and Electronics Engineers Inc."
"You J., Ampomah W., Morgan A., Sun Q., Huang X.","A comprehensive techno-eco-assessment of CO2 enhanced oil recovery projects using a machine-learning assisted workflow",2021,"International Journal of Greenhouse Gas Control",,"10.1016/j.ijggc.2021.103480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116598560&doi=10.1016%2fj.ijggc.2021.103480&partnerID=40&md5=458dac041034ff4e758bbb5fad1b3670","Carbon dioxide enhanced oil recovery (CO2-EOR) projects not only extract residual oil but also sequestrate CO2 in the depleted reservoirs. This study develops a machine-learning-based workflow to co-optimize the hydrocarbon recovery, CO2 sequestration volume and project net present value (NPV) simultaneously. Considering the trade-off relationships among the objective functions, support vector regression with Gaussian kernel (Gaussian- SVR) proxies are coupled with multi-objective particle swarm optimization (PSO) protocol and generate Pareto optimal solutions. Taking advantage of the high computational efficacy of the proxy model, economic uncertainties introduced by tax credits, capital costs and oil price are investigated by this study. The results indicate that the tax incentive policy (Section 45Q) plays a vital role in enhancing the economic returns of CO2-EOR projects, especially under the depression of crude oil market. The proposed workflow has been successfully implemented to optimize a water alternative CO2 (CO2-WAG) injection project in a depleted oil sand in the US. The optimization results yield an incremental oil production of 15.8 MM STB and 1.37 MM metric tons of CO2 storage in a 20-year development strategy, with the highest project NPV to be 205.6 MM US dollars. © 2021","CCUS; CO2-EOR; Economics assessment; Machine learning; Multi-objective optimization","Elsevier Ltd"
"Chen J., Li K., Li K., Yu P.S., Zeng Z.","Dynamic bicycle dispatching of dockless public bicycle-sharing systems using multi-objective reinforcement learning",2021,"ACM Transactions on Cyber-Physical Systems",,"10.1145/3447623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116049596&doi=10.1145%2f3447623&partnerID=40&md5=31fd1b961d728f5656311d0c4de3f560","As a new generation of Public Bicycle-sharing Systems (PBS), the Dockless PBS (DL-PBS) is an important application of cyber-physical systems and intelligent transportation. How to use artificial intelligence to provide efficient bicycle dispatching solutions based on dynamic bicycle rental demand is an essential issue for DL-PBS. In this article, we propose MORL-BD, a dynamic bicycle dispatching algorithm based on multi-objective reinforcement learning to provide the optimal bicycle dispatching solution for DL-PBS. We model the DL-PBS system from the perspective of cyber-physical systems and use deep learning to predict the layout of bicycle parking spots and the dynamic demand of bicycle dispatching. We define the multi-route bicycle dispatching problem as a multi-objective optimization problem by considering the optimization objectives of dispatching costs, dispatch truck's initial load, workload balance among the trucks, and the dynamic balance of bicycle supply and demand. On this basis, the collaborative multi-route bicycle dispatching problem among multiple dispatch trucks is modeled as a multi-agent and multi-objective reinforcement learning model. All dispatch paths between parking spots are defined as state spaces, and the reciprocal of dispatching costs is defined as a reward. Each dispatch truck is equipped with an agent to learn the optimal dispatch path in the dynamic DL-PBS network. We create an elite list to store the Pareto optimal solutions of bicycle dispatch paths found in each action, and finally get the Pareto frontier. Experimental results on the actual DL-PBS show that compared with existing methods, MORL-BD can find a higher quality Pareto frontier with less execution time. © 2021 Association for Computing Machinery.","bicycle dispatching; Bicycle-sharing systems; intelligent transportation; multi-objective reinforcement learning; Pareto optimality","Association for Computing Machinery"
"Guilcher A., Laneelle D., Mahé G.","Use of a pre‐trained neural network for automatic classification of arterial doppler flow waveforms: A proof of concept",2021,"Journal of Clinical Medicine",,"10.3390/jcm10194479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115874724&doi=10.3390%2fjcm10194479&partnerID=40&md5=ad8817bc5f4b2c3d4cd6ce9dddb20ac1","Background: Arterial Doppler flow waveform analysis is a tool recommended for the management of lower extremity peripheral arterial disease (PAD). To standardize the waveform analysis, classifications have been proposed. Neural networks have shown a great ability to categorize data. The aim of the present study was to use an existing neural network to evaluate the potential for categorization of arterial Doppler flow waveforms according to a commonly used classification. Methods: The Pareto efficient ResNet‐101 (ResNet‐101) neural network was chosen to categorize 424 images of arterial Doppler flow waveforms according to the Simplified Saint‐Bonnet classification. As a reference, the inter‐operator variability between two trained vascular medicine physicians was also assessed. Accuracy was expressed in percentage, and agreement was assessed using Cohen’s Kappa coefficient. Results: After retraining, ResNet‐101 was able to categorize waveforms with 83.7 ± 4.6% accuracy resulting in a kappa coefficient of 0.79 (0.75–0.83) (CI 95%), compared with a kappa coefficient of 0.83 (0.79–0.87) (CI 95%) between the two physicians. Conclusion: This study suggests that the use of transfer learning on a pre‐trained neural network is feasible for the automatic classification of images of arterial Doppler flow waveforms. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Doppler waveform; Neural network classification; Peripheral artery disease","MDPI"
"Mooselu M.G., Nikoo M.R., Bakhtiari P.H., Rayani N.B., Izady A.","Conflict resolution in the multi-stakeholder stepped spillway design under uncertainty by machine learning techniques",2021,"Applied Soft Computing",2,"10.1016/j.asoc.2021.107721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111308641&doi=10.1016%2fj.asoc.2021.107721&partnerID=40&md5=146aee9586828d11c3a74ba56896171a","The optimal spillway design is of great significance since these structures can reduce erosion downstream of the dams. This study proposes a risk-based optimization framework for a stepped spillway to achieve an economical design scenario with the minimum loss in hydraulic performance. Accordingly, the stepped spillway was simulated in the FLOW-3D® model, and the validated model was repeatedly performed for various geometric states. The results were used to form a Multilayer Perceptron artificial neural network (MLP-ANN) surrogate model. Then, a risk-based optimization model was formed by coupling the MLP-ANN and NSGA-II. The concept of conditional value at risk (CVaR) was utilized to reduce the risk of the designed spillway malfunctions in high flood flow rates, while minimizing the construction cost and the loss in hydraulic performance. Lastly, given the conflicting objectives of stakeholders, the non-cooperative graph model for conflict resolution (GMCR) was applied to achieve a compromise on the Pareto optimal solutions. Applicability of the suggested approach in the Jarreh Dam, Iran, resulted in a practical design scenario, which simultaneously minimizes the loss in hydraulic performance and the project cost and satisfies the priorities of decision-makers. © 2021 Elsevier B.V.","CVaR-based optimization model; FLOW-3D®; GMCR-plus; NSGA-II; Stepped spillway","Elsevier Ltd"
"Wei L., Chen Y., Chen M., Chen Y.","Deep reinforcement learning and parameter transfer based approach for the multi-objective agile earth observation satellite scheduling problem",2021,"Applied Soft Computing",1,"10.1016/j.asoc.2021.107607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109489206&doi=10.1016%2fj.asoc.2021.107607&partnerID=40&md5=0261744b94460181b778be52c55defc8","The agile earth observation satellite scheduling problem (AEOSSP) consists of selecting and scheduling a number of tasks from a set of user requests in order to optimize one or multiple criteria. In this paper, we consider a multi-objective version of AEOSSP (called MO-AEOSSP) where the failure rate and the timeliness of scheduled requests are optimized simultaneously. Due to its NP-hardness, traditional iterative problem-tailored heuristic methods are sensitive to problem instances and require massive computational overhead. We thus propose a deep reinforcement learning and parameter transfer based approach (RLPT) to tackle the MO-AEOSSP in a non-iterative manner. RLPT first decomposes the MO-AEOSSP into a number of scalarized sub-problems by a weight sum approach where each sub-problem can be formulated as a Markov Decision Process (MDP). RLPT then applies an encoder–decoder structure neural network (NN) trained by a deep reinforcement learning procedure to producing a high-quality schedule for each sub-problem. The resulting schedules of all scalarized sub-problems form an approximate pareto front for the MO-AEOSSP. Once a NN of a subproblem is trained, RLPT applies a parameter transfer strategy to reducing the training expenses for its neighboring sub-problems. Experimental results on a large set of randomly generated instances show that RLPT outperforms three classical multi-objective evolutionary algorithms (MOEAs) in terms of solution quality, solution distribution and computational efficiency. Results on various-size instances also show that RLPT is highly general and scalable. To the best of our knowledge, this study is the first attempt that applies deep reinforcement learning to a satellite scheduling problem considering multiple objectives. © 2021 Elsevier B.V.","Agile satellite scheduling; Deep reinforcement learning; MOEA; Multi-objective","Elsevier Ltd"
"Kookalani S., Cheng B., Xiang S.","Shape optimization of GFRP elastic gridshells by the weighted Lagrange ε-twin support vector machine and multi-objective particle swarm optimization algorithm considering structural weight",2021,"Structures",1,"10.1016/j.istruc.2021.05.077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107557969&doi=10.1016%2fj.istruc.2021.05.077&partnerID=40&md5=d9009fb231ceb138875940dfc2d8525d","Elastic gridshell is a type of free-form structure usually with double-curved shape and it is constructed by deforming an initially flat grid to achieve the final structural form. Determining a reasonable structural shape considering structural performance is an essential task in the design of such structures. This paper presents a shape optimization method for elastic gridshells considering structural weight, aiming to minimize the structural stress and deformation. Support vector machine is utilized to predict the structural performance in the optimization process in order to avoid the time-consuming structural analysis. The least square support vector machine (LSSVM), weighted least square support vector machine (WLSSVM), a combination of particle swarm optimization and least square support vector machine (PSO-LSSVM), and weighted Lagrange ε-twin support vector machine (WL-ε-TSVM) are first compared for predicting the structural analysis results. The WL-ε-TSVM algorithm shows superior performance and is further adopted in the optimization method. The k-fold cross validation is implemented during the validation process of this algorithm to improve the predictive performance. Based on predicted structural performance, the optimal shape of gridshell is provided by using the multi-objective particle swarm optimization (MOPSO) algorithm. The Taguchi technique is applied to tune the parameters of the MOPSO algorithm. Afterwards, the technique for order preference by similarity to ideal solution (TOPSIS) is implemented to determine the most desirable solution from the Pareto optimal set. The presented method is validated through an example and the structural behavior of the optimized structure is further assessed by finite element analysis. Results demonstrate that the presented method is applicable for finding the optimum shape of gridshells with high structural performance. © 2021 Institution of Structural Engineers","Cross validation; Gridshell structure; Machine learning; MOPSO; Particle swarm optimization; Structural optimization; Support vector machine; Taguchi; TOPSIS","Elsevier Ltd"
"Li M., Wang Z., Li K., Liao X., Hone K., Liu X.","Task Allocation on Layered Multiagent Systems: When Evolutionary Many-Objective Optimization Meets Deep Q-Learning",2021,"IEEE Transactions on Evolutionary Computation",3,"10.1109/TEVC.2021.3049131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099253961&doi=10.1109%2fTEVC.2021.3049131&partnerID=40&md5=cc37ccfae9f7e868405dd36f6a7e1218","This article is concerned with the multitask multiagent allocation problem via many-objective optimization for multiagent systems (MASs). First, a novel layered MAS model is constructed to address the multitask multiagent allocation problem that includes both the original task simplification and the many-objective allocation. In the first layer of the model, the deep Q-learning method is introduced to simplify the prioritization of the original task set. In the second layer of the model, the modified shift-based density estimation (MSDE) method is put forward to improve the conventional strength Pareto evolutionary algorithm 2 (SPEA2) in order to achieve many-objective optimization on task assignments. Then, an MSDE-SPEA2-based method is proposed to tackle the many-objective optimization problem with objectives including task allocation, makespan, agent satisfaction, resource utilization, task completion, and task waiting time. As compared with the existing allocation methods, the developed method in this article exhibits an outstanding feature that the task assignment and the task scheduling are carried out simultaneously. Finally, extensive experiments are conducted to: 1) verify the validity of the proposed model and the effectiveness of two main algorithms and 2) illustrate the optimal solution for task allocation and efficient strategy for task scheduling under different scenarios. © 1997-2012 IEEE.","Deep Q-learning (DQL); evolutionary computation; many-objective optimization; multiagent systems (MAS); task allocation.","Institute of Electrical and Electronics Engineers Inc."
"Yildirim G., Alatas B.","New adaptive intelligent grey wolf optimizer based multi-objective quantitative classification rules mining approaches",2021,"Journal of Ambient Intelligence and Humanized Computing",,"10.1007/s12652-020-02701-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098559581&doi=10.1007%2fs12652-020-02701-9&partnerID=40&md5=d08507ac2ccc71a64b0d3ea8060fa26c","The classification rule mining problem is one of the most important tasks of data mining. A constructed classification model is needed to have high accuracy, comprehensiveness, interestingness, etc. Furthermore, when the data composed of quantitative, numerical, or mixed data types, automatically discovering the appropriate intervals at the time of the mining process is a hard problem. The standard classification algorithms in the literature do not find the intervals of the quantitative attributes in the rules and this is performed a priori that causes the modification of datasets. Automatically constructing a successful classification model consisting of an explainable rule set without changing or modifying the data in artificial intelligence and machine learning is a very hot topic. Due to the philosophy of constantly researching to discover more accurate, surprising, and comprehensible rule sets and the absence of the most effective algorithm for all kinds of data sets, new methods or new versions of existing methods are proposed. In this study, automatic mining of high-quality rule set is handled as a multi-objective optimization problem due to the nature of the necessities and novel adaptive multi-objective intelligent search and optimization algorithms based on Grey Wolf Optimizer are proposed for this task. The datasets are considered as search spaces and the proposed adaptive Pareto based multi-objective Grey Wolf Optimizer algorithms are designed and applied as search methods for automatically discovering the high-quality rules. The proposed intelligent methods and successful classification algorithms such as naïve Bayes, k-NN, support vector machines, decision trees, and RIPPER are tested in five real-world data sets with different characteristics. The obtained results show the efficiency of the proposed intelligent search and optimization methods. © 2021, Springer-Verlag GmbH Germany, part of Springer Nature.","Classification; Grey wolf optimizer; Multi-objective optimization; Rule mining","Springer Science and Business Media Deutschland GmbH"
"Watson D.S., Floridi L.","The explanation game: a formal framework for interpretable machine learning",2021,"Synthese",10,"10.1007/s11229-020-02629-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083192479&doi=10.1007%2fs11229-020-02629-9&partnerID=40&md5=6c73072ee058653181cad0cdc5d4f6d9","We propose a formal framework for interpretable machine learning. Combining elements from statistical learning, causal interventionism, and decision theory, we design an idealised explanation game in which players collaborate to find the best explanation(s) for a given algorithmic prediction. Through an iterative procedure of questions and answers, the players establish a three-dimensional Pareto frontier that describes the optimal trade-offs between explanatory accuracy, simplicity, and relevance. Multiple rounds are played at different levels of abstraction, allowing the players to explore overlapping causal patterns of variable granularity and scope. We characterise the conditions under which such a game is almost surely guaranteed to converge on a (conditionally) optimal explanation surface in polynomial time, and highlight obstacles that will tend to prevent the players from advancing beyond certain explanatory thresholds. The game serves a descriptive and a normative function, establishing a conceptual space in which to analyse and compare existing proposals, as well as design new and improved solutions. © 2020, The Author(s).","Algorithmic explainability; Explanation game; Interpretable machine learning; Pareto frontier; Relevance","Springer Science and Business Media B.V."
"Jahed Armaghani D., Kumar D., Samui P., Hasanipanah M., Roy B.","A novel approach for forecasting of ground vibrations resulting from blasting: modified particle swarm optimization coupled extreme learning machine",2021,"Engineering with Computers",21,"10.1007/s00366-020-00997-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081567423&doi=10.1007%2fs00366-020-00997-x&partnerID=40&md5=5afb8eb67871d074734742f4d0faf237","Ground vibration is one of the most important undesirable effects induced by blasting operations in the mining or tunneling projects. Hence, developing a precise model for prediction of ground vibration would be much beneficial to control environmental issues of blasting. The present study proposes a new hybrid machine learning (ML) technique, i.e., autonomous groups particles swarm optimization (AGPSO)–extreme learning machine (ELM) to predict ground vibration resulting from blasting. In fact, AGPSO–ELM model is a modified version of PSO–ELM that can solve problems in a way with higher prediction performance. For comparison purposes, PSO–ELM, minimax probability machine regression, least square–support vector machine and Gaussian process regression models were also proposed to estimate ground vibration. The said ML models were trained and tested based on a database comprising of 102 datasets collected from a quarry site in Malaysia. In the modeling of ML techniques, six input parameters were considered: burden to spacing ratio, maximum charge per delay, stemming, distance from the blasting-face, powder factor and hole depth. The results of ML techniques were evaluated in both stages of training and testing based on five fitness parameters criteria. Considering results of both training and testing datasets, AGPSO–ELM model was able to provide higher prediction performance for PPV prediction. Root-mean-square error values of (0.08 and 0.08) and coefficient of determination values of (0.92 and 0.90) were obtained, respectively, for training and testing datasets of AGPSO–ELM model which revealed that the new hybrid model is capable enough to forecast ground vibration induced by blasting. The newly proposed model can be used in other fields of science and engineering in order to get high accuracy level of prediction. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Autonomous groups particles swarm optimization; Blasting; Extreme learning machine; Ground vibration; Hybrid model","Springer Science and Business Media Deutschland GmbH"
"Xie Z., Xu X., Walker M., Knebel J., Palaniswamy K., Hebert N., Hu J., Yang H., Chen Y., Das S.","APOLLO: An automated power modeling framework for runtime power introspection in high-volume commercial microprocessors",2021,"Proceedings of the Annual International Symposium on Microarchitecture, MICRO",,"10.1145/3466752.3480064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118834231&doi=10.1145%2f3466752.3480064&partnerID=40&md5=7210b022a1bd59f5a018462f8e311496","Accurate power modeling is crucial for energy-efficient CPU design and runtime management. An ideal power modeling framework needs to be accurate yet fast, achieve high temporal resolution (ideally cycle-accurate) yet with low runtime computational overheads, and easily extensible to diverse designs through automation. Simultaneously satisfying such conflicting objectives is challenging and largely unattained despite significant prior research. In this paper, we propose APOLLO, an automated per-cycle power modeling framework that serves as the basis for both a design-time power estimator and a low-overhead runtime on-chip power meter (OPM). APOLLO uses the minimax concave penalty (MCP)-based feature selection algorithm to automatically select less than 0.05% of RTL signals as power proxies. The power estimation achieves R2 > 0.95 on Arm Neoverse N1 [3] and R2 > 0.94 on Arm Cortex-A77 [2] microprocessors, respectively. When integrated with an emulator-assisted flow, APOLLO finishes per-cycle power estimation on millions-of-cycles benchmark in minutes for million-gate industrial CPU designs. Furthermore, the power model is synthesized and integrated into the microprocessor implementation as a runtime OPM. APOLLO's accuracy further improves when coarse-grained temporal resolution is preferred. To our best knowledge, this is the first runtime OPM that simultaneously achieves percycle temporal resolution and < 1% area/power overhead without compromising accuracy, which is validated on high-performance, out-of-order industrial CPU designs. © 2021 Association for Computing Machinery.","Commercial microprocessors; Machine learning; On-chip power meter; Power modeling and estimation; Voltage droop","IEEE Computer Society"
"Mills K.G., Han F.X., Zhang J., Changiz Rezaei S.S., Chudak F., Lu W., Lian S., Jui S., Niu D.","Profiling Neural Blocks and Design Spaces for Mobile Neural Architecture Search",2021,"International Conference on Information and Knowledge Management, Proceedings",,"10.1145/3459637.3481944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119189281&doi=10.1145%2f3459637.3481944&partnerID=40&md5=6c87f64885492a55a7e0c92b6532c894","Neural architecture search automates neural network design and has achieved state-of-the-art results in many deep learning applications. While recent literature has focused on designing networks to maximize accuracy, little work has been conducted to understand the compatibility of architecture design spaces to varying hardware. In this paper, we analyze the neural blocks used to build Once-for-All (MobileNetV3), ProxylessNAS and ResNet families, in order to understand their predictive power and inference latency on various devices, including Huawei Kirin 9000 NPU, RTX 2080 Ti, AMD Threadripper 2990WX, and Samsung Note10. We introduce a methodology to quantify the friendliness of neural blocks to hardware and the impact of their placement in a macro network on overall network performance via only end-to-end measurements. Based on extensive profiling results, we derive design insights and apply them to hardware-specific search space reduction. We show that searching in the reduced search space generates better accuracy-latency Pareto frontiers than searching in the original search spaces, customizing architecture search according to the hardware. Moreover, insights derived from measurements lead to notably higher ImageNet top-1 scores on all search spaces investigated. © 2021 ACM.","design space; latency measurement; neural architecture search","Association for Computing Machinery"
"Agarwal G., Doan H.A., Robertson L.A., Zhang L., Assary R.S.","Discovery of Energy Storage Molecular Materials Using Quantum Chemistry-Guided Multiobjective Bayesian Optimization",2021,"Chemistry of Materials",,"10.1021/acs.chemmater.1c02040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118191005&doi=10.1021%2facs.chemmater.1c02040&partnerID=40&md5=baaae19e63f94b0a85c3ec380a6c200f","Redox flow batteries (RFBs) are a promising technology for stationary energy storage applications due to their flexible design, scalability, and low cost. In RFBs, energy is carried in flowable redox-active materials (redoxmers) which are stored externally and pumped to the cell during operation. Further improvements in the energy density of RFBs necessitates redoxmer designs with wider redox potential windows and higher solubility. Additionally, designing redoxmers with a fluorescence-enabled self-reporting functionality allows monitoring of the state of health of RFBs. To accelerate the discovery of redoxmers with desired properties, state-of-the-art machine learning (ML) methods, such as multiobjective Bayesian optimization (MBO), are useful. Here, we first employed density functional theory calculations to generate a database of reduction potentials, solvation free energies, and absorption wavelengths for 1400 redoxmer molecules based on a 2,1,3-benzothiadiazole (BzNSN) core structure. From the computed properties, we identified 22 Pareto-optimal molecules that represent best trade-off among all of the desired properties. We further utilized these data to develop and benchmark an MBO approach to identify candidates quickly and efficiently with multiple targeted properties. With MBO, optimal candidates from the 1400-molecule data set can be identified at least 15 times more efficiently compared to the brute force or random selection approach. Importantly, we utilized this approach for discovering promising redoxmers from an unseen database of 1 million BzNSN-based molecules, where we discovered 16 new Pareto-optimal molecules with significant improvements in properties over the initial 1400 molecules. We anticipate that this active learning technique is general and can be utilized for the discovery of any class of functional materials that satisfies multiple desired property criteria. © 2021 UChicago Argonne, LLC, Operator of Argonne National Laboratory. Published by American Chemical Society.",,"American Chemical Society"
"Niu Y., Kong D., Wen R., Cao Z., Xiao J.","An improved learnable evolution model for solving multi-objective vehicle routing problem with stochastic demand",2021,"Knowledge-Based Systems",2,"10.1016/j.knosys.2021.107378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113234462&doi=10.1016%2fj.knosys.2021.107378&partnerID=40&md5=bf25351b7194c9150bdf81ee58fe8693","The multi-objective vehicle routing problem with stochastic demand (MO-VRPSD) is much harder to tackle than other traditional vehicle routing problems (VRPs), due to the uncertainty in customer demands and potentially conflicted objectives. In this paper, we present an improved multi-objective learnable evolution model (IMOLEM) to solve MO-VRPSD with three objectives of travel distance, driver remuneration and number of vehicles. In our method, a machine learning algorithm, i.e., decision tree, is exploited to help find and guide the desirable direction of evolution process. To cope with the key issue of ”route failure” caused due to stochastic customer demands, we propose a novel chromosome representation based on priority with bubbles. Moreover, an efficient nondominated sort using a sequential search strategy (ENS-SS) in conjunction with some heuristic operations are leveraged to handle the multi-objective property of the problem. Our algorithm is evaluated on the instances of modified Solomon VRP benchmark. Experimental results show that the proposed IMOLEM is capable to find better Pareto front of solutions and also deliver superior performance to other evolutionary algorithms. © 2021 Elsevier B.V.","Learnable evolution model; Multi-objective evolutionary algorithm; Stochastic demand; Vehicle routing problems","Elsevier B.V."
"Li Y., Zhang Y., Luo F., Zou W., Zhang Y., Zhou K.","Customer tiered purchase forecast by mobile edge computing based on Pareto/NBD and SVR",2021,"China Communications",,"10.23919/JCC.2021.11.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120812798&doi=10.23919%2fJCC.2021.11.001&partnerID=40&md5=a90f25f7555e045012808873127e800e","Mobile edge computing is trending nowadays for its computation efficiency and privacy. The rapid development of e-commerce show great interest in mobile edge computing due to numerous rise of small and middle-sized enterprises(SMEs) in the internet. This paper predicts the overall sales volume of the enterprise through the classic ARIMA model, and notes that the behavior and arrival differences between the new and old customer groups will affect the accuracy of our forecasts, so we then use Pareto/NBD to explore the repeated purchases of customers at the individual level of the old customer and the SVR model to predict the arrival of new customers, thus helping the enterprise to make layered and accurate marketing of new and old customers through machine learning. In general, machine learning relies on powerful computation and storage resources, while mobile edge computing typically provides limited computation resources locally. Therefore, it is essential to combine machine learning with mobile edge computing to further promote the proliferation of data analysis among SMEs. © 2013 China Institute of Communications.","ARIMA model; customer behavior; e-commerce; mobile edge computing; Pareto/NBD model; SVR model","Editorial Board of Journal on Communications"
"Zhao H., Zhang M., Chen F.","GAN-GL: Generative adversarial networks for glacial lake mapping",2021,"Remote Sensing",,"10.3390/rs13224728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119915825&doi=10.3390%2frs13224728&partnerID=40&md5=5959e572873e636d9b8c427e50b7d8c4","Remote sensing is a powerful tool that provides flexibility and scalability for monitoring and investigating glacial lakes in High Mountain Asia (HMA). However, existing methods for mapping glacial lakes are designed based on a combination of several spectral features and ancillary data (such as the digital elevation model, DEM) to highlight the lake extent and suppress background information. These methods, however, suffer from either the inevitable requirement of post-processing work or the high costs of additional data acquisition. Signifying a key advancement in the deep learning models, a generative adversarial network (GAN) can capture multi-level features and learn the mapping rules in source and target domains using a minimax game between a generator and discriminator. This provides a new and feasible way to conduct large-scale glacial lake mapping. In this work, a complete glacial lake dataset was first created, containing approximately 4600 patches of Landsat-8 OLI images edited in three ways—random cropping, density cropping, and uniform cropping. Then, a GAN model for glacial lake mapping (GAN-GL) was constructed. The GAN-GL consists of two parts—a generator that incorporates a water attention module and an image segmentation module to produce the glacial lake masks, and a discriminator which employs the ResNet-152 backbone to ascertain whether a given pixel belonged to a glacial lake. The model was evaluated using the created glacial lake dataset, delivering a good performance, with an F1 score of 92.17% and IoU of 86.34%. Moreover, compared to the mapping results derived from the global–local iterative segmentation algorithm and random forest for the entire Eastern Himalayas, our proposed model was superior regarding the segmentation of glacial lakes under complex and diverse environmental conditions, in terms of accuracy (precision = 93.19%) and segmentation effi-ciency. Our model was also very good at detecting small glacial lakes without assistance from ancillary data or human intervention. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Attention mechanism; Generative adversarial networks; Glacial lake mapping; Landsat-8 OLI","MDPI"
"Dos Santos R.R., Machado T.G.P., Castro S.G.P.","Support vector machine applied to the optimal design of composite wing panels",2021,"Aerospace",1,"10.3390/aerospace8110328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119053188&doi=10.3390%2faerospace8110328&partnerID=40&md5=928d24488efa0afad27090e78da6631a","One of the core technologies in lightweight structures is the optimal design of laminated composite stiffened panels. The increasing tailoring potential of new materials added to the simultaneous optimization of various design regions, leading to design spaces that are vast and non-convex. In order to find an optimal design using limited information, this paper proposes a workflow consisting of design of experiments, metamodeling and optimization phases. A machine learning strategy based on support vector machine (SVM) is used for data classification and interpolation. The combination of mass minimization and buckling evaluation under combined load is handled by a multi-objective formulation. The choice of a deterministic algorithm for the optimization cycle accelerates the convergence towards an optimal design. The analysis of the Pareto frontier illustrates the compromise between conflicting objectives. As a result, a balance is found between the exploration of new design regions and the optimal design refinement. Numerical experiments evaluating the design of a representative upper skin wing panel are used to show the viability of the proposed methodology. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Buckling; Composite wing; Layout optimization; Multi-objective optimization; Sizing optimization; Stiffened panels","MDPI"
"Wei Q., Huang D., Zhang Y.","Artificial chicken swarm algorithm for multi-objective optimization with deep learning",2021,"Journal of Supercomputing",,"10.1007/s11227-021-03770-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117856603&doi=10.1007%2fs11227-021-03770-z&partnerID=40&md5=fb02963f1b4236c087e33132bb1889dd","With the rapid development of computer hardware in the past three decades, various classic algorithms such as neural computing and bionic optimization computing have been widely used in practical problems. This paper extended the new bionic algorithm-flock algorithm proposed in 2014 and obtained a multi-objective flock algorithm to solve the multi-objective problem. This study used aggregate functions to define social ranks, and simulated the foraging behavior of chickens in the process of searching for food in the objective space and found the balance between diversity and convergence when looking for the best Pareto solution. The algorithm took five types of bi-objective functions and four types of three-objective functions as objects and compared it with four more widely used algorithms in multi-objective problems. The results demonstrate that the MOCSO (multi-objective chicken swarm optimization) algorithm shows better results in the optimization of multi-objective problems. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Bionic optimization calculation; Chicken swarm optimization algorithm; Deep learning; Multi-objective optimization; Neural computing; Pareto solution set","Springer"
"Fathi K., van de Venn H.W., Honegger M.","Predictive maintenance: an autoencoder anomaly-based approach for a 3 dof delta robot",2021,"Sensors",,"10.3390/s21216979","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117359478&doi=10.3390%2fs21216979&partnerID=40&md5=a810ecd01731f7b76e0f0608753bedd8","Performing predictive maintenance (PdM) is challenging for many reasons. Dealing with large datasets which may not contain run-to-failure data (R2F) complicates PdM even more. When no R2F data are available, identifying condition indicators (CIs), estimating the health index (HI), and thereafter, calculating a degradation model for predicting the remaining useful lifetime (RUL) are merely impossible using supervised learning. In this paper, a 3 DoF delta robot used for pick and place task is studied. In the proposed method, autoencoders (AEs) are used to predict when maintenance is required based on the signal sequence distribution and anomaly detection, which is vital when no R2F data are available. Due to the sequential nature of the data, nonlinearity of the system, and correlations between parameter time-series, convolutional layers are used for feature extraction. Thereafter, a sigmoid function is used to predict the probability of having an anomaly given CIs acquired from AEs. This function can be manually tuned given the sensitivity of the system or optimized by solving a minimax problem. Moreover, the proposed architecture can be used for fault localization for the specified system. Additionally, the proposed method can calculate RUL using Gaussian process (GP), as a degradation model, given HI values as its input. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Anomaly detection; Autoencoder; Data-driven maintenance; Deep learning; Gaussian processes; Predictive maintenance","MDPI"
"Alafaghani A., Ablat M.A., Abedi H., Qattawi A.","Modeling the influence of fused filament fabrication processing parameters on the mechanical properties of ABS parts",2021,"Journal of Manufacturing Processes",,"10.1016/j.jmapro.2021.09.057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117147167&doi=10.1016%2fj.jmapro.2021.09.057&partnerID=40&md5=8a4ac82e89854714cdea77aa4a1cecab","Modeling the influence of the processing parameters of fused filament fabrication (FFF) on the mechanical properties of FFF fabricated parts is a challenging task due to the complex dynamics and the large number of factors that affect the quality of the fabricated parts. Therefore, optimizing the mechanical properties of parts fabricated using FFF usually requires a considerable number of test samples. Most past studies have focused on the main effects of the processing parameters and have ignored the interactions between the parameters or their non-linear effects on the mechanical properties of FFF fabricated parts. In the work presented, the effects of the layer thickness, nozzle temperature, infill percentage, and infill pattern are investigated to achieve the fabricated parts' optimum strength and stiffness. A group of Artificial Neural Networks (ANN) was used to model the influence of these processing parameters on the mechanical properties of FFF fabricated ABS parts. The Design of Experiments (DOE) approach was utilized to minimize the number of tests needed to study the investigated parameters. Response Surface Methodology (RSM) and Taguchi's orthogonal arrays were used to generate the training and testing data sets used to develop a group of ANN models and evaluate their performance. Furthermore, the fitness of ANN models was compared to the regression models of the RSM and Taguchi's DOE. It was found that some parameters exhibit strong interaction and nonlinear effects on the strength, stiffness, and ductility of FFF fabricated parts. The coefficient of determination R2 indicates that the ANN models were more accurate at predicting the mechanical properties than DOE regression models. The contour plots show that generally, increasing the layer thickness and infill percentage increase the tensile strength and the elastic modulus and that increasing the nozzle temperature is important when thick layers are used. For the ductility, the infill pattern is the most significant parameter, with linear infill yielding the highest ductility and triangular yielding the lowest. Lower nozzle temperature generally improves the ductility which is the exact opposite of what is required to maximize the elastic modulus and tensile strength. Finally, a multi-objective particle swarm optimization algorithm was used to obtain the non-dominated Pareto-optimal solutions that can lead to an optimal combination of the mechanical properties. © 2021 The Society of Manufacturing Engineers","Additive manufacturing; Artificial neural network; Fused deposition modeling; Machine learning; Multi-objective optimization; Particle swarm optimization; Response surface methodology","Elsevier Ltd"
"Sun Z., Liu H., Huyan J., Li W., Guo M., Hao X., Pei L.","Assessment of importance-based machine learning feature selection methods for aggregate size distribution measurement in a 3D binocular vision system",2021,"Construction and Building Materials",1,"10.1016/j.conbuildmat.2021.124894","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115005391&doi=10.1016%2fj.conbuildmat.2021.124894&partnerID=40&md5=c5a6d625ff7ae766381fadcb5f0f9368","Aggregate size is usually measured by manual sampling and sieving. Machine vision techniques can provide fast, non-invasive measurement. However, the traditional imaging method using a single size descriptor to discriminate different sieve-size classes of coarse aggregates might not yield high-precision classification results. To determine the optimum supervised machine learning model for coarse aggregates sieve-size measurement, 17 methods were evaluated and compared. To train our model, a new dataset named MFCA27 (Multiple Features of Coarse Aggregate 27) was introduced, which contains 27 features of aggregates based on aggregate three-dimensional (3D) top-surface object. In addition, a feature selection approach for investigating how accuracy varied with the datasets under different feature sets was developed, where feature selection was performed according to the impurity-based feature importance score measured using an extremely randomized tree model. Experiments demonstrated that the Gaussian process classifier (GPC) was the best-performing method on the datasets with two- or three-dimensional (2D/3D) feature sets in terms of accuracy and robustness. The results also showed that, compared with the traditional aggregate sieve-size measurement method, which is based on a single size descriptor, GPC can achieve an accuracy of 95.06% on the test dataset of MFCA27 in the aggregate sieve-size class measurement task. © 2021","Aggregates; Digital sieving; Importance-based feature selection; Size distribution; Supervised machine learning","Elsevier Ltd"
"Ottervanger G., Baratchi M., Hoos H.H.","MultiETSC: automated machine learning for early time series classification",2021,"Data Mining and Knowledge Discovery",,"10.1007/s10618-021-00781-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112581958&doi=10.1007%2fs10618-021-00781-5&partnerID=40&md5=4bcf940722287ae8c6fc37f3e9929204","Early time series classification (EarlyTSC) involves the prediction of a class label based on partial observation of a given time series. Most EarlyTSC algorithms consider the trade-off between accuracy and earliness as two competing objectives, using a single dedicated hyperparameter. To obtain insights into this trade-off requires finding a set of non-dominated (Pareto efficient) classifiers. So far, this has been approached through manual hyperparameter tuning. Since the trade-off hyperparameters only provide indirect control over the earliness-accuracy trade-off, manual tuning is tedious and tends to result in many sub-optimal hyperparameter settings. This complicates the search for optimal hyperparameter settings and forms a hurdle for the application of EarlyTSC to real-world problems. To address these issues, we propose an automated approach to hyperparameter tuning and algorithm selection for EarlyTSC, building on developments in the fast-moving research area known as automated machine learning (AutoML). To deal with the challenging task of optimising two conflicting objectives in early time series classification, we propose MultiETSC, a system for multi-objective algorithm selection and hyperparameter optimisation (MO-CASH) for EarlyTSC. MultiETSC can potentially leverage any existing or future EarlyTSC algorithm and produces a set of Pareto optimal algorithm configurations from which a user can choose a posteriori. As an additional benefit, our proposed framework can incorporate and leverage time-series classification algorithms not originally designed for EarlyTSC for improving performance on EarlyTSC; we demonstrate this property using a newly defined, “naïve” fixed-time algorithm. In an extensive empirical evaluation of our new approach on a benchmark of 115 data sets, we show that MultiETSC performs substantially better than baseline methods, ranking highest (avg. rank 1.98) compared to conceptually simpler single-algorithm (2.98) and single-objective alternatives (4.36). © 2021, The Author(s).","Automated machine learning; Early classification; Time series classification","Springer"
"Bhosekar A., Badejo O., Ierapetritou M.","Modular supply chain optimization considering demand uncertainty to manage risk",2021,"AIChE Journal",3,"10.1002/aic.17367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112055918&doi=10.1002%2faic.17367&partnerID=40&md5=5a7d1100ca227ce45439bdfd72beb3b0","Supply chain under demand uncertainty has been a challenging problem due to increased competition and market volatility in modern markets. Flexibility in planning decisions makes modular manufacturing a promising way to address this problem. In this work, the problem of multiperiod process and supply chain network design is considered under demand uncertainty. A mixed integer two-stage stochastic programming problem is formulated with integer variables indicating the process design and continuous variables to represent the material flow in the supply chain. The problem is solved using a rolling horizon approach. Benders decomposition is used to reduce the computational complexity of the optimization problem. To promote risk-averse decisions, a downside risk measure is incorporated in the model. The results demonstrate the several advantages of modular designs in meeting product demands. A pareto-optimal curve for minimizing the objectives of expected cost and downside risk is obtained. © 2021 American Institute of Chemical Engineers.","feasibility analysis; machine learning; modular manufacturing; stochastic mixed integer programming; supply chain optimization","John Wiley and Sons Inc"
"Yu X., Peng Q., Xu L., Jiang F., Du J., Gong D.","A selective ensemble learning based two-sided cross-domain collaborative filtering algorithm",2021,"Information Processing and Management",19,"10.1016/j.ipm.2021.102691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111305957&doi=10.1016%2fj.ipm.2021.102691&partnerID=40&md5=e3b1c228527a7691c1910b247f084af2","Recently, various Cross-Domain Collaborative Filtering (CDCF) algorithms are presented to address the sparsity problem, leveraging ratings of auxiliary domains to improve target domain's recommendation performance. Therein, two-sided CDCF algorithms have shown better performance, given the fact that they can extract both user and item information. However, as the auxiliary domains are not all related to the target domain, utilizing information from all the auxiliary domains may not be optimal and would lead to low efficiency. A Two-Sided CDCF model based on Selective Ensemble learning considering both Accuracy and Efficiency (TSSEAE) is proposed to balance recommendation accuracy and efficiency. In TSSEAE, user-sided and item-sided auxiliary domains are firstly combined to improve performance of target domain. Then, CDCF problems are converted to ensemble learning problems, with each combination corresponding to a classifier. In this way, the problem of selecting combinations can be converted to that of selecting classifiers, which is a selective ensemble learning problem. Finally, a bi-objective optimization problem is solved to obtain Pareto optimal solutions for the selective ensemble learning problem. The experimental result on Amazon dataset shows the effectiveness of TSSEAE. © 2021 Elsevier Ltd","Bi-objective optimization problem; Cross-domain collaborative filtering; Ensemble learning; Pareto optimal solutions; Selective ensemble","Elsevier Ltd"
"Li G., Li Y., Zheng Y., Li Y., Hong Y., Zhou X.","A novel feature selection approach with Pareto optimality for multi-label data",2021,"Applied Intelligence",,"10.1007/s10489-021-02228-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102936191&doi=10.1007%2fs10489-021-02228-2&partnerID=40&md5=6728e91113196365472937da75e3f058","Multi-label learning has widely applied in machine learning and data mining. The purpose of feature selection is to select an approximately optimal feature subset to characterize the original feature space. Similar to single-label data, feature selection is an import preprocessing step to enhance the performance of multi-label classification model. In this paper, we propose a multi-label feature selection approach with Pareto optimality for continuous data, called MLFSPO. It maps multi-label features to high-dimensional space to evaluate the correlation between features and labels by utilizing the Hilbert-Schmidt Independence Criterion (HSIC). Then, the feature subset obtains by combining the Pareto optimization with feature ordering criteria and label weighting. Eventually, extensive experimental results on publicly available data sets show the effectiveness of the proposed algorithm in multi-label tasks. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","Feature selection; Hilbert-Schmidt independence criterion; Multi-label learning; Pareto optimality","Springer"
"Khan F.S., Bao N.","Quantum Prisoner’s Dilemma and High Frequency Trading on the Quantum Cloud",2021,"Frontiers in Artificial Intelligence",,"10.3389/frai.2021.769392","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119403164&doi=10.3389%2ffrai.2021.769392&partnerID=40&md5=61f8e4a0b1da4f5a9b625a19e0337ac1","High-frequency trading (HFT) offers an excellent use case and a potential killer application of the commercially available, first generation quasi-quantum computers. To this end, we offer here a simple game-theoretic model of HFT as the famous two player game, Prisoner’s Dilemma. We explore the implementation of HFT as an instance of Prisoner’s Dilemma on the (quasi) quantum cloud using the Eisert, Wilkens, and Lewenstein quantum mediated communication protocol, and how this implementation can not only increase transaction speed but also improve the lot of the players in HFT. Using cooperative game-theoretic reasoning, we also note that in the near future when the internet is properly quantum, players will be able to achieve Pareto-optimality in HFT as an instance of reinforced machine learning. © Copyright © 2021 Khan and Bao.","high-frequency trading (HFT); Nash equilbrium; Pareto optimal; quantum computing (QC); quantum games","Frontiers Media S.A."
"Zerenner T., Venema V., Friederichs P., Simmer C.","Multi-objective downscaling of precipitation time series by genetic programming",2021,"International Journal of Climatology",,"10.1002/joc.7172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107402997&doi=10.1002%2fjoc.7172&partnerID=40&md5=bb6f29aa4aae4f2996bbd18d201c9920","We use symbolic regression to estimate daily precipitation amounts at six stations in the Alpine region from a global reanalysis. Symbolic regression only prescribes the set of mathematical expressions allowed in the regression model, but not its structure. The regression models are generated by genetic programming (GP) in analogy to biological evolution. The two conflicting objectives of a low root-mean-square error (RMSE) and consistency in the distribution between model and observations are treated as a multi-objective optimization problem. This allows us to derive a set of downscaling models that represents different achievable trade-offs between the two conflicting objectives, a so-called Pareto set. Our GP setup limits the size of the regression models and uses an analytical quotient instead of a standard or protected division operator. With this setup we obtain models that have a generalization performance comparable with generalized linear regression models (GLMs), which are used as a benchmark. We generate deterministic and stochastic downscaling models with GP. The deterministic downscaling models with low RMSE outperform the respective stochastic models. The stochastic models with low IQD, however, perform slightly better than the respective deterministic models for the majority of cases. No approach is uniquely superior. The stochastic models with optimal IQD provide useful distribution estimates that capture the stochastic uncertainty similar to or slightly better than the GLM-based downscaling. © 2021 The Authors International Journal of Climatology published by John Wiley & Sons Ltd on behalf of Royal Meteorological Society.","genetic programming; machine learning; Pareto optimality; stochastic downscaling","John Wiley and Sons Ltd"
"Anton C., Curteanu S., Lisa C., Leon F.","Machine learning methods applied for modeling the process of obtaining bricks using silicon-based materials",2021,"Materials",,"10.3390/ma14237232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119958217&doi=10.3390%2fma14237232&partnerID=40&md5=1ccf96e972b11e948a93fe191ad4f201","Most of the time, industrial brick manufacture facilities are designed and commissioned for a particular type of manufacture mix and a particular type of burning process. Productivity and product quality maintenance and improvement is a challenge for process engineers. Our paper aims at using machine learning methods to evaluate the impact of adding new auxiliary materials on the amount of exhaust emissions. Experimental determinations made in similar conditions en-abled us to build a database containing information about 121 brick batches. Various models (arti-ficial neural networks and regression algorithms) were designed to make predictions about exhaust emission changes when auxiliary materials are introduced into the manufacture mix. The best models were feed-forward neural networks with two hidden layers, having MSE &lt; 0.01 and r2&gt; 0.82 and, as regression model, kNN with error &lt; 0.6. Also, an optimization procedure, including the best models, was developed in order to determine the optimal values for the parameters that as-sure the minimum quantities for the gas emission. The Pareto front obtained in the multi-objective optimization conducted with grid search method allows the user the chose the most convenient values for the dry product mass, clay, ash and organic raw materials which minimize gas emissions with energy potential. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Bricks; Influence of additives; Machine learning; Neural networks; Random forest","MDPI"
"Bardhan A., Kardani N., GuhaRay A., Burman A., Samui P., Zhang Y.","Hybrid ensemble soft computing approach for predicting penetration rate of tunnel boring machine in a rock environment",2021,"Journal of Rock Mechanics and Geotechnical Engineering",2,"10.1016/j.jrmge.2021.06.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119420943&doi=10.1016%2fj.jrmge.2021.06.015&partnerID=40&md5=0c207853b5881337ffd575bebb888319","This study implements a hybrid ensemble machine learning method for forecasting the rate of penetration (ROP) of tunnel boring machine (TBM), which is becoming a prerequisite for reliable cost assessment and project scheduling in tunnelling and underground projects in a rock environment. For this purpose, a sum of 185 datasets was collected from the literature and used to predict the ROP of TBM. Initially, the main dataset was utilised to construct and validate four conventional soft computing (CSC) models, i.e. minimax probability machine regression, relevance vector machine, extreme learning machine, and functional network. Consequently, the estimated outputs of CSC models were united and trained using an artificial neural network (ANN) to construct a hybrid ensemble model (HENSM). The outcomes of the proposed HENSM are superior to other CSC models employed in this study. Based on the experimental results (training RMSE = 0.0283 and testing RMSE = 0.0418), the newly proposed HENSM is potential to assist engineers in predicting ROP of TBM in the design phase of tunnelling and underground projects. © 2021 Institute of Rock and Soil Mechanics, Chinese Academy of Sciences","Artificial intelligence; Artificial neural network (ANN); Ensemble modelling; Rate of penetration (ROP); Tunnel boring machine (TBM)","Chinese Academy of Sciences"
"Liu X., Ye K., van Vlijmen H.W.T., Emmerich M.T.M., IJzerman A.P., van Westen G.J.P.","DrugEx v2: de novo design of drug molecules by Pareto-based multi-objective reinforcement learning in polypharmacology",2021,"Journal of Cheminformatics",,"10.1186/s13321-021-00561-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119016033&doi=10.1186%2fs13321-021-00561-9&partnerID=40&md5=fc61f3a8015d4db907bdaa1206179b9f","In polypharmacology drugs are required to bind to multiple specific targets, for example to enhance efficacy or to reduce resistance formation. Although deep learning has achieved a breakthrough in de novo design in drug discovery, most of its applications only focus on a single drug target to generate drug-like active molecules. However, in reality drug molecules often interact with more than one target which can have desired (polypharmacology) or undesired (toxicity) effects. In a previous study we proposed a new method named DrugEx that integrates an exploration strategy into RNN-based reinforcement learning to improve the diversity of the generated molecules. Here, we extended our DrugEx algorithm with multi-objective optimization to generate drug-like molecules towards multiple targets or one specific target while avoiding off-targets (the two adenosine receptors, A1AR and A2AAR, and the potassium ion channel hERG in this study). In our model, we applied an RNN as the agent and machine learning predictors as the environment. Both the agent and the environment were pre-trained in advance and then interplayed under a reinforcement learning framework. The concept of evolutionary algorithms was merged into our method such that crossover and mutation operations were implemented by the same deep learning model as the agent. During the training loop, the agent generates a batch of SMILES-based molecules. Subsequently scores for all objectives provided by the environment are used to construct Pareto ranks of the generated molecules. For this ranking a non-dominated sorting algorithm and a Tanimoto-based crowding distance algorithm using chemical fingerprints are applied. Here, we adopted GPU acceleration to speed up the process of Pareto optimization. The final reward of each molecule is calculated based on the Pareto ranking with the ranking selection algorithm. The agent is trained under the guidance of the reward to make sure it can generate desired molecules after convergence of the training process. All in all we demonstrate generation of compounds with a diverse predicted selectivity profile towards multiple targets, offering the potential of high efficacy and low toxicity. © 2021, The Author(s).","Adenosine receptors; Cheminformatics; Deep learning; Exploration strategy; Multi-objective optimization; Reinforcement learning","BioMed Central Ltd"
"Joseph Shibu K., Shankar K., Babu C.K., Degaonkar G.K.","Multi-Objective Optimization of a Maneuvering Small Aircraft Turbine Engine Rotor System",2021,"Journal of Intelligent and Robotic Systems: Theory and Applications",,"10.1007/s10846-021-01511-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118782187&doi=10.1007%2fs10846-021-01511-1&partnerID=40&md5=6ba209a92c3e60436ed70d2f881a4951","This paper presents the multi-objective optimization of a small aircraft turbine engine rotor system subjected to maneuver loads. Application of a clustering algorithm, an unsupervised machine learning technique, to the Pareto front developed from multi-objective optimization of maneuvering aircraft rotor system is the novelty of the present work. An in-house finite element code is developed using MATLAB for the analysis of rotor system. Hybrid Genetic Algorithm is employed to simultaneously minimize the rotor response at maximum speed during maneuver and rotor response at critical speed with restrictions imposed on critical speed. Shaft diameters and pedestal stiffness at both the bearing locations are identified as design variables. Pareto optimal solutions are generated, clustering is carried out in both objective space and decision space and the solution close to the utopia point is selected as final compromise solution. The average of the values of design variables for the selected cluster is compared with final compromise solution and is found in good agreement. The response of the rotor system and the critical speeds are verified by carrying out tests on ground. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.","Clustering; Genetic algorithm; Maneuvering; Multi-objective optimization; Pareto front","Springer Science and Business Media B.V."
"Pan Y., Zhang L., Yan Z., Lwin M.O., Skibniewski M.J.","Discovering optimal strategies for mitigating COVID-19 spread using machine learning: Experience from Asia",2021,"Sustainable Cities and Society",5,"10.1016/j.scs.2021.103254","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113643073&doi=10.1016%2fj.scs.2021.103254&partnerID=40&md5=e83d7bcc14b2b6197fbe80e957d6ce65","To inform data-driven decisions in fighting the global pandemic caused by COVID-19, this research develops a spatiotemporal analysis framework under the combination of an ensemble model (random forest regression) and a multi-objective optimization algorithm (NSGA-II). It has been verified for four Asian countries, including Japan, South Korea, Pakistan, and Nepal. Accordingly, we can gain some valuable experience to better understand the disease evolution, forecast the prevalence of the disease, which can provide sustainable evidence to guide further intervention and management. Random forest with a proper rolling time-window can learn the combined effects of environmental and social factors to accurately predict the daily growth of confirmed cases and daily death rate on a national scale, which is followed by NSGA-II to find a range of Pareto optimal solutions for ensuring the minimization of the infection rate and mortality at the same time. Experimental results demonstrate that the predictive model can alert the local government in advance, allowing the accused time to put forward relevant measures. The temperature in the category of environment and the stringency index belonging to the social factor are identified as the top 2 important features to exert a greater impact on the virus transmission. Moreover, optimal solutions provide references to design the best control strategies towards pandemic containment and prevention that can accommodate the country-specific circumstance, which are possible to decrease the two objectives by more than 95%. In particular, appropriate adjustment of social-related features needs to take priority over others, since it can bring about at least 1.47% average improvement of two objectives compared to environmental factors. © 2021 Elsevier Ltd","COVID-19; Feature importance analysis; Multi-objective optimization; Random forest regression; Sustainability","Elsevier Ltd"
"Zhang L., Lin P.","Multi-objective optimization for limiting tunnel-induced damages considering uncertainties",2021,"Reliability Engineering and System Safety",18,"10.1016/j.ress.2021.107945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112131978&doi=10.1016%2fj.ress.2021.107945&partnerID=40&md5=88129ba498ee74a0b8f8c8d24a515086","Due to the rapid development of the urban metro system, the situation of new excavation work being conducted adjacent to existing tunnels is quite common and becomes prime hazards in the tunnel design stage, together with uncertainties from the ground condition. To solve this problem, this paper develops a hybrid approach that integrates ensemble learning and non-dominant sorting genetic algorithm-II (NSGA-II) to mitigate the limit support pressure (LSP) and the ground surface deformation (GSD) during the tunnel excavation for improved design. The extreme gradient boosting (XGBoost) algorithm is used to establish ensemble learning models predicting LSP and GSD, where the new tunnel is constructed in parallel to an existing tunnel. NSGA-II is further used to optimize the two targets (i.e., LSP and GSD), considering the uncertainties from geotechnical conditions and errors from the meta-model. With the Monte-Carlo simulation, probability constraints are established to conduct the multi-objective optimization (MOO). Finally, the Pareto front is generated to obtain the best location of the new tunnel, and a comparison is made between MOO with and without considering uncertainties. The best solution is selected by the criterion of the point with the shortest distance from the ideal point. It is found that after considering uncertainties: (1) The improvement percentage of LSP is increased from 9.67% to 11.03%, and that of GSD drops from 2.39% to 0.9%; (2) A higher stability of improvement from optimization is achieved with the standard deviation of improvement percentage drops from 0.310 to 0.298 for LSP and 0.024 to 0.020 for GSD; (3) With a weaker confidence on the meta-model, a higher degree of sacrifice on GSD is observed. The novelty of the proposed approach lies in its capability to not only predict and optimize the damage from excavation adjacent to an existing tunnel, but also consider various types of uncertainties from geological conditions and meta-models to guarantee reliability. © 2021","Ensemble learning; Multi-objective optimization; Probability constraints; Tunnel alignment","Elsevier Ltd"
"Lysogorskiy Y., Oord C., Bochkarev A., Menon S., Rinaldi M., Hammerschmidt T., Mrovec M., Thompson A., Csányi G., Ortner C., Drautz R.","Performant implementation of the atomic cluster expansion (PACE) and application to copper and silicon",2021,"npj Computational Materials",8,"10.1038/s41524-021-00559-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110944044&doi=10.1038%2fs41524-021-00559-9&partnerID=40&md5=0bd62d2d4e2a6cf1d05e9d755e67c1ad","The atomic cluster expansion is a general polynomial expansion of the atomic energy in multi-atom basis functions. Here we implement the atomic cluster expansion in the performant C++ code PACE that is suitable for use in large-scale atomistic simulations. We briefly review the atomic cluster expansion and give detailed expressions for energies and forces as well as efficient algorithms for their evaluation. We demonstrate that the atomic cluster expansion as implemented in PACE shifts a previously established Pareto front for machine learning interatomic potentials toward faster and more accurate calculations. Moreover, general purpose parameterizations are presented for copper and silicon and evaluated in detail. We show that the Cu and Si potentials significantly improve on the best available potentials for highly accurate large-scale atomistic simulations. © 2021, The Author(s).",,"Nature Research"
"Desai S., Strachan A.","Parsimonious neural networks learn interpretable physical laws",2021,"Scientific Reports",1,"10.1038/s41598-021-92278-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108115598&doi=10.1038%2fs41598-021-92278-w&partnerID=40&md5=5ef827082f6db5964f6a4b2ddba9ff40","Machine learning is playing an increasing role in the physical sciences and significant progress has been made towards embedding domain knowledge into models. Less explored is its use to discover interpretable physical laws from data. We propose parsimonious neural networks (PNNs) that combine neural networks with evolutionary optimization to find models that balance accuracy with parsimony. The power and versatility of the approach is demonstrated by developing models for classical mechanics and to predict the melting temperature of materials from fundamental properties. In the first example, the resulting PNNs are easily interpretable as Newton’s second law, expressed as a non-trivial time integrator that exhibits time-reversibility and conserves energy, where the parsimony is critical to extract underlying symmetries from the data. In the second case, the PNNs not only find the celebrated Lindemann melting law, but also new relationships that outperform it in the pareto sense of parsimony vs. accuracy. © 2021, The Author(s).",,"Nature Research"
"Jablonka K.M., Jothiappan G.M., Wang S., Smit B., Yoo B.","Bias free multiobjective active learning for materials design and discovery",2021,"Nature Communications",7,"10.1038/s41467-021-22437-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104506055&doi=10.1038%2fs41467-021-22437-0&partnerID=40&md5=b1df5de1b10c2eddcc3c99f8e5fea7f8","The design rules for materials are clear for applications with a single objective. For most applications, however, there are often multiple, sometimes competing objectives where there is no single best material and the design rules change to finding the set of Pareto optimal materials. In this work, we leverage an active learning algorithm that directly uses the Pareto dominance relation to compute the set of Pareto optimal materials with desirable accuracy. We apply our algorithm to de novo polymer design with a prohibitively large search space. Using molecular simulations, we compute key descriptors for dispersant applications and drastically reduce the number of materials that need to be evaluated to reconstruct the Pareto front with a desired confidence. This work showcases how simulation and machine learning techniques can be coupled to discover materials within a design space that would be intractable using conventional screening approaches. © 2021, The Author(s).",,"Nature Research"
"Roccetti M., Delnevo G., Casini L., Mirri S.","An alternative approach to dimension reduction for pareto distributed data: a case study",2021,"Journal of Big Data",7,"10.1186/s40537-021-00428-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101944804&doi=10.1186%2fs40537-021-00428-8&partnerID=40&md5=b79937d69441908779adf9d5876299c2","Deep learning models are tools for data analysis suitable for approximating (non-linear) relationships among variables for the best prediction of an outcome. While these models can be used to answer many important questions, their utility is still harshly criticized, being extremely challenging to identify which data descriptors are the most adequate to represent a given specific phenomenon of interest. With a recent experience in the development of a deep learning model designed to detect failures in mechanical water meter devices, we have learnt that a sensible deterioration of the prediction accuracy can occur if one tries to train a deep learning model by adding specific device descriptors, based on categorical data. This can happen because of an excessive increase in the dimensions of the data, with a correspondent loss of statistical significance. After several unsuccessful experiments conducted with alternative methodologies that either permit to reduce the data space dimensionality or employ more traditional machine learning algorithms, we changed the training strategy, reconsidering that categorical data, in the light of a Pareto analysis. In essence, we used those categorical descriptors, not as an input on which to train our deep learning model, but as a tool to give a new shape to the dataset, based on the Pareto rule. With this data adjustment, we trained a more performative deep learning model able to detect defective water meter devices with a prediction accuracy in the range 87–90%, even in the presence of categorical descriptors. © 2021, The Author(s).","Binning; Categorical data; Dataset coherence analysis; Deep learning models; Imbalanced datasets; Learning space dimensions; Machine learning; Pareto analysis; Principal component analysis","Springer Science and Business Media Deutschland GmbH"
"Roy R., Raiman J., Kant N., Elkin I., Kirby R., Siu M., Oberman S., Godil S., Catanzaro B.","PrefixRL: Optimization of Parallel Prefix Circuits using Deep Reinforcement Learning",2021,"Proceedings - Design Automation Conference",1,"10.1109/DAC18074.2021.9586094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119453344&doi=10.1109%2fDAC18074.2021.9586094&partnerID=40&md5=2487d6c6e76cbe8664f664229dd8d43a","In this work, we present a reinforcement learning (RL) based approach to designing parallel prefix circuits such as adders or priority encoders that are fundamental to high-performance digital design. Unlike prior methods, our approach designs solutions tabula rasa purely through learning with synthesis in the loop. We design a grid-based state-action representation and an RL environment for constructing legal prefix circuits. Deep Convolutional RL agents trained on this environment produce prefix adder circuits that Pareto-dominate existing baselines with up to 16.0% and 30.2% lower area for the same delay in the 32b and 64b settings respectively. We observe that agents trained with open-source synthesis tools and cell library can design adder circuits that achieve lower area and delay than commercial tool adders in an industrial cell library. © 2021 IEEE.","datapath optimization; machine learning; reinforcement learning","Institute of Electrical and Electronics Engineers Inc."
"Risso M., Burrello A., Pagliari D.J., Conti F., Lamberti L., MacIi E., Benini L., Poncino M.","Pruning in Time (PIT): A Lightweight Network Architecture Optimizer for Temporal Convolutional Networks",2021,"Proceedings - Design Automation Conference",,"10.1109/DAC18074.2021.9586187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119421885&doi=10.1109%2fDAC18074.2021.9586187&partnerID=40&md5=4a6dd0580295a540b56d54bdad733bca","Temporal Convolutional Networks (TCNs) are promising Deep Learning models for time-series processing tasks. One key feature of TCNs is time-dilated convolution, whose optimization requires extensive experimentation. We propose an automatic dilation optimizer, which tackles the problem as a weight pruning on the time-axis, and learns dilation factors together with weights, in a single training. Our method reduces the model size and inference latency on a real SoC hardware target by up to 7.4× and 3×, respectively with no accuracy drop compared to a network without dilation. It also yields a rich set of Pareto-optimal TCNs starting from a single model, outperforming hand-designed solutions in both size and accuracy. © 2021 IEEE.","Deep Learning; Edge Computing; Neural Architecture Search; Temporal Convolutional Networks","Institute of Electrical and Electronics Engineers Inc."
"Shaheen A.M., El-Sehiemy R.A., Alharthi M.M., Ghoneim S.S.M., Ginidi A.R.","Multi-objective jellyfish search optimizer for efficient power system operation based on multi-dimensional OPF framework",2021,"Energy",5,"10.1016/j.energy.2021.121478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111768517&doi=10.1016%2fj.energy.2021.121478&partnerID=40&md5=bbee91239b603b2c515f8d33d109a465","An enhanced multi-objective Quasi-Reflected Jellyfish Search Optimizer (MOQRJFS) is presented in this article for solving multi-dimensional Optimal Power Flow (MDOPF) issue with diverse objectives which display the minimization of economic fuel cost, total emissions, and the active power loss with satisfying operational constraints. Despite the simple structure of JFS with control of exploitation and exploration, searching capability of the JFS requires more support. Hence, two modifications are performed on the standard JFS algorithm. The first modification is that a cluster with a random size has been proposed which illustrates the social community that can share the data in the cluster and are dissimilar from one to another. The second modification is that a quasi-opposition-based learning is emerged in JFS to support the exploration phase. As selection criteria for the best solutions, a fuzzy decision-making strategy is joint into MOQRJFS optimizer. Additionally, the Pareto optimality concept is added to extract the non-dominated solutions. The superiority of the MOQRJFS is proved throughout application on IEEE 30-bus system, IEEE 57-bus system, the West Delta Region System of 52 bus (WDRS-52) in Egypt, and a large scale 118-bus system. Thirteen cases with economic, environmental, and technical objectives of MDOPF are included in this study. The outcomes of the proposed MOQRJFS have been compared with the conventional MOJFS and the reported techniques in the literature. It is clearly observed that the MOQRJFS give the minimum values compared with these techniques which reveals its robustness, effectiveness, and superiority when handling MDOPF among other techniques. © 2021","Fuel cost; Multi-dimension optimal power flow; Quasi-reflected jellyfish search optimizer; Real power loss; Total emissions","Elsevier Ltd"
"Jose N.A., Kovalev M., Bradford E., Schweidtmann A.M., Chun Zeng H., Lapkin A.A.","Pushing nanomaterials up to the kilogram scale – An accelerated approach for synthesizing antimicrobial ZnO with high shear reactors, machine learning and high-throughput analysis",2021,"Chemical Engineering Journal",,"10.1016/j.cej.2021.131345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110585632&doi=10.1016%2fj.cej.2021.131345&partnerID=40&md5=cfc520398f3d2a8ccdcb3da84a58e130","Novel materials are the backbone of major technological advances. However, the development and wide-scale introduction of new materials, such as nanomaterials, is limited by three main factors—the expense of experiments, inefficiency of synthesis methods and complexity of scale-up. Reaching the kilogram scale is a hurdle that takes years of effort for many nanomaterials. We introduce an improved methodology for materials development, combining state-of-the-art techniques—multi-objective machine learning optimization, high yield microreactors and high throughput analysis. We demonstrate this approach through the optimization of ZnO nanoparticle synthesis, simultaneously targeting high yield and high antibacterial activity. In fewer than 100 experiments, we developed a 1 kg day−1 continuous synthesis for ZnO (with a space-time-yield of 62.4 kg day−1 m−3), having an antibacterial activity comparable to hydrothermally synthesized nano-ZnO and cetrimonium bromide. Following this, we provide insights into the mechanistic factors underlying the performance-yield tradeoffs of synthesis and highlight the need for benchmarking machine learning models with traditional chemical engineering methods. Methods for increasing model accuracy at steep pareto fronts, in this case at yields close to 1 kg per day, should also be improved. To project the next steps for process scale-up and the potential advantages of this methodology, we conduct a scalability analysis in comparison to conventional batch production methods, in which there is a significant reduction in degrees of freedom. The proposed method has the potential to significantly reduce experimental costs, increase process efficiency and enhance material performance, which culminate to form a new pathway for materials discovery. © 2021 Elsevier B.V.","Antibacterial; Machine learning; Nanomaterials; Reactor; Scale-up","Elsevier B.V."
"Balashankar A., Lees A.","The Need for Transparent Demographic Group Trade-Offs in Credit Risk and Income Classification",2022,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-96957-8_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126261208&doi=10.1007%2f978-3-030-96957-8_30&partnerID=40&md5=a735a948d70503fefc69bcbb22bf5b4a","Prevalent methodology towards constructing fair machine learning (ML) systems, is to enforce a strict equality metric for demographic groups based on protected attributes like race and gender. While definitions of fairness in philosophy are varied, mitigating bias in ML classifiers often relies on demographic parity-based constraints across sub-populations. However, enforcing such constraints blindly can lead to undesirable trade-offs between group-level accuracy if groups possess different underlying sampled population metrics, an occurrence that is surprisingly common in real-world applications like credit risk and income classification. Similarly, attempts to relax hard constraints may lead to unintentional degradation in classification performance, without benefit to any demographic group. In these increasingly likely scenarios, we make the case for transparent human intervention in making the trade-offs between the accuracies of demographic groups. We propose that transparency in trade-offs between demographic groups should be a key tenet of ML design and implementation. Our evaluation demonstrates that a transparent human-in-the-loop trade-off technique based on the Pareto principle increases both overall and group-level accuracy by 9.5% and 9.6% respectively, in two commonly explored UCI datasets for credit risk and income classification. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",,"Springer Science and Business Media Deutschland GmbH"
"Gorbunova A.V., Lebedev A.V.","Response Time Estimate for a Fork-Join System with Pareto Distributed Service Time as a Model of a Cloud Computing System Using Neural Networks",2022,"Communications in Computer and Information Science",,"10.1007/978-3-030-97110-6_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126250503&doi=10.1007%2f978-3-030-97110-6_25&partnerID=40&md5=dc0e28cba695df87c623c5181358c17b","A cloud computing system that receives complex user tasks involving several subtasks is studied from the point of view of the response time. In order to reduce the service time, the tasks are divided into smaller components and processed in parallel. As a cloud center model we use a fork-join queuing system with Pareto distribution of the service time on the servers. To analyze the mean response time and its standard deviation, a new approach is used combining simulation modeling with one of the machine learning methods. The estimates obtained are much more accurate than the earlier analytical results on fork-join systems. © 2022, Springer Nature Switzerland AG.","Artificial neural networks; Cloud computing; Machine learning; Mean response time; Parallel computing; Parallel processing; Queuing system","Springer Science and Business Media Deutschland GmbH"
"Hou Z., Kung S.-Y.","Multi-Dimensional Dynamic Model Compression for Efficient Image Super-Resolution",2022,"Proceedings - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022",,"10.1109/WACV51458.2022.00355","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126084312&doi=10.1109%2fWACV51458.2022.00355&partnerID=40&md5=6831baa4f422704e62231d35a4168b98","Modern single image super-resolution (SR) system based on convolutional neural networks achieves substantial progress. However, most SR deep networks are computationally expensive and require excessively large activation memory footprints, impeding their effective deployment to resource-limited devices. Based on the observation that the activation patterns in SR networks exhibit high input-dependency, we propose Multi-Dimensional Dynamic Model Compression method that can reduce both spatial and channel wise redundancy in an SR deep network for different input images. To reduce the spatial-wise redundancy, we propose to perform convolution on scaled-down feature-maps where the down-scaling factor is made adaptive to different input images. To reduce the channel-wise redundancy, we introduce a low-cost channel saliency predictor for each convolution to dynamically skip the computation of unimportant channels based on the Gumbel-Softmax. To better capture the feature-maps information and facilitate input-adaptive decision, we employ classic image processing metrics, e.g., Spatial Information, to guide the saliency predictors. The proposed method can be readily applied to a variety of SR deep networks and trained end-to-end with standard super-resolution loss, in combination with a sparsity criterion. Experiments on several benchmarks demonstrate that our method can effectively reduce the FLOPs of both lightweight and non-compact SR models with negligible PSNR loss. Moreover, our compressed models achieve competitive PSNR-FLOPs Pareto frontier compared with SOTA NAS-based SR methods. © 2022 IEEE.","Deep Learning Deep Learning; Efficient Training and Inference Methods for Networks","Institute of Electrical and Electronics Engineers Inc."
"Avci-Karatas C.","Application of Machine Learning in Prediction of Shear Capacity of Headed Steel Studs in Steel–Concrete Composite Structures",2022,"International Journal of Steel Structures",,"10.1007/s13296-022-00589-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126044937&doi=10.1007%2fs13296-022-00589-z&partnerID=40&md5=13dcf971d947ba3d26ff3470ab58c811","Headed studs are generally utilized as shear connectors at the interface between steel and concrete in composite structures primarily to transfer longitudinal shear force. This paper presents regression methodologies to predict the shear capacity of headed steel studs by using the concepts of minimax probability machine regression (MPMR) and extreme machine learning (EML). MPMR is carried out based on a minimax probability machine classification. EML is an updated version of a single hidden layer feedforward network. From the experimental data presented in extensive literature, key input parameters influencing the shear capacity have been identified and consolidated. The identified parameters include (i) steel stud shank diameter, (ii) compressive strength of concrete, and (iii) tensile strength of headed steel stud. After careful examination of the data and their limits, about 70–75% of the mixed dataset comprising the range of the values has been used for developing MPMR and EML-based models. The input data has been normalized based on the limits of individual parameters. The remaining data has been utilized for verification of the developed models. It is observed that the predicted shear strength capacity is comparable with the experimental observations. Further, the efficacy of the models has been evaluated through several statistical parameters, namely; root mean square error, mean absolute error, the coefficient of efficiency, root mean square error to observation’s standard deviation ratio, normalized mean bias error, performance index, and variance account factor. It is found that the R2 value is 0.9913 and 0.9479, respectively, for the models developed based on the concepts of MPMR and EML, indicating that the predicted value is closer to the experimental data. © 2022, Korean Society of Steel Construction.","Extreme machine learning; Headed stud; Minimax probability machine regression; Shear strength; Statistical modeling technique; Steel–concrete composite structure","Korean Society of Steel Construction"
"Latotzke C., Loh J., Gemmeke T.","Cascaded Classifier for Pareto-Optimal Accuracy-Cost Trade-Off Using Off-the-Shelf ANNs",2022,"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",,"10.1007/978-3-030-95470-3_32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125502557&doi=10.1007%2f978-3-030-95470-3_32&partnerID=40&md5=f25051b287170815d79ed3433944de14","Machine-learning classifiers provide high quality of service in classification tasks. Research now targets cost reduction measured in terms of average processing time or energy per solution. Revisiting the concept of cascaded classifiers, we present a first of its kind analysis of optimal pass-on criteria between the classifier stages. Based on this analysis, we derive a methodology to maximize accuracy and efficiency of cascaded classifiers. On the one hand, our methodology allows cost reduction of 1.32 × while preserving reference classifier’s accuracy. On the other hand, it allows to scale cost over two orders while gracefully degrading accuracy. Thereby, the final classifier stage sets the top accuracy. Hence, the multi-stage realization can be employed to optimize any state-of-the-art classifier. © 2022, Springer Nature Switzerland AG.","Cascaded classifier; Design methodology; Edge devices; Machine learning; Pareto analysis; Preliminary classifier","Springer Science and Business Media Deutschland GmbH"
"Kumar A., Goel S., Sinha N., Bhardwaj A.","A Logarithmic Distance-Based Multi-Objective Genetic Programming Approach for Classification of Imbalanced Data",2022,"Communications in Computer and Information Science",,"10.1007/978-3-030-95502-1_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125288719&doi=10.1007%2f978-3-030-95502-1_23&partnerID=40&md5=51ab5d580f6d25cbfb918c13eaed7518","Standard classification algorithms give biased results when data sets are imbalanced. Genetic Programming, a machine learning algorithm based on the evolution of species in nature, also suffers from the same issue. In this research work, we introduced a logarithmic distance-based multi-objective genetic programming (MOGP) approach for classifying imbalanced data. The proposed approach utilizes the logarithmic value of the distance between predicted and expected values. This logarithmic value for the minority and the majority classes is treated as two separate objectives while learning. In the final generation, the proposed approach generated a Pareto-front of classifiers with a balanced surface representing the majority and the minority class accuracies for binary classification. The primary advantage of the MOGP technique is that it can produce a set of good-performing classifiers in a single experimental execution. Against the MOGP approach, the canonical GP method requires multiple experimental runs and a priori objective-based fitness function. Another benefit of MOGP is that it explicitly includes the learning bias into the algorithms. For evaluation of the proposed approach, we performed extensive experimentation of five imbalanced problems. The proposed approach’s results have proven its superiority over the traditional method, where the minority and majority class accuracies are taken as two separate objectives. © 2022, Springer Nature Switzerland AG.","Fitness function; Genetic programming; Imbalanced data classification; Multi-objective optimization; Pareto front","Springer Science and Business Media Deutschland GmbH"
"Entezami A., Shariatmadar H., De Michele C.","Non-parametric empirical machine learning for short-term and long-term structural health monitoring",2022,"Structural Health Monitoring",1,"10.1177/14759217211069842","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125010228&doi=10.1177%2f14759217211069842&partnerID=40&md5=fe15223c6613af1b0ddd933a5f46e55e","Early damage detection is an initial step of structural health monitoring. Thanks to recent advances in sensing technology, the application of data-driven methods based on the concept of machine learning has significantly increased among civil engineers and researchers. On this basis, this article proposes a novel non-parametric anomaly detection method in an unsupervised learning manner via the theory of empirical machine learning. The main objective of this method is to define a new damage index by using some empirical measure and the concept of minimum distance value. For this reason, an empirical local density is initially computed for each feature and then multiplied by the minimum distance of that feature to derive a new damage index for decision-making. The minimum distance is obtained by calculating the distances between each feature and training samples and finding the minimum quantity. The major contributions of this research contain developing a novel non-parametric algorithm for decision-making under high-dimensional and low-dimensional features and proposing a new damage index. To detect early damage, a threshold boundary is computed by using the extreme value theory, generalized Pareto distribution, and peak-over-threshold approach. Dynamic and statistical features of two full-scale bridges are used to verify the effectiveness and reliability of the proposed non-parametric anomaly detection. In order to further demonstrate its accuracy and proper performance, it is compared with some classical and recently published anomaly detection techniques. Results show that the proposed non-parametric method can effectively discriminate a damaged state from its undamaged condition with high damage detectability and inconsiderable false positive and false negative errors. This method also outperforms the anomaly detection techniques considered in the comparative studies. © The Author(s) 2022.","bridges; empirical machine learning; environmental variability; non-parametric anomaly detection; Structural health monitoring","SAGE Publications Ltd"
"Zhang Z., Wu Z., Zhang H., Wang J.","Meta-Learning-Based Deep Reinforcement Learning for Multiobjective Optimization Problems",2022,"IEEE Transactions on Neural Networks and Learning Systems",,"10.1109/TNNLS.2022.3148435","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124831559&doi=10.1109%2fTNNLS.2022.3148435&partnerID=40&md5=81fb82be75ebf567876cf0fd1b58d809","Deep reinforcement learning (DRL) has recently shown its success in tackling complex combinatorial optimization problems. When these problems are extended to multiobjective ones, it becomes difficult for the existing DRL approaches to flexibly and efficiently deal with multiple subproblems determined by the weight decomposition of objectives. This article proposes a concise meta-learning-based DRL approach. It first trains a meta-model by meta-learning. The meta-model is fine-tuned with a few update steps to derive submodels for the corresponding subproblems. The Pareto front is then built accordingly. Compared with other learning-based methods, our method can greatly shorten the training time of multiple submodels. Due to the rapid and excellent adaptability of the meta-model, more submodels can be derived so as to increase the quality and diversity of the found solutions. The computational experiments on multiobjective traveling salesman problems and multiobjective vehicle routing problems with time windows demonstrate the superiority of our method over most of the learning-based and iteration-based approaches. IEEE","Deep reinforcement learning (DRL); Learning systems; meta-learning; multiobjective optimization; Optimization; Pareto optimization; Task analysis; Training; traveling salesman problem; Traveling salesman problems; Vehicle routing; vehicle routing problem.","Institute of Electrical and Electronics Engineers Inc."
"Wegier W., Koziarski M., Wozniak M., Wegier W.","Multicriteria Classifier Ensemble Learning for Imbalanced Data",2022,"IEEE Access",,"10.1109/ACCESS.2022.3149914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124735202&doi=10.1109%2fACCESS.2022.3149914&partnerID=40&md5=16aeae3d6e3baa62857f8ae9414566b9","One of the vital problems with the imbalanced data classifier training is the definition of an optimization criterion. Typically, since the exact cost of misclassification of the individual classes is unknown, combined metrics and loss functions that roughly balance the cost for each class are used. However, this approach can lead to a loss of information, since different trade-offs between class misclassification rates can produce similar combined metric values. To address this issue, this paper discusses a multi-criteria ensemble training method for the imbalanced data. The proposed method jointly optimizes precision and recall, and provides the end-user with a set of Pareto optimal solutions, from which the final one can be chosen according to the user's preference. The proposed approach was evaluated on a number of benchmark datasets and compared with the single-criterion approach (where the selected criterion was one of the chosen metrics). The results of the experiments confirmed the usefulness of the obtained method, which on the one hand guarantees good quality, i.e., not worse than the one obtained with the use of single-criterion optimization, and on the other hand, offers the user the opportunity to choose the solution that best meets their expectations regarding the trade-off between errors on the minority and the majority class. © 2013 IEEE.","Classifier ensemble; imbalanced data; multi-objective optimization; pattern classification","Institute of Electrical and Electronics Engineers Inc."
"Lee H., Lee S.H., Quek T.Q.S.","MOSAIC: Multi-objective Optimization Strategy for AI-aided Internet-of-Things Communications",2022,"IEEE Internet of Things Journal",,"10.1109/JIOT.2022.3150747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124711596&doi=10.1109%2fJIOT.2022.3150747&partnerID=40&md5=1451136b75b9cb2e54380d371082c413","Future Internet-of-Things (IoT) communication trends toward heterogeneous services and diverse quality-of-service requirements pose fundamental challenges for network management strategies. In particular, multi-objective optimization is necessary in resolving the competition among different nodes sharing limited wireless network resources. A unified coordination mechanism is essential such that individual nodes conduct the opportunistic maximization of heterogeneous local objectives for efficient distributed resource allocation. To such a problem, this paper proposes an artificial intelligence (AI) based framework which is termed as multi-objective optimization strategy for AI-aided Internet-of-Things communications (MOSAIC). This framework enables to tackle numerous MOO tasks in IoT network management with simple reconfiguration of learning rules. In this strategy, a component unit associated with an individual network node includes a pair of DNNs to learn optimal local functions responsible for calculation and distributed coordination, respectively. The resultant AI module swarm called DNN tiles realizes the node cooperation that collectively seeks distributed MOO calculation rules. The advantage of MOSAIC is characterized by Pareto tradeoffs among conflicting performance metrics in diverse wireless networking configurations subject to severe interference and distinct criteria for multiple targets. IEEE","deep learning; distributed network management; Evolutionary computation; Internet of Things; Linear programming; Multi-objective optimization; Optimization; primal-dual training.; Task analysis; Training; Wireless communication","Institute of Electrical and Electronics Engineers Inc."
"Khan F., Urooj A., Khan S.A., Khosa S.K., Muhammadullah S., Almaspoor Z.","Evaluating the Performance of Feature Selection Methods Using Huge Big Data: A Monte Carlo Simulation Approach",2022,"Mathematical Problems in Engineering",,"10.1155/2022/6607330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124033087&doi=10.1155%2f2022%2f6607330&partnerID=40&md5=fd79376ff891236a3ee0099883c99c12","In this article, we compare autometrics and machine learning techniques including Minimax Concave Penalty (MCP), Elastic Smoothly Clipped Absolute Deviation (E-SCAD), and Adaptive Elastic Net (AEnet). For simulation experiments, three kinds of scenarios are considered by allowing the multicollinearity, heteroscedasticity, and autocorrelation conditions with varying sample sizes and the varied number of covariates. We found that all methods show improved their performance for a large sample size. In the presence of low and moderate multicollinearity and low and moderate autocorrelation, the considered methods retain all relevant variables. However, for low and moderate multicollinearity, excluding AEnet, all methods keep many irrelevant predictors as well. In contrast, under low and moderate autocorrelation, along with AEnet, the Autometrics retain less irrelevant predictors. Considering the case of extreme multicollinearity, AEnet retains more than 93 percent correct variables with an outstanding gauge (zero percent). However, the potency of remaining techniques, specifically MCP and E-SCAD, tends towards unity with augmenting sample size but capturing massive irrelevant predictors. Similarly, in case of high autocorrelation, E-SCAD has shown good performance in the selection of relevant variables for a small sample, while in gauge, Autometrics and AEnet are performed better and often retained less than 5 percent irrelevant variables. In the presence of heteroscedasticity, all techniques often hold all relevant variables but also suffer from overspecification problems except AEnet and Autometrics which circumvent the irrelevant predictors and establish the true model precisely. For an empirical application, we take into account the workers' remittance data for Pakistan along its twenty-seven determinants spanning from 1972 to 2020 for Pakistan. The AEnet selected thirteen relevant covariates of workers' remittance while E-SCAD and MCP suffered from an overspecification problem. Hence, the policymakers and practitioners should focus on the relevant variables selected by AEnet to improve workers' remittance in the case of Pakistan. In this regard, the Pakistan government has devised policies that make it easy to transfer remittances legally and mitigate the cost of transferring remittances from abroad. The AEnet approach can help policymakers arrive at relevant variables in the presence of a huge set of covariates, which in turn produce accurate predictions. © 2022 Faridoon Khan et al.",,"Hindawi Limited"
"Kaka J.R., Satya Prasad K.","Differential Evolution and Multiclass Support Vector Machine for Alzheimer's Classification",2022,"Security and Communication Networks",,"10.1155/2022/7275433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123978187&doi=10.1155%2f2022%2f7275433&partnerID=40&md5=956b8fe51aec3f8e1d6d54354adc544b","Early diagnosis of Alzheimer's helps a doctor to decide the treatment for the patient based on the stages. The existing methods involve applying the deep learning methods for Alzheimer's classification and have the limitations of overfitting problems. Some researchers were involved in applying the feature selection based on the optimization method, having limitations of easily trapping into local optima and poor convergence. In this research, Differential Evolution-Multiclass Support Vector Machine (DE-MSVM) is proposed to increase the performance of Alzheimer's classification. The image normalization method is applied to enhance the quality of the image and represent the features effectively. The AlexNet model is applied to the normalized images to extract the features and also applied for feature selection. The Differential Evolution method applies Pareto Optimal Front for nondominated feature selection. This helps to select the feature that represents the characteristics of the input images. The selected features are applied in the MSVM method to represent in high dimension and classify Alzheimer's. The DE-MSVM method has accuracy of 98.13% in the axial slice, and the existing whale optimization with MSVM has 95.23% accuracy. © 2022 Jhansi Rani Kaka and K. Satya Prasad.",,"Hindawi Limited"
"Mohanty R., Das S.K., Mohanty M.","Shear Wave Velocity-Based Liquefaction Susceptibility of Soil Using Extreme Learning Machine (ELM) with Strength Pareto Evolutionary Algorithm (SPEA 2)",2022,"Lecture Notes in Civil Engineering",,"10.1007/978-981-16-5669-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123284338&doi=10.1007%2f978-981-16-5669-9_3&partnerID=40&md5=ffa8ff2f650cb88acc086e8847b18797","In the present study, the multi-objective optimization problems observed in the prediction of shear wave velocity (Vs)-based liquefaction susceptibility of soil are solved in the framework of multi-objective feature selection (MOFS) algorithms. The learning algorithm, extreme learning machine, ELM and a multi-objective evolutionary algorithm (MOEA) algorithm, strength Pareto evolutionary algorithm (SPEA 2) are unified to form the MOFS algorithm. The proposed MOFS model is equally proficient in predicting the liquefied and non-liquefied cases for a highly unbalanced database of Vs with the ratio of liquefaction (L) to non-liquefaction (NL) cases being 287:124 (L/NL = 2.31). The additional merit of the present study is the identification of important input features; cyclic stress ratio (CSR), Vs, and moment magnitude of the earthquake (Mw). The representation of the results as Pareto front facilitates in the decision-making process. ELM + SPEA 2 is also found to be more efficient in equal prediction of majority and minority class instances; thus, it outperforms ELM + non-dominated sorting genetic algorithm (NSGA-II) as a classifier model. It was also observed that for training to testing ratios of 0.70:0.30 and 0.75:0.25, ELM + SPEA 2 has better generalization capacity than ELM + NSGA-II. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Extreme learning machine (ELM); Liquefaction; Multi-objective feature selection (MOFS); Shear wave velocity (Vs); Strength Pareto evolutionary algorithm (SPEA 2)","Springer Science and Business Media Deutschland GmbH"
"Balicki J.","Many-Objective Quantum-Inspired Particle Swarm Optimization Algorithm for Placement of Virtual Machines in Smart Computing Cloud",2022,"Entropy",1,"10.3390/e24010058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122963068&doi=10.3390%2fe24010058&partnerID=40&md5=4c96ae32465486970785f56fdd3e5c19","Particle swarm optimization algorithm (PSO) is an effective metaheuristic that can determine Pareto-optimal solutions. We propose an extended PSO by introducing quantum gates in order to ensure the diversity of particle populations that are looking for efficient alternatives. The quality of solutions was verified in the issue of assignment of resources in the computing cloud to improve the live migration of virtual machines. We consider the multi-criteria optimization problem of deep learning-based models embedded into virtual machines. Computing clouds with deep learning agents can support several areas of education, smart city or economy. Because deep learning agents require lots of computer resources, seven criteria are studied such as electric power of hosts, reliability of cloud, CPU workload of the bottleneck host, communication capacity of the critical node, a free RAM capacity of the most loaded memory, a free disc memory capacity of the most busy storage, and overall computer costs. Quantum gates modify an accepted position for the current location of a particle. To verify the above concept, various simulations have been carried out on the laboratory cloud based on the OpenStack platform. Numerical experiments have confirmed that multi-objective quantum-inspired particle swarm optimization algorithm provides better solutions than the other metaheuristics. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Computing cloud; Manyobjective optimization; Particle swarm optimization; Quantum gates; Virtual machines","MDPI"
"Zaki M., Venugopal V., Bhattoo R., Bishnoi S., Singh S.K., Allu A.R., Jayadeva, Krishnan N.M.A.","Interpreting the optical properties of oxide glasses with machine learning and Shapely additive explanations",2022,"Journal of the American Ceramic Society",,"10.1111/jace.18345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122922699&doi=10.1111%2fjace.18345&partnerID=40&md5=bdff64a1f536e947caa84c5e0b640fee","Due to their excellent optical properties, glasses are used for various applications ranging from smartphone screens to telescopes. Developing compositions with tailored Abbe number (Vd) and refractive index at 587.6 nm (nd), two crucial optical properties, is a major challenge. To this extent, machine learning (ML) approaches have been successfully used to develop composition–property models. However, these models are essentially black boxes in nature and suffer from the lack of interpretability. In this paper, we demonstrate the use of ML models to predict the composition-dependent variations of Vd and nd. Further, using Shapely additive explanations (SHAP), we interpret the ML models to identify the contribution of each of the input components toward target prediction. We observe that glass formers such as SiO2, B2O3, and P2O5 and intermediates such as TiO2, PbO, and Bi2O3 play a significant role in controlling the optical properties. Interestingly, components contributing toward increasing the nd are found to decrease the Vd and vice versa. Finally, we develop the Abbe diagram, using the ML models, allowing accelerated discovery of new glasses for optical properties beyond the experimental pareto front. Overall, employing explainable ML, we predict and interpret the compositional control on the optical properties of oxide glasses. © 2022 The American Ceramic Society",,"John Wiley and Sons Inc"
"Tai X.Y., Ocone R., Christie S.D.R., Xuan J.","Multi-objective optimisation with hybrid machine learning strategy for complex catalytic processes",2022,"Energy and AI",,"10.1016/j.egyai.2021.100134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122021799&doi=10.1016%2fj.egyai.2021.100134&partnerID=40&md5=ca8558c6f7d0e01788c6e79a6582f019","Catalytic chemical processes such as hydrocracking, gasification and pyrolysis play a vital role in the renewable energy and net zero transition. Due to the complex and non-linear behaviours during operation, catalytic chemical processes require a powerful modelling tool for prediction and optimisation for smart operation, speedy green process routes discovery and rapid process design. However, challenges remain due to the lack of an effective modelling and optimisation toolbox, which requires not only a precise analysis but also a fast optimisation. Here, we propose a hybrid machine learning strategy by embedding the physics-based continuum lumping kinetic model into the data-driven artificial neural network framework. This hybrid model is adopted as the surrogate model in the multi-objective optimisation and demonstrated in the benchmarking of a hydrocracking process. The results show that the novel hybrid surrogate model exhibits the mean square error less than 0.01 by comparing with the physics-based simulation results. This well-trained hybrid model was then integrated with non-dominated-sort genetic algorithm (NSGA-II) as the surrogate model to evaluate and optimise the yield and selectivity of the hydrocracking process. The Pareto front from the multi-objective optimisation was able to identify the trade-off curve between the objective functions which is essential for the decision-making during process design. Our work indicates that adopting the hybrid machine learning strategy as the surrogate model in the multi-objective optimisation is a promising approach in various complex catalytic chemical processes to enable an accurate computation as well as a rapid optimisation. © 2021 The Author(s)","Catalytic chemical process; Hybrid machine learning; Hybrid surrogate model; Multi-objective optimisation","Elsevier B.V."
"Du Y., Li J., Chen X., Duan P., Pan Q.","Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem",2022,"IEEE Transactions on Emerging Topics in Computational Intelligence",1,"10.1109/TETCI.2022.3145706","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121913974&doi=10.1109%2fTETCI.2022.3145706&partnerID=40&md5=19eda79a516dca5b3871a3ab12a2089c","In this study, a flexible job shop scheduling problem with time-of-use electricity price constraint is considered. The problem includes machine processing speed, setup time, idle time, and the transportation time between machines. Both maximum completion time and total electricity price are optimized simultaneously. A hybrid multi-objective optimization algorithm of estimation of distribution algorithm and deep Q-network is proposed to solve this. The processing sequence, machine assignment, and processing speed assignment are all described using a three-dimensional solution representation. Two knowledge-based initialization strategies are designed for better performance. In the estimation of distribution algorithm component, three probability matrices corresponding to solution representation are provided. In the deep Q-network component, 34 state features are selected to describe the scheduling situation, while nine knowledge-based actions are defined to refine the scheduling solution, and the reward based on the two objectives is designed. As the knowledge for initialization and optimization strategies, five properties of the considered problem are proposed. The proposed mixed integer linear programming model of the problem is validated by exact solver CPLEX. The results of the numerical testing on wide-range scale instances show that the proposed hybrid algorithm is efficient and effective at solving the integrated flexible job shop scheduling problem. IEEE","deep reinforcement learning; Estimation; estimation of distribution algorithm; Flexible job shop scheduling problem; Indexes; Job shop scheduling; Knowledge based systems; multi-objective optimization; Optimization; Standards; Transportation","Institute of Electrical and Electronics Engineers Inc."
"Koh P.W., Steinhardt J., Liang P.","Stronger data poisoning attacks break data sanitization defenses",2022,"Machine Learning",,"10.1007/s10994-021-06119-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120623996&doi=10.1007%2fs10994-021-06119-y&partnerID=40&md5=a3361e7ee7fd97e8160f002e135f3337","Machine learning models trained on data from the outside world can be corrupted by data poisoning attacks that inject malicious points into the models’ training sets. A common defense against these attacks is data sanitization: first filter out anomalous training points before training the model. In this paper, we develop three attacks that can bypass a broad range of common data sanitization defenses, including anomaly detectors based on nearest neighbors, training loss, and singular-value decomposition. By adding just 3% poisoned data, our attacks successfully increase test error on the Enron spam detection dataset from 3 to 24% and on the IMDB sentiment classification dataset from 12 to 29%. In contrast, existing attacks which do not explicitly account for these data sanitization defenses are defeated by them. Our attacks are based on two ideas: (i) we coordinate our attacks to place poisoned points near one another, and (ii) we formulate each attack as a constrained optimization problem, with constraints designed to ensure that the poisoned points evade detection. As this optimization involves solving an expensive bilevel problem, our three attacks correspond to different ways of approximating this problem, based on influence functions; minimax duality; and the Karush–Kuhn–Tucker (KKT) conditions. Our results underscore the need to develop more robust defenses against data poisoning attacks. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.","Anomaly detection; Data poisoning; Data sanitization; Security","Springer"
"Ohanyan H., Portengen L., Huss A., Traini E., Beulens J.W.J., Hoek G., Lakerveld J., Vermeulen R.","Machine learning approaches to characterize the obesogenic urban exposome",2022,"Environment International",,"10.1016/j.envint.2021.107015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120458428&doi=10.1016%2fj.envint.2021.107015&partnerID=40&md5=61994e78d6125e5335caec7a84f71ea7","Background: Characteristics of the urban environment may contain upstream drivers of obesity. However, research is lacking that considers the combination of environmental factors simultaneously. Objectives: We aimed to explore what environmental factors of the urban exposome are related to body mass index (BMI), and evaluated the consistency of findings across multiple statistical approaches. Methods: A cross-sectional analysis was conducted using baseline data from 14,829 participants of the Occupational and Environmental Health Cohort study. BMI was obtained from self-reported height and weight. Geocoded exposures linked to individual home addresses (using 6-digit postcode) of 86 environmental factors were estimated, including air pollution, traffic noise, green-space, built environmental and neighborhood socio-demographic characteristics. Exposure-obesity associations were identified using the following approaches: sparse group Partial Least Squares, Bayesian Model Averaging, penalized regression using the Minimax Concave Penalty, Generalized Additive Model-based boosting Random Forest, Extreme Gradient Boosting, and Multiple Linear Regression, as the most conventional approach. The models were adjusted for individual socio-demographic variables. Environmental factors were ranked according to variable importance scores attributed by each approach and median ranks were calculated across these scores to identify the most consistent associations. Results: The most consistent environmental factors associated with BMI were the average neighborhood value of the homes, oxidative potential of particulate matter air pollution (OP), healthy food outlets in the neighborhood (5 km buffer), low-income neighborhoods, and one-person households in the neighborhood. Higher BMI levels were observed in low-income neighborhoods, with lower average house values, lower share of one-person households and smaller amount of healthy food retailers. Higher BMI levels were observed in low-income neighborhoods, with lower average house values, lower share of one-person households, smaller amounts of healthy food retailers and higher OP levels. Across the approaches, we observed consistent patterns of results based on model's capacity to incorporate linear or nonlinear associations. Discussion: The pluralistic analysis on environmental obesogens strengthens the existing evidence on the role of neighborhood socioeconomic position, urbanicity and air pollution. © 2021 The Author(s)","Air pollution; Exposome; Extreme gradient boosting (XGBoost); Random forest; Shapley values; Socioeconomic position","Elsevier Ltd"
"Cao J., Ma J., Huang D., Yu P.","Finding the optimal multilayer network structure through reinforcement learning in fault diagnosis",2022,"Measurement: Journal of the International Measurement Confederation",1,"10.1016/j.measurement.2021.110377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119429715&doi=10.1016%2fj.measurement.2021.110377&partnerID=40&md5=1303f95bcc598534a62cb1e436501915","Deep learning (DL) is an important method in industrial fault diagnosis. However, DL's network structure needs to be designed with experience. To simplify the design of network structures, we propose the neural architecture search network with Pareto efficiency reward and insert replay buffer (NAS-PERIRB) algorithm. In this paper, the early stopping and insert replay buffer (IRB) are used to improving the training efficiency of the samples. In addition, we design the Pareto efficiency reward function to optimize the goals and design a network search space to perform effective searches. What is more, we evaluate the NAS-PERIRB under two datasets. Results show that the two datasets have reached 99% accuracy in various situations, which means the NAS-PERIRB can achieve the purpose of designing the network structure independently. © 2021 Elsevier Ltd","Fault diagnosis; Neural architecture search; Pareto efficiency; Reinforcement learning","Elsevier B.V."
"Nakonechnyi O., Martsenyuk V., Klos-Witkowska A., Zhehestovska D.","Minimax Combined with Machine Learning to Cope with Uncertainties in Medical Application",2022,"Lecture Notes in Networks and Systems",,"10.1007/978-981-16-2102-4_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118996776&doi=10.1007%2f978-981-16-2102-4_64&partnerID=40&md5=eb695ac6bc987daeae45e1c2712ae9e2","The work considers ML problems in medical application and presents a minimax approach for developing ML models that would be resistant to aleatoric and epistemic uncertainties. Aleatoric uncertainties are presented with the help of different resampling strategies whereas epistemic ones are a variety of models. The main methods applied are based on linear regression, SVM, random forest for ML, PCA for dimension reduction, and cross-validation as a resampling strategy. The approach which is offered is presented with the help of the flowchart which includes the basic steps of ML model development under uncertainties, including import and primary processing of the clinical data, the statement of task, resampling strategy including the dimension reduction, the choice of methods (learners), tuning their parameters, and models comparison on the basis of minimax criterion. As a clinical example, we consider the problem of the development of learners for lifetime prediction for cardiac patients. The software implementation of the ML model development under uncertainties is offered in the package mlr with the help of the benchmark of learners. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Cardiac pathology; Cross-validation; Machine learning; Medical research; Minimax; mlr; Resampling strategy; Uncertainty","Springer Science and Business Media Deutschland GmbH"
"Priyanka N., Reshmi T.R., Murugan K.","CEOF: Enhanced Clustering-based Entries Optimization scheme to prevent Flow table overflow",2022,"Wireless Networks",,"10.1007/s11276-021-02823-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118295540&doi=10.1007%2fs11276-021-02823-8&partnerID=40&md5=a7d2fc1187c0055d9faff297740f7a9d","Software-Defined Networking is an advanced networking architecture that decouples the control and data plane for efficient and flexible network administration. The packets are forwarded based on the rules existing in the flow table that resides in the Ternary Content Addressable Memory (TCAM) and plays a key role in packet forwarding. TCAM is prominent for wire-speed processing with certain limitations such as high power consumption, expensive, and limited storage. It creates a serious challenge in terms of scalability where the limited sized flow tables are over-utilized and are easily overflowed during a high traffic rate. The flow table overflow creates blocking of new incoming flows or eviction of existing entries that are accessed by active flows. To overcome these challenges and to provide Quality of Service to the current network design, an entry reduction scheme is proposed using machine learning algorithms. It consists of two phases (1) Detection of overflow by estimating the cardinality of entries in each snapshot of the flow table which is carried out using HyperLogLog. (2) When overflow is detected, immediately the mitigation is carried out by evicting the extravagant entries using Hierarchical Agglomerative Clustering followed by entries optimization of each cluster using Pareto Optimizer. The simulation results proved that the proposed work reduces 99.99% of redundant entries and, 99.98% of increased network throughput with reduced controller overhead. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Flow table; HAC; HLL; Pareto optimization; SDN; TCAM","Springer"
"Guarrasi V., D'Amico N.C., Sicilia R., Cordelli E., Soda P.","Pareto optimization of deep networks for COVID-19 diagnosis from chest X-rays",2022,"Pattern Recognition",3,"10.1016/j.patcog.2021.108242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112583272&doi=10.1016%2fj.patcog.2021.108242&partnerID=40&md5=1c1e1595c7df74df07cc8c1372ed2060","The year 2020 was characterized by the COVID-19 pandemic that has caused, by the end of March 2021, more than 2.5 million deaths worldwide. Since the beginning, besides the laboratory test, used as the gold standard, many applications have been applying deep learning algorithms to chest X-ray images to recognize COVID-19 infected patients. In this context, we found out that convolutional neural networks perform well on a single dataset but struggle to generalize to other data sources. To overcome this limitation, we propose a late fusion approach where we combine the outputs of several state-of-the-art CNNs, introducing a novel method that allows us to construct an optimum ensemble determining which and how many base learners should be aggregated. This choice is driven by a two-objective function that maximizes, on a validation set, the accuracy and the diversity of the ensemble itself. A wide set of experiments on several publicly available datasets, accounting for more than 92,000 images, shows that the proposed approach provides average recognition rates up to 93.54% when tested on external datasets. © 2021 Elsevier Ltd","Convolutional neural networks; COVID-19; Deep-learning; Multi-expert systems; Optimization; X-ray","Elsevier Ltd"
"Zhou X., Gao Y., Li C., Huang Z.","A Multiple Gradient Descent Design for Multi-Task Learning on Edge Computing: Multi-Objective Machine Learning Approach",2022,"IEEE Transactions on Network Science and Engineering",1,"10.1109/TNSE.2021.3067454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103287032&doi=10.1109%2fTNSE.2021.3067454&partnerID=40&md5=7957f9eec9d09165a78eefd368b57e7d","Multi-task learning technique is widely utilized in machine learning modeling where commonalities and differences across multiple tasks are exploited. However, multiple conflicting objectives often occur in multi-task learning. Conventionally, a common compromise is to minimize the weighted sum of multiple objectives which may be invalid if the objectives are competing. In this paper, a novel multi-objective machine learning approach is proposed to solve this challenging issue, which reformulates the multi-task learning as multi-objective optimization. To address the issues contributed by existing multi-objective optimization algorithms, a multi-gradient descent algorithm is introduced for the multi-objective machine learning problem by which an innovative gradient-based optimization is leveraged to converge to an optimal solution of the Pareto set. Moreover, the gradient surgery for the multi-gradient descent algorithm is proposed to obtain a stable Pareto optimal solution. As most of the edge computing devices are computational resource-constrained, the proposed method is implemented for optimizing the edge device's memory, computation and communication demands. The proposed method is applied to the multiple license plate recognition problem. The experimental results show that the proposed method outperforms state-of-the-art learning methods and can successfully find solutions that balance multiple objectives of the learning task over different datasets. © 2013 IEEE.","Deep neural network; Edge computing; Multi-objective machine learning; Multi-task learning; Multiple gradient descent","IEEE Computer Society"
"Lin S., Wu W., Wu S., Xu Y., Wong H.-S.","Unreliable-to-Reliable Instance Translation for Semi-Supervised Pedestrian Detection",2022,"IEEE Transactions on Multimedia",,"10.1109/TMM.2021.3058546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100867886&doi=10.1109%2fTMM.2021.3058546&partnerID=40&md5=5c382e5770650ddf7edc5c06aedf5498","Generating realistic pedestrian instances in a semi-supervised setting is promising but challenging due to the limited labeled data. We propose an unreliable-to-reliable instance translation model (Un2Reliab) conditioned on unreliable instances which poorly align with pedestrians. Un2Reliab mainly consists of an encoder-decoder-like generative network and a discriminative network, which are jointly trained in a minimax game. We adopt regularization to ensure that the synthesized instances are semantically similar to the corresponding ground truth. Furthermore, to preserve the identities of persons, we propose another regularization to ensure that the synthesized instances associated with the same person should be consistent in appearance. As a result, Un2Reliab learns to restore the missing parts of the original instances. As a side benefit, the synthesized instances are brought into better alignment. Inclusion of the synthesized data improves both the diversity and quality of training data, which eventually leads to better generalization performance. Extensive experiments indicate that Un2Reliab is able to synthesize high-fidelity pedestrian instances and improve the previous state-of-the-art results on multiple semi-supervised pedestrian detection benchmarks. © 1999-2012 IEEE.","Generative adversarial network; image-to-image translation; pedestrian detection; semi-supervised learning","Institute of Electrical and Electronics Engineers Inc."
"Lyu B., Yuan H., Lu L., Zhang Y.","Resource-Constrained Neural Architecture Search on Edge Devices",2022,"IEEE Transactions on Network Science and Engineering",2,"10.1109/TNSE.2021.3054583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100454516&doi=10.1109%2fTNSE.2021.3054583&partnerID=40&md5=f90130fefe37f379fc702401a1a213fb","The performance requirement of deep learning inevitably brings up with the expense of high computational complexity and memory requirements, to make it problematic for the deployment on resource-constrained devices. Edge computing, which distributedly organizes the computing node close to the data source and end-device, provides a feasible way to tackle the high-efficiency demand and substantial computational load. Whereas given edge device is resource-constrained and energy-sensitive, designing effective neural network architecture for specific edge device is urgent in the sense that deploys the deep learning application by the edge computing solution. Undoubtedly manually design the high-performing neural architectures is burdensome, let alone taking account of the resource-constraint for the specific platform. Fortunately, the success of Neural Architecture Search techniques come up with hope recently. This paper dedicates to directly employ multi-objective NAS on the resource-constrained edge devices. We first propose the framework of multi-objective NAS on edge device, which comprehensively considers the performance and real-world efficiency. Our improved MobileNet-V2 search space also strikes the scalability and practicality, so that a series of Pareto-optimal architectures are received. Benefits from the directness and specialization during search procedure, our experiment on JETSON NANO shows the comparable result with the state-of-the-art models on ImageNet. © 2013 IEEE.","Edge computing; multi-objective; neural architecture search; reinforcement learning.","IEEE Computer Society"
"Vogel R.M.","The geometric mean?",2022,"Communications in Statistics - Theory and Methods",5,"10.1080/03610926.2020.1743313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083584916&doi=10.1080%2f03610926.2020.1743313&partnerID=40&md5=e116d180698a110326ecd4f8ab901f58","The sample geometric mean (SGM) introduced by Cauchy in 1821, is a measure of central tendency with many applications in the natural and social sciences including environmental monitoring, scientometrics, nuclear medicine, infometrics, economics, finance, ecology, surface and groundwater hydrology, geoscience, geomechanics, machine learning, chemical engineering, poverty and human development, to name a few. Remarkably, it was not until 2013 that a theoretical definition of the population geometric mean (GM) was introduced. Analytic expressions for the GM are derived for many common probability distributions, including: lognormal, Gamma, exponential, uniform, Chi-square, F, Beta, Weibull, Power law, Pareto, generalized Pareto and Rayleigh. Many previous applications of SGM assumed lognormal data, though investigators were unaware that for that case, the GM is the median and SGM is a maximum likelihood estimator of the median. Unlike other measures of central tendency such as the mean, median, and mode, the GM lacks a clear physical interpretation and its estimator SGM exhibits considerable bias and mean square error, which depends significantly on sample size, pd, and skewness. A review of the literature reveals that there is little justification for use of the GM in many applications. Recommendations for future research and application of the GM are provided. © 2020 Taylor & Francis Group, LLC.","arithmetic mean; Central tendency; effective; log transformation; lognormal; median; multiplicative aggregation","Taylor and Francis Ltd."
"Acharya A., Bansak K., Hainmueller J.","Combining Outcome-Based and Preference-Based Matching: A Constrained Priority Mechanism",2022,"Political Analysis",1,"10.1017/pan.2020.48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114628828&doi=10.1017%2fpan.2020.48&partnerID=40&md5=35d5c4404ba702a8df72ecc69882e04b","We introduce a constrained priority mechanism that combines outcome-based matching from machine learning with preference-based allocation schemes common in market design. Using real-world data, we illustrate how our mechanism could be applied to the assignment of refugee families to host country locations, and kindergarteners to schools. Our mechanism allows a planner to first specify a threshold for the minimum acceptable average outcome score that should be achieved by the assignment. In the refugee matching context, this score corresponds to the probability of employment, whereas in the student assignment context, it corresponds to standardized test scores. The mechanism is a priority mechanism that considers both outcomes and preferences by assigning agents (refugee families and students) based on their preferences, but subject to meeting the planner's specified threshold. The mechanism is both strategy-proof and constrained efficient in that it always generates a matching that is not Pareto dominated by any other matching that respects the planner's threshold. ©","game theory; machine learning; matching; political market design; social choice","Cambridge University Press"
"Huang H., Xue C., Zhang W., Guo M.","Torsion design of CFRP-CFST columns using a data-driven optimization approach",2022,"Engineering Structures",9,"10.1016/j.engstruct.2021.113479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118869513&doi=10.1016%2fj.engstruct.2021.113479&partnerID=40&md5=bcf232c5751ed78c27712549b969f539","A challenging issue of utilizing the merit of the machine learning model to the multi-objective optimization (MOO) problem is that sufficient physical experiments data are hard to get. With the limited training data, overfitting of the surrogate model is inevitable, which may mislead the search engine. A data-driven model based on simulations commonly has a better performance for addressing overfitting problems. However, there is a gap between the numerical model and the real structure/physical experiments. In this paper, a framework called data-driven optimization is proposed for structural performance optimization. First, the transfer learning algorithm (two-stage TrAdaBoost) is designed to reweight the simulation data points that have more significant residuals predicted by a base learner (i.e., ensemble machine learning model), which goal is to select the “accuracy” of simulation data points as supplements to the real structure/physical experiments data points, instead of trying to reduce the gap by model-updating methods, as the traditional methods do. In this way, simulation data points relevant to the real structure/physical experiments will be assigned a large weight value. Then, the generated two-stage TrAdaBoost model incorporated with nondominated sorting genetic algorithm II (NSGA-II) is used to optimize structure design. Finally, this paper used the proposed framework to conduct feature impact analysis, fast predict, and optimize torsion design for the concrete-filled steel tube (CFST) column subjected to combined compression-bending-torsion. The results showed that the two-stage TrAdaBoost algorithm performs better and outperforms the baseline model, an extreme gradient boosting (XGBoost). By typical examples, the proposed framework can be a viable tool for the preliminary design of the CFST column. The Pareto fronts of the two objectives (ultimate torsion strength and cost) are successfully obtained. © 2021 Elsevier Ltd","CFST columns; Combined loads; Multi-objective optimization; Overfitting; SHAP values; Transfer learning","Elsevier Ltd"
"Lyaqini S., Nachaoui M., Hadri A.","An efficient primal-dual method for solving non-smooth machine learning problem",2022,"Chaos, Solitons and Fractals",,"10.1016/j.chaos.2021.111754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122162471&doi=10.1016%2fj.chaos.2021.111754&partnerID=40&md5=bb5738a2ea6b27e994806ca6a7699aa1","This paper deals with the machine learning model as a framework of regularized loss minimization problem in order to obtain a generalized model. Recently, some studies have proved the success and the efficiency of nonsmooth loss function for supervised learning problems Lyaqini et al. [1]. Motivated by the success of this choice, in this paper we formulate the supervised learning problem based on L1 fidelity term. To solve this nonsmooth optimization problem we transform it into a mini-max one. Then we propose a Primal-Dual method that handles the mini-max problem. This method leads to an efficient and significantly faster numerical algorithm to solve supervised learning problems in the most general case. To illustrate the effectiveness of the proposed approach we present some experimental-numerical validation examples, which are made through synthetic and real-life data. Thus, we show that our approach is outclassing existing methods in terms of convergence speed, quality, and stability of the predicted models. © 2021 Elsevier Ltd","ECG; Kernel methods EMG; Non-smooth optimization; Primal-dual algorithm; Supervised learning","Elsevier Ltd"
"Li H., Sansalone J.","A CFD-ML augmented alternative to residence time for clarification basin scaling and design",2022,"Water Research",1,"10.1016/j.watres.2021.117965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121565206&doi=10.1016%2fj.watres.2021.117965&partnerID=40&md5=11630b4f1787f6f000389614e38c3a8b","Particulate matter (PM), while not an emerging contaminant, remains the primary labile substrate for partitioning and transport of emerging and known chemicals and pathogens. As a common unit operation and also green infrastructure, clarification basins are widely implemented to sequester PM as well as PM-partitioned chemicals and pathogens. Despite ubiquitous application for urban drainage, stormwater clarification basin design and optimization lacks robust and efficient design guidance and tools. Current basin design and regulation primarily adopt residence time (RT) as presumptive guidance. This study examines the accuracy and generalizability of RT and nondimensional groups of basin geometric and dynamic similarity (Hazen, Reynolds, Schmidt numbers) to scale clarification basin performance (measured as PM separation and total PM separation). Published data and 160,000 computational fluid dynamics (CFD) simulations of basin PM separation over a wide range of basin configurations, loading conditions, and PM granulometry (particle size distribution [PSD], density) are examined. Based on the CFD database, a novel implementation of machine learning (ML) models: decision tree (DT), random forest (RF), artificial neural networks (ANN), and symbolic regression (SR) are developed and trained as surrogate models for basin PM separation predictions. Study results indicate that: (1) Models based solely on RT are not accurate or generalizable for basin PM separation, with significant differences between CFD and RT models primarily for RT &lt; 200 hr, (2) RT models are agnostic to basin configurations and PM granulometrics and therefore do not reproduce total PM separation, (3) Trained ML models provide high predictive capability, with (R2) above 0.99 and prediction for total PM separation within ±15%. In particular, the SR model distilled from CFD simulations is entirely defined by only two compact algebraic equations (allowing use in a spreadsheet tool). The SR model has a physical basis and indicates PM separation is primarily a function of the Hazen number and basin horizontal and vertical aspect ratios, (4) With common presumptive guidance of 80% for PM separation, a Pareto frontier analysis indicates that the CFD-ML augmented SR model generates significant economic benefit for basin planning/design, and (5) CFD-ML models show that enlarging basin dimensions (increasing RT) to address impaired behavior can result in exponential cost increases, irrespective of land/infrastructure adjacency conflicts. CFD-ML applications can extend to intra-basin retrofits (permeable baffles) to upgrade impaired basins. © 2021 Elsevier Ltd","CFD; Computer aided design; Green water infrastructure; Machine learning; Retention; Water treatment","Elsevier Ltd"
"Sui Z., Sui Y., Wu W.","Multi-objective optimization of a microchannel membrane-based absorber with inclined grooves based on CFD and machine learning",2022,"Energy",1,"10.1016/j.energy.2021.122809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120677881&doi=10.1016%2fj.energy.2021.122809&partnerID=40&md5=cfb748592dee5edc43210969c3392bf7","A novel microchannel membrane-based absorber with inclined grooves is proposed and studied by a three-dimensional CFD model. Parametric analysis is carried out to analyze the effects of structural parameters on the absorption rate and pressure drop. Results indicate that the groove introduces a swirling effect in the solution channel, interrupting the boundary layer at the solution-membrane interface and increasing the solution residence time inside the microchannel. The absorption rate in the grooved channel is up to 1.55 times higher, while the pressure drop is 0.77–0.96 times lower. To optimize the novel absorber geometries and maximize the integrated performance, the Pareto front is obtained by performing a multi-objective optimization, in which a machine learning method based on ANN and NSGA-ΙΙ is developed. The optimal design parameters from the Pareto front are identified by two well-known decision-making methods, LINMAP and TOPSIS. Compared to the basic smooth channel, these methods generate 1.41 and 1.47 times improvement in volumetric cooling capacities, at a much lower solution pressure drop. Moreover, a high absorption rate equivalent to that of a 200 μm-thick smooth channel is achieved by LINMAP and TOPSIS, with pressure drops lower by 6.29 and 5.63 times, respectively. © 2021 Elsevier Ltd","Absorption refrigeration; Groove structure; Microchannel membrane absorber; ML and CFD; Multi-objective optimization","Elsevier Ltd"
"Khan T.Z., Kirk T., Vazquez G., Singh P., Smirnov A.V., Johnson D.D., Youssef K., Arróyave R.","Towards stacking fault energy engineering in FCC high entropy alloys",2022,"Acta Materialia",1,"10.1016/j.actamat.2021.117472","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120454238&doi=10.1016%2fj.actamat.2021.117472&partnerID=40&md5=1f83d7e461644c8228dee408469666ac","Stacking Fault Energy (SFE) is an intrinsic alloy property that governs much of the plastic deformation mechanisms observed in fcc alloys. While SFE has been recognized for many years as a key intrinsic mechanical property, its inference via experimental observations or prediction using, for example, computationally intensive first-principles methods is challenging. This difficulty precludes the explicit use of SFE as an alloy design parameter. In this work, we combine DFT calculations (with necessary configurational averaging), machine-learning (ML) and physics-based models to predict the SFE in the fcc CoCrFeMnNiV-Al high-entropy alloy space. The best-performing ML model is capable of accurately predicting the SFE of arbitrary compositions within this 7-element system. This efficient model along with a recently developed model to estimate intrinsic strength of fcc HEAs is used to explore the strength–SFE Pareto front, predicting new-candidate alloys with particularly interesting mechanical behavior. © 2021 Acta Materialia Inc.","Alloy design; High entropy alloys; Machine learning; Stacking fault energy","Acta Materialia Inc"
"Dong Y., Xiao H., Dong Y.","SA-CGAN: An oversampling method based on single attribute guided conditional GAN for multi-class imbalanced learning",2022,"Neurocomputing",,"10.1016/j.neucom.2021.04.135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119920919&doi=10.1016%2fj.neucom.2021.04.135&partnerID=40&md5=36499e21d9486263a7113ede0b3f2775","Imbalanced data can always be observed in our daily life and various practical tasks. A lot of well-constructed machine learning methodologies may produce ineffective performance, when conducted on this kind of data. This originates from the produced high training biases that towards the majority class instances. Among all the solutions of this problem, data generation of the minority class is always considered the most effective approach. However, in all the previous works, data are always processed sample-wisely and the distribution of each single data attribute is never noticed. So, in this paper, to estimate the mechanism of how each attribute contributes to its label, we explore the potential connection between the two items by Conditional Generative Adversarial Networks (CGAN) separately and individually. Then, the constructed new instances are purified by a designed attribute-based minimax filter and the survivors are concatenated to form the eventual generated data. In other words, different from the CGAN based data generation way, the proposed approach improves it by additionally considering all the single attribute patterns of the data that to construct new instances. In addition, we extend the binary class imbalanced learning framework to multiple class one. In the experimental part, the improved model is compared against GAN, CGAN and some other standard multiple-class oversampling algorithms on several widely used datasets. Results, in terms of four common measurements, have shown that the proposed approach can produce comparable and always superior performance when compared with the competitors. © 2021 Elsevier B.V.","Attribute/feature pattern learning; Data generation; Generative adversarial network; Multi-class uneven/imbalanced data","Elsevier B.V."
"Paul A., Zhao X., Fang L., Wu Z.","Ownership Recommendation via Iterative Adversarial Training",2022,"Neural Processing Letters",1,"10.1007/s11063-021-10647-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117045557&doi=10.1007%2fs11063-021-10647-y&partnerID=40&md5=9a3d2cf940104d6759b6b72fceef6095","Machine learning classifiers are vulnerable to adversarial perturbation, and their presence raises security concerns, especially in recommendation systems. While attacks and defense mechanisms in recommendation systems have received significant attention, Basic Iterative Method (BIM), which has been shown in Computer Vision to increase attack effectiveness by more than 60%, has received little attention in ownership recommendation. As a result, ownership recommender systems may be more sensitive to iterative perturbations, resulting in significant generalization errors. Adversarial Training, a regularization strategy that can withstand worst-case iterative perturbations, could be a viable option for improving model robustness and generalization. In this paper, we implement BIM for ownership recommendations. Through adversarial training, we propose the Adversarial Consumer and Producer Recommendation (ACPR) approach that integrates ownership features into a multi-objective pairwise ranking to capture the user’s preferences. The ACPR method learns a core embedding for each user and two transformation matrices that project the user’s core embedding into two role embeddings (i.e., a producer and consumer role) using an extension of matrix factorization. To minimize the impact of iterative perturbation, we train a consumer and producer recommender objective function using minimax adversarial training. Empirical studies on two Large-scale applications show that our method outperforms standard recommendation methods and recent methods that model ownership information. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Adversarial training; Iterative perturbation; Ownership recommendation; Sharing platforms","Springer"
"Swan B.P., Mayorga M.E., Ivy J.S.","The SMART Framework: Selection of Machine Learning Algorithms with ReplicaTions - A Case Study on the Microvascular Complications of Diabetes",2022,"IEEE Journal of Biomedical and Health Informatics",,"10.1109/JBHI.2021.3094777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112608698&doi=10.1109%2fJBHI.2021.3094777&partnerID=40&md5=0e1d5f5737aa09c2e3324a9428cfbd4b","Over 34 million people in the US have diabetes, a major cause of blindness, renal failure, and amputations. Machine learning (ML) models can predict high-risk patients to help prevent adverse outcomes. Selecting the 'best' prediction model for a given disease, population, and clinical application is challenging due to the hundreds of health-related ML models in the literature and the increasing availability of ML methodologies. To support this decision process, we developed the Selection of Machine-learning Algorithms with ReplicaTions (SMART) Framework that integrates building and selecting ML models with decision theory. We build ML models and estimate performance for multiple plausible future populations with a replicated nested cross-validation technique. We rank ML models by simulating decision-maker priorities, using a range of accuracy measures (e.g., AUC) and robustness metrics from decision theory (e.g., minimax Regret). We present the SMART Framework through a case study on the microvascular complications of diabetes using data from the ACCORD clinical trial. We compare selections made by risk-averse, -neutral, and -seeking decision-makers, finding agreement in 80% of the risk-averse and risk-neutral selections, with the risk-averse selections showing consistency for a given complication. We also found that the models that best predicted outcomes in the validation set were those with low performance variance on the testing set, indicating a risk-averse approach in model selection is ideal when there is a potential for high population feature variability. The SMART Framework is a powerful, interactive tool that incorporates various ML algorithms and stakeholder preferences, generalizable to new data and technological advancements. © 2013 IEEE.","Data-driven modeling; decision theory; diabetes; machine learning","Institute of Electrical and Electronics Engineers Inc."
"Yuan Y., Banzhaf W.","Expensive Multiobjective Evolutionary Optimization Assisted by Dominance Prediction",2022,"IEEE Transactions on Evolutionary Computation",,"10.1109/TEVC.2021.3098257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111029129&doi=10.1109%2fTEVC.2021.3098257&partnerID=40&md5=420dfc813def7d11fe908e2629eba413","We propose a new surrogate-assisted evolutionary algorithm for expensive multiobjective optimization. Two classification-based surrogate models are used, which can predict the Pareto dominance relation and θ-dominance relation between two solutions, respectively. To make such surrogates as accurate as possible, we formulate dominance prediction as an imbalanced classification problem and address this problem using deep learning techniques. Furthermore, to integrate the surrogates based on dominance prediction with multiobjective evolutionary optimization, we develop a two-stage preselection strategy. This strategy aims to select a promising solution to be evaluated among those produced by genetic operations, taking proper account of the balance between convergence and diversity. We conduct an empirical study on a number of well-known multiobjective and many-objective benchmark problems, over a relatively small number of function evaluations. Our experimental results demonstrate the superiority of the proposed algorithm compared with several representative surrogate-assisted algorithms. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Computational modeling; Convergence; Linear programming; Optimization; Prediction algorithms; Predictive models; Support vector machines","Institute of Electrical and Electronics Engineers Inc."
"Wang X., Huzhang G., Lin Q., Da Q.","Learning-to-ensemble by contextual rank aggregation in e-commerce",2022,"WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining",,"10.1145/3488560.3498401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125798467&doi=10.1145%2f3488560.3498401&partnerID=40&md5=a6ed81ee79e98bbf473bfc5d615d844f","Ensemble models in E-commerce combine predictions from multiple sub-models for ranking and revenue improvement. Industrial ensemble models are typically deep neural networks, following the supervised learning paradigm to infer conversion rate given inputs from sub-models. However, this process has the following two problems. Firstly, the point-wise scoring approach disregards the relationships between items and leads to homogeneous displayed results, while diversified display benefits user experience and revenue. Secondly, the learning paradigm focuses on the ranking metrics and does not directly optimize the revenue. In our work, we propose a new Learning-To-Ensemble (LTE) framework RA-EGO, which replaces the ensemble model with a contextual Rank Aggregator (RA) and explores the best weights of sub-models by the Evaluator-Generator Optimization (EGO). To achieve the best online performance, we propose a new rank aggregation algorithm TournamentGreedy as a refinement of classic rank aggregators, which also produces the best average weighted Kendall Tau Distance (KTD) amongst all the considered algorithms with quadratic time complexity. Under the assumption that the best output list should be Pareto Optimal on the KTD metric for sub-models, we show that our RA algorithm has higher efficiency and coverage in exploring the optimal weights. Combined with the idea of Bayesian Optimization and gradient descent, we solve the online contextual Black-Box Optimization task that finds the optimal weights for sub-models given a chosen RA model. RA-EGO has been deployed in our online system and has improved the revenue significantly. © 2022 ACM.","Contextual black-box optimization; Rank aggregation","Association for Computing Machinery, Inc"
"Zhang T., Bokrantz R., Olsson J.","Probabilistic Pareto plan generation for semiautomated multicriteria radiation therapy treatment planning",2022,"Physics in Medicine and Biology",,"10.1088/1361-6560/ac4da5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125493677&doi=10.1088%2f1361-6560%2fac4da5&partnerID=40&md5=fc30972fc37833e5181e26a920898a57","Objective. We propose a semiautomatic pipeline for radiation therapy treatment planning, combining ideas from machine learning-automated planning and multicriteria optimization (MCO). Approach. Using knowledge extracted from historically delivered plans, prediction models for spatial dose and dose statistics are trained and furthermore systematically modified to simulate changes in tradeoff priorities, creating a set of differently biased predictions. Based on the predictions, an MCO problem is subsequently constructed using previously developed dose mimicking functions, designed in such a way that its Pareto surface spans the range of clinically acceptable yet realistically achievable plans as exactly as possible. The result is an algorithm outputting a set of Pareto optimal plans, either fluence-based or machine parameter-based, which the user can navigate between in real time to make adjustments before a final deliverable plan is created. Main results. Numerical experiments performed on a dataset of prostate cancer patients show that one may often navigate to a better plan than one produced by a single-plan-output algorithm. Significance. We demonstrate the potential of merging MCO and a data-driven workflow to automate labor-intensive parts of the treatment planning process while maintaining a certain extent of manual control for the user. © 2022 Institute of Physics and Engineering in Medicine.","dose mimicking; dose prediction; dose-volume histogram prediction; knowledge-based planning; multicriteria optimization; uncertainty modeling","IOP Publishing Ltd"
"Sun J., Tang Y., Wang J., Wang X., Wang J., Yu Z., Cheng Q., Wang Y.","A multi-objective optimisation approach for activity excitation of waste glass mortar",2022,"Journal of Materials Research and Technology",,"10.1016/j.jmrt.2022.01.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125674101&doi=10.1016%2fj.jmrt.2022.01.066&partnerID=40&md5=d5038eb34e32b71fa98c9c9344c4f428","Waste glass is promising to be recycled and reused in construction for sustainability. Silicon dioxide is the main component of glass, however, its pozzolanic activity is latent mainly due to its stable silica tetrahedron structure. To excite the activation of waste glass, chemical activation and mechanical grinding of waste glass powder (WGP) were investigated. As the supplementary, hydrothermal and combined (mechanical-chemical-hydrothermal) treatments were conducted on part of the WGP samples. The unconfined compression strength (UCS), expansion caused by alkali–silica reaction (ASR), and the microstructural morphology of WGP were investigated. The results showed the dosage threshold (around 2%) of the chemical activators (alkali and sodium sulfate) and the combined activation were optimal. Besides, a firefly algorithm (FA) based multi-objective optimisation model (MOFA) was applied to seek the Pareto fronts based on three objectives: UCS, ASR expansion, and Cost of mixture proportion. The objective functions of UCS and expansion were established through training the machine learning (ML) models where FA was used to tune the hyperparameters. The cost was calculated by a polynomial function. The ultimate values of root mean square error (RMSE) and correlation coefficient (R) showed the robustness of the ML models. Moreover, the Pareto fronts for mortars containing 300 μm and 75 μm WGPs were successfully obtained, which contributed to the practical application of waste glass in mortar production. In addition, the sensitivity analysis was conducted to rank the importance of input variables. The results showed that curing time, activator's content, and WGP particle size were three essential parameters. © 2022","Activation methodology; Alkali–silica reaction; Compressive strength; Machine learning; Multi-objective optimisation; Waste glass","Elsevier Editora Ltda"
"Isaj S., Pedersen T.B., Zimanyi E.","Multi-Source Spatial Entity Linkage",2022,"IEEE Transactions on Knowledge and Data Engineering",,"10.1109/TKDE.2020.2990491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124655235&doi=10.1109%2fTKDE.2020.2990491&partnerID=40&md5=fc028bf56c0b98d8748fde5a025a83a0","Besides the traditional cartographic data sources, spatial information can also be derived from location-based sources. However, even though different location-based sources refer to the same physical world, each one has only partial coverage of the spatial entities, describe them with different attributes, and sometimes provide contradicting information. Hence, we introduce the spatial entity linkage problem, which finds which pairs of spatial entities belong to the same physical spatial entity. Our proposed solution (QuadSky) starts with a time-efficient spatial blocking technique (QuadFlex), compares pairwise the spatial entities in the same block, ranks the pairs using Pareto optimality with the SkyRank algorithm, and finally, classifies the pairs with our novel SkyEx-∗ family of algorithms that yield 0.85 precision and 0.85 recall for a manually labeled dataset of 1,500 pairs and 0.87 precision and 0.6 recall for a semi-manually labeled dataset of 777,452 pairs. Moreover, we provide a theoretical guarantee and formalize the SkyEx-FES algorithm that explores only 27 percent of the skylines without any loss in F-measure. Furthermore, our fully unsupervised algorithm SkyEx-D approximates the optimal result with an F-measure loss of just 0.01. Finally, QuadSky provides the best trade-off between precision and recall, and the best F-measure compared to the existing baselines and clustering techniques, and approximates the results of supervised learning solutions. © 2020 IEEE.","Entity resolution; Skyline-based; Spatial blocking; Spatial data","IEEE Computer Society"
"Yoo C., Lee H.W., Kang J.-W.","Transferring Structured Knowledge in Unsupervised Domain Adaptation of a Sleep Staging Network",2022,"IEEE Journal of Biomedical and Health Informatics",1,"10.1109/JBHI.2021.3103614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124578570&doi=10.1109%2fJBHI.2021.3103614&partnerID=40&md5=f31b366139138b18d47b2a472da0335b","Automatic sleep staging based on deep learning (DL) has been attracting attention for analyzing sleep quality and determining treatment effects. It is challenging to acquire long-term sleep data from numerous subjects and manually labeling them even though most DL-based models are trained using large-scale sleep data to provide state-of-the-art performance. One way to overcome this data shortage is to create a pre-trained network with an existing large-scale dataset (source domain) that is applicable to small cohorts of datasets (target domain); however, discrepancies in data distribution between the domains prevent successful refinement of this approach. In this paper, we propose an unsupervised domain adaptation method for sleep staging networks to reduce discrepancies by re-aligning the domains in the same space and producing domain-invariant features. Specifically, in addition to a classical domain discriminator, we introduce local discriminators - subject and stage - to maintain the intrinsic structure of sleep data to decrease local misalignments while using adversarial learning to play a minimax game between the feature extractor and discriminators. Moreover, we present several optimization schemes during training because the conventional adversarial learning is not effective to our training scheme. We evaluate the performance of the proposed method by examining the staging performances of a baseline network compared with direct transfer (DT) learning in various conditions. The experimental results demonstrate that the proposed domain adaptation significantly improves the performance though it needs no labeled sleep data in target domain. © 2013 IEEE.","knowledge transfer; local alignment; Sleep staging; unsupervised domain adaptation","Institute of Electrical and Electronics Engineers Inc."
"Khan H., Wahab F., Hussain S., Khan S., Rashid M.","Multi-object optimization of Navy-blue anodic oxidation via response surface models assisted with statistical and machine learning techniques",2022,"Chemosphere",1,"10.1016/j.chemosphere.2021.132818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119930917&doi=10.1016%2fj.chemosphere.2021.132818&partnerID=40&md5=ee84cc5179b7cea6e0849667e3f9bfec","This study aims to model, analyze, and compare the electrochemical removal of Navy-blue dye (NB, %) and subsequent energy consumption (EC, Wh) using the integrated response surface modelling and optimization approaches. The Box-Behnken experimental design was exercised using current density, electrolyte concentration, pH and oxidation time as inputs, while NB removal and EC were recorded as responses for the implementation and analysis of multiple linear regression, support vector regression and artificial neural network models. The dual-response optimization using genetic algorithm generated multi-Pareto solutions for maximized NB removal at minimum energy cost, which were further ranked by employing the desirability function approach. The optimal parametric solution having total desirability of 0.804 is found when pH, current density, Na2SO4 concentration and electrolysis time were 6.4, 11.89 mA cm−2, 0.055 M and 21.5 min, respectively. At these conditions, NB degradation and EC were 83.23% and 3.64 Wh, respectively. Sensitivity analyses revealed the influential patterns of variables on simultaneous optimization of NB removal and EC to be current density followed by treatment time and finally supporting electrolyte concentration. Statistical metrics of modeling and validation confirmed the accuracy of artificial neural network model followed by support vector regression and multiple linear regression anlaysis. The results revealed that statistical and computational modeling is an effective approach for the optimization of process variables of an electrochemical degradation process. © 2021 Elsevier Ltd","ANN; Electrochemical degradation; MLR; Navy blue; Nb/BDD; SVR","Elsevier Ltd"
"Hou H., Wang Q., Xiao Z., Xue M., Wu Y., Deng X., Xie C.","Data-driven economic dispatch for islanded micro-grid considering uncertainty and demand response",2022,"International Journal of Electrical Power and Energy Systems",,"10.1016/j.ijepes.2021.107623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119098975&doi=10.1016%2fj.ijepes.2021.107623&partnerID=40&md5=0f1b2cd616e15b28f4a46eb55b5ea96b","The variability and intermittency of renewable energy and power load bring great pressure to the dispatch of Micro-Grid, especially intra-day dispatch. In order to reduce the intra-day dispatch pressure, this paper proposes a data-driven two-stage day-ahead dispatch model for islanded Micro-Grid. The first stage dispatch model considers multiple demand responses, and applies phase space reconstruction and machine learning to predict renewable energy output and power load. Multi-objective particle swarm optimization algorithm is used to solve the first stage dispatch model. For the obtained Pareto Front, weight multiple objectives by entropy weight method to get the optimal solution. Since the deviation between the predicted value and the actual value can lead to renewable energy curtailment or load loss, the role of the second stage is to predict the renewable energy curtailment and load loss after the first stage dispatch. Firstly, extreme gradient boosting is used to predict when renewable energy curtailment and load loss occur. Secondly, extreme learning machine is used to predict the amount of renewable energy curtailment and load loss at the corresponding time points. Finally, linear programming and mixed integer linear programming are used to solve the second stage dispatch model. By comparative cases analysis, simulation results show that the enhancement of demand response to system efficiency is at the cost of increasing dispatch cost and reducing reliability. In contrast, the proposed two-stage dispatch method using regulation reserve capacity not only reduces dispatch cost, but also improves system efficiency and reliability. © 2021 Elsevier Ltd","Data-driven; Demand response; Multi-objective economic dispatch; Uncertainty of source and load","Elsevier Ltd"
"Paul A., Wu Z., Liu K., Gong S.","Robust multi-objective visual bayesian personalized ranking for multimedia recommendation",2022,"Applied Intelligence",,"10.1007/s10489-021-02355-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109349724&doi=10.1007%2fs10489-021-02355-w&partnerID=40&md5=9fa0e6665a7262683489bbd915900998","Machine learning classifiers are susceptible to adversarial perturbations, and their existence raises security concerns with a focus on recommendation systems. While there is a substantial effort to investigate attacks and defensive techniques in recommendation systems, Basic Iterative perturbation strategies (BIM) have been under-researched in multimedia recommendation. In this work, we adapt the iterative approach for multimedia recommendation. We proposed a novel Dynamic Collaborative Filtering with Aesthetic (DCFA) approach which leverages aesthetic features of clothing images into a multi-objective pairwise ranking to capture consumer aesthetic taste at a specific time through adversarial training (ADCFA). The DCFA method extends visual recommendation to make three key contributions: (1) incorporate aesthetic features into multimedia recommender system to model consumers’ preferences in the aesthetic aspect. (2) Design a multi-objective personalized ranking for the visual recommendation. (3) Use the aesthetic features to optimize the learning strategy to capture the temporal dynamics of image aesthetic preferences. To reduce the impact of perturbation, we train a DCFA objective function using minimax adversarial training. Extensive experiments on three datasets demonstrate the effectiveness of our method. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Adversarial perturbation; Adversarial training; Aesthetic features; Multimedia recommendation; Temporal dynamics","Springer"
"Meng J., Cai L., Stroe D.-I., Huang X., Peng J., Liu T., Teodorescu R.","An Automatic Weak Learner Formulation for Lithium-Ion Battery State of Health Estimation",2022,"IEEE Transactions on Industrial Electronics",7,"10.1109/TIE.2021.3065594","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103161112&doi=10.1109%2fTIE.2021.3065594&partnerID=40&md5=29e892c3e39495b126e37fb2c5476ff8","Current pulses are convenient to be actively implemented by a battery management system. However, the short-term features (STF) from current pulses originate from various sensors with uneven qualities, which hinder one powerful and strong learner with STF for the battery state of health (SOH) estimation. This article, thus, proposes an optimized weak learner formulation procedure for lithium-ion battery SOH estimation, which further enables the automatic initialization and integration of the weak learners with STF into an efficient SOH estimation framework. A Pareto front-based selection strategy is designed to select the representative solutions from the nondominated solutions fed by a knee point driven evolutionary algorithm, which guarantees both the diversity and accuracy of the weak learners. Afterward, the weak learners, whose coefficients are obtained by self-adaptive differential evolution, are integrated by a weight-based structure. The proposed method utilizes the weak learners with STF to boost the overall performance of the SOH estimation. The validation of the proposed method is proved by LiFePO4/C batteries under accelerated cycling ageing test including one mission profile providing primary frequency regulation service to the grid and one constant current profile. © 1982-2012 IEEE.","Automatic weak learner formulation; ensemble learning; lithium-ion (Li-ion) battery; state of health (SOH) estimation","Institute of Electrical and Electronics Engineers Inc."
"Zhu Y., Zhao D.","Online Minimax Q Network Learning for Two-Player Zero-Sum Markov Games",2022,"IEEE Transactions on Neural Networks and Learning Systems",3,"10.1109/TNNLS.2020.3041469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097948429&doi=10.1109%2fTNNLS.2020.3041469&partnerID=40&md5=e655b0b645162f2dc93b143b649c3e5d","The Nash equilibrium is an important concept in game theory. It describes the least exploitability of one player from any opponents. We combine game theory, dynamic programming, and recent deep reinforcement learning (DRL) techniques to online learn the Nash equilibrium policy for two-player zero-sum Markov games (TZMGs). The problem is first formulated as a Bellman minimax equation, and generalized policy iteration (GPI) provides a double-loop iterative way to find the equilibrium. Then, neural networks are introduced to approximate Q functions for large-scale problems. An online minimax Q network learning algorithm is proposed to train the network with observations. Experience replay, dueling network, and double Q-learning are applied to improve the learning process. The contributions are twofold: 1) DRL techniques are combined with GPI to find the TZMG Nash equilibrium for the first time and 2) the convergence of the online learning algorithm with a lookup table and experience replay is proven, whose proof is not only useful for TZMGs but also instructive for single-agent Markov decision problems. Experiments on different examples validate the effectiveness of the proposed algorithm on TZMG problems. © 2012 IEEE.","Deep reinforcement learning (DRL); generalized policy iteration (GPI); Markov game (MG); Nash equilibrium; Q network; zero sum","Institute of Electrical and Electronics Engineers Inc."
"Liu D., Zhang J., Cui J., Ng S.-X., Maunder R.G., Hanzo L.","Deep-Learning-Aided Packet Routing in Aeronautical Ad Hoc Networks Relying on Real Flight Data: From Single-Objective to Near-Pareto Multiobjective Optimization",2022,"IEEE Internet of Things Journal",,"10.1109/JIOT.2021.3105357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113192187&doi=10.1109%2fJIOT.2021.3105357&partnerID=40&md5=1d0ba3f1f3006011d076d89f1cdf4e56","Data packet routing in aeronautical ad hoc networks (AANETs) is challenging due to their high-dynamic topology. In this article, we invoke deep learning (DL) to assist routing in AANETs. We set out from the single objective of minimizing the end-to-end (E2E) delay. Specifically, a deep neural network (DNN) is conceived for mapping the local geographic information observed by the forwarding node into the information required for determining the optimal next hop. The DNN is trained by exploiting the regular mobility pattern of commercial passenger airplanes from historical flight data. After training, the DNN is stored by each airplane for assisting their routing decisions during flight relying solely on local geographic information. Furthermore, we extend the DL-aided routing algorithm to a multiobjective scenario, where we aim for simultaneously minimizing the delay, maximizing the path capacity, and maximizing the path lifetime. Our simulation results based on real flight data show that the proposed DL-aided routing outperforms existing position-based routing protocols in terms of its E2E delay, path capacity, as well as path lifetime, and it is capable of approaching the Pareto front that is obtained using global link information. © 2014 IEEE.","Aeronautical ad hoc network (AANET); deep learning (DL); multiobjective optimization (MOO); routing","Institute of Electrical and Electronics Engineers Inc."
"Yin Z., Wu J., Song J., Yang Y., Zhu X., Wu J.","Multi-objective optimization-based reactive nitrogen transport modeling for the water-environment-agriculture nexus in a basin-scale coastal aquifer",2022,"Water Research",,"10.1016/j.watres.2022.118111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123708673&doi=10.1016%2fj.watres.2022.118111&partnerID=40&md5=f6a8037861b0adc5b105fafce3d6ba43","The quantification of trade-offs between social-economic and environmental effects is of great importance, especially in the semi-arid coastal areas with highly developed agriculture. The study presents an integrated multi-objective simulation-optimization (S-O) framework to evaluate the basin-scale water-environment-agriculture (WEA) nexus. First, the variable-density groundwater model (SEAWAT) is coupled to the reactive transport model (RT3D) for the first attempt to simulate the environmental effects subject to seawater intrusion (SWI) and nitrate pollution (NP). Then, the surrogate assisted multi-objective optimization algorithm is utilized to investigate the trade-offs between the net agricultural benefits and extents of SWI and NP while considering the water supply, food security, and land availability simultaneously. The S-O modeling methodology is applied to the Dagu River Basin (DRB), a typical SWI region with intensive agricultural irrigation in China. It is shown that the three-objective space based on Pareto-optimal front can be achieved by optimizing planting area in the irrigation districts, indicating the optimal evolution of the WEA nexus system. The Pareto-optimal solutions generated by multi-objective S-O model are more realistic and pragmatic, avoiding the decision bias that may often lead to cognitive myopia caused by the low-dimensional objectives. Although the net agricultural benefits in Pareto-optimal solutions are declined to some extent, the environmental objectives (the extents of SWI and NP) are improved compared to those in the pre-optimized scheme. Therefore, the proposed multi-objective S-O framework can be applied to the WEA nexus in the river basin with intensive agriculture development, which is significant to implement the integrated management of water, food, and environment, especially for the semi-arid coastal aquifers. © 2022 Elsevier Ltd","Kernel extreme learning machine (KELM); Multi-objective trade-off; Reactive nitrogen transport; Seawater intrusion (SWI); Simulation-optimization (S-O); Water-environment-agriculture (WEA) nexus","Elsevier Ltd"
"Yin J., Wang R., Guo Y., Bai Y., Ju S., Liu W., Huang J.Z.","Wealth Flow Model: Online Portfolio Selection Based on Learning Wealth Flow Matrices",2022,"ACM Transactions on Knowledge Discovery from Data",,"10.1145/3464308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115021838&doi=10.1145%2f3464308&partnerID=40&md5=7fa8234d162f4f9c01a382cf996a32d1","This article proposes a deep learning solution to the online portfolio selection problem based on learning a latent structure directly from a price time series. It introduces a novel wealth flow matrix for representing a latent structure that has special regular conditions to encode the knowledge about the relative strengths of assets in portfolios. Therefore, a wealth flow model (WFM) is proposed to learn wealth flow matrices and maximize portfolio wealth simultaneously. Compared with existing approaches, our work has several distinctive benefits: (1) the learning of wealth flow matrices makes our model more generalizable than models that only predict wealth proportion vectors, and (2) the exploitation of wealth flow matrices and the exploration of wealth growth are integrated into our deep reinforcement algorithm for the WFM. These benefits, in combination, lead to a highly-effective approach for generating reasonable investment behavior, including short-term trend following, the following of a few losers, no self-investment, and sparse portfolios. Extensive experiments on five benchmark datasets from real-world stock markets confirm the theoretical advantage of the WFM, which achieves the Pareto improvements in terms of multiple performance indicators and the steady growth of wealth over the state-of-the-art algorithms. © 2021 Association for Computing Machinery.","deep reinforcement learning; Online portfolio selection; regret bound; wealth flow matrix","Association for Computing Machinery"
"Yu Y., Guo L., Gao H., Liu Y., Feng T.","Pareto-Optimal Adaptive Loss Residual Shrinkage Network for Imbalanced Fault Diagnostics of Machines",2022,"IEEE Transactions on Industrial Informatics",1,"10.1109/TII.2021.3094186","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110833341&doi=10.1109%2fTII.2021.3094186&partnerID=40&md5=4d6b5b75fe2cbdb40c3f0209e56095cf","In the industrial applications of mechanical fault diagnosis, machines work in normal condition at most time. In other words, most of the collected datasets are highly imbalanced. Although deep learning has been widely applied in intelligent diagnosis, it is unsuitable for such imbalanced situation. In addition, few studies attempted to determine the parameters in the diagnosis models. For solving such problems, Pareto-optimal adaptive loss residual shrinkage network (PALRSN) is proposed. First, a fixed length-based encoding method is implemented to represent the candidate architectures of PALRSN. Then, multiply accumulate operations and Gmean value representing the model complexity and identification performance, respectively, on imbalanced datasets are selected as the optimization targets to search for the optimal PALRSN architecture. In the training process, an adaptive loss function assigns different misclassification costs on all categories according to their number discrepancy to highlight the minority samples. The proposed method is validated by bearing data and milling cutter data with different imbalanced ratio. The experimental results demonstrate that such approach outperforms the state-of-The-Art methods in imbalanced classification. © 2005-2012 IEEE.","Adaptive loss function; imbalanced data; multiobjective genetic algorithm (GA); Pareto front; residual shrinkage network","IEEE Computer Society"
"Motlagh S.A.T., Naghizadehrokni M.","An extended multi-model regression approach for compressive strength prediction and optimization of a concrete mixture",2022,"Construction and Building Materials",,"10.1016/j.conbuildmat.2022.126828","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125132900&doi=10.1016%2fj.conbuildmat.2022.126828&partnerID=40&md5=7d7895bc8c6a0f4c77f2d5427bfe94f1","Due to the significant delay and cost associated with experimental tests, a model-based evaluation of concrete compressive strength is of high value, both for the purpose of strength prediction as well as the mixture optimization. In contrast to the prior recent studies employing a single regression model, in this paper, we present a combined multi-model framework where the regression methods based on artificial neural network, random forest regression and polynomial regression are jointly implemented for compressive strength prediction with a higher accuracy. The outcomes of the individual regression models are combined via a linear weighting strategy and optimized over the training data set as a quadratic convex optimization problem. It is worth mentioning that due to the convexity of the formulated problem, the globally optimum weighting strategy is obtained via standard numerical solvers. Afterwards, employing the obtained regression model, a multi-objective genetic algorithm-based method is proposed for mixture optimization under practical constraints, where a Pareto front of the cost-CS trade-off has been obtained employing the available data set. Numerical evaluations show that the proposed multi-model regression achieves a significantly higher prediction accuracy, i.e., approximately 18% reduction in the obtained prediction mean squared error, without weight optimization, and roughly 30% reduction in the obtained prediction mean squared error with an optimized combination following a convex quadratic optimization, compared to the best single model regression method employing a multi-layered artificial neural network. © 2022 Elsevier Ltd","Compressive strength prediction; Concrete; Convex optimization; Deep neural network; Genetic algorithm; Heuristic optimization; Machine learning; Multi-model regression; Predictive regression","Elsevier Ltd"
"Wang J., Zhou Y., Li Z.","Hour-ahead photovoltaic generation forecasting method based on machine learning and multi objective optimization algorithm",2022,"Applied Energy",,"10.1016/j.apenergy.2022.118725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124725878&doi=10.1016%2fj.apenergy.2022.118725&partnerID=40&md5=06240fd5e48a150f5002df879d3c51ed","As the penetration rate of solar energy in the grid continues to enhance, solar power photovoltaic generation forecasts have become an indispensable aspect of mechanism mobilization and maintenance of the stability of the power system. In this regard, many researchers have done a lot of study, and put forward some predictive models. However, many individual prediction systems only consider the prediction accuracy rate without further considering the prediction utility and stability. To fill this gap, a comprehensive system is designed in this paper, which is on the basis of automatic optimization of variational mode decomposition mechanism, and the weight of system is determined by multi objective intelligent optimization algorithm. In particular, it can be proved theoretically that the developed predictive system can achieve the pareto optimal solution. And the designed system is shown to be very effective in forecasting the 2021 photovoltaic power data obtained from Belgium. The empirical study reports that the combination of variational mode decomposition strategy based on genetic algorithm and multi objective grasshopper optimization algorithm is found to be the satisfactory strategy to optimize the predictive system compared with other common mechanism. And the results of several numerical studies show that the designed predictive system achieves the superior performance as compared to the control systems, and in multi-step forecasting, the designed system has better stability than the comparison systems. © 2022 Elsevier Ltd","Data preprocessing method; Machine learning; Multi objective optimization algorithm; Photovoltaic power forecast","Elsevier Ltd"
"Du J., Shi X., Mo S., Kang X., Wu J.","Deep learning based optimization under uncertainty for surfactant-enhanced DNAPL remediation in highly heterogeneous aquifers",2022,"Journal of Hydrology",,"10.1016/j.jhydrol.2022.127639","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125759892&doi=10.1016%2fj.jhydrol.2022.127639&partnerID=40&md5=82a88a8071fb461bb076ea3efa84e9d8","The optimization for surfactant-enhanced aquifer remediation (SEAR) of dense non-aqueous phase liquid (DNAPL)-contaminated aquifers is usually accompanied by uncertainties, which may arise from the characterization of complex aquifer heterogeneity and DNAPL source zone architecture (SZA) due to measurement sparsity. Optimization under uncertainty is computationally expensive as it involves an enormous number of model runs. The huge computational burden can be alleviated by utilizing a surrogate model for repeated model evaluations. However, most of the developed surrogates are often limited to low-dimensional optimization problems that only consider simplified aquifer heterogeneity. In this study, we developed a multi-objective simulation-optimization framework to optimize the SEAR schemes considering the characterization uncertainties from both highly heterogeneous aquifer permeability and complex SZA. A fast-to-run convolutional neural network (CNN)-based surrogate model was developed to approximate the high-dimensional and highly complex input-output mapping of the DNAPL multiphase flow simulation model. We first used the rejection sampling strategy to generate random realizations of permeability and SZA conditioning on their limited measurements and then formulated a multi-objective optimization under uncertainty problem based on these realizations. The developed 3-D CNN was trained and used as the surrogate for repeated model runs in optimization to identify the optimal SEAR schemes under uncertainty. A 3-D numerical experiment was used to test the performance of the CNN-based simulation-optimization framework. Comprehensive analysis on the obtained Pareto fronts demonstrates that the proposed framework can efficiently identify reliable Pareto-optimal solutions with a 99.8% speedup compared to the traditional optimization coupled with the forward model. Moreover, the optimization considering multiple realizations enables us to perform the risk assessment to locate the risk zone where the NAPL phase possibly exists after remediation, which provides useful information for decision-making. © 2022 Elsevier B.V.","Deep learning; DNAPL; Heterogeneous permeability; Optimization under uncertainty; Remediation strategy design; Risk assessment","Elsevier B.V."
"Reiners M., Klamroth K., Heldmann F., Stiglmayr M.","Efficient and sparse neural networks by pruning weights in a multiobjective learning approach",2022,"Computers and Operations Research",,"10.1016/j.cor.2021.105676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122957418&doi=10.1016%2fj.cor.2021.105676&partnerID=40&md5=610a47251a96fe77d45088eec9f04064","Overparameterization and overfitting are common concerns when designing and training deep neural networks, that are often counteracted by pruning and regularization strategies. However, these strategies remain secondary to most learning approaches and suffer from time and computational intensive procedures. We suggest a multiobjective perspective on the training of neural networks by treating its prediction accuracy and the network complexity as two individual objective functions in a biobjective optimization problem. As a showcase example, we use the cross entropy as a measure of the prediction accuracy while adopting an l1-penalty function to assess the total cost (or complexity) of the network parameters. The latter is combined with an intra-training pruning approach that reinforces complexity reduction and requires only marginal extra computational cost. From the perspective of multiobjective optimization, this is a truly large-scale optimization problem. We compare two different optimization paradigms: On the one hand, we adopt a scalarization-based approach that transforms the biobjective problem into a series of weighted-sum scalarizations. On the other hand we implement stochastic multi-gradient descent algorithms that generate a single Pareto optimal solution without requiring or using preference information. In the first case, favorable knee solutions are identified by repeated training runs with adaptively selected scalarization parameters. Numerical results on exemplary convolutional neural networks confirm that large reductions in the complexity of neural networks with negligible loss of accuracy are possible. © 2022 Elsevier Ltd","Automated machine learning; l1-regularization; Multiobjective learning; Stochastic multi-gradient descent; Unstructured pruning","Elsevier Ltd"
"Rastogi (nee Khemchandani) R., Jain S.","Multi-label learning via minimax probability machine",2022,"International Journal of Approximate Reasoning",,"10.1016/j.ijar.2022.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125962714&doi=10.1016%2fj.ijar.2022.02.002&partnerID=40&md5=904559ce2cda418e45bd882fb14b1e43","In this paper, we propose Minimax Probability Machine for Multi-label data classification and is termed as Multi-Label Minimax Probability Machine (MLMPM). Based on data mean and covariance information, MLMPM builds a classifier that minimizes an upper bound on the mis-classification probability of unseen future data. For capturing label correlation we have considered asymmetric co-occurrency matrix into the model. The proposed model has also been extended to non-linear settings using the Mercer Kernel trick. To accelerate the training procedure, iterative weighted least squares is used to train the underlying optimization model efficiently. Extensive experimental comparisons of our proposed method with related multi-label algorithms on synthetic as well as real world multi-label datasets, along with Amazon rainforest satellite images dataset, prove its efficacy. © 2022 Elsevier Inc.","Label correlation; Minimax probability machine; Multi-label classification; Second order cone programming problem; Weighted least squares","Elsevier Inc."
"Cai Z., Yan X., Ma K., Wu Y., Huang Y., Cheng J., Su T., Yu F.","TensorOpt: Exploring the Tradeoffs in Distributed DNN Training with Auto-Parallelism",2022,"IEEE Transactions on Parallel and Distributed Systems",,"10.1109/TPDS.2021.3132413","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121369598&doi=10.1109%2fTPDS.2021.3132413&partnerID=40&md5=eea3b7307ca76f844c163cbaf28c5dd3","Effective parallelization strategies are crucial for the performance of distributed deep neural network (DNN) training. Recently, several methods have been proposed to search parallelization strategies but they all optimize a single objective (e.g., execution time, memory consumption) and produce only one strategy. We propose Frontier Tracking (FT), an efficient algorithm that finds a set of Pareto-optimal parallelization strategies to explore the best trade-off among different objectives. FT can minimize the memory consumption when the number of devices is limited and fully utilize additional resources to reduce the execution time. Based on FT, we develop a user-friendly system, called TensorOpt, which allows users to run their distributed DNN training jobs without caring the details about searching and coding parallelization strategies. Experimental results show that TensorOpt is more flexible in adapting to resource availability compared with existing frameworks. © 1990-2012 IEEE.","Deep learning; distributed systems; large-scale model training","IEEE Computer Society"
