@inproceedings{10.1145/3419604.3419799,
author = {Haddar, Imane and Raouyane, Brahim and Bellafkih, Mostafa},
title = {Neural Network for Learning and Analyzing Preferences for Multi-Criteria Services},
year = {2020},
isbn = {9781450377331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419604.3419799},
doi = {10.1145/3419604.3419799},
abstract = {In the latest years, service selection is becoming more and more important due to the significant effect of internet based services in the telecom industry. When it comes to selecting the best service, different candidate services with similar settings are proposed by different service providers. The selection should take into consideration the respect of the constraints of consumers in terms of Service Level Agreement contracts, what makes the modelling of the preferences of decision-makers for choice problems the main focus of this work. In order to model these preferences, we propose contextual preference functions based on machine learning techniques from neural networks. It will therefore be possible to further explain and decode preferences in order to facilitate negotiation and thus decision-making, thereby improving the quality of service providers while being on customer preferences.},
booktitle = {Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications},
articleno = {13},
numpages = {6},
keywords = {Decision aid, Preferences, Neural network, Service selection},
location = {Rabat, Morocco},
series = {SITA'20}
}

@inbook{10.1145/3461702.3462592,
author = {Shah, Kulin and Gupta, Pooja and Deshpande, Amit and Bhattacharyya, Chiranjib},
title = {Rawlsian Fair Adaptation of Deep Learning Classifiers},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461702.3462592},
abstract = {Group-fairness in classification aims for equality of a predictive utility across different sensitive sub-populations, e.g., race or gender. Equality or near-equality constraints in group-fairness often worsen not only the aggregate utility but also the utility for the least advantaged sub-population. In this paper, we apply the principles of Pareto-efficiency and least-difference to the utility being accuracy, as an illustrative example, and arrive at the Rawls classifier that minimizes the error rate on the worst-off sensitive sub-population. Our mathematical characterization shows that the Rawls classifier uniformly applies a threshold to an ideal score of features, in the spirit of fair equality of opportunity. In practice, such a score or a feature representation is often computed by a black-box model that has been useful but unfair. Our second contribution is practical Rawlsian fair adaptation of any given black-box deep learning model, without changing the score or feature representation it computes. Given any score function or feature representation and only its second-order statistics on the sensitive sub-populations, we seek a threshold classifier on the given score or a linear threshold classifier on the given feature representation that achieves the Rawls error rate restricted to this hypothesis class. Our technical contribution is to formulate the above problems using ambiguous chance constraints, and to provide efficient algorithms for Rawlsian fair adaptation, along with provable upper bounds on the Rawls error rate. Our empirical results show significant improvement over state-of-the-art group-fair algorithms, even without retraining for fairness.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {936–945},
numpages = {10}
}

@inproceedings{10.1145/3055635.3056619,
author = {Choudhary, Priyankar and Kant, Vibhor and Dwivedi, Pragya},
title = {A Particle Swarm Optimization Approach to Multi Criteria Recommender System Utilizing Effective Similarity Measures},
year = {2017},
isbn = {9781450348171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3055635.3056619},
doi = {10.1145/3055635.3056619},
abstract = {Recommender system (RS), a web personalization tool, attempts to generate suitable recommendations to users based on their preferences. Generally, recommender system works on overall ratings but these ratings do not reflect the actual user preferences. Therefore, incorporation of multiple criteria ratings into RS can capture the user preferences accurately and produce effective recommendations to users. Multi criteria recommender systems (MCRS) generate recommendations to users based on the aggregation of similarities computed on multiple criteria using collaborative filtering. However, capturing optimal weights of various users on different criteria in the process of similarity aggregation is a major concern. Further selection of appropriate similarity measure is another challenge for employing collaborative filtering. Our work in this paper is an attempt towards developing multi criteria recommender systems by utilizing various similarity measures and particle swarm optimization to learn optimal weights. Experimental results reveal that our proposed approaches outperform other traditional approaches.},
booktitle = {Proceedings of the 9th International Conference on Machine Learning and Computing},
pages = {81–85},
numpages = {5},
keywords = {collaborative filtering, particle swarm optimization, similarity measures, Multi criteria recommender system},
location = {Singapore, Singapore},
series = {ICMLC 2017}
}

@article{10.1016/j.neucom.2021.04.111,
author = {Liu, Jia and Jin, Yaochu},
title = {Multi-Objective Search of Robust Neural Architectures against Multiple Types of Adversarial Attacks},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {453},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.04.111},
doi = {10.1016/j.neucom.2021.04.111},
journal = {Neurocomput.},
month = {sep},
pages = {73–84},
numpages = {12},
keywords = {Adversarial attacks, Robustness, Multi-objective evolutionary algorithm, Neural architecture search}
}

@inproceedings{10.1145/3380688.3380717,
author = {Dinh, Thi Thu Huong and Vu, Van Truong and Bui, Lam Thu},
title = {An Ensemble Multi-Objective Particle Swarm Optimization Approach for Exchange Rates Forecasting Problem},
year = {2020},
isbn = {9781450376310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380688.3380717},
doi = {10.1145/3380688.3380717},
abstract = {In this paper, the authors propose an ensemble multi-objective particle swarm optimisation approach (named EMPSO) for forecasting the currency exchange rate chain. The proposed algorithm consists of two main phases. The first phase uses a multi-objective particle swarm optimisation algorithm to find a set of the best optimal particles (named leaders). The second phase then uses these leaders to jointly calculate the final results by using the soft voting ensemble method. The two objective functions used here are predictive error and particle diversity. The empirical data used in this study are six different sets of currency exchange rates. Through comparison results with other evolutionary algorithms and other multi-objective PSO algorithms, the proposed algorithm shows that it can achieve better as well as more stability results on experimental data sets.},
booktitle = {Proceedings of the 4th International Conference on Machine Learning and Soft Computing},
pages = {66–70},
numpages = {5},
keywords = {multi-objective PSO, ensemble learning, Time series forecasting, PSO},
location = {Haiphong City, Viet Nam},
series = {ICMLSC 2020}
}

@article{10.1016/j.compbiomed.2021.104916,
author = {Chen, Xi and Zhou, Meijuan and Wang, Zhilong and Lu, Si and Chang, Shaojie and Zhou, Zhiguo},
title = {Immunotherapy Treatment Outcome Prediction in Metastatic Melanoma through an Automated Multi-Objective Delta-Radiomics Model},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {138},
number = {C},
issn = {0010-4825},
url = {https://doi.org/10.1016/j.compbiomed.2021.104916},
doi = {10.1016/j.compbiomed.2021.104916},
journal = {Comput. Biol. Med.},
month = {nov},
numpages = {16},
keywords = {Ensemble learning, Genetic algorithms, Delta radiomics, Multi-objective learning, Outcome prediction}
}

@article{10.1145/3447623,
author = {Chen, Jianguo and Li, Kenli and Li, Keqin and Yu, Philip S. and Zeng, Zeng},
title = {Dynamic Bicycle Dispatching of Dockless Public Bicycle-Sharing Systems Using Multi-Objective Reinforcement Learning},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2378-962X},
url = {https://doi.org/10.1145/3447623},
doi = {10.1145/3447623},
abstract = {As a new generation of Public Bicycle-sharing Systems (PBS), the Dockless PBS (DL-PBS) is an important application of cyber-physical systems and intelligent transportation. How to use artificial intelligence to provide efficient bicycle dispatching solutions based on dynamic bicycle rental demand is an essential issue for DL-PBS. In this article, we propose MORL-BD, a dynamic bicycle dispatching algorithm based on multi-objective reinforcement learning to provide the optimal bicycle dispatching solution for DL-PBS. We model the DL-PBS system from the perspective of cyber-physical systems and use deep learning to predict the layout of bicycle parking spots and the dynamic demand of bicycle dispatching. We define the multi-route bicycle dispatching problem as a multi-objective optimization problem by considering the optimization objectives of dispatching costs, dispatch truck's initial load, workload balance among the trucks, and the dynamic balance of bicycle supply and demand. On this basis, the collaborative multi-route bicycle dispatching problem among multiple dispatch trucks is modeled as a multi-agent and multi-objective reinforcement learning model. All dispatch paths between parking spots are defined as state spaces, and the reciprocal of dispatching costs is defined as a reward. Each dispatch truck is equipped with an agent to learn the optimal dispatch path in the dynamic DL-PBS network. We create an elite list to store the Pareto optimal solutions of bicycle dispatch paths found in each action, and finally get the Pareto frontier. Experimental results on the actual DL-PBS show that compared with existing methods, MORL-BD can find a higher quality Pareto frontier with less execution time.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = {sep},
articleno = {34},
numpages = {24},
keywords = {Pareto optimality, intelligent transportation, bicycle dispatching, multi-objective reinforcement learning, Bicycle-sharing systems}
}

@inproceedings{10.1109/SEAMS.2019.00015,
author = {Jamshidi, Pooyan and C\'{a}mara, Javier and Schmerl, Bradley and K\"{a}stner, Christian and Garlan, David},
title = {Machine Learning Meets Quantitative Planning: Enabling Self-Adaptation in Autonomous Robots},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEAMS.2019.00015},
doi = {10.1109/SEAMS.2019.00015},
abstract = {Modern cyber-physical systems (e.g., robotics systems) are typically composed of physical and software components, the characteristics of which are likely to change over time. Assumptions about parts of the system made at design time may not hold at run time, especially when a system is deployed for long periods (e.g., over decades). Self-adaptation is designed to find reconfigurations of systems to handle such run-time inconsistencies. Planners can be used to find and enact optimal reconfigurations in such an evolving context. However, for systems that are highly configurable, such planning becomes intractable due to the size of the adaptation space. To overcome this challenge, in this paper we explore an approach that (a) uses machine learning to find Pareto-optimal configurations without needing to explore every configuration and (b) restricts the search space to such configurations to make planning tractable. We explore this in the context of robot missions that need to consider task timeliness and energy consumption. An independent evaluation shows that our approach results in high-quality adaptation plans in uncertain and adversarial environments.},
booktitle = {Proceedings of the 14th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {39–50},
numpages = {12},
keywords = {robotics systems, machine learning, self-adaptive systems, quantitative planning, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {SEAMS '19}
}

@inproceedings{10.1145/3229762.3229767,
author = {Lokhmotov, Anton and Chunosov, Nikolay and Vella, Flavio and Fursin, Grigori},
title = {Multi-Objective Autotuning of MobileNets across the Full Software/Hardware Stack},
year = {2018},
isbn = {9781450359238},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229762.3229767},
doi = {10.1145/3229762.3229767},
abstract = {We present a customizable Collective Knowledge workflow to study the execution time vs. accuracy trade-offs for the MobileNets CNN family. We use this workflow to evaluate MobileNets on Arm Cortex CPUs using TensorFlow and Arm Mali GPUs using several versions of the Arm Compute Library. Our optimizations for the Arm Bifrost GPU architecture reduce the execution time by 2--3 times, while lying on a Pareto-optimal frontier. We also highlight the challenge of maintaining the accuracy when deploying CNN models across diverse platforms. We make all the workflow components (models, programs, scripts, etc.) publicly available to encourage further exploration by the community.},
booktitle = {Proceedings of the 1st on Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning},
articleno = {6},
keywords = {live scoreboard, system co-design, crowdtuning, accuracy, customizable workflows, reproducible experimentation, Collective Knowledge, autotuning, MobileNets, performance},
location = {Williamsburg, VA, USA},
series = {ReQuEST '18}
}

@article{10.1016/j.eswa.2020.113237,
author = {Niu, Tong and Wang, Jianzhou and Lu, Haiyan and Yang, Wendong and Du, Pei},
title = {Developing a Deep Learning Framework with Two-Stage Feature Selection for Multivariate Financial Time Series Forecasting},
year = {2020},
issue_date = {Jun 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {148},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.113237},
doi = {10.1016/j.eswa.2020.113237},
journal = {Expert Syst. Appl.},
month = {jun},
numpages = {17},
keywords = {Multi-objective optimization, Multivariate financial time series, Deep learning, Forecasting, Feature selection}
}

@article{10.1145/3358185,
author = {Park, Sunghyun and Wu, Youfeng and Lee, Janghaeng and Aupov, Amir and Mahlke, Scott},
title = {Multi-Objective Exploration for Practical Optimization Decisions in Binary Translation},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3358185},
doi = {10.1145/3358185},
abstract = {In the design of mobile systems, hardware/software (HW/SW) co-design has important advantages by creating specialized hardware for the performance or power optimizations. Dynamic binary translation (DBT) is a key component in co-design. During the translation, a dynamic optimizer in the DBT system applies various software optimizations to improve the quality of the translated code. With dynamic optimization, optimization time is an exposed run-time overhead and useful analyses are often restricted due to their high costs. Thus, a dynamic optimizer needs to make smart decisions with limited analysis information, which complicates the design of optimization decision models and often causes failures in human-made heuristics. In mobile systems, this problem is even more challenging because of strict constraints on computing capabilities and memory size.To overcome the challenge, we investigate an opportunity to build practical optimization decision models for DBT by using machine learning techniques. As the first step, loop unrolling is chosen as the representative optimization. We base our approach on the industrial strength DBT infrastructure and conduct evaluation with 17,116 unrollable loops collected from 200 benchmarks and real-life programs across various domains. By utilizing all available features that are potentially important for loop unrolling decision, we identify the best classification algorithm for our infrastructure with consideration for both prediction accuracy and cost. The greedy feature selection algorithm is then applied to the classification algorithm to distinguish its significant features and cut down the feature space. By maintaining significant features only, the best affordable classifier, which satisfies the budgets allocated to the decision process, shows 74.5% of prediction accuracy for the optimal unroll factor and realizes an average 20.9% reduction in dynamic instruction count during the steady-state translated code execution. For comparison, the best baseline heuristic achieves 46.0% prediction accuracy with an average 13.6% instruction count reduction. Given that the infrastructure is already highly optimized and the ideal upper bound for instruction reduction is observed at 23.8%, we believe this result is noteworthy.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {oct},
articleno = {57},
numpages = {19},
keywords = {Loop unrolling<!--?clr?-->}
}

@inproceedings{10.1145/2576768.2598271,
author = {Azzouz, Nessrine and Bechikh, Slim and Ben Said, Lamjed},
title = {Steady State IBEA Assisted by MLP Neural Networks for Expensive Multi-Objective Optimization Problems},
year = {2014},
isbn = {9781450326629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2576768.2598271},
doi = {10.1145/2576768.2598271},
abstract = {Several engineering problems involve simultaneously several objective functions where at least one of them is expensive to evaluate. This fact has yielded to a new class of Multi-Objective Problems (MOPs) called expensive MOPs. Several attempts have been conducted in the literature with the goal to minimize the number of expensive evaluations by using surrogate models stemming from the machine learning field. Usually, researchers substitute the expensive objective function evaluation by an estimation drawn from the used surrogate. In this paper, we propose a new way to tackle expensive MOPs. The main idea is to use Neural Networks (NNs) within the Indicator-Based Evolutionary Algorithm (IBEA) in order to estimate the contribution of each generated offspring in terms of hypervolume. After that, only fit individuals with respect to the estimations are exactly evaluated. Our proposed algorithm called NN-SS-IBEA (Neural Networks assisted Steady State IBEA) have been demonstrated to provide good performance with a low number of function evaluations when compared against the original IBEA and MOEA/D-RBF on a set of benchmark problems in addition to the airfoil design problem.},
booktitle = {Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {581–588},
numpages = {8},
keywords = {multi-objective optimization, neural networks, surrogate model, fitness approximation},
location = {Vancouver, BC, Canada},
series = {GECCO '14}
}

@inproceedings{10.1145/3184066.3184075,
author = {Huynh, Tri Minh and Huynh, Hung Huu and Tran, Vu The and Huynh, Hiep Xuan},
title = {Collaborative Filtering Recommender System Base on the Interaction Multi-Criteria Decision with Ordered Weighted Averaging Operator},
year = {2018},
isbn = {9781450363365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3184066.3184075},
doi = {10.1145/3184066.3184075},
abstract = {In the recommender system, the most important is the decision-making solutionto consulte for user. Depending on the type and size of data stored, decision-making will always be improved to produce the best possible result.. The main task in implementing the model is to use methods to find the most valuable product or service for the user. In this paper, we propose a new approach to building a multi-user based collaborative filtering model using the interaction multi-criteria decision with ordered weighted averaging operator. This model demonstrates the synergy and interplay between user criteria for decision making. The model was evaluated through experimentation with the multirecsys tool on three datasets: MovieLense 100K, MSWeb and Jester5k. The experiment illustrated the model comparison with some other interactive multi-criteria counseling methods that have been researchedon both sparse datasets and thick datasets. In addition, the model is compared and evaluated with item-base collaborative filtering model using the interaction multi-criteria decision with ordered weighted averaging operator on two types of datasets. Consultancy results of the proposed model are quite effective compared to some traditional consulting models and some models with other operator. This counseling model can be applied well in a variety of contexts, especially in the case of sparse data, this model will give result in improved counseling. In addition, with the above method, the user-base model is always more efficient than item-base on all datasets.},
booktitle = {Proceedings of the 2nd International Conference on Machine Learning and Soft Computing},
pages = {45–49},
numpages = {5},
keywords = {the interaction multi-criteria decision, item-base, user-base, ordered weighted averaging operator, collaborative filtering recommender system},
location = {Phu Quoc Island, Viet Nam},
series = {ICMLSC '18}
}

@article{10.1145/3474059,
author = {Mittal, Sukrit and Saxena, Dhish Kumar and Deb, Kalyanmoy and Goodman, Erik D.},
title = {A Learning-Based <i>Innovized</i> Progress Operator for Faster Convergence in Evolutionary Multi-Objective Optimization},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2688-299X},
url = {https://doi.org/10.1145/3474059},
doi = {10.1145/3474059},
abstract = {Learning effective problem information from already explored search space in an optimization run, and utilizing it to improve the convergence of subsequent solutions, have represented important directions in Evolutionary Multi-objective Optimization (EMO) research. In this article, a machine learning (ML)-assisted approach is proposed that: (a) maps the solutions from earlier generations of an EMO run to the current non-dominated solutions in the decision space; (b) learns the salient patterns in the mapping using an ML method, here an artificial neural network (ANN); and (c) uses the learned ML model to advance some of the subsequent offspring solutions in an adaptive manner. Such a multi-pronged approach, quite different from the popular surrogate-modeling methods, leads to what is here referred to as the Innovized Progress (IP) operator. On several test and engineering problems involving two and three objectives, with and without constraints, it is shown that an EMO algorithm assisted by the IP operator offers faster convergence behavior, compared to its base version independent of the IP operator. The results are encouraging, pave a new path for the performance improvement of EMO algorithms, and set the motivation for further exploration on more challenging problems.},
journal = {ACM Trans. Evol. Learn. Optim.},
month = {nov},
articleno = {1},
numpages = {29},
keywords = {artificial neural networks, Multiobjective optimization, online innovization, learning-based optimization, innovization}
}

@inproceedings{10.1145/3383972.3384041,
author = {Xiao, Long and Li, Changhe and Wang, Junchen and Mavrovouniotis, Michalis and Yang, Shengxiang and Dan, Xiaorong},
title = {Modeling and Evolutionary Optimization for Multi-Objective Vehicle Routing Problem with Real-Time Traffic Conditions},
year = {2020},
isbn = {9781450376426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383972.3384041},
doi = {10.1145/3383972.3384041},
abstract = {The study of the vehicle routing problem (VRP) is of outstanding significance for reducing logistics costs. Currently, there is little VRP considering real-time traffic conditions. In this paper, we propose a more realistic and challenging multi-objective VRP containing real-time traffic conditions. Besides, we also offer an adaptive local search algorithm combined with a dynamic constrained multi-objective evolutionary framework. In the algorithm, we design eight local search operators and select them adaptively to optimize the initial solutions. Experimental results show that our algorithm can obtain an excellent solution that satisfies the constraints of the vehicle routing problem with real-time traffic conditions.},
booktitle = {Proceedings of the 2020 12th International Conference on Machine Learning and Computing},
pages = {518–523},
numpages = {6},
keywords = {Local Search, Multi-objective Optimization, Constrained Optimization, Vehicle Routing Problem},
location = {Shenzhen, China},
series = {ICMLC 2020}
}

@article{10.1016/j.eswa.2016.11.017,
author = {Gorza\l{}czany, Marian B. and Rudzi\'{n}ski, Filip},
title = {Interpretable and Accurate Medical Data Classification - a Multi-Objective Genetic-Fuzzy Optimization Approach},
year = {2017},
issue_date = {April 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {71},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.11.017},
doi = {10.1016/j.eswa.2016.11.017},
abstract = {Novel fuzzy rule-based system (FRBS) for medical data classification tasks is proposed.FRBSs are designed using multi-objective evolutionary optimization algorithms.Set of FRBSs with various levels of accuracy-interpretability trade-off is generated.Benchmark medical data sets are used to evaluate the effectiveness of the system.Highly interpretable and accurate medical decision support is provided by our approach. In medical decision support systems, both the accuracy (i.e., the ability to adequately represent the decision making processes) as well as the transparency and interpretability (i.e., the ability to provide a domain user with compact and understandable explanation and justification of the proposed decisions) play essential roles. This paper presents an approach for automatic design of fuzzy rule-based classification systems (FRBCSs) from medical data using multi-objective evolutionary optimization algorithms (MOEOAs). Our approach generates, in a single run, a collection of solutions (medical FRBCSs) characterized by various levels of accuracy-interpretability trade-off. We propose a new complexity-related interpretability measure and we address the semantics-related interpretability issue by means of efficient implementation of the so-called strong fuzzy partitions of attribute domains. We also introduce a special-coding-free representation of the rule base and original genetic operators for its processing as well as we implement our ideas in the context of well-known and one of the presently most advanced MOEOAs, i.e., Non-dominated Sorting Genetic Algorithm II (NSGA-II). An important part of the paper is devoted to a broad comparative analysis of our approach and as many as 26 alternative techniques arranged in 32 experimental set-ups and applied to three well-known benchmark medical data sets (Breast Cancer Wisconsin (Original), Pima Indians Diabetes, and Heart Disease (Cleveland)) available from the UCI repository of machine learning databases (http://archive.ics.uci.edu/ml). A number of useful in medical applications performance measures including accuracy, sensitivity, specificity, and several interpretability measures are employed. The results of such a broad comparative analysis demonstrate that our approach significantly outperforms the alternative methods in terms of the interpretability of the obtained FRBCSs while remaining either competitive or superior in terms of their accuracy. It is worth stressing that the overwhelming majority of the existing medical classification methods concentrate almost exclusively on the accuracy issues.},
journal = {Expert Syst. Appl.},
month = {apr},
pages = {26–39},
numpages = {14},
keywords = {Accuracy and interpretability of medical classification systems, Fuzzy rule-based systems, Genetic computations, Multi-objective evolutionary optimization, Medical decision support}
}

@article{10.1145/3393668,
author = {Eldafrawy, Mohamed and Boutros, Andrew and Yazdanshenas, Sadegh and Betz, Vaughn},
title = {FPGA Logic Block Architectures for Efficient Deep Learning Inference},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1936-7406},
url = {https://doi.org/10.1145/3393668},
doi = {10.1145/3393668},
abstract = {Reducing the precision of deep neural network (DNN) inference accelerators can yield large efficiency gains with little or no accuracy degradation compared to half or single precision floating-point by enabling more multiplication operations per unit area. A wide range of precisions fall on the pareto-optimal curve of hardware efficiency vs. accuracy with no single precision dominating, making the variable precision capabilities of FPGAs very valuable. We propose three types of logic block architectural enhancements and fully evaluate a total of six architectures that improve the area efficiency of multiplications and additions implemented in the soft fabric. Increasing the LUT fracturability and adding two adders to the ALM (4-bit Adder Double Chain architecture) leads to a 1.5\texttimes{} area reduction for arithmetic heavy machine learning (ML) kernels, while increasing their speed. In addition, this architecture also reduces the logic area of general applications by 6%, while increasing the critical path delay by only 1%. However, our highest impact option, which adds a 9-bit shadow multiplier to the logic clusters, reduces the area and critical path delay of ML kernels by 2.4\texttimes{} and 1.2\texttimes{}, respectively. These large gains come at a cost of 15% logic area increase for general applications.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = {jun},
articleno = {12},
numpages = {34},
keywords = {CAD tools, Deep neural networks, FPGA}
}

@article{10.1016/j.ipm.2017.02.008,
author = {Onan, Aytu and Korukolu, Serdar and Bulut, Hasan},
title = {A Hybrid Ensemble Pruning Approach Based on Consensus Clustering and Multi-Objective Evolutionary Algorithm for Sentiment Classification},
year = {2017},
issue_date = {July 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {53},
number = {4},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2017.02.008},
doi = {10.1016/j.ipm.2017.02.008},
abstract = {Sentiment analysis is a critical task of extracting subjective information from online text documents. Ensemble learning can be employed to obtain more robust classification schemes. However, most approaches in the field incorporated feature engineering to build efficient sentiment classifiers.The purpose of our research is to establish an effective sentiment classification scheme by pursuing the paradigm of ensemble pruning. Ensemble pruning is a crucial method to build classifier ensembles with high predictive accuracy and efficiency. Previous studies employed exponential search, randomized search, sequential search, ranking based pruning and clustering based pruning. However, there are tradeoffs in selecting the ensemble pruning methods. In this regard, hybrid ensemble pruning schemes can be more promising.In this study, we propose a hybrid ensemble pruning scheme based on clustering and randomized search for text sentiment classification. Furthermore, a consensus clustering scheme is presented to deal with the instability of clustering results. The classifiers of the ensemble are initially clustered into groups according to their predictive characteristics. Then, two classifiers from each cluster are selected as candidate classifiers based on their pairwise diversity. The search space of candidate classifiers is explored by the elitist Pareto-based multi-objective evolutionary algorithm.For the evaluation task, the proposed scheme is tested on twelve balanced and unbalanced benchmark text classification tasks. In addition, the proposed approach is experimentally compared with three ensemble methods (AdaBoost, Bagging and Random Subspace) and three ensemble pruning algorithms (ensemble selection from libraries of models, Bagging ensemble selection and LibD3C algorithm). Results demonstrate that the consensus clustering and the elitist pareto-based multi-objective evolutionary algorithm can be effectively used in ensemble pruning. The experimental analysis with conventional ensemble methods and pruning algorithms indicates the validity and effectiveness of the proposed scheme.},
journal = {Inf. Process. Manage.},
month = {jul},
pages = {814–833},
numpages = {20},
keywords = {Consensus clustering, Sentiment classification, Ensemble pruning, Multi-objective evolutionary algorithm}
}

@inbook{10.1145/3459637.3482397,
author = {Wang, Yongjie and Ding, Qinxu and Wang, Ke and Liu, Yue and Wu, Xingyu and Wang, Jinglong and Liu, Yong and Miao, Chunyan},
title = {The Skyline of Counterfactual Explanations for Machine Learning Decision Models},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482397},
abstract = {Counterfactual explanations are minimum changes of a given input to alter the original prediction by a machine learning model, usually from an undesirable prediction to a desirable one. Previous works frame this problem as a constrained cost minimization, where the cost is defined as L1/L2 distance (or variants) over multiple features to measure the change. In real-life applications, features of different types are hardly comparable and it is difficult to measure the changes of heterogeneous features by a single cost function. Moreover, existing approaches do not support interactive exploration of counterfactual explanations. To address above issues, we propose the skyline counterfactual explanations that define the skyline of counterfactual explanations as all non-dominated changes. We solve this problem as multi-objective optimization over actionable features. This approach does not require any cost function over heterogeneous features. With the skyline, the user can interactively and incrementally refine their goals on the features and magnitudes to be changed, especially when lacking prior knowledge to express their needs precisely. Intensive experiment results on three real-life datasets demonstrate that the skyline method provides a friendly way for finding interesting counterfactual explanations, and achieves superior results compared to the state-of-the-art methods.},
booktitle = {Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management},
pages = {2030–2039},
numpages = {10}
}

@article{10.1016/j.neucom.2014.06.076,
author = {Duro, Jo\~{a}o A. and Kumar Saxena, Dhish and Deb, Kalyanmoy and Zhang, Qingfu},
title = {Machine Learning Based Decision Support for Many-Objective Optimization Problems},
year = {2014},
issue_date = {December, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {146},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2014.06.076},
doi = {10.1016/j.neucom.2014.06.076},
abstract = {Multiple Criteria Decision-Making (MCDM) based Multi-objective Evolutionary Algorithms (MOEAs) are increasingly becoming popular for dealing with optimization problems with more than three objectives, commonly termed as many-objective optimization problems (MaOPs). These algorithms elicit preferences from a single or multiple Decision Makers (DMs), a priori or interactively, to guide the search towards the solutions most preferred by the DM(s), as against the whole Pareto-optimal Front (POF). Despite its promise for dealing with MaOPs, the utility of this approach is impaired by the lack of-objectivity; repeatability; consistency; and coherence in DM s preferences. This paper proposes a machine learning based framework to counter the above limitations. Towards it, the preference-structure of the different objectives embedded in the problem model is learnt in terms of: a smallest set of conflicting objectives which can generate the same POF as the original problem; the smallest objective sets corresponding to pre-specified errors; and the objective sets of pre-specified sizes that correspond to minimum error. While the focus is on demonstrating how the proposed framework could serve as a decision support for the DM, its performance is also studied vis-\'{\i} -vis an alternative approach (based on dominance relation preservation), for a wide range of test problems and a real-world problem. The results mark a new direction for MCDM based MOEAs for MaOPs.},
journal = {Neurocomput.},
month = {oct},
pages = {30–47},
numpages = {18},
keywords = {Principal component analysis, Maximum variance unfolding, Evolutionary many-objective optimization, Kernels and multiple criteria decision-making}
}

@article{10.5555/2747904.2748252,
author = {Oztekin, Asil and Delen, Dursun and Turkyilmaz, Ali and Zaim, Selim},
title = {A Machine Learning-Based Usability Evaluation Method for ELearning Systems},
year = {2013},
issue_date = {December 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {56},
number = {C},
issn = {0167-9236},
abstract = {The research presented in this paper proposes a new machine learning-based evaluation method for assessing the usability of eLearning systems. Three machine learning methods (support vector machines, neural networks and decision trees) along with multiple linear regression are used to develop prediction models in order to discover the underlying relationship between the overall eLearning system usability and its predictor factors. A subsequent sensitivity analysis is conducted to determine the rank-order importance of the predictors. Using both sensitivity values along with the usability scores, a metric (called severity index) is devised. By applying a Pareto-like analysis, the severity index values are ranked and the most important usability characteristics are identified. The case study results show that the proposed methodology enhances the determination of eLearning system problems by identifying the most pertinent usability factors. The proposed method could provide an invaluable guidance to the usability experts as to what measures should be improved in order to maximize the system usability for a targeted group of end-users of an eLearning system. Usability assessment of eLearning systems is a necessary and challenging problem.Machine learning techniques are effective tools for usability assessments.Pareto-like analysis can help devise severity index values.Sensitivity analysis can help rank the most important usability factors.},
journal = {Decis. Support Syst.},
month = {dec},
pages = {63–73},
numpages = {11},
keywords = {Machine learning, Information fusion, Severity index, Sensitivity analysis, eLearning (web-based learning/distance learning), Usability engineering}
}

@article{10.1016/j.jbi.2020.103578,
author = {Ambalavanan, Ashwin Karthik and Devarakonda, Murthy V.},
title = {Using the Contextual Language Model BERT for Multi-Criteria Classification of Scientific Articles},
year = {2020},
issue_date = {Dec 2020},
publisher = {Elsevier Science},
address = {San Diego, CA, USA},
volume = {112},
number = {C},
issn = {1532-0464},
url = {https://doi.org/10.1016/j.jbi.2020.103578},
doi = {10.1016/j.jbi.2020.103578},
journal = {J. of Biomedical Informatics},
month = {dec},
numpages = {8},
keywords = {Screening scientific articles, Text classification, BERT, Neural networks, Biomedical natural language processing, SciBERT, Machine learning}
}

@article{10.1007/s00500-018-3479-0,
author = {Jim\'{e}nez, Fernando and P\'{e}rez-S\'{a}nchez, Horacio and Palma, Jos\'{e} and S\'{a}nchez, Gracia and Mart\'{\i}nez, Carlos},
title = {A Methodology for Evaluating Multi-Objective Evolutionary Feature Selection for Classification in the Context of Virtual Screening},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3479-0},
doi = {10.1007/s00500-018-3479-0},
abstract = {Virtual screening (VS) methods have been shown to increase success rates in many drug discovery campaigns, when they complement experimental approaches, such as high-throughput screening methods or classical medicinal chemistry approaches. Nevertheless, predictive capability of VS is not yet optimal, mainly due to limitations in the underlying physical principles describing drug binding phenomena. One approach that can improve VS methods is the aid of machine learning methods. When enough experimental data are available to train such methods, predictive capability can considerably increase. We show in this research work how a multi-objective evolutionary search strategy for feature selection, which can provide with small and accurate decision trees that can be very easily understood by chemists, can drastically increase the applicability and predictive ability of these techniques and therefore aid considerable in the drug discovery problem. With the proposed methodology, we find classification models with accuracy between 0.9934 and 1.00 and area under ROC between 0.96 and 1.00 evaluated in full training sets, and accuracy between 0.9849 and 0.9940 and area under ROC between 0.89 and 0.93 evaluated with tenfold cross-validation over 30 iterations, while substantially reducing the model size.},
journal = {Soft Comput.},
month = {sep},
pages = {8775–8800},
numpages = {26},
keywords = {Feature selection, Multi-objective evolutionary algorithms, Virtual screening, Classification, Drug discovery, Decision trees}
}

@inproceedings{10.1145/3457682.3457770,
author = {Shi, Fan and Wang, Honghua and Lu, Tianhang and Wang, Chengliang},
title = {Multi-Objective Optimal Design of Excitation Systems of Synchronous Condensers for HVDC Systems Based on MOEA/D},
year = {2021},
isbn = {9781450389310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457682.3457770},
doi = {10.1145/3457682.3457770},
abstract = {In order to optimize the reactive power characteristics of synchronous condensers and improve the capability of condensers to support the voltage of AC systems, in this paper, the outer loop control of the reactive power of condensers and the outer loop control of the voltage of AC systems are introduced into the design of the main excitation systems of condensers in high voltage direct current (HVDC) systems. Meanwhile, taking the integral values, peak values and steady-state values of voltage deviations of AC systems as objective functions, the multi-objective optimization design of the proportional adjustment coefficients in the outer loop control of the reactive power of condensers and the voltage of AC systems is carried out via utilizing a multi-objective evolutionary algorithm based on decomposition (MOEA/D) combining with fuzzy control method. Its purpose is to alleviate the overvoltage problems of power grids caused by the feedback of the reactive power of condensers and the voltage of AC systems. Lastly, the simulation model of ±100 kV HVDC system with a synchronous condenser is established. The simulation results show that the optimal design method of excitation systems of synchronous condensers proposed in this paper can optimize the reactive power characteristics of the condenser, ensure the rapid regulation of the voltage of the AC system by the condenser, and solve the overvoltage problem in the AC system caused by the reactive power regulation of the condenser which can not change suddenly and the feedback links of the reactive power of the condenser and the voltage of the AC system in the excitation system.},
booktitle = {2021 13th International Conference on Machine Learning and Computing},
pages = {575–581},
numpages = {7},
keywords = {Synchronous condenser, Optimal design, Fuzzy control, HVDC, Multi-objective optimization},
location = {Shenzhen, China},
series = {ICMLC 2021}
}

@article{10.1016/j.asoc.2015.11.037,
author = {Gorza\l{}czany, Marian B. and Rudzi\'{n}ski, Filip},
title = {A Multi-Objective Genetic Optimization for Fast, Fuzzy Rule-Based Credit Classification with Balanced Accuracy and Interpretability},
year = {2016},
issue_date = {March 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.11.037},
doi = {10.1016/j.asoc.2015.11.037},
abstract = {Graphical abstractDisplay Omitted HighlightsNovel fuzzy rule-based classifiers (FRBCs) for financial data classification tasks are proposed.FRBCs are designed using multi-objective evolutionary optimization algorithms.Collection of FRBCs with various levels of accuracy-interpretability trade-off is generated.Benchmark financial data sets are used to evaluate the effectiveness of the proposed system.Highly accurate, interpretable and fast financial decision support is provided by our approach. Credit classification is an important component of critical financial decision making tasks such as credit scoring and bankruptcy prediction. Credit classification methods are usually evaluated in terms of their accuracy, interpretability, and computational efficiency. In this paper, we propose an approach for automatic designing of fuzzy rule-based classifiers (FRBCs) from financial data using multi-objective evolutionary optimization algorithms (MOEOAs). Our method generates, in a single experiment, an optimized collection of solutions (financial FRBCs) characterized by various levels of accuracy-interpretability trade-off. In our approach we address the complexity- and semantics-related interpretability issues, we introduce original genetic operators for the classifier's rule base processing, and we implement our ideas in the context of Non-dominated Sorting Genetic Algorithm II (NSGA-II), i.e., one of the presently most advanced MOEOAs. A significant part of the paper is devoted to an extensive comparative analysis of our approach and 24 alternative methods applied to three standard financial benchmark data sets, i.e., Statlog (Australian Credit Approval), Statlog (German Credit Approval), and Credit Approval (also referred to as Japanese Credit) sets available from the UCI repository of machine learning databases (http://archive.ics.uci.edu/ml). Several performance measures including accuracy, sensitivity, specificity, and some number of interpretability measures are employed in order to evaluate the obtained systems. Our approach significantly outperforms the alternative methods in terms of the interpretability of the obtained financial data classifiers while remaining either competitive or superior in terms of their accuracy and the speed of decision making.},
journal = {Appl. Soft Comput.},
month = {mar},
pages = {206–220},
numpages = {15},
keywords = {Fuzzy rule-based systems, Multi-objective evolutionary optimization, Accuracy and interpretability of credit classification systems, Financial decision support, Genetic computations}
}

@article{10.1109/TCAD.2018.2878129,
author = {Ma, Yuzhe and Roy, Subhendu and Miao, Jin and Chen, Jiamin and Yu, Bei},
title = {Cross-Layer Optimization for High Speed Adders: A Pareto Driven Machine Learning Approach},
year = {2019},
issue_date = {Dec. 2019},
publisher = {IEEE Press},
volume = {38},
number = {12},
issn = {0278-0070},
url = {https://doi.org/10.1109/TCAD.2018.2878129},
doi = {10.1109/TCAD.2018.2878129},
abstract = {In spite of maturity to the modern electronic design automation (EDA) tools, optimized designs at architectural stage may become suboptimal after going through physical design flow. Adder design has been such a long studied fundamental problem in very large-scale integration industry yet designers cannot achieve optimal solutions by running EDA tools on the set of available prefix adder architectures. In this paper, we enhance a state-of-the-art prefix adder synthesis algorithm to obtain a much wider solution space in architectural domain. On top of that, a machine learning-based design space exploration methodology is applied to predict the Pareto frontier of the adders in physical domain, which is infeasible by exhaustively running EDA tools for innumerable architectural solutions. Considering the high cost of obtaining the true values for learning, an active learning algorithm is proposed to select the representative data during learning process, which uses less labeled data while achieving better quality of Pareto frontier. Experimental results demonstrate that our framework can achieve Pareto frontier of high quality over a wide design space, bridging the gap between architectural and physical designs. Source code and data are available at <uri>https://github.com/yuzhe630/adder-DSE</uri>.},
journal = {Trans. Comp.-Aided Des. Integ. Cir. Sys.},
month = {dec},
pages = {2298–2311},
numpages = {14}
}

@article{10.1177/1094342019842915,
author = {Dongarra, Jack and Tourancheau, Bernard and Endrei, Mark and Jin, Chao and Dinh, Minh Ngoc and Abramson, David and Poxon, Heidi and DeRose, Luiz and de Supinski, Bronis R},
title = {Statistical and Machine Learning Models for Optimizing Energy in Parallel Applications},
year = {2019},
issue_date = {Nov 2019},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {33},
number = {6},
issn = {1094-3420},
url = {https://doi.org/10.1177/1094342019842915},
doi = {10.1177/1094342019842915},
abstract = {Rising power costs and constraints are driving a growing focus on the energy efficiency of high performance computing systems. The unique characteristics of a particular system and workload and their effect on performance and energy efficiency are typically difficult for application users to assess and to control. Settings for optimum performance and energy efficiency can also diverge, so we need to identify trade-off options that guide a suitable balance between energy use and performance. We present statistical and machine learning models that only require a small number of runs to make accurate Pareto-optimal trade-off predictions using parameters that users can control. We study model training and validation using several parallel kernels and more complex workloads, including Algebraic Multigrid (AMG), Large-scale Atomic Molecular Massively Parallel Simulator, and Livermore Unstructured Lagrangian Explicit Shock Hydrodynamics. We demonstrate that we can train the models using as few as 12 runs, with prediction error of less than 10%. Our AMG results identify trade-off options that provide up to 45% improvement in energy efficiency for around 10% performance loss. We reduce the sample measurement time required for AMG by 90%, from 13 h to 74 min.},
journal = {Int. J. High Perform. Comput. Appl.},
month = {nov},
pages = {1079–1097},
numpages = {19},
keywords = {regression modeling, high performance computing, machine learning, performance, Energy efficiency}
}

@inproceedings{10.5555/3437539.3437632,
author = {Wang, Zi and Schafer, Benjamin Carrion},
title = {Machine Learning to Set Meta-Heuristic Specific Parameters for High-Level Synthesis Design Space Exploration},
year = {2020},
isbn = {9781450367257},
publisher = {IEEE Press},
abstract = {Raising the level of VLSI design abstraction to C leads to many advantages compared to the use of low-level Hardware Description Languages (HDLs). One key advantage is that it allows the generation of micro-architectures with different trade-offs by simply setting unique combinations of synthesis options. Because the number of these synthesis options is typically very large, exhaustive enumerations are not possible. Hence, heuristics are required. Meta-heuristics like Simulated Annealing (SA), Genetic Algorithm (GA) and Ant Colony Optimizations (ACO) have shown to lead to good results for these types of multi-objective optimization problems. The main problem with these meta-heuristics is that they are very sensitive to their hyper-parameter settings, e.g. in the GA case, the mutation and cross-over rate and the number of parents pairs. To address this, in this work we present a machine learning based approach to automatically set the search parameters for these three meta-heuristics such that a new unseen behavioral description given in C can be effectively explored. Moreover, we present an exploration technique that combines the SA, GA and ACO together and show that our proposed exploration method outperforms a single meta-heuristic.},
booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
articleno = {93},
numpages = {6},
keywords = {meta heuristics, predictive models, high-level synthesis, design space exploration},
location = {Virtual Event, USA},
series = {DAC '20}
}

@article{10.1145/3292040.3219655,
author = {Chen, Yudong and Su, Lili and Xu, Jiaming},
title = {Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/3292040.3219655},
doi = {10.1145/3292040.3219655},
abstract = {We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks. In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q \l{}e m for an arbitrarily small but fixed constant ε&gt;0. The parameter estimate converges in O(\l{}og N) rounds with an estimation error on the order of max √dq/N, ~√d/N , which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q . The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log 3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {96},
numpages = {1},
keywords = {byzantine adversaries, learning, security, distributed systems}
}

@inproceedings{10.1145/3219617.3219655,
author = {Chen, Yudong and Su, Lili and Xu, Jiaming},
title = {Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent},
year = {2018},
isbn = {9781450358460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219617.3219655},
doi = {10.1145/3219617.3219655},
abstract = {We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks. In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q \l{}e m for an arbitrarily small but fixed constant ε&gt;0. The parameter estimate converges in O(\l{}og N) rounds with an estimation error on the order of max √dq/N, ~√d/N , which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q . The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log 3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.},
booktitle = {Abstracts of the 2018 ACM International Conference on Measurement and Modeling of Computer Systems},
pages = {96},
numpages = {1},
keywords = {distributed systems, security, byzantine adversaries, learning},
location = {Irvine, CA, USA},
series = {SIGMETRICS '18}
}

@inproceedings{10.1145/2966986.2967058,
author = {Smithson, Sean C. and Yang, Guang and Gross, Warren J. and Meyer, Brett H.},
title = {Neural Networks Designing Neural Networks: Multi-Objective Hyper-Parameter Optimization},
year = {2016},
isbn = {9781450344661},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2966986.2967058},
doi = {10.1145/2966986.2967058},
abstract = {Artificial neural networks have gone through a recent rise in popularity, achieving state-of-the-art results in various fields, including image classification, speech recognition, and automated control. Both the performance and computational complexity of such models are heavily dependant on the design of characteristic hyper-parameters (e.g., number of hidden layers, nodes per layer, or choice of activation functions), which have traditionally been optimized manually. With machine learning penetrating low-power mobile and embedded areas, the need to optimize not only for performance (accuracy), but also for implementation complexity, becomes paramount. In this work, we present a multi-objective design space exploration method that reduces the number of solution networks trained and evaluated through response surface modelling. Given spaces which can easily exceed 1020 solutions, manually designing a near-optimal architecture is unlikely as opportunities to reduce network complexity, while maintaining performance, may be overlooked. This problem is exacerbated by the fact that hyper-parameters which perform well on specific datasets may yield sub-par results on others, and must therefore be designed on a per-application basis. In our work, machine learning is leveraged by training an artificial neural network to predict the performance of future candidate networks. The method is evaluated on the MNIST and CIFAR-10 image datasets, optimizing for both recognition accuracy and computational complexity. Experimental results demonstrate that the proposed method can closely approximate the Pareto-optimal front, while only exploring a small fraction of the design space.},
booktitle = {Proceedings of the 35th International Conference on Computer-Aided Design},
articleno = {104},
numpages = {8},
location = {Austin, Texas},
series = {ICCAD '16}
}

@article{10.1145/3154503,
author = {Chen, Yudong and Su, Lili and Xu, Jiaming},
title = {Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent},
year = {2017},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3154503},
doi = {10.1145/3154503},
abstract = {We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks.In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q ≤ for an arbitrarily small but fixed constant ε &gt; 0. The parameter estimate converges in O(log N) rounds with an estimation error on the order of max{√dq/N, √d/N, which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q. The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem.A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
month = {dec},
articleno = {44},
numpages = {25},
keywords = {learning, distributed systems, security, byzantine adversaries}
}

@inproceedings{10.1145/2906363.2906380,
author = {Pham, Nam Khanh and Kumar, Akash and Aung, Khin Mi Mi},
title = {Machine Learning Approach to Generate Pareto Front for List-Scheduling Algorithms},
year = {2016},
isbn = {9781450343206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906363.2906380},
doi = {10.1145/2906363.2906380},
abstract = {List Scheduling is one of the most widely used techniques for scheduling due to its simplicity and efficiency. In traditional list-based schedulers, a cost/priority function is used to compute the priority of tasks/jobs and put them in an ordered list. The cost function has been becoming more and more complex to cover increasing number of constraints in the system design. However, most of the existing list-based schedulers implement a static priority function that usually provides only one schedule for each task graph input. Therefore, they may not be able to satisfy the desire of system designers, who want to examine the trade-off between a number of design requirements (performance, power, energy, reliability ...). To address this problem, we propose a framework to utilize the Genetic Algorithm (GA) for exploring the design space and obtaining Pareto-optimal design points. Furthermore, multiple regression techniques are used to build predictive models for the Pareto fronts to limit the execution time of GA. The models are built using training task graph datasets and applied on incoming task graphs. The Pareto fronts for incoming task graphs are produced in time 2 orders of magnitude faster than the traditional GA, with only 4% degradation in the quality.},
booktitle = {Proceedings of the 19th International Workshop on Software and Compilers for Embedded Systems},
pages = {127–134},
numpages = {8},
keywords = {Machine Learning, List-scheduling, Design space exploration},
location = {Sankt Goar, Germany},
series = {SCOPES '16}
}

@article{10.1007/s10257-019-00402-1,
author = {Yang, Ying},
title = {Research on the Optimization of the Supplier Intelligent Management System for Cross-Border e-Commerce Platforms Based on Machine Learning},
year = {2020},
issue_date = {Dec 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {4},
issn = {1617-9846},
url = {https://doi.org/10.1007/s10257-019-00402-1},
doi = {10.1007/s10257-019-00402-1},
abstract = {At present, with the continuous development of the intelligent system, it is used in many industries. In e-commerce industry, the intelligent system has also been used, especially in supplier management. Based on the machine learning theory, this paper studies the optimization of the supplier management intelligent system of cross-border e-commerce platforms. Based on the wisdom algorithm and machine learning perspective, the optimization of cross-border e-commerce platform supplier credit system is studied in this paper. Firstly, the calculation of the traditional supplier credit evaluation is optimized by introducing the decision matrix algorithm of the difference matrix and the cloud model evaluation method. Then a multi-objective joint decision model of supplier selection and order allocation is established, and the multi-objective evolutionary algorithm combined with actual examples is applied to verify the effectiveness and feasibility of the algorithm and model. Finally, the decision makers’ preferences are integrated into the intelligent decision-making, and the cloud model evaluation method is adopted. The rough set and gray relational analysis mathematical tools are used to construct the procurement supply evaluation system. The research results show that the comparison of the three general indicators of the procurement supply chain can be obtained through the cloud model evaluation calculation, which indirectly reflects the preference decision weights of the three objective functions of the cross-border e-commerce supplier selection and order allocation multi-objective optimization model. This indicates that the procurement supply evaluation system constructed in this paper has achieved the purpose of scientific evaluation and selection of suppliers, and has played a theoretical reference role for supplier management of cross-border e-commerce platform.},
journal = {Inf. Syst. E-Bus. Manag.},
month = {dec},
pages = {851–870},
numpages = {20},
keywords = {Machine learning, System optimization, Cross-border e-commerce}
}

@inproceedings{10.1145/3478905.3478982,
author = {Cheng, Fangyuan and Jia, Junmin},
title = {Quantitative Interactive Investment Algorithm Based on Machine Learning and Data Mining},
year = {2021},
isbn = {9781450390248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478905.3478982},
doi = {10.1145/3478905.3478982},
abstract = {Quantitative investment is a mean to predict the development of securities and conduct transactions by using computer algorithms, but it usually ignores the guiding role of investors' personal preferences in deciding investment plans. Thus, we suggest a quantitative interactive investment algorithm to integrate the rational goals of investment with the individual preference indicators of decision-making investors. The interactive multi-objective solution algorithm creatively combines the decision tree algorithm which mine the investor's individual preference index from the investor's decision data with the second-generation non-dominated sorting genetic algorithm (NSGA-II). This method solves the problem of the lack of personalized choices in current quantitative investment methods by adding decision-makers’ preference indicators.},
booktitle = {2021 4th International Conference on Data Science and Information Technology},
pages = {396–401},
numpages = {6},
keywords = {Quantitative investment, multi-objective optimization, machine learning, decision maker preference},
location = {Shanghai, China},
series = {DSIT 2021}
}

@article{10.1109/TIP.2015.2492825,
author = {Yousaf, Saqib and Shiyin Qin},
title = {Closed-Loop Restoration Approach to Blurry Images Based on Machine Learning and Feedback Optimization},
year = {2015},
issue_date = {Dec. 2015},
publisher = {IEEE Press},
volume = {24},
number = {12},
issn = {1057-7149},
url = {https://doi.org/10.1109/TIP.2015.2492825},
doi = {10.1109/TIP.2015.2492825},
abstract = {Blind image deconvolution (BID) aims to remove or reduce the degradations that have occurred during the acquisition or processing. It is a challenging ill-posed problem due to a lack of enough information in degraded image for unambiguous recovery of both point spread function (PSF) and clear image. Although recently many powerful algorithms appeared; however, it is still an active research area due to the diversity of degraded images as well as degradations. Closed-loop control systems are characterized with their powerful ability to stabilize the behavior response and overcome external disturbances by designing an effective feedback optimization. In this paper, we employed feedback control to enhance the stability of BID by driving the current estimation quality of PSF to the desired level without manually selecting restoration parameters and using an effective combination of machine learning with feedback optimization. The foremost challenge when designing a feedback structure is to construct or choose a suitable performance metric as a controlled index and a feedback information. Our proposed quality metric is based on the blur assessment of deconvolved patches to identify the best PSF and computing its relative quality. The Kalman filter-based extremum seeking approach is employed to find the optimum value of controlled variable. To find better restoration parameters, learning algorithms, such as multilayer perceptron and bagged decision trees, are used to estimate the generic PSF support size instead of trial and error methods. The problem is modeled as a combination of pattern classification and regression using multiple training features, including noise metrics, blur metrics, and low-level statistics. Multi-objective genetic algorithm is used to find key patches from multiple saliency maps which enhance performance and save extra computation by avoiding ineffectual regions of the image. The proposed scheme is shown to outperform corresponding open-loop schemes, which often fails or needs many assumptions regarding images and thus resulting in sub-optimal results.},
journal = {Trans. Img. Proc.},
month = {dec},
pages = {5928–5941},
numpages = {14},
keywords = {bagged decision trees, learning, blur metric, blind deconvolution, closed-loop, image quality, Feedback optimization}
}

@article{10.1016/j.micpro.2016.09.012,
author = {Pham, Nam Khanh and Kumar, Akash and Singh, Amit Kumar and Khin, Mi Mi Aung},
title = {Leakage Aware Resource Management Approach with Machine Learning Optimization Framework for Partially Reconfigurable Architectures},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {47},
number = {PA},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2016.09.012},
doi = {10.1016/j.micpro.2016.09.012},
abstract = {Developing a comprehensive framework for integrating Genetic Algorithm and Machine Learning techniques to optimize our Leakage-aware RMA: from generating data to building predictive models and predicting Pareto fronts for new Task Graphs.Building a Linear Regression model describing the dependency between the range of Pareto front and Task Graphs features.Applying Density-based Clustering Algorithm to generate near-Pareto-optimal design points.Conducting experiments to examine the performance and efficiency of the proposed ML Optimization Framework. Shrinking size of transistors has enabled us to integrate more and more logic elements into FPGA chips leading to higher computing power. However, it also brings a serious concern to the leakage power dissipation of the FPGA devices. One of the major reasons for leakage power dissipation in FPGA is the utilization of prefetching technique to minimize the reconfiguration overhead (delay) in Partially Reconfigurable (PR) FPGAs. This technique creates delays between the reconfiguration and execution parts of a task, which may lead up to 38% leakage power of FPGA since the SRAM-cells containing reconfiguration information cannot be powered down. In this work, a resource management approach (RMA) containing scheduling, placement and post-placement stages has been proposed to address the aforementioned issue. In scheduling stage, a leakage-aware priority function is derived to cope with the leakage power. The placement stage uses a cost function that allows designers to determine the desired trade-off between performance and leakage-saving. The post-placement stage employs a heuristic approach to close the gaps between reconfiguration and execution of tasks, hence further reduce leakage waste. To further examine the trade-off between performance (schedule length) and leakage waste, we propose a framework to utilize the Genetic Algorithm (GA) for exploring the design space and obtaining Pareto optimal design points. Addressing the time-consuming limitation of GA, we apply Regression technique and Clustering algorithm to build predictive models for the Pareto fronts using a training task graph dataset. Experiments show that our approach can achieve large leakage savings for both synthetic and real-life applications with acceptable extended deadline. Furthermore, different variants of the proposed approach can reduce leakage power by 4065% when compared to a performance-driven approach and by 1543% when compared to state-of-the-art works. Its also proven that our Machine Learning Optimization framework can estimate the Pareto front for new coming task graphs 10x faster than well-established GA approach with only 10% degradation in quality.},
journal = {Microprocess. Microsyst.},
month = {nov},
pages = {231–243},
numpages = {13},
keywords = {Scheduling, Machine learning, Design space exploration, Mapping, Resource management}
}

@article{10.1016/j.neucom.2020.08.094,
author = {Pastor-L\'{o}pez, Iker and Sanz, Borja and Tellaeche, Alberto and Psaila, Giuseppe and de la Puerta, Jos\'{e} Gaviria and Bringas, Pablo G.},
title = {Quality Assessment Methodology Based on Machine Learning with Small Datasets: Industrial Castings Defects},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {456},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.08.094},
doi = {10.1016/j.neucom.2020.08.094},
journal = {Neurocomput.},
month = {oct},
pages = {622–628},
numpages = {7},
keywords = {Artificial vision, Surface defect detection, Machine-learning, Defect categorization}
}

@article{10.1109/TSMCC.2009.2018893,
author = {Jin, Yaochu and Sendhoff, Bernhard},
title = {Corrections to "Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies"},
year = {2009},
issue_date = {May 2009},
publisher = {IEEE Press},
volume = {39},
number = {3},
issn = {1094-6977},
url = {https://doi.org/10.1109/TSMCC.2009.2018893},
doi = {10.1109/TSMCC.2009.2018893},
abstract = {In the above titled paper (ibid., vol. 38, no. 3, pp. 397-415, May 08), there are three sites where an inequality is put wrongly. The corrections are presented here.},
journal = {Trans. Sys. Man Cyber Part C},
month = {may},
pages = {373},
numpages = {1}
}

@article{10.1016/j.inffus.2016.11.005,
author = {Martnez-Ballesteros, Mara and Garca-Heredia, Jos M. and Nepomuceno-Chamorro, Isabel A. and Riquelme-Santos, Jos C.},
title = {Machine Learning Techniques to Discover Genes with Potential Prognosis Role in Alzheimers Disease Using Different Biological Sources},
year = {2017},
issue_date = {July 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {36},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2016.11.005},
doi = {10.1016/j.inffus.2016.11.005},
abstract = {Analyze Alzheimer disease gene expression profiles by changes in expression levels.Integration of machine learning methods: decision tree, associations and clustering.Fusion of external information sources: microarray, PubMed, GO and PPI network.Significant set of down/up regulated genes highly related with Alzheimer disease.Gene expression patterns and deep knowledge into relevant biological functions. Alzheimers disease is a complex progressive neurodegenerative brain disorder, being its prevalence expected to rise over the next decades. Unconventional strategies for elucidating the genetic mechanisms are necessary due to its polygenic nature. In this work, the input information sources are five: a public DNA microarray that measures expression levels of control and patient samples, repositories of known genes associated to Alzheimers disease, additional data, Gene Ontology and finally, a literature review or expert knowledge to validate the results. As methodology to identify genes highly related to this disease, we present the integration of three machine learning techniques: particularly, we have used decision trees, quantitative association rules and hierarchical cluster to analyze Alzheimers disease gene expression profiles to identify genes highly linked to this neurodegenerative disease, through changes in their expression levels between control and patient samples. We propose an ensemble of decision trees and quantitative association rules to find the most suitable configurations of the multi-objective evolutionary algorithm GarNet, in order to overcome the complex parametrization intrinsic to this type of algorithms. To fulfill this goal, GarNet has been executed using multiple configuration settings and the well-known C4.5 has been used to find the minimum accuracy to be satisfied. Then, GarNet is rerun to identify dependencies between genes and their expression levels, so we are able to distinguish between healthy individuals and Alzheimers patients using the configurations that overcome the minimum threshold of accuracy defined by C4.5 algorithm. Finally, a hierarchical cluster analysis has been used to validate the obtained gene-Alzheimers Disease associations provided by GarNet. The results have shown that the obtained rules were able to successfully characterize the underlying information, grouping relevant genes for Alzheimer Disease. The genes reported by our approach provided two well defined groups that perfectly divided the samples between healthy and Alzheimers Disease patients. To prove the relevance of the obtained results, a statistical test and gene expression fold-change were used. Furthermore, this relevance has been summarized in a volcano plot, showing two clearly separated and significant groups of genes that are up or down-regulated in Alzheimers Disease patients. A biological knowledge integration phase was performed based on the information fusion of systematic literature review, enrichment Gene Ontology terms for the described genes found in the hippocampus of patients. Finally, a validation phase with additional data and a permutation test is carried out, being the results consistent with previous studies.},
journal = {Inf. Fusion},
month = {jul},
pages = {114–129},
numpages = {16},
keywords = {Biological knowledge integration, Gene expression profiles, Ensemble learning, Association rules, Alzheimers disease, Statistical significant genes}
}

@inproceedings{10.1145/3205455.3205457,
author = {Sanhueza, Claudio and Jim\'{e}nez, Francia and Berretta, Regina and Moscato, Pablo},
title = {MQAPViz: A Divide-and-Conquer Multi-Objective Optimization Algorithm to Compute Large Data Visualizations},
year = {2018},
isbn = {9781450356183},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205455.3205457},
doi = {10.1145/3205455.3205457},
abstract = {Algorithms for data visualizations are essential tools for transforming data into useful narratives. Unfortunately, very few visualization algorithms can handle the large datasets of many real-world scenarios. In this study, we address the visualization of these datasets as a Multi-Objective Optimization Problem. We propose mQAPViz, a divide-and-conquer multi-objective optimization algorithm to compute large-scale data visualizations. Our method employs the Multi-Objective Quadratic Assignment Problem (mQAP) as the mathematical foundation to solve the visualization task at hand. The algorithm applies advanced sampling techniques originating from the field of machine learning and efficient data structures to scale to millions of data objects. The algorithm allocates objects onto a 2D grid layout. Experimental results on real-world and large datasets demonstrate that mQAPViz is a competitive alternative to existing techniques.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {737–744},
numpages = {8},
keywords = {visualization, large datasets, multi-objective optimization},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@article{10.1007/s00500-019-04047-7,
author = {Sudharson, D. and Prabha, D.},
title = {A Novel Machine Learning Approach for Software Reliability Growth Modelling with Pareto Distribution Function},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-04047-7},
doi = {10.1007/s00500-019-04047-7},
abstract = {Software reliability is the important quantifiable attribute in gaining reliability by assessing faults at the time of testing in the software products. Time-based software reliability models used to identify the defects in the product, and it is not suitable for dynamic situations. Instead of time, test effect is used in few explorations through effort function and it is not realistic for infinite testing time. Identifying number of defects is essential in software reliability models, and this research work presents a Pareto distribution (PD) to predict the fault distribution of software under homogenous and nonhomogeneous conditions along with artificial neural network (ANN). This methodology enables the parallel evolution of a product through NN models which exhibit estimated Pareto optimality with respect to multiple error measures. The proposed PD-ANN-based SRGM describes types of failure data and also improves the accuracy of parameter estimation more than existing growth models such as homogeneous poison process and two fuzzy time series-based software reliability models. Experimental evidence is presented for general application and the proposed framework by generating solutions for different product and developer indexes.
},
journal = {Soft Comput.},
month = {sep},
pages = {8379–8387},
numpages = {9},
keywords = {Software reliability, Pareto distribution, Artificial neural networks, Distribution parameter estimation}
}

@inproceedings{10.1145/3321707.3321729,
author = {Lu, Zhichao and Whalen, Ian and Boddeti, Vishnu and Dhebar, Yashesh and Deb, Kalyanmoy and Goodman, Erik and Banzhaf, Wolfgang},
title = {NSGA-Net: Neural Architecture Search Using Multi-Objective Genetic Algorithm},
year = {2019},
isbn = {9781450361118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321707.3321729},
doi = {10.1145/3321707.3321729},
abstract = {This paper introduces NSGA-Net --- an evolutionary approach for neural architecture search (NAS). NSGA-Net is designed with three goals in mind: (1) a procedure considering multiple and conflicting objectives, (2) an efficient procedure balancing exploration and exploitation of the space of potential neural network architectures, and (3) a procedure finding a diverse set of trade-off network architectures achieved in a single run. NSGA-Net is a population-based search algorithm that explores a space of potential neural network architectures in three steps, namely, a population initialization step that is based on prior-knowledge from hand-crafted architectures, an exploration step comprising crossover and mutation of architectures, and finally an exploitation step that utilizes the hidden useful knowledge stored in the entire history of evaluated neural architectures in the form of a Bayesian Network. Experimental results suggest that combining the dual objectives of minimizing an error metric and computational complexity, as measured by FLOPs, allows NSGA-Net to find competitive neural architectures. Moreover, NSGA-Net achieves error rate on the CIFAR-10 dataset on par with other state-of-the-art NAS methods while using orders of magnitude less computational resources. These results are encouraging and shows the promise to further use of EC methods in various deep-learning paradigms.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {419–427},
numpages = {9},
keywords = {deep learning, image classification, multi objective, bayesian optimization, neural architecture search},
location = {Prague, Czech Republic},
series = {GECCO '19}
}

@inbook{10.5555/3454287.3454537,
author = {Sanmart\'{\i}n, Enrique Fita and Damrich, Sebastian and Hamprecht, Fred A.},
title = {Probabilistic Watershed: Sampling All Spanning Forests for Seeded Segmentation and Semi-Supervised Learning},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The seeded Watershed algorithm / minimax semi-supervised learning on a graph computes a minimum spanning forest which connects every pixel / unlabeled node to a seed / labeled node. We propose instead to consider all possible spanning forests and calculate, for every node, the probability of sampling a forest connecting a certain seed with that node. We dub this approach "Probabilistic Watershed". Leo Grady (2006) already noted its equivalence to the Random Walker / Harmonic energy minimization. We here give a simpler proof of this equivalence and establish the computational feasibility of the Probabilistic Watershed with Kirchhoff's matrix tree theorem. Furthermore, we show a new connection between the Random Walker probabilities and the triangle inequality of the effective resistance. Finally, we derive a new and intuitive interpretation of the Power Watershed.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {250},
numpages = {12}
}

@inproceedings{10.1145/3321707.3321726,
author = {Evans, Benjamin P. and Xue, Bing and Zhang, Mengjie},
title = {What's inside the Black-Box? A Genetic Programming Method for Interpreting Complex Machine Learning Models},
year = {2019},
isbn = {9781450361118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321707.3321726},
doi = {10.1145/3321707.3321726},
abstract = {Interpreting state-of-the-art machine learning algorithms can be difficult. For example, why does a complex ensemble predict a particular class? Existing approaches to interpretable machine learning tend to be either local in their explanations, apply only to a particular algorithm, or overly complex in their global explanations. In this work, we propose a global model extraction method which uses multi-objective genetic programming to construct accurate, simplistic and model-agnostic representations of complex black-box estimators. We found the resulting representations are far simpler than existing approaches while providing comparable reconstructive performance. This is demonstrated on a range of datasets, by approximating the knowledge of complex black-box models such as 200 layer neural networks and ensembles of 500 trees, with a single tree.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1012–1020},
numpages = {9},
keywords = {interpretable machine learning, evolutionary multi-objective optimisation, explainable artificial intelligence},
location = {Prague, Czech Republic},
series = {GECCO '19}
}

@inproceedings{10.5555/3491440.3492099,
author = {Lu, Zhichao and Whalen, Ian and Dhebar, Yashesh and Deb, Kalyanmoy and Goodman, Erik and Banzhaf, Wolfgang and Boddeti, Vishnu Naresh},
title = {NSGA-Net: Neural Architecture Search Using Multi-Objective Genetic Algorithm (Extended Abstract)},
year = {2021},
isbn = {9780999241165},
abstract = {Convolutional neural networks (CNNs) are the backbones of deep learning paradigms for numerous vision tasks. Early advancements in CNN architectures are primarily driven by human expertise and elaborate design. Recently, neural architecture search (NAS) was proposed with the aim of automating the network design process and generating task-dependent architectures. This paper introduces NSGA-Net - an evolutionary search algorithm that explores a space of potential neural network architectures in three steps, namely, a population initialization step that is based on prior-knowledge from hand-crafted architectures, an exploration step comprising crossover and mutation of architectures, and finally an exploitation step that utilizes the hidden useful knowledge stored in the entire history of evaluated neural architectures in the form of a Bayesian Network. The integration of these components allows an efficient design of architectures that are competitive and in many cases outperform both manually and automatically designed architectures on CIFAR-10 classification task. The flexibility provided from simultaneously obtaining multiple architecture choices for different compute requirements further differentiates our approach from other methods in the literature.},
booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
articleno = {659},
numpages = {5},
location = {Yokohama, Yokohama, Japan},
series = {IJCAI'20}
}

@article{10.1016/j.ins.2021.05.008,
author = {Zhang, Nana and Ying, Shi and Ding, Weiping and Zhu, Kun and Zhu, Dandan},
title = {WGNCS: A Robust Hybrid Cross-Version Defect Model via Multi-Objective Optimization and Deep Enhanced Feature Representation},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {570},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.05.008},
doi = {10.1016/j.ins.2021.05.008},
journal = {Inf. Sci.},
month = {sep},
pages = {545–576},
numpages = {32},
keywords = {Wasserstein GAN with Gradient Penalty, Convolutional neural network, Cross-version defect prediction, Multi-objective feature selection, Deep learning techniques}
}

@inproceedings{10.5555/2971808.2972020,
author = {Meng, Pingfan and Althoff, Alric and Gautier, Quentin and Kastner, Ryan},
title = {Adaptive Threshold Non-Pareto Elimination: Re-Thinking Machine Learning for System Level Design Space Exploration on FPGAs},
year = {2016},
isbn = {9783981537062},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {One major bottleneck of the system level OpenCL-to-FPGA design tools is their extremely time consuming synthesis process (including place and route). The design space for a typical OpenCL application contains thousands of possible designs even when considering a small number of design space parameters. It costs months of compute time to synthesize all these possible designs into end-to-end FPGA implementations. Thus, the brute force design space exploration (DSE) is impractical for these design tools.Machine learning is one solution that identifies the valuable Pareto designs by sampling only a small portion of the entire design space. However, most of the existing machine learning frameworks focus on improving the design objective regression accuracy, which is not necessarily suitable for the FPGA DSE task. To address this issue, we propose a novel strategy - Adaptive Threshold Non-Pareto Elimination (ATNE). Instead of focusing on regression accuracy improvement, ATNE focuses on understanding and estimating the inaccuracy. ATNE provides a Pareto identification threshold that adapts to the estimated inaccuracy of the regressor. This adaptive threshold results in a more efficient DSE. For the same prediction quality, ATNE reduces the synthesis complexity by 1.6-2.89x (hundreds of synthesis hours) against the other state of the art frameworks for FPGA DSE. In addition, ATNE is capable of identifying the Pareto designs for certain difficult design spaces which the other existing frameworks are incapable of exploring effectively.},
booktitle = {Proceedings of the 2016 Conference on Design, Automation &amp; Test in Europe},
pages = {918–923},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '16}
}

@article{10.1155/2021/6117513,
author = {Khan, Faridoon and Urooj, Amena and Khan, Saud Ahmed and Alsubie, Abdelaziz and Almaspoor, Zahra and Muhammadullah, Sara and Ferreira, Paulo Jorge Silveira},
title = {Comparing the Forecast Performance of Advanced Statistical and Machine Learning Techniques Using Huge Big Data: Evidence from Monte Carlo Experiments},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6117513},
doi = {10.1155/2021/6117513},
abstract = {This research compares factor models based on principal component analysis (PCA) and partial least squares (PLS) with Autometrics, elastic smoothly clipped absolute deviation (E-SCAD), and minimax concave penalty (MCP) under different simulated schemes like multicollinearity, heteroscedasticity, and autocorrelation. The comparison is made with varying sample size and covariates. We found that in the presence of low and moderate multicollinearity, MCP often produces superior forecasts in contrast to small sample case, whereas E-SCAD remains better. In the case of high multicollinearity, the PLS-based factor model remained dominant, but asymptotically the prediction accuracy of E-SCAD significantly enhances compared to other methods. Under heteroscedasticity, MCP performs very well and most of the time beats the rival methods. In some circumstances under large samples, Autometrics provides a similar forecast as MCP. In the presence of low and moderate autocorrelation, MCP shows outstanding forecasting performance except for the small sample case, whereas E-SCAD produces a remarkable forecast. In the case of extreme autocorrelation, E-SCAD outperforms the rival techniques under both the small and medium samples, but further augmentation in sample size enables MCP forecast more accurate comparatively. To compare the predictive ability of all methods, we split the data into two halves (i.e., data over 1973–2007 as training data and data over 2008–2020 as testing data). Based on the root mean square error and mean absolute error, the PLS-based factor model outperforms the competitor models in terms of forecasting performance.},
journal = {Complex.},
month = {jan},
numpages = {11}
}

@inproceedings{10.1145/3448734.3450463,
author = {Cai, Tian and Gao, Xing and Song, Liang and Liao, Minghong},
title = {The Multi-Task Learning with an Application of Pareto Improvement},
year = {2021},
isbn = {9781450389570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448734.3450463},
doi = {10.1145/3448734.3450463},
abstract = {Multi-task learning is a promising field in machine learning, which aims to improve the performance of multiple related learning tasks by taking advantage of useful information between them. Multi-task learning is essentially equivalent to multi-objective optimization problem, the purpose is to find the most appropriate weight, and because the performance of many deep learning systems based on multi-task learning largely depends on the relative weight of each task loss. It's a problem that we need to study how to calculate the weight value under some constraint conditions by reasonable method. Therefore, this paper employs a powerful method based on convex optimization theory, whose purpose is to find the Pareto optimal solution and get the specific task loss weight. The optimization process is closely related to the gradient in deep learning. In addition, to improve the accuracy, we add the modules of gradient normalization and weight standardization. The experimental results show that the performance of our method is better than that of single task experiment or multi-task experiment under fixed weight, and multi-task experiment based on uncertainty based adaptive learning, and the accuracy is further improved after adding the above modules.},
booktitle = {The 2nd International Conference on Computing and Data Science},
articleno = {11},
numpages = {5},
keywords = {Multi-task learning, multi-objective optimization, Pareto improvement},
location = {Stanford, CA, USA},
series = {CONF-CDS 2021}
}

@article{10.1016/j.asoc.2021.107533,
author = {Macedo, Mariana and Santana, Maira and dos Santos, Wellington P. and Menezes, Ronaldo and Bastos-Filho, Carmelo},
title = {Breast Cancer Diagnosis Using Thermal Image Analysis: A Data-Driven Approach Based on Swarm Intelligence and Supervised Learning for Optimized Feature Selection},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {109},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107533},
doi = {10.1016/j.asoc.2021.107533},
journal = {Appl. Soft Comput.},
month = {sep},
numpages = {21},
keywords = {Swarm intelligence, Feature selection, Breast cancer image diagnosis, Convolutional Neural Networks, Feature extraction, Fish school search}
}

