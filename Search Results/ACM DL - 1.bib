@inproceedings{10.1109/CEC.2016.7743932,
author = {Fan, Zhun and Hu, Kaiwen and Li, Fang and Rong, Yibiao and Li, Wenji and Lin, Huibiao},
title = {Multi-Objective Evolutionary Algorithms Embedded with Machine Learning — A Survey},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC.2016.7743932},
doi = {10.1109/CEC.2016.7743932},
abstract = {Multi-objective evolutionary algorithms (MOEAs) have been widely used in solving multi-objective optimization problems. A great number of the-state-of-art MOEAs have been proposed. These MOEAs can be classified into the following categories: decomposition-based, domination-based, indicator-based, and probability-based methods. Among them, the first four categories belong to non-model based methods, while the fifth one is considered to be model-based method, in which machine learning techniques are often used to build the models. Recently, embedding machine learning mechanisms into MOEAs is becoming popular and promising. In this paper, a relatively thorough review on both traditional MOEAs and those equipped with machine learning mechanisms are made, with the aim of shedding light on the future development of this emerging research field.},
booktitle = {2016 IEEE Congress on Evolutionary Computation (CEC)},
pages = {1262–1266},
numpages = {5},
location = {Vancouver, BC, Canada}
}

@article{10.1016/j.asoc.2015.01.005,
author = {Koch, Patrick and Wagner, Tobias and Emmerich, Michael T.M. and B\"{a}ck, Thomas and Konen, Wolfgang},
title = {Efficient Multi-Criteria Optimization on Noisy Machine Learning Problems},
year = {2015},
issue_date = {April 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {29},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.01.005},
doi = {10.1016/j.asoc.2015.01.005},
abstract = {Graphical abstractDisplay Omitted HighlightsThe Kriging-based EGO techniques performed better than the baseline LHS approach.The use of re-interpolation is crucial to cope with noise.Repeats can be necessary but also decrease the number of possible infill points. Recent research revealed that model-assisted parameter tuning can improve the quality of supervised machine learning (ML) models. The tuned models were especially found to generalize better and to be more robust compared to other optimization approaches. However, the advantages of the tuning often came along with high computation times, meaning a real burden for employing tuning algorithms. While the training with a reduced number of patterns can be a solution to this, it is often connected with decreasing model accuracies and increasing instabilities and noise. Hence, we propose a novel approach defined by a two criteria optimization task, where both the runtime and the quality of ML models are optimized. Because the budgets for this optimization task are usually very restricted in ML, the surrogate-assisted Efficient Global Optimization (EGO) algorithm is adapted. In order to cope with noisy experiments, we apply two hypervolume indicator based EGO algorithms with smoothing and re-interpolation of the surrogate models. The techniques do not need replicates. We find that these EGO techniques can outperform traditional approaches such as latin hypercube sampling (LHS), as well as EGO variants with replicates.},
journal = {Appl. Soft Comput.},
month = {apr},
pages = {357–370},
numpages = {14},
keywords = {Kriging, Machine learning, Multi-criteria optimization, Efficient Global Optimization, Hypervolume indicator}
}

@article{10.1016/j.eswa.2016.11.034,
author = {Ali, Rahman and Lee, Sungyoung and Chung, Tae Choong},
title = {Accurate Multi-Criteria Decision Making Methodology for Recommending Machine Learning Algorithm},
year = {2017},
issue_date = {April 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {71},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.11.034},
doi = {10.1016/j.eswa.2016.11.034},
abstract = {A multi-criteria decision making methodology is proposed to select best classifier.NGT-based method is adapted to choose suitable classifier's evaluation metrics.Accuracy, time complexity and consistency based new ranking criteria is designed.AHP-based method is adapted to estimate relative weights for evaluation metrics.Classifiers are ranked based on relative closeness score, computed using TOPSIS. ObjectiveManual evaluation of machine learning algorithms and selection of a suitable classifier from the list of available candidate classifiers, is highly time consuming and challenging task. If the selection is not carefully and accurately done, the resulting classification model will not be able to produce the expected performance results. In this study, we present an accurate multi-criteria decision making methodology (AMD) which empirically evaluates and ranks classifiers' and allow end users or experts to choose the top ranked classifier for their applications to learn and build classification models for them. Methods and materialExisting classifiers performance analysis and recommendation methodologies lack (a) appropriate method for suitable evaluation criteria selection, (b) relative consistent weighting mechanism, (c) fitness assessment of the classifiers' performances, and (d) satisfaction of various constraints during the analysis process. To assist machine learning practitioners in the selection of suitable classifier(s), AMD methodology is proposed that presents an expert group-based criteria selection method, relative consistent weighting scheme, a new ranking method, called optimum performance ranking criteria, based on multiple evaluation metrics, statistical significance and fitness assessment functions, and implicit and explicit constraints satisfaction at the time of analysis. For ranking the classifiers performance, the proposed ranking method integrates Wgt.Avg.F-score, CPUTimeTesting, CPUTimeTraining, and Consistency measures using the technique for order performance by similarity to ideal solution (TOPSIS). The final relative closeness score produced by TOPSIS, is ranked and the practitioners select the best performance (top-ranked) classifier for their problems in-hand. FindingsBased on the extensive experiments performed on 15 publically available UCI and OpenML datasets using 35 classification algorithms from heterogeneous families of classifiers, an average Spearman's rank correlation coefficient of 0.98 is observed. Similarly, the AMD method has showed improved performance of 0.98 average Spearman's rank correlation coefficient as compared to 0.83 and 0.045 correlation coefficient of the state-of-the-art ranking methods, performance of algorithms (PAlg) and adjusted ratio of ratio (ARR). Conclusion and implicationThe evaluation, empirical analysis of results and comparison with state-of-the-art methods demonstrate the feasibility of AMD methodology, especially the selection and weighting of right evaluation criteria, accurate ranking and selection of optimum performance classifier(s) for the user's application's data in hand. AMD reduces expert's time and efforts and improves system performance by designing suitable classifier recommended by AMD methodology.},
journal = {Expert Syst. Appl.},
month = {apr},
pages = {257–278},
numpages = {22},
keywords = {Classification algorithms, Algorithm recommendation, Ranking classifiers, TOPSIS, Classifiers recommendation, Multi-criteria decision making, Algorithm selection}
}

@article{10.1109/TASL.2012.2191955,
author = {Cui, Xiaodong and Huang, Jing and Chien, Jen-Tzung},
title = {Multi-View and Multi-Objective Semi-Supervised Learning for HMM-Based Automatic Speech Recognition},
year = {2012},
issue_date = {September 2012},
publisher = {IEEE Press},
volume = {20},
number = {7},
issn = {1558-7916},
url = {https://doi.org/10.1109/TASL.2012.2191955},
doi = {10.1109/TASL.2012.2191955},
abstract = {Current hidden Markov acoustic modeling for large-vocabulary continuous speech recognition (LVCSR) heavily relies on the availability of abundant labeled transcriptions. Given that speech labeling is both expensive and time-consuming while there is a huge amount of unlabeled data easily available nowadays, the semi-supervised learning (SSL) from both labeled and unlabeled data aiming to reduce the development cost for LVCSR becomes more important than ever. In this paper, a new SSL approach is proposed which exploits the cross-view transfer learning for LVCSR through a committee machine consisting of multiple views learned from different acoustic features and randomized decision trees. In addition, a multi-objective learning scheme is developed in each view by maximizing a hybrid information-theoretic criterion which is established by the relative entropy between labeled data and their labels and the entropy of unlabeled data. The multi-objective scheme is then generalized to a unified SSL framework which can be interpreted into a variety of learning strategies under different weighting schemes. Experiments conducted on English Broadcast News using 50 hours of transcribed speech with 50 hours and 150 hours of untranscribed speech show the benefits of proposed approaches.},
journal = {Trans. Audio, Speech and Lang. Proc.},
month = {sep},
pages = {1923–1935},
numpages = {13}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining Cross Product Line Rules with Multi-Objective Search and Machine Learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {product line, multi-objective search, configuration, machine learning, rule mining},
location = {Berlin, Germany},
series = {GECCO '17}
}

@article{10.1016/j.cor.2016.10.003,
author = {Wang, Xianpeng and Tang, Lixin},
title = {A Machine-Learning Based Memetic Algorithm for the Multi-Objective Permutation Flowshop Scheduling Problem},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {79},
number = {C},
issn = {0305-0548},
url = {https://doi.org/10.1016/j.cor.2016.10.003},
doi = {10.1016/j.cor.2016.10.003},
abstract = {In recent years, the historical data during the search process of evolutionary algorithms has received increasing attention from many researchers, and some hybrid evolutionary algorithms with machine-learning have been proposed. However, the majority of the literature is centered on continuous problems with a single optimization objective. There are still a lot of problems to be handled for multi-objective combinatorial optimization problems. Therefore, this paper proposes a machine-learning based multi-objective memetic algorithm (ML-MOMA) for the discrete permutation flowshop scheduling problem. There are two main features in the proposed ML-MOMA. First, each solution is assigned with an individual archive to store the non-dominated solutions found by it and based on these individual archives a new population update method is presented. Second, an adaptive multi-objective local search is developed, in which the analysis of historical data accumulated during the search process is used to adaptively determine which non-dominated solutions should be selected for local search and how the local search should be applied. Computational results based on benchmark problems show that the cooperation of the above two features can help to achieve a balance between evolutionary global search and local search. In addition, many of the best known Pareto fronts for these benchmark problems in the literature can be improved by the proposed ML-MOMA. A machine-learning based multi-objective memetic algorithm is proposed.An individual archive is adopted in the generation of new solutions.A machine-learning based two-phase local search is presented.Computational results show that the ML-MOMA is superior to other algorithms.},
journal = {Comput. Oper. Res.},
month = {mar},
pages = {60–77},
numpages = {18},
keywords = {Multi-objective permutation flowshop scheduling, Memetic algorithm, Data analysis}
}

@article{10.1007/s10515-019-00266-2,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat and Lu, Hong},
title = {Using Multi-Objective Search and Machine Learning to Infer Rules Constraining Product Configurations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00266-2},
doi = {10.1007/s10515-019-00266-2},
abstract = {Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i.e., C4.5 and PART) and two multi-objective search algorithms (i.e., NSGA-II and NSGA-III), employs a clustering algorithm (i.e., k means) for classifying rules as high or low confidence rules, which are used for defining three objectives to guide the search. To evaluate SBRM+ (i.e., SBRMNSGA-II+-C45, SBRMNSGA-III+-C45, SBRMNSGA-II+-PART, and SBRMNSGA-III+-PART), we performed two case studies (Cisco and Jitsi) and conducted three types of analyses of results: difference analysis, correlation analysis, and trend analysis. Results of the analyses show that all the SBRM+ approaches performed significantly better than two Random Search-based approaches (RBRM+-C45 and RBRM+-PART) in terms of fitness values, six quality indicators, and 17 machine learning quality measurements (MLQMs). As compared to RBRM+ approaches, SBRM+ approaches have improved the quality of rules based on MLQMs up to 27% for the Cisco case study and 28% for the Jitsi case study.
},
journal = {Automated Software Engg.},
month = {jun},
pages = {1–62},
numpages = {62},
keywords = {Rule mining, Configuration, Interacting products, Machine learning, Multi-objective search, Product line}
}

@article{10.1016/j.cie.2016.06.004,
author = {Kartal, Hasan and Oztekin, Asil and Gunasekaran, Angappa and Cebi, Ferhan},
title = {An Integrated Decision Analytic Framework of Machine Learning with Multi-Criteria Decision Making for Multi-Attribute Inventory Classification},
year = {2016},
issue_date = {November 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {101},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2016.06.004},
doi = {10.1016/j.cie.2016.06.004},
abstract = {A multi-criteria inventory classification method was developed.Machine learning algorithms are integrated with multi-criteria decision making.A case study at an automotive company validates the model with its high accuracy.The proposed method yields significantly better results than others in literature.It is flexibly applicable to other multi-criteria inventory classification cases. The purpose of this study is to develop a hybrid methodology that integrates machine learning algorithms with multi-criteria decision making (MCDM) techniques to effectively conduct multi-attribute inventory analysis. In the proposed methodology, first, ABC analyses using three different MCDM methods (i.e. simple-additive weighting, analytical hierarchy process, and VIKOR) are employed to determine the appropriate class for each of the inventory items. Following this, na\"{\i}ve Bayes, Bayesian network, artificial neural network (ANN), and support vector machine (SVM) algorithms are implemented to predict classes of initially determined stock items. Finally, the detailed prediction performance metrics of algorithms for each method are determined. The comprehensive case study executed at a large-scale automotive company revealed that the best classification accuracy is achieved by SVMs. The results also revealed that Bayesian networks, SVMs and ANNs are all capable of successfully dealing with the unbalanced data problems associated with Pareto distribution, and each of these algorithms performed well against all examined measures, thus validating the fact that machine learning algorithms are highly applicable to inventory classification problems. Therefore, this study presents uniqueness in that it is the first and foremost of its kind to effectively combine MCDM methods with machine learning algorithms in multi-attribute inventory classification and is practically applicable in various inventory settings. Furthermore, this study also provides a comprehensive chronological overview of the existing literature of machine learning methods within inventory classification problems.},
journal = {Comput. Ind. Eng.},
month = {nov},
pages = {599–613},
numpages = {15},
keywords = {ABC analysis, Data mining, Business analytics, Multi-attribute inventory classification}
}

@inproceedings{10.1145/3123024.3123163,
author = {Mlakar, Miha and Lu\v{s}trek, Mitja},
title = {Analyzing Tennis Game through Sensor Data with Machine Learning and Multi-Objective Optimization},
year = {2017},
isbn = {9781450351904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123024.3123163},
doi = {10.1145/3123024.3123163},
abstract = {Wearable devices are heavily used in many sports. However, the existing sports wearables are either not tennis-specific, or are limited to information on shots. We therefore added tennis-specific information to a leading commercial device. Firstly, we developed a method for classifying shot types into forehand, backhand and serve. Secondly, we used multi-objective optimization to distinguish active play from the time in-between points. By combining both parts with the general movement information already provided by the device, we get comprehensive metrics for professional players and coaches to objectively measure a player's performance and enable in-depth tactical analysis.},
booktitle = {Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers},
pages = {153–156},
numpages = {4},
keywords = {wearable analytics, shot detection, tennis, optimization},
location = {Maui, Hawaii},
series = {UbiComp '17}
}

@article{10.1145/3520439,
author = {Sonthi, Vijaya Krishna and Nagarajan, S. and Krishnaraj, N.},
title = {An Intelligent Telugu Handwritten Character Recognition Using Multi-Objective Mayfly Optimization with Deep Learning Based DenseNet Model},
year = {2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3520439},
doi = {10.1145/3520439},
abstract = {Handwritten character recognition process has gained significant attention among research communities due to the application in assistive technologies for visually impaired people, human robot interaction, automated registry for business document, and so on. Handwritten character recognition of Telugu language is hard owing to the absence of massive dataset and trained convolution neural network (CNN). Therefore, this paper introduces an intelligent Telugu character recognition using multi-objective mayfly optimization with deep learning (MOMFO-DL) model. The proposed MOMFO-DL technique involves DenseNet-169 model as a feature extractor to generate a useful set of feature vectors. Moreover, functional link neural network (FLNN) is used as a classification model to recognize and classify the printer characters. The design of MOMFO technique for the parameter optimization of DenseNet model and FLNN model shows the novelty of the work. The use of MOMFO technique helps to optimally tune the parameters in such a way that the overall performance can be improved. The extensive experimental analysis takes place on benchmark datasets and the outcomes are examined with respect to different measures. The experimental results pointed out the supremacy of the MOMFO technique over the recent state of art methods.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {sep}
}

@inproceedings{10.1145/2739480.2754791,
author = {Zhang, Tiantian and Georgiopoulos, Michael and Anagnostopoulos, Georgios C.},
title = {SPRINT Multi-Objective Model Racing},
year = {2015},
isbn = {9781450334723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2739480.2754791},
doi = {10.1145/2739480.2754791},
abstract = {Multi-objective model selection, which is an important aspect of Machine Learning, refers to the problem of identifying a set of Pareto optimal models from a given ensemble of models. This paper proposes SPRINT-Race, a multi-objective racing algorithm based on the Sequential Probability Ratio Test with an Indifference Zone. In SPRINT-Race, a non-parametric ternary-decision sequential analogue of the sign test is adopted to identify pair-wise dominance and non-dominance relationship. In addition, a Bonferroni approach is employed to control the overall probability of any erroneous decisions. In the fixed confidence setting, SPRINT-Race tries to minimize the computational effort needed to achieve a predefined confidence about the quality of the returned models. The efficiency of SPRINT-Race is analyzed on artificially-constructed multi-objective model selection problems with known ground-truth. Moreover, SPRINT-Race is applied to identifying the Pareto optimal parameter settings of Ant Colony Optimization algorithms in the context of solving Traveling Salesman Problems. The experimental results confirm the advantages of SPRINT-Race for multi-objective model selection.},
booktitle = {Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation},
pages = {1383–1390},
numpages = {8},
keywords = {model selection, multi-objective optimization, racing algorithm, sequential probability ratio test},
location = {Madrid, Spain},
series = {GECCO '15}
}

@article{10.1109/TSMCC.2008.919172,
author = {Jin, Yaochu and Sendhoff, B.},
title = {Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies},
year = {2008},
issue_date = {May 2008},
publisher = {IEEE Press},
volume = {38},
number = {3},
issn = {1094-6977},
url = {https://doi.org/10.1109/TSMCC.2008.919172},
doi = {10.1109/TSMCC.2008.919172},
abstract = {Machine learning is inherently a multiobjective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can be mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multiobjective optimization methodology have gained increasing impetus, particularly due to the great success of multiobjective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multiobjective learning approaches are more powerful compared to learning algorithms with a scalar cost function in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. One common benefit of the different multiobjective learning approaches is that a deeper insight into the learning problem can be gained by analyzing the Pareto front composed of multiple Pareto-optimal solutions. This paper provides an overview of the existing research on multiobjective machine learning, focusing on supervised learning. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multiobjective ensemble generation are compared and discussed in detail. Finally, potentially interesting topics in multiobjective machine learning are suggested.},
journal = {Trans. Sys. Man Cyber Part C},
month = {may},
pages = {397–415},
numpages = {19},
keywords = {multiobjective learning, Ensemble, generalization, machine learning, evolutionary multiobjective optimization, neural networks, multiobjective optimization, Pareto optimization}
}

@article{10.1016/j.neucom.2014.05.077,
author = {Rosales-P\'{e}rez, Alejandro and Gonzalez, Jesus A. and Coello Coello, Carlos A. and Escalante, Hugo Jair and Reyes-Garcia, Carlos A.},
title = {Multi-Objective Model Type Selection},
year = {2014},
issue_date = {December, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {146},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2014.05.077},
doi = {10.1016/j.neucom.2014.05.077},
abstract = {Classification is a mainstream within the machine learning community. As a result, a large number of learning algorithms have been proposed. The performance of many of these could highly depend on the chosen values of their hyper-parameters. This paper introduces a novel method for addressing the model selection problem for a given classification task. In our model selection formulation, both the learning algorithm and its hyper-parameters are considered. In our proposed approach, model selection is tackled as a multi-objective optimization problem. The empirical error, or training error, and the model complexity are defined as the objectives. We adopt a multi-objective evolutionary algorithm as the search engine, due to its high performance and its advantages for solving multi-objective problems. The model complexity is estimated experimentally, in a general fashion, for any learning algorithm, through the VC dimension. Strategies for choosing a single model or for constructing an ensemble of models from the resulting non-dominated set are also proposed. Experimental results on benchmark data sets indicate the effectiveness of the proposed approach. Furthermore, a comparative study shows that the obtained models are highly competitive, in terms of generalization performance, with other methods in the state of the art that focus on a single-learning algorithm, or a single-objective approach.},
journal = {Neurocomput.},
month = {oct},
pages = {83–94},
numpages = {12},
keywords = {VC dimension, Multi-objective optimization, Model type selection, Ensemble methods}
}

@article{10.1007/s00607-020-00813-w,
author = {Ghasemi, Arezoo and Toroghi Haghighat, Abolfazl},
title = {A Multi-Objective Load Balancing Algorithm for Virtual Machine Placement in Cloud Data Centers Based on Machine Learning},
year = {2020},
issue_date = {Sep 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {102},
number = {9},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-020-00813-w},
doi = {10.1007/s00607-020-00813-w},
abstract = {Cloud computing provides utility computing in which clients pay the cost according to their demands and service use. There are some challenges to this technology. One of these issues in data centers is virtual machine (VM) placement so that mapping of these VMs to hosts is executed for a variety of objectives such as load balancing, reducing energy consumption, increasing resource utilization, shortening response time, etc. In this paper, a strategy is presented based on machine learning for VM replacement which aims to balance the load in host machines (HM). In this proposed strategy, the learning agent, in each learning episode by selecting an action from among the permissible actions and executing it on the environment receives a reward according to the desirability of the solution obtained by doing that action in the environment. Receiving a reward from the environment and updating the action value table enable the learner agent to learn in the following episodes that in each environment state, selecting and executing which action is better in the environment and this leads to further enhancement. Our proposed algorithm has, on average, improved the inter-HM load balance in terms of processor, memory, and bandwidth by 25%, 34%, and 32%, respectively, prior to the implementation of the algorithm. Our strategy was compared from diffrent aspects in three scenarios to the MOVMrB strategy. Finally, it was concluded that our proposed algorithm can be more effective in load balancing by having much less runtime and turning off more HMs.},
journal = {Computing},
month = {sep},
pages = {2049–2072},
numpages = {24},
keywords = {68T05, Virtual machine placement, 68Q99, 68M14, Cloud computing, Load balancing, Machine learning}
}

@article{10.1016/j.eswa.2020.113236,
author = {Martins, Isabelle D. and Bahiense, Laura and Infante, Carlos E.D. and Arruda, Edilson F.},
title = {Dimensionality Reduction for Multi-Criteria Problems: An Application to the Decommissioning of Oil and Gas Installations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {148},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.113236},
doi = {10.1016/j.eswa.2020.113236},
journal = {Expert Syst. Appl.},
month = {jun},
numpages = {11},
keywords = {Dimensionality reduction, Machine learning, Multi-criteria decision analysis, Oil and gas, Decommissioning, Feature selection}
}

@inproceedings{10.1145/3205651.3208219,
author = {Ribeiro, Victor Henrique Alves and Reynoso-Meza, Gilberto},
title = {A Multi-Objective Optimization Design Framework for Ensemble Generation},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208219},
doi = {10.1145/3205651.3208219},
abstract = {Machine learning algorithms have found to be useful for the solution of complex engineering problems. However, due to problem's characteristics, such as class imbalance, classical methods may not be formidable. The authors believe that the application of multi-objective optimization design can improve the results of machine learning algorithms on such scenarios. Thus, this paper proposes a novel methodology for the creation of ensembles of classifiers. To do so, a multi-objective optimization design approach composed of two steps is used. The first step focus on generating a set of diverse classifiers, while the second step focus on the selection of such classifiers as ensemble members. The proposed method is tested on a real-world competition data set, using both decision trees and logistic regression classifiers. Results show that the ensembles created with such technique outperform the best ensemble members.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1882–1885},
numpages = {4},
keywords = {logistic regression, decision trees, multi-objective optimization, ensemble methods},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1145/3055635.3056653,
author = {Das, Sunanda and Chaudhuri, Shreya and Das, Asit K.},
title = {Optimal Set of Overlapping Clusters Using Multi-Objective Genetic Algorithm},
year = {2017},
isbn = {9781450348171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3055635.3056653},
doi = {10.1145/3055635.3056653},
abstract = {Clustering is an important unsupervised machine learning techniqueused in diverse fields to explore the inherent structure of the data. In most of the real life datasets, one object resides in many clusters with different membership values. Many clustering algorithms have been proposed for finding such overlapping clusters for knowledge extraction and future trend prediction. In the paper, multi-objective genetic algorithm based cluster analysis technique is proposed for finding the optimal set of overlapping clusters. As most of the real world search and optimization problems involve multiple objectives, multi-objective Genetic Algorithm is an obvious choice for capturing multiple optimal solutions. Thus the usefulness of applying the multi-objective Genetic Algorithm is to grouping the objects based on different objective functions for finding optimal set of overlapping clusters. The advantage of this algorithm is that it assigns a membership value only to the objects which are the members of several clusters, instead of assigning membership values for all clusters like fuzzy clustering algorithm. If any object positively belongs only to a single cluster, its membership value for this cluster is ' 1' and '0' for all other clusters. The overall performance of the method is investigated on some popular UCI and microarray datasets and the optimality of the clusters is measured by some important cluster validation indices. The experimental results show the effectiveness of the proposed method.},
booktitle = {Proceedings of the 9th International Conference on Machine Learning and Computing},
pages = {232–237},
numpages = {6},
keywords = {Cluster Analysis, Cluster validation index, Fuzzy Clustering, Multi-objective Genetic Algorithm, Overlapping Cluster},
location = {Singapore, Singapore},
series = {ICMLC 2017}
}

@inproceedings{10.1145/3229762.3229764,
author = {Zheng, Lanmin and Chen, Tianqi},
title = {Optimizing Deep Learning Workloads on ARM GPU with TVM},
year = {2018},
isbn = {9781450359238},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229762.3229764},
doi = {10.1145/3229762.3229764},
abstract = {With the great success of deep learning, the demand for deploying deep neural networks to mobile devices is growing rapidly. However, current popular deep learning frameworks are often poorly optimized for mobile devices, especially mobile GPU. In this paper, we follow the pipeline proposed by TVM/NNVM, and optimize both kernel implementations and dataflow graph for ARM Mali GPU. Compared with vendor-provided ARM Compute Library, our kernel implementations and end-to-end pipeline are 1.7x faster on VGG16 and 2.2x faster on mobilenet.},
booktitle = {Proceedings of the 1st on Reproducible Quality-Efficient Systems Tournament on Co-Designing Pareto-Efficient Deep Learning},
articleno = {3},
keywords = {TVM, ARM GPU, GPU Kernel, Deep Learning},
location = {Williamsburg, VA, USA},
series = {ReQuEST '18}
}

@inproceedings{10.5555/3306127.3331714,
author = {Li, Changjian and Czarnecki, Krzysztof},
title = {Urban Driving with Multi-Objective Deep Reinforcement Learning},
year = {2019},
isbn = {9781450363099},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Autonomous driving is a challenging domain that entails multiple aspects: a vehicle should be able to drive to its destination as fast as possible while avoiding collision, obeying traffic rules and ensuring the comfort of passengers. In this paper, we present a deep learning variant of thresholded lexicographic Q-learning for the task of urban driving. Our multi-objective DQN agent learns to drive on multi-lane roads and intersections, yielding and changing lanes according to traffic rules. We also propose an extension for factored Markov Decision Processes to the DQN architecture that provides auxiliary features for the Q function. This is shown to significantly improve data efficiency. footnoteData efficiency as measured by the number of training steps required to achieve similar performance. We then show that the learned policy is able to zero-shot transfer to a ring road without sacrificing performance.},
booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {359–367},
numpages = {9},
keywords = {markov decision process (mdp), reinforcement learning, autonomous driving, deep learning, multi-objective optimization},
location = {Montreal QC, Canada},
series = {AAMAS '19}
}

@inproceedings{10.1145/1830483.1830575,
author = {Kramer, Oliver and Danielsiek, Holger},
title = {DBSCAN-Based Multi-Objective Niching to Approximate Equivalent Pareto-Subsets},
year = {2010},
isbn = {9781450300728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1830483.1830575},
doi = {10.1145/1830483.1830575},
abstract = {In systems optimization and machine learning multiple alternative solutions may exist in different parts of decision space for the same parts of the Pareto-front. The detection of equivalent Pareto-subsets may be desirable. In this paper we introduce a niching method that approximates Pareto-optimal solutions with diversity mechanisms in objective and decision space. For diversity in objective space we use rake selection, a selection method based on the distances to reference lines in objective space. For diversity in decision space we introduce a niching approach that uses the density based clustering method DBSCAN. The clustering process assigns the population to niches while the multi-objective optimization process concentrates on each niche independently. We introduce an indicator for the adaptive control of clustering processes, and extend rake selection by the concept of adaptive corner points. The niching method is experimentally validated on parameterized test function with the help of the S-metric.},
booktitle = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation},
pages = {503–510},
numpages = {8},
keywords = {local search, hybrid metaheuristics, hybrid evolutionary multiobjective algorithm, memetic algorithms},
location = {Portland, Oregon, USA},
series = {GECCO '10}
}

@article{10.1016/j.asoc.2015.09.009,
author = {Mousavi, R. and Eftekhari, M.},
title = {A New Ensemble Learning Methodology Based on Hybridization of Classifier Ensemble Selection Approaches},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {37},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.09.009},
doi = {10.1016/j.asoc.2015.09.009},
abstract = {Proposing a new hybrid approach for ensemble learning systems that exploits the abilities of static ensemble selection (SES) and dynamic ensemble selection (DES) strategies.Presenting an SES approach based on NSGAII multi-objective genetic algorithm.Improving one of the DES approaches by utilizing the SES proposed method.Justifying the performance of the proposed methods by UCI repository and LKC datasets. Ensemble learning is a system that improves the performance and robustness of the classification problems. How to combine the outputs of base classifiers is one of the fundamental challenges in ensemble learning systems. In this paper, an optimized Static Ensemble Selection (SES) approach is first proposed on the basis of NSGA-II multi-objective genetic algorithm (called SES-NSGAII), which selects the best classifiers along with their combiner, by simultaneous optimization of error and diversity objectives. In the second phase, the Dynamic Ensemble Selection-Performance (DES-P) is improved by utilizing the first proposed method. The second proposed method is a hybrid methodology that exploits the abilities of both SES and DES approaches and is named Improved DES-P (IDES-P). Accordingly, combining static and dynamic ensemble strategies as well as utilizing NSGA-II are the main contributions of this research. Findings of the present study confirm that the proposed methods outperform the other ensemble approaches over 14 datasets in terms of classification accuracy. Furthermore, the experimental results are described from the view point of Pareto front with the aim of illustrating the relationship between diversity and the over-fitting problem.},
journal = {Appl. Soft Comput.},
month = {dec},
pages = {652–666},
numpages = {15},
keywords = {Static ensemble selection, Ensemble learning system, Classifier combination, Classifier diversity, Multi-objective optimization, Dynamic ensemble selection}
}

@inproceedings{10.1145/3234804.3234823,
author = {Wei, Wu and He, Shuai and Wang, DongLiang and Yeboah, Yao},
title = {Multi-Objective Deep CNN for Outdoor Auto-Navigation},
year = {2018},
isbn = {9781450364737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234804.3234823},
doi = {10.1145/3234804.3234823},
abstract = {Target-guided navigation establishes the foundation for efficiently addressing vision-based multi-agent coordination for robotics. This work proposes a multi-objective deep convolution network which consists of two parallel branches built atop a shared feature extractor. The proposed network is capable of concurrently constructing semantic maps while achieving efficient visual detection of a designated guider robot or landmark towards outdoor navigation. In order to achieve the low latency requirements of the navigation controller, the structure and parameters of the network have been meticulously designed to boost run-time performance. The model is trained and tested on an altered version of the Cityscape outdoor dataset. We further finetune using a collected dataset in order to improve generalization performance on unseen outdoor scenes. Experimental results on an outdoor navigation robot equipped with an RGBD camera and GPU mini PC verifies the feasibility of the model.},
booktitle = {Proceedings of the 2018 2nd International Conference on Deep Learning Technologies},
pages = {81–85},
numpages = {5},
keywords = {Single-shot-detector, Object detection, Deeplab, Semantic segmentation, Outdoor navigation, MobileNet},
location = {Chongqing, China},
series = {ICDLT '18}
}

@article{10.1016/j.eswa.2016.09.008,
author = {Heloulou, Imen and Radjef, Mohammed Said and Kechadi, Mohand Tahar},
title = {Automatic Multi-Objective Clustering Based on Game Theory},
year = {2017},
issue_date = {January 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.09.008},
doi = {10.1016/j.eswa.2016.09.008},
abstract = {Novel multi-objective clustering algorithm based-sequential games was proposed.It optimizes simultaneously and efficiently multiple conflicting objectives.Proposed approach can automatically calculate the optimal number of clusters.This algorithm shows good performance of generating high-quality solutions.Experimental study demonstrates the effectiveness of our algorithm over others. Data clustering is a very well studied problem in machine learning, data mining, and related disciplines. Most of the existing clustering methods have focused on optimizing a single clustering objective. Often, several recent disciplines such as robot team deployment, ad hoc networks, multi-agent systems, facility location, etc., need to consider multiple criteria, often conflicting, during clustering. Motivated by this, in this paper, we propose a sequential game theoretic approach for multi-objective clustering, called ClusSMOG-II. It is specially designed to optimize simultaneously intrinsically conflicting objectives, which are inter-cluster/intra-cluster inertia and connectivity. This technique has an advantage of keeping the number of clusters dynamic. The approach consists of three main steps. The first step sets initial clusters with their representatives, whereas the second step calculates the correct number of clusters by resolving a sequence of multi-objective multi-act sequential two-player games for conflict-clusters. Finally, the third step constructs homogenous clusters by resolving sequential two-player game between each cluster representative and the representative of its nearest neighbor. For each game, we define payoff functions that correspond to the model objectives. We use a methodology based on backward induction to calculate a pure Nash equilibrium for each game. Experimental results confirm the effectiveness of the proposed approach over state-of-the-art clustering algorithms.},
journal = {Expert Syst. Appl.},
month = {jan},
pages = {32–48},
numpages = {17},
keywords = {Sequential game, Backward induction, Multi-objective clustering, Nash equilibrium}
}

@article{10.1016/j.asoc.2021.107850,
author = {Espinosa, Raquel and Palma, Jos\'{e} and Jim\'{e}nez, Fernando and Kami\'{n}ska, Joanna and Sciavicco, Guido and Lucena-S\'{a}nchez, Estrella},
title = {A Time Series Forecasting Based Multi-Criteria Methodology for Air Quality Prediction},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107850},
doi = {10.1016/j.asoc.2021.107850},
journal = {Appl. Soft Comput.},
month = {dec},
numpages = {25},
keywords = {Multivariate time series forecasting, Deep learning, Multi-criteria decision support systems, Air quality}
}

@article{10.1007/s00500-020-04967-9,
author = {Sekh, Arif Ahmed and Dogra, Debi Prosad and Kar, Samarjit and Roy, Partha Pratim},
title = {Video Trajectory Analysis Using Unsupervised Clustering and Multi-Criteria Ranking},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-04967-9},
doi = {10.1007/s00500-020-04967-9},
abstract = {Surveillance camera usage has increased significantly for visual surveillance. Manual analysis of large video data recorded by cameras may not be feasible on a larger scale. In various applications, deep learning-guided supervised systems are used to track and identify unusual patterns. However, such systems depend on learning which may not be possible. Unsupervised methods relay on suitable features and demand cluster analysis by experts. In this paper, we propose an unsupervised trajectory clustering method referred to as t-Cluster. Our proposed method prepares indexes of object trajectories by fusing high-level interpretable features such as origin, destination, path, and deviation. Next, the clusters are fused using multi-criteria decision making and trajectories are ranked accordingly. The method is able to place abnormal patterns on the top of the list. We have evaluated our algorithm and compared it against competent baseline trajectory clustering methods applied to videos taken from publicly available benchmark datasets. We have obtained higher clustering accuracies on public datasets with significantly lesser computation overhead.},
journal = {Soft Comput.},
month = {nov},
pages = {16643–16654},
numpages = {12},
keywords = {Unsupervised clustering, Object trajectory, Motion analysis}
}

@article{10.1016/j.engappai.2015.05.009,
author = {Ma, Haiping and Su, Shufei and Simon, Dan and Fei, Minrui},
title = {Ensemble Multi-Objective Biogeography-Based Optimization with Application to Automated Warehouse Scheduling},
year = {2015},
issue_date = {September 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {44},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.05.009},
doi = {10.1016/j.engappai.2015.05.009},
abstract = {This paper proposes an ensemble multi-objective biogeography-based optimization (EMBBO) algorithm, which is inspired by ensemble learning, to solve the automated warehouse scheduling problem. First, a real-world automated warehouse scheduling problem is formulated as a constrained multi-objective optimization problem. Then EMBBO is formulated as a combination of several multi-objective biogeography-based optimization (MBBO) algorithms, including vector evaluated biogeography-based optimization (VEBBO), non-dominated sorting biogeography-based optimization (NSBBO), and niched Pareto biogeography-based optimization (NPBBO). Performance is tested on a set of 10 unconstrained multi-objective benchmark functions and 10 constrained multi-objective benchmark functions from the 2009 Congress on Evolutionary Computation (CEC), and compared with single constituent MBBO and CEC competition algorithms. Results show that EMBBO is better than its constituent algorithms, and among the best CEC competition algorithms, for the benchmark functions studied in this paper. Finally, EMBBO is successfully applied to the automated warehouse scheduling problem, and the results show that EMBBO is a competitive algorithm for automated warehouse scheduling.},
journal = {Eng. Appl. Artif. Intell.},
month = {sep},
pages = {79–90},
numpages = {12},
keywords = {Automated warehousing, Performance analysis, Multi-objective optimization, Simulation, Travel time analysis}
}

@article{10.1016/j.cie.2021.107425,
author = {Liu, Ling and Mart\'{\i}n-Barrag\'{a}n, Bel\'{e}n and Prieto, Francisco J.},
title = {A Projection Multi-Objective SVM Method for Multi-Class Classification},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107425},
doi = {10.1016/j.cie.2021.107425},
journal = {Comput. Ind. Eng.},
month = {aug},
numpages = {13},
keywords = {Multi-class multi-objective SVM, Pareto-optimal solution, Multiple objective programming, Support vector machine}
}

@inproceedings{10.5555/3465085.3465129,
author = {Wortmann, Thomas and Natanian, Jonathan},
title = {Multi-Objective Optimization for Zero-Energy Urban Design in China: A Benchmark},
year = {2020},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Environmental simulation supports the design of more sustainable, zero-energy neighborhoods, especially when leveraged with multi-objective optimization. This study explores the tradeoff between urban density and energy balance---specifically, monthly load match between energy usage and generation---in terms of courtyard, slab, and tower typologies for a hypothetical neighborhood in Shanghai. Using this problem as a multi-objective optimization benchmark, the study compares the evolutionary algorithms HypE and NSGA-II with RBFMOpt, a novel, machine learning-related algorithm. The study concludes that RBFMOpt finds slightly better Pareto fronts and is much more robust, and that courtyard typologies are the most efficient for both low- and high-density neighborhoods.},
booktitle = {Proceedings of the 11th Annual Symposium on Simulation for Architecture and Urban Design},
articleno = {44},
numpages = {8},
keywords = {monthly load match, multi-objective optimization benchmark, zero-energy urban design, model-based optimization},
location = {Virtual Event, Austria},
series = {SimAUD '20}
}

@inproceedings{10.5555/3408352.3408593,
author = {Yin, Zixuan and Gross, Warren and Meyer, Brett H.},
title = {Probabilistic Sequential Multi-Objective Optimization of Convolutional Neural Networks},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {With the advent of deeper, larger and more complex convolutional neural networks (CNN), manual design has become a daunting task, especially when hardware performance must be optimized. Sequential model-based optimization (SMBO) is an efficient method for hyperparameter optimization on highly parameterized machine learning (ML) algorithms, able to find good configurations with a limited number of evaluations by predicting the performance of candidates before evaluation. A case study on MNIST shows that SMBO regression model prediction error significantly impedes search performance in multi-objective optimization. To address this issue, we propose probabilistic SMBO, which selects candidates based on probabilistic estimation of their Pareto efficiency. With a formulation that incorporates error in accuracy prediction and uncertainty in latency measurement, probabilistic Pareto efficiency quantifies a candidate's quality in two ways: its likelihood of being Pareto optimal, and the expected number of current Pareto optimal solutions that it will dominate. We evaluate our proposed method on four image classification problems. Compared to a deterministic approach, probabilistic SMBO consistently generates Pareto optimal solutions that perform better, and that are competitive with state-of-the-art efficient CNN models, offering tremendous speedup in inference latency while maintaining comparable accuracy.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {1055–1060},
numpages = {6},
location = {Grenoble, France},
series = {DATE '20}
}

@article{10.14778/3467861.3467867,
author = {Zhang, Yuhao and McQuillan, Frank and Jayaram, Nandish and Kak, Nikhil and Khanna, Ekta and Kislal, Orhan and Valdano, Domino and Kumar, Arun},
title = {Distributed Deep Learning on Data Systems: A Comparative Analysis of Approaches},
year = {2021},
issue_date = {June 2021},
publisher = {VLDB Endowment},
volume = {14},
number = {10},
issn = {2150-8097},
url = {https://doi.org/10.14778/3467861.3467867},
doi = {10.14778/3467861.3467867},
abstract = {Deep learning (DL) is growing in popularity for many data analytics applications, including among enterprises. Large business-critical datasets in such settings typically reside in RDBMSs or other data systems. The DB community has long aimed to bring machine learning (ML) to DBMS-resident data. Given past lessons from in-DBMS ML and recent advances in scalable DL systems, DBMS and cloud vendors are increasingly interested in adding more DL support for DB-resident data. Recently, a new parallel DL model selection execution approach called Model Hopper Parallelism (MOP) was proposed. In this paper, we characterize the particular suitability of MOP for DL on data systems, but to bring MOP-based DL to DB-resident data, we show that there is no single "best" approach, and an interesting tradeoff space of approaches exists. We explain four canonical approaches and build prototypes upon Greenplum Database, compare them analytically on multiple criteria (e.g., runtime efficiency and ease of governance) and compare them empirically with large-scale DL workloads. Our experiments and analyses show that it is non-trivial to meet all practical desiderata well and there is a Pareto frontier; for instance, some approaches are 3x-6x faster but fare worse on governance and portability. Our results and insights can help DBMS and cloud vendors design better DL support for DB users. All of our source code, data, and other artifacts are available at https://github.com/makemebitter/cerebro-ds.},
journal = {Proc. VLDB Endow.},
month = {jun},
pages = {1769–1782},
numpages = {14}
}

@inproceedings{10.1145/3297156.3297205,
author = {Malandrino, Delfina and Zaccagnino, Rocco and Zizza, Rosalba},
title = {A Multi-Objective Optimization Model for Music Styles},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297156.3297205},
doi = {10.1145/3297156.3297205},
abstract = {Style recognition is one of the problems mostly faced by Computational Intelligence techniques. Most of them were defined ad-hoc for a specific music genre and so not generalizable and applicable to any style. A music style, both of soloists performer and of musical collectives, is the result of aesthetic goals, i.e., experience and preferences, functional rules, i.e., rules used to produce music, and external influence, i.e., the choices depending by the simultaneous presence of other musicians. We propose a new model of style, defined in terms of a multi-objective problem, where the objective is to minimize the distance between the style of each musician and the stylistic features derived by other musicians. Such a model is general since it is applicable to any type of style. We also propose a new approach for both recognition and automatic composition of styles based on such a model, which exploits a machine learning recognizer and a splicing composer. To assess the effectiveness and the generalization capability of our system we performed several tests using a large set of Jazz transcriptions and a corpus of 4-voice music by J. S. Bach. We show that our classifier is able to achieve a recognition accuracy of 97.1%. With regard to the composition process, we measured the capability of our system to capture both aesthetic goals by collecting subjective perceptions from domain experts, and functional rules by computing the average percentage of (1) typical harmonic progressions in the Jazz music produced and (2) forbidden exceptions, which occur in the 4-voice music, produced.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {247–251},
numpages = {5},
keywords = {Machine learning, Splicing systems, Music Style recognition},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1145/3377930.3389815,
author = {Binder, Martin and Moosbauer, Julia and Thomas, Janek and Bischl, Bernd},
title = {Multi-Objective Hyperparameter Tuning and Feature Selection Using Filter Ensembles},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377930.3389815},
doi = {10.1145/3377930.3389815},
abstract = {Both feature selection and hyperparameter tuning are key tasks in machine learning. Hyperparameter tuning is often useful to increase model performance, while feature selection is undertaken to attain sparse models. Sparsity may yield better model interpretability and lower cost of data acquisition, data handling and model inference. While sparsity may have a beneficial or detrimental effect on predictive performance, a small drop in performance may be acceptable in return for a substantial gain in sparseness. We therefore treat feature selection as a multi-objective optimization task. We perform hyperparameter tuning and feature selection simultaneously because the choice of features of a model may influence what hyperparameters perform well.We present, benchmark, and compare two different approaches for multi-objective joint hyperparameter optimization and feature selection: The first uses multi-objective model-based optimization. The second is an evolutionary NSGA-II-based wrapper approach to feature selection which incorporates specialized sampling, mutation and recombination operators. Both methods make use of parameterized filter ensembles.While model-based optimization needs fewer objective evaluations to achieve good performance, it incurs computational overhead compared to the NSGA-II, so the preferred choice depends on the cost of evaluating a model on given data.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {471–479},
numpages = {9},
keywords = {model-based optimization, multiobjective optimization, hyperparameter optimization, evolutionary algorithms, feature selection},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inproceedings{10.1109/SMC.2015.19,
author = {Zhang, Chong and Sun, Jia Hui and Tan, Kay Chen},
title = {Deep Belief Networks Ensemble with Multi-Objective Optimization for Failure Diagnosis},
year = {2015},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC.2015.19},
doi = {10.1109/SMC.2015.19},
abstract = {Early diagnosis that can detect faults from some symptoms accurately is critical, because it provides the potential benefits such as reducing maintenance costs, improving productivity and avoiding serious damages. Degradation pattern classification for early diagnosis has not been explored in many researches yet. This paper will use hybrid ensemble model for degradation pattern classification. Supervised training of deep models (e.g. Many-layered Neural Nets) is difficult for optimization problem with unlabeled datasets or insufficient data sample. Shallow models (SVMs, Neural Networks, etc...) are unlikely candidates for learning high-level abstractions, since they are affected by the curse of dimensionality. Therefore, deep learning network (DBN), an unsupervised learning model, in diagnosis problem has been investigated to do classification. Few researches have been done for exploring the effects of DBN in diagnosis. In this paper, an ensemble of DBNs with MOEA/D has been applied for diagnosis to handle failure degradation with multivariate sensory data. Turbofan engine degradation dataset is employed to demonstrate the efficacy of the proposed model. We believe that deep learning with multi-objective ensemble for degradation pattern classification can shed new light on failure diagnosis, and our work presented the applicability of this method to diagnosis as well as prognostics.},
booktitle = {2015 IEEE International Conference on Systems, Man, and Cybernetics},
pages = {32–37},
numpages = {6},
location = {Kowloon Tong, Hong Kong}
}

@article{10.1145/3503540,
author = {Sun, Qi and Chen, Tinghuan and Liu, Siting and Chen, Jianli and Yu, Hao and Yu, Bei},
title = {Correlated Multi-Objective Multi-Fidelity Optimization for HLS Directives Design},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {4},
issn = {1084-4309},
url = {https://doi.org/10.1145/3503540},
doi = {10.1145/3503540},
abstract = {High-level synthesis (HLS) tools have gained great attention in recent years because it emancipates engineers from the complicated and heavy hardware description language writing and facilitates the implementations of modern applications (e.g., deep learning models) on Field-programmable Gate Array (FPGA), by using high-level languages and HLS directives. However, finding good HLS directives is challenging, due to the time-consuming design processes, the balances among different design objectives, and the diverse fidelities (accuracies of data) of the performance values between the consecutive FPGA design stages.To find good HLS directives, a novel automatic optimization algorithm is proposed to explore the Pareto designs of the multiple objectives while making full use of the data with different fidelities from different FPGA design stages. Firstly, a non-linear Gaussian process (GP) is proposed to model the relationships among the different FPGA design stages. Secondly, for the first time, the GP model is enhanced as correlated GP (CGP) by considering the correlations between the multiple design objectives, to find better Pareto designs. Furthermore, we extend our model to be a deep version deep CGP (DCGP) by using the deep neural network to improve the kernel functions in Gaussian process models, to improve the characterization capability of the models, and learn better feature representations. We test our design method on some public benchmarks (including general matrix multiplication and sparse matrix-vector multiplication) and deep learning-based object detection model iSmart2 on FPGA. Experimental results show that our methods outperform the baselines significantly and facilitate the deep learning designs on FPGA.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {mar},
articleno = {31},
numpages = {27},
keywords = {Gaussian process, multi-fidelity optimization, High-level synthesis, correlated multi-objective optimization, design space exploration}
}

@article{10.1016/j.neucom.2014.08.075,
author = {Rosales-P\'{e}rez, Alejandro and Gonzalez, Jesus A. and Coello Coello, Carlos A. and Escalante, Hugo Jair and Reyes-Garcia, Carlos A.},
title = {Surrogate-Assisted Multi-Objective Model Selection for Support Vector Machines},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {150},
number = {PA},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2014.08.075},
doi = {10.1016/j.neucom.2014.08.075},
abstract = {Classification is one of the most well-known tasks in supervised learning. A vast number of algorithms for pattern classification have been proposed so far. Among these, support vector machines (SVMs) are one of the most popular approaches, due to the high performance reached by these methods in a wide number of pattern recognition applications. Nevertheless, the effectiveness of SVMs highly depends on their hyper-parameters. Besides the fine-tuning of their hyper-parameters, the way in which the features are scaled as well as the presence of non-relevant features could affect their generalization performance. This paper introduces an approach for addressing model selection for support vector machines used in classification tasks. In our formulation, a model can be composed of feature selection and pre-processing methods besides the SVM classifier. We formulate the model selection problem as a multi-objective one, aiming to minimize simultaneously two components that are closely related to the error of a model: bias and variance components, which are estimated in an experimental fashion. A surrogate-assisted evolutionary multi-objective optimization approach is adopted to explore the hyper-parameters space. We adopted this approach due to the fact that estimating the bias and variance could be computationally expensive. Therefore, by using surrogate-assisted optimization, we expect to reduce the number of solutions evaluated by the fitness functions so that the computational cost would also be reduced. Experimental results conducted on benchmark datasets widely used in the literature, indicate that highly competitive models with a fewer number of fitness function evaluations are obtained by our proposal when it is compared to state of the art model selection methods.},
journal = {Neurocomput.},
month = {feb},
pages = {163–172},
numpages = {10},
keywords = {Support vector machines, Surrogate-assisted optimization, Model selection, Multi-objective optimization}
}

@article{10.1016/j.procs.2016.09.398,
author = {Ba\c{s}aran, Seren},
title = {Multi-Criteria Decision Analysis Approaches for Selecting and Evaluating Digital Learning Objects},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2016.09.398},
doi = {10.1016/j.procs.2016.09.398},
abstract = {The wide spread of internet resources has emerged new paradigms of learning and knowledge delivery to facilitate and enhance learning particularly in e-learning systems. The important milestones of these new paradigms are known as digital learning objects (DLO) which are smallest packed bits for learning. The abundance of these DLOs raises an important question on how to select effectively high quality reusable learning objects. There exist many soft computing approaches such as; fuzzy computing, neural networks, evolutionary computing, support vector machines, machine learning and probabilistic reasoning. In this paper, fuzzy multi-criteria decision-making methods in choosing suitable DLOs were reviewed. This paper discusses recent variety of soft computing methods used in selecting and evaluating digital learning objects through multi criteria decision analysis approaches used; for selecting metrics like basic topical, course similarity, internal topical, basic and user similarity personal, and context similarity situational relevance and for evaluation; scalarization method, employing triangular, trapezoidal and distance based similarity (adapted from TOPSIS techniques). As DLOs continue to evolve it is inevitable to utilize multi-criteria techniques for selecting and or improving quality. The abundance of DLOs has increased the need for applying practical soft computing techniques to retrieve high quality, reusable DLOs.},
journal = {Procedia Comput. Sci.},
month = {dec},
pages = {251–258},
numpages = {8},
keywords = {Digital Learning Objects(DLOs), multi-criteria decision making, soft computing, expert evaluation, fuzzy approach}
}

@article{10.1016/j.eswa.2016.10.015,
author = {Bandaru, Sunith and Ng, Amos H.C. and Deb, Kalyanmoy},
title = {Data Mining Methods for Knowledge Discovery in Multi-Objective Optimization},
year = {2017},
issue_date = {March 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {70},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.10.015},
doi = {10.1016/j.eswa.2016.10.015},
abstract = {Data mining methods for extracting knowledge from multi-objective optimization are reviewed.Methods are classified based on the type and form of knowledge generated.Descriptive statistics, visual data mining and machine learning methods are discussed.Limitations of existing methods are discussed.A generic framework for knowledge-driven optimization is proposed. Real-world optimization problems typically involve multiple objectives to be optimized simultaneously under multiple constraints and with respect to several variables. While multi-objective optimization itself can be a challenging task, equally difficult is the ability to make sense of the obtained solutions. In this two-part paper, we deal with data mining methods that can be applied to extract knowledge about multi-objective optimization problems from the solutions generated during optimization. This knowledge is expected to provide deeper insights about the problem to the decision maker, in addition to assisting the optimization process in future design iterations through an expert system. The current paper surveys several existing data mining methods and classifies them by methodology and type of knowledge discovered. Most of these methods come from the domain of exploratory data analysis and can be applied to any multivariate data. We specifically look at methods that can generate explicit knowledge in a machine-usable form. A framework for knowledge-driven optimization is proposed, which involves both online and offline elements of knowledge discovery. One of the conclusions of this survey is that while there are a number of data mining methods that can deal with data involving continuous variables, only a few ad hoc methods exist that can provide explicit knowledge when the variables involved are of a discrete nature. Part B of this paper proposes new techniques that can be used with such datasets and applies them to discrete variable multi-objective problems related to production systems.},
journal = {Expert Syst. Appl.},
month = {mar},
pages = {139–159},
numpages = {21},
keywords = {Data mining, Machine learning, Multi-objective optimization, Descriptive statistics, Visual data mining, Knowledge-driven optimization}
}

@article{10.1016/j.comnet.2016.07.010,
author = {Ojog, Cristian-Octavian and Marin, Radu-Corneliu and Ciobanu, Radu-Ioan and Dobre, Ciprian},
title = {Multi-Criteria Optimization of Wireless Connectivity over Sparse Networks},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {111},
number = {C},
issn = {1389-1286},
url = {https://doi.org/10.1016/j.comnet.2016.07.010},
doi = {10.1016/j.comnet.2016.07.010},
abstract = {Opportunistic networking shows great promise in providing an infrastructure for MNP, through its unique perspective over mobility.Our previous studies show that WiFi is the most feasible media for opportunistic contacts between peers connected to the same wireless access point.We propose a machine learning algorithm that aims to increase the number of contacts between mobile nodes by using a smarter WiFi access point choosing heuristic.The algorithm properly balances signal strength, latency, bandwidth, and the number of friends predicted to connect to the respective access point.We show through simulations based on real-life tracing data-sets that our proposed solution not only increases the likelihood of opportunistic contacts, but it also evenly distributes social subgraphs of users over wireless networks while improving the overall hit rate. Opportunistic networking is at the basis of cyber-physical Mobile Networks in Proximity (MNP), through its unique perspective over mobility and the incorporation of socio-inspired networking algorithms. However, results in the field are mostly theoretical, proven to account for stricter hit rate and latency requirements in specific environments. They generally assume that two devices being in proximity automatically see one-another, an assumption which might not stand under real-world conditions (Bluetooth assumes a peering session and close-proximity, WiFi Direct implementations are different between manufacturers, etc.).Our previous studies in the area show that WiFi is still the most feasible media for opportunistic contacts. WiFi-enabled devices, with out-of-the-box networking capabilities, can connect in an ad-hoc opportunistic network, over wireless routers, and thus support a cyber-physical infrastructure for opportunistically spreading information.In this article, we propose a machine learning algorithm that aims to increase the number of contacts between mobile nodes by using a smarter WiFi access point selection heuristic. The algorithm is based on properly balancing signal strength, latency, bandwidth, and, most importantly, the number of friends predicted to connect to the respective access point. We show through simulations based on real-life tracing data-sets that our proposed solution not only increases the likelihood of opportunistic contacts, but it also evenly distributes social subgraphs of users over wireless networks while improving the overall hit rate.},
journal = {Comput. Netw.},
month = {dec},
pages = {120–128},
numpages = {9},
keywords = {Learning, Wifi, Social, Machine, Networking, Opportunistic}
}

@article{10.1007/s11042-020-08704-0,
author = {Berlin, S. Jeba and John, Mala},
title = {Particle Swarm Optimization with Deep Learning for Human Action Recognition},
year = {2020},
issue_date = {Jul 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {25–26},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-08704-0},
doi = {10.1007/s11042-020-08704-0},
abstract = {A novel method for human action recognition using a deep learning network with features optimized using particle swarm optimization is proposed. The binary histogram, Harris corner points and wavelet coefficients are the features extracted from the spatiotemporal volume of the video sequence. In order to reduce the computational complexity of the system, the feature space is reduced by particle swarm optimization technique with the multi-objective fitness function. Finally, the performance of the system is evaluated using deep learning neural network (DLNN). Two autoencoders are trained independently and the knowledge embedded in the autoencoders are transferred to the proposed DLNN for human action recognition. The proposed framework achieves an average recognition rate of 91% on UT interaction set 1, 88% on UT interaction set 2, 91% on SBU interaction dataset and 94% on Weizmann dataset.},
journal = {Multimedia Tools Appl.},
month = {jul},
pages = {17349–17371},
numpages = {23},
keywords = {Human action recognition, Video surveillance, Autoencoder, Deep learning network, Particle swarm optimization}
}

@article{10.1016/j.patcog.2015.09.016,
author = {Shu, Wenhao and Shen, Hong},
title = {Multi-Criteria Feature Selection on Cost-Sensitive Data with Missing Values},
year = {2016},
issue_date = {March 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {51},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2015.09.016},
doi = {10.1016/j.patcog.2015.09.016},
abstract = {Feature selection plays an important role in pattern recognition and machine learning. Confronted with high dimensional data in many data analysis tasks, feature selection techniques are designed to find a relevant feature subset of the original features which can facilitate classification. However, in many real-world applications, missing feature values that contribute to test and misclassification costs are emerging to be an issue of increasing concern for most data sets, particularly dealing with big data. The existing feature selection approaches do not address this issue effectively. In this paper, based on rough set theory we address the problem of feature selection for cost-sensitive data with missing values. We first propose a multi-criteria evaluation function to characterize the significance of candidate features, by taking into consideration not only the power in the positive region and boundary region but also their associated costs. On this basis, we develop a forward greedy feature selection algorithm for selecting a feature subset of minimized cost that preserves the same information as the whole feature set. In addition, to improve the efficiency of this algorithm, we implement the selection of candidate features in a dwindling object set. Finally, we demonstrate the superior performance of the proposed algorithm to the existing feature selection algorithms through experimental results on different data sets. HighlightsA multi-criteria based evaluation function is proposed for measuring features from different viewpoints.A dwindling universe is provided to accelerate the feature selection process.A feature selection algorithm is developed on cost-sensitive data with missing values.The efficiency and effectiveness of the proposed algorithm are demonstrated on different data sets.},
journal = {Pattern Recogn.},
month = {mar},
pages = {268–280},
numpages = {13},
keywords = {Cost-sensitive data, Feature selection, Incomplete data, Algorithm MCFSMulti-criteria based feature selection algorithm on cost-sensitive data with missing values, Multi-criteria, Rough sets}
}

@inproceedings{10.1145/2001576.2001756,
author = {Bhowan, Urvesh and Johnston, Mark and Zhang, Mengjie},
title = {Evolving Ensembles in Multi-Objective Genetic Programming for Classification with Unbalanced Data},
year = {2011},
isbn = {9781450305570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2001576.2001756},
doi = {10.1145/2001576.2001756},
abstract = {Machine learning algorithms can suffer a performance bias when data sets are unbalanced. This paper proposes a Multi-objective Genetic Programming approach using negative correlation learning to evolve accurate and diverse ensembles of non-dominated solutions where members vote on class membership. We also compare two popular Pareto-based fitness schemes on the classification tasks. We show that the evolved ensembles achieve high accuracy on both classes using six unbalanced binary data sets, and that this performance is usually better than many of its individual members.},
booktitle = {Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation},
pages = {1331–1338},
numpages = {8},
keywords = {class imbalance, evolutionary multi-objective optimisation, classification, genetic programming},
location = {Dublin, Ireland},
series = {GECCO '11}
}

@inproceedings{10.1145/3453800.3453805,
author = {Ivanova, Malinka and Rozeva, Anna},
title = {Detection of XSS Attack and Defense of REST Web Service – Machine Learning Perspective},
year = {2021},
isbn = {9781450387613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453800.3453805},
doi = {10.1145/3453800.3453805},
abstract = {The paper presents a machine learning approach for detection of stored XSS attack and for defense of REST web service. For this purpose, a XML-based REST web service is developed in JAVA, which is tested and attacked in specially created test-bed simulation environment, consisting of IntelliJ IDEA environment, Postman and web browser. The obtained data sets are processed resulting in the selection of 30 out of 171 features for further treatment. Supervised machine learning classifiers: Random Forest, Random Tree, Decision Tree and Gradient Boosted Tree are used for the detection of known attacks and clustering algorithm k-Means for the identification of unknown threats. The efficiency of implementing machine learning algorithms is evaluated and the results confirm their high accuracy. In addition fuzzy sets and fuzzy logic theory is utilized for solving multi-criteria task in support of decision making for web service defense.},
booktitle = {2021 The 5th International Conference on Machine Learning and Soft Computing},
pages = {22–28},
numpages = {7},
keywords = {machine learning, REST web service defense, XSS stored attack, fuzzy logic},
location = {Da Nang, Viet Nam},
series = {ICMLSC'21}
}

@article{10.1016/j.asoc.2016.06.043,
author = {Basto-Fernandes, Vitor and Yevseyeva, Iryna and M\'{e}ndez, Jos\'{e} R. and Zhao, Jiaqi and Fdez-Riverola, Florentino and T.M. Emmerich, Michael},
title = {A Spam Filtering Multi-Objective Optimization Study Covering Parsimony Maximization and Three-Way Classification},
year = {2016},
issue_date = {November 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {48},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.06.043},
doi = {10.1016/j.asoc.2016.06.043},
abstract = {Display Omitted Advances on applications of multi-objective optimization to anti-SPAM filtering.Parsimony maximization of rule-based SPAM classifiers.Three-way classification balancing user effort and confidence level.Indicator-based/machine learning/decomposition-based evolutionary optimization. Classifier performance optimization in machine learning can be stated as a multi-objective optimization problem. In this context, recent works have shown the utility of simple evolutionary multi-objective algorithms (NSGA-II, SPEA2) to conveniently optimize the global performance of different anti-spam filters. The present work extends existing contributions in the spam filtering domain by using three novel indicator-based (SMS-EMOA, CH-EMOA) and decomposition-based (MOEA/D) evolutionary multi-objective algorithms. The proposed approaches are used to optimize the performance of a heterogeneous ensemble of classifiers into two different but complementary scenarios: parsimony maximization and e-mail classification under low confidence level. Experimental results using a publicly available standard corpus allowed us to identify interesting conclusions regarding both the utility of rule-based classification filters and the appropriateness of a three-way classification system in the spam filtering domain.},
journal = {Appl. Soft Comput.},
month = {nov},
pages = {111–123},
numpages = {13},
keywords = {Spam filtering, Three-way classification, Multi-objective optimization, Rule-based classifiers, SpamAssassin, Parsimony}
}

@article{10.1016/j.eswa.2015.01.061,
author = {Kimovski, Dragi and Ortega, Julio and Ortiz, Andr\'{e}s and Ba\~{n}os, Ra\'{u}l},
title = {Parallel Alternatives for Evolutionary Multi-Objective Optimization in Unsupervised Feature Selection},
year = {2015},
issue_date = {June 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {9},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.01.061},
doi = {10.1016/j.eswa.2015.01.061},
abstract = {Multiobjective unsupervised feature selection with many decision variables is tackled.EEG signals for Brain-Computer Interface (BCI) applications are used as benchmarks.Cooperative evolutionary algorithms for multiobjective optimization are given.Parallel implementations obtain quality results in terms of hypervolume and speedup.Superlinear speedups are justified by adjusting models to experimental results. Many machine learning and pattern recognition applications require reducing dimensionality to improve learning accuracy while irrelevant inputs are removed. This way, feature selection has become an important issue on these researching areas. Nevertheless, as in past years the number of patterns and, more specifically, the number of features to be selected have grown very fast, parallel processing constitutes an important tool to reach efficient approaches that make possible to tackle complex problems within reasonable computing times. In this paper we propose parallel multi-objective optimization approaches to cope with high-dimensional feature selection problems. Several parallel multi-objective evolutionary alternatives are proposed, and experimentally evaluated by using some synthetic and BCI (Brain-Computer Interface) benchmarks. The experimental results show that the cooperation of parallel evolving subpopulations provides improvements in the solution quality and computing time speedups depending on the parallel alternative and data profile.},
journal = {Expert Syst. Appl.},
month = {jun},
pages = {4239–4252},
numpages = {14},
keywords = {Parallel evolutionary algorithms, Unsupervised classification, Multi-objective clustering, Feature selection, High-dimensional data, Speedup models}
}

@inproceedings{10.1109/CEC.2016.7744257,
author = {Cococcioni, Marco and Lazzerini, Beatrice and Pistolesi, Francesco},
title = {A Semi-Supervised Learning-Aided Evolutionary Approach to Occupational Safety Improvement},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC.2016.7744257},
doi = {10.1109/CEC.2016.7744257},
abstract = {Worldwide, four people die every minute as a consequence of illnesses and accidents at work. This considerable number makes occupational safety an important research area aimed at obtaining safer and safer workplaces. This paper presents a semi-supervised learning-aided evolutionary approach to improve occupational safety by classifying workers depending on their own risk perception for the task assigned. More in detail, a semi-supervised learning phase is carried out to initialize a good population of a non-dominated sorting genetic algorithm (NSGA-II). Each chromosome of the population represents a pair of classifiers: one determines a worker's risk perception with respect to a task, the other determines the level of caution of the same worker for the same task. Learning from constraints reinforces the initial training performance. The best Pareto-optimal solution to the problem is selected by means of the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). The proposed framework was tested on real-world data gathered through a website purposely developed. Results showed a good performance of the obtained classifiers, thus validating the effectiveness of the proposed approach in supporting the decision-maker in critical job assignment problems, where risks are a serious threat to the workers' health.},
booktitle = {2016 IEEE Congress on Evolutionary Computation (CEC)},
pages = {3695–3701},
numpages = {7},
location = {Vancouver, BC, Canada}
}

@article{10.1109/TCBB.2019.2918523,
author = {Dutta, Pratik and Saha, Sriparna and Chopra, Saraansh and Miglani, Varnika},
title = {Ensembling of Gene Clusters Utilizing Deep Learning and Protein-Protein Interaction Information},
year = {2020},
issue_date = {Nov.-Dec. 2020},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {17},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2019.2918523},
doi = {10.1109/TCBB.2019.2918523},
abstract = {Cluster ensemble techniques aim to combine the outputs of multiple clustering algorithms to obtain a single consensus partitioning. The current paper reports about the development of a cluster ensemble based technique combining the concepts of multiobjective optimization and deep-learning models for gene clustering where some additional protein-protein interaction information are utilized for generating the consensus partitioning. The proposed ensemble based framework works in four phases: (i) filtering out the irrelevant genes from the microarray dataset: only the statistically significant genes are considered for further data analysis; (ii) generation of diverse base partitionings: a multi-objective optimization-based clustering technique is proposed which simultaneously optimizes three different cluster quality measures and generates a set of partitioning solutions on the Pareto optimal front; (iii) generation of a consensus partitioning: mentha scores, calculated by accessing a highly enriched protein-protein interaction archive named <italic>mentha</italic>, of different clustering solutions are considered for generating a weighted incidence matrix; (iv) finally, two approaches are used to generate a consensus partitioning from the obtained incidence matrix. The first approach is based on a traditional machine learning method, and another approach exploits the graph partitioning algorithm and two deep neural models to generate the final clustering. To validate the efficacy of the proposed ensemble framework, it is applied on five gene expression datasets. We present a comparative analysis of the proposed technique over different clustering algorithms in terms of biological homogeneity index (BHI) and biological stability index (BSI). The traditional approach attains an average 3 and 2 percent improvements over the best non-dominated solution with respect to BHI and BSI, respectively, whereas deep learning models illustrate an average 6.8 and 1.5 percent improvements over the proposed traditional approach with respect to BHI and BSI, respectively. Subsequently, Welch's t-test is executed to prove that the results obtained by the proposed methods are statistically significant. <italic>Availability of data and materials:</italic> <uri>https://github.com/sduttap16/DeepEnsm</uri>.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = {nov},
pages = {2005–2016},
numpages = {12}
}

@article{10.1504/ijcse.2021.113655,
author = {Chaudhuri, Abhilasha and Sahu, Tirath Prasad},
title = {Feature Weighting for Na\"{\i}ve Bayes Using Multi Objective Artificial Bee Colony Algorithm},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {24},
number = {1},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2021.113655},
doi = {10.1504/ijcse.2021.113655},
abstract = {Na\"{\i}ve Bayes (NB) is a widely used classifier in the field of machine learning. However, its conditional independence assumption does not hold true in real-world applications. In literature, various feature weighting approaches have attempted to alleviate this assumption. Almost all of these approaches consider the relationship between feature-class (relevancy) and feature-feature (redundancy) independently, to determine the weights of features. We argue that these two relationships are mutually dependent and both cannot be improved simultaneously, i.e., form a trade-off. This paper proposes a new paradigm to determine the feature weight by formulating it as a multi-objective optimisation problem to balance the trade-off between relevancy and redundancy. Multi-objective artificial bee colony-based feature weighting technique for na\"{\i}ve Bayes (MOABC-FWNB) is proposed. An extensive experimental study was conducted on 20 benchmark UCI datasets. Experimental results show that MOABC-FWNB outperforms NB and other existing state-of-the-art feature weighting techniques.},
journal = {Int. J. Comput. Sci. Eng.},
month = {jan},
pages = {74–88},
numpages = {14},
keywords = {na\"{\i}ve Bayes, multi objective optimisation, artificial bee colony, feature weighting}
}

@inproceedings{10.5555/3390098.3390107,
author = {Aijazi, Arfa N. and Glicksman, Leon R.},
title = {Application of Surrogate Modeling to Multi-Objective Optimization for Residential Retrofit Design},
year = {2019},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {This project combines surrogate modeling, a supervised machine learning technique, to bypass whole building energy simulations to enable multi-objective design optimization. We applied this method to identify Pareto optimal retrofit designs that are energy and cost effective for three residential apartments in Lisbon, Portugal. As part of our validation of this approach, we compared the surrogate model error for these Pareto optimal designs to the error in the rest of the design space when compared to a detailed energy simulation. Surrogate model error is higher towards the minimum and maximum energy consumption within the Pareto optimal designs compared to the rest of the design space. We also find that in the Pareto optimal set some design variable values are near their minimum or maximum value, which could be driving higher surrogate model error. We propose that future research should retrain the surrogate model after identifying design variable values of interest from an initial optimization run.},
booktitle = {Proceedings of the Symposium on Simulation for Architecture and Urban Design},
articleno = {9},
numpages = {7},
location = {Atlanta, Georgia},
series = {SIMAUD '19}
}

@article{10.1016/j.neucom.2020.01.031,
author = {Fan, Chaodong and Ding, Changkun and Zheng, Jinhua and Xiao, Leyi and Ai, Zhaoyang},
title = {Empirical Mode Decomposition Based Multi-Objective Deep Belief Network for Short-Term Power Load Forecasting},
year = {2020},
issue_date = {May 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {388},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.01.031},
doi = {10.1016/j.neucom.2020.01.031},
journal = {Neurocomput.},
month = {may},
pages = {110–123},
numpages = {14},
keywords = {Multi-objective optimization algorithm, Ensemble learning, Power load forecasting, Deep belief network, Empirical Mode Decomposition}
}

@inproceedings{10.1145/3357384.3357995,
author = {Huang, Zhenya and Liu, Qi and Zhai, Chengxiang and Yin, Yu and Chen, Enhong and Gao, Weibo and Hu, Guoping},
title = {Exploring Multi-Objective Exercise Recommendations in Online Education Systems},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3357995},
doi = {10.1145/3357384.3357995},
abstract = {Recommending suitable exercises to students in an online education system is highly useful. Existing approaches usually rely on machine learning techniques to mine large amounts of student interaction log data accumulated in the systems to select the most suitable exercises for each student. Generally, they mainly aim to optimize a single objective, i.e., recommending non-mastered exercises to address the immediate weakness of students. While this is a reasonable objective, there exist more beneficial multiple objectives in the long-term learning process that need to be addressed including Review &amp; Explore, Smoothness of difficulty level and Engagement. In this paper, we propose a novel Deep Reinforcement learning framework, namely DRE, for adaptively recommending Exercises to students with optimization of above three objectives. In the framework, we propose two different Exercise Q-Networks for the agent, i.e., EQNM and EQNR, to generate recommendations following Markov property and Recurrent manner, respectively. We also propose novel reward functions to formally quantify those three objectives so that DRE could update and optimize its recommendation strategy by interactively receiving students' performance feedbacks (e.g., score). We conduct extensive experiments on two real-world datasets. Experimental results clearly show that the proposed DRE can effectively learn from the student interaction data to optimize multiple objectives in a single unified framework and adaptively recommend suitable exercises to students.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {1261–1270},
numpages = {10},
keywords = {recommendation, multiple objectives, deep reinforcement learning},
location = {Beijing, China},
series = {CIKM '19}
}

